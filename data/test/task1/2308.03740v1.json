{
  "paper_id": "2308.03740v1",
  "title": "A Cost Analysis of Generative Language Models and Influence Operations",
  "abstract": "Abstract\nDespite speculation that recent large language models (LLMs) are likely to be used maliciously to improve the quality or scale of influence operations, uncertainty persists regarding the economic value that LLMs offer propagandists. This research constructs a model of costs facing propagandists for content generation at scale and analyzes (1) the potential savings that LLMs could offer propagandists, (2) the potential deterrent effect of monitoring controls on API-accessible LLMs, and (3) the optimal strategy for propagandists choosing between multiple private and/or open source LLMs when conducting influence operations. Primary results suggest that LLMs need only produce usable outputs with relatively low reliability (roughly 25%) to offer cost savings to propagandists, that the potential reduction in content generation costs can be quite high (up to 70% for a highly reliable model), and that monitoring capabilities have sharply limited cost imposition effects when alternative open source models are available. In addition, these results suggest that nation-states—even those conducting many large-scale influence operations per year—are unlikely to benefit economically from training custom LLMs specifically for use in influence operations.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Deepfake video of Zelenskyy could be ‘tip of the iceberg’ in info war, experts warm",
      "abstract": "",
      "year": "2022",
      "venue": "NPR",
      "authors": "Allyn, Bobby"
    },
    {
      "index": 1,
      "title": "Towards Robust Model Watermark via Reducing Parametric Vulnerability",
      "abstract": "",
      "year": "",
      "venue": "Open Review preprint",
      "authors": "Anonymous"
    },
    {
      "index": 2,
      "title": "Artificial Intelligence and Extremism: The Threat of Language Models for Propaganda Purposes",
      "abstract": "",
      "year": "2022",
      "venue": "Centre for Research and Evidence on Security Threats",
      "authors": "Baele, Stephane"
    },
    {
      "index": 3,
      "title": "Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv [cs.CR]",
      "authors": "Bagdasaryan, Eugene and Vitaly Shmatikov"
    },
    {
      "index": 4,
      "title": "What a Pixel Can Tell: Text-to-Image Generation and its Disinformation Potential",
      "abstract": "",
      "year": "2022",
      "venue": "Democracy Reporting International",
      "authors": "Böswald, Lena-Maria and Beatriz Almeida Saab"
    },
    {
      "index": 5,
      "title": "Industrialized Disinformation: 2020 Global Inventory of Organized Social Media Manipulation",
      "abstract": "",
      "year": "2021",
      "venue": "Oxford Internet Institute",
      "authors": "Bradshaw, Samantha, Hannah Bailey, and Philip N. Howard"
    },
    {
      "index": 6,
      "title": "Language Models are Few-Shot Learners",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv [cs.CL]",
      "authors": "Brown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan et al.",
      "orig_title": "Language Models are Few-Shot Learners",
      "paper_id": "2005.14165v4"
    },
    {
      "index": 7,
      "title": "Generative AI at Work",
      "abstract": "",
      "year": "",
      "venue": "NBER Workiing Paper No. 31161",
      "authors": "Brynjolfsson, Erik, Danielle Li, and Lindsey R. Raymond"
    },
    {
      "index": 8,
      "title": "Truth, Lies, and Automation: How Language Models Could Change Disinformation",
      "abstract": "",
      "year": "2021",
      "venue": "Center for Security and Emerging Technology",
      "authors": "Buchanan, Ben, Andrew Lohn, Micah Musser, and Katerina Sedova"
    },
    {
      "index": 9,
      "title": "AI scam calls imitating familiar voices are a growing problem – here’s how they work",
      "abstract": "",
      "year": "2023",
      "venue": "The Conversation",
      "authors": "Buckley, Oliver"
    },
    {
      "index": 10,
      "title": "Artificial Imposters—Cybercriminals Turn to AI Voice Cloning for a New Breed of Scam",
      "abstract": "",
      "year": "2023",
      "venue": "McAfee",
      "authors": "Bunn, Amy"
    },
    {
      "index": 11,
      "title": "Evaluating Large Language Models Trained on Code",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv [cs.LG]",
      "authors": "Chen, Mark, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliviera Pinto, Jared Kaplan, and Harri Edwards et al.",
      "orig_title": "Evaluating Large Language Models Trained on Code",
      "paper_id": "2107.03374v2"
    },
    {
      "index": 12,
      "title": "Pricing",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Cohere"
    },
    {
      "index": 13,
      "title": "Best Practices for Deploying Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "OpenAI Blog",
      "authors": "Cohere, OpenAI and AI21 Labs"
    },
    {
      "index": 14,
      "title": "One Topic, Two Networks: Evaluating Two Chinese Influence Operations on Twitter Related to Xinjiang",
      "abstract": "",
      "year": "2021",
      "venue": "Stanford Internet Observatory & Stanford Cyber Policy Center",
      "authors": "DiResta, Renée, Josh A. Goldstein, Carly Miller and Harvey Wang"
    },
    {
      "index": 15,
      "title": "Exposure to the Russian Internet Research Agency foreign influence campaign on Twitter in the 2016 US election and its relationship to attitudes and voting behavior",
      "abstract": "",
      "year": "2023",
      "venue": "Nature Communications",
      "authors": "Eady, Gregory, Tom Paskhalis, Jan Zilinsky, Richard Bonneau, Jonathan Nagler, and Joshua A. Tucker"
    },
    {
      "index": 16,
      "title": "GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv [econ.GN]",
      "authors": "Eloundou, Tyna, Sam Manning, Pamela Mishkin, and Daniel Rock",
      "orig_title": "GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models",
      "paper_id": "2303.10130v5"
    },
    {
      "index": 17,
      "title": "Disinformation for Hire, a Shadow Industry, Is Quietly Booming",
      "abstract": "",
      "year": "2021",
      "venue": "New York Times",
      "authors": "Fisher, Max"
    },
    {
      "index": 18,
      "title": "Inside Cyber Front Z, the ‘People’s Movement’ Spreading Russian Propaganda",
      "abstract": "",
      "year": "2022",
      "venue": "Vice News",
      "authors": "Gilbert, David"
    },
    {
      "index": 19,
      "title": "Large Language Models and the Future of Disinformation",
      "abstract": "",
      "year": "2022",
      "venue": "YouTube",
      "authors": "Goldstein, Josh, Girish Sastry, Sarah Kreps, and J.D. Maddox"
    },
    {
      "index": 20,
      "title": "Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv [cs.CY]",
      "authors": "Goldstein, Josh, Girish Sastry, Micah Musser, Matthew Gentzel, Renée DiResta, and Katerina Sedova"
    },
    {
      "index": 21,
      "title": "Can AI Write Persuasive Propaganda?",
      "abstract": "",
      "year": "2023",
      "venue": "SocArXiv",
      "authors": "Goldstein, Josh, Jason Chao, Shelby Grossman, Alex Stamos, and Michael Tomz"
    },
    {
      "index": 22,
      "title": "China’s Fake Twitter Accounts Are Tweeting Into the Void",
      "abstract": "",
      "year": "2021",
      "venue": "Foreign Policy",
      "authors": "Goldstein, Josh and Renée DiResta"
    },
    {
      "index": 23,
      "title": "Unheard Voice: Evaluating five years of pro-Western covert influence operations",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Graphika, Stanford Internet Observatory, and Stanford Cyber Policy Center"
    },
    {
      "index": 24,
      "title": "The Microeconomics of Disinformation",
      "abstract": "",
      "year": "2022",
      "venue": "YouTube",
      "authors": "Hwang, Tim"
    },
    {
      "index": 25,
      "title": "How much did GPT-3 cost?",
      "abstract": "",
      "year": "2023",
      "venue": "PC Guide",
      "authors": "Isahq, Rana"
    },
    {
      "index": 26,
      "title": "Research: quantifying GitHub Copilot’s impact on developer productivity and happiness",
      "abstract": "",
      "year": "2022",
      "venue": "GitHub Blog",
      "authors": "Kalliamvakou, Eirini"
    },
    {
      "index": 27,
      "title": "How the Chinese Government Fabricates Social Media Posts for Strategic Distraction, not Engaged Argument",
      "abstract": "",
      "year": "2017",
      "venue": "American Political Science Review",
      "authors": "King, Gary, Jennifer Pan, and Margaret E. Roberts"
    },
    {
      "index": 28,
      "title": "A Watermark for Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv [cs.LG]",
      "authors": "Kirchenbauer, John, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein"
    },
    {
      "index": 29,
      "title": "‘You don’t believe these are real reviews, do you?’ How Fontanka looked at the front line of Cyber Front Z",
      "abstract": "",
      "year": "2022",
      "venue": "Fontanka",
      "authors": "Klochkova, Ksenia"
    },
    {
      "index": 30,
      "title": "Language Models and Cognitive Automation for Economic Research",
      "abstract": "",
      "year": "",
      "venue": "NBER Working Paper 30957",
      "authors": "Korinek, Anton"
    },
    {
      "index": 31,
      "title": "All the News That’s Fit to Fabricate: AI-Generated Text as a Tool of Media Misinformation",
      "abstract": "",
      "year": "2022",
      "venue": "Journal of Experimental Political Science",
      "authors": "Kreps, Sarah, R. Miles McCain and Miles Brundage"
    },
    {
      "index": 32,
      "title": "Ethics for Generative Agents",
      "abstract": "",
      "year": "2023",
      "venue": "Normative Philosophy of Computing",
      "authors": "Lazar, Seth"
    },
    {
      "index": 33,
      "title": "Why Release a Large Language Model?",
      "abstract": "",
      "year": "2021",
      "venue": "EleutherAI Blog",
      "authors": "Leahy, Connor"
    },
    {
      "index": 34,
      "title": "Will AI Make Cyber Swords or Shields A few mathematical models of technological progress",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv [cs.CR]",
      "authors": "Lohn, Andrew and Krystal Jackson",
      "orig_title": "Will AI Make Cyber Swords or Shields: A few mathematical models of technological progress",
      "paper_id": "2207.13825v1"
    },
    {
      "index": 35,
      "title": "Here Are Some Job Ads For The Russian Troll Factory",
      "abstract": "",
      "year": "2018",
      "venue": "BuzzFeed News",
      "authors": "Lytvynenko, Jane"
    },
    {
      "index": 36,
      "title": "Deepfakes and the New AI-Generated Fake Media Creation-Detection Arms Race",
      "abstract": "",
      "year": "2020",
      "venue": "Scientific American",
      "authors": "Lyu, Siwei"
    },
    {
      "index": 37,
      "title": "Pro-PRC DRAGONBRIDGE Influence Campaign Leverages New TTPs to Aggressively Target U.S. Interests, Including Midterm Elections",
      "abstract": "",
      "year": "2022",
      "venue": "Mandiant",
      "authors": "Mandiant Intelligence"
    },
    {
      "index": 38,
      "title": "The Radicalization Risks Posed by GPT-3 and Adavanced Neural Language Models",
      "abstract": "",
      "year": "2020",
      "venue": "Center on Terrorism, Extremism, and Counterterrorism, Middlebury Institute of International Studes",
      "authors": "McGuffie, Kris and Alex Newhouse"
    },
    {
      "index": 39,
      "title": "Machine Learning Model Attribution Challenge",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv [cs.LG]",
      "authors": "Merkhofer, Elizabeth, Deepesh Chaudhari, Hyrum S. Anderson, Keith Manville, Lily Wong, and João Gante"
    },
    {
      "index": 40,
      "title": "The West is ill-prepared for the wave of ‘deep fakes’ that artificial intelligence could unleash",
      "abstract": "",
      "year": "2018",
      "venue": "Brookings Institution",
      "authors": "Meserole, Chris and Alina Polyakova"
    },
    {
      "index": 41,
      "title": "CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code Authoring",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv [cs.SE]",
      "authors": "Murali, Vijayaraghavan, Chandra Maddila, Imad Ahmad, Michael Bolin, Daniel Cheng, Negar Ghorbani, Renuka Fernandez, and Nachiappan Nagappan"
    },
    {
      "index": 42,
      "title": "The LLaMA is out of the bag. Should we expect a tidal wave of disinformation?",
      "abstract": "",
      "year": "2023",
      "venue": "AI Snake Oil",
      "authors": "Narayanan, Arvind and Sayash Kapoor"
    },
    {
      "index": 43,
      "title": "Twitter Post",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Norteño, Conspirador (@conspirator0)"
    },
    {
      "index": 44,
      "title": "Face Check: Photo of Putin on His Knees in Front of China’s Xi",
      "abstract": "",
      "year": "2023",
      "venue": "Newsweek",
      "authors": "Norton, Tom"
    },
    {
      "index": 45,
      "title": "Experimental evidence on the productivity benefits of generative artificial intelligence",
      "abstract": "",
      "year": "2023",
      "venue": "Science",
      "authors": "Noy, Shakked, and Whitney Zhang"
    },
    {
      "index": 46,
      "title": "DALL·E Now Available Without Waitlist",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "OpenAI"
    },
    {
      "index": 47,
      "title": "OpenAI’s API Now Available with No Waitlist",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "OpenAI"
    },
    {
      "index": 48,
      "title": "Pricing",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "OpenAI"
    },
    {
      "index": 49,
      "title": "1 Overview",
      "abstract": "",
      "year": "",
      "venue": "Machine Learning Model Attribution Challenge",
      "authors": "",
      "orig_title": "Overview",
      "paper_id": "2310.16165v2"
    },
    {
      "index": 50,
      "title": "Creatively malicious prompt engineering",
      "abstract": "",
      "year": "2023",
      "venue": "WithSecure Intelligence",
      "authors": "Patel, Andrew and Jason Sattler"
    },
    {
      "index": 51,
      "title": "MosaicBERT: Pretraining BERT from Scratch for $20",
      "abstract": "",
      "year": "2023",
      "venue": "Mosaic",
      "authors": "Portes, Jacob, Alex Trott, Daniel King, and Sam Havens"
    },
    {
      "index": 52,
      "title": "Better Language Models and Their Implications",
      "abstract": "",
      "year": "2019",
      "venue": "OpenAI Blog",
      "authors": "Radford, Alec, Jeffrey Wu, Dario Amodei, Daniela Amodei, Jack Clark, Miles Brundage, and Ilya Sutskever"
    },
    {
      "index": 53,
      "title": "Chilling AI deepfakes purporting to show Trump arrest take over Twitter",
      "abstract": "",
      "year": "2023",
      "venue": "The Independent",
      "authors": "Sarkar, Alisha Rahaman"
    },
    {
      "index": 54,
      "title": "The People Onscreen Are Fake. The Disinformation Is Real",
      "abstract": "",
      "year": "2023",
      "venue": "New York Times",
      "authors": "Satariano, Adam, and Paul Mozur"
    },
    {
      "index": 55,
      "title": "Documents Show How Russia’s Troll Army Hit America",
      "abstract": "",
      "year": "2014",
      "venue": "Buzzfeed News",
      "authors": "Seddon, Max"
    },
    {
      "index": 56,
      "title": "AI and the Future of Disinformation Campaigns, Part 1: The RICHDATA Framework",
      "abstract": "",
      "year": "2021",
      "venue": "Center for Security and Emerging Technology",
      "authors": "Sedova, Katerina"
    },
    {
      "index": 57,
      "title": "AI and the Future of Disinformation Campaigns, Part 2: A Threat Model",
      "abstract": "",
      "year": "2021",
      "venue": "Center for Security and Emerging Technology",
      "authors": "Sedova, Katerina"
    },
    {
      "index": 58,
      "title": "Structured access: an emerging paradigm for safe AI deployment",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv [cs.AI]",
      "authors": "Shelvane, Toby"
    },
    {
      "index": 59,
      "title": "Generative AI Systems Aren’t Just Open or Closed Source",
      "abstract": "",
      "year": "2023",
      "venue": "Wired",
      "authors": "Solaiman, Irene"
    },
    {
      "index": 60,
      "title": "The Gradient of Generative AI Release: Methods and Considerations",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv [cs.CY]",
      "authors": "Solaiman, Irene",
      "orig_title": "The Gradient of Generative AI Release: Methods and Considerations",
      "paper_id": "2302.04844v1"
    },
    {
      "index": 61,
      "title": "Release Strategies and the Social Impacts of Language Models",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv [cs.CL]",
      "authors": "Solaiman, Irene, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford et al."
    },
    {
      "index": 62,
      "title": "Twitter Analysis: Identifying a Pro-BJP Copypasta Influence Operation in India",
      "abstract": "",
      "year": "2021",
      "venue": "<Ben>",
      "authors": "Strick, Benjamin"
    },
    {
      "index": 63,
      "title": "ML-Enahnced Code Completion Improves Developer Productivity",
      "abstract": "",
      "year": "2022",
      "venue": "Google Research Blog",
      "authors": "Tabachnyk, Maxim and Stoyan Nikolov"
    },
    {
      "index": 64,
      "title": "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv [cs.CL]",
      "authors": "Tamkin, Alex, Miles Brundage, Jack Clark, and Deep Ganguli"
    },
    {
      "index": 65,
      "title": "Alpaca: A Strong, Replicable Instruction-Following Model",
      "abstract": "",
      "year": "2023",
      "venue": "Stanford University Center for Research on Foundation Models",
      "authors": "Taori, Rohan, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori Hashimoto"
    },
    {
      "index": 66,
      "title": "AI can now create any image in seconds, bringing wonder and danger",
      "abstract": "",
      "year": "2022",
      "venue": "Washington Post",
      "authors": "Tiku, Nitasha"
    },
    {
      "index": 67,
      "title": "Information Operations",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Twitter Transparency"
    },
    {
      "index": 68,
      "title": "Ethical and Social Risks of Harm from Language Models",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv [cs.CL]",
      "authors": "Weidinger, Laura, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng et al."
    }
  ]
}