{
  "paper_id": "2212.02705v5",
  "title": "What is the Solution for State-Adversarial Multi-Agent Reinforcement Learning?",
  "abstract": "Abstract\nVarious methods for Multi-Agent Reinforcement Learning (MARL) have been developed with the assumption that agents‚Äô policies are based on accurate state information. However, policies learned through Deep Reinforcement Learning (DRL) are susceptible to adversarial state perturbation attacks. In this work, we propose a State-Adversarial Markov Game (SAMG) and make the first attempt to investigate the fundamental properties of MARL under state uncertainties. Our analysis shows that the commonly used solution concepts of optimal agent policy and robust Nash equilibrium do not always exist in SAMGs. To circumvent this difficulty, we consider a new solution concept called robust agent policy, where agents aim to maximize the worst-case expected state value. We prove the existence of robust agent policy for finite state and finite action SAMGs. Additionally, we propose a Robust Multi-Agent Adversarial Actor-Critic (RMA3C) algorithm to learn robust policies for MARL agents under state uncertainties. Our experiments demonstrate that our algorithm outperforms existing methods when faced with state perturbations and greatly improves the robustness of MARL policies. Our code is public on https://songyanghan.github.io/what_is_solution/.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks",
      "abstract": "",
      "year": "2017",
      "venue": "MLDM",
      "authors": "Behzadan, V. and Munir, A.",
      "orig_title": "Vulnerability of deep reinforcement learning to policy induction attacks",
      "paper_id": "1701.04143v1"
    },
    {
      "index": 1,
      "title": "The complexity of decentralized control of markov decision processes",
      "abstract": "",
      "year": "2002",
      "venue": "Mathematics of operations research",
      "authors": "Bernstein, D. S., Givan, R., Immerman, N., and Zilberstein, S."
    },
    {
      "index": 2,
      "title": "A comprehensive survey of multiagent reinforcement learning",
      "abstract": "",
      "year": "2008",
      "venue": "IEEE Trans. Syst., Man, Cybern. Syst.",
      "authors": "Busoniu, L., Babuska, R., and De Schutter, B."
    },
    {
      "index": 3,
      "title": "A social equilibrium existence theorem",
      "abstract": "",
      "year": "1952",
      "venue": "National Academy of Sciences",
      "authors": "Debreu, G."
    },
    {
      "index": 4,
      "title": "Certifiable Robustness to Adversarial State Uncertainty in Deep Reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Trans. Neural Netw. Learn. Syst.",
      "authors": "Everett, M., L√ºtjens, B., and How, J. P.",
      "orig_title": "Certifiable robustness to adversarial state uncertainty in deep reinforcement learning",
      "paper_id": "2004.06496v6"
    },
    {
      "index": 5,
      "title": "Fixed-point and minimax theorems in locally convex topological linear spaces",
      "abstract": "",
      "year": "1952",
      "venue": "National Academy of Sciences of the United States of America",
      "authors": "Fan, K."
    },
    {
      "index": 6,
      "title": "Equilibrium in a stochastic nùëõn-person game",
      "abstract": "",
      "year": "1964",
      "venue": "Journal of science of the hiroshima university, series ai (mathematics)",
      "authors": "Fink, A. M."
    },
    {
      "index": 7,
      "title": "Counterfactual Multi-Agent Policy Gradients",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI",
      "authors": "Foerster, J. and Farquhar, G.",
      "orig_title": "Counterfactual multi-agent policy gradients",
      "paper_id": "1705.08926v3"
    },
    {
      "index": 8,
      "title": "A further generalization of the kakutani fixed point theorem, with application to nash equilibrium points",
      "abstract": "",
      "year": "1952",
      "venue": "American Mathematical Society",
      "authors": "Glicksberg, I. L."
    },
    {
      "index": 9,
      "title": "Joint optimization of handover control and power allocation based on multi-agent deep reinforcement learning",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Trans. Veh. Technol.",
      "authors": "Guo, D., Tang, L., Zhang, X., and Liang, Y.-C."
    },
    {
      "index": 10,
      "title": "Multiagent reinforcement learning: theoretical framework and an algorithm",
      "abstract": "",
      "year": "1998",
      "venue": "ICML",
      "authors": "Hu, J., Wellman, M. P., et al."
    },
    {
      "index": 11,
      "title": "Robust multi-agent reinforcement learning driven by correlated equilibrium",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Hu, Y., Shao, K., Li, D., Jianye, H., Liu, W., Yang, Y., Wang, J., and Zhu, Z."
    },
    {
      "index": 12,
      "title": "Adversarial attacks on neural network policies",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR",
      "authors": "Huang, S., Papernot, N., Goodfellow, I., Duan, Y., and Abbeel, P."
    },
    {
      "index": 13,
      "title": "Guided Deep Reinforcement Learning for Swarm Systems",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1709.06011",
      "authors": "H√ºttenrauch, M. and ≈†o≈°iƒá, A.",
      "orig_title": "Guided deep reinforcement learning for swarm systems",
      "paper_id": "1709.06011v1"
    },
    {
      "index": 14,
      "title": "Actor-Attention-Critic for Multi-Agent Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Iqbal, S. and Sha, F.",
      "orig_title": "Actor-attention-critic for multi-agent reinforcement learning",
      "paper_id": "1810.02912v2"
    },
    {
      "index": 15,
      "title": "Robust dynamic programming",
      "abstract": "",
      "year": "2005",
      "venue": "Mathematics of Operations Research",
      "authors": "Iyengar, G. N."
    },
    {
      "index": 16,
      "title": "What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization?",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Jin, C., Netrapalli, P., and Jordan, M.",
      "orig_title": "What is local optimality in nonconvex-nonconcave minimax optimization?",
      "paper_id": "1902.00618v3"
    },
    {
      "index": 17,
      "title": "V-Learning‚ÄîA Simple, Efficient, Decentralized Algorithm for Multiagent RL",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2110.14555",
      "authors": "Jin, C., Liu, Q., Wang, Y., and Yu, T.",
      "orig_title": "V-learning‚Äìa simple, efficient, decentralized algorithm for multiagent rl",
      "paper_id": "2110.14555v1"
    },
    {
      "index": 18,
      "title": "Discounted robust stochastic games and an application to queueing control",
      "abstract": "",
      "year": "2011",
      "venue": "Operations research",
      "authors": "Karde≈ü, E., Ord√≥√±ez, F., and Hall, R. W."
    },
    {
      "index": 19,
      "title": "Delving Into Adversarial Attacks on Deep Policies",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR",
      "authors": "Kos, J. and Song, D.",
      "orig_title": "Delving into adversarial attacks on deep policies",
      "paper_id": "1705.06452v1"
    },
    {
      "index": 20,
      "title": "SS-SFDA : Self-Supervised Source-Free Domain Adaptation for Road Segmentation in Hazardous Environments",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "Kothandaraman, D., Chandra, R., and Manocha, D.",
      "orig_title": "Ss-sfda: Self-supervised source-free domain adaptation for road segmentation in hazardous environments",
      "paper_id": "2012.08939v2"
    },
    {
      "index": 21,
      "title": "Introductory functional analysis with applications, volume 17",
      "abstract": "",
      "year": "1991",
      "venue": "John Wiley & Sons",
      "authors": "Kreyszig, E."
    },
    {
      "index": 22,
      "title": "Improving Policies via Search in Cooperative Partially Observable Games",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI",
      "authors": "Lerer, A., Hu, H., Foerster, J., and Brown, N.",
      "orig_title": "Improving policies via search in cooperative partially observable games",
      "paper_id": "1912.02318v1"
    },
    {
      "index": 23,
      "title": "Robust multi-agent reinforcement learning via minimax deep deterministic policy gradient",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI",
      "authors": "Li, S., Wu, Y., Cui, X., Dong, H., Fang, F., and Russell, S."
    },
    {
      "index": 24,
      "title": "Efficient adversarial training without attacking: Worst-case-aware robust reinforcement learning",
      "abstract": "",
      "year": "2022",
      "venue": "NeurIPS",
      "authors": "Liang, Y., Sun, Y., Zheng, R., and Huang, F."
    },
    {
      "index": 25,
      "title": "On the Robustness of Cooperative Multi-Agent Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Security and Privacy Workshops (SPW)",
      "authors": "Lin, J., Dzeparoska, K., Zhang, S. Q., Leon-Garcia, A., and Papernot, N.",
      "orig_title": "On the robustness of cooperative multi-agent reinforcement learning",
      "paper_id": "2003.03722v1"
    },
    {
      "index": 26,
      "title": "On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "Lin, T., Jin, C., and Jordan, M.",
      "orig_title": "On gradient descent ascent for nonconvex-concave minimax problems",
      "paper_id": "1906.00331v10"
    },
    {
      "index": 27,
      "title": "Tactics of adversarial attack on deep reinforcement learning agents",
      "abstract": "",
      "year": "2017",
      "venue": "IJCAI",
      "authors": "Lin, Y.-C., Hong, Z.-W., Liao, Y.-H., Shih, M.-L., Liu, M.-Y., and Sun, M."
    },
    {
      "index": 28,
      "title": "Robust target recognition and tracking of self-driving cars with radar and camera information fusion under severe weather conditions",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Trans. Intell. Transp. Syst.",
      "authors": "Liu, Z., Cai, Y., Wang, H., Chen, L., Gao, H., Jia, Y., and Li, Y."
    },
    {
      "index": 29,
      "title": "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "Lowe, R., Wu, Y. I., Tamar, A., Harb, J., Abbeel, O. P., and Mordatch, I.",
      "orig_title": "Multi-agent actor-critic for mixed cooperative-competitive environments",
      "paper_id": "1706.02275v4"
    },
    {
      "index": 30,
      "title": "Adversarially robust policy learning: Active construction of physically-plausible perturbations",
      "abstract": "",
      "year": "2017",
      "venue": "IROS",
      "authors": "Mandlekar, A., Zhu, Y., Garg, A., Fei-Fei, L., and Savarese, S."
    },
    {
      "index": 31,
      "title": "Human-level control through deep reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "Mnih, V., Kavukcuoglu, K., et al."
    },
    {
      "index": 32,
      "title": "Robust reinforcement learning",
      "abstract": "",
      "year": "2005",
      "venue": "Neural computation",
      "authors": "Morimoto, J. and Doya, K."
    },
    {
      "index": 33,
      "title": "Enforcing signal temporal logic specifications in multi-agent adversarial environments: A deep q-learning approach",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Conference on Decision and Control (CDC)",
      "authors": "Muniraj, D., Vamvoudakis, K. G., and Farhood, M."
    },
    {
      "index": 34,
      "title": "Non-cooperative games",
      "abstract": "",
      "year": "1951",
      "venue": "Annals of mathematics",
      "authors": "Nash, J."
    },
    {
      "index": 35,
      "title": "Robust control of markov decision processes with uncertain transition matrices",
      "abstract": "",
      "year": "2005",
      "venue": "Operations Research",
      "authors": "Nilim, A. and El Ghaoui, L."
    },
    {
      "index": 36,
      "title": "A concise introduction to decentralized POMDPs, volume 1",
      "abstract": "",
      "year": "2016",
      "venue": "Springer",
      "authors": "Oliehoek, F. A., Amato, C., et al."
    },
    {
      "index": 37,
      "title": "Robust Deep Reinforcement Learning with Adversarial Attacks",
      "abstract": "",
      "year": "2017",
      "venue": "AAMAS",
      "authors": "Pattanaik, A. and Tang, Z.",
      "orig_title": "Robust deep reinforcement learning with adversarial attacks",
      "paper_id": "1712.03632v1"
    },
    {
      "index": 38,
      "title": "Robust Deep Reinforcement Learning with Adversarial Attacks",
      "abstract": "",
      "year": "2018",
      "venue": "AAMAS",
      "authors": "Pattanaik, A., Tang, Z., Liu, S., Bommannan, G., and Chowdhary, G.",
      "orig_title": "Robust deep reinforcement learning with adversarial attacks",
      "paper_id": "1712.03632v1"
    },
    {
      "index": 39,
      "title": "A game-theoretic analysis of networked system control for common-pool resource management using multi-agent reinforcement learning",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Pretorius, A., Cameron, S., et al.",
      "orig_title": "A game-theoretic analysis of networked system control for common-pool resource management using multi-agent reinforcement learning",
      "paper_id": "2010.07777v1"
    },
    {
      "index": 40,
      "title": "Markov decision processes: discrete stochastic dynamic programming",
      "abstract": "",
      "year": "2014",
      "venue": "John Wiley & Sons",
      "authors": "Puterman, M. L."
    },
    {
      "index": 41,
      "title": "Scalable Multi-Agent Reinforcement Learning for Networked Systems with Average Reward",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Qu, G., Lin, Y., Wierman, A., and Li, N.",
      "orig_title": "Scalable multi-agent reinforcement learning for networked systems with average reward",
      "paper_id": "2006.06626v1"
    },
    {
      "index": 42,
      "title": "Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Rashid, T., Farquhar, G., Peng, B., and Whiteson, S.",
      "orig_title": "Weighted qmix: Expanding monotonic value function factorisation for deep multi-agent reinforcement learning",
      "paper_id": "2006.10800v2"
    },
    {
      "index": 43,
      "title": "Non-convex Min-Max Optimization: Applications, Challenges, and Recent Theoretical Advances",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Signal Process. Mag.",
      "authors": "Razaviyayn, M., Huang, T., Lu, S., Nouiehed, M., Sanjabi, M., and Hong, M.",
      "orig_title": "Nonconvex min-max optimization: Applications, challenges, and recent theoretical advances",
      "paper_id": "2006.08141v2"
    },
    {
      "index": 44,
      "title": "Principles of mathematical analysis, volume 3",
      "abstract": "",
      "year": "1976",
      "venue": "McGraw-hill New York",
      "authors": "Rudin, W. et al."
    },
    {
      "index": 45,
      "title": "Stochastic games",
      "abstract": "",
      "year": "1953",
      "venue": "National Academy of Sciences",
      "authors": "Shapley, L. S."
    },
    {
      "index": 46,
      "title": "Robust opponent modeling via adversarial ensemble reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "ICAPS",
      "authors": "Shen, M. and How, J. P."
    },
    {
      "index": 47,
      "title": "FormulaZero: Distributionally Robust Online Adaptation via Offline Population Synthesis",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Sinha, A., O‚ÄôKelly, M., et al.",
      "orig_title": "Formulazero: Distributionally robust online adaptation via offline population synthesis",
      "paper_id": "2003.03900v2"
    },
    {
      "index": 48,
      "title": "Value-Decomposition Multi-Agent Actor-Critics",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI",
      "authors": "Su, J., Adams, S., and Beling, P.",
      "orig_title": "Value-decomposition multi-agent actor-critics",
      "paper_id": "2007.12306v4"
    },
    {
      "index": 49,
      "title": "Romax: Certifiably robust deep multiagent reinforcement learning via convex relaxation",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2109.06795",
      "authors": "Sun, C., Kim, D.-K., and How, J. P."
    },
    {
      "index": 50,
      "title": "Certifiably Robust Policy Learning against Adversarial Communication in Multi-agent Systems",
      "abstract": "",
      "year": "2022",
      "venue": "ICLR",
      "authors": "Sun, Y., Zheng, R., Hassanzadeh, P., Liang, Y., Feizi, S., Ganesh, S., and Huang, F.",
      "orig_title": "Certifiably robust policy learning against adversarial communication in multi-agent systems",
      "paper_id": "2206.10158v2"
    },
    {
      "index": 51,
      "title": "Value-decomposition networks for cooperative multi-agent learning based on team reward",
      "abstract": "",
      "year": "2018",
      "venue": "AAMAS",
      "authors": "Sunehag, P., Lever, G., et al."
    },
    {
      "index": 52,
      "title": "Introduction to reinforcement learning, volume 135",
      "abstract": "",
      "year": "1998",
      "venue": "MIT press Cambridge",
      "authors": "Sutton, R. S., Barto, A. G., et al."
    },
    {
      "index": 53,
      "title": "Robust Multi-Agent Reinforcement Learning with Social Empowerment for Coordination and Communication",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2012.08255",
      "authors": "van der Heiden, T., Salge, C., Gavves, E., and van Hoof, H.",
      "orig_title": "Robust multi-agent reinforcement learning with social empowerment for coordination and communication",
      "paper_id": "2012.08255v1"
    },
    {
      "index": 54,
      "title": "Characterizing Attacks on Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1907.09470",
      "authors": "Xiao, C., Pan, X., et al.",
      "orig_title": "Characterizing attacks on deep reinforcement learning",
      "paper_id": "1907.09470v3"
    },
    {
      "index": 55,
      "title": "The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games",
      "abstract": "",
      "year": "2022",
      "venue": "NeurIPS",
      "authors": "Yu, C., Velu, A., Vinitsky, E., Wang, Y., Bayen, A., and Wu, Y.",
      "orig_title": "The surprising effectiveness of ppo in cooperative multi-agent games",
      "paper_id": "2103.01955v4"
    },
    {
      "index": 56,
      "title": "Robust reinforcement learning: A constrained game-theoretic approach",
      "abstract": "",
      "year": "2021",
      "venue": "Learning for Dynamics and Control",
      "authors": "Yu, J., Gehring, C., Sch√§fer, F., and Anandkumar, A."
    },
    {
      "index": 57,
      "title": "Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Zhang, H., Chen, H., Xiao, C., Li, B., Liu, M., Boning, D., and Hsieh, C.-J.",
      "orig_title": "Robust deep reinforcement learning against adversarial perturbations on state observations",
      "paper_id": "2003.08938v7"
    },
    {
      "index": 58,
      "title": "Robust reinforcement learning on state observations with learned optimal adversary",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2101.08452",
      "authors": "Zhang, H., Chen, H., Boning, D., and Hsieh, C.-J."
    },
    {
      "index": 59,
      "title": "Robust multi-agent reinforcement learning with model uncertainty",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Zhang, K., Sun, T., Tao, Y., Genc, S., Mallya, S., and Basar, T."
    },
    {
      "index": 60,
      "title": "Learning Implicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Zhou, M., Liu, Z., Sui, P., Li, Y., and Chung, Y. Y.",
      "orig_title": "Learning implicit credit assignment for cooperative multi-agent reinforcement learning",
      "paper_id": "2007.02529v2"
    }
  ]
}