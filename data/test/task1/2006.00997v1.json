{
  "paper_id": "2006.00997v1",
  "title": "Temporal-Differential Learning in Continuous Environments",
  "abstract": "Abstract\nIn this paper, a new reinforcement learning (RL) method known as the method of temporal differential is introduced.\nCompared to the traditional temporal-difference learning method, it plays a crucial role in developing novel RL techniques for continuous environments.\nIn particular, the continuous-time least squares policy evaluation (CT-LSPE) and the continuous-time temporal-differential (CT-TD) learning methods are developed.\nBoth theoretical and empirical evidences are provided to demonstrate the effectiveness of the proposed temporal-differential learning methodology.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Fitted Q-iteration in continuous action-space MDPs",
      "abstract": "",
      "year": "2008",
      "venue": "Advances in Neural Information Processing Systems 20",
      "authors": "A. Antos, C. Szepesvári, and R. Munos"
    },
    {
      "index": 1,
      "title": "Ergodic Control of Diffusion Processes",
      "abstract": "",
      "year": "2012",
      "venue": "Cambridge University Press",
      "authors": "A. Arapostathis, V. S. Borkar, and M. K. Ghosh"
    },
    {
      "index": 2,
      "title": "Stochastic Differential Equations: Theory and Applications",
      "abstract": "",
      "year": "1974",
      "venue": "John Wiley & Sons, Inc.",
      "authors": "L. Arnold"
    },
    {
      "index": 3,
      "title": "Theory of reproducing kernels",
      "abstract": "",
      "year": "1950",
      "venue": "Transactions of the American Mathematical Society",
      "authors": "N. Aronszajn"
    },
    {
      "index": 4,
      "title": "Advantage updating",
      "abstract": "",
      "year": "1993",
      "venue": "Wright Laboratory",
      "authors": "L. C. Baird, III"
    },
    {
      "index": 5,
      "title": "Some recent applications of reinforcement learning",
      "abstract": "",
      "year": "2017",
      "venue": "Eighteenth Yale Workshop on Adaptive and Learning Systems",
      "authors": "A. G. Barto, P. S. Tomas, and R. S. Sutton"
    },
    {
      "index": 6,
      "title": "Adaptive algorithms and stochastic approximations",
      "abstract": "",
      "year": "1990",
      "venue": "Springer Berlin Heidelberg",
      "authors": "A. Benveniste, M. Métivier, and P. Priouret"
    },
    {
      "index": 7,
      "title": "On the functional central limit theorem and the law of the iterated logarithm for markov processes",
      "abstract": "",
      "year": "1982",
      "venue": "Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete",
      "authors": "R. N. Bhattacharya"
    },
    {
      "index": 8,
      "title": "Value iteration and adaptive dynamic programming for data-driven adaptive optimal control design",
      "abstract": "",
      "year": "2016",
      "venue": "Automatica",
      "authors": "T. Bian and Z. P. Jiang"
    },
    {
      "index": 9,
      "title": "Continuous-time robust dynamic programming",
      "abstract": "",
      "year": "2019",
      "venue": "SIAM Journal on Control and Optimization",
      "authors": "T. Bian and Z. P. Jiang"
    },
    {
      "index": 10,
      "title": "Learning through reinforcement and replicator dynamics",
      "abstract": "",
      "year": "1997",
      "venue": "Journal of Economic Theory",
      "authors": "T. Börgers and R. Sarin"
    },
    {
      "index": 11,
      "title": "Fifty years of maximal monotonicity",
      "abstract": "",
      "year": "2010",
      "venue": "Optimization Letters",
      "authors": "J. M. Borwein"
    },
    {
      "index": 12,
      "title": "Deep relaxation: partial differential equations for optimizing deep neural networks",
      "abstract": "",
      "year": "2018",
      "venue": "Research in the Mathematical Sciences",
      "authors": "P. Chaudhari, A. Oberman, S. Osher, S. Soatto, and G. Carlier"
    },
    {
      "index": 13,
      "title": "Neural Ordinary Differential Equations",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems 31",
      "authors": "T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. K. Duvenaud",
      "orig_title": "Neural ordinary differential equations",
      "paper_id": "1806.07366v5"
    },
    {
      "index": 14,
      "title": "Temporal difference learning in continuous time and space",
      "abstract": "",
      "year": "1996",
      "venue": "Advances in Neural Information Processing Systems 8",
      "authors": "K. Doya"
    },
    {
      "index": 15,
      "title": "Reinforcement learning in continuous time and space",
      "abstract": "",
      "year": "2000",
      "venue": "Neural Computation",
      "authors": "K. Doya"
    },
    {
      "index": 16,
      "title": "Benchmarking Deep Reinforcement Learning for Continuous Control",
      "abstract": "",
      "year": "2016",
      "venue": "33nd International Conference on Machine Learning",
      "authors": "Y. Duan, X. Chen, R. Houthooft, J. Schulman, and P. Abbeel",
      "orig_title": "Benchmarking deep reinforcement learning for continuous control",
      "paper_id": "1604.06778v3"
    },
    {
      "index": 17,
      "title": "A proposal on machine learning via dynamical systems",
      "abstract": "",
      "year": "2017",
      "venue": "Communications in Mathematics and Statistics",
      "authors": "W. E"
    },
    {
      "index": 18,
      "title": "Reinforcement learning using a continuous time actor-critic framework with spiking neurons",
      "abstract": "",
      "year": "2013",
      "venue": "PLOS Computational Biology",
      "authors": "N. Frémaux, H. Sprekeler, and W. Gerstner"
    },
    {
      "index": 19,
      "title": "A Liapounov bound for solutions of the Poisson equation",
      "abstract": "",
      "year": "1996",
      "venue": "Ann. Probab.",
      "authors": "P. W. Glynn and S. P. Meyn"
    },
    {
      "index": 20,
      "title": "Back to the future: Generating moment implications for continuous-time markov processes",
      "abstract": "",
      "year": "1995",
      "venue": "Econometrica",
      "authors": "L. P. Hansen and J. A. Scheinkman"
    },
    {
      "index": 21,
      "title": "Advantage updating applied to a differential game",
      "abstract": "",
      "year": "1995",
      "venue": "Advances in Neural Information Processing Systems 7",
      "authors": "M. E. Harmon, L. C. Baird, III, and A. H. Klopf"
    },
    {
      "index": 22,
      "title": "Lectures on stochastic processes",
      "abstract": "",
      "year": "1960",
      "venue": "Tata Institute of Fundamental Research",
      "authors": "K. Ito"
    },
    {
      "index": 23,
      "title": "Computational adaptive optimal control for continuous-time linear systems with completely unknown dynamics",
      "abstract": "",
      "year": "2012",
      "venue": "Automatica",
      "authors": "Y. Jiang and Z. P. Jiang"
    },
    {
      "index": 24,
      "title": "Robust Adaptive Dynamic Programming",
      "abstract": "",
      "year": "2017",
      "venue": "Wiley-IEEE Press",
      "authors": "Y. Jiang and Z. P. Jiang"
    },
    {
      "index": 25,
      "title": "Nonlinear Control",
      "abstract": "",
      "year": "2015",
      "venue": "Pearson Education",
      "authors": "H. K. Khalil"
    },
    {
      "index": 26,
      "title": "Optimal and autonomous control using reinforcement learning: A survey",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "B. Kiumarsi, K. G. Vamvoudakis, H. Modares, and F. L. Lewis"
    },
    {
      "index": 27,
      "title": "Dynamic replication and hedging: A reinforcement learning approach",
      "abstract": "",
      "year": "2019",
      "venue": "The Journal of Financial Data Science",
      "authors": "P. N. Kolm and G. Ritter"
    },
    {
      "index": 28,
      "title": "Actor-Critic Algorithms",
      "abstract": "",
      "year": "2002",
      "venue": "Massachusetts Institute of Technology",
      "authors": "V. R. Konda"
    },
    {
      "index": 29,
      "title": "Actor-critic algorithms",
      "abstract": "",
      "year": "2000",
      "venue": "Advances in Neural Information Processing Systems 12",
      "authors": "V. R. Konda and J. N. Tsitsiklis"
    },
    {
      "index": 30,
      "title": "Spectral theory and limit theorems for geometrically ergodic markov processes",
      "abstract": "",
      "year": "2003",
      "venue": "The Annals of Applied Probability",
      "authors": "I. Kontoyiannis and S. P. Meyn"
    },
    {
      "index": 31,
      "title": "Stochastic Stability and Control",
      "abstract": "",
      "year": "1967",
      "venue": "Academic Press",
      "authors": "H. J. Kushner"
    },
    {
      "index": 32,
      "title": "Optimal discounted stochastic control for diffusion processes",
      "abstract": "",
      "year": "1967",
      "venue": "SIAM Journal on Control",
      "authors": "H. J. Kushner"
    },
    {
      "index": 33,
      "title": "Stochastic Approximation and Recursive Algorithms and Applications",
      "abstract": "",
      "year": "2003",
      "venue": "Springer New York",
      "authors": "H. J. Kushner and G. G. Yin"
    },
    {
      "index": 34,
      "title": "Continuous control with deep reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "4th International Conference on Learning Representations (ICLR 2016)",
      "authors": "T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, and D. Wierstra"
    },
    {
      "index": 35,
      "title": "Analysis of recursive stochastic algorithms",
      "abstract": "",
      "year": "1977",
      "venue": "IEEE Transactions on Automatic Control",
      "authors": "L. Ljung"
    },
    {
      "index": 36,
      "title": "Dissipative operators in a Banach space",
      "abstract": "",
      "year": "1961",
      "venue": "Pacific Journal of Mathematics",
      "authors": "G. Lumer and R. S. Phillips"
    },
    {
      "index": 37,
      "title": "Parallel Robots",
      "abstract": "",
      "year": "2006",
      "venue": "Springer",
      "authors": "J.-P. Merlet"
    },
    {
      "index": 38,
      "title": "Monotone (nonlinear) operators in Hilbert space",
      "abstract": "",
      "year": "1962",
      "venue": "Duke Math. J.",
      "authors": "G. J. Minty"
    },
    {
      "index": 39,
      "title": "Balancing a double inverted pendulum using optimal control and laguerre functions",
      "abstract": "",
      "year": "2016",
      "venue": "Aristotle University of Thessaloniki",
      "authors": "L. Moysis"
    },
    {
      "index": 40,
      "title": "A study of reinforcement learning in the continuous case by the means of viscosity solutions",
      "abstract": "",
      "year": "2000",
      "venue": "Machine Learning",
      "authors": "R. Munos"
    },
    {
      "index": 41,
      "title": "Finite-time bounds for fitted value iteration",
      "abstract": "",
      "year": "2008",
      "venue": "Journal of Machine Learning Research",
      "authors": "R. Munos and C. Szepesvári"
    },
    {
      "index": 42,
      "title": "Least squares policy evaluation algorithms with linear function approximation",
      "abstract": "",
      "year": "2003",
      "venue": "Discrete Event Dynamic Systems",
      "authors": "A. Nedić and D. P. Bertsekas"
    },
    {
      "index": 43,
      "title": "The adjoint Markoff process",
      "abstract": "",
      "year": "1958",
      "venue": "Duke Mathematical Journal",
      "authors": "E. Nelson"
    },
    {
      "index": 44,
      "title": "Semigroups of Linear Operators and Applications to Partial Differential Equations",
      "abstract": "",
      "year": "1983",
      "venue": "Springer-Verlag New York",
      "authors": "A. Pazy"
    },
    {
      "index": 45,
      "title": "A note on the abstract cauchy problem",
      "abstract": "",
      "year": "1954",
      "venue": "National Academy of Sciences of the United States of America",
      "authors": "R. S. Phillips"
    },
    {
      "index": 46,
      "title": "A Tour of Reinforcement Learning: The View from Continuous Control",
      "abstract": "",
      "year": "2019",
      "venue": "Annual Review of Control, Robotics, and Autonomous Systems",
      "authors": "B. Recht",
      "orig_title": "A tour of reinforcement learning: The view from continuous control",
      "paper_id": "1806.09460v2"
    },
    {
      "index": 47,
      "title": "Rationality and intelligence",
      "abstract": "",
      "year": "1997",
      "venue": "Artificial Intelligence",
      "authors": "S. J. Russell"
    },
    {
      "index": 48,
      "title": "Artificial Intelligence: A Modern Approach",
      "abstract": "",
      "year": "2010",
      "venue": "Pearson Education",
      "authors": "S. J. Russell and P. Norvig"
    },
    {
      "index": 49,
      "title": "Deep Neural Networks Motivated by Partial Differential Equations",
      "abstract": "",
      "year": "2020",
      "venue": "Journal of Mathematical Imaging and Vision",
      "authors": "L. Ruthotto and E. Haber",
      "orig_title": "Deep neural networks motivated by partial differential equations",
      "paper_id": "1804.04272v2"
    },
    {
      "index": 50,
      "title": "Nonlinear model reduction by moment matching",
      "abstract": "",
      "year": "2017",
      "venue": "Foundations and Trends® in Systems and Control",
      "authors": "G. Scarciotti and A. Astolfi"
    },
    {
      "index": 51,
      "title": "Mastering the game of go without human knowledge",
      "abstract": "",
      "year": "2017",
      "venue": "Nature",
      "authors": "D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton, Y. Chen, T. Lillicrap, F. Hui, L. Sifre, G. van den Driessche, T. Graepel, and D. Hassabis"
    },
    {
      "index": 52,
      "title": "Mathematical Control Theory: Deterministic Finite Dimensional Systems",
      "abstract": "",
      "year": "1998",
      "venue": "Springer New York",
      "authors": "E. D. Sontag"
    },
    {
      "index": 53,
      "title": "Input to state stability: Basic concepts and results",
      "abstract": "",
      "year": "2008",
      "venue": "Nonlinear and Optimal Control Theory",
      "authors": "E. D. Sontag"
    },
    {
      "index": 54,
      "title": "Learning to predict by the methods of temporal differences",
      "abstract": "",
      "year": "1988",
      "venue": "Machine Learning",
      "authors": "R. S. Sutton"
    },
    {
      "index": 55,
      "title": "Reinforcement Learning: An Introduction",
      "abstract": "",
      "year": "2018",
      "venue": "The MIT Press",
      "authors": "R. S. Sutton and A. G. Barto"
    },
    {
      "index": 56,
      "title": "Asynchronous stochastic approximation and Q-learning",
      "abstract": "",
      "year": "1994",
      "venue": "Machine Learning",
      "authors": "J. N. Tsitsiklis"
    },
    {
      "index": 57,
      "title": "An analysis of temporal-difference learning with function approximation",
      "abstract": "",
      "year": "1997",
      "venue": "IEEE Transactions on Automatic Control",
      "authors": "J. N. Tsitsiklis and B. Van Roy"
    },
    {
      "index": 58,
      "title": "Reinforcement learning in continuous state and action spaces",
      "abstract": "",
      "year": "2012",
      "venue": "Reinforcement Learning: State-of-the-Art",
      "authors": "H. van Hasselt"
    },
    {
      "index": 59,
      "title": "Reinforcement learning in continuous action spaces",
      "abstract": "",
      "year": "2007",
      "venue": "IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning",
      "authors": "H. van Hasselt and M. A. Wiering"
    },
    {
      "index": 60,
      "title": "Optimal Adaptive Control and Differential Games by Reinforcement Learning Principles",
      "abstract": "",
      "year": "2013",
      "venue": "Institution of Engineering and Technology",
      "authors": "D. Vrabie, K. G. Vamvoudakis, and F. L. Lewis"
    },
    {
      "index": 61,
      "title": "Prefrontal cortex as a meta-reinforcement learning system",
      "abstract": "",
      "year": "2018",
      "venue": "Nature Neuroscience",
      "authors": "J. X. Wang, Z. Kurth-Nelson, D. Kumaran, D. Tirumala, H. Soyer, J. Z. Leibo, D. Hassabis, and M. Botvinick"
    },
    {
      "index": 62,
      "title": "Convergence results for some temporal difference methods based on least squares",
      "abstract": "",
      "year": "2009",
      "venue": "IEEE Transactions on Automatic Control",
      "authors": "H. Yu and D. P. Bertsekas"
    }
  ]
}