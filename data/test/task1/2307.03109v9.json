{
  "paper_id": "2307.03109v9",
  "title": "A Survey on Evaluation of Large Language Models",
  "abstract": "Abstract.\nLarge language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives.\nThis paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate.\nFirstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs.\nThen, we summarize the success and failure cases of LLMs in different tasks.\nFinally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Benchmarking Arabic AI with Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.14982",
      "authors": "Ahmed Abdelali, Hamdy Mubarak, Shammur Absar Chowdhury, Maram Hasanain, Basel Mousi, Sabri Boughorbel, Yassine El Kheir, Daniel Izham, Fahim Dalvi, Majd Hawasly, et al."
    },
    {
      "index": 1,
      "title": "MEGA: Multilingual Evaluation of Generative AI",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.12528",
      "authors": "Kabir Ahuja, Rishav Hada, Millicent Ochieng, Prachi Jain, Harshita Diddee, Samuel Maina, Tanuja Ganu, Sameer Segal, Maxamed Axmed, Kalika Bali, et al.",
      "orig_title": "Mega: Multilingual evaluation of generative ai",
      "paper_id": "2303.12528v4"
    },
    {
      "index": 2,
      "title": "Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.15074",
      "authors": "Daman Arora, Himanshu Gaurav Singh, et al.",
      "orig_title": "Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models",
      "paper_id": "2305.15074v3"
    },
    {
      "index": 3,
      "title": "A General Language Assistant as a Laboratory for Alignment",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2112.00861",
      "authors": "Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et al.",
      "orig_title": "A general language assistant as a laboratory for alignment",
      "paper_id": "2112.00861v3"
    },
    {
      "index": 4,
      "title": "Benchmarking Foundation Models with Language-Model-as-an-Examiner",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.04181",
      "authors": "Yushi Bai, Jiahao Ying, Yixin Cao, Xin Lv, Yuze He, Xiaozhi Wang, Jifan Yu, Kaisheng Zeng, Yijia Xiao, Haozhe Lyu, et al."
    },
    {
      "index": 5,
      "title": "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2302.04023",
      "authors": "Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al.",
      "orig_title": "A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity",
      "paper_id": "2302.04023v4"
    },
    {
      "index": 6,
      "title": "Comparing automatic and human evaluation of NLG systems",
      "abstract": "",
      "year": "2006",
      "venue": "11th conference of the european chapter of the association for computational linguistics",
      "authors": "Anja Belz and Ehud Reiter"
    },
    {
      "index": 7,
      "title": "Cross-Validation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Daniel Berrar"
    },
    {
      "index": 8,
      "title": "ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.16421",
      "authors": "Ning Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie Lu, and Ben He",
      "orig_title": "Chatgpt is a knowledgeable but inexperienced solver: An investigation of commonsense problem in large language models",
      "paper_id": "2303.16421v3"
    },
    {
      "index": 9,
      "title": "Personality testing of GPT-3: Limited temporal reliability, but highlighted social desirability of GPT-3’s personality instruments results",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.04308",
      "authors": "Bojana Bodroza, Bojana M Dinic, and Ljubisa Bojic"
    },
    {
      "index": 10,
      "title": "Personality testing of GPT-3: Limited temporal reliability, but highlighted social desirability of GPT-3’s personality instruments results",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.04308\n(",
      "authors": "Bojana Bodroza, Bojana M\nDinic, and Ljubisa Bojic.\n2023."
    },
    {
      "index": 11,
      "title": "On the opportunities and risks of foundation models",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2108.07258\n(",
      "authors": "Rishi Bommasani, Drew A\nHudson, Ehsan Adeli, Russ Altman,\nSimran Arora, Sydney von Arx,\nMichael S Bernstein, Jeannette Bohg,\nAntoine Bosselut, Emma Brunskill,\net al. 2021."
    },
    {
      "index": 12,
      "title": "What is intelligence?",
      "abstract": "",
      "year": "1999",
      "venue": "International Review of Psychiatry\n11, 1 (1999),\n19–25",
      "authors": "Nathan Brody.\n1999."
    },
    {
      "index": 13,
      "title": "Class-based n-gram models of natural language",
      "abstract": "",
      "year": "1992",
      "venue": "Computational linguistics\n18, 4 (1992),\n467–480",
      "authors": "Peter F Brown, Vincent J\nDella Pietra, Peter V Desouza, Jennifer C\nLai, and Robert L Mercer.\n1992."
    },
    {
      "index": 14,
      "title": "Language Models are Few-Shot Learners",
      "abstract": "",
      "year": "1901",
      "venue": "Advances in neural information processing\nsystems 33 (2020)",
      "authors": "Tom Brown, Benjamin Mann,\nNick Ryder, Melanie Subbiah,\nJared D Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam,\nGirish Sastry, Amanda Askell,\net al. 2020.",
      "orig_title": "Language models are few-shot learners",
      "paper_id": "2005.14165v4"
    },
    {
      "index": 15,
      "title": "Sparks of artificial general intelligence: Early experiments with gpt-4",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.12712\n(",
      "authors": "Sébastien Bubeck,\nVarun Chandrasekaran, Ronen Eldan,\nJohannes Gehrke, Eric Horvitz,\nEce Kamar, Peter Lee,\nYin Tat Lee, Yuanzhi Li,\nScott Lundberg, et al.\n2023."
    },
    {
      "index": 16,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Yong Cao, Li Zhou,\nSeolhwa Lee, Laura Cabello,\nMin Chen, and Daniel Hershcovich.\n2023.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 17,
      "title": "Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios",
      "abstract": "",
      "year": "2023",
      "venue": "Journal of Medical Systems\n47, 1 (2023),\n33",
      "authors": "Marco Cascella, Jonathan\nMontomoli, Valentina Bellini, and Elena\nBignami. 2023."
    },
    {
      "index": 18,
      "title": "Do Large Language Models Understand Chemistry? A Conversation with ChatGPT",
      "abstract": "",
      "year": "2023",
      "venue": "Journal of Chemical Information and\nModeling 63, 6 (2023)",
      "authors": "Cayque Monteiro Castro Nascimento and\nAndré Silva Pimentel. 2023."
    },
    {
      "index": 19,
      "title": "Evaluating Large Language Models Trained on Code",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2107.03374\n(",
      "authors": "Mark Chen, Jerry Tworek,\nHeewoo Jun, Qiming Yuan,\nHenrique Ponde de Oliveira Pinto, Jared\nKaplan, Harri Edwards, Yuri Burda,\nNicholas Joseph, Greg Brockman,\net al. 2021.",
      "orig_title": "Evaluating large language models trained on code",
      "paper_id": "2107.03374v2"
    },
    {
      "index": 20,
      "title": "Exploring the use of large language models for reference-free text quality evaluation: A preliminary empirical study",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.00723\n(",
      "authors": "Yi Chen, Rui Wang,\nHaiyun Jiang, Shuming Shi, and\nRuifeng Xu. 2023."
    },
    {
      "index": 21,
      "title": "The promise and peril of using a large language model to obtain clinical information: ChatGPT performs strongly as a fertility counseling tool with limitations",
      "abstract": "",
      "year": "2023",
      "venue": "Fertility and Sterility\n(",
      "authors": "Joseph Chervenak, Harry\nLieman, Miranda Blanco-Breindel, and\nSangita Jindal. 2023."
    },
    {
      "index": 22,
      "title": "INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.04757\n(",
      "authors": "Yew Ken Chia, Pengfei\nHong, Lidong Bing, and Soujanya\nPoria. 2023."
    },
    {
      "index": 23,
      "title": "Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.14938\n(",
      "authors": "Minje Choi, Jiaxin Pei,\nSagar Kumar, Chang Shu, and\nDavid Jurgens. 2023."
    },
    {
      "index": 24,
      "title": "PaLM: Scaling Language Modeling with Pathways",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2204.02311\n(",
      "authors": "Aakanksha Chowdhery,\nSharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra,\nAdam Roberts, Paul Barham,\nHyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al.\n2022.",
      "orig_title": "Palm: Scaling language modeling with pathways",
      "paper_id": "2204.02311v5"
    },
    {
      "index": 25,
      "title": "Deep Reinforcement Learning from Human Preferences",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing\nsystems 30 (",
      "authors": "Paul F Christiano, Jan\nLeike, Tom Brown, Miljan Martic,\nShane Legg, and Dario Amodei.\n2017.",
      "orig_title": "Deep reinforcement learning from human preferences",
      "paper_id": "1706.03741v4"
    },
    {
      "index": 26,
      "title": "Frederick Naylor",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Benjamin Clavié,\nAlexandru Ciceu, Frederick Naylor,\nGuillaume Soulié, and Thomas\nBrightwell. 2023."
    },
    {
      "index": 27,
      "title": "Evaluating Language Models for Mathematics through Interactions",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.01694\n(",
      "authors": "Katherine M Collins,\nAlbert Q Jiang, Simon Frieder,\nLionel Wong, Miri Zilka,\nUmang Bhatt, Thomas Lukasiewicz,\nYuhuai Wu, Joshua B Tenenbaum,\nWilliam Hart, et al.\n2023."
    },
    {
      "index": 28,
      "title": "Support-vector networks",
      "abstract": "",
      "year": "1995",
      "venue": "Machine learning 20\n(",
      "authors": "Corinna Cortes and\nVladimir Vapnik. 1995."
    },
    {
      "index": 29,
      "title": "Uncovering ChatGPT’s Capabilities in Recommender Systems",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.02182\n(",
      "authors": "Sunhao Dai, Ninglu Shao,\nHaiyuan Zhao, Weijie Yu,\nZihua Si, Chen Xu,\nZhongxiang Sun, Xiao Zhang, and\nJun Xu. 2023b.",
      "orig_title": "Uncovering ChatGPT’s Capabilities in Recommender Systems",
      "paper_id": "2305.02182v3"
    },
    {
      "index": 30,
      "title": "Can large language models provide feedback to students? a case study on chatgpt",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Wei Dai, Jionghao Lin,\nFlora Jin, Tongguang Li,\nYi-Shan Tsai, Dragan Gasevic, and\nGuanliang Chen. 2023a."
    },
    {
      "index": 31,
      "title": "Investigating the Effectiveness of ChatGPT in Mathematical Reasoning and Problem Solving: Evidence from the Vietnamese National High School Graduation Examination",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.06331\n(",
      "authors": "Xuan-Quy Dao and\nNgoc-Bich Le. 2023."
    },
    {
      "index": 32,
      "title": "Can ChatGPT pass high school exams on English language comprehension",
      "abstract": "",
      "year": "2023",
      "venue": "Researchgate. Preprint\n(",
      "authors": "Joost CF de Winter.\n2023."
    },
    {
      "index": 33,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "Jia Deng, Wei Dong,\nRichard Socher, Li-Jia Li,\nKai Li, and Li Fei-Fei.\n2009.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 34,
      "title": "How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.01248\n(",
      "authors": "Aniket Deroy, Kripabandhu\nGhosh, and Saptarshi Ghosh.\n2023.",
      "orig_title": "How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?",
      "paper_id": "2306.01248v2"
    },
    {
      "index": 35,
      "title": "Toxicity in ChatGPT: Analyzing Persona-assigned Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.05335\n(",
      "authors": "Ameet Deshpande, Vishvak\nMurahari, Tanmay Rajpurohit, Ashwin\nKalyan, and Karthik Narasimhan.\n2023.",
      "orig_title": "Toxicity in chatgpt: Analyzing persona-assigned language models",
      "paper_id": "2304.05335v1"
    },
    {
      "index": 36,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1810.04805\n(",
      "authors": "Jacob Devlin, Ming-Wei\nChang, Kenton Lee, and Kristina\nToutanova. 2018.",
      "orig_title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 37,
      "title": "Satyapriya Krishna",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Jwala Dhamala, Tony Sun,\nVarun Kumar, Satyapriya Krishna,\nYada Pruksachatkun, Kai-Wei Chang, and\nRahul Gupta. 2021."
    },
    {
      "index": 38,
      "title": "AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.14387\n(",
      "authors": "Yann Dubois, Xuechen Li,\nRohan Taori, Tianyi Zhang,\nIshaan Gulrajani, Jimmy Ba,\nCarlos Guestrin, Percy Liang, and\nTatsunori B Hashimoto. 2023.",
      "orig_title": "Alpacafarm: A simulation framework for methods that learn from human feedback",
      "paper_id": "2305.14387v4"
    },
    {
      "index": 39,
      "title": "Analysis of large-language model versus human performance for genetics questions",
      "abstract": "",
      "year": "2023",
      "venue": "European Journal of Human Genetics\n(",
      "authors": "Dat Duong and Benjamin D\nSolomon. 2023."
    },
    {
      "index": 40,
      "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv:",
      "authors": "Wenqi Fan, Zihuai Zhao,\nJiatong Li, Yunqing Liu,\nXiaowei Mei, Yiqi Wang,\nJiliang Tang, and Qing Li.\n2023.",
      "orig_title": "Recommender Systems in the Era of Large Language Models (LLMs)",
      "paper_id": "2307.02046v6"
    },
    {
      "index": 41,
      "title": "DDXPlus: A New Dataset For Automatic Medical Diagnosis",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing\nSystems 35 (2022)",
      "authors": "Arsene Fansi Tchango,\nRishab Goel, Zhi Wen,\nJulien Martel, and Joumana Ghosn.\n2022.",
      "orig_title": "Ddxplus: A new dataset for automatic medical diagnosis",
      "paper_id": "2205.09148v3"
    },
    {
      "index": 42,
      "title": "Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.03738\n(",
      "authors": "Emilio Ferrara.\n2023.",
      "orig_title": "Should chatgpt be biased? challenges and risks of bias in large language models",
      "paper_id": "2304.03738v3"
    },
    {
      "index": 43,
      "title": "GPT-3: Its nature, scope, limits, and consequences",
      "abstract": "",
      "year": "2020",
      "venue": "Minds and Machines 30\n(",
      "authors": "Luciano Floridi and\nMassimo Chiriatti. 2020."
    },
    {
      "index": 44,
      "title": "Baby steps in evaluating the capacities of large language models",
      "abstract": "",
      "year": "2023",
      "venue": "Nature Reviews Psychology\n(",
      "authors": "Michael C Frank.\n2023."
    },
    {
      "index": 45,
      "title": "Mathematical Capabilities of ChatGPT",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2301.13867\n(",
      "authors": "Simon Frieder, Luca\nPinchetti, Ryan-Rhys Griffiths, Tommaso\nSalvatori, Thomas Lukasiewicz,\nPhilipp Christian Petersen, Alexis\nChevalier, and Julius Berner.\n2023.",
      "orig_title": "Mathematical capabilities of chatgpt",
      "paper_id": "2301.13867v2"
    },
    {
      "index": 46,
      "title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.13394\n(",
      "authors": "Chaoyou Fu, Peixian Chen,\nYunhang Shen, Yulei Qin,\nMengdan Zhang, Xu Lin,\nZhenyu Qiu, Wei Lin,\nJinrui Yang, Xiawu Zheng,\net al. 2023a.",
      "orig_title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models",
      "paper_id": "2306.13394v4"
    },
    {
      "index": 47,
      "title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models’ Reasoning Performance",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.17306\n(",
      "authors": "Yao Fu, Litu Ou,\nMingyu Chen, Yuhao Wan,\nHao Peng, and Tushar Khot.\n2023b.",
      "orig_title": "Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models’ Reasoning Performance",
      "paper_id": "2305.17306v1"
    },
    {
      "index": 48,
      "title": "Estimation of prediction error by using K-fold cross-validation",
      "abstract": "",
      "year": "2011",
      "venue": "Statistics and Computing\n21 (",
      "authors": "Tadayoshi Fushiki.\n2011."
    },
    {
      "index": 49,
      "title": "Perceptron-based learning algorithms",
      "abstract": "",
      "year": "1990",
      "venue": "IEEE Transactions on neural networks\n1, 2 (1990),\n179–191",
      "authors": "Stephen I Gallant et al.\n1990."
    },
    {
      "index": 50,
      "title": "Adaptive Testing of Computer Vision Models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2212.02774\n(",
      "authors": "Irena Gao, Gabriel\nIlharco, Scott Lundberg, and\nMarco Tulio Ribeiro. 2022.",
      "orig_title": "Adaptive Testing of Computer Vision Models",
      "paper_id": "2212.02774v2"
    },
    {
      "index": 51,
      "title": "Introduction to the special issue on statistical language modeling",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": "Jianfeng Gao and\nChin-Yew Lin. 2004."
    },
    {
      "index": 52,
      "title": "Making pre-trained language models better few-shot learners",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2012.15723\n(",
      "authors": "Tianyu Gao, Adam Fisch,\nand Danqi Chen. 2020."
    },
    {
      "index": 53,
      "title": "Suchin Gururangan",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Samuel Gehman, Suchin\nGururangan, Maarten Sap, Yejin Choi,\nand Noah A Smith. 2020."
    },
    {
      "index": 54,
      "title": "Selective Classification for Deep Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing\nsystems 30 (",
      "authors": "Yonatan Geifman and Ran\nEl-Yaniv. 2017.",
      "orig_title": "Selective classification for deep neural networks",
      "paper_id": "1705.08500v2"
    },
    {
      "index": 55,
      "title": "Trueteacher: Learning factual consistency evaluation with large language models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.11171\n(",
      "authors": "Zorik Gekhman, Jonathan\nHerzig, Roee Aharoni, Chen Elkind, and\nIdan Szpektor. 2023."
    },
    {
      "index": 56,
      "title": "Large Language Models Are Not Abstract Reasoners",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.19555\n(",
      "authors": "Gaël Gendron, Qiming\nBao, Michael Witbrock, and Gillian\nDobbie. 2023."
    },
    {
      "index": 57,
      "title": "How does CHATGPT perform on the United States Medical Licensing Examination? the implications of large language models for medical education and knowledge assessment",
      "abstract": "",
      "year": "2023",
      "venue": "JMIR Medical Education 9,\n1 (",
      "authors": "Aidan Gilson, Conrad W\nSafranek, Thomas Huang, Vimig Socrates,\nLing Chi, Richard Andrew Taylor,\nDavid Chartash, et al.\n2023."
    },
    {
      "index": 58,
      "title": "Moral foundations theory: The pragmatic validity of moral pluralism",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": "Jesse Graham, Jonathan\nHaidt, Sena Koleva, Matt Motyl,\nRavi Iyer, Sean P Wojcik, and\nPeter H Ditto. 2013."
    },
    {
      "index": 59,
      "title": "Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.05783\n(",
      "authors": "Zhouhong Gu, Xiaoxuan\nZhu, Haoning Ye, Lin Zhang,\nJianchen Wang, Sihang Jiang,\nZhuozhi Xiong, Zihan Li,\nQianyu He, Rui Xu, et al.\n2023."
    },
    {
      "index": 60,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Chuan Guo, Geoff Pleiss,\nYu Sun, and Kilian Q Weinberger.\n2017.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 61,
      "title": "What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.18365\n(",
      "authors": "Taicheng Guo, Kehan Guo,\nZhengwen Liang, Zhichun Guo,\nNitesh V Chawla, Olaf Wiest,\nXiangliang Zhang, et al.\n2023."
    },
    {
      "index": 62,
      "title": "Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models – and Disappeared in GPT-4",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv:",
      "authors": "Thilo Hagendorff and\nSarah Fabi. 2023."
    },
    {
      "index": 63,
      "title": "Evaluation of AI Chatbots for Patient-Specific EHR Questions",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.02549\n(",
      "authors": "Alaleh Hamidi and Kirk\nRoberts. 2023.",
      "orig_title": "Evaluation of AI Chatbots for Patient-Specific EHR Questions",
      "paper_id": "2306.02549v1"
    },
    {
      "index": 64,
      "title": "Equality of Opportunity in Supervised Learning",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in neural information processing\nsystems 29 (",
      "authors": "Moritz Hardt, Eric Price,\nand Nati Srebro. 2016.",
      "orig_title": "Equality of opportunity in supervised learning",
      "paper_id": "1610.02413v1"
    },
    {
      "index": 65,
      "title": "The political ideology of conversational AI: Converging evidence on ChatGPT’s pro-environmental, left-libertarian orientation",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2301.01768\n(",
      "authors": "Jochen Hartmann, Jasper\nSchwenzow, and Maximilian Witte.\n2023."
    },
    {
      "index": 66,
      "title": "Can Large Language Models Understand Real-World Complex Instructions?",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2309.09150\n(",
      "authors": "Qianyu He, Jie Zeng,\nWenhao Huang, Lina Chen,\nJin Xiao, Qianxi He,\nXunzhe Zhou, Lida Chen,\nXintao Wang, Yuncheng Huang,\net al. 2023."
    },
    {
      "index": 67,
      "title": "Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.05715\n(",
      "authors": "Arto Hellas, Juho\nLeinonen, Sami Sarsa, Charles Koutcheme,\nLilja Kujanpää, and Juha\nSorva. 2023.",
      "orig_title": "Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests",
      "paper_id": "2306.05715v1"
    },
    {
      "index": 68,
      "title": "Measuring coding challenge competence with apps",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2105.09938\n(",
      "authors": "Dan Hendrycks, Steven\nBasart, Saurav Kadavath, Mantas Mazeika,\nAkul Arora, Ethan Guo,\nCollin Burns, Samir Puranik,\nHorace He, Dawn Song, et al.\n2021a."
    },
    {
      "index": 69,
      "title": "Aligning AI With Shared Human Values",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2008.02275\n(",
      "authors": "Dan Hendrycks, Collin\nBurns, Steven Basart, Andrew Critch,\nJerry Li, Dawn Song, and\nJacob Steinhardt. 2020a.",
      "orig_title": "Aligning ai with shared human values",
      "paper_id": "2008.02275v6"
    },
    {
      "index": 70,
      "title": "Measuring Massive Multitask Language Understanding",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2009.03300\n(",
      "authors": "Dan Hendrycks, Collin\nBurns, Steven Basart, Andy Zou,\nMantas Mazeika, Dawn Song, and\nJacob Steinhardt. 2020b.",
      "orig_title": "Measuring massive multitask language understanding",
      "paper_id": "2009.03300v3"
    },
    {
      "index": 71,
      "title": "CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2103.06268\n(",
      "authors": "Dan Hendrycks, Collin\nBurns, Anya Chen, and Spencer Ball.\n2021b.",
      "orig_title": "Cuad: An expert-annotated nlp dataset for legal contract review",
      "paper_id": "2103.06268v2"
    },
    {
      "index": 72,
      "title": "Measuring Mathematical Problem Solving With the MATH Dataset",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2103.03874\n(",
      "authors": "Dan Hendrycks, Collin\nBurns, Saurav Kadavath, Akul Arora,\nSteven Basart, Eric Tang,\nDawn Song, and Jacob Steinhardt.\n2021c.",
      "orig_title": "Measuring mathematical problem solving with the math dataset",
      "paper_id": "2103.03874v2"
    },
    {
      "index": 73,
      "title": "Evaluating large language models on a highly-specialized topic, radiation oncology physics",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.01938\n(",
      "authors": "Jason Holmes, Zhengliang\nLiu, Lian Zhang, Yuzhen Ding,\nTerence T Sio, Lisa A McGee,\nJonathan B Ashman, Xiang Li,\nTianming Liu, Jiajian Shen,\net al. 2023."
    },
    {
      "index": 74,
      "title": "TRUE: Re-evaluating Factual Consistency Evaluation",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2204.04991\n(",
      "authors": "Or Honovich, Roee\nAharoni, Jonathan Herzig, Hagai\nTaitelbaum, Doron Kukliansy, Vered\nCohen, Thomas Scialom, Idan Szpektor,\nAvinatan Hassidim, and Yossi Matias.\n2022.",
      "orig_title": "TRUE: Re-evaluating factual consistency evaluation",
      "paper_id": "2204.04991v3"
    },
    {
      "index": 75,
      "title": "Choice-75: A Dataset on Decision Branching in Script Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2309.11737\n(",
      "authors": "Zhaoyi Joey Hou, Li\nZhang, and Chris Callison-Burch.\n2023.",
      "orig_title": "Choice-75: A Dataset on Decision Branching in Script Learning",
      "paper_id": "2309.11737v2"
    },
    {
      "index": 76,
      "title": "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2308.03656\n(",
      "authors": "Jen-tse Huang, Man Ho\nLam, Eric John Li, Shujie Ren,\nWenxuan Wang, Wenxiang Jiao,\nZhaopeng Tu, and Michael R. Lyu.\n2023c.",
      "orig_title": "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench",
      "paper_id": "2308.03656v6"
    },
    {
      "index": 77,
      "title": "Language Is Not All You Need: Aligning Perception with Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2302.14045\n(",
      "authors": "Shaohan Huang, Li Dong,\nWenhui Wang, Yaru Hao,\nSaksham Singhal, Shuming Ma,\nTengchao Lv, Lei Cui,\nOwais Khan Mohammed, Qiang Liu,\net al. 2023b.",
      "orig_title": "Language is not all you need: Aligning perception with language models",
      "paper_id": "2302.14045v2"
    },
    {
      "index": 78,
      "title": "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.08322\n(",
      "authors": "Yuzhen Huang, Yuzhuo Bai,\nZhihao Zhu, Junlei Zhang,\nJinghan Zhang, Tangjun Su,\nJunteng Liu, Chuancheng Lv,\nYikai Zhang, Jiayi Lei, et al.\n2023a.",
      "orig_title": "C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models",
      "paper_id": "2305.08322v3"
    },
    {
      "index": 79,
      "title": "TrustGPT: A Benchmark for Trustworthy and Responsible Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Yue Huang, Qihui Zhang,\nPhilip S. Y, and Lichao Sun.\n2023d.",
      "orig_title": "TrustGPT: A Benchmark for Trustworthy and Responsible Large Language Models",
      "paper_id": "2306.11507v1"
    },
    {
      "index": 80,
      "title": "Open-source Large Language Models Leaderboard",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "HuggingFace.\n2023."
    },
    {
      "index": 81,
      "title": "Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.04504\n(",
      "authors": "Israt Jahan,\nMd Tahmid Rahman Laskar, Chun Peng, and\nJimmy Huang. 2023.",
      "orig_title": "Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers",
      "paper_id": "2306.04504v3"
    },
    {
      "index": 82,
      "title": "Bring Your Own Data! Self-Supervised Evaluation of Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.13651\n(",
      "authors": "Neel Jain, Khalid\nSaifullah, Yuxin Wen, John Kirchenbauer,\nManli Shu, Aniruddha Saha,\nMicah Goldblum, Jonas Geiping, and\nTom Goldstein. 2023.",
      "orig_title": "Bring Your Own Data! Self-Supervised Evaluation for Large Language Models",
      "paper_id": "2306.13651v2"
    },
    {
      "index": 83,
      "title": "Online question and answer sessions: How students support their own and other students’ processes of inquiry in a text-based learning environment",
      "abstract": "",
      "year": "2021",
      "venue": "The Internet and Higher Education\n51 (",
      "authors": "Malin Jansson, Stefan\nHrastinski, Stefan Stenbom, and Fredrik\nEnoksson. 2021."
    },
    {
      "index": 84,
      "title": "ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.04563\n(",
      "authors": "Sophie Jentzsch and\nKristian Kersting. 2023.",
      "orig_title": "ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models",
      "paper_id": "2306.04563v1"
    },
    {
      "index": 85,
      "title": "BeaverTails: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2307.04657\n(",
      "authors": "Jiaming Ji, Mickel Liu,\nJuntao Dai, Xuehai Pan,\nChi Zhang, Ce Bian,\nRuiyang Sun, Yizhou Wang, and\nYaodong Yang. 2023.",
      "orig_title": "Beavertails: Towards improved safety alignment of llm via a human-preference dataset",
      "paper_id": "2307.04657v3"
    },
    {
      "index": 86,
      "title": "StructGPT: A General Framework for Large Language Model to Reason over Structured Data",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.09645\n(",
      "authors": "Jinhao Jiang, Kun Zhou,\nZican Dong, Keming Ye,\nWayne Xin Zhao, and Ji-Rong Wen.\n2023.",
      "orig_title": "Structgpt: A general framework for large language model to reason over structured data",
      "paper_id": "2305.09645v2"
    },
    {
      "index": 87,
      "title": "Assessing the accuracy and reliability of AI-generated medical responses: an evaluation of the Chat-GPT model",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Douglas Johnson, Rachel\nGoodman, J Patrinely, Cosby Stone,\nEli Zimmerman, Rebecca Donald,\nSam Chang, Sean Berkowitz,\nAvni Finn, Eiman Jahangir,\net al. 2023."
    },
    {
      "index": 88,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Mandar Joshi, Eunsol\nChoi, Daniel S. Weld, and Luke\nZettlemoyer. 2017.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 89,
      "title": "Language Models (Mostly) Know What They Know",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv abs/2207.05221\n(",
      "authors": "",
      "orig_title": "Language Models (Mostly) Know What They Know",
      "paper_id": "2207.05221v4"
    },
    {
      "index": 90,
      "title": "MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2205.00445\n(",
      "authors": "Ehud Karpas, Omri Abend,\nYonatan Belinkov, Barak Lenz,\nOpher Lieber, Nir Ratner,\nYoav Shoham, Hofit Bata,\nYoav Levine, Kevin Leyton-Brown,\net al. 2022."
    },
    {
      "index": 91,
      "title": "ChatGPT for good? On opportunities and challenges of large language models for education",
      "abstract": "",
      "year": "2023",
      "venue": "Learning and Individual Differences\n103 (",
      "authors": "Enkelejda Kasneci, Kathrin\nSeßler, Stefan Küchemann, Maria\nBannert, Daryna Dementieva, Frank\nFischer, Urs Gasser, Georg Groh,\nStephan Günnemann, Eyke\nHüllermeier, et al. 2023."
    },
    {
      "index": 92,
      "title": "What is intelligence?",
      "abstract": "",
      "year": "1994",
      "venue": "",
      "authors": "Jean Khalfa.\n1994."
    },
    {
      "index": 93,
      "title": "covLLM: Large Language Models for COVID-19 Biomedical Literature",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.04926\n(",
      "authors": "Yousuf A Khan, Clarisse\nHokia, Jennifer Xu, and Ben Ehlert.\n2023."
    },
    {
      "index": 94,
      "title": "Dynabench: Rethinking Benchmarking in NLP",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2104.14337\n(",
      "authors": "Douwe Kiela, Max Bartolo,\nYixin Nie, Divyansh Kaushik,\nAtticus Geiger, Zhengxuan Wu,\nBertie Vidgen, Grusha Prasad,\nAmanpreet Singh, Pratik Ringshia,\net al. 2021.",
      "orig_title": "Dynabench: Rethinking benchmarking in NLP",
      "paper_id": "2104.14337v1"
    },
    {
      "index": 95,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "1995",
      "venue": "",
      "authors": "Ron Kohavi et al.\n1995.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 96,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": "Stefan Kombrink, Tomas\nMikolov, Martin Karafiát, and\nLukás Burget. 2011.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 97,
      "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models",
      "abstract": "",
      "year": "2023",
      "venue": "PLoS digital health 2,\n2 (",
      "authors": "Tiffany H Kung, Morgan\nCheatham, Arielle Medenilla, Czarina\nSillos, Lorie De Leon, Camille\nElepaño, Maria Madriaga, Rimel\nAggabao, Giezel Diaz-Candido, James\nManingo, et al. 2023."
    },
    {
      "index": 98,
      "title": "Natural Questions: a Benchmark for Question Answering Research",
      "abstract": "",
      "year": "2019",
      "venue": "Transactions of the Association of\nComputational Linguistics (",
      "authors": "Tom Kwiatkowski,\nJennimaria Palomaki, Olivia Redfield,\nMichael Collins, Ankur Parikh,\nChris Alberti, Danielle Epstein,\nIllia Polosukhin, Matthew Kelcey,\nJacob Devlin, Kenton Lee,\nKristina N. Toutanova, Llion Jones,\nMing-Wei Chang, Andrew Dai,\nJakob Uszkoreit, Quoc Le, and\nSlav Petrov. 2019."
    },
    {
      "index": 99,
      "title": "Evaluating the use of large language model in identifying top research questions in gastroenterology",
      "abstract": "",
      "year": "2023",
      "venue": "Scientific reports 13,\n1 (",
      "authors": "Adi Lahat, Eyal Shachar,\nBenjamin Avidan, Zina Shatz,\nBenjamin S Glicksberg, and Eyal Klang.\n2023."
    },
    {
      "index": 100,
      "title": "ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.05613\n(",
      "authors": "Viet Dac Lai, Nghia Trung\nNgo, Amir Pouran Ben Veyseh, Hieu Man,\nFranck Dernoncourt, Trung Bui, and\nThien Huu Nguyen. 2023.",
      "orig_title": "ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning",
      "paper_id": "2304.05613v1"
    },
    {
      "index": 101,
      "title": "ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.02155\n(",
      "authors": "Pier Luca Lanzi and\nDaniele Loiacono. 2023.",
      "orig_title": "Chatgpt and other large language models as evolutionary engines for online interactive collaborative game design",
      "paper_id": "2303.02155v2"
    },
    {
      "index": 102,
      "title": "A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.18486\n(",
      "authors": "Md Tahmid Rahman Laskar,\nM Saiful Bari, Mizanur Rahman,\nMd Amran Hossen Bhuiyan, Shafiq Joty,\nand Jimmy Xiangji Huang.\n2023.",
      "orig_title": "A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets",
      "paper_id": "2305.18486v4"
    },
    {
      "index": 103,
      "title": "An Evaluation of Log Parsing with ChatGPT",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.01590\n(",
      "authors": "Van-Hoang Le and Hongyu\nZhang. 2023."
    },
    {
      "index": 104,
      "title": "Deep Learning",
      "abstract": "",
      "year": "2015",
      "venue": "nature 521",
      "authors": "Yann LeCun, Yoshua\nBengio, and Geoffrey Hinton.\n2015.",
      "orig_title": "Deep learning",
      "paper_id": "1807.07987v2"
    },
    {
      "index": 105,
      "title": "Can Large Language Models Infer and Disagree Like Humans?",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.13788\n(",
      "authors": "Noah Lee, Na Min An,\nand James Thorne. 2023."
    },
    {
      "index": 106,
      "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1910.13461\n(",
      "authors": "Mike Lewis, Yinhan Liu,\nNaman Goyal, Marjan Ghazvininejad,\nAbdelrahman Mohamed, Omer Levy,\nVes Stoyanov, and Luke Zettlemoyer.\n2019.",
      "orig_title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
      "paper_id": "1910.13461v1"
    },
    {
      "index": 107,
      "title": "SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2307.16125\n(",
      "authors": "Bohao Li, Rui Wang,\nGuangzhi Wang, Yuying Ge,\nYixiao Ge, and Ying Shan.\n2023e.",
      "orig_title": "Seed-bench: Benchmarking multimodal llms with generative comprehension",
      "paper_id": "2307.16125v2"
    },
    {
      "index": 108,
      "title": "CMMLU: Measuring massive multitask language understanding in Chinese",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.09212\n(",
      "authors": "Haonan Li, Yixuan Zhang,\nFajri Koto, Yifei Yang,\nHai Zhao, Yeyun Gong,\nNan Duan, and Timothy Baldwin.\n2023g.",
      "orig_title": "CMMLU: Measuring massive multitask language understanding in Chinese",
      "paper_id": "2306.09212v2"
    },
    {
      "index": 109,
      "title": "API-Bank: A Benchmark for Tool-Augmented LLMs",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Minghao Li, Feifan Song,\nBowen Yu, Haiyang Yu,\nZhoujun Li, Fei Huang, and\nYongbin Li. 2023d."
    },
    {
      "index": 110,
      "title": "Exploring the Upper Limits of Text-Based Collaborative Filtering Using Large Language Models: Discoveries and Insights",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.11700\n(",
      "authors": "Ruyu Li, Wenhao Deng,\nYu Cheng, Zheng Yuan,\nJiaqi Zhang, and Fajie Yuan.\n2023a.",
      "orig_title": "Exploring the Upper Limits of Text-Based Collaborative Filtering Using Large Language Models: Discoveries and Insights",
      "paper_id": "2305.11700v1"
    },
    {
      "index": 111,
      "title": "A Survey on Out-of-Distribution Evaluation of Neural NLP Models",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Xinzhe Li, Ming Liu,\nShang Gao, and Wray Buntine.\n2023c.",
      "orig_title": "A Survey on Out-of-Distribution Evaluation of Neural NLP Models",
      "paper_id": "2306.15261v1"
    },
    {
      "index": 112,
      "title": "AlpacaEval: An Automatic Evaluator of Instruction-following Models",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Xuechen Li, Tianyi Zhang,\nYann Dubois, Rohan Taori,\nIshaan Gulrajani, Carlos Guestrin,\nPercy Liang, and Tatsunori B.\nHashimoto. 2023f."
    },
    {
      "index": 113,
      "title": "Evaluating Object Hallucination in Large Vision-Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.10355\n(",
      "authors": "Yifan Li, Yifan Du,\nKun Zhou, Jinpeng Wang,\nWayne Xin Zhao, and Ji-Rong Wen.\n2023b.",
      "orig_title": "Evaluating object hallucination in large vision-language models",
      "paper_id": "2305.10355v3"
    },
    {
      "index": 114,
      "title": "Holistic Evaluation of Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2211.09110\n(",
      "authors": "Percy Liang, Rishi\nBommasani, Tony Lee, Dimitris Tsipras,\nDilara Soylu, Michihiro Yasunaga,\nYian Zhang, Deepak Narayanan,\nYuhuai Wu, Ananya Kumar, et al.\n2022.",
      "orig_title": "Holistic evaluation of language models",
      "paper_id": "2211.09110v2"
    },
    {
      "index": 115,
      "title": "Leveraging Word Guessing Games to Assess the Intelligence of Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2310.20499\n(",
      "authors": "Tian Liang, Zhiwei He,\nJen-tes Huang, Wenxuan Wang,\nWenxiang Jiao, Rui Wang,\nYujiu Yang, Zhaopeng Tu,\nShuming Shi, and Xing Wang.\n2023a.",
      "orig_title": "Leveraging Word Guessing Games to Assess the Intelligence of Large Language Models",
      "paper_id": "2310.20499v2"
    },
    {
      "index": 116,
      "title": "UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2311.15296\n(",
      "authors": "Xun Liang, Shichao Song,\nSimin Niu, Zhiyu Li,\nFeiyu Xiong, Bo Tang,\nZhaohui Wy, Dawei He,\nPeng Cheng, Zhonghao Wang,\net al. 2023b."
    },
    {
      "index": 117,
      "title": "Can Large Language Models Reason about Medical Questions?",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2207.08143\n(",
      "authors": "Valentin Liévin,\nChristoffer Egeberg Hother, and Ole\nWinther. 2022.",
      "orig_title": "Can large language models reason about medical questions?",
      "paper_id": "2207.08143v4"
    },
    {
      "index": 118,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2004",
      "venue": "https://aclanthology.org/W04-",
      "authors": "Chin-Yew Lin.\n2004.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 119,
      "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2109.07958\n(",
      "authors": "Stephanie Lin, Jacob\nHilton, and Owain Evans.\n2021.",
      "orig_title": "Truthfulqa: Measuring how models mimic human falsehoods",
      "paper_id": "2109.07958v2"
    },
    {
      "index": 120,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "Tsung-Yi Lin, Michael\nMaire, Serge Belongie, James Hays,\nPietro Perona, Deva Ramanan,\nPiotr Dollár, and C Lawrence\nZitnick. 2014.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 121,
      "title": "LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.13711\n(",
      "authors": "Yen-Ting Lin and\nYun-Nung Chen. 2023.",
      "orig_title": "LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models",
      "paper_id": "2305.13711v1"
    },
    {
      "index": 122,
      "title": "M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Chuang Liu, Renren Jin,\nYuqi Ren, Linhao Yu,\nTianyu Dong, Xiaohan Peng,\nShuting Zhang, Jianxiang Peng,\nPeiyi Zhang, Qingqing Lyu,\nXiaowen Su, Qun Liu, and\nDeyi Xiong. 2023c.",
      "orig_title": "M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models",
      "paper_id": "2305.10263v2"
    },
    {
      "index": 123,
      "title": "Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Fuxiao Liu, Kevin Lin,\nLinjie Li, Jianfeng Wang,\nYaser Yacoob, and Lijuan Wang.\n2023d.",
      "orig_title": "Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning",
      "paper_id": "2306.14565v4"
    },
    {
      "index": 124,
      "title": "Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Hanmeng Liu, Ruoxi Ning,\nZhiyang Teng, Jian Liu,\nQiji Zhou, and Yue Zhang.\n2023e.",
      "orig_title": "Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4",
      "paper_id": "2304.03439v3"
    },
    {
      "index": 125,
      "title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.01210\n(",
      "authors": "Jiawei Liu, Chunqiu Steven\nXia, Yuyao Wang, and Lingming Zhang.\n2023f.",
      "orig_title": "Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation",
      "paper_id": "2305.01210v3"
    },
    {
      "index": 126,
      "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Yuan Liu, Haodong Duan,\nYuanhan Zhang, Bo Li,\nSongyang Zhang, Wangbo Zhao,\nYike Yuan, Jiaqi Wang,\nConghui He, Ziwei Liu,\nKai Chen, and Dahua Lin.\n2023a.",
      "orig_title": "MMBench: Is Your Multi-modal Model an All-around Player?",
      "paper_id": "2307.06281v5"
    },
    {
      "index": 127,
      "title": "Summary of chatgpt/gpt-4 research and perspective towards the future of large language models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.01852\n(",
      "authors": "Yiheng Liu, Tianle Han,\nSiyuan Ma, Jiayue Zhang,\nYuanyuan Yang, Jiaming Tian,\nHao He, Antong Li,\nMengshen He, Zhengliang Liu,\net al. 2023b."
    },
    {
      "index": 128,
      "title": "Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "LMSYS. 2023."
    },
    {
      "index": 129,
      "title": "Can chatgpt forecast stock price movements? Return predictability and large language models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.07619\n(",
      "authors": "Alejandro Lopez-Lira and\nYuehua Tang. 2023."
    },
    {
      "index": 130,
      "title": "New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.01181\n(",
      "authors": "Chenyang Lyu, Jitao Xu,\nand Longyue Wang. 2023b.",
      "orig_title": "New trends in machine translation using large language models: Case examples with chatgpt",
      "paper_id": "2305.01181v3"
    },
    {
      "index": 131,
      "title": "Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.09038\n(",
      "authors": "Qing Lyu, Josh Tan,\nMike E Zapadka, Janardhana Ponnatapuram,\nChuang Niu, Ge Wang, and\nChristopher T Whitlow. 2023a.",
      "orig_title": "Translating radiology reports into plain language using chatgpt and gpt-4 with prompt learning: Promising results, limitations, and potential",
      "paper_id": "2303.09038v3"
    },
    {
      "index": 132,
      "title": "Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing\nSystems 34 (2021)",
      "authors": "Zhiyi Ma, Kawin\nEthayarajh, Tristan Thrush, Somya Jain,\nLedell Wu, Robin Jia,\nChristopher Potts, Adina Williams, and\nDouwe Kiela. 2021.",
      "orig_title": "Dynaboard: An evaluation-as-a-service platform for holistic next-generation benchmarking",
      "paper_id": "2106.06052v1"
    },
    {
      "index": 133,
      "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.08896\n(",
      "authors": "Potsawee Manakul, Adian\nLiusie, and Mark JF Gales.\n2023a.",
      "orig_title": "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models",
      "paper_id": "2303.08896v3"
    },
    {
      "index": 134,
      "title": "MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Potsawee Manakul, Adian\nLiusie, and Mark J. F. Gales.\n2023b."
    },
    {
      "index": 135,
      "title": "Dynamic Benchmarking of Masked Language Models on Temporal Concept Drift with Multiple Views",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2302.12297\n(",
      "authors": "Katerina Margatina, Shuai\nWang, Yogarshi Vyas, Neha Anna John,\nYassine Benajiba, and Miguel\nBallesteros. 2023.",
      "orig_title": "Dynamic benchmarking of masked language models on temporal concept drift with multiple views",
      "paper_id": "2302.12297v1"
    },
    {
      "index": 136,
      "title": "What is artificial intelligence",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": "John McCarthy.\n2007."
    },
    {
      "index": 137,
      "title": "Bing Chat",
      "abstract": "",
      "year": "2023",
      "venue": "https://www.bing.com/new\n(",
      "authors": "Microsoft.\n2023."
    },
    {
      "index": 138,
      "title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.14251\n(",
      "authors": "Sewon Min, Kalpesh\nKrishna, Xinxi Lyu, Mike Lewis,\nWen-tau Yih, Pang Wei Koh,\nMohit Iyyer, Luke Zettlemoyer, and\nHannaneh Hajishirzi. 2023.",
      "orig_title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation",
      "paper_id": "2305.14251v2"
    },
    {
      "index": 139,
      "title": "Large Language Models as Tax Attorneys: A Case Study in Legal Capabilities Emergence",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.07075\n(",
      "authors": "John J Nay, David\nKaramardian, Sarah B Lawsky, Wenting\nTao, Meghana Bhat, Raghav Jain,\nAaron Travis Lee, Jonathan H Choi, and\nJungo Kasai. 2023."
    },
    {
      "index": 140,
      "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1910.14599\n(",
      "authors": "Yixin Nie, Adina\nWilliams, Emily Dinan, Mohit Bansal,\nJason Weston, and Douwe Kiela.\n2019.",
      "orig_title": "Adversarial NLI: A new benchmark for natural language understanding",
      "paper_id": "1910.14599v2"
    },
    {
      "index": 141,
      "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2203.13474\n(",
      "authors": "Erik Nijkamp, Bo Pang,\nHiroaki Hayashi, Lifu Tu,\nHuan Wang, Yingbo Zhou,\nSilvio Savarese, and Caiming Xiong.\n2022.",
      "orig_title": "Codegen: An open large language model for code with multi-turn program synthesis",
      "paper_id": "2203.13474v5"
    },
    {
      "index": 142,
      "title": "Why we need new evaluation metrics for NLG",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1707.06875\n(",
      "authors": "Jekaterina Novikova,\nOndřej Dušek, Amanda Cercas\nCurry, and Verena Rieser.\n2017."
    },
    {
      "index": 143,
      "title": "ChatGPT goes to the operating room: evaluating GPT-4 performance and its potential in surgical education and training in the era of large language models",
      "abstract": "",
      "year": "2023",
      "venue": "Annals of Surgical Treatment and Research\n104, 5 (2023),\n269",
      "authors": "Namkee Oh, Gyu-Seong\nChoi, and Woo Yong Lee.\n2023."
    },
    {
      "index": 144,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Andrew M Olney.\n2023.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 145,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "OpenAI. 2023a.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 146,
      "title": "GPT-4 Technical Report",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "OpenAI. 2023b.",
      "orig_title": "GPT-4 Technical Report",
      "paper_id": "2303.08774v6"
    },
    {
      "index": 147,
      "title": "Human-like problem-solving abilities in large language models using ChatGPT",
      "abstract": "",
      "year": "2023",
      "venue": "Frontiers in Artificial Intelligence\n6 (",
      "authors": "Graziella Orrù, Andrea\nPiarulli, Ciro Conversano, and Angelo\nGemignani. 2023."
    },
    {
      "index": 148,
      "title": "ThoughtSource: A central hub for large language model reasoning data",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2301.11596\n(",
      "authors": "Simon Ott, Konstantin\nHebenstreit, Valentin Liévin,\nChristoffer Egeberg Hother, Milad Moradi,\nMaximilian Mayrhauser, Robert Praas,\nOle Winther, and Matthias Samwald.\n2023."
    },
    {
      "index": 149,
      "title": "Training language models to follow instructions with human feedback",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing\nSystems 35 (2022)",
      "authors": "Long Ouyang, Jeffrey Wu,\nXu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin,\nChong Zhang, Sandhini Agarwal,\nKatarina Slama, Alex Ray,\net al. 2022."
    },
    {
      "index": 150,
      "title": "Understanding the Capabilities of Large Language Models for Automated Planning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.16151\n(",
      "authors": "Vishal Pallagani, Bharath\nMuppasani, Keerthiram Murugesan,\nFrancesca Rossi, Biplav Srivastava,\nLior Horesh, Francesco Fabiano, and\nAndrea Loreggia. 2023.",
      "orig_title": "Understanding the Capabilities of Large Language Models for Automated Planning",
      "paper_id": "2305.16151v1"
    },
    {
      "index": 151,
      "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv:",
      "authors": "Shirui Pan, Linhao Luo,\nYufei Wang, Chen Chen,\nJiapu Wang, and Xindong Wu.\n2023.",
      "orig_title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
      "paper_id": "2306.08302v3"
    },
    {
      "index": 152,
      "title": "TALM: Tool Augmented Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2205.12255\n(",
      "authors": "Aaron Parisi, Yao Zhao,\nand Noah Fiedel. 2022.",
      "orig_title": "Talm: Tool augmented language models",
      "paper_id": "2205.12255v1"
    },
    {
      "index": 153,
      "title": "Vishakh Padmakumar",
      "abstract": "",
      "year": "2086",
      "venue": "",
      "authors": "Alicia Parrish, Angelica\nChen, Nikita Nangia, Vishakh Padmakumar,\nJason Phang, Jana Thompson,\nPhu Mon Htut, and Samuel Bowman.\n2022."
    },
    {
      "index": 154,
      "title": "Leveraging Large Language Models for Topic Classification in the Domain of Public Affairs",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.02864\n(",
      "authors": "Alejandro Peña,\nAythami Morales, Julian Fierrez,\nIgnacio Serna, Javier Ortega-Garcia,\nIñigo Puente, Jorge Cordova, and\nGonzalo Cordova. 2023.",
      "orig_title": "Leveraging Large Language Models for Topic Classification in the Domain of Public Affairs",
      "paper_id": "2306.02864v2"
    },
    {
      "index": 155,
      "title": "Validity problems comparing values across cultures and possible solutions",
      "abstract": "",
      "year": "1997",
      "venue": "Psychological methods 2,\n4 (",
      "authors": "Kaiping Peng, Richard E\nNisbett, and Nancy YC Wong.\n1997."
    },
    {
      "index": 156,
      "title": "Measuring and Modifying Factual Knowledge in Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.06264\n(",
      "authors": "Pouya Pezeshkpour.\n2023.",
      "orig_title": "Measuring and Modifying Factual Knowledge in Large Language Models",
      "paper_id": "2306.06264v1"
    },
    {
      "index": 157,
      "title": "Adversarially Constructed Evaluation Sets Are More Challenging, but May Not Be Fair",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2111.08181\n(",
      "authors": "Jason Phang, Angelica\nChen, William Huang, and Samuel R\nBowman. 2021.",
      "orig_title": "Adversarially constructed evaluation sets are more challenging, but may not be fair",
      "paper_id": "2111.08181v1"
    },
    {
      "index": 158,
      "title": "ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv:",
      "authors": "Dongqi Pu and Vera\nDemberg. 2023.",
      "orig_title": "ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer",
      "paper_id": "2306.07799v2"
    },
    {
      "index": 159,
      "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2302.06476\n(",
      "authors": "Chengwei Qin, Aston\nZhang, Zhuosheng Zhang, Jiaao Chen,\nMichihiro Yasunaga, and Diyi Yang.\n2023c.",
      "orig_title": "Is ChatGPT a general-purpose natural language processing task solver?",
      "paper_id": "2302.06476v3"
    },
    {
      "index": 160,
      "title": "Tool Learning with Foundation Models",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "",
      "orig_title": "Tool Learning with Foundation Models",
      "paper_id": "2304.08354v3"
    },
    {
      "index": 161,
      "title": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Yujia Qin, Shihao Liang,\nYining Ye, Kunlun Zhu,\nLan Yan, Yaxi Lu, Yankai\nLin, Xin Cong, Xiangru Tang,\nBill Qian, Sihan Zhao,\nRunchu Tian, Ruobing Xie,\nJie Zhou, Mark Gerstein,\nDahai Li, Zhiyuan Liu, and\nMaosong Sun. 2023b.",
      "orig_title": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs",
      "paper_id": "2307.16789v2"
    },
    {
      "index": 162,
      "title": "Improving language understanding by generative pre-training",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Alec Radford, Karthik\nNarasimhan, Tim Salimans, Ilya\nSutskever, et al. 2018."
    },
    {
      "index": 163,
      "title": "A Survey of Hallucination in “Large” Foundation Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2309.05922\n(",
      "authors": "Vipula Rawte, Amit Sheth,\nand Amitava Das. 2023.",
      "orig_title": "A Survey of Hallucination in Large Foundation Models",
      "paper_id": "2309.05922v1"
    },
    {
      "index": 164,
      "title": "Marco Tulio Ribeiro and Scott Lundberg",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Marco Tulio Ribeiro and\nScott Lundberg. 2022."
    },
    {
      "index": 165,
      "title": "Beyond Accuracy: Behavioral Testing of NLP Models with CheckList",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2005.04118\n(",
      "authors": "Marco Tulio Ribeiro,\nTongshuang Wu, Carlos Guestrin, and\nSameer Singh. 2020.",
      "orig_title": "Beyond accuracy: Behavioral testing of NLP models with CheckList",
      "paper_id": "2005.04118v1"
    },
    {
      "index": 166,
      "title": "The Two Word Test: A Semantic Benchmark for Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.04610\n(",
      "authors": "Nicholas Riccardi and\nRutvik H Desai. 2023."
    },
    {
      "index": 167,
      "title": "The Self-Perception and Political Biases of ChatGPT",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.07333\n(",
      "authors": "Jérôme Rutinowski,\nSven Franke, Jan Endendyk,\nIna Dormuth, and Markus Pauly.\n2023.",
      "orig_title": "The Self-Perception and Political Biases of ChatGPT",
      "paper_id": "2304.07333v1"
    },
    {
      "index": 168,
      "title": "Personality Traits in Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2307.00184\n(",
      "authors": "Mustafa Safdari, Greg\nSerapio-García, Clément Crepy,\nStephen Fitz, Peter Romero,\nLuning Sun, Marwa Abdulhai,\nAleksandra Faust, and Maja\nMatarić. 2023."
    },
    {
      "index": 169,
      "title": "Assessing the accuracy of responses by the language model ChatGPT to questions regarding bariatric surgery",
      "abstract": "",
      "year": "2023",
      "venue": "Obesity Surgery (2023),\n1–7",
      "authors": "Jamil S Samaan, Yee Hui\nYeo, Nithya Rajeev, Lauren Hawley,\nStuart Abel, Wee Han Ng,\nNitin Srinivasan, Justin Park,\nMiguel Burch, Rabindra Watson,\net al. 2023."
    },
    {
      "index": 170,
      "title": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.15269\n(",
      "authors": "Abulhair Saparov,\nRichard Yuanzhe Pang, Vishakh Padmakumar,\nNitish Joshi, Seyed Mehran Kazemi,\nNajoung Kim, and He He.\n2023.",
      "orig_title": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples",
      "paper_id": "2305.15269v3"
    },
    {
      "index": 171,
      "title": "ARB: Advanced Reasoning Benchmark for Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv:",
      "authors": "Tomohiro Sawada, Daniel\nPaleka, Alexander Havrilla, Pranav\nTadepalli, Paula Vidas, Alexander\nKranias, John J. Nay, Kshitij Gupta,\nand Aran Komatsuzaki. 2023.",
      "orig_title": "ARB: Advanced Reasoning Benchmark for Large Language Models",
      "paper_id": "2307.13692v2"
    },
    {
      "index": 172,
      "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2302.04761\n(",
      "authors": "Timo Schick, Jane\nDwivedi-Yu, Roberto Dessì, Roberta\nRaileanu, Maria Lomeli, Luke\nZettlemoyer, Nicola Cancedda, and\nThomas Scialom. 2023.",
      "orig_title": "Toolformer: Language models can teach themselves to use tools",
      "paper_id": "2302.04761v1"
    },
    {
      "index": 173,
      "title": "Performance of ChatGPT on USMLE: Unlocking the Potential of Large Language Models for AI-Assisted Medical Education",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2307.00112\n(",
      "authors": "Prabin Sharma, Kisan\nThapa, Prastab Dhakal, Mala Deep\nUpadhaya, Santosh Adhikari, and\nSalik Ram Khanal. 2023."
    },
    {
      "index": 174,
      "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.17580\n(",
      "authors": "Yongliang Shen, Kaitao\nSong, Xu Tan, Dongsheng Li,\nWeiming Lu, and Yueting Zhuang.\n2023.",
      "orig_title": "Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface",
      "paper_id": "2303.17580v4"
    },
    {
      "index": 175,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Emily Sheng, Kai-Wei\nChang, Prem Natarajan, and Nanyun\nPeng. 2021.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 176,
      "title": "Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2209.12106\n(",
      "authors": "Gabriel Simmons.\n2022.",
      "orig_title": "Moral mimicry: Large language models produce moral rationalizations tailored to political identity",
      "paper_id": "2209.12106v2"
    },
    {
      "index": 177,
      "title": "Large Language Models Encode Clinical Knowledge",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2212.13138\n(",
      "authors": "Karan Singhal, Shekoofeh\nAzizi, Tao Tu, S Sara Mahdavi,\nJason Wei, Hyung Won Chung,\nNathan Scales, Ajay Tanwani,\nHeather Cole-Lewis, Stephen Pfohl,\net al. 2022.",
      "orig_title": "Large Language Models Encode Clinical Knowledge",
      "paper_id": "2212.13138v1"
    },
    {
      "index": 178,
      "title": "Large Language Models Encode Clinical Knowledge",
      "abstract": "",
      "year": "2023",
      "venue": "Nature 620",
      "authors": "Karan Singhal, Shekoofeh\nAzizi, Tao Tu, S Sara Mahdavi,\nJason Wei, Hyung Won Chung,\nNathan Scales, Ajay Tanwani,\nHeather Cole-Lewis, Stephen Pfohl,\net al. 2023.",
      "orig_title": "Large language models encode clinical knowledge",
      "paper_id": "2212.13138v1"
    },
    {
      "index": 179,
      "title": "Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2201.11990\n(",
      "authors": "Shaden Smith, Mostofa\nPatwary, Brandon Norick, Patrick\nLeGresley, Samyam Rajbhandari, Jared\nCasper, Zhun Liu, Shrimai Prabhumoye,\nGeorge Zerveas, Vijay Korthikanti,\net al. 2022."
    },
    {
      "index": 180,
      "title": "Have Large Language Models Developed a Personality?: Applicability of Self-Assessment Tests in Measuring Personality in LLMs",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.14693\n(",
      "authors": "Xiaoyang Song, Akshat\nGupta, Kiyan Mohebbizadeh, Shujie Hu,\nand Anant Singh. 2023.",
      "orig_title": "Have Large Language Models Developed a Personality?: Applicability of Self-Assessment Tests in Measuring Personality in LLMs",
      "paper_id": "2305.14693v1"
    },
    {
      "index": 181,
      "title": "ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.16837\n(",
      "authors": "Giriprasad Sridhara,\nSourav Mazumdar, et al.\n2023.",
      "orig_title": "ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks",
      "paper_id": "2305.16837v1"
    },
    {
      "index": 182,
      "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2206.04615\n(",
      "authors": "Aarohi Srivastava, Abhinav\nRastogi, Abhishek Rao, Abu Awal Md\nShoeb, Abubakar Abid, Adam Fisch,\nAdam R Brown, Adam Santoro,\nAditya Gupta, Adrià Garriga-Alonso,\net al. 2022.",
      "orig_title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
      "paper_id": "2206.04615v3"
    },
    {
      "index": 183,
      "title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.09542\n(",
      "authors": "Weiwei Sun, Lingyong Yan,\nXinyu Ma, Pengjie Ren,\nDawei Yin, and Zhaochun Ren.\n2023.",
      "orig_title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent",
      "paper_id": "2304.09542v3"
    },
    {
      "index": 184,
      "title": "EvEval : A Comprehensive Evaluation of Event Semantics for Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.15268\n(",
      "authors": "Zhengwei Tao, Zhi Jin,\nXiaoying Bai, Haiyan Zhao,\nYanlin Feng, Jia Li, and\nWenpeng Hu. 2023.",
      "orig_title": "EvEval: A Comprehensive Evaluation of Event Semantics for Large Language Models",
      "paper_id": "2305.15268v1"
    },
    {
      "index": 185,
      "title": "BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2104.08663\n(",
      "authors": "Nandan Thakur, Nils\nReimers, Andreas Rücklé, Abhishek\nSrivastava, and Iryna Gurevych.\n2021.",
      "orig_title": "Beir: A heterogenous benchmark for zero-shot evaluation of information retrieval models",
      "paper_id": "2104.08663v4"
    },
    {
      "index": 186,
      "title": "Trialling a large language model (ChatGPT) in general practice with the Applied Knowledge Test: observational study demonstrating opportunities and limitations in primary care",
      "abstract": "",
      "year": "2023",
      "venue": "JMIR Medical Education 9,\n1 (",
      "authors": "Arun James Thirunavukarasu,\nRefaat Hassan, Shathar Mahmood,\nRohan Sanghera, Kara Barzangi,\nMohanned El Mukashfi, and Sachin Shah.\n2023."
    },
    {
      "index": 187,
      "title": "LaMDA: Language Models for Dialog Applications",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2201.08239\n(",
      "authors": "Romal Thoppilan, Daniel\nDe Freitas, Jamie Hall, Noam Shazeer,\nApoorv Kulshreshtha, Heng-Tze Cheng,\nAlicia Jin, Taylor Bos,\nLeslie Baker, Yu Du, et al.\n2022.",
      "orig_title": "Lamda: Language models for dialog applications",
      "paper_id": "2201.08239v3"
    },
    {
      "index": 188,
      "title": "Dynatask: A Framework for Creating Dynamic AI Benchmark Tasks",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2204.01906\n(",
      "authors": "Tristan Thrush, Kushal\nTirumala, Anmol Gupta, Max Bartolo,\nPedro Rodriguez, Tariq Kane,\nWilliam Gaviria Rojas, Peter Mattson,\nAdina Williams, and Douwe Kiela.\n2022.",
      "orig_title": "Dynatask: A framework for creating dynamic AI benchmark tasks",
      "paper_id": "2204.01906v1"
    },
    {
      "index": 189,
      "title": "Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.14975\n(",
      "authors": "Katherine Tian, Eric\nMitchell, Allan Zhou, Archit Sharma,\nRafael Rafailov, Huaxiu Yao,\nChelsea Finn, and Christopher D\nManning. 2023.",
      "orig_title": "Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback",
      "paper_id": "2305.14975v2"
    },
    {
      "index": 190,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Yuchi Tian, Kexin Pei,\nSuman Jana, and Baishakhi Ray.\n2018.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 191,
      "title": "Open-source tools learning benchmarks",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "ToolBench.\n2023."
    },
    {
      "index": 192,
      "title": "LLaMA: Open and Efficient Foundation Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2302.13971\n(",
      "authors": "Hugo Touvron, Thibaut\nLavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux,\nTimothée Lacroix, Baptiste\nRozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al.\n2023.",
      "orig_title": "Llama: Open and efficient foundation language models",
      "paper_id": "2302.13971v1"
    },
    {
      "index": 193,
      "title": "Computing machinery and intelligence",
      "abstract": "",
      "year": "2009",
      "venue": "Springer",
      "authors": "Alan M Turing.\n2009."
    },
    {
      "index": 194,
      "title": "On the Planning Abilities of Large Language Models–A Critical Investigation",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.15771\n(",
      "authors": "Karthik Valmeekam, Matthew\nMarquez, Sarath Sreedharan, and\nSubbarao Kambhampati. 2023."
    },
    {
      "index": 195,
      "title": "Large Language Models Still Can’t Plan (A Benchmark for LLMs on Planning and Reasoning about Change)",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2206.10498\n(",
      "authors": "Karthik Valmeekam, Alberto\nOlmo, Sarath Sreedharan, and Subbarao\nKambhampati. 2022."
    },
    {
      "index": 196,
      "title": "Emiel Van Miltenburg",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Chris Van Der Lee, Albert\nGatt, Emiel Van Miltenburg, Sander\nWubben, and Emiel Krahmer.\n2019."
    },
    {
      "index": 197,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing\nsystems 30 (",
      "authors": "Ashish Vaswani, Noam\nShazeer, Niki Parmar, Jakob Uszkoreit,\nLlion Jones, Aidan N Gomez,\nŁukasz Kaiser, and Illia\nPolosukhin. 2017.",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 198,
      "title": "FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv:",
      "authors": "Tu Vu, Mohit Iyyer,\nXuezhi Wang, Noah Constant,\nJerry Wei, Jason Wei,\nChris Tar, Yun-Hsuan Sung,\nDenny Zhou, Quoc Le, and\nThang Luong. 2023.",
      "orig_title": "FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation",
      "paper_id": "2310.03214v2"
    },
    {
      "index": 199,
      "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in neural information processing\nsystems 32 (",
      "authors": "Alex Wang, Yada\nPruksachatkun, Nikita Nangia, Amanpreet\nSingh, Julian Michael, Felix Hill,\nOmer Levy, and Samuel Bowman.\n2019.",
      "orig_title": "Superglue: A stickier benchmark for general-purpose language understanding systems",
      "paper_id": "1905.00537v3"
    },
    {
      "index": 200,
      "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1804.07461\n(",
      "authors": "Alex Wang, Amanpreet\nSingh, Julian Michael, Felix Hill,\nOmer Levy, and Samuel R Bowman.\n2018.",
      "orig_title": "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
      "paper_id": "1804.07461v3"
    },
    {
      "index": 201,
      "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Boxin Wang, Weixin Chen,\nHengzhi Pei, Chulin Xie,\nMintong Kang, Chenhui Zhang,\nChejian Xu, Zidi Xiong,\nRitik Dutta, Rylan Schaeffer,\nSang T. Truong, Simran Arora,\nMantas Mazeika, Dan Hendrycks,\nZinan Lin, Yu Cheng,\nSanmi Koyejo, Dawn Song, and\nBo Li. 2023a.",
      "orig_title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models",
      "paper_id": "2306.11698v5"
    },
    {
      "index": 202,
      "title": "GPT-J-6B: A 6 billion parameter autoregressive language model",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Ben Wang and Aran\nKomatsuzaki. 2021."
    },
    {
      "index": 203,
      "title": "Adversarial glue: A multi-task benchmark for robustness evaluation of language models",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2111.02840\n(",
      "authors": "Boxin Wang, Chejian Xu,\nShuohang Wang, Zhe Gan,\nYu Cheng, Jianfeng Gao,\nAhmed Hassan Awadallah, and Bo Li.\n2021b."
    },
    {
      "index": 204,
      "title": "Evaluating open question answering evaluation",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.12421\n(",
      "authors": "Cunxiang Wang, Sirui\nCheng, Zhikun Xu, Bowen Ding,\nYidong Wang, and Yue Zhang.\n2023c."
    },
    {
      "index": 205,
      "title": "Chain-of-thought prompting for responding to in-depth dialogue questions with LLM",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Hongru Wang, Rui Wang,\nFei Mi, Zezhong Wang,\nRuifeng Xu, and Kam-Fai Wong.\n2023j."
    },
    {
      "index": 206,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Jindong Wang, Xixu Hu,\nWenxin Hou, Hao Chen,\nRunkai Zheng, Yidong Wang,\nLinyi Yang, Haojun Huang,\nWei Ye, Xiubo Geng, et al.\n2023d.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 207,
      "title": "Generalizing to Unseen Domains: A Survey on Domain Generalization",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE Transactions on Knowledge and Data\nEngineering (",
      "authors": "Jindong Wang, Cuiling\nLan, Chang Liu, Yidong Ouyang,\nTao Qin, Wang Lu,\nYiqiang Chen, Wenjun Zeng, and\nPhilip Yu. 2022.",
      "orig_title": "Generalizing to unseen domains: A survey on domain generalization",
      "paper_id": "2103.03097v7"
    },
    {
      "index": 208,
      "title": "Document-Level Machine Translation with Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.02210\n(",
      "authors": "Longyue Wang, Chenyang\nLyu, Tianbo Ji, Zhirui Zhang,\nDian Yu, Shuming Shi, and\nZhaopeng Tu. 2023h.",
      "orig_title": "Document-level machine translation with large language models",
      "paper_id": "2304.02210v2"
    },
    {
      "index": 209,
      "title": "Large Language Models are not Fair Evaluators",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.17926\n(",
      "authors": "Peiyi Wang, Lei Li,\nLiang Chen, Dawei Zhu,\nBinghuai Lin, Yunbo Cao,\nQi Liu, Tianyu Liu, and\nZhifang Sui. 2023e.",
      "orig_title": "Large language models are not fair evaluators",
      "paper_id": "2305.17926v2"
    },
    {
      "index": 210,
      "title": "Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For Scoring and Providing Actionable Insights on Classroom Instruction",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.03090\n(",
      "authors": "Rose E Wang and Dorottya\nDemszky. 2023.",
      "orig_title": "Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For Scoring and Providing Actionable Insights on Classroom Instruction",
      "paper_id": "2306.03090v1"
    },
    {
      "index": 211,
      "title": "CMB: A Comprehensive Medical Benchmark in Chinese",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2308.08833\n(",
      "authors": "Xidong Wang, Guiming Hardy\nChen, Dingjie Song, Zhiyi Zhang,\nZhihong Chen, Qingying Xiao,\nFeng Jiang, Jianquan Li,\nXiang Wan, Benyou Wang, et al.\n2023b.",
      "orig_title": "CMB: A Comprehensive Medical Benchmark in Chinese",
      "paper_id": "2308.08833v2"
    },
    {
      "index": 212,
      "title": "Emotional Intelligence of Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Xuena Wang, Xueting Li,\nZi Yin, Yue Wu, and\nLiu Jia. 2023g."
    },
    {
      "index": 213,
      "title": "MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2309.10691\n(",
      "authors": "Xingyao Wang, Zihan Wang,\nJiateng Liu, Yangyi Chen,\nLifan Yuan, Hao Peng, and\nHeng Ji. 2023i."
    },
    {
      "index": 214,
      "title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2109.00859\n(",
      "authors": "Yue Wang, Weishi Wang,\nShafiq Joty, and Steven CH Hoi.\n2021a.",
      "orig_title": "Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation",
      "paper_id": "2109.00859v1"
    },
    {
      "index": 215,
      "title": "Exploring Vision-Language Models for Imbalanced Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.01457\n(",
      "authors": "Yidong Wang, Zhuohao Yu,\nJindong Wang, Qiang Heng,\nHao Chen, Wei Ye, Rui\nXie, Xing Xie, and Shikun Zhang.\n2023l.",
      "orig_title": "Exploring Vision-Language Models for Imbalanced Learning",
      "paper_id": "2304.01457v2"
    },
    {
      "index": 216,
      "title": "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.05087\n(",
      "authors": "Yidong Wang, Zhuohao Yu,\nZhengran Zeng, Linyi Yang,\nCunxiang Wang, Hao Chen,\nChaoya Jiang, Rui Xie,\nJindong Wang, Xing Xie, et al.\n2023m.",
      "orig_title": "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization",
      "paper_id": "2306.05087v2"
    },
    {
      "index": 217,
      "title": "Can LLMs like GPT-4 outperform traditional AI tools in dementia diagnosis? Maybe, but not today",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.01499\n(",
      "authors": "Zhuo Wang, Rongzhen Li,\nBowen Dong, Jie Wang,\nXiuxing Li, Ning Liu,\nChenhui Mao, Wei Zhang,\nLiling Dong, Jing Gao, et al.\n2023f.",
      "orig_title": "Can LLMs like GPT-4 outperform traditional AI tools in dementia diagnosis? Maybe, but not today",
      "paper_id": "2306.01499v1"
    },
    {
      "index": 218,
      "title": "Is ChatGPT a Good Sentiment Analyzer? A Preliminary Study",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Zengzhi Wang, Qiming Xie,\nZixiang Ding, Yi Feng, and\nRui Xia. 2023k.",
      "orig_title": "Is ChatGPT a Good Sentiment Analyzer? A Preliminary Study",
      "paper_id": "2304.04339v2"
    },
    {
      "index": 219,
      "title": "Emergent Abilities of Large Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2206.07682\n(",
      "authors": "Jason Wei, Yi Tay,\nRishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud,\nDani Yogatama, Maarten Bosma,\nDenny Zhou, Donald Metzler,\net al. 2022a.",
      "orig_title": "Emergent abilities of large language models",
      "paper_id": "2206.07682v2"
    },
    {
      "index": 220,
      "title": "Emergent Abilities of Large Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "Trans. Mach. Learn. Res",
      "authors": "Jason Wei, Yi Tay,\nRishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud,\nDani Yogatama, Maarten Bosma,\nDenny Zhou, Donald Metzler,\nEd Huai hsin Chi, Tatsunori Hashimoto,\nOriol Vinyals, Percy Liang,\nJeff Dean, and William Fedus.\n2022b.",
      "orig_title": "Emergent Abilities of Large Language Models",
      "paper_id": "2206.07682v2"
    },
    {
      "index": 221,
      "title": "CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv:",
      "authors": "Tianwen Wei, Jian Luan,\nWei Liu, Shuang Dong, and\nBin Wang. 2023.",
      "orig_title": "CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?",
      "paper_id": "2306.16636v1"
    },
    {
      "index": 222,
      "title": "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2302.11382\n(",
      "authors": "Jules White, Quchen Fu,\nSam Hays, Michael Sandborn,\nCarlos Olea, Henry Gilbert,\nAshraf Elnashar, Jesse Spencer-Smith,\nand Douglas C Schmidt. 2023.",
      "orig_title": "A prompt pattern catalog to enhance prompt engineering with chatgpt",
      "paper_id": "2302.11382v1"
    },
    {
      "index": 223,
      "title": "Performance evaluation of classification algorithms by k-fold and leave-one-out cross validation",
      "abstract": "",
      "year": "2015",
      "venue": "Pattern Recognition 48,\n9 (",
      "authors": "Tzu-Tsung Wong.\n2015."
    },
    {
      "index": 224,
      "title": "Large Language Models Can Be Used to Estimate the Ideologies of Politicians in a Zero-Shot Learning Setting",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.12057\n(",
      "authors": "Patrick Y Wu, Joshua A\nTucker, Jonathan Nagler, and Solomon\nMessing. 2023c."
    },
    {
      "index": 225,
      "title": "An Empirical Study on Challenging Math Problem Solving with GPT-4",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.01337\n(",
      "authors": "Yiran Wu, Feiran Jia,\nShaokun Zhang, Qingyun Wu,\nHangyu Li, Erkang Zhu,\nYue Wang, Yin Tat Lee,\nRichard Peng, and Chi Wang.\n2023a.",
      "orig_title": "An Empirical Study on Challenging Math Problem Solving with GPT-4",
      "paper_id": "2306.01337v3"
    },
    {
      "index": 226,
      "title": "Autoformalization with Large Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing\nSystems 35 (2022)",
      "authors": "Yuhuai Wu, Albert Qiaochu\nJiang, Wenda Li, Markus Rabe,\nCharles Staats, Mateja Jamnik, and\nChristian Szegedy. 2022.",
      "orig_title": "Autoformalization with large language models",
      "paper_id": "2205.12615v1"
    },
    {
      "index": 227,
      "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2307.02477\n(",
      "authors": "Zhaofeng Wu, Linlu Qiu,\nAlexis Ross, Ekin Akyürek,\nBoyuan Chen, Bailin Wang,\nNajoung Kim, Jacob Andreas, and\nYoon Kim. 2023b.",
      "orig_title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
      "paper_id": "2307.02477v3"
    },
    {
      "index": 228,
      "title": "Ask Again, Then Fail: Large Language Models’ Vacillations in Judgement",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv:",
      "authors": "Qiming Xie, Zengzhi Wang,\nYi Feng, and Rui Xia.\n2023.",
      "orig_title": "Ask Again, Then Fail: Large Language Models’ Vacillations in Judgement",
      "paper_id": "2310.02174v5"
    },
    {
      "index": 229,
      "title": "Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.09841\n(",
      "authors": "Fangzhi Xu, Qika Lin,\nJiawei Han, Tianzhe Zhao,\nJun Liu, and Erik Cambria.\n2023b."
    },
    {
      "index": 230,
      "title": "CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Guohai Xu, Jiayi Liu,\nMing Yan, Haotian Xu,\nJinghui Si, Zhuoran Zhou,\nPeng Yi, Xing Gao, Jitao\nSang, Rong Zhang, Ji Zhang,\nChao Peng, Fei Huang, and\nJingren Zhou. 2023c.",
      "orig_title": "CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility",
      "paper_id": "2307.09705v1"
    },
    {
      "index": 231,
      "title": "LVLM-eHub: A Comprehensive Evaluation Benchmark for Large Vision-Language Models",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Peng Xu, Wenqi Shao,\nKaipeng Zhang, Peng Gao,\nShuo Liu, Meng Lei,\nFanqing Meng, Siyuan Huang,\nYu Qiao, and Ping Luo.\n2023d.",
      "orig_title": "LVLM-eHub: A Comprehensive Evaluation Benchmark for Large Vision-Language Models",
      "paper_id": "2306.09265v1"
    },
    {
      "index": 232,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2307.01135\n(",
      "authors": "Ruiyun Xu, Yue Feng,\nand Hailiang Chen. 2023a.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 233,
      "title": "Large language models can rate news outlet credibility",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.00228\n(",
      "authors": "Kai-Cheng Yang and\nFilippo Menczer. 2023."
    },
    {
      "index": 234,
      "title": "GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-Distribution Generalization Perspective",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2211.08073\n(",
      "authors": "Linyi Yang, Shuibai\nZhang, Libo Qin, Yafu Li,\nYidong Wang, Hanmeng Liu,\nJindong Wang, Xing Xie, and\nYue Zhang. 2022.",
      "orig_title": "Glue-x: Evaluating natural language understanding models from an out-of-distribution generalization perspective",
      "paper_id": "2211.08073v4"
    },
    {
      "index": 235,
      "title": "LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.06687\n(",
      "authors": "Zhenfei Yin, Jiong Wang,\nJianjian Cao, Zhelun Shi,\nDingning Liu, Mukai Li,\nLu Sheng, Lei Bai,\nXiaoshui Huang, Zhiyong Wang,\net al. 2023.",
      "orig_title": "LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark",
      "paper_id": "2306.06687v3"
    },
    {
      "index": 236,
      "title": "KoLA: Carefully Benchmarking World Knowledge of Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.09296\n(",
      "authors": "Jifan Yu, Xiaozhi Wang,\nShangqing Tu, Shulin Cao,\nDaniel Zhang-Li, Xin Lv,\nHao Peng, Zijun Yao,\nXiaohan Zhang, Hanming Li,\net al. 2023b."
    },
    {
      "index": 237,
      "title": "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2309.12284\n(",
      "authors": "Longhui Yu, Weisen Jiang,\nHan Shi, Jincheng Yu,\nZhengying Liu, Yu Zhang,\nJames T Kwok, Zhenguo Li,\nAdrian Weller, and Weiyang Liu.\n2023a.",
      "orig_title": "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models",
      "paper_id": "2309.12284v4"
    },
    {
      "index": 238,
      "title": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2308.02490\n(",
      "authors": "Weihao Yu, Zhengyuan\nYang, Linjie Li, Jianfeng Wang,\nKevin Lin, Zicheng Liu,\nXinchao Wang, and Lijuan Wang.\n2023c.",
      "orig_title": "Mm-vet: Evaluating large multimodal models for integrated capabilities",
      "paper_id": "2308.02490v4"
    },
    {
      "index": 239,
      "title": "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Lifan Yuan, Yangyi Chen,\nGanqu Cui, Hongcheng Gao,\nFangyuan Zou, Xingyi Cheng,\nHeng Ji, Zhiyuan Liu, and\nMaosong Sun. 2023a.",
      "orig_title": "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations",
      "paper_id": "2306.04618v2"
    },
    {
      "index": 240,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Zheng Yuan, Fajie Yuan,\nYu Song, Youhua Li,\nJunchen Fu, Fei Yang,\nYunzhu Pan, and Yongxin Ni.\n2023b.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 241,
      "title": "How well do Large Language Models perform in Arithmetic tasks?",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.02015\n(",
      "authors": "Zheng Yuan, Hongyi Yuan,\nChuanqi Tan, Wei Wang, and\nSongfang Huang. 2023c.",
      "orig_title": "How well do Large Language Models perform in Arithmetic tasks?",
      "paper_id": "2304.02015v1"
    },
    {
      "index": 242,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": "Rich Zemel, Yu Wu,\nKevin Swersky, Toni Pitassi, and\nCynthia Dwork. 2013.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 243,
      "title": "Glm-130b: An open bilingual pre-trained model",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2210.02414\n(",
      "authors": "Aohan Zeng, Xiao Liu,\nZhengxiao Du, Zihan Wang,\nHanyu Lai, Ming Ding,\nZhuoyi Yang, Yifan Xu,\nWendi Zheng, Xiao Xia, et al.\n2022."
    },
    {
      "index": 244,
      "title": "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.02408\n(",
      "authors": "Beichen Zhang, Kun Zhou,\nXilin Wei, Wayne Xin Zhao,\nJing Sha, Shijin Wang, and\nJi-Rong Wen. 2023h.",
      "orig_title": "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning",
      "paper_id": "2306.02408v1"
    },
    {
      "index": 245,
      "title": "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.02408\n(",
      "authors": "Beichen Zhang, Kun Zhou,\nXilin Wei, Wayne Xin Zhao,\nJing Sha, Shijin Wang, and\nJi-Rong Wen. 2023i.",
      "orig_title": "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning",
      "paper_id": "2306.02408v1"
    },
    {
      "index": 246,
      "title": "Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.07609\n(",
      "authors": "Jizhi Zhang, Keqin Bao,\nYang Zhang, Wenjie Wang,\nFuli Feng, and Xiangnan He.\n2023b.",
      "orig_title": "Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation",
      "paper_id": "2305.07609v3"
    },
    {
      "index": 247,
      "title": "OPT: Open Pre-trained Transformer Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2205.01068\n(",
      "authors": "Susan Zhang, Stephen\nRoller, Naman Goyal, Mikel Artetxe,\nMoya Chen, Shuohui Chen,\nChristopher Dewan, Mona Diab,\nXian Li, Xi Victoria Lin,\net al. 2022.",
      "orig_title": "Opt: Open pre-trained transformer language models",
      "paper_id": "2205.01068v4"
    },
    {
      "index": 248,
      "title": "Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.08997\n(",
      "authors": "Sarah J Zhang, Samuel\nFlorin, Ariel N Lee, Eamon Niknafs,\nAndrei Marginean, Annie Wang,\nKeith Tyser, Zad Chin,\nYann Hicke, Nikhil Singh,\net al. 2023d."
    },
    {
      "index": 249,
      "title": "BERTScore: Evaluating Text Generation with BERT",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1904.09675\n(",
      "authors": "Tianyi Zhang, Varsha\nKishore, Felix Wu, Kilian Q Weinberger,\nand Yoav Artzi. 2019.",
      "orig_title": "Bertscore: Evaluating text generation with bert",
      "paper_id": "1904.09675v3"
    },
    {
      "index": 250,
      "title": "M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.05179\n(",
      "authors": "Wenxuan Zhang,\nSharifah Mahani Aljunied, Chang Gao,\nYew Ken Chia, and Lidong Bing.\n2023a.",
      "orig_title": "M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models",
      "paper_id": "2306.05179v2"
    },
    {
      "index": 251,
      "title": "Sentiment Analysis in the Era of Large Language Models: A Reality Check",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.15005\n(",
      "authors": "Wenxuan Zhang, Yue Deng,\nBing Liu, Sinno Jialin Pan, and\nLidong Bing. 2023c.",
      "orig_title": "Sentiment Analysis in the Era of Large Language Models: A Reality Check",
      "paper_id": "2305.15005v1"
    },
    {
      "index": 252,
      "title": "Wider and deeper llm networks are fairer llm evaluators",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2308.01862\n(",
      "authors": "Xinghua Zhang, Bowen Yu,\nHaiyang Yu, Yangyu Lv,\nTingwen Liu, Fei Huang,\nHongbo Xu, and Yongbin Li.\n2023g."
    },
    {
      "index": 253,
      "title": "Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Yue Zhang, Yafu Li,\nLeyang Cui, Deng Cai,\nLemao Liu, Tingchen Fu,\nXinting Huang, Enbo Zhao,\nYu Zhang, Yulong Chen,\nLongyue Wang, Anh Tuan Luu,\nWei Bi, Freda Shi, and\nShuming Shi. 2023f.",
      "orig_title": "Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models",
      "paper_id": "2309.01219v2"
    },
    {
      "index": 254,
      "title": "SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2309.07045\n(",
      "authors": "Zhexin Zhang, Leqi Lei,\nLindong Wu, Rui Sun,\nYongkang Huang, Chong Long,\nXiao Liu, Xuanyu Lei,\nJie Tang, and Minlie Huang.\n2023e.",
      "orig_title": "SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions",
      "paper_id": "2309.07045v2"
    },
    {
      "index": 255,
      "title": "MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2309.07915\n(",
      "authors": "Haozhe Zhao, Zefan Cai,\nShuzheng Si, Xiaojian Ma,\nKaikai An, Liang Chen,\nZixuan Liu, Sheng Wang,\nWenjuan Han, and Baobao Chang.\n2023a.",
      "orig_title": "MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning",
      "paper_id": "2309.07915v3"
    },
    {
      "index": 256,
      "title": "CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Jiaxu Zhao, Meng Fang,\nZijing Shi, Yitong Li,\nLing Chen, and Mykola Pechenizkiy.\n2023b."
    },
    {
      "index": 257,
      "title": "A Survey of Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.18223\n(",
      "authors": "Wayne Xin Zhao, Kun Zhou,\nJunyi Li, Tianyi Tang,\nXiaolei Wang, Yupeng Hou,\nYingqian Min, Beichen Zhang,\nJunjie Zhang, Zican Dong,\net al. 2023d.",
      "orig_title": "A survey of large language models",
      "paper_id": "2303.18223v16"
    },
    {
      "index": 258,
      "title": "On Evaluating Adversarial Robustness of Large Vision-Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.16934\n(",
      "authors": "Yunqing Zhao, Tianyu\nPang, Chao Du, Xiao Yang,\nChongxuan Li, Ngai-Man Cheung, and\nMin Lin. 2023c.",
      "orig_title": "On Evaluating Adversarial Robustness of Large Vision-Language Models",
      "paper_id": "2305.16934v2"
    },
    {
      "index": 259,
      "title": "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2309.11998\n(",
      "authors": "Lianmin Zheng, Wei-Lin\nChiang, Ying Sheng, Tianle Li,\nSiyuan Zhuang, Zhanghao Wu,\nYonghao Zhuang, Zhuohan Li,\nZi Lin, Eric Xing, et al.\n2023a.",
      "orig_title": "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset",
      "paper_id": "2309.11998v4"
    },
    {
      "index": 260,
      "title": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Lianmin Zheng, Wei-Lin\nChiang, Ying Sheng, Siyuan Zhuang,\nZhanghao Wu, Yonghao Zhuang,\nZi Lin, Zhuohan Li,\nDacheng Li, Eric. P Xing,\nHao Zhang, Joseph E. Gonzalez, and\nIon Stoica. 2023b.",
      "orig_title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena",
      "paper_id": "2306.05685v4"
    },
    {
      "index": 261,
      "title": "Towards a Unified Multi-Dimensional Evaluator for Text Generation",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2210.07197\n(",
      "authors": "Ming Zhong, Yang Liu,\nDa Yin, Yuning Mao,\nYizhu Jiao, Pengfei Liu,\nChenguang Zhu, Heng Ji, and\nJiawei Han. 2022.",
      "orig_title": "Towards a unified multi-dimensional evaluator for text generation",
      "paper_id": "2210.07197v1"
    },
    {
      "index": 262,
      "title": "AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2304.06364\n(",
      "authors": "Wanjun Zhong, Ruixiang\nCui, Yiduo Guo, Yaobo Liang,\nShuai Lu, Yanlin Wang,\nAmin Saied, Weizhu Chen, and\nNan Duan. 2023.",
      "orig_title": "Agieval: A human-centric benchmark for evaluating foundation models",
      "paper_id": "2304.06364v2"
    },
    {
      "index": 263,
      "title": "Large Language Models are Human-Level Prompt Engineers",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2211.01910\n(",
      "authors": "Yongchao Zhou, Andrei Ioan\nMuresanu, Ziwen Han, Keiran Paster,\nSilviu Pitis, Harris Chan, and\nJimmy Ba. 2022.",
      "orig_title": "Large language models are human-level prompt engineers",
      "paper_id": "2211.01910v2"
    },
    {
      "index": 264,
      "title": "PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.04528\n(",
      "authors": "Kaijie Zhu, Jindong Wang,\nJiaheng Zhou, Zichen Wang,\nHao Chen, Yidong Wang,\nLinyi Yang, Wei Ye,\nNeil Zhenqiang Gong, Yue Zhang,\net al. 2023.",
      "orig_title": "PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts",
      "paper_id": "2306.04528v5"
    },
    {
      "index": 265,
      "title": "Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.10512\n(",
      "authors": "Yan Zhuang, Qi Liu,\nYuting Ning, Weizhe Huang,\nRui Lv, Zhenya Huang,\nGuanhao Zhao, Zheng Zhang,\nQingyang Mao, Shijin Wang,\net al. 2023.",
      "orig_title": "Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective",
      "paper_id": "2306.10512v4"
    },
    {
      "index": 266,
      "title": "Exploring ai ethics of chatgpt: A diagnostic analysis",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2301.12867\n(",
      "authors": "Terry Yue Zhuo, Yujin\nHuang, Chunyang Chen, and Zhenchang\nXing. 2023a."
    },
    {
      "index": 267,
      "title": "On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2301.12868\n(",
      "authors": "Terry Yue Zhuo, Zhuang\nLi, Yujin Huang, Yuan-Fang Li,\nWeiqing Wang, Gholamreza Haffari, and\nFatemeh Shiri. 2023b.",
      "orig_title": "On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex",
      "paper_id": "2301.12868v3"
    },
    {
      "index": 268,
      "title": "Fine-Tuning Language Models from Human Preferences",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1909.08593\n(",
      "authors": "Daniel M Ziegler, Nisan\nStiennon, Jeffrey Wu, Tom B Brown,\nAlec Radford, Dario Amodei,\nPaul Christiano, and Geoffrey Irving.\n2019.",
      "orig_title": "Fine-tuning language models from human preferences",
      "paper_id": "1909.08593v2"
    },
    {
      "index": 269,
      "title": "Can Large Language Models Transform Computational Social Science?",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2305.03514\n(",
      "authors": "Caleb Ziems, William\nHeld, Omar Shaikh, Jiaao Chen,\nZhehao Zhang, and Diyi Yang.\n2023.",
      "orig_title": "Can Large Language Models Transform Computational Social Science?",
      "paper_id": "2305.03514v3"
    }
  ]
}