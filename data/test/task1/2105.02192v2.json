{
  "paper_id": "2105.02192v2",
  "title": "Audio Retrieval with Natural Language Queries",
  "abstract": "Abstract\nWe consider the task of retrieving audio using free-form natural language queries. To study this problem, which has received limited attention in the existing literature, we introduce challenging new benchmarks for text-based audio retrieval using text annotations sourced from the AudioCaps and Clotho datasets.\nWe then employ these benchmarks to establish baselines for cross-modal audio retrieval, where we demonstrate the benefits of pre-training on diverse audio tasks.\nWe hope that our benchmarks will inspire further research into cross-modal text-based audio retrieval with free-form text queries.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Word2VisualVec: Image and Video to Sentence Matching by Visual Feature Prediction",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv:1604.06838",
      "authors": "J. Dong et al.",
      "orig_title": "Word2visualvec: Image and video to sentence matching by visual feature prediction",
      "paper_id": "1604.06838v2"
    },
    {
      "index": 1,
      "title": "Learning a Text-Video Embedding from Incomplete and Heterogeneous Data",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:1804.02516",
      "authors": "A. Miech et al.",
      "orig_title": "Learning a text-video embedding from incomplete and heterogeneous data",
      "paper_id": "1804.02516v2"
    },
    {
      "index": 2,
      "title": "Learning joint embedding with multimodal cues for cross-modal video-text retrieval",
      "abstract": "",
      "year": "2018",
      "venue": "ACM ICMR",
      "authors": "N. C. Mithun et al."
    },
    {
      "index": 3,
      "title": "Content-based representations of audio using siamese neural networks",
      "abstract": "",
      "year": "2018",
      "venue": "ICASSP",
      "authors": "P. Manocha et al."
    },
    {
      "index": 4,
      "title": "Content-based retrieval of environmental sounds by multiresolution analysis",
      "abstract": "",
      "year": "2012",
      "venue": "SMC",
      "authors": "I. Lallemand et al."
    },
    {
      "index": 5,
      "title": "Use What You Have: Video Retrieval Using Representations From Collaborative Experts",
      "abstract": "",
      "year": "2019",
      "venue": "BMVC",
      "authors": "Y. Liu et al.",
      "orig_title": "Use what you have: Video retrieval using representations from collaborative experts",
      "paper_id": "1907.13487v2"
    },
    {
      "index": 6,
      "title": "Multi-modal transformer for video retrieval",
      "abstract": "",
      "year": "2020",
      "venue": "ECCV",
      "authors": "V. Gabeur et al."
    },
    {
      "index": 7,
      "title": "Audiocaps: Generating captions for audios in the wild",
      "abstract": "",
      "year": "2019",
      "venue": "NACCL",
      "authors": "C. D. Kim et al."
    },
    {
      "index": 8,
      "title": "Clotho: An Audio Captioning Dataset",
      "abstract": "",
      "year": "2020",
      "venue": "ICASSP",
      "authors": "K. Drossos et al.",
      "orig_title": "Clotho: An audio captioning dataset",
      "paper_id": "1910.09387v1"
    },
    {
      "index": 9,
      "title": "Audio set: An ontology and human-labeled dataset for audio events",
      "abstract": "",
      "year": "2017",
      "venue": "ICASSP",
      "authors": "J. F. Gemmeke et al."
    },
    {
      "index": 10,
      "title": "Freesound technical demo",
      "abstract": "",
      "year": "2013",
      "venue": "ACM Multimedia",
      "authors": "F. Font et al."
    },
    {
      "index": 11,
      "title": "Detection and classification of acoustic scenes and events",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE Transactions on Multimedia",
      "authors": "D. Stowell et al."
    },
    {
      "index": 12,
      "title": "DCASE 2017 challenge setup: Tasks, datasets and baseline system",
      "abstract": "",
      "year": "2017",
      "venue": "DCASE 2017",
      "authors": "A. Mesaros et al."
    },
    {
      "index": 13,
      "title": "TUT Acoustic scenes 2017, Dev. dataset",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "A. Mesaros et al."
    },
    {
      "index": 14,
      "title": "Chime-home: A dataset for sound source recognition in a domestic environment",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE WASPAA",
      "authors": "P. Foster et al."
    },
    {
      "index": 15,
      "title": "ESC: Dataset for environmental sound classification",
      "abstract": "",
      "year": "2015",
      "venue": "ACM Multimedia",
      "authors": "K. J. Piczak"
    },
    {
      "index": 16,
      "title": "Audio tagging with noisy labels and minimal supervision",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:1906.02975",
      "authors": "E. Fonseca et al.",
      "orig_title": "Audio tagging with noisy labels and minimal supervision",
      "paper_id": "1906.02975v4"
    },
    {
      "index": 17,
      "title": "Audio Set classification with attention model: A probabilistic perspective",
      "abstract": "",
      "year": "2018",
      "venue": "ICASSP",
      "authors": "Q. Kong et al.",
      "orig_title": "Audio set classification with attention model: A probabilistic perspective",
      "paper_id": "1711.00927v2"
    },
    {
      "index": 18,
      "title": "Multi-level Attention Model for Weakly Supervised Audio Classification",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:1803.02353",
      "authors": "C. Yu et al.",
      "orig_title": "Multi-level attention model for weakly supervised audio classification",
      "paper_id": "1803.02353v1"
    },
    {
      "index": 19,
      "title": "Weakly Labelled AudioSet Tagging with Attention Neural Networks",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/ACM TASLP",
      "authors": "Q. Kong et al.",
      "orig_title": "Weakly labelled audioset tagging with attention neural networks",
      "paper_id": "1903.00765v6"
    },
    {
      "index": 20,
      "title": "A deep residual network for large-scale acoustic scene analysis.",
      "abstract": "",
      "year": "2019",
      "venue": "INTERSPEECH",
      "authors": "L. Ford et al."
    },
    {
      "index": 21,
      "title": "PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/ACM TASLP",
      "authors": "Q. Kong et al.",
      "orig_title": "Panns: Large-scale pretrained audio neural networks for audio pattern recognition",
      "paper_id": "1912.10211v5"
    },
    {
      "index": 22,
      "title": "Automated audio captioning with recurrent neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE WASPAA",
      "authors": "K. Drossos et al."
    },
    {
      "index": 23,
      "title": "DCASE2020 challenge task 6: Automated audio captioning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 24,
      "title": "AUDIO CAPTION: LISTEN AND TELL",
      "abstract": "",
      "year": "2019",
      "venue": "ICASSP",
      "authors": "M. Wu et al.",
      "orig_title": "Audio caption: Listen and tell",
      "paper_id": "1902.09254v4"
    },
    {
      "index": 25,
      "title": "Audio Captioning using Pre-Trained Large-Scale Language Model Guided by Audio-based Similar Caption Retrieval",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:2012.07331",
      "authors": "Y. Koizumi et al.",
      "orig_title": "Audio captioning using pre-trained large-scale language model guided by audio-based similar caption retrieval",
      "paper_id": "2012.07331v1"
    },
    {
      "index": 26,
      "title": "Investigating Local and Global Information for Automated Audio Captioning with Transfer Learning",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv:2102.11457",
      "authors": "X. Xu et al.",
      "orig_title": "Investigating local and global information for automated audio captioning with transfer learning",
      "paper_id": "2102.11457v1"
    },
    {
      "index": 27,
      "title": "Audio captioning based on combined audio and semantic embeddings",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE ISM",
      "authors": "A. √ñ. Eren and M. Sert"
    },
    {
      "index": 28,
      "title": "Content-based retrieval of music and audio",
      "abstract": "",
      "year": "1997",
      "venue": "Multimedia Storage and Archiving Systems II. International Society for Optics and Photonics",
      "authors": "J. T. Foote"
    },
    {
      "index": 29,
      "title": "Content-based classification, search, and retrieval of audio",
      "abstract": "",
      "year": "1996",
      "venue": "IEEE Multimedia",
      "authors": "E. Wold et al."
    },
    {
      "index": 30,
      "title": "Query by example of audio signals using euclidean distance between gaussian mixture models",
      "abstract": "",
      "year": "2007",
      "venue": "ICASSP",
      "authors": "M. Hel√©n and T. Virtanen"
    },
    {
      "index": 31,
      "title": "Event-based video retrieval using audio",
      "abstract": "",
      "year": "2012",
      "venue": "ISCA",
      "authors": "Q. Jin et al."
    },
    {
      "index": 32,
      "title": "Audio-based Near-Duplicate Video Retrieval with Audio Similarity Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:2010.08737",
      "authors": "P. Avgoustinakis et al.",
      "orig_title": "Audio-based near-duplicate video retrieval with audio similarity learning",
      "paper_id": "2010.08737v2"
    },
    {
      "index": 33,
      "title": "Audio-visual-based query by example video retrieval",
      "abstract": "",
      "year": "2013",
      "venue": "Mathematical Problems in Engineering",
      "authors": "S. Hou and S. Zhou"
    },
    {
      "index": 34,
      "title": "Fine-Grained Action Retrieval Through Multiple Parts-of-Speech Embeddings",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "M. Wray et al.",
      "orig_title": "Fine-grained action retrieval through multiple parts-of-speech embeddings",
      "paper_id": "1908.03477v1"
    },
    {
      "index": 35,
      "title": "NELS - Never-Ending Learner of Sounds",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:1801.05544",
      "authors": "B. Elizalde et al.",
      "orig_title": "Nels-never-ending learner of sounds",
      "paper_id": "1801.05544v2"
    },
    {
      "index": 36,
      "title": "Semantic-audio retrieval",
      "abstract": "",
      "year": "2002",
      "venue": "ICASSP",
      "authors": "M. Slaney"
    },
    {
      "index": 37,
      "title": "Large-scale content-based audio retrieval from text queries",
      "abstract": "",
      "year": "2008",
      "venue": "ACM ICMIR",
      "authors": "G. Chechik et al."
    },
    {
      "index": 38,
      "title": "See, hear, and read: Deep aligned representations",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv:1706.00932",
      "authors": "Y. Aytar et al."
    },
    {
      "index": 39,
      "title": "Cross modal audio search and retrieval with joint embeddings based on text and audio",
      "abstract": "",
      "year": "2019",
      "venue": "ICASSP",
      "authors": "B. Elizalde et al."
    },
    {
      "index": 40,
      "title": "Grounded compositional semantics for finding and describing images with sentences",
      "abstract": "",
      "year": "2014",
      "venue": "Transactions of the Association for Computational Linguistics",
      "authors": "R. Socher et al."
    },
    {
      "index": 41,
      "title": "NetVLAD: CNN architecture for weakly supervised place recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "R. Arandjelovic et al.",
      "orig_title": "Netvlad: Cnn architecture for weakly supervised place recognition",
      "paper_id": "1511.07247v3"
    },
    {
      "index": 42,
      "title": "Efficient estimation of word representations in vector space",
      "abstract": "",
      "year": "2013",
      "venue": "arXiv:1301.3781",
      "authors": "T. Mikolov et al."
    },
    {
      "index": 43,
      "title": "VGG-Sound: A Large-scale Audio-Visual Dataset",
      "abstract": "",
      "year": "2020",
      "venue": "ICASSP",
      "authors": "H. Chen et al.",
      "orig_title": "Vggsound: A large-scale audio-visual dataset",
      "paper_id": "2004.14368v2"
    },
    {
      "index": 44,
      "title": "Project page.",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 45,
      "title": "Dense-Captioning Events in Videos",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "R. Krishna et al.",
      "orig_title": "Dense-captioning events in videos",
      "paper_id": "1705.00754v1"
    },
    {
      "index": 46,
      "title": "QuerYD: a video dataset with high-quality text and audio narrations",
      "abstract": "",
      "year": "2021",
      "venue": "ICASSP",
      "authors": "A.-M. Oncescu et al.",
      "orig_title": "QuerYD: A video dataset with high-quality textual and audio narrations",
      "paper_id": "2011.11071v2"
    },
    {
      "index": 47,
      "title": "Youdescribe",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": "Video Description Research and Development Center"
    },
    {
      "index": 48,
      "title": "Msr-vtt: A large video description dataset for bridging video and language",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "J. Xu et al."
    },
    {
      "index": 49,
      "title": "CNN architectures for large-scale audio classification",
      "abstract": "",
      "year": "2016",
      "venue": "ICASSP",
      "authors": "S. Hershey et al."
    },
    {
      "index": 50,
      "title": "Speech-to-Text API",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Google"
    },
    {
      "index": 51,
      "title": "METEOR: An automatic metric for MT evaluation with improved correlation with human judgments",
      "abstract": "",
      "year": "2005",
      "venue": "ACL Workshop",
      "authors": "S. Banerjee and A. Lavie"
    },
    {
      "index": 52,
      "title": "YouTube-8M: A Large-Scale Video Classification Benchmark",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1609.08675",
      "authors": "S. Abu-El-Haija et al.",
      "orig_title": "Youtube-8m: A large-scale video classification benchmark",
      "paper_id": "1609.08675v1"
    },
    {
      "index": 53,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:1512.03385",
      "authors": "K. He et al.",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 54,
      "title": "Jointly modeling deep video and compositional text to bridge vision and language in a unified framework",
      "abstract": "",
      "year": "2015",
      "venue": "AAAI",
      "authors": "R. Xu et al."
    },
    {
      "index": 55,
      "title": "Exploring the Limits of Weakly Supervised Pretraining",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "D. Mahajan et al.",
      "orig_title": "Exploring the limits of weakly supervised pretraining",
      "paper_id": "1805.00932v1"
    },
    {
      "index": 56,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "CVPR",
      "authors": "J. Deng et al."
    },
    {
      "index": 57,
      "title": "Densely connected convolutional networks",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "G. Huang et al."
    },
    {
      "index": 58,
      "title": "Places: A 10 million image database for scene recognition",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE PAMI",
      "authors": "B. Zhou et al."
    },
    {
      "index": 59,
      "title": "A closer look at spatiotemporal convolutions for action recognition",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "D. Tran et al."
    },
    {
      "index": 60,
      "title": "Large-scale weakly-supervised pre-training for video action recognition",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "D. Ghadiyaram et al.",
      "orig_title": "Large-scale weakly-supervised pre-training for video action recognition",
      "paper_id": "1905.00561v1"
    },
    {
      "index": 61,
      "title": "Lookahead Optimizer: ùëò steps forward, 1 step back",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "M. R. Zhang et al.",
      "orig_title": "Lookahead optimizer: k steps forward, 1 step back",
      "paper_id": "1907.08610v2"
    },
    {
      "index": 62,
      "title": "On the Variance of the Adaptive Learning Rate and Beyond",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1908.03265",
      "authors": "L. Liu et al.",
      "orig_title": "On the variance of the adaptive learning rate and beyond",
      "paper_id": "1908.03265v4"
    },
    {
      "index": 63,
      "title": "Ranger optimiser.",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    }
  ]
}