{
  "paper_id": "2307.02728v2",
  "title": "Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill Learning",
  "abstract": "Abstract\nGeneral purpose agents will require large repertoires of skills. Empowerment—the maximum mutual information between skills and states—provides a pathway for learning large collections of distinct skills, but mutual information is difficult to optimize. We introduce a new framework, Hierarchical Empowerment, that makes computing empowerment more tractable by integrating concepts from Goal-Conditioned Hierarchical Reinforcement Learning. Our framework makes two specific contributions. First, we introduce a new variational lower bound on mutual information that can be used to compute empowerment over short horizons. Second, we introduce a hierarchical architecture for computing empowerment over exponentially longer time scales. We verify the contributions of the framework in a series of simulated robotics tasks. In a popular ant navigation domain, our four level agents are able to learn skills that cover a surface area over two orders of magnitude larger than prior work.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Variational Option Discovery Algorithms",
      "abstract": "",
      "year": "2018",
      "venue": "CoRR",
      "authors": "Joshua Achiam, Harrison Edwards, Dario Amodei, and Pieter Abbeel",
      "orig_title": "Variational option discovery algorithms",
      "paper_id": "1807.10299v1"
    },
    {
      "index": 1,
      "title": "Hindsight experience replay",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong, Peter Welinder, Bob McGrew, Josh Tobin, OpenAI Pieter Abbeel, and Wojciech Zaremba"
    },
    {
      "index": 2,
      "title": "The Option-Critic Architecture",
      "abstract": "",
      "year": "2017",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Pierre-Luc Bacon, Jean Harb, and Doina Precup",
      "orig_title": "The option-critic architecture",
      "paper_id": "1609.05140v2"
    },
    {
      "index": 3,
      "title": "Active learning of inverse models with intrinsically motivated goal exploration in robots",
      "abstract": "",
      "year": "2013",
      "venue": "Robotics and Autonomous Systems",
      "authors": "Adrien Baranes and Pierre-Yves Oudeyer"
    },
    {
      "index": 4,
      "title": "The im algorithm: A variational approach to information maximization",
      "abstract": "",
      "year": "2003",
      "venue": "16th International Conference on Neural Information Processing Systems",
      "authors": "David Barber and Felix Agakov"
    },
    {
      "index": 5,
      "title": "Relative Variational Intrinsic Control",
      "abstract": "",
      "year": "2020",
      "venue": "CoRR",
      "authors": "Kate Baumli, David Warde-Farley, Steven Hansen, and Volodymyr Mnih",
      "orig_title": "Relative variational intrinsic control",
      "paper_id": "2012.07827v1"
    },
    {
      "index": 6,
      "title": "Unifying count-based exploration and intrinsic motivation",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Marc G. Bellemare, Sriram Srinivasan, Georg Ostrovski, Tom Schaul, David Saxton, and Rémi Munos"
    },
    {
      "index": 7,
      "title": "Exploration by Random Network Distillation",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "Yuri Burda, Harrison Edwards, Amos Storkey, and Oleg Klimov",
      "orig_title": "Exploration by random network distillation",
      "paper_id": "1810.12894v1"
    },
    {
      "index": 8,
      "title": "Explore, Discover and Learn: Unsupervised Discovery of State-Covering Skills",
      "abstract": "",
      "year": "2020",
      "venue": "CoRR",
      "authors": "Víctor Campos, Alexander Trott, Caiming Xiong, Richard Socher, Xavier Giró-i-Nieto, and Jordi Torres",
      "orig_title": "Explore, discover and learn: Unsupervised discovery of state-covering skills",
      "paper_id": "2002.03647v4"
    },
    {
      "index": 9,
      "title": "Variational empowerment as representation learning for goal-conditioned reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Machine Learning",
      "authors": "Jongwook Choi, Archit Sharma, Honglak Lee, Sergey Levine, and Shixiang Shane Gu"
    },
    {
      "index": 10,
      "title": "CURIOUS: Intrinsically Motivated Modular Multi-Goal Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Machine Learning",
      "authors": "Cédric Colas, Pierre Fournier, Mohamed Chetouani, Olivier Sigaud, and Pierre-Yves Oudeyer",
      "orig_title": "CURIOUS: Intrinsically motivated modular multi-goal reinforcement learning",
      "paper_id": "1810.06284v4"
    },
    {
      "index": 11,
      "title": "Elements of Information Theory 2nd Edition (Wiley Series in Telecommunications and Signal Processing)",
      "abstract": "",
      "year": "2006",
      "venue": "Wiley-Interscience",
      "authors": "Thomas M. Cover and Joy A. Thomas"
    },
    {
      "index": 12,
      "title": "Feudal reinforcement learning",
      "abstract": "",
      "year": "1992",
      "venue": "Advances in neural information processing systems",
      "authors": "Peter Dayan and Geoffrey E Hinton"
    },
    {
      "index": 13,
      "title": "Hierarchical reinforcement learning with the MAXQ value function decomposition",
      "abstract": "",
      "year": "1999",
      "venue": "CoRR",
      "authors": "Thomas G. Dietterich"
    },
    {
      "index": 14,
      "title": "Diversity is All You Need: Learning Skills without a Reward Function",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, and Sergey Levine",
      "orig_title": "Diversity is all you need: Learning skills without a reward function",
      "paper_id": "1802.06070v6"
    },
    {
      "index": 15,
      "title": "Stochastic Neural Networks for Hierarchical Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Learning Representations",
      "authors": "Carlos Florensa, Yan Duan, and Pieter Abbeel",
      "orig_title": "Stochastic neural networks for hierarchical reinforcement learning",
      "paper_id": "1704.03012v1"
    },
    {
      "index": 16,
      "title": "Automatic Goal Generation for Reinforcement Learning Agents",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Carlos Florensa, David Held, Xinyang Geng, and Pieter Abbeel",
      "orig_title": "Automatic goal generation for reinforcement learning agents",
      "paper_id": "1705.06366v5"
    },
    {
      "index": 17,
      "title": "Brax - a differentiable physics engine for large scale rigid body simulation",
      "abstract": "",
      "year": "2021",
      "venue": "Neural Information Processing Systems Datasets and Benchmarks Track",
      "authors": "C. Daniel Freeman, Erik Frey, Anton Raichuk, Sertan Girgin, Igor Mordatch, and Olivier Bachem"
    },
    {
      "index": 18,
      "title": "Brax - a differentiable physics engine for large scale rigid body simulation",
      "abstract": "",
      "year": "2021",
      "venue": "Neural Information Processing Systems Track on Datasets and Benchmarks",
      "authors": "Daniel Freeman, Erik Frey, Anton Raichuk, Sertan Girgin, Igor Mordatch, and Olivier Bachem"
    },
    {
      "index": 19,
      "title": "Generative adversarial nets",
      "abstract": "",
      "year": "2014",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio"
    },
    {
      "index": 20,
      "title": "Variational Intrinsic Control",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR",
      "authors": "Karol Gregor, Danilo Jimenez Rezende, and Daan Wierstra",
      "orig_title": "Variational intrinsic control",
      "paper_id": "1611.07507v1"
    },
    {
      "index": 21,
      "title": "Braxlines: Fast and Interactive Toolkit for RL-driven Behavior Engineering beyond Reward Maximization",
      "abstract": "",
      "year": "2021",
      "venue": "CoRR",
      "authors": "Shixiang Shane Gu, Manfred Diaz, C. Daniel Freeman, Hiroki Furuta, Seyed Kamyar Seyed Ghasemipour, Anton Raichuk, Byron David, Erik Frey, Erwin Coumans, and Olivier Bachem",
      "orig_title": "Braxlines: Fast and interactive toolkit for rl-driven behavior engineering beyond reward maximization",
      "paper_id": "2110.04686v1"
    },
    {
      "index": 22,
      "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine",
      "orig_title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
      "paper_id": "1801.01290v2"
    },
    {
      "index": 23,
      "title": "Fast Task Inference with Variational Intrinsic Successor Features",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Learning Representations",
      "authors": "Steven Hansen, Will Dabney, Andre Barreto, David Warde-Farley, Tom Van de Wiele, and Volodymyr Mnih",
      "orig_title": "Fast task inference with variational intrinsic successor features",
      "paper_id": "1906.05030v2"
    },
    {
      "index": 24,
      "title": "Learning Continuous Control Policies by Stochastic Value Gradients",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Nicolas Heess, Gregory Wayne, David Silver, Timothy Lillicrap, Tom Erez, and Yuval Tassa",
      "orig_title": "Learning continuous control policies by stochastic value gradients",
      "paper_id": "1510.09142v1"
    },
    {
      "index": 25,
      "title": "Empowerment for continuous agent-environment systems",
      "abstract": "",
      "year": "2012",
      "venue": "CoRR",
      "authors": "Tobias Jung, Daniel Polani, and Peter Stone"
    },
    {
      "index": 26,
      "title": "Learning to achieve goals",
      "abstract": "",
      "year": "1993",
      "venue": "International Joint Conference on Artificial Intelligence",
      "authors": "Leslie Pack Kaelbling"
    },
    {
      "index": 27,
      "title": "Unsupervised Skill Discovery with Bottleneck Option Learning",
      "abstract": "",
      "year": "2021",
      "venue": "CoRR",
      "authors": "Jaekyeom Kim, Seohong Park, and Gunhee Kim",
      "orig_title": "Unsupervised skill discovery with bottleneck option learning",
      "paper_id": "2106.14305v1"
    },
    {
      "index": 28,
      "title": "Auto-Encoding Variational Bayes",
      "abstract": "",
      "year": "2014",
      "venue": "International Conference on Learning Representations",
      "authors": "Diederik P. Kingma and Max Welling"
    },
    {
      "index": 29,
      "title": "Empowerment: a universal agent-centric measure of control",
      "abstract": "",
      "year": "2005",
      "venue": "Congress on Evolutionary Computation",
      "authors": "Alexander S. Klyubin, Daniel Polani, and Chrystopher L. Nehaniv"
    },
    {
      "index": 30,
      "title": "Skill discovery in continuous reinforcement learning domains using skill chaining",
      "abstract": "",
      "year": "2009",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "George Konidaris and Andrew Barto"
    },
    {
      "index": 31,
      "title": "URLB: unsupervised reinforcement learning benchmark",
      "abstract": "",
      "year": "2021",
      "venue": "CoRR",
      "authors": "Michael Laskin, Denis Yarats, Hao Liu, Kimin Lee, Albert Zhan, Kevin Lu, Catherine Cang, Lerrel Pinto, and Pieter Abbeel"
    },
    {
      "index": 32,
      "title": "Efficient Exploration via State Marginal Matching",
      "abstract": "",
      "year": "2019",
      "venue": "CoRR",
      "authors": "Lisa Lee, Benjamin Eysenbach, Emilio Parisotto, Eric P. Xing, Sergey Levine, and Ruslan Salakhutdinov",
      "orig_title": "Efficient exploration via state marginal matching",
      "paper_id": "1906.05274v3"
    },
    {
      "index": 33,
      "title": "Hierarchical actor-critic",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint",
      "authors": "Andrew Levy, George Konidaris, Robert Platt, and Kate Saenko"
    },
    {
      "index": 34,
      "title": "Learning Multi-Level Hierarchies with Hindsight",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "Andrew Levy, George Dimitri Konidaris, Robert Platt Jr., and Kate Saenko",
      "orig_title": "Learning multi-level hierarchies with hindsight",
      "paper_id": "1712.00948v5"
    },
    {
      "index": 35,
      "title": "Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement Learning",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Sam Lobel, Akhil Bagaria, and George Konidaris",
      "orig_title": "Flipping coins to estimate pseudocounts for exploration in reinforcement learning",
      "paper_id": "2306.03186v1"
    },
    {
      "index": 36,
      "title": "HAC explore: Accelerating exploration with hierarchical reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "CoRR",
      "authors": "Willie McClinton, Andrew Levy, and George Konidaris"
    },
    {
      "index": 37,
      "title": "Variational information maximisation for intrinsically motivated reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "NIPS",
      "authors": "Shakir Mohamed and Danilo Jimenez Rezende"
    },
    {
      "index": 38,
      "title": "Data-Efficient Hierarchical Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Neural Information Processing Systems",
      "authors": "Ofir Nachum, Shixiang Gu, Honglak Lee, and Sergey Levine",
      "orig_title": "Data-efficient hierarchical reinforcement learning",
      "paper_id": "1805.08296v4"
    },
    {
      "index": 39,
      "title": "Visual Reinforcement Learning with Imagined Goals",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ashvin V Nair, Vitchyr Pong, Murtaza Dalal, Shikhar Bahl, Steven Lin, and Sergey Levine",
      "orig_title": "Visual reinforcement learning with imagined goals",
      "paper_id": "1807.04742v2"
    },
    {
      "index": 40,
      "title": "Count-Based Exploration with Neural Density Models",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "Georg Ostrovski, Marc G. Bellemare, Aäron van den Oord, and Rémi Munos",
      "orig_title": "Count-based exploration with neural density models",
      "paper_id": "1703.01310v2"
    },
    {
      "index": 41,
      "title": "Lipschitz-constrained Unsupervised Skill Discovery",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Learning Representations",
      "authors": "Seohong Park, Jongwook Choi, Jaekyeom Kim, Honglak Lee, and Gunhee Kim",
      "orig_title": "Lipschitz-constrained unsupervised skill discovery",
      "paper_id": "2202.00914v2"
    },
    {
      "index": 42,
      "title": "Reinforcement learning with hierarchies of machines",
      "abstract": "",
      "year": "1997",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ronald Parr and Stuart Russell"
    },
    {
      "index": 43,
      "title": "Curiosity-driven Exploration by Self-supervised Prediction",
      "abstract": "",
      "year": "2017",
      "venue": "ICML",
      "authors": "Deepak Pathak, Pulkit Agrawal, Alexei A. Efros, and Trevor Darrell",
      "orig_title": "Curiosity-driven exploration by self-supervised prediction",
      "paper_id": "1705.05363v1"
    },
    {
      "index": 44,
      "title": "Maximum entropy gain exploration for long horizon multi-goal reinforcement learning",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Silviu Pitis, Harris Chan, Stephen Zhao, Bradly C. Stadie, and Jimmy Ba"
    },
    {
      "index": 45,
      "title": "Skew-Fit: State-Covering Self-Supervised Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "CoRR",
      "authors": "Vitchyr H. Pong, Murtaza Dalal, Steven Lin, Ashvin Nair, Shikhar Bahl, and Sergey Levine",
      "orig_title": "Skew-fit: State-covering self-supervised reinforcement learning",
      "paper_id": "1903.03698v4"
    },
    {
      "index": 46,
      "title": "Empowerment–An Introduction, pp. 67–114",
      "abstract": "",
      "year": "2014",
      "venue": "Springer Berlin Heidelberg",
      "authors": "Christoph Salge, Cornelius Glackin, and Daniel Polani"
    },
    {
      "index": 47,
      "title": "Universal value function approximators",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Machine Learning",
      "authors": "Tom Schaul, Daniel Horgan, Karol Gregor, and David Silver"
    },
    {
      "index": 48,
      "title": "Curious model-building control systems",
      "abstract": "",
      "year": "1991",
      "venue": "IEEE International Joint Conference on Neural Networks",
      "authors": "J. Schmidhuber"
    },
    {
      "index": 49,
      "title": "Dynamics-Aware Unsupervised Discovery of Skills",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Learning Representations",
      "authors": "Archit Sharma, Shixiang Gu, Sergey Levine, Vikash Kumar, and Karol Hausman",
      "orig_title": "Dynamics-aware unsupervised discovery of skills",
      "paper_id": "1907.01657v2"
    },
    {
      "index": 50,
      "title": "Deterministic policy gradient algorithms",
      "abstract": "",
      "year": "2014",
      "venue": "International Conference on Machine Learning",
      "authors": "David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and Martin Riedmiller"
    },
    {
      "index": 51,
      "title": "Identifying useful subgoals in reinforcement learning by local graph partitioning",
      "abstract": "",
      "year": "2005",
      "venue": "ICML",
      "authors": "Özgür Simsek, Alicia P. Wolfe, and Andrew G. Barto"
    },
    {
      "index": 52,
      "title": "Learning options in reinforcement learning",
      "abstract": "",
      "year": "2002",
      "venue": "SARA",
      "authors": "Martin Stolle and Doina Precup"
    },
    {
      "index": 53,
      "title": "Learning more skills through optimistic exploration",
      "abstract": "",
      "year": "2021",
      "venue": "CoRR",
      "authors": "DJ Strouse, Kate Baumli, David Warde-Farley, Vlad Mnih, and Steven Hansen"
    },
    {
      "index": 54,
      "title": "Policy gradient methods for reinforcement learning with function approximation",
      "abstract": "",
      "year": "1999",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Richard S Sutton, David McAllester, Satinder Singh, and Yishay Mansour"
    },
    {
      "index": 55,
      "title": "Reinforcement Learning: An Introduction",
      "abstract": "",
      "year": "1998",
      "venue": "MIT Press",
      "authors": "R.S. Sutton and A.G. Barto"
    },
    {
      "index": 56,
      "title": "Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning",
      "abstract": "",
      "year": "1999",
      "venue": "Artificial Intelligence",
      "authors": "R.S. Sutton, D. Precup, and S.P. Singh"
    },
    {
      "index": 57,
      "title": "Mujoco: A physics engine for model-based control",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems",
      "authors": "Emanuel Todorov, Tom Erez, and Yuval Tassa"
    },
    {
      "index": 58,
      "title": "Keeping Your Distance: Solving Sparse Reward Tasks Using Self-Balancing Shaped Rewards",
      "abstract": "",
      "year": "2019",
      "venue": "Curran Associates Inc.",
      "authors": "Alexander Trott, Stephan Zheng, Caiming Xiong, and Richard Socher"
    },
    {
      "index": 59,
      "title": "Unsupervised Control through Non-Parametric Discriminative Rewards",
      "abstract": "",
      "year": "2018",
      "venue": "CoRR",
      "authors": "David Warde-Farley, Tom Van de Wiele, Tejas D. Kulkarni, Catalin Ionescu, Steven Hansen, and Volodymyr Mnih",
      "orig_title": "Unsupervised control through non-parametric discriminative rewards",
      "paper_id": "1811.11359v1"
    },
    {
      "index": 60,
      "title": "Hierarchical Reinforcement Learning by Discovering Intrinsic Options",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Learning Representations",
      "authors": "Jesse Zhang, Haonan Yu, and Wei Xu",
      "orig_title": "Hierarchical reinforcement learning by discovering intrinsic options",
      "paper_id": "2101.06521v3"
    },
    {
      "index": 61,
      "title": "Maximum entropy inverse reinforcement learning",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": "Brian D. Ziebart, Andrew L. Maas, J. Andrew Bagnell, and Anind K. Dey"
    }
  ]
}