{
  "paper_id": "2205.07384v8",
  "title": "Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel",
  "abstract": "Abstract\nIt is challenging to guide neural network (NN) learning with prior knowledge. In contrast, many known properties, such as spatial smoothness or seasonality, are straightforward to model by choosing an appropriate kernel in a Gaussian process (GP). Many deep learning applications could be enhanced by modeling such known properties. For example, convolutional neural networks (CNNs) are frequently used in remote sensing, which is subject to strong seasonal effects. We propose to blend the strengths of deep learning and the clear modeling capabilities of GPs by using a composite kernel that combines a kernel implicitly defined by a neural network with a second kernel function chosen to model known properties (e.g., seasonality). We implement this idea by combining a deep network and an efficient mapping based on the Nyström approximation, which we call Implicit Composite Kernel (ICK). We then adopt a sample-then-optimize approach to approximate the full GP posterior distribution. We demonstrate that ICK has superior performance and flexibility on both synthetic and real-world data sets. The ICK framework can be used to include prior information into neural networks in many applications.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Deep neural network approach for predicting the productivity of garment employees",
      "abstract": "",
      "year": "2019",
      "venue": "6th International Conference on Control, Decision and Information Technologies (CoDIT)",
      "authors": "Abdullah Al Imran, Md Nur Amin, Md Rifatul Islam Rifat, and Shamprikta Mehreen"
    },
    {
      "index": 1,
      "title": "Pattern recognition and machine learning, volume 4",
      "abstract": "",
      "year": "2006",
      "venue": "Springer",
      "authors": "Christopher M Bishop and Nasser M Nasrabadi"
    },
    {
      "index": 2,
      "title": "Optimization Methods for Large-Scale Machine Learning",
      "abstract": "",
      "year": "2018",
      "venue": "Siam Review",
      "authors": "Léon Bottou, Frank E Curtis, and Jorge Nocedal",
      "orig_title": "Optimization methods for large-scale machine learning",
      "paper_id": "1606.04838v3"
    },
    {
      "index": 3,
      "title": "Gradient-enhanced kriging for high-dimensional problems",
      "abstract": "",
      "year": "2019",
      "venue": "Engineering with Computers",
      "authors": "Mohamed A Bouhlel and Joaquim RRA Martins",
      "orig_title": "Gradient-enhanced kriging for high-dimensional problems",
      "paper_id": "1708.02663v1"
    },
    {
      "index": 4,
      "title": "Improving kriging surrogates of high-dimensional design models by partial least squares dimension reduction",
      "abstract": "",
      "year": "2016",
      "venue": "Structural and Multidisciplinary Optimization",
      "authors": "Mohamed Amine Bouhlel, Nathalie Bartoli, Abdelkader Otsmane, and Joseph Morlier"
    },
    {
      "index": 5,
      "title": "Nonparametric binary regression using a gaussian process prior",
      "abstract": "",
      "year": "2007",
      "venue": "Statistical Methodology",
      "authors": "Nidhan Choudhuri, Subhashis Ghosal, and Anindya Roy"
    },
    {
      "index": 6,
      "title": "Hierarchical nearest-neighbor gaussian process models for large geostatistical datasets",
      "abstract": "",
      "year": "2016",
      "venue": "Journal of the American Statistical Association",
      "authors": "Abhirup Datta, Sudipto Banerjee, Andrew O Finley, and Alan E Gelfand"
    },
    {
      "index": 7,
      "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2010.11929",
      "authors": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al.",
      "orig_title": "An image is worth 16x16 words: Transformers for image recognition at scale",
      "paper_id": "2010.11929v2"
    },
    {
      "index": 8,
      "title": "On the nyström method for approximating a gram matrix for improved kernel-based learning",
      "abstract": "",
      "year": "2005",
      "venue": "journal of machine learning research",
      "authors": "Petros Drineas, Michael W Mahoney, and Nello Cristianini"
    },
    {
      "index": 9,
      "title": "Automatic model construction with Gaussian processes",
      "abstract": "",
      "year": "2014",
      "venue": "University of Cambridge",
      "authors": "David Duvenaud"
    },
    {
      "index": 10,
      "title": "Geometric data analysis, beyond convolutions",
      "abstract": "",
      "year": "2020",
      "venue": "Université Paris-Saclay Gif-sur-Yvette, France",
      "authors": "Jean Feydy"
    },
    {
      "index": 11,
      "title": "GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in neural information processing systems",
      "authors": "Jacob Gardner, Geoff Pleiss, Kilian Q Weinberger, David Bindel, and Andrew G Wilson",
      "orig_title": "Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration",
      "paper_id": "1809.11165v6"
    },
    {
      "index": 12,
      "title": "Neural Processes",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1807.01622",
      "authors": "Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J Rezende, SM Eslami, and Yee Whye Teh",
      "orig_title": "Neural processes",
      "paper_id": "1807.01622v1"
    },
    {
      "index": 13,
      "title": "Deep Convolutional Networks as shallow Gaussian Processes",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1808.05587",
      "authors": "Adrià Garriga-Alonso, Carl Edward Rasmussen, and Laurence Aitchison",
      "orig_title": "Deep convolutional networks as shallow gaussian processes",
      "paper_id": "1808.05587v2"
    },
    {
      "index": 14,
      "title": "Spatial statistics and gaussian processes: A beautiful marriage",
      "abstract": "",
      "year": "2016",
      "venue": "Spatial Statistics",
      "authors": "Alan E Gelfand and Erin M Schliep"
    },
    {
      "index": 15,
      "title": "Variational bayesian multinomial probit regression with gaussian process priors",
      "abstract": "",
      "year": "2006",
      "venue": "Neural Computation",
      "authors": "Mark Girolami and Simon Rogers"
    },
    {
      "index": 16,
      "title": "Deep Learning",
      "abstract": "",
      "year": "2016",
      "venue": "MIT press",
      "authors": "Ian Goodfellow, Yoshua Bengio, and Aaron Courville",
      "orig_title": "Deep learning",
      "paper_id": "1807.07987v2"
    },
    {
      "index": 17,
      "title": "Bayesian Deep Ensembles via the Neural Tangent Kernel",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in neural information processing systems",
      "authors": "Bobby He, Balaji Lakshminarayanan, and Yee Whye Teh",
      "orig_title": "Bayesian deep ensembles via the neural tangent kernel",
      "paper_id": "2007.05864v2"
    },
    {
      "index": 18,
      "title": "Masked autoencoders are scalable vision learners",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick"
    },
    {
      "index": 19,
      "title": "Gaussian processes for big data",
      "abstract": "",
      "year": "2013",
      "venue": "arXiv preprint arXiv:1309.6835",
      "authors": "James Hensman, Nicolo Fusi, and Neil D Lawrence"
    },
    {
      "index": 20,
      "title": "Neural Tangent Kernel: Convergence and Generalization in Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in neural information processing systems",
      "authors": "Arthur Jacot, Franck Gabriel, and Clément Hongler",
      "orig_title": "Neural tangent kernel: Convergence and generalization in neural networks",
      "paper_id": "1806.07572v4"
    },
    {
      "index": 21,
      "title": "Spatial Transformer Networks",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in neural information processing systems",
      "authors": "Max Jaderberg, Karen Simonyan, Andrew Zisserman, et al.",
      "orig_title": "Spatial transformer networks",
      "paper_id": "1506.02025v3"
    },
    {
      "index": 22,
      "title": "Improving spatial variation of ground-level pm2. 5 prediction with contrastive learning from satellite imagery",
      "abstract": "",
      "year": "2022",
      "venue": "Science of Remote Sensing",
      "authors": "Ziyang Jiang, Tongshu Zheng, Mike Bergin, and David Carlson"
    },
    {
      "index": 23,
      "title": "Mining geostatistics",
      "abstract": "",
      "year": "1976",
      "venue": "The Blackburn Press",
      "authors": "Andre G Journel and Charles J Huijbregts"
    },
    {
      "index": 24,
      "title": "Analyzing nonstationary spatial data using piecewise gaussian processes",
      "abstract": "",
      "year": "2005",
      "venue": "Journal of the American Statistical Association",
      "authors": "Hyoung-Moon Kim, Bani K Mallick, and Chris C Holmes"
    },
    {
      "index": 25,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1412.6980",
      "authors": "Diederik P Kingma and Jimmy Ba"
    },
    {
      "index": 26,
      "title": "A statistical approach to some basic mine valuation problems on the witwatersrand",
      "abstract": "",
      "year": "1951",
      "venue": "Journal of the Southern African Institute of Mining and Metallurgy",
      "authors": "Daniel G Krige"
    },
    {
      "index": 27,
      "title": "Artificial neural networks for solving ordinary and partial differential equations",
      "abstract": "",
      "year": "1998",
      "venue": "IEEE transactions on neural networks",
      "authors": "Isaac E Lagaris, Aristidis Likas, and Dimitrios I Fotiadis"
    },
    {
      "index": 28,
      "title": "Deep Learning",
      "abstract": "",
      "year": "2015",
      "venue": "nature",
      "authors": "Yann LeCun, Yoshua Bengio, and Geoffrey Hinton",
      "orig_title": "Deep learning",
      "paper_id": "1807.07987v2"
    },
    {
      "index": 29,
      "title": "Deep Neural Networks as Gaussian Processes",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1711.00165",
      "authors": "Jaehoon Lee, Yasaman Bahri, Roman Novak, Samuel S Schoenholz, Jeffrey Pennington, and Jascha Sohl-Dickstein",
      "orig_title": "Deep neural networks as gaussian processes",
      "paper_id": "1711.00165v3"
    },
    {
      "index": 30,
      "title": "Wide neural networks of any depth evolve as linear models under gradient descent",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in neural information processing systems",
      "authors": "Jaehoon Lee, Lechao Xiao, Samuel Schoenholz, Yasaman Bahri, Roman Novak, Jascha Sohl-Dickstein, and Jeffrey Pennington"
    },
    {
      "index": 31,
      "title": "The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1611.00712",
      "authors": "Chris J Maddison, Andriy Mnih, and Yee Whye Teh",
      "orig_title": "The concrete distribution: A continuous relaxation of discrete random variables",
      "paper_id": "1611.00712v3"
    },
    {
      "index": 32,
      "title": "Deep learning: A critical appraisal",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1801.00631",
      "authors": "Gary Marcus"
    },
    {
      "index": 33,
      "title": "The Ridgelet Prior: A Covariance Function Approach to Prior Specification for Bayesian Neural Networks",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2010.08488",
      "authors": "Takuo Matsubara, Chris J Oates, and François-Xavier Briol",
      "orig_title": "The ridgelet prior: A covariance function approach to prior specification for bayesian neural networks",
      "paper_id": "2010.08488v4"
    },
    {
      "index": 34,
      "title": "Sample-then-optimize posterior sampling for bayesian linear models",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS Workshop on Advances in Approximate Bayesian Inference",
      "authors": "Alexander G de G Matthews, Jiri Hron, Richard E Turner, and Zoubin Ghahramani"
    },
    {
      "index": 35,
      "title": "Gaussian Process Behaviour in Wide Deep Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1804.11271",
      "authors": "Alexander G de G Matthews, Mark Rowland, Jiri Hron, Richard E Turner, and Zoubin Ghahramani",
      "orig_title": "Gaussian process behaviour in wide deep neural networks",
      "paper_id": "1804.11271v2"
    },
    {
      "index": 36,
      "title": "Learning multi-modal similarity",
      "abstract": "",
      "year": "2011",
      "venue": "Journal of machine learning research",
      "authors": "Brian McFee, Gert Lanckriet, and Tony Jebara"
    },
    {
      "index": 37,
      "title": "Solving the wave equation with physics-informed deep learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2006.11894",
      "authors": "Ben Moseley, Andrew Markham, and Tarje Nissen-Meyer"
    },
    {
      "index": 38,
      "title": "Priors for infinite networks",
      "abstract": "",
      "year": "1996",
      "venue": "Bayesian Learning for Neural Networks",
      "authors": "Radford M Neal"
    },
    {
      "index": 39,
      "title": "Neural Tangents: Fast and Easy Infinite Neural Networks in Python",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Learning Representations",
      "authors": "Roman Novak, Lechao Xiao, Jiri Hron, Jaehoon Lee, Alexander A. Alemi, Jascha Sohl-Dickstein, and Samuel S. Schoenholz",
      "orig_title": "Neural tangents: Fast and easy infinite neural networks in python",
      "paper_id": "1912.02803v1"
    },
    {
      "index": 40,
      "title": "Expressive Priors in Bayesian Neural Networks: Kernel Combinations and Periodic Functions",
      "abstract": "",
      "year": "2020",
      "venue": "Uncertainty in artificial intelligence",
      "authors": "Tim Pearce, Russell Tsuchida, Mohamed Zaki, Alexandra Brintrup, and Andy Neely",
      "orig_title": "Expressive priors in bayesian neural networks: Kernel combinations and periodic functions",
      "paper_id": "1905.06076v2"
    },
    {
      "index": 41,
      "title": "Evolving gaussian process models for prediction of ozone concentration in the air",
      "abstract": "",
      "year": "2013",
      "venue": "Simulation modelling practice and theory",
      "authors": "Dejan Petelin, Alexandra Grancharova, and Juš Kocijan"
    },
    {
      "index": 42,
      "title": "Random features for large-scale kernel machines",
      "abstract": "",
      "year": "2007",
      "venue": "Advances in neural information processing systems",
      "authors": "Ali Rahimi and Benjamin Recht"
    },
    {
      "index": 43,
      "title": "Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning",
      "abstract": "",
      "year": "2008",
      "venue": "Advances in neural information processing systems",
      "authors": "Ali Rahimi and Benjamin Recht"
    },
    {
      "index": 44,
      "title": "Unsupervised learning with random forest predictors",
      "abstract": "",
      "year": "2006",
      "venue": "Journal of Computational and Graphical Statistics",
      "authors": "Tao Shi and Steve Horvath"
    },
    {
      "index": 45,
      "title": "Sparse gaussian processes using pseudo-inputs",
      "abstract": "",
      "year": "2005",
      "venue": "Advances in neural information processing systems",
      "authors": "Edward Snelson and Zoubin Ghahramani"
    },
    {
      "index": 46,
      "title": "Convolutional Gaussian Processes",
      "abstract": "",
      "year": "2017",
      "venue": "Neural Information Processing Systems",
      "authors": "Mark Van der Wilk, Carl Edward Rasmussen, and James Hensman",
      "orig_title": "Convolutional gaussian processes",
      "paper_id": "1709.01894v1"
    },
    {
      "index": 47,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 48,
      "title": "Continuously Indexed Domain Adaptation",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "Hao Wang, Hao He, and Dina Katabi",
      "orig_title": "Continuously indexed domain adaptation",
      "paper_id": "2007.01807v2"
    },
    {
      "index": 49,
      "title": "Exact Gaussian Processes on a Million Data Points",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in neural information processing systems",
      "authors": "Ke Wang, Geoff Pleiss, Jacob Gardner, Stephen Tyree, Kilian Q Weinberger, and Andrew Gordon Wilson",
      "orig_title": "Exact gaussian processes on a million data points",
      "paper_id": "1903.08114v2"
    },
    {
      "index": 50,
      "title": "Using the nyström method to speed up kernel machines",
      "abstract": "",
      "year": "2000",
      "venue": "Advances in neural information processing systems",
      "authors": "Christopher Williams and Matthias Seeger"
    },
    {
      "index": 51,
      "title": "Gaussian processes for machine learning, volume 2",
      "abstract": "",
      "year": "2006",
      "venue": "MIT press Cambridge, MA",
      "authors": "Christopher K Williams and Carl Edward Rasmussen"
    },
    {
      "index": 52,
      "title": "Bayesian classification with gaussian processes",
      "abstract": "",
      "year": "1998",
      "venue": "IEEE Transactions on pattern analysis and machine intelligence",
      "authors": "Christopher KI Williams and David Barber"
    },
    {
      "index": 53,
      "title": "Gaussian process kernels for pattern discovery and extrapolation",
      "abstract": "",
      "year": "2013",
      "venue": "International conference on machine learning",
      "authors": "Andrew Wilson and Ryan Adams"
    },
    {
      "index": 54,
      "title": "Deep Kernel Learning",
      "abstract": "",
      "year": "2016",
      "venue": "Artificial intelligence and statistics",
      "authors": "Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P Xing",
      "orig_title": "Deep kernel learning",
      "paper_id": "1511.02222v1"
    },
    {
      "index": 55,
      "title": "Gaussian process regression networks",
      "abstract": "",
      "year": "2011",
      "venue": "arXiv preprint arXiv:1110.4411",
      "authors": "Andrew Gordon Wilson, David A Knowles, and Zoubin Ghahramani"
    },
    {
      "index": 56,
      "title": "Nyström method vs random fourier features: A theoretical and empirical comparison",
      "abstract": "",
      "year": "2012",
      "venue": "Advances in neural information processing systems",
      "authors": "Tianbao Yang, Yu-Feng Li, Mehrdad Mahdavi, Rong Jin, and Zhi-Hua Zhou"
    },
    {
      "index": 57,
      "title": "Multimodal classification of alzheimer’s disease and mild cognitive impairment",
      "abstract": "",
      "year": "2011",
      "venue": "Neuroimage",
      "authors": "Daoqiang Zhang, Yaping Wang, Luping Zhou, Hong Yuan, Dinggang Shen, Alzheimer’s Disease Neuroimaging Initiative, et al."
    },
    {
      "index": 58,
      "title": "Local pm2. 5 hotspot detector at 300 m resolution: A random forest–convolutional neural network joint model jointly trained on satellite images and meteorology",
      "abstract": "",
      "year": "2021",
      "venue": "Remote Sensing",
      "authors": "Tongshu Zheng, Michael Bergin, Guoyin Wang, and David Carlson"
    },
    {
      "index": 59,
      "title": "Estimating ground-level pm2. 5 using micro-satellite images by a convolutional neural network and random forest approach",
      "abstract": "",
      "year": "2020",
      "venue": "Atmospheric Environment",
      "authors": "Tongshu Zheng, Michael H Bergin, Shijia Hu, Joshua Miller, and David E Carlson"
    },
    {
      "index": 60,
      "title": "Deepvit: Towards deeper vision transformer",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2103.11886",
      "authors": "Daquan Zhou, Bingyi Kang, Xiaojie Jin, Linjie Yang, Xiaochen Lian, Zihang Jiang, Qibin Hou, and Jiashi Feng"
    }
  ]
}