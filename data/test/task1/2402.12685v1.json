{
  "paper_id": "2402.12685v1",
  "title": "XRL-Bench: A Benchmark for Evaluating and Comparing Explainable Reinforcement Learning Techniques",
  "abstract": "Abstract.\nReinforcement Learning (RL) has demonstrated substantial potential across diverse fields, yet understanding its decision-making process, especially in real-world scenarios where rationality and safety are paramount, is an ongoing challenge. This paper delves in to Explainable RL (XRL), a subfield of Explainable AI (XAI) aimed at unravelling the complexities of RL models. Our focus rests on state-explaining techniques, a crucial subset within XRL methods, as they reveal the underlying factors influencing an agent’s actions at any given time. Despite their significant role, the lack of a unified evaluation framework hinders assessment of their accuracy and effectiveness. To address this, we introduce XRL-Bench111https://github.com/fuxiAIlab/xrl-bench, a unified standardized benchmark tailored for the evaluation and comparison of XRL methods, encompassing three main modules: standard RL environments, explainers based on state importance, and standard evaluators. XRL-Bench supports both tabular and image data for state explanation. We also propose TabularSHAP, an innovative and competitive XRL method. We demonstrate the practical utility of TabularSHAP in real-world online gaming services and offer an open-source benchmark platform for the straightforward implementation and evaluation of XRL methods. Our contributions facilitate the continued progression of XRL technology.",
  "reference_labels": [
    {
      "index": 0,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 1,
      "title": "Openxai: Towards a transparent evaluation of model explanations",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Chirag Agarwal, Satyapriya Krishna, Eshika Saxena, Martin Pawelczyk, Nari Johnson, Isha Puri, Marinka Zitnik, and Himabindu Lakkaraju"
    },
    {
      "index": 2,
      "title": "On the robustness of interpretability methods",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1806.08049",
      "authors": "David Alvarez-Melis and Tommi S Jaakkola"
    },
    {
      "index": 3,
      "title": "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation",
      "abstract": "",
      "year": "2015",
      "venue": "PloS one",
      "authors": "Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech Samek"
    },
    {
      "index": 4,
      "title": "Recent advances in hierarchical reinforcement learning",
      "abstract": "",
      "year": "2003",
      "venue": "Discrete event dynamic systems",
      "authors": "Andrew G Barto and Sridhar Mahadevan"
    },
    {
      "index": 5,
      "title": "Verifiable Reinforcement Learning via Policy Extraction",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in neural information processing systems",
      "authors": "Osbert Bastani, Yewen Pu, and Armando Solar-Lezama",
      "orig_title": "Verifiable reinforcement learning via policy extraction",
      "paper_id": "1805.08328v2"
    },
    {
      "index": 6,
      "title": "Learning to Explain: An Information-Theoretic Perspective on Model Interpretation",
      "abstract": "",
      "year": "2018",
      "venue": "International conference on machine learning",
      "authors": "Jianbo Chen, Le Song, Martin Wainwright, and Michael Jordan",
      "orig_title": "Learning to explain: An information-theoretic perspective on model interpretation",
      "paper_id": "1802.07814v2"
    },
    {
      "index": 7,
      "title": "Fairness via Explanation Quality: Evaluating Disparities in the Quality of Post hoc Explanations",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI/ACM Conference on AI, Ethics, and Society",
      "authors": "Jessica Dai, Sohini Upadhyay, Ulrich Aivodji, Stephen H Bach, and Himabindu Lakkaraju",
      "orig_title": "Fairness via explanation quality: Evaluating disparities in the quality of post hoc explanations",
      "paper_id": "2205.07277v2"
    },
    {
      "index": 8,
      "title": "Techniques for Interpretable Machine Learning",
      "abstract": "",
      "year": "2019",
      "venue": "Commun. ACM",
      "authors": "Mengnan Du, Ninghao Liu, and Xia Hu",
      "orig_title": "Techniques for interpretable machine learning",
      "paper_id": "1808.00033v3"
    },
    {
      "index": 9,
      "title": "Automated Rationale Generation: A Technique for Explainable AI and its Effects on Human Perceptions",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Intelligent User Interfaces",
      "authors": "Upol Ehsan, Pradyumna Tambwekar, Larry Chan, Brent Harrison, and Mark O Riedl",
      "orig_title": "Automated rationale generation: a technique for explainable AI and its effects on human perceptions",
      "paper_id": "1901.03729v1"
    },
    {
      "index": 10,
      "title": "Learning explainable models using attribution priors",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Gabriel Erion, Joseph D Janizek, Pascal Sturmfels, Scott M Lundberg, and Su-In Lee"
    },
    {
      "index": 11,
      "title": "Counterfactual Multi-Agent Policy Gradients",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "Jakob Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, and Shimon Whiteson",
      "orig_title": "Counterfactual multi-agent policy gradients",
      "paper_id": "1705.08926v3"
    },
    {
      "index": 12,
      "title": "Autonomous Self-Explanation of Behavior for Interactive Reinforcement Learning Agents",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Human Agent Interaction",
      "authors": "Yosuke Fukuchi, Masahiko Osawa, Hiroshi Yamakawa, and Michita Imai",
      "orig_title": "Autonomous self-explanation of behavior for interactive reinforcement learning agents",
      "paper_id": "1810.08811v1"
    },
    {
      "index": 13,
      "title": "How should I explain? A comparison of different explanation types for recommender systems",
      "abstract": "",
      "year": "2014",
      "venue": "International Journal of Human-Computer Studies",
      "authors": "Fatih Gedikli, Dietmar Jannach, and Mouzhi Ge"
    },
    {
      "index": 14,
      "title": "Interpretation of Neural Networks is Fragile",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "Amirata Ghorbani, Abubakar Abid, and James Zou",
      "orig_title": "Interpretation of neural networks is fragile",
      "paper_id": "1710.10547v2"
    },
    {
      "index": 15,
      "title": "Visualizing and Understanding Atari Agents",
      "abstract": "",
      "year": "2018",
      "venue": "International conference on machine learning",
      "authors": "Samuel Greydanus, Anurag Koul, Jonathan Dodge, and Alan Fern",
      "orig_title": "Visualizing and understanding atari agents",
      "paper_id": "1711.00138v5"
    },
    {
      "index": 16,
      "title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE international conference on computer vision",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun"
    },
    {
      "index": 17,
      "title": "Interpretable Policies for Reinforcement Learning by Genetic Programming",
      "abstract": "",
      "year": "2018",
      "venue": "Engineering Applications of Artificial Intelligence",
      "authors": "Daniel Hein, Steffen Udluft, and Thomas A Runkler",
      "orig_title": "Interpretable policies for reinforcement learning by genetic programming",
      "paper_id": "1712.04170v2"
    },
    {
      "index": 18,
      "title": "The promise and peril of human evaluation for model interpretability",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1711.07414",
      "authors": "Bernease Herman"
    },
    {
      "index": 19,
      "title": "Transparency and Explanation in Deep Reinforcement Learning Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI/ACM Conference on AI, Ethics, and Society",
      "authors": "Rahul Iyer, Yuezhang Li, Huao Li, Michael Lewis, Ramitha Sundar, and Katia Sycara",
      "orig_title": "Transparency and explanation in deep reinforcement learning neural networks",
      "paper_id": "1809.06061v1"
    },
    {
      "index": 20,
      "title": "Language as an abstraction for hierarchical deep reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Yiding Jiang, Shixiang Shane Gu, Kevin P Murphy, and Chelsea Finn"
    },
    {
      "index": 21,
      "title": "Neural Logic Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "International conference on machine learning",
      "authors": "Zhengyao Jiang and Shan Luo",
      "orig_title": "Neural logic reinforcement learning",
      "paper_id": "1904.10729v2"
    },
    {
      "index": 22,
      "title": "Creativity of ai: Automatic symbolic option discovery for facilitating deep reinforcement learning",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Mu Jin, Zhihao Ma, Kebing Jin, Hankz Hankui Zhuo, Chen Chen, and Chao Yu"
    },
    {
      "index": 23,
      "title": "Explainable reinforcement learning via reward decomposition",
      "abstract": "",
      "year": "2019",
      "venue": "IJCAI/ECAI Workshop on explainable artificial intelligence",
      "authors": "Zoe Juozapaitis, Anurag Koul, Alan Fern, Martin Erwig, and Finale Doshi-Velez"
    },
    {
      "index": 24,
      "title": "Lightgbm: A highly efficient gradient boosting decision tree",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu"
    },
    {
      "index": 25,
      "title": "Actor-critic algorithms",
      "abstract": "",
      "year": "1999",
      "venue": "Advances in neural information processing systems",
      "authors": "Vijay Konda and John Tsitsiklis"
    },
    {
      "index": 26,
      "title": "Human evaluation of models built for interpretability",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI Conference on Human Computation and Crowdsourcing",
      "authors": "Isaac Lage, Emily Chen, Jeffrey He, Menaka Narayanan, Been Kim, Samuel J Gershman, and Finale Doshi-Velez"
    },
    {
      "index": 27,
      "title": "Social Attention for Autonomous Decision-Making in Dense Traffic",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1911.12250",
      "authors": "Edouard Leurent and Jean Mercat",
      "orig_title": "Social attention for autonomous decision-making in dense traffic",
      "paper_id": "1911.12250v1"
    },
    {
      "index": 28,
      "title": "Toward Interpretable Deep Reinforcement Learning with Linear Model U-Trees",
      "abstract": "",
      "year": "2018",
      "venue": "Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD",
      "authors": "Guiliang Liu, Oliver Schulte, Wang Zhu, and Qingcan Li",
      "orig_title": "Toward interpretable deep reinforcement learning with linear model u-trees",
      "paper_id": "1807.05887v1"
    },
    {
      "index": 29,
      "title": "Synthetic Benchmarks for Scientific Research in Explainable Machine Learning",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2106.12543",
      "authors": "Yang Liu, Sujay Khandagale, Colin White, and Willie Neiswanger",
      "orig_title": "Synthetic benchmarks for scientific research in explainable machine learning",
      "paper_id": "2106.12543v4"
    },
    {
      "index": 30,
      "title": "Consistent Individualized Feature Attribution for Tree Ensembles",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1802.03888",
      "authors": "Scott M Lundberg, Gabriel G Erion, and Su-In Lee",
      "orig_title": "Consistent individualized feature attribution for tree ensembles",
      "paper_id": "1802.03888v3"
    },
    {
      "index": 31,
      "title": "A Unified Approach to Interpreting Model Predictions",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "Scott M Lundberg and Su-In Lee",
      "orig_title": "A unified approach to interpreting model predictions",
      "paper_id": "1705.07874v2"
    },
    {
      "index": 32,
      "title": "SDRL: Interpretable and Data-efficient Deep Reinforcement Learning Leveraging Symbolic Planning",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Daoming Lyu, Fangkai Yang, Bo Liu, and Steven Gustafson",
      "orig_title": "SDRL: interpretable and data-efficient deep reinforcement learning leveraging symbolic planning",
      "paper_id": "1811.00090v4"
    },
    {
      "index": 33,
      "title": "Explainable reinforcement learning through a causal lens",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "Prashan Madumal, Tim Miller, Liz Sonenberg, and Frank Vetere"
    },
    {
      "index": 34,
      "title": "A Survey of Explainable Reinforcement Learning",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2202.08434",
      "authors": "Stephanie Milani, Nicholay Topin, Manuela Veloso, and Fei Fang",
      "orig_title": "A survey of explainable reinforcement learning",
      "paper_id": "2202.08434v1"
    },
    {
      "index": 35,
      "title": "ELLA: Exploration through Learned Language Abstraction",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Suvir Mirchandani, Siddharth Karamcheti, and Dorsa Sadigh",
      "orig_title": "Ella: Exploration through learned language abstraction",
      "paper_id": "2103.05825v2"
    },
    {
      "index": 36,
      "title": "Playing atari with deep reinforcement learning",
      "abstract": "",
      "year": "2013",
      "venue": "arXiv preprint arXiv:1312.5602",
      "authors": "Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller"
    },
    {
      "index": 37,
      "title": "A Multidisciplinary Survey and Framework for Design and Evaluation of Explainable AI Systems",
      "abstract": "",
      "year": "2021",
      "venue": "ACM Transactions on Interactive Intelligent Systems (TiiS)",
      "authors": "Sina Mohseni, Niloofar Zarei, and Eric D Ragan",
      "orig_title": "A multidisciplinary survey and framework for design and evaluation of explainable AI systems",
      "paper_id": "1811.11839v5"
    },
    {
      "index": 38,
      "title": "A Boolean Task Algebra For Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Geraud Nangue Tasse, Steven James, and Benjamin Rosman",
      "orig_title": "A boolean task algebra for reinforcement learning",
      "paper_id": "2001.01394v2"
    },
    {
      "index": 39,
      "title": "A review on reinforcement learning: Introduction and applications in industrial process control",
      "abstract": "",
      "year": "2020",
      "venue": "Computers & Chemical Engineering",
      "authors": "Rui Nian, Jinfeng Liu, and Biao Huang"
    },
    {
      "index": 40,
      "title": "Counterfactual State Explanations for Reinforcement Learning Agents via Generative Deep Learning",
      "abstract": "",
      "year": "2021",
      "venue": "Artificial Intelligence",
      "authors": "Matthew L Olson, Roli Khanna, Lawrence Neal, Fuxin Li, and Weng-Keen Wong",
      "orig_title": "Counterfactual state explanations for reinforcement learning agents via generative deep learning",
      "paper_id": "2101.12446v1"
    },
    {
      "index": 41,
      "title": "Incorporating Relational Background Knowledge into Reinforcement Learning via Differentiable Inductive Logic Programming",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2003.10386",
      "authors": "Ali Payani and Faramarz Fekri",
      "orig_title": "Incorporating relational background knowledge into reinforcement learning via differentiable inductive logic programming",
      "paper_id": "2003.10386v1"
    },
    {
      "index": 42,
      "title": "RISE: Randomized Input Sampling for Explanation of Black-box Models",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1806.07421",
      "authors": "Vitali Petsiuk, Abir Das, and Kate Saenko",
      "orig_title": "Rise: Randomized input sampling for explanation of black-box models",
      "paper_id": "1806.07421v3"
    },
    {
      "index": 43,
      "title": "Model Agnostic Supervised Local Explanations",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in neural information processing systems",
      "authors": "Gregory Plumb, Denali Molitor, and Ameet S Talwalkar",
      "orig_title": "Model agnostic supervised local explanations",
      "paper_id": "1807.02910v3"
    },
    {
      "index": 44,
      "title": "Explainable Reinforcement Learning: A Survey",
      "abstract": "",
      "year": "2020",
      "venue": "International cross-domain conference for machine learning and knowledge extraction",
      "authors": "Erika Puiutta and Eric MSP Veith",
      "orig_title": "Explainable reinforcement learning: A survey",
      "paper_id": "2005.06247v1"
    },
    {
      "index": 45,
      "title": "Explain your move: Understanding agent actions using specific and relevant feature attribution",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1912.12191",
      "authors": "Nikaash Puri, Sukriti Verma, Piyush Gupta, Dhruv Kayastha, Shripad Deshmukh, Balaji Krishnamurthy, and Sameer Singh"
    },
    {
      "index": 46,
      "title": "“Why Should I Trust You?” Explaining the Predictions of Any Classifier",
      "abstract": "",
      "year": "2016",
      "venue": "ACM SIGKDD international conference on knowledge discovery and data mining",
      "authors": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin",
      "orig_title": "Why should i trust you? Explaining the predictions of any classifier",
      "paper_id": "1602.04938v3"
    },
    {
      "index": 47,
      "title": "Anchors: High-precision model-agnostic explanations",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin"
    },
    {
      "index": 48,
      "title": "Learning important features through propagating activation differences",
      "abstract": "",
      "year": "2017",
      "venue": "International conference on machine learning",
      "authors": "Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje"
    },
    {
      "index": 49,
      "title": "Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1712.07294",
      "authors": "Tianmin Shu, Caiming Xiong, and Richard Socher",
      "orig_title": "Hierarchical and interpretable skill acquisition in multi-task reinforcement learning",
      "paper_id": "1712.07294v1"
    },
    {
      "index": 50,
      "title": "Multi-task reinforcement learning with context-based representations",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Machine Learning",
      "authors": "Shagun Sodhani, Amy Zhang, and Joelle Pineau"
    },
    {
      "index": 51,
      "title": "Axiomatic attribution for deep networks",
      "abstract": "",
      "year": "2017",
      "venue": "International conference on machine learning",
      "authors": "Mukund Sundararajan, Ankur Taly, and Qiqi Yan"
    },
    {
      "index": 52,
      "title": "The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Yujin Tang and David Ha",
      "orig_title": "The sensory neuron as a transformer: Permutation-invariant neural networks for reinforcement learning",
      "paper_id": "2109.02869v2"
    },
    {
      "index": 53,
      "title": "Explainable Artificial Intelligence: a Systematic Review",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2006.00093",
      "authors": "Giulia Vilone and Luca Longo",
      "orig_title": "Explainable artificial intelligence: a systematic review",
      "paper_id": "2006.00093v4"
    },
    {
      "index": 54,
      "title": "Explainable Deep Reinforcement Learning: State of the Art and Challenges",
      "abstract": "",
      "year": "2022",
      "venue": "Comput. Surveys",
      "authors": "George A Vouros",
      "orig_title": "Explainable deep reinforcement learning: state of the art and challenges",
      "paper_id": "2301.09937v1"
    },
    {
      "index": 55,
      "title": "Shapley Q-value: A Local Reward Approach to Solve Global Reward Games",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Jianhong Wang, Yuan Zhang, Tae-Kyun Kim, and Yunjie Gu",
      "orig_title": "Shapley Q-value: A local reward approach to solve global reward games",
      "paper_id": "1907.05707v6"
    },
    {
      "index": 56,
      "title": "Artificial general intelligence and the human mental model",
      "abstract": "",
      "year": "2013",
      "venue": "Singularity hypotheses: A scientific and philosophical assessment",
      "authors": "Roman V Yampolskiy and Joshua Fox"
    },
    {
      "index": 57,
      "title": "Mastering Complex Control in MOBA Games with Deep Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Deheng Ye, Zhao Liu, Mingfei Sun, Bei Shi, Peilin Zhao, Hao Wu, Hongsheng Yu, Shaojie Yang, Xipeng Wu, Qingwei Guo, Qiaobo Chen, Yinyuting Yin, Hao Zhang, Tengfei Shi, Liang Wang, Qiang Fu, Wei Yang, and Lanxiao Huang",
      "orig_title": "Mastering complex control in moba games with deep reinforcement learning",
      "paper_id": "1912.09729v3"
    },
    {
      "index": 58,
      "title": "Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE symposium series on computational intelligence (SSCI)",
      "authors": "Wenshuai Zhao, Jorge Peña Queralta, and Tomi Westerlund",
      "orig_title": "Sim-to-real transfer in deep reinforcement learning for robotics: a survey",
      "paper_id": "2009.13303v2"
    },
    {
      "index": 59,
      "title": "Evaluating the quality of machine learning explanations: A survey on methods and metrics",
      "abstract": "",
      "year": "2021",
      "venue": "Electronics",
      "authors": "Jianlong Zhou, Amir H Gandomi, Fang Chen, and Andreas Holzinger"
    }
  ]
}