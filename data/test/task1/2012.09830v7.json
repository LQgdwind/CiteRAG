{
  "paper_id": "2012.09830v7",
  "title": "Autotelic Agents with Intrinsically Motivated Goal-Conditioned Reinforcement Learning: A Short Survey",
  "abstract": "Abstract\nBuilding autonomous machines that can explore open-ended environments, discover possible interactions and build repertoires of skills is a general objective of artificial intelligence. Developmental approaches argue that this can only be achieved by autotelic agents: intrinsically motivated learning agents that can learn to represent, generate, select and solve their own problems.\nIn recent years, the convergence of developmental approaches with deep reinforcement learning (rl) methods has been leading to the emergence of a new field: developmental reinforcement learning.\nDevelopmental rl is concerned with the use of deep rl algorithms to tackle a developmental problem — the intrinsically motivated acquisition of open-ended repertoires of skills.\nThe self-generation of goals requires the learning of compact goal encodings as well as their associated goal-achievement functions. This raises new challenges compared to standard rl algorithms originally designed to tackle pre-defined sets of goals using external reward signals.\nThe present paper introduces developmental rl and proposes a computational framework based on goal-conditioned rl to tackle the intrinsically motivated skills acquisition problem. It proceeds to present a typology of the various goal representations used in the literature, before reviewing existing methods to learn to represent and prioritize goals in autonomous systems. We finally close the paper by discussing some open challenges in the quest of intrinsically motivated skills acquisition.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Imitating Interactive Intelligence.",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Abramson, J., Ahuja, A., Brussee, A., Carnevale, F., Cassin, M., Clark, S., Dudzik, A., Georgiev, P., Guy, A., Harley, T., Hill, F., Hung, A., Kenton, Z., Landon, J., Lillicrap, T., Mathewson, K., Muldal, A., Santoro, A., Savinov, N., Varma, V., Wayne, G., Wong, N., Yan, C., and Zhu, R."
    },
    {
      "index": 1,
      "title": "Variational Option Discovery Algorithms",
      "abstract": "",
      "year": "2018",
      "venue": "ArXiv - abs/1807.10299",
      "authors": "Achiam, J., Edwards, H., Amodei, D., and Abbeel, P.",
      "orig_title": "Variational option discovery algorithms.",
      "paper_id": "1807.10299v1"
    },
    {
      "index": 2,
      "title": "Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "ArXiv - abs/1703.01732",
      "authors": "Achiam, J., and Sastry, S.",
      "orig_title": "Surprise-based intrinsic motivation for deep reinforcement learning.",
      "paper_id": "1703.01732v1"
    },
    {
      "index": 3,
      "title": "DECSTR: Learning goal-directed abstract behaviors using pre-verbal spatial predicates in intrinsically motivated agents.",
      "abstract": "",
      "year": "2021",
      "venue": "ICLR",
      "authors": "Akakzia, A., Colas, C., Oudeyer, P.-Y., Chetouani, M., and Sigaud, O."
    },
    {
      "index": 4,
      "title": "Neural module networks.",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016",
      "authors": "Andreas, J., Rohrbach, M., Darrell, T., and Klein, D."
    },
    {
      "index": 5,
      "title": "Hindsight experience replay.",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "Andrychowicz, M., Crow, D., Ray, A., Schneider, J., Fong, R., Welinder, P., McGrew, B., Tobin, J., Abbeel, P., and Zaremba, W."
    },
    {
      "index": 6,
      "title": "Cognitive developmental robotics: A survey.",
      "abstract": "",
      "year": "2009",
      "venue": "IEEE transactions on autonomous mental development",
      "authors": "Asada, M., Hosoda, K., Kuniyoshi, Y., Ishiguro, H., Inui, T., Yoshikawa, Y., Ogino, M., and Yoshida, C."
    },
    {
      "index": 7,
      "title": "The Option-Critic Architecture",
      "abstract": "",
      "year": "2017",
      "venue": "AAAI",
      "authors": "Bacon, P., Harb, J., and Precup, D.",
      "orig_title": "The option-critic architecture.",
      "paper_id": "1609.05140v2"
    },
    {
      "index": 8,
      "title": "Agent57: Outperforming the Atari Human Benchmark",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Badia, A. P., Piot, B., Kapturowski, S., Sprechmann, P., Vitvitskyi, A., Guo, Z. D., and Blundell, C.",
      "orig_title": "Agent57: Outperforming the atari human benchmark.",
      "paper_id": "2003.13350v1"
    },
    {
      "index": 9,
      "title": "Never Give Up: Learning Directed Exploration Strategies",
      "abstract": "",
      "year": "2020",
      "venue": "ICLR",
      "authors": "Badia, A. P., Sprechmann, P., Vitvitskyi, A., Guo, D., Piot, B., Kapturowski, S., Tieleman, O., Arjovsky, M., Pritzel, A., Bolt, A., and Blundell, C.",
      "orig_title": "Never give up: Learning directed exploration strategies.",
      "paper_id": "2002.06038v1"
    },
    {
      "index": 10,
      "title": "Learning to Understand Goal Specifications by Modelling Reward",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "Bahdanau, D., Hill, F., Leike, J., Hughes, E., Hosseini, S. A., Kohli, P., and Grefenstette, E.",
      "orig_title": "Learning to understand goal specifications by modelling reward.",
      "paper_id": "1806.01946v4"
    },
    {
      "index": 11,
      "title": "Systematic Generalization: What Is Required and Can It Be Learned?",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "Bahdanau, D., Murty, S., Noukhovitch, M., Nguyen, T. H., de Vries, H., and Courville, A. C.",
      "orig_title": "Systematic generalization: What is required and can it be learned?.",
      "paper_id": "1811.12889v3"
    },
    {
      "index": 12,
      "title": "Proximo-distal competence based curiosity-driven exploration.",
      "abstract": "",
      "year": "2009",
      "venue": "International Conference on Epigenetic Robotics",
      "authors": "Baranes, A., and Oudeyer, P.-Y."
    },
    {
      "index": 13,
      "title": "R-iac: Robust intrinsically motivated exploration and active learning.",
      "abstract": "",
      "year": "2009",
      "venue": "IEEE Transactions on Autonomous Mental Development",
      "authors": "Baranes, A., and Oudeyer, P.-Y."
    },
    {
      "index": 14,
      "title": "Intrinsically motivated goal exploration for active motor learning in robots: A case study.",
      "abstract": "",
      "year": "2010",
      "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems",
      "authors": "Baranes, A., and Oudeyer, P.-Y."
    },
    {
      "index": 15,
      "title": "Active learning of inverse models with intrinsically motivated goal exploration in robots.",
      "abstract": "",
      "year": "2013",
      "venue": "Robotics and Autonomous Systems",
      "authors": "Baranes, A., and Oudeyer, P.-Y."
    },
    {
      "index": 16,
      "title": "The option keyboard: Combining skills in reinforcement learning.",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Barreto, A., Borsa, D., Hou, S., Comanici, G., Aygün, E., Hamel, P., Toyama, D., hunt, J., Mourad, S., Silver, D., and Precup, D."
    },
    {
      "index": 17,
      "title": "Successor features for transfer in reinforcement learning.",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "Barreto, A., Dabney, W., Munos, R., Hunt, J. J., Schaul, T., Silver, D., and van Hasselt, H."
    },
    {
      "index": 18,
      "title": "Fast reinforcement learning with generalized policy updates.",
      "abstract": "",
      "year": "2020",
      "venue": "National Academy of Sciences",
      "authors": "Barreto, A., Hou, S., Borsa, D., Silver, D., and Precup, D."
    },
    {
      "index": 19,
      "title": "Autonomous navigation of stratospheric balloons using reinforcement learning.",
      "abstract": "",
      "year": "2020",
      "venue": "Nature",
      "authors": "Bellemare, M. G., Candido, S., Castro, P. S., Gong, J., Machado, M. C., Moitra, S., Ponda, S. S., and Wang, Z."
    },
    {
      "index": 20,
      "title": "Unifying count-based exploration and intrinsic motivation.",
      "abstract": "",
      "year": "2016",
      "venue": "NeurIPS",
      "authors": "Bellemare, M. G., Srinivasan, S., Ostrovski, G., Schaul, T., Saxton, D., and Munos, R."
    },
    {
      "index": 21,
      "title": "Why Children Talk to Themselves.",
      "abstract": "",
      "year": "1994",
      "venue": "Scientific American",
      "authors": "Berk, L. E."
    },
    {
      "index": 22,
      "title": "Curiosity and exploration.",
      "abstract": "",
      "year": "1966",
      "venue": "Science",
      "authors": "Berlyne, D. E."
    },
    {
      "index": 23,
      "title": "Smirl: Surprise minimizing rl in dynamic environments.",
      "abstract": "",
      "year": "2019",
      "venue": "ArXiv - abs/1912.05510",
      "authors": "Berseth, G., Geng, D., Devin, C., Finn, C., Jayaraman, D., and Levine, S."
    },
    {
      "index": 24,
      "title": "Control What You Can Intrinsically Motivated Task-Planning Agent",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Blaes, S., Pogancic, M. V., Zhu, J., and Martius, G.",
      "orig_title": "Control what you can: Intrinsically motivated task-planning agent.",
      "paper_id": "1906.08190v2"
    },
    {
      "index": 25,
      "title": "Language Models are Few-Shot Learners",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D.",
      "orig_title": "Language models are few-shot learners.",
      "paper_id": "2005.14165v4"
    },
    {
      "index": 26,
      "title": "Exploration by Random Network Distillation",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "Burda, Y., Edwards, H., Storkey, A. J., and Klimov, O.",
      "orig_title": "Exploration by random network distillation.",
      "paper_id": "1810.12894v1"
    },
    {
      "index": 27,
      "title": "Learning with AMIGo: Adversarially Motivated Intrinsic Goals",
      "abstract": "",
      "year": "2021",
      "venue": "ICLR",
      "authors": "Campero, A., Raileanu, R., Küttler, H., Tenenbaum, J. B., Rocktäschel, T., and Grefenstette, E.",
      "orig_title": "Learning with amigo: Adversarially motivated intrinsic goals.",
      "paper_id": "2006.12122v2"
    },
    {
      "index": 28,
      "title": "Explore, Discover and Learn: Unsupervised Discovery of State-Covering Skills",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Campos, V., Trott, A., Xiong, C., Socher, R., Giró-i-Nieto, X., and Torres, J.",
      "orig_title": "Explore, discover and learn: Unsupervised discovery of state-covering skills.",
      "paper_id": "2002.03647v4"
    },
    {
      "index": 29,
      "title": "Developmental Robotics: From Babies to Robots.",
      "abstract": "",
      "year": "2015",
      "venue": "MIT press",
      "authors": "Cangelosi, A., and Schlesinger, M."
    },
    {
      "index": 30,
      "title": "Modularity, Language, and the Flexibility of Thought.",
      "abstract": "",
      "year": "2002",
      "venue": "Behavioral and Brain Sciences",
      "authors": "Carruthers, P."
    },
    {
      "index": 31,
      "title": "Multitask learning.",
      "abstract": "",
      "year": "1997",
      "venue": "Machine learning",
      "authors": "Caruana, R."
    },
    {
      "index": 32,
      "title": "Specializing Versatile Skill Libraries using Local Mixture of Experts.",
      "abstract": "",
      "year": "2021",
      "venue": "Annual Conference on Robot Learning",
      "authors": "Celik, O., Zhou, D., Li, G., Becker, P., and Neumann, G."
    },
    {
      "index": 33,
      "title": "Actrce: Augmenting experience via teacher’s advice for multi-goal reinforcement learning.",
      "abstract": "",
      "year": "2019",
      "venue": "ArXiv - abs/1902.04546",
      "authors": "Chan, H., Wu, Y., Kiros, J., Fidler, S., and Ba, J."
    },
    {
      "index": 34,
      "title": "Gated-Attention Architectures for Task-Oriented Language Grounding",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI",
      "authors": "Chaplot, D. S., Sathyendra, K. M., Pasumarthi, R. K., Rajagopal, D., and Salakhutdinov, R.",
      "orig_title": "Gated-attention architectures for task-oriented language grounding.",
      "paper_id": "1706.07230v2"
    },
    {
      "index": 35,
      "title": "PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Charlesworth, H., and Montana, G.",
      "orig_title": "Plangan: Model-based planning with sparse rewards and multiple goals.",
      "paper_id": "2006.00900v1"
    },
    {
      "index": 36,
      "title": "BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop.",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "Chevalier-Boisvert, M., Bahdanau, D., Lahlou, S., Willems, L., Saharia, C., Nguyen, T. H., and Bengio, Y."
    },
    {
      "index": 37,
      "title": "GLIB: Efficient Exploration for Relational Model-Based Reinforcement Learning via Goal-Literal Babbling",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI",
      "authors": "Chitnis, R., Silver, T., Tenenbaum, J., Kaelbling, L. P., and Lozano-Pérez, T.",
      "orig_title": "Glib: Efficient exploration for relational model-based reinforcement learning via goal-literal babbling.",
      "paper_id": "2001.08299v3"
    },
    {
      "index": 38,
      "title": "Variational Empowerment as Representation Learning for Goal-Based Reinforcement Learning.",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv - abs/2106.01404",
      "authors": "Choi, J., Sharma, A., Lee, H., Levine, S., and Gu, S. S."
    },
    {
      "index": 39,
      "title": "Exploratory play, rational action, and efficient search.",
      "abstract": "",
      "year": "2020",
      "venue": "PsyArXiv",
      "authors": "Chu, J., and Schulz, L."
    },
    {
      "index": 40,
      "title": "Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Chua, K., Calandra, R., McAllister, R., and Levine, S.",
      "orig_title": "Deep reinforcement learning in a handful of trials using probabilistic dynamics models.",
      "paper_id": "1805.12114v2"
    },
    {
      "index": 41,
      "title": "Higher: Improving instruction following with hindsight generation for experience replay.",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Symposium Series on Computational Intelligence (SSCI)",
      "authors": "Cideron, G., Seurin, M., Strub, F., and Pietquin, O."
    },
    {
      "index": 42,
      "title": "Being There: Putting Brain, Body, and World Together Again.",
      "abstract": "",
      "year": "1998",
      "venue": "MIT press",
      "authors": "Clark, A."
    },
    {
      "index": 43,
      "title": "End-to-end Driving via Conditional Imitation Learning",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE International Conference on Robotics and Automation (ICRA)",
      "authors": "Codevilla, F., Müller, M., López, A., Koltun, V., and Dosovitskiy, A.",
      "orig_title": "End-to-end driving via conditional imitation learning.",
      "paper_id": "1710.02410v2"
    },
    {
      "index": 44,
      "title": "Language-Conditioned Goal Generation: a New Approach to Language Grounding in RL",
      "abstract": "",
      "year": "2020",
      "venue": "ArXiv - abs/2006.07043",
      "authors": "Colas, C., Akakzia, A., Oudeyer, P.-Y., Chetouani, M., and Sigaud, O.",
      "orig_title": "Language-conditioned goal generation: a new approach to language grounding for rl.",
      "paper_id": "2006.07043v1"
    },
    {
      "index": 45,
      "title": "EpidemiOptim: a toolbox for the optimization of control policies in epidemiological models",
      "abstract": "",
      "year": "2021",
      "venue": "Journal of Artificial Intelligence Research",
      "authors": "Colas, C., Hejblum, B., Rouillon, S., Thiébaut, R., Oudeyer, P.-Y., Moulin-Frier, C., and Prague, M.",
      "orig_title": "Epidemioptim: A toolbox for the optimization of control policies in epidemiological models.",
      "paper_id": "2010.04452v1"
    },
    {
      "index": 46,
      "title": "Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven Exploration",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Colas, C., Karch, T., Lair, N., Dussoux, J., Moulin-Frier, C., Dominey, P. F., and Oudeyer, P.",
      "orig_title": "Language as a cognitive tool to imagine goals in curiosity driven exploration.",
      "paper_id": "2002.09253v4"
    },
    {
      "index": 47,
      "title": "Scaling map-elites to deep neuroevolution.",
      "abstract": "",
      "year": "2020",
      "venue": "GECCO",
      "authors": "Colas, C., Madhavan, V., Huizinga, J., and Clune, J."
    },
    {
      "index": 48,
      "title": "CURIOUS: Intrinsically Motivated Modular Multi-Goal Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Colas, C., Oudeyer, P., Sigaud, O., Fournier, P., and Chetouani, M.",
      "orig_title": "CURIOUS: intrinsically motivated modular multi-goal reinforcement learning.",
      "paper_id": "1810.06284v4"
    },
    {
      "index": 49,
      "title": "GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms",
      "abstract": "",
      "year": "2018",
      "venue": "ICML",
      "authors": "Colas, C., Sigaud, O., and Oudeyer, P.",
      "orig_title": "GEP-PG: decoupling exploration and exploitation in deep reinforcement learning algorithms.",
      "paper_id": "1802.05054v5"
    },
    {
      "index": 50,
      "title": "An Empowerment-based Solution to Robotic Manipulation Tasks with Sparse Rewards",
      "abstract": "",
      "year": "2020",
      "venue": "ArXiv - abs/2010.07986",
      "authors": "Dai, S., Xu, W., Hofmann, A., and Williams, B.",
      "orig_title": "An Empowerment-based Solution to Robotic Manipulation Tasks with Sparse Rewards.",
      "paper_id": "2010.07986v3"
    },
    {
      "index": 51,
      "title": "Embodied Question Answering",
      "abstract": "",
      "year": "2018",
      "venue": "2018 IEEE Conference on Computer Vision and Pattern\nRecognition, CVPR",
      "authors": "Das, A., Datta, S., Gkioxari, G., Lee, S., Parikh, D., and Batra, D.\n(2018).",
      "orig_title": "Embodied question answering",
      "paper_id": "1711.11543v2"
    },
    {
      "index": 52,
      "title": "From Embodied to Socially Embedded Agents – Implications for Interaction-Aware Robots",
      "abstract": "",
      "year": "2002",
      "venue": "",
      "authors": "Dautenhahn, K., Ogden, B., and Quick, T. (2002)."
    },
    {
      "index": 53,
      "title": "Feudal reinforcement learning",
      "abstract": "",
      "year": "1993",
      "venue": "Advances in neural information processing systems",
      "authors": "Dayan, P.,  and Hinton, G. E. (1993)."
    },
    {
      "index": 54,
      "title": "The Helmholtz Machine",
      "abstract": "",
      "year": "1995",
      "venue": "",
      "authors": "Dayan, P., Hinton, G. E., Neal, R. M., and Zemel, R. S. (1995)."
    },
    {
      "index": 55,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of NAACL-HLT, pp. 4171–4186. Association for\nComputational Linguistics",
      "authors": "Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019).",
      "orig_title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 56,
      "title": "Goal-conditioned Imitation Learning",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of NeurIPS",
      "authors": "Ding, Y., Florensa, C., Abbeel, P., and Phielipp, M. (2019).",
      "orig_title": "Goal-conditioned imitation learning",
      "paper_id": "1906.05838v3"
    },
    {
      "index": 57,
      "title": "First return, then explore",
      "abstract": "",
      "year": "2021",
      "venue": "Nature, 590(",
      "authors": "Ecoffet, A., Huizinga, J., Lehman, J., Stanley, K. O., and Clune, J.\n(2021)."
    },
    {
      "index": 58,
      "title": "The goal construct in psychology",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": "Elliot, A. J.,  and Fryer, J. W. (2008)."
    },
    {
      "index": 59,
      "title": "Learning and development in neural networks: the importance of starting small",
      "abstract": "",
      "year": "1993",
      "venue": "",
      "authors": "Elman, J. L. (1993)."
    },
    {
      "index": 60,
      "title": "Hierarchically Organized Latent Modules for Exploratory Search in Morphogenetic Systems",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Etcheverry, M., Moulin-Frier, C., and Oudeyer, P. (2020).",
      "orig_title": "Hierarchically organized latent modules for exploratory search in morphogenetic systems",
      "paper_id": "2007.01195v3"
    },
    {
      "index": 61,
      "title": "Rewriting history with inverse RL: hindsight inference for policy improvement",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Eysenbach, B., Geng, X., Levine, S., and Salakhutdinov, R. R. (2020)."
    },
    {
      "index": 62,
      "title": "Diversity is All You Need: Learning Skills without a Reward Function",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of ICLR",
      "authors": "Eysenbach, B., Gupta, A., Ibarz, J., and Levine, S. (2019).",
      "orig_title": "Diversity is all you need: Learning skills without a reward function",
      "paper_id": "1802.06070v6"
    },
    {
      "index": 63,
      "title": "Discovering Generalizable Skills via Automated Generation of Diverse Tasks",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of Robotics: Science and Systems",
      "authors": "Fang, K., Zhu, Y., Savarese, S., and Fei-Fei, L. (2021).",
      "orig_title": "Discovering Generalizable Skills via Automated Generation of Diverse Tasks",
      "paper_id": "2106.13935v1"
    },
    {
      "index": 64,
      "title": "Self-supervised Learning of Image Embedding for Continuous Control",
      "abstract": "",
      "year": "1901",
      "venue": "ArXiv - abs/",
      "authors": "Florensa, C., Degrave, J., Heess, N., Springenberg, J. T., and Riedmiller, M.\n(2019).",
      "orig_title": "Self-supervised learning of image embedding for continuous control",
      "paper_id": "1901.00943v1"
    },
    {
      "index": 65,
      "title": "Automatic Goal Generation for Reinforcement Learning Agents",
      "abstract": "",
      "year": "2018",
      "venue": "Proc. of ICML, Vol. 80",
      "authors": "Florensa, C., Held, D., Geng, X., and Abbeel, P. (2018).",
      "orig_title": "Automatic goal generation for reinforcement learning agents",
      "paper_id": "1705.06366v5"
    },
    {
      "index": 66,
      "title": "Modular active curiosity-driven discovery of tool use",
      "abstract": "",
      "year": "2016",
      "venue": "Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ\nInternational Conference on",
      "authors": "Forestier, S.,  and Oudeyer, P.-Y. (2016)."
    },
    {
      "index": 67,
      "title": "Intrinsically Motivated Goal Exploration Processes with Automatic Curriculum Learning",
      "abstract": "",
      "year": "2017",
      "venue": "ArXiv - abs/",
      "authors": "Forestier, S., Portelas, R., Mollard, Y., and Oudeyer, P.-Y. (2017).",
      "orig_title": "Intrinsically motivated goal exploration processes with automatic curriculum learning",
      "paper_id": "1708.02190v3"
    },
    {
      "index": 68,
      "title": "Clic: Curriculum learning and imitation for object control in nonrewarding environments",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems,\n13(2), 239–248",
      "authors": "Fournier, P., Colas, C., Chetouani, M., and Sigaud, O. (2021)."
    },
    {
      "index": 69,
      "title": "Accuracy-based Curriculum Learning in Deep Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "ArXiv - abs/",
      "authors": "Fournier, P., Sigaud, O., Chetouani, M., and Oudeyer, P.-Y. (2018).",
      "orig_title": "Accuracy-based curriculum learning in deep reinforcement learning",
      "paper_id": "1806.09614v2"
    },
    {
      "index": 70,
      "title": "Meta Learning Shared Hierarchies",
      "abstract": "",
      "year": "2018",
      "venue": "Proc. of ICLR",
      "authors": "Frans, K., Ho, J., Chen, X., Abbeel, P., and Schulman, J. (2018).",
      "orig_title": "Meta learning shared hierarchies",
      "paper_id": "1710.09767v1"
    },
    {
      "index": 71,
      "title": "Generative adversarial nets",
      "abstract": "",
      "year": "2014",
      "venue": "Proc. of NeurIPS",
      "authors": "Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,\nOzair, S., Courville, A. C., and Bengio, Y. (2014)."
    },
    {
      "index": 72,
      "title": "The scientist in the crib: Minds, brains, and how children learn",
      "abstract": "",
      "year": "1999",
      "venue": "",
      "authors": "Gopnik, A., Meltzoff, A. N., and Kuhl, P. K. (1999)."
    },
    {
      "index": 73,
      "title": "Towards a neuroscience of active sampling and curiosity",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Gottlieb, J.,  and Oudeyer, P.-Y. (2018)."
    },
    {
      "index": 74,
      "title": "Recurrent independent mechanisms",
      "abstract": "",
      "year": "2021",
      "venue": "Proc. of ICLR",
      "authors": "Goyal, A., Lamb, A., Hoffmann, J., Sodhani, S., Levine, S., Bengio, Y., and Schölkopf, B. (2021)."
    },
    {
      "index": 75,
      "title": "Variational Intrinsic Control",
      "abstract": "",
      "year": "2016",
      "venue": "ArXiv - abs/",
      "authors": "Gregor, K., Rezende, D. J., and Wierstra, D. (2016).",
      "orig_title": "Variational intrinsic control",
      "paper_id": "1611.07507v1"
    },
    {
      "index": 76,
      "title": "On the role of planning in model-based deep reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "Proc. of ICLR",
      "authors": "Hamrick, J. B., Friesen, A. L., Behbahani, F., Guez, A., Viola, F.,\nWitherspoon, S., Anthony, T., Buesing, L. H., Velickovic, P., and Weber, T.\n(2021).",
      "orig_title": "On the role of planning in model-based deep reinforcement learning",
      "paper_id": "2011.04021v2"
    },
    {
      "index": 77,
      "title": "Dynamical distance learning for semi-supervised and unsupervised skill discovery",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. of ICLR",
      "authors": "Hartikainen, K., Geng, X., Haarnoja, T., and Levine, S. (2020)."
    },
    {
      "index": 78,
      "title": "Learning an embedding space for transferable robot skills",
      "abstract": "",
      "year": "2018",
      "venue": "Proc. of ICLR",
      "authors": "Hausman, K., Springenberg, J. T., Wang, Z., Heess, N., and Riedmiller, M. A.\n(2018)."
    },
    {
      "index": 79,
      "title": "Grounded Language Learning in a Simulated 3D World",
      "abstract": "",
      "year": "2017",
      "venue": "ArXiv - abs/",
      "authors": "Hermann, K. M., Hill, F., Green, S., Wang, F., Faulkner, R., Soyer, H.,\nSzepesvari, D., Czarnecki, W. M., Jaderberg, M., Teplyashin, D., Wainwright,\nM., Apps, C., Hassabis, D., and Blunsom, P. (2017).",
      "orig_title": "Grounded Language Learning in a Simulated 3D World",
      "paper_id": "1706.06551v2"
    },
    {
      "index": 80,
      "title": "Deep Q-learning from Demonstrations",
      "abstract": "",
      "year": "2018",
      "venue": "Proc. of AAAI",
      "authors": "Hester, T., Vecerík, M., Pietquin, O., Lanctot, M., Schaul, T., Piot,\nB., Horgan, D., Quan, J., Sendonaris, A., Osband, I., Dulac-Arnold, G.,\nAgapiou, J. P., Leibo, J. Z., and Gruslys, A. (2018).",
      "orig_title": "Deep q-learning from demonstrations",
      "paper_id": "1704.03732v4"
    },
    {
      "index": 81,
      "title": "Emergent systematic generalization in a situated agent",
      "abstract": "",
      "year": "",
      "venue": "Proc. of ICLR",
      "authors": "Hill, F., Lampinen, A., Schneider, R., Clark, S., Botvinick, M., McClelland,\nJ. L., and Santoro, A. (2020a)."
    },
    {
      "index": 82,
      "title": "Human Instruction-Following with Deep Reinforcement Learning via Transfer-Learning from Text",
      "abstract": "",
      "year": "2005",
      "venue": "ArXiv - abs/",
      "authors": "Hill, F., Mokra, S., Wong, N., and Harley, T. (2020b)."
    },
    {
      "index": 83,
      "title": "Grounded Language Learning Fast and Slow",
      "abstract": "",
      "year": "2021",
      "venue": "Proc. of ICLR",
      "authors": "Hill, F., Tieleman, O., von Glehn, T., Wong, N., Merzic, H., and Clark, S.\n(2021).",
      "orig_title": "Grounded language learning fast and slow",
      "paper_id": "2009.01719v4"
    },
    {
      "index": 84,
      "title": "Open-Endedness for the Sake of Open-Endedness",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Hintze, A. (2019)."
    },
    {
      "index": 85,
      "title": "Generative adversarial imitation learning",
      "abstract": "",
      "year": "2016",
      "venue": "Proc. of NeurIPS",
      "authors": "Ho, J.,  and Ermon, S. (2016)."
    },
    {
      "index": 86,
      "title": "VIME: variational information maximizing exploration",
      "abstract": "",
      "year": "2016",
      "venue": "Proc. of NeurIPS",
      "authors": "Houthooft, R., Chen, X., Duan, Y., Schulman, J., Turck, F. D., and Abbeel, P.\n(2016)."
    },
    {
      "index": 87,
      "title": "Reinforcement Learning with Unsupervised Auxiliary Tasks",
      "abstract": "",
      "year": "2017",
      "venue": "Proc. of ICLR",
      "authors": "Jaderberg, M., Mnih, V., Czarnecki, W. M., Schaul, T., Leibo, J. Z., Silver,\nD., and Kavukcuoglu, K. (2017).",
      "orig_title": "Reinforcement learning with unsupervised auxiliary tasks",
      "paper_id": "1611.05397v1"
    },
    {
      "index": 88,
      "title": "Language as an abstraction for hierarchical deep reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of NeurIPS",
      "authors": "Jiang, Y., Gu, S., Murphy, K., and Finn, C. (2019)."
    },
    {
      "index": 89,
      "title": "Learning to achieve goals",
      "abstract": "",
      "year": "1993",
      "venue": "IJCAI",
      "authors": "Kaelbling, L. P. (1993)."
    },
    {
      "index": 90,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": "Kaplan, F.,  and Oudeyer, P.-Y. (2007).",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 91,
      "title": "Maximizing Learning Progress: An Internal Reward System for Development",
      "abstract": "",
      "year": "2004",
      "venue": "Embodied artificial intelligence, pp. 259–270.\nSpringer",
      "authors": "Kaplan, F.,  and Oudeyer, P.-Y. (2004)."
    },
    {
      "index": 92,
      "title": "Grounding Spatio-Temporal Language with Transformers",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Karch, T., Teodorescu, L., Hofmann, K., Moulin-Frier, C., and Oudeyer, P.-Y.\n(2021).",
      "orig_title": "Grounding spatio-temporal language with transformers",
      "paper_id": "2106.08858v2"
    },
    {
      "index": 93,
      "title": "The psychology and neuroscience of curiosity",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Kidd, C.,  and Hayden, B. Y. (2015)."
    },
    {
      "index": 94,
      "title": "Active World Model Learning with Progress Curiosity",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. of ICML, Vol. 119",
      "authors": "Kim, K., Sano, M., Freitas, J. D., Haber, N., and Yamins, D. (2020).",
      "orig_title": "Active world model learning with progress curiosity",
      "paper_id": "2007.07853v1"
    },
    {
      "index": 95,
      "title": "Grimgep: Learning progress for robust goal sampling in visual deep reinforcement learning",
      "abstract": "",
      "year": "2008",
      "venue": "ArXiv - abs/",
      "authors": "Kovač, G., Laversanne-Finot, A., and Oudeyer, P.-Y. (2020)."
    },
    {
      "index": 96,
      "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation",
      "abstract": "",
      "year": "2016",
      "venue": "Proc. of NeurIPS",
      "authors": "Kulkarni, T. D., Narasimhan, K., Saeedi, A., and Tenenbaum, J.\n(2016).",
      "orig_title": "Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation",
      "paper_id": "1604.06057v2"
    },
    {
      "index": 97,
      "title": "One solution is not all you need: Few-shot extrapolation via structured maxent RL",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Kumar, S., Kumar, A., Levine, S., and Finn, C. (2020)."
    },
    {
      "index": 98,
      "title": "Curiosity-driven multi-criteria hindsight experience replay",
      "abstract": "",
      "year": "1906",
      "venue": "ArXiv - abs/",
      "authors": "Lanier, J. B., McAleer, S., and Baldi, P. (2019)."
    },
    {
      "index": 99,
      "title": "Evolving a diversity of virtual creatures through novelty search and local competition",
      "abstract": "",
      "year": "2011",
      "venue": "Proc. of GECCO",
      "authors": "Lehman, J.,  and Stanley, K. O. (2011)."
    },
    {
      "index": 100,
      "title": "Hierarchical reinforcement learning with hindsight",
      "abstract": "",
      "year": "2018",
      "venue": "ArXiv - abs/",
      "authors": "Levy, A., Platt, R., and Saenko, K. (2018)."
    },
    {
      "index": 101,
      "title": "Towards Practical Multi-Object Manipulation using Relational Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "2020 IEEE International Conference on Robotics and\nAutomation (ICRA)",
      "authors": "Li, R., Jabri, A., Darrell, T., and Agrawal, P. (2020).",
      "orig_title": "Towards practical multi-object manipulation using relational reinforcement learning",
      "paper_id": "1912.11032v1"
    },
    {
      "index": 102,
      "title": "Social Situatedness of Natural and Artificial Intelligence: Vygotsky and Beyond",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": "Lindblom, J.,  and Ziemke, T. (2003)."
    },
    {
      "index": 103,
      "title": "Adapting behavior via intrinsic reward: a survey and empirical study",
      "abstract": "",
      "year": "2020",
      "venue": "Journal of Artificial Intelligence Research, 69",
      "authors": "Linke, C., Ady, N. M., White, M., Degris, T., and White, A. (2020)."
    },
    {
      "index": 104,
      "title": "Robust active binocular vision through intrinsically motivated learning",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": "Lonini, L., Forestier, S., Teulière, C., Zhao, Y., Shi, B. E., and Triesch, J. (2013)."
    },
    {
      "index": 105,
      "title": "Exploration in model-based reinforcement learning by empirically estimating learning progress",
      "abstract": "",
      "year": "2012",
      "venue": "Proc. of NeurIPS",
      "authors": "Lopes, M., Lang, T., Toussaint, M., and Oudeyer, P. (2012)."
    },
    {
      "index": 106,
      "title": "Working Memory Graphs",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. of ICML, Vol. 119",
      "authors": "Loynd, R., Fernandez, R., Çelikyilmaz, A., Swaminathan, A., and Hausknecht, M. J. (2020).",
      "orig_title": "Working memory graphs",
      "paper_id": "1911.07141v4"
    },
    {
      "index": 107,
      "title": "A survey of reinforcement learning informed by natural language",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of IJCAI",
      "authors": "Luketina, J., Nardelli, N., Farquhar, G., Foerster, J. N., Andreas, J.,\nGrefenstette, E., Whiteson, S., and Rocktäschel, T. (2019)."
    },
    {
      "index": 108,
      "title": "What Do Words Do? Toward a Theory of Language-Augmented Thought",
      "abstract": "",
      "year": "2012",
      "venue": "Psychology of Learning and Motivation,\nVol. 57",
      "authors": "Lupyan, G. (2012)."
    },
    {
      "index": 109,
      "title": "Learning Latent Plans from Play",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the Conference on Robot Learning,\nVol. 100",
      "authors": "Lynch, C., Khansari, M., Xiao, T., Kumar, V., Tompson, J., Levine, S., and Sermanet, P. (2020).",
      "orig_title": "Learning latent plans from play",
      "paper_id": "1903.01973v2"
    },
    {
      "index": 110,
      "title": "Grounding language in play",
      "abstract": "",
      "year": "2005",
      "venue": "ArXiv - abs/",
      "authors": "Lynch, C.,  and Sermanet, P. (2020)."
    },
    {
      "index": 111,
      "title": "Unicorn: Continual learning with a universal, off-policy agent",
      "abstract": "",
      "year": "2018",
      "venue": "ArXiv - abs/",
      "authors": "Mankowitz, D. J., Žídek, A., Barreto, A., Horgan, D., Hessel, M.,\nQuan, J., Oh, J., van Hasselt, H., Silver, D., and Schaul, T.\n(2018).",
      "orig_title": "Unicorn: Continual learning with a universal, off-policy agent",
      "paper_id": "1802.08294v2"
    },
    {
      "index": 112,
      "title": "Information driven self-organization of complex robotic behaviors",
      "abstract": "",
      "year": "2013",
      "venue": "PloS one, 8(5), e",
      "authors": "Martius, G., Der, R., and Ay, N. (2013)."
    },
    {
      "index": 113,
      "title": "Automatic discovery of subgoals in reinforcement learning using diverse density",
      "abstract": "",
      "year": "2001",
      "venue": "Proc. of ICML",
      "authors": "McGovern, A.,  and Barto, A. G. (2001)."
    },
    {
      "index": 114,
      "title": "Towards a Vygotskyan Cognitive Robotics: The Role of Language as a Cognitive Tool",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": "Mirolli, M.,  and Parisi, D. (2011)."
    },
    {
      "index": 115,
      "title": "Human-level control through deep reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "nature, 518(",
      "authors": "Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare,\nM. G., Graves, A., Riedmiller, M., Fidjeland, A. K., Ostrovski, G., et al.\n(2015)."
    },
    {
      "index": 116,
      "title": "The Intersection of Planning and Learning",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Moerland, T. M. (2021)."
    },
    {
      "index": 117,
      "title": "Variational information maximisation for intrinsically motivated reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "Proc. of NeurIPS",
      "authors": "Mohamed, S.,  and Rezende, D. J. (2015)."
    },
    {
      "index": 118,
      "title": "Self-organization of early vocal development in infants and machines: The role of intrinsic motivation",
      "abstract": "",
      "year": "2014",
      "venue": "Frontiers in Psychology (Cognitive Science), 4(",
      "authors": "Moulin-Frier, C., Nguyen, S. M., and Oudeyer, P.-Y. (2014)."
    },
    {
      "index": 119,
      "title": "Illuminating search spaces by mapping elites",
      "abstract": "",
      "year": "2015",
      "venue": "ArXiv - abs/",
      "authors": "Mouret, J.-B.,  and Clune, J. (2015)."
    },
    {
      "index": 120,
      "title": "Data-Efficient Hierarchical Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "Proc. of NeurIPS",
      "authors": "Nachum, O., Gu, S., Lee, H., and Levine, S. (2018).",
      "orig_title": "Data-efficient hierarchical reinforcement learning",
      "paper_id": "1805.08296v4"
    },
    {
      "index": 121,
      "title": "Contextual Imagined Goals for Self-Supervised Robotic Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Robot Learning",
      "authors": "Nair, A., Bahl, S., Khazatsky, A., Pong, V., Berseth, G., and Levine, S.\n(2020).",
      "orig_title": "Contextual imagined goals for self-supervised robotic learning",
      "paper_id": "1910.11670v1"
    },
    {
      "index": 122,
      "title": "Overcoming Exploration in Reinforcement Learning with Demonstrations",
      "abstract": "",
      "year": "2018",
      "venue": "2018 IEEE international conference on robotics and\nautomation (ICRA)",
      "authors": "Nair, A., McGrew, B., Andrychowicz, M., Zaremba, W., and Abbeel, P.\n(2018a).",
      "orig_title": "Overcoming exploration in reinforcement learning with demonstrations",
      "paper_id": "1709.10089v2"
    },
    {
      "index": 123,
      "title": "Visual Reinforcement Learning with Imagined Goals",
      "abstract": "",
      "year": "",
      "venue": "Proc. of NeurIPS",
      "authors": "Nair, A., Pong, V., Dalal, M., Bahl, S., Lin, S., and Levine, S.\n(2018b).",
      "orig_title": "Visual reinforcement learning with imagined goals",
      "paper_id": "1807.04742v2"
    },
    {
      "index": 124,
      "title": "Planning with Goal-Conditioned Policies",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of NeurIPS",
      "authors": "Nasiriany, S., Pong, V., Lin, S., and Levine, S. (2019).",
      "orig_title": "Planning with goal-conditioned policies",
      "paper_id": "1911.08453v1"
    },
    {
      "index": 125,
      "title": "Socially Guided Intrinsic Motivation for Robot Learning of Motor Skills",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "Nguyen, M.,  and Oudeyer, P.-Y. (2014).",
      "orig_title": "Socially guided intrinsic motivation for robot learning of motor skills",
      "paper_id": "1804.07269v1"
    },
    {
      "index": 126,
      "title": "Model Learning for Robot Control: A Survey",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": "Nguyen-Tuong, D.,  and Peters, J. (2011)."
    },
    {
      "index": 127,
      "title": "Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "Proc. of ICML, Vol. 70",
      "authors": "Oh, J., Singh, S. P., Lee, H., and Kohli, P. (2017).",
      "orig_title": "Zero-shot task generalization with multi-task deep reinforcement learning",
      "paper_id": "1706.05064v2"
    },
    {
      "index": 128,
      "title": "Discovering Diverse Solutions in Deep Reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv - abs/",
      "authors": "Osa, T., Tangkaratt, V., and Sugiyama, M. (2021)."
    },
    {
      "index": 129,
      "title": "Intrinsic Motivation Systems for Autonomous Mental Development",
      "abstract": "",
      "year": "2007",
      "venue": "IEEE transactions on evolutionary computation, 11(2),\n265–286",
      "authors": "Oudeyer, P.-Y., Kaplan, F., and Hafner, V. V. (2007)."
    },
    {
      "index": 130,
      "title": "What is intrinsic motivation? a typology of computational approaches",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": "Oudeyer, P.-Y.,  and Kaplan, F. (2007)."
    },
    {
      "index": 131,
      "title": "How evolution may work through curiosity-driven developmental process",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "Oudeyer, P.-Y.,  and Smith, L. B. (2016)."
    },
    {
      "index": 132,
      "title": "Curiosity-driven Exploration by Self-supervised Prediction",
      "abstract": "",
      "year": "2017",
      "venue": "Proc. of ICML, Vol. 70",
      "authors": "Pathak, D., Agrawal, P., Efros, A. A., and Darrell, T. (2017).",
      "orig_title": "Curiosity-driven exploration by self-supervised prediction",
      "paper_id": "1705.05363v1"
    },
    {
      "index": 133,
      "title": "FiLM: Visual Reasoning with a General Conditioning Layer",
      "abstract": "",
      "year": "2018",
      "venue": "Proc. of AAAI",
      "authors": "Perez, E., Strub, F., de Vries, H., Dumoulin, V., and Courville, A. C.\n(2018).",
      "orig_title": "Film: Visual reasoning with a general conditioning layer",
      "paper_id": "1709.07871v2"
    },
    {
      "index": 134,
      "title": "Maximum entropy gain exploration for long horizon multi-goal reinforcement learning",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. of ICML, Vol. 119",
      "authors": "Pitis, S., Chan, H., Zhao, S., Stadie, B. C., and Ba, J. (2020)."
    },
    {
      "index": 135,
      "title": "Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research",
      "abstract": "",
      "year": "2018",
      "venue": "ArXiv - abs/",
      "authors": "Plappert, M., Andrychowicz, M., Ray, A., McGrew, B., Baker, B., Powell, G.,\nSchneider, J., Tobin, J., Chociej, M., Welinder, P., et al. (2018).",
      "orig_title": "Multi-goal reinforcement learning: Challenging robotics environments and request for research",
      "paper_id": "1802.09464v2"
    },
    {
      "index": 136,
      "title": "Skew-Fit: State-Covering Self-Supervised Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. of ICML, Vol. 119",
      "authors": "Pong, V., Dalal, M., Lin, S., Nair, A., Bahl, S., and Levine, S.\n(2020).",
      "orig_title": "Skew-fit: State-covering self-supervised reinforcement learning",
      "paper_id": "1903.03698v4"
    },
    {
      "index": 137,
      "title": "Automatic curriculum learning for deep RL: A short survey",
      "abstract": "",
      "year": "",
      "venue": "Proc. of IJCAI",
      "authors": "Portelas, R., Colas, C., Weng, L., Hofmann, K., and Oudeyer, P.\n(2020a)."
    },
    {
      "index": 138,
      "title": "Teacher algorithms for curriculum learning of Deep RL in continuously parameterized environments",
      "abstract": "",
      "year": "",
      "venue": "Proc. of CoRL",
      "authors": "Portelas, R., Colas, C., Hofmann, K., and Oudeyer, P.-Y. (2020b).",
      "orig_title": "Teacher Algorithms for Curriculum Learning of Deep Rl in Continuously Parameterized Environments",
      "paper_id": "1910.07224v1"
    },
    {
      "index": 139,
      "title": "Temporal Abstraction in Reinforcement Learning",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Precup, D. (2000a)."
    },
    {
      "index": 140,
      "title": "Temporal abstraction in reinforcement learning",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Precup, D. (2000b)."
    },
    {
      "index": 141,
      "title": "Automated curricula through setter-solver interactions",
      "abstract": "",
      "year": "1909",
      "venue": "ArXiv - abs/",
      "authors": "Racanière, S., Lampinen, A., Santoro, A., Reichert, D., Firoiu, V., and Lillicrap, T. (2019).",
      "orig_title": "Automated curricula through setter-solver interactions",
      "paper_id": "1909.12892v2"
    },
    {
      "index": 142,
      "title": "RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. of ICLR",
      "authors": "Raileanu, R.,  and Rocktäschel, T. (2020).",
      "orig_title": "RIDE: rewarding impact-driven exploration for procedurally-generated environments",
      "paper_id": "2002.12292v2"
    },
    {
      "index": 143,
      "title": "Goal-driven learning",
      "abstract": "",
      "year": "1995",
      "venue": "MIT press",
      "authors": "Ram, A., Leake, D. B., and Leake, D. (1995)."
    },
    {
      "index": 144,
      "title": "Successor Options: An Option Discovery Framework for Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of IJCAI",
      "authors": "Ramesh, R., Tomar, M., and Ravindran, B. (2019).",
      "orig_title": "Successor options: An option discovery framework for reinforcement learning",
      "paper_id": "1905.05731v1"
    },
    {
      "index": 145,
      "title": "Learning by Playing – Solving Sparse Reward Tasks from Scratch",
      "abstract": "",
      "year": "2018",
      "venue": "Proc. of ICML, Vol. 80",
      "authors": "Riedmiller, M. A., Hafner, R., Lampe, T., Neunert, M., Degrave, J., de Wiele,\nT. V., Mnih, V., Heess, N., and Springenberg, J. T. (2018).",
      "orig_title": "Learning by playing solving sparse reward tasks from scratch",
      "paper_id": "1802.10567v1"
    },
    {
      "index": 146,
      "title": "Curious Hierarchical Actor-Critic Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Artificial Neural Networks",
      "authors": "Röder, F., Eppe, M., Nguyen, P. D., and Wermter, S. (2020).",
      "orig_title": "Curious hierarchical actor-critic reinforcement learning",
      "paper_id": "2005.03420v3"
    },
    {
      "index": 147,
      "title": "Efficient exploratory learning of inverse kinematics on a bionic elephant trunk",
      "abstract": "",
      "year": "2013",
      "venue": "IEEE transactions on neural networks and learning systems,\n25(6)",
      "authors": "Rolf, M.,  and Steil, J. J. (2013)."
    },
    {
      "index": 148,
      "title": "Goal babbling permits direct learning of inverse kinematics",
      "abstract": "",
      "year": "2010",
      "venue": "IEEE Transactions on Autonomous Mental Development, 2(3), 216–229",
      "authors": "Rolf, M., Steil, J. J., and Gienger, M. (2010)."
    },
    {
      "index": 149,
      "title": "A Benchmark for Systematic Generalization in Grounded Language Understanding",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Ruis, L., Andreas, J., Baroni, M., Bouchacourt, D., and Lake, B. M.\n(2020).",
      "orig_title": "A benchmark for systematic generalization in grounded language understanding",
      "paper_id": "2003.05161v2"
    },
    {
      "index": 150,
      "title": "Sequential Thought Processes in Pdp Models",
      "abstract": "",
      "year": "1986",
      "venue": "",
      "authors": "Rumelhart, D. E., Smolensky, P., McClelland, J. L., and Hinton, G.\n(1986)."
    },
    {
      "index": 151,
      "title": "Evolution strategies as a scalable alternative to reinforcement learning",
      "abstract": "",
      "year": "2017",
      "venue": "ArXiv - abs/",
      "authors": "Salimans, T., Ho, J., Chen, X., Sidor, S., and Sutskever, I. (2017)."
    },
    {
      "index": 152,
      "title": "Grail: a goal-discovering robotic architecture for intrinsically-motivated learning",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems,\n8(3), 214–231",
      "authors": "Santucci, V. G., Baldassarre, G., and Mirolli, M. (2016)."
    },
    {
      "index": 153,
      "title": "Intrinsically motivated open-ended learning in autonomous robots",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Santucci, V. G., Oudeyer, P.-Y., Barto, A., and Baldassarre, G.\n(2020)."
    },
    {
      "index": 154,
      "title": "Universal value function approximators",
      "abstract": "",
      "year": "2015",
      "venue": "Proc. of ICML, Vol. 37",
      "authors": "Schaul, T., Horgan, D., Gregor, K., and Silver, D. (2015)."
    },
    {
      "index": 155,
      "title": "General Value Function Networks",
      "abstract": "",
      "year": "2021",
      "venue": "Journal of Artificial Intelligence Research, 70,\n497–543",
      "authors": "Schlegel, M., Jacobsen, A., Abbas, Z., Patterson, A., White, A., and White,\nM. (2021).",
      "orig_title": "General value function networks",
      "paper_id": "1807.06763v4"
    },
    {
      "index": 156,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "1990",
      "venue": "",
      "authors": "Schmidhuber, J. (1990).",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 157,
      "title": "Curious model-building control systems",
      "abstract": "",
      "year": "1991",
      "venue": "Neural Networks, 1991. 1991 IEEE International Joint\nConference on",
      "authors": "Schmidhuber, J. (1991a)."
    },
    {
      "index": 158,
      "title": "Learning to generate sub-goals for action sequences",
      "abstract": "",
      "year": "",
      "venue": "Artificial neural networks",
      "authors": "Schmidhuber, J. (1991b)."
    },
    {
      "index": 159,
      "title": "A possibility for implementing curiosity and boredom in model-building neural controllers",
      "abstract": "",
      "year": "",
      "venue": "Proc. of the international conference on simulation of\nadaptive behavior: From animals to animats",
      "authors": "Schmidhuber, J. (1991c)."
    },
    {
      "index": 160,
      "title": "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model",
      "abstract": "",
      "year": "2020",
      "venue": "Nature, 588(",
      "authors": "Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L.,\nSchmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., Lillicrap,\nT., and Silver, D. (2020).",
      "orig_title": "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model",
      "paper_id": "1911.08265v2"
    },
    {
      "index": 161,
      "title": "Parameter-exploring policy gradients",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": "Sehnke, F., Osendorfer, C., Rückstieß, T., Graves, A., Peters, J.,\nand Schmidhuber, J. (2010)."
    },
    {
      "index": 162,
      "title": "Planning to explore via self-supervised world models",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. of ICML, Vol. 119",
      "authors": "Sekar, R., Rybkin, O., Daniilidis, K., Abbeel, P., Hafner, D., and Pathak, D.\n(2020)."
    },
    {
      "index": 163,
      "title": "Dynamics-Aware Unsupervised Discovery of Skills",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. of ICLR",
      "authors": "Sharma, A., Gu, S., Levine, S., Kumar, V., and Hausman, K. (2020).",
      "orig_title": "Dynamics-aware unsupervised discovery of skills",
      "paper_id": "1907.01657v2"
    },
    {
      "index": 164,
      "title": "Towards teachable autonomous agents",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv - abs/",
      "authors": "Sigaud, O., Caselles-Dupré, H., Colas, C., Akakzia, A., Oudeyer, P.-Y.,\nand Chetouani, M. (2021)."
    },
    {
      "index": 165,
      "title": "Mastering the game of go with deep neural networks and tree search",
      "abstract": "",
      "year": "2016",
      "venue": "nature, Vol. 529, pp. 484–489. Nature\nPublishing Group",
      "authors": "Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche,\nG., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M.,\net al. (2016)."
    },
    {
      "index": 166,
      "title": "Using relative novelty to identify useful temporal abstractions in reinforcement learning",
      "abstract": "",
      "year": "2004",
      "venue": "Proc. of ICML, Vol. 69",
      "authors": "Simsek, Ö.,  and Barto, A. G. (2004)."
    },
    {
      "index": 167,
      "title": "Skill characterization based on betweenness",
      "abstract": "",
      "year": "2008",
      "venue": "Proc. of NeurIPS",
      "authors": "Simsek, Ö.,  and Barto, A. G. (2008)."
    },
    {
      "index": 168,
      "title": "Intrinsically motivated reinforcement learning: An evolutionary perspective",
      "abstract": "",
      "year": "2010",
      "venue": "IEEE Transactions on Autonomous Mental Development, 2(2), 70–82",
      "authors": "Singh, S., Lewis, R. L., Barto, A. G., and Sorg, J. (2010)."
    },
    {
      "index": 169,
      "title": "Why Open-Endedness Matters",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Stanley, K. O. (2019)."
    },
    {
      "index": 170,
      "title": "The Role of Subjectivity in the Evaluation of Open-Endedness",
      "abstract": "",
      "year": "2016",
      "venue": "Presentation delivered in OEE2: The Second Workshop\non Open-Ended Evolution, at ALIFE",
      "authors": "Stanley, K. O.,  and Soros, L. (2016)."
    },
    {
      "index": 171,
      "title": "Open-Ended Learning Leads to Generally Capable Agents",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv - abs/",
      "authors": "Stooke, A., Mahajan, A., Barros, C., Deck, C., Bauer, J., Sygnowski, J.,\nTrebacz, M., Jaderberg, M., Mathieu, M., et al. (2021).",
      "orig_title": "Open-ended learning leads to generally capable agents",
      "paper_id": "2107.12808v2"
    },
    {
      "index": 172,
      "title": "Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play",
      "abstract": "",
      "year": "2018",
      "venue": "Proc. of ICLR",
      "authors": "Sukhbaatar, S., Lin, Z., Kostrikov, I., Synnaeve, G., Szlam, A., and Fergus,\nR. (2018).",
      "orig_title": "Intrinsic motivation and automatic curricula via asymmetric self-play",
      "paper_id": "1703.05407v5"
    },
    {
      "index": 173,
      "title": "Reinforcement learning: An introduction",
      "abstract": "",
      "year": "2018",
      "venue": "MIT press",
      "authors": "Sutton, R. S.,  and Barto, A. G. (2018)."
    },
    {
      "index": 174,
      "title": "Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction",
      "abstract": "",
      "year": "2011",
      "venue": "The 10th International Conference on Autonomous Agents and\nMultiagent Systems-Volume 2",
      "authors": "Sutton, R. S., Modayil, J., Delp, M., Degris, T., Pilarski, P. M., White, A.,\nand Precup, D. (2011)."
    },
    {
      "index": 175,
      "title": "Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning",
      "abstract": "",
      "year": "1999",
      "venue": "",
      "authors": "Sutton, R. S., Precup, D., and Singh, S. (1999)."
    },
    {
      "index": 176,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "1998",
      "venue": "ICML, Vol. 98",
      "authors": "Sutton, R. S., Precup, D., and Singh, S. P. (1998).",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 177,
      "title": "Temporal-Difference Networks",
      "abstract": "",
      "year": "2004",
      "venue": "Saul, L., Weiss, Y., and Bottou, L. (Eds.), Advances in\nNeural Information Processing Systems, Vol. 17. MIT Press",
      "authors": "Sutton, R. S.,  and Tanner, B. (2004).",
      "orig_title": "Temporal-difference networks",
      "paper_id": "1504.05539v1"
    },
    {
      "index": 178,
      "title": "A Boolean Task Algebra For Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Tasse, G. N., James, S. D., and Rosman, B. (2020).",
      "orig_title": "A boolean task algebra for reinforcement learning",
      "paper_id": "2001.01394v2"
    },
    {
      "index": 179,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2009",
      "venue": "Journal of Machine Learning Research, 10(7)",
      "authors": "Taylor, M. E.,  and Stone, P. (2009).",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 180,
      "title": "The Cultural Origins of Human Cognition",
      "abstract": "",
      "year": "1999",
      "venue": "",
      "authors": "Tomasello, M. (1999)."
    },
    {
      "index": 181,
      "title": "Constructing a Language",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "Tomasello, M. (2009)."
    },
    {
      "index": 182,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Proc. of NeurIPS",
      "authors": "Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,\nKaiser, L., and Polosukhin, I. (2017).",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 183,
      "title": "Many-Goals Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "ArXiv - abs/",
      "authors": "Veeriah, V., Oh, J., and Singh, S. (2018).",
      "orig_title": "Many-goals reinforcement learning",
      "paper_id": "1806.09605v1"
    },
    {
      "index": 184,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Venkattaramanujam, S., Crawford, E., Doan, T., and Precup, D. (2019).",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 185,
      "title": "FeUdal Networks for Hierarchical Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "Proc. of ICML, Vol. 70",
      "authors": "Vezhnevets, A. S., Osindero, S., Schaul, T., Heess, N., Jaderberg, M., Silver,\nD., and Kavukcuoglu, K. (2017).",
      "orig_title": "Feudal networks for hierarchical reinforcement learning",
      "paper_id": "1703.01161v2"
    },
    {
      "index": 186,
      "title": "Thought and Language",
      "abstract": "",
      "year": "1934",
      "venue": "MIT press",
      "authors": "Vygotsky, L. S. (1934)."
    },
    {
      "index": 187,
      "title": "Unsupervised Control through Non-Parametric Discriminative Rewards",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of ICLR",
      "authors": "Warde-Farley, D., de Wiele, T. V., Kulkarni, T. D., Ionescu, C., Hansen, S.,\nand Mnih, V. (2019).",
      "orig_title": "Unsupervised control through non-parametric discriminative rewards",
      "paper_id": "1811.11359v1"
    },
    {
      "index": 188,
      "title": "Language, Thought, and Reality: Selected Writings of Benjamin Lee Whorf",
      "abstract": "",
      "year": "1956",
      "venue": "MIT press",
      "authors": "Whorf, B. L. (1956)."
    },
    {
      "index": 189,
      "title": "Natural evolution strategies",
      "abstract": "",
      "year": "2014",
      "venue": "The Journal of Machine Learning Research, 15(1),\n949–980",
      "authors": "Wierstra, D., Schaul, T., Glasmachers, T., Sun, Y., Peters, J., and Schmidhuber, J. (2014)."
    },
    {
      "index": 190,
      "title": "The Role of Tutoring in Problem Solving",
      "abstract": "",
      "year": "1976",
      "venue": "Journal of Child Psychology and Psychiatry, 17(2),\n89–100",
      "authors": "Wood, D., Bruner, J. S., and Ross, G. (1976)."
    },
    {
      "index": 191,
      "title": "The Laplacian in RL: Learning Representations with Efficient Approximations",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of ICLR",
      "authors": "Wu, Y., Tucker, G., and Nachum, O. (2019).",
      "orig_title": "The laplacian in RL: learning representations with efficient approximations",
      "paper_id": "1810.04586v1"
    },
    {
      "index": 192,
      "title": "Interactive Language Learning by Question Answering",
      "abstract": "",
      "year": "2019",
      "venue": "Proc. of EMNLP, pp. 2796–2813. Association for\nComputational Linguistics",
      "authors": "Yuan, X., Côté, M.-A., Fu, J., Lin, Z., Pal, C., Bengio, Y., and Trischler, A. (2019).",
      "orig_title": "Interactive language learning by question answering",
      "paper_id": "1908.10909v1"
    },
    {
      "index": 193,
      "title": "Automatic Curriculum Learning through Value Disagreement",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Zhang, Y., Abbeel, P., and Pinto, L. (2020).",
      "orig_title": "Automatic curriculum learning through value disagreement",
      "paper_id": "2006.09641v1"
    },
    {
      "index": 194,
      "title": "Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning∗",
      "abstract": "",
      "year": "2017",
      "venue": "2017 IEEE international conference on robotics and\nautomation (ICRA)",
      "authors": "Zhu, Y., Mottaghi, R., Kolve, E., Lim, J. J., Gupta, A., Fei-Fei, L., and Farhadi, A. (2017).",
      "orig_title": "Target-driven visual navigation in indoor scenes using deep reinforcement learning",
      "paper_id": "1609.05143v1"
    },
    {
      "index": 195,
      "title": "The Epigenesis of Meaning in Human Beings, and Possibly in Robots",
      "abstract": "",
      "year": "2001",
      "venue": "",
      "authors": "Zlatev, J. (2001)."
    }
  ]
}