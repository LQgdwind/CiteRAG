{
  "paper_id": "2403.08319v2",
  "title": "Knowledge Conflicts for LLMs: A Survey",
  "abstract": "Abstract\nThis survey provides an in-depth analysis of knowledge conflicts for large language models (LLMs), highlighting the complex challenges they encounter when blending contextual and parametric knowledge.\nOur focus is on three categories of knowledge conflicts: context-memory, inter-context, and intra-memory conflict. These conflicts can significantly impact the trustworthiness and performance of LLMs, especially in real-world applications where noise and misinformation are common.\nBy categorizing these conflicts, exploring the causes, examining the behaviors of LLMs under such conflicts, and reviewing available solutions, this survey aims to shed light on strategies for improving the robustness of LLMs, thereby serving as a valuable resource for advancing research in this evolving area.",
  "reference_labels": [
    {
      "index": 0,
      "title": "GPT-4 Technical Report",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph",
      "orig_title": "Gpt-4 technical report",
      "paper_id": "2303.08774v6"
    },
    {
      "index": 1,
      "title": "Explanations for CommonsenseQA: New Dataset and Models",
      "abstract": "",
      "year": "2021",
      "venue": "59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
      "authors": "Shourya Aggarwal, Divyanshu Mandowara, Vishwajeet Agrawal, Dinesh Khandelwal, Parag Singla, and Dinesh Garg"
    },
    {
      "index": 2,
      "title": "Do Language Models Know When They’re Hallucinating References?",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint",
      "authors": "Ayush Agrawal, Lester Mackey, and Adam Tauman Kalai",
      "orig_title": "Do language models know when they’re hallucinating references?",
      "paper_id": "2305.18248v3"
    },
    {
      "index": 3,
      "title": "Towards tracing knowledge in language models back to the training data",
      "abstract": "",
      "year": "2022",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022",
      "authors": "Ekin Akyürek, Tolga Bolukbasi, Frederick Liu, Binbin Xiong, Ian Tenney, Jacob Andreas, and Kelvin Guu"
    },
    {
      "index": 4,
      "title": "Flamingo: a visual language model for few-shot learning",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in neural information processing systems",
      "authors": "Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al."
    },
    {
      "index": 5,
      "title": "The Looming Threat of Fake and LLM-generated LinkedIn Profiles: Challenges and Opportunities for Detection and Prevention",
      "abstract": "",
      "year": "2023",
      "venue": "34th ACM Conference on Hypertext and Social Media",
      "authors": "Navid Ayoobi, Sadat Shahriar, and Arjun Mukherjee",
      "orig_title": "The looming threat of fake and llm-generated linkedin profiles: Challenges and opportunities for detection and prevention",
      "paper_id": "2307.11864v1"
    },
    {
      "index": 6,
      "title": "Identifying and Mitigating the Security Risks of Generative AI",
      "abstract": "",
      "year": "2023",
      "venue": "Foundations and Trends® in Privacy and Security",
      "authors": "Clark Barrett, Brad Boyd, Elie Bursztein, Nicholas Carlini, Brad Chen, Jihye Choi, Amrita Roy Chowdhury, Mihai Christodorescu, Anupam Datta, Soheil Feizi, et al.",
      "orig_title": "Identifying and mitigating the security risks of generative ai",
      "paper_id": "2308.14840v4"
    },
    {
      "index": 7,
      "title": "Self-Consistency of Large Language Models under Ambiguity",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint",
      "authors": "Henning Bartsch, Ole Jorgensen, Domenic Rosati, Jason Hoelscher-Obermaier, and Jacob Pfau",
      "orig_title": "Self-consistency of large language models under ambiguity",
      "paper_id": "2310.13439v1"
    },
    {
      "index": 8,
      "title": "On the dangers of stochastic parrots: Can language models be too big?",
      "abstract": "",
      "year": "2021",
      "venue": "2021 ACM conference on fairness, accountability, and transparency",
      "authors": "Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell"
    },
    {
      "index": 9,
      "title": "Managing AI Risks in an Era of Rapid Progress",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint",
      "authors": "Yoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Yuval Noah Harari, Ya-Qin Zhang, Lan Xue, Shai Shalev-Shwartz, Gillian Hadfield, et al.",
      "orig_title": "Managing ai risks in an era of rapid progress",
      "paper_id": "2310.17688v3"
    },
    {
      "index": 10,
      "title": "SubjQA: A Dataset for Subjectivity and Review Comprehension",
      "abstract": "",
      "year": "2020",
      "venue": "2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "authors": "Johannes Bjerva, Nikita Bhutani, Behzad Golshan, Wang-Chiew Tan, and Isabelle Augenstein",
      "orig_title": "SubjQA: A Dataset for Subjectivity and Review Comprehension",
      "paper_id": "2004.14283v3"
    },
    {
      "index": 11,
      "title": "Improving language models by retrieving from trillions of tokens",
      "abstract": "",
      "year": "2022",
      "venue": "International conference on machine learning",
      "authors": "Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. 2022.",
      "orig_title": "Improving language models by retrieving from trillions of tokens",
      "paper_id": "2112.04426v3"
    },
    {
      "index": 12,
      "title": "AudioLM: a Language Modeling Approach to Audio Generation",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
      "authors": "Zalán Borsos, Raphaël Marinier, Damien Vincent, Eugene Kharitonov, Olivier Pietquin, Matt Sharifi, Dominik Roblek, Olivier Teboul, David Grangier, Marco Tagliasacchi, et al. 2023.",
      "orig_title": "Audiolm: a language modeling approach to audio generation",
      "paper_id": "2209.03143v2"
    },
    {
      "index": 13,
      "title": "Language Models are Few-Shot Learners",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
      "authors": "",
      "orig_title": "Language models are few-shot learners",
      "paper_id": "2005.14165v4"
    },
    {
      "index": 14,
      "title": "On the application of Large Language Models for language teaching and assessment technology",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Andrew Caines, Luca Benedetto, Shiva Taslimipoor, Christopher Davis, Yuan Gao, Oeistein Andersen, Zheng Yuan, Mark Elliott, Russell Moore, Christopher Bryant, et al. 2023.",
      "orig_title": "On the application of large language models for language teaching and assessment technology",
      "paper_id": "2307.08393v1"
    },
    {
      "index": 15,
      "title": "Poisoning Web-Scale Training Datasets is Practical",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Nicholas Carlini, Matthew Jagielski, Christopher A Choquette-Choo, Daniel Paleka, Will Pearce, Hyrum Anderson, Andreas Terzis, Kurt Thomas, and Florian Tramèr. 2023.",
      "orig_title": "Poisoning web-scale training datasets is practical",
      "paper_id": "2302.10149v2"
    },
    {
      "index": 16,
      "title": "Language Model Behavior: A Comprehensive Survey",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Tyler A Chang and Benjamin K Bergen. 2023.",
      "orig_title": "Language model behavior: A comprehensive survey",
      "paper_id": "2303.11504v2"
    },
    {
      "index": 17,
      "title": "Can LMs Generalize to Future Data? An Empirical Analysis on Text Summarization",
      "abstract": "",
      "year": "2023",
      "venue": "Proceedings of the",
      "authors": "Chi Cheang, Hou Chan, Derek Wong, Xuebo Liu, Zhaocong Li, Yanming Sun, Shudong Liu, and Lidia Chao. 2023.",
      "orig_title": "Can lms generalize to future data? an empirical analysis on text summarization",
      "paper_id": "2305.01951v3"
    },
    {
      "index": 18,
      "title": "Can LLM-Generated Misinformation Be Detected?",
      "abstract": "",
      "year": "2023",
      "venue": "NeurIPS",
      "authors": "Canyu Chen and Kai Shu. 2023a.",
      "orig_title": "Can llm-generated misinformation be detected?",
      "paper_id": "2309.13788v5"
    },
    {
      "index": 19,
      "title": "Combating Misinformation in the Age of LLMs: Opportunities and Challenges",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Canyu Chen and Kai Shu. 2023b.",
      "orig_title": "Combating misinformation in the age of llms: Opportunities and challenges",
      "paper_id": "2311.05656v1"
    },
    {
      "index": 20,
      "title": "Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Hung-Ting Chen, Michael JQ Zhang, and Eunsol Choi. 2022.",
      "orig_title": "Rich knowledge sources bring complex knowledge conflicts: Recalibrating models to reflect conflicting evidence",
      "paper_id": "2210.13701v1"
    },
    {
      "index": 21,
      "title": "Say what you mean! large language models speak too positively about negative commonsense knowledge",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jiangjie Chen, Wei Shi, Ziquan Fu, Sijie Cheng, Lei Li, and Yanghua Xiao. 2023a."
    },
    {
      "index": 22,
      "title": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun. 2023b.",
      "orig_title": "Benchmarking large language models in retrieval-augmented generation",
      "paper_id": "2309.01431v2"
    },
    {
      "index": 23,
      "title": "Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators",
      "abstract": "",
      "year": "2023",
      "venue": "Proceedings of the",
      "authors": "Liang Chen, Yang Deng, Yatao Bian, Zeyu Qin, Bingzhe Wu, Tat-Seng Chua, and Kam-Fai Wong. 2023c.",
      "orig_title": "Beyond factuality: A comprehensive evaluation of large language models as knowledge generators",
      "paper_id": "2310.07289v1"
    },
    {
      "index": 24,
      "title": "A Dataset for Answering Time-Sensitive Questions",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv preprint, abs/",
      "authors": "Wenhu Chen, Xinyi Wang, and William Yang Wang. 2021.",
      "orig_title": "A dataset for answering time-sensitive questions",
      "paper_id": "2108.06314v5"
    },
    {
      "index": 25,
      "title": "FacTool: Factuality Detection in Generative AI A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "I Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu, et al. 2023.",
      "orig_title": "Factool: Factuality detection in generative ai–a tool augmented framework for multi-task and multi-domain scenarios",
      "paper_id": "2307.13528v2"
    },
    {
      "index": 26,
      "title": "Factllama: Optimizing instruction-following language models with external knowledge for automated fact-checking",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Tsun-Hin Cheung and Kin-Man Lam. 2023."
    },
    {
      "index": 27,
      "title": "PaLM: Scaling Language Modeling with Pathways",
      "abstract": "",
      "year": "2023",
      "venue": "Journal of Machine Learning Research, 24(240):1–113",
      "authors": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2023.",
      "orig_title": "Palm: Scaling language modeling with pathways",
      "paper_id": "2204.02311v5"
    },
    {
      "index": 28,
      "title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James Glass, and Pengcheng He. 2023.",
      "orig_title": "Dola: Decoding by contrasting layers improves factuality in large language models",
      "paper_id": "2309.03883v2"
    },
    {
      "index": 29,
      "title": "Summing up the facts: Additive mechanisms behind factual recall in llms",
      "abstract": "",
      "year": "2024",
      "venue": "ArXiv preprint, abs/",
      "authors": "Bilal Chughtai, Alan Cooney, and Neel Nanda. 2024."
    },
    {
      "index": 30,
      "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the",
      "authors": "Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. 2019.",
      "orig_title": "BoolQ: Exploring the surprising difficulty of natural yes/no questions",
      "paper_id": "1905.10044v1"
    },
    {
      "index": 31,
      "title": "Does bert solve commonsense task via commonsense knowledge",
      "abstract": "",
      "year": "2008",
      "venue": "ArXiv preprint, abs/",
      "authors": "Leyang Cui, Sijie Cheng, Yu Wu, and Yue Zhang. 2020."
    },
    {
      "index": 32,
      "title": "Editing Factual Knowledge in Language Models",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the",
      "authors": "Nicola De Cao, Wilker Aziz, and Ivan Titov. 2021.",
      "orig_title": "Editing factual knowledge in language models",
      "paper_id": "2104.08164v2"
    },
    {
      "index": 33,
      "title": "A continual learning survey: Defying forgetting in classification tasks",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE transactions on pattern analysis and machine intelligence, 44(7):",
      "authors": "Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. 2021.",
      "orig_title": "A continual learning survey: Defying forgetting in classification tasks",
      "paper_id": "1909.08383v3"
    },
    {
      "index": 34,
      "title": "Cross-lingual evidence improves monolingual fake news detection",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop",
      "authors": "Daryna Dementieva and Alexander Panchenko. 2021."
    },
    {
      "index": 35,
      "title": "Time-Aware Language Models as Temporal Knowledge Bases",
      "abstract": "",
      "year": "2022",
      "venue": "Transactions of the Association for Computational Linguistics, 10:257–273",
      "authors": "Bhuwan Dhingra, Jeremy R Cole, Julian Martin Eisenschlos, Daniel Gillick, Jacob Eisenstein, and William W Cohen. 2022.",
      "orig_title": "Time-aware language models as temporal knowledge bases",
      "paper_id": "2106.15110v2"
    },
    {
      "index": 36,
      "title": "Chain-of-Verification Reduces Hallucination in Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. 2023.",
      "orig_title": "Chain-of-verification reduces hallucination in large language models",
      "paper_id": "2309.11495v2"
    },
    {
      "index": 37,
      "title": "Statistical Knowledge Assessment for Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "Thirty-seventh Conference on Neural Information Processing Systems",
      "authors": "Qingxiu Dong, Jingjing Xu, Lingpeng Kong, Zhifang Sui, and Lei Li. 2023.",
      "orig_title": "Statistical knowledge assessment for large language models",
      "paper_id": "2305.10519v2"
    },
    {
      "index": 38,
      "title": "e-CARE: a New Dataset for Exploring Explainable Causal Reasoning",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
      "authors": "Li Du, Xiao Ding, Kai Xiong, Ting Liu, and Bing Qin. 2022a.",
      "orig_title": "e-care: a new dataset for exploring explainable causal reasoning",
      "paper_id": "2205.05849v1"
    },
    {
      "index": 39,
      "title": "Synthetic disinformation attacks on automated fact verification systems",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 36",
      "authors": "Yibing Du, Antoine Bosselut, and Christopher D Manning. 2022b."
    },
    {
      "index": 40,
      "title": "Neural path hunter: Reducing hallucination in dialogue systems via path grounding",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv preprint, abs/",
      "authors": "Nouha Dziri, Andrea Madotto, Osmar Zaiane, and Avishek Joey Bose. 2021."
    },
    {
      "index": 41,
      "title": "Measuring causal effects of data statistics on language model’sfactual’predictions",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yanai Elazar, Nora Kassner, Shauli Ravfogel, Amir Feder, Abhilasha Ravichander, Marius Mosbach, Yonatan Belinkov, Hinrich Schütze, and Yoav Goldberg. 2022."
    },
    {
      "index": 42,
      "title": "Measuring and Improving Consistency in Pretrained Language Models",
      "abstract": "",
      "year": "2021",
      "venue": "Transactions of the Association for Computational Linguistics, 9:",
      "authors": "Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich Schütze, and Yoav Goldberg. 2021.",
      "orig_title": "Measuring and improving consistency in pretrained language models",
      "paper_id": "2102.01017v2"
    },
    {
      "index": 43,
      "title": "T-REx: A large scale alignment of natural language with knowledge base triples",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC",
      "authors": "Hady Elsahar, Pavlos Vougiouklis, Arslen Remaci, Christophe Gravier, Jonathon Hare, Frederique Laforest, and Elena Simperl. 2018."
    },
    {
      "index": 44,
      "title": "Hierarchical neural story generation",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
      "authors": "Angela Fan, Mike Lewis, and Yann Dauphin. 2018."
    },
    {
      "index": 45,
      "title": "Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Zhangyin Feng, Weitao Ma, Weijiang Yu, Lei Huang, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al. 2023.",
      "orig_title": "Trends in integration of knowledge and large language models: A survey and taxonomy of methods, benchmarks, and applications",
      "paper_id": "2311.05876v3"
    },
    {
      "index": 46,
      "title": "GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Emilio Ferrara. 2023.",
      "orig_title": "Genai against humanity: Nefarious applications of generative artificial intelligence and large language models",
      "paper_id": "2310.00737v3"
    },
    {
      "index": 47,
      "title": "Ai as agency without intelligence: on chatgpt, large language models, and other generative models",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Luciano Floridi. 2023."
    },
    {
      "index": 48,
      "title": "The battlefront of combating misinformation and coping with media bias",
      "abstract": "",
      "year": "2022",
      "venue": "Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining",
      "authors": "Yi R Fung, Kung-Hsiang Huang, Preslav Nakov, and Heng Ji. 2022."
    },
    {
      "index": 49,
      "title": "RARR: Researching and Revising What Language Models Say, Using Language Models",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
      "authors": "Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, et al. 2023a.",
      "orig_title": "Rarr: Researching and revising what language models say, using language models",
      "paper_id": "2210.08726v3"
    },
    {
      "index": 50,
      "title": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 2023b.",
      "orig_title": "Retrieval-augmented generation for large language models: A survey",
      "paper_id": "2312.10997v5"
    },
    {
      "index": 51,
      "title": "Trueteacher: Learning factual consistency evaluation with large language models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Zorik Gekhman, Jonathan Herzig, Roee Aharoni, Chen Elkind, and Idan Szpektor. 2023."
    },
    {
      "index": 52,
      "title": "Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies",
      "abstract": "",
      "year": "2021",
      "venue": "Transactions of the Association for Computational Linguistics, 9:346–361",
      "authors": "Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021.",
      "orig_title": "Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies",
      "paper_id": "2101.02235v1"
    },
    {
      "index": 53,
      "title": "Generative language models and automated influence operations: Emerging threats and potential mitigations",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Josh A Goldstein, Girish Sastry, Micah Musser, Renee DiResta, Matthew Gentzel, and Katerina Sedova. 2023."
    },
    {
      "index": 54,
      "title": "More than you’ve asked for: A comprehensive analysis of novel prompt injection threats to application-integrated large language models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv e-prints",
      "authors": "Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario Fritz. 2023."
    },
    {
      "index": 55,
      "title": "Studying large language model generalization with influence functions",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Roger Grosse, Juhan Bae, Cem Anil, Nelson Elhage, Alex Tamkin, Amirhossein Tajdini, Benoit Steiner, Dustin Li, Esin Durmus, Ethan Perez, et al. 2023."
    },
    {
      "index": 56,
      "title": "A survey on automated fact-checking",
      "abstract": "",
      "year": "2022",
      "venue": "Transactions of the Association for Computational Linguistics, 10:178–206",
      "authors": "Zhijiang Guo, Michael Schlichtkrull, and Andreas Vlachos. 2022."
    },
    {
      "index": 57,
      "title": "Retrieval augmented language model pre-training",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the 37th International Conference on Machine Learning, ICML",
      "authors": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020."
    },
    {
      "index": 58,
      "title": "Methods for measuring, updating, and visualizing factual beliefs in language models",
      "abstract": "",
      "year": "2023",
      "venue": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
      "authors": "Peter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin Stoyanov, Mohit Bansal, and Srinivasan Iyer. 2023."
    },
    {
      "index": 59,
      "title": "Analyzing the Forgetting Problem in Pretrain-Finetuning of Open-domain Dialogue Response Models",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
      "authors": "Tianxing He, Jun Liu, Kyunghyun Cho, Myle Ott, Bing Liu, James Glass, and Fuchun Peng. 2021.",
      "orig_title": "Analyzing the forgetting problem in pretrain-finetuning of open-domain dialogue response models",
      "paper_id": "1910.07117v5"
    },
    {
      "index": 60,
      "title": "Teaching machines to read and comprehend",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems",
      "authors": "Karl Moritz Hermann, Tomás Kociský, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. 2015."
    },
    {
      "index": 61,
      "title": "Training Compute-Optimal Large Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. 2022.",
      "orig_title": "Training compute-optimal large language models",
      "paper_id": "2203.15556v1"
    },
    {
      "index": 62,
      "title": "The curious case of neural text degeneration",
      "abstract": "",
      "year": "2020",
      "venue": "8th International Conference on Learning Representations, ICLR",
      "authors": "Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020."
    },
    {
      "index": 63,
      "title": "Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Giwon Hong, Jeonghwan Kim, Junmo Kang, Sung-Hyon Myaeng, and Joyce Jiyoung Whang. 2023.",
      "orig_title": "Discern and answer: Mitigating the impact of misinformation in retrieval-augmented models with discriminators",
      "paper_id": "2305.01579v3"
    },
    {
      "index": 64,
      "title": "WikiContradiction: Detecting Self-Contradiction Articles on Wikipedia",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Cheng Hsu, Cheng-Te Li, Diego Saez-Trumper, and Yi-Zhan Hsu. 2021.",
      "orig_title": "Wikicontradiction: Detecting self-contradiction articles on wikipedia",
      "paper_id": "2111.08543v1"
    },
    {
      "index": 65,
      "title": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al. 2023.",
      "orig_title": "A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions",
      "paper_id": "2311.05232v2"
    },
    {
      "index": 66,
      "title": "Editing Models with Task Arithmetic",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Suchin Gururangan, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi. 2022.",
      "orig_title": "Editing models with task arithmetic",
      "paper_id": "2212.04089v3"
    },
    {
      "index": 67,
      "title": "Temporalwiki: A lifelong benchmark for training and evaluating ever-evolving language models",
      "abstract": "",
      "year": "2022",
      "venue": "Proceedings of the",
      "authors": "Joel Jang, Seonghyeon Ye, Changho Lee, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun Kim, and Minjoon Seo. 2022."
    },
    {
      "index": 68,
      "title": "Towards continual knowledge learning of language models",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Learning Representations",
      "authors": "Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, KIM Gyeonghun, Stanley Jungkyu Choi, and Minjoon Seo. 2021."
    },
    {
      "index": 69,
      "title": "Improving Language Models’ Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Myeongjun Erik Jang and Thomas Lukasiewicz. 2023.",
      "orig_title": "Improving language models meaning understanding and consistency by learning conceptual roles from dictionary",
      "paper_id": "2310.15541v1"
    },
    {
      "index": 70,
      "title": "Automatic Detection of Machine Generated Text: A Critical Survey",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the 28th International Conference on Computational Linguistics",
      "authors": "Ganesh Jawahar, Muhammad Abdul-Mageed, and Laks Lakshmanan, V.S. 2020.",
      "orig_title": "Automatic detection of machine generated text: A critical survey",
      "paper_id": "2011.01314v1"
    },
    {
      "index": 71,
      "title": "What does BERT learn about the structure of language?",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "authors": "Ganesh Jawahar, Benoît Sagot, and Djamé Seddah. 2019."
    },
    {
      "index": 72,
      "title": "Survey of Hallucination in Natural Language Generation",
      "abstract": "",
      "year": "2023",
      "venue": "ACM Computing Surveys, 55(12):1–38",
      "authors": "Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023.",
      "orig_title": "Survey of hallucination in natural language generation",
      "paper_id": "2202.03629v7"
    },
    {
      "index": 73,
      "title": "Disinformation Detection: An Evolving Challenge in the Age of LLMs",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Bohan Jiang, Zhen Tan, Ayushi Nirmal, and Huan Liu. 2023.",
      "orig_title": "Disinformation detection: An evolving challenge in the age of llms",
      "paper_id": "2309.15847v1"
    },
    {
      "index": 74,
      "title": "Tug-of-War Between Knowledge: Exploring and Resolving Knowledge Conflicts in Retrieval-Augmented Language Models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Xiaojian Jiang, Jiexin Xu, Qiuxia Li, and Jun Zhao. 2024a.",
      "orig_title": "Tug-of-war between knowledge: Exploring and resolving knowledge conflicts in retrieval-augmented language models",
      "paper_id": "2402.14409v1"
    },
    {
      "index": 75,
      "title": "Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Zhuoran Jin, Pengfei Cao, Hongbang Yuan, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, and Jun Zhao. 2024b.",
      "orig_title": "Cutting off the head ends the conflict: A mechanism for interpreting and mitigating knowledge conflicts in language models",
      "paper_id": "2402.18154v1"
    },
    {
      "index": 76,
      "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
      "abstract": "",
      "year": "2017",
      "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
      "authors": "Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. 2017.",
      "orig_title": "TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension",
      "paper_id": "1705.03551v2"
    },
    {
      "index": 77,
      "title": "Prompting Visual-Language Models for Efficient Video Understanding",
      "abstract": "",
      "year": "2022",
      "venue": "European Conference on Computer Vision",
      "authors": "Chen Ju, Tengda Han, Kunhao Zheng, Ya Zhang, and Weidi Xie. 2022.",
      "orig_title": "Prompting visual-language models for efficient video understanding",
      "paper_id": "2112.04478v2"
    },
    {
      "index": 78,
      "title": "Challenges and Applications of Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy. 2023.",
      "orig_title": "Challenges and applications of large language models",
      "paper_id": "2307.10169v1"
    },
    {
      "index": 79,
      "title": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "abstract": "",
      "year": "2023",
      "venue": "International Conference on Machine Learning",
      "authors": "Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. 2023.",
      "orig_title": "Large language models struggle to learn long-tail knowledge",
      "paper_id": "2211.08411v2"
    },
    {
      "index": 80,
      "title": "Impact of Co-occurrence on Factual Knowledge of Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Cheongwoong Kang and Jaesik Choi. 2023.",
      "orig_title": "Impact of co-occurrence on factual knowledge of large language models",
      "paper_id": "2310.08256v1"
    },
    {
      "index": 81,
      "title": "Dense Passage Retrieval for Open-Domain Question Answering",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the",
      "authors": "Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020.",
      "orig_title": "Dense passage retrieval for open-domain question answering",
      "paper_id": "2004.04906v3"
    },
    {
      "index": 82,
      "title": "RealTime QA: What’s the Answer Right Now?",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jungo Kasai, Keisuke Sakaguchi, Yoichi Takahashi, Ronan Le Bras, Akari Asai, Xinyan Yu, Dragomir Radev, Noah A Smith, Yejin Choi, and Kentaro Inui. 2022.",
      "orig_title": "Realtime qa: What’s the answer right now?",
      "paper_id": "2207.13332v2"
    },
    {
      "index": 83,
      "title": "How ai can distort human beliefs",
      "abstract": "",
      "year": "2023",
      "venue": "Science, 380(",
      "authors": "Celeste Kidd and Abeba Birhane. 2023."
    },
    {
      "index": 84,
      "title": "ClaimDiff: Comparing and Contrasting Claims on Contentious Issues",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Miyoung Ko, Ingyu Seong, Hwaran Lee, Joonsuk Park, Minsuk Chang, and Minjoon Seo. 2022.",
      "orig_title": "Claimdiff: Comparing and contrasting claims on contentious issues",
      "paper_id": "2205.12221v2"
    },
    {
      "index": 85,
      "title": "The NarrativeQA Reading Comprehension Challenge",
      "abstract": "",
      "year": "2018",
      "venue": "Transactions of the Association for Computational Linguistics, 6:317–328",
      "authors": "Tomáš Kočiský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, and Edward Grefenstette. 2018.",
      "orig_title": "The NarrativeQA reading comprehension challenge",
      "paper_id": "1712.07040v1"
    },
    {
      "index": 86,
      "title": "False Information on Web and Social Media: A Survey",
      "abstract": "",
      "year": "2018",
      "venue": "ArXiv preprint, abs/",
      "authors": "Srijan Kumar and Neil Shah. 2018.",
      "orig_title": "False information on web and social media: A survey",
      "paper_id": "1804.08559v1"
    },
    {
      "index": 87,
      "title": "Natural questions: A benchmark for question answering research",
      "abstract": "",
      "year": "2019",
      "venue": "Transactions of the Association for Computational Linguistics, 7:452–466",
      "authors": "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019."
    },
    {
      "index": 88,
      "title": "Analyzing the Use of Influence Functions for Instance-Specific Data Filtering in Neural Machine Translation",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Tsz Kin Lam, Eva Hasler, and Felix Hieber. 2022.",
      "orig_title": "Analyzing the use of influence functions for instance-specific data filtering in neural machine translation",
      "paper_id": "2210.13281v1"
    },
    {
      "index": 89,
      "title": "Internet-augmented language models through few-shot prompting for open-domain question answering",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Angeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. 2022.",
      "orig_title": "Internet-augmented language models through few-shot prompting for open-domain question answering",
      "paper_id": "2203.05115v2"
    },
    {
      "index": 90,
      "title": "Mind the Gap: Assessing Temporal Generalization in Neural Language Models",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems, 34:",
      "authors": "Angeliki Lazaridou, Adhi Kuncoro, Elena Gribovskaya, Devang Agrawal, Adam Liska, Tayfun Terzi, Mai Gimenez, Cyprien de Masson d’Autume, Tomas Kocisky, Sebastian Ruder, et al. 2021.",
      "orig_title": "Mind the gap: Assessing temporal generalization in neural language models",
      "paper_id": "2102.01951v2"
    },
    {
      "index": 91,
      "title": "Plug-and-Play Adaptation for Continuously-updated QA",
      "abstract": "",
      "year": "2022",
      "venue": "Findings of the Association for Computational Linguistics: ACL",
      "authors": "Kyungjae Lee, Wookje Han, Seung-won Hwang, Hwaran Lee, Joonsuk Park, and Sang-Woo Lee. 2022a.",
      "orig_title": "Plug-and-play adaptation for continuously-updated qa",
      "paper_id": "2204.12785v1"
    },
    {
      "index": 92,
      "title": "Factuality Enhanced Language Models for Open-Ended Text Generation",
      "abstract": "",
      "year": "",
      "venue": "Advances in Neural Information Processing Systems, 35:",
      "authors": "Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pascale N Fung, Mohammad Shoeybi, and Bryan Catanzaro. 2022b.",
      "orig_title": "Factuality enhanced language models for open-ended text generation",
      "paper_id": "2206.04624v3"
    },
    {
      "index": 93,
      "title": "Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "João A Leite, Olesya Razuvayevskaya, Kalina Bontcheva, and Carolina Scarton. 2023.",
      "orig_title": "Detecting misinformation with llm-predicted credibility signals and weak supervision",
      "paper_id": "2309.07601v3"
    },
    {
      "index": 94,
      "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
      "authors": "Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020.",
      "orig_title": "Retrieval-augmented generation for knowledge-intensive NLP tasks",
      "paper_id": "2005.11401v4"
    },
    {
      "index": 95,
      "title": "Large Language Models with Controllable Working Memory",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Daliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin Wang, Michal Lukasik, Andreas Veit, Felix Yu, and Sanjiv Kumar. 2022a.",
      "orig_title": "Large language models with controllable working memory",
      "paper_id": "2211.05110v1"
    },
    {
      "index": 96,
      "title": "Contradoc: Understanding self-contradictions in documents with large language models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jierui Li, Vipul Raheja, and Dhruv Kumar. 2023a."
    },
    {
      "index": 97,
      "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "International conference on machine learning",
      "authors": "Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. 2023b.",
      "orig_title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models",
      "paper_id": "2301.12597v3"
    },
    {
      "index": 98,
      "title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, and Martin Wattenberg. 2023c.",
      "orig_title": "Inference-time intervention: Eliciting truthful answers from a language model",
      "paper_id": "2306.03341v6"
    },
    {
      "index": 99,
      "title": "How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Shaobo Li, Xiaoguang Li, Lifeng Shang, Zhenhua Dong, Chengjie Sun, Bingquan Liu, Zhenzhou Ji, Xin Jiang, and Qun Liu. 2022b.",
      "orig_title": "How pre-trained language models capture factual knowledge? a causal-inspired analysis",
      "paper_id": "2203.16747v1"
    },
    {
      "index": 100,
      "title": "Contrastive Decoding: Open-ended Text Generation as Optimization",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Xiang Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori Hashimoto, Luke Zettlemoyer, and Mike Lewis. 2022c.",
      "orig_title": "Contrastive decoding: Open-ended text generation as optimization",
      "paper_id": "2210.15097v2"
    },
    {
      "index": 101,
      "title": "Benchmarking and improving generator-validator consistency of language models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Xiang Lisa Li, Vaishnavi Shrivastava, Siyan Li, Tatsunori Hashimoto, and Percy Liang. 2023d."
    },
    {
      "index": 102,
      "title": "Large Language Models in Finance: A Survey",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the Fourth ACM International Conference on AI in Finance",
      "authors": "Yinheng Li, Shaofei Wang, Han Ding, and Hang Chen. 2023e.",
      "orig_title": "Large language models in finance: A survey",
      "paper_id": "2311.10723v2"
    },
    {
      "index": 103,
      "title": "Unveiling the Pitfalls of Knowledge Editing for Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Zhoubo Li, Ningyu Zhang, Yunzhi Yao, Mengru Wang, Xi Chen, and Huajun Chen. 2023f.",
      "orig_title": "Unveiling the pitfalls of knowledge editing for large language models",
      "paper_id": "2310.02129v5"
    },
    {
      "index": 104,
      "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods",
      "abstract": "",
      "year": "2022",
      "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
      "authors": "Stephanie Lin, Jacob Hilton, and Owain Evans. 2022.",
      "orig_title": "Truthfulqa: Measuring how models mimic human falsehoods",
      "paper_id": "2109.07958v2"
    },
    {
      "index": 105,
      "title": "StreamingQA: A Benchmark for Adaptation to New Knowledge over Time in Question Answering Models",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "authors": "Adam Liska, Tomas Kocisky, Elena Gribovskaya, Tayfun Terzi, Eren Sezener, Devang Agrawal, D’Autume Cyprien De Masson, Tim Scholtes, Manzil Zaheer, Susannah Young, et al. 2022.",
      "orig_title": "Streamingqa: A benchmark for adaptation to new knowledge over time in question answering models",
      "paper_id": "2205.11388v1"
    },
    {
      "index": 106,
      "title": "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
      "abstract": "",
      "year": "",
      "venue": "ACM Computing Surveys, 55(9):1–35",
      "authors": "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023a."
    },
    {
      "index": 107,
      "title": "Prompt Injection attack against LLM-integrated Applications",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, and Yang Liu. 2023b.",
      "orig_title": "Prompt injection attack against llm-integrated applications",
      "paper_id": "2306.05499v2"
    },
    {
      "index": 108,
      "title": "Entity-Based Knowledge Conflicts in Question Answering",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the",
      "authors": "Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, and Sameer Singh. 2021.",
      "orig_title": "Entity-based knowledge conflicts in question answering",
      "paper_id": "2109.05052v2"
    },
    {
      "index": 109,
      "title": "Time waits for no one! analysis and challenges of temporal misalignment",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv preprint, abs/",
      "authors": "Kelvin Luu, Daniel Khashabi, Suchin Gururangan, Karishma Mandyam, and Noah A Smith. 2021."
    },
    {
      "index": 110,
      "title": "When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Hannaneh Hajishirzi, and Daniel Khashabi. 2022."
    },
    {
      "index": 111,
      "title": "When not to trust language models: Investigating effectiveness of parametric and non-parametric memories",
      "abstract": "",
      "year": "2023",
      "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
      "authors": "Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. 2023."
    },
    {
      "index": 112,
      "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Potsawee Manakul, Adian Liusie, and Mark JF Gales. 2023.",
      "orig_title": "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models",
      "paper_id": "2303.08896v3"
    },
    {
      "index": 113,
      "title": "Dynamic Benchmarking of Masked Language Models on Temporal Concept Drift with Multiple Views",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Katerina Margatina, Shuai Wang, Yogarshi Vyas, Neha Anna John, Yassine Benajiba, and Miguel Ballesteros. 2023.",
      "orig_title": "Dynamic benchmarking of masked language models on temporal concept drift with multiple views",
      "paper_id": "2302.12297v1"
    },
    {
      "index": 114,
      "title": "Better Call GPT, Comparing Large Language Models Against Lawyers",
      "abstract": "",
      "year": "2024",
      "venue": "ArXiv preprint, abs/",
      "authors": "Lauren Martin, Nick Whitehouse, Stephanie Yiu, Lizzie Catterson, and Rivindu Perera. 2024.",
      "orig_title": "Better call gpt, comparing large language models against lawyers",
      "paper_id": "2401.16212v1"
    },
    {
      "index": 115,
      "title": "How Decoding Strategies Affect the Verifiability of Generated Text",
      "abstract": "",
      "year": "2020",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP",
      "authors": "Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktäschel, Vassilis Plachouras, Fabrizio Silvestri, and Sebastian Riedel. 2020.",
      "orig_title": "How decoding strategies affect the verifiability of generated text",
      "paper_id": "1911.03587v2"
    },
    {
      "index": 116,
      "title": "Fake news, rumor, information pollution in social media and web: A contemporary survey of state-of-the-arts, challenges and opportunities",
      "abstract": "",
      "year": "2020",
      "venue": "Expert Systems with Applications, 153:",
      "authors": "Priyanka Meel and Dinesh Kumar Vishwakarma. 2020."
    },
    {
      "index": 117,
      "title": "Addressing the harms of ai-generated inauthentic content",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Filippo Menczer, David Crandall, Yong-Yeol Ahn, and Apu Kapadia. 2023."
    },
    {
      "index": 118,
      "title": "Locating and Editing Factual Associations in GPT",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems, 35:",
      "authors": "Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. 2022.",
      "orig_title": "Locating and editing factual associations in gpt",
      "paper_id": "2202.05262v5"
    },
    {
      "index": 119,
      "title": "Pointer Sentinel Mixture Models",
      "abstract": "",
      "year": "2017",
      "venue": "5th International Conference on Learning Representations, ICLR",
      "authors": "Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. 2017.",
      "orig_title": "Pointer sentinel mixture models",
      "paper_id": "1609.07843v1"
    },
    {
      "index": 120,
      "title": "Large language models challenge the future of higher education",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Silvia Milano, Joshua A McGrane, and Sabina Leonelli. 2023."
    },
    {
      "index": 121,
      "title": "Fast model editing at scale",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv preprint, abs/",
      "authors": "Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher D Manning. 2021."
    },
    {
      "index": 122,
      "title": "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Eric Mitchell, Joseph J Noh, Siyan Li, William S Armstrong, Ananth Agarwal, Patrick Liu, Chelsea Finn, and Christopher D Manning. 2022.",
      "orig_title": "Enhancing self-consistency and performance of pre-trained language models through natural language inference",
      "paper_id": "2211.11875v1"
    },
    {
      "index": 123,
      "title": "Self-contradictory hallucinations of large language models: Evaluation, detection and mitigation",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Niels Mündler, Jingxuan He, Slobodan Jenko, and Martin Vechev. 2023."
    },
    {
      "index": 124,
      "title": "A Comprehensive Overview of Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Humza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Nick Barnes, and Ajmal Mian. 2023.",
      "orig_title": "A comprehensive overview of large language models",
      "paper_id": "2307.06435v10"
    },
    {
      "index": 125,
      "title": "DisentQA: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Ella Neeman, Roee Aharoni, Or Honovich, Leshem Choshen, Idan Szpektor, and Omri Abend. 2022.",
      "orig_title": "Disentqa: Disentangling parametric and contextual knowledge with counterfactual question answering",
      "paper_id": "2211.05655v1"
    },
    {
      "index": 126,
      "title": "Confirmation bias: A ubiquitous phenomenon in many guises",
      "abstract": "",
      "year": "1998",
      "venue": "",
      "authors": "Raymond S Nickerson. 1998."
    },
    {
      "index": 127,
      "title": "Separating form and meaning: Using self-consistency to quantify task understanding across multiple senses",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Xenia Ohmer, Elia Bruni, and Dieuwke Hupkes. 2023.",
      "orig_title": "Separating form and meaning: Using self-consistency to quantify task understanding across multiple senses",
      "paper_id": "2305.11662v3"
    },
    {
      "index": 128,
      "title": "Can LMs Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yasumasa Onoe, Michael JQ Zhang, Shankar Padmanabhan, Greg Durrett, and Eunsol Choi. 2023.",
      "orig_title": "Can lms learn new entities from descriptions? challenges in propagating injected knowledge",
      "paper_id": "2305.01651v1"
    },
    {
      "index": 129,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "OpenAI. 2023.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 130,
      "title": "Training language models to follow instructions with human feedback",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems, 35:",
      "authors": "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022."
    },
    {
      "index": 131,
      "title": "Attacking Open-domain Question Answering by Injecting Misinformation",
      "abstract": "",
      "year": "",
      "venue": "IJCNLP-AACL. ACL",
      "authors": "Liangming Pan, Wenhu Chen, Min-Yen Kan, and William Yang Wang. 2023a.",
      "orig_title": "Attacking open-domain question answering by injecting misinformation",
      "paper_id": "2110.07803v3"
    },
    {
      "index": 132,
      "title": "Knowledge-in-context: Towards knowledgeable semi-parametric language models",
      "abstract": "",
      "year": "2022",
      "venue": "The Eleventh International Conference on Learning Representations",
      "authors": "Xiaoman Pan, Wenlin Yao, Hongming Zhang, Dian Yu, Dong Yu, and Jianshu Chen. 2022."
    },
    {
      "index": 133,
      "title": "On the Risk of Misinformation Pollution with Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yikang Pan, Liangming Pan, Wenhu Chen, Preslav Nakov, Min-Yen Kan, and William Yang Wang. 2023b.",
      "orig_title": "On the risk of misinformation pollution with large language models",
      "paper_id": "2305.13661v2"
    },
    {
      "index": 134,
      "title": "Check your facts and try again: Improving large language models with external knowledge and automated feedback",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, et al. 2023."
    },
    {
      "index": 135,
      "title": "Discovering Language Model Behaviors with Model-Written Evaluations",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Ethan Perez, Sam Ringer, Kamilė Lukošiūtė, Karina Nguyen, Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath, et al. 2022.",
      "orig_title": "Discovering language model behaviors with model-written evaluations",
      "paper_id": "2212.09251v1"
    },
    {
      "index": 136,
      "title": "Language models as knowledge bases?",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the",
      "authors": "Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019."
    },
    {
      "index": 137,
      "title": "A linguistic investigation of machine learning based contradiction detection models: an empirical analysis and future perspectives",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Maren Pielka, Felix Rode, Lisa Pucknat, Tobias Deußer, and Rafet Sifa. 2022."
    },
    {
      "index": 138,
      "title": "Emptying the Ocean with a Spoon: Should We Edit Models?",
      "abstract": "",
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP",
      "authors": "Yuval Pinter and Michael Elhadad. 2023.",
      "orig_title": "Emptying the ocean with a spoon: Should we edit models?",
      "paper_id": "2310.11958v1"
    },
    {
      "index": 139,
      "title": "Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jirui Qi, Raquel Fernández, and Arianna Bisazza. 2023.",
      "orig_title": "Cross-lingual consistency of factual knowledge in multilingual language models",
      "paper_id": "2310.10378v5"
    },
    {
      "index": 140,
      "title": "“Merge Conflicts!” Exploring the Impacts of External Distractors to Parametric Knowledge Graphs",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Cheng Qian, Xinran Zhao, and Sherry Tongshuang Wu. 2023.",
      "orig_title": "merge conflicts!\" exploring the impacts of external distractors to parametric knowledge graphs",
      "paper_id": "2309.08594v1"
    },
    {
      "index": 141,
      "title": "Predicting Question-Answering Performance of Large Language Models through Semantic Consistency",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Ella Rabinovich, Samuel Ackerman, Orna Raz, Eitan Farchi, and Ateret Anaby-Tavor. 2023.",
      "orig_title": "Predicting question-answering performance of large language models through semantic consistency",
      "paper_id": "2311.01152v1"
    },
    {
      "index": 142,
      "title": "Semantic Consistency for Assuring Reliability of Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Harsh Raj, Vipul Gupta, Domenic Rosati, and Subhabrata Majumdar. 2023.",
      "orig_title": "Semantic consistency for assuring reliability of large language models",
      "paper_id": "2308.09138v2"
    },
    {
      "index": 143,
      "title": "Measuring Reliability of Large Language Models through Semantic Consistency",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Harsh Raj, Domenic Rosati, and Subhabrata Majumdar. 2022.",
      "orig_title": "Measuring reliability of large language models through semantic consistency",
      "paper_id": "2211.05853v2"
    },
    {
      "index": 144,
      "title": "Know What You Don’t Know: Unanswerable Questions for SQuAD",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
      "authors": "Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.",
      "orig_title": "Know what you don’t know: Unanswerable questions for SQuAD",
      "paper_id": "1806.03822v1"
    },
    {
      "index": 145,
      "title": "SQuAD: 100,000+ questions for machine comprehension of text",
      "abstract": "",
      "year": "2016",
      "venue": "Proceedings of the",
      "authors": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016."
    },
    {
      "index": 146,
      "title": "How Much Knowledge Can You Pack Into the Parameters of a Language Model?",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the",
      "authors": "Adam Roberts, Colin Raffel, and Noam Shazeer. 2020.",
      "orig_title": "How much knowledge can you pack into the parameters of a language model?",
      "paper_id": "2002.08910v4"
    },
    {
      "index": 147,
      "title": "A Primer in BERTology: What We Know About How BERT Works",
      "abstract": "",
      "year": "2020",
      "venue": "Transactions of the Association for Computational Linguistics, 8:842–866",
      "authors": "Anna Rogers, Olga Kovaleva, and Anna Rumshisky. 2020.",
      "orig_title": "A primer in BERTology: What we know about how BERT works",
      "paper_id": "2002.12327v3"
    },
    {
      "index": 148,
      "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.",
      "orig_title": "Toolformer: Language models can teach themselves to use tools",
      "paper_id": "2302.04761v1"
    },
    {
      "index": 149,
      "title": "The Cost of Training NLP Models A Concise Overview",
      "abstract": "",
      "year": "2004",
      "venue": "ArXiv preprint, abs/",
      "authors": "Or Sharir, Barak Peleg, and Yoav Shoham. 2020.",
      "orig_title": "The cost of training nlp models: A concise overview",
      "paper_id": "2004.08900v1"
    },
    {
      "index": 150,
      "title": "Towards Understanding Sycophancy in Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott R Johnston, et al. 2023.",
      "orig_title": "Towards understanding sycophancy in language models",
      "paper_id": "2310.13548v4"
    },
    {
      "index": 151,
      "title": "Trusting Your Evidence: Hallucinate Less with Context-aware Decoding",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, and Scott Wen-tau Yih. 2023a.",
      "orig_title": "Trusting your evidence: Hallucinate less with context-aware decoding",
      "paper_id": "2305.14739v1"
    },
    {
      "index": 152,
      "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Weijia Shi, Sewon Min, Maria Lomeli, Chunting Zhou, Margaret Li, Victoria Lin, Noah A Smith, Luke Zettlemoyer, Scott Yih, and Mike Lewis. 2023b.",
      "orig_title": "In-context pretraining: Language modeling beyond document boundaries",
      "paper_id": "2310.10638v6"
    },
    {
      "index": 153,
      "title": "RePlug: Retrieval-Augmented Black-Box Language Models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023c.",
      "orig_title": "Replug: Retrieval-augmented black-box language models",
      "paper_id": "2301.12652v4"
    },
    {
      "index": 154,
      "title": "Fake News Detection on Social Media: A Data Mining Perspective",
      "abstract": "",
      "year": "2017",
      "venue": "ACM SIGKDD explorations newsletter, 19(1):22–36",
      "authors": "Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017.",
      "orig_title": "Fake news detection on social media: A data mining perspective",
      "paper_id": "1708.01967v3"
    },
    {
      "index": 155,
      "title": "A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Ruihao Shui, Yixin Cao, Xiang Wang, and Tat-Seng Chua. 2023.",
      "orig_title": "A comprehensive evaluation of large language models on legal judgment prediction",
      "paper_id": "2310.11761v1"
    },
    {
      "index": 156,
      "title": "Retrieval augmentation reduces hallucination in conversation",
      "abstract": "",
      "year": "2021",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP",
      "authors": "Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021."
    },
    {
      "index": 157,
      "title": "Large Language Models Encode Clinical Knowledge",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. 2022.",
      "orig_title": "Large language models encode clinical knowledge",
      "paper_id": "2212.13138v1"
    },
    {
      "index": 158,
      "title": "Editable Neural Networks",
      "abstract": "",
      "year": "2020",
      "venue": "8th International Conference on Learning Representations, ICLR",
      "authors": "Anton Sinitsin, Vsevolod Plokhotnyuk, Dmitriy Pyrkin, Sergei Popov, and Artem Babenko. 2020.",
      "orig_title": "Editable neural networks",
      "paper_id": "2004.00345v2"
    },
    {
      "index": 159,
      "title": "What large models cost you – there is no free ai lunch",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Craig S. Smith. 2023."
    },
    {
      "index": 160,
      "title": "Evaluating the Social Impact of Generative AI Systems in Systems and Society",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Hal Daumé III, Jesse Dodge, Ellie Evans, Sara Hooker, et al. 2023.",
      "orig_title": "Evaluating the social impact of generative ai systems in systems and society",
      "paper_id": "2306.05949v4"
    },
    {
      "index": 161,
      "title": "Ai model gpt-3 (dis) informs us better than humans",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Giovanni Spitale, Nikola Biller-Andorno, and Federico Germani. 2023."
    },
    {
      "index": 162,
      "title": "Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?",
      "abstract": "",
      "year": "2024",
      "venue": "ArXiv preprint, abs/",
      "authors": "Hexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi Cao, and Xueqi Cheng. 2024.",
      "orig_title": "Blinded by generated contexts: How language models merge generated and retrieved contexts for open-domain qa?",
      "paper_id": "2401.11911v6"
    },
    {
      "index": 163,
      "title": "The science of detecting llm-generated texts",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Ruixiang Tang, Yu-Neng Chuang, and Xia Hu. 2023."
    },
    {
      "index": 164,
      "title": "BERT Rediscovers the Classical NLP Pipeline",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "authors": "Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019.",
      "orig_title": "BERT rediscovers the classical NLP pipeline",
      "paper_id": "1905.05950v2"
    },
    {
      "index": 165,
      "title": "Large language models in medicine",
      "abstract": "",
      "year": "1940",
      "venue": "Nature medicine, 29(8):",
      "authors": "Arun James Thirunavukarasu, Darren Shu Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel Shu Wei Ting. 2023."
    },
    {
      "index": 166,
      "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023.",
      "orig_title": "Llama 2: Open foundation and fine-tuned chat models",
      "paper_id": "2307.09288v2"
    },
    {
      "index": 167,
      "title": "♫ MuSiQue: Multihop Questions via Single-hop Question Composition",
      "abstract": "",
      "year": "2022",
      "venue": "Transactions of the Association for Computational Linguistics, 10:539–554",
      "authors": "Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2022.",
      "orig_title": "Musique: Multihop questions via single-hop question composition",
      "paper_id": "2108.00573v3"
    },
    {
      "index": 168,
      "title": "Language Models Don’t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Miles Turpin, Julian Michael, Ethan Perez, and Samuel R Bowman. 2023.",
      "orig_title": "Language models don’t always say what they think: Unfaithful explanations in chain-of-thought prompting",
      "paper_id": "2305.04388v2"
    },
    {
      "index": 169,
      "title": "The epistemology of fact checking",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": "Joseph E Uscinski and Ryden W Butler. 2013."
    },
    {
      "index": 170,
      "title": "Comparing GPT-4 and Open-Source Language Models in Misinformation Mitigation",
      "abstract": "",
      "year": "2024",
      "venue": "ArXiv preprint, abs/",
      "authors": "Tyler Vergho, Jean-Francois Godbout, Reihaneh Rabbany, and Kellin Pelrine. 2024.",
      "orig_title": "Comparing gpt-4 and open-source language models in misinformation mitigation",
      "paper_id": "2401.06920v1"
    },
    {
      "index": 171,
      "title": "FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Tu Vu, Mohit Iyyer, Xuezhi Wang, Noah Constant, Jerry Wei, Jason Wei, Chris Tar, Yun-Hsuan Sung, Denny Zhou, Quoc Le, et al. 2023.",
      "orig_title": "Freshllms: Refreshing large language models with search engine augmentation",
      "paper_id": "2310.03214v2"
    },
    {
      "index": 172,
      "title": "What Evidence Do Language Models Find Convincing?",
      "abstract": "",
      "year": "2024",
      "venue": "ArXiv preprint, abs/",
      "authors": "Alexander Wan, Eric Wallace, and Dan Klein. 2024.",
      "orig_title": "What evidence do language models find convincing?",
      "paper_id": "2402.11782v2"
    },
    {
      "index": 173,
      "title": "Does It Make Sense? And Why? A Pilot Study for Sense Making and Explanation",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "authors": "Cunxiang Wang, Shuailong Liang, Yue Zhang, Xiaonan Li, and Tian Gao. 2019.",
      "orig_title": "Does it make sense? and why? a pilot study for sense making and explanation",
      "paper_id": "1906.00363v2"
    },
    {
      "index": 174,
      "title": "Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Xiangru Tang, Tianhang Zhang, Cheng Jiayang, Yunzhi Yao, Wenyang Gao, Xuming Hu, Zehan Qi, Yidong Wang, Linyi Yang, Jindong Wang, Xing Xie, Zheng Zhang, and Yue Zhang. 2023a.",
      "orig_title": "Survey on factuality in large language models: Knowledge, retrieval and domain-specificity",
      "paper_id": "2310.07521v3"
    },
    {
      "index": 175,
      "title": "Exploiting Abstract Meaning Representation for Open-Domain Question Answering",
      "abstract": "",
      "year": "2096",
      "venue": "Findings of the Association for Computational Linguistics: ACL",
      "authors": "Cunxiang Wang, Zhikun Xu, Qipeng Guo, Xiangkun Hu, Xuefeng Bai, Zheng Zhang, and Yue Zhang. 2023b.",
      "orig_title": "Exploiting Abstract Meaning Representation for open-domain question answering",
      "paper_id": "2305.17050v1"
    },
    {
      "index": 176,
      "title": "RFiD: Towards Rational Fusion-in-Decoder for Open-Domain Question Answering",
      "abstract": "",
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: ACL",
      "authors": "Cunxiang Wang, Haofei Yu, and Yue Zhang. 2023c.",
      "orig_title": "RFiD: Towards rational fusion-in-decoder for open-domain question answering",
      "paper_id": "2305.17041v1"
    },
    {
      "index": 177,
      "title": "A Causal View of Entity Bias in (Large) Language Models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, and Muhao Chen. 2023d.",
      "orig_title": "A causal view of entity bias in (large) language models",
      "paper_id": "2305.14695v2"
    },
    {
      "index": 178,
      "title": "Cross-lingual knowledge editing in large language models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jiaan Wang, Yunlong Liang, Zengkui Sun, Yuxuan Cao, and Jiarong Xu. 2023e."
    },
    {
      "index": 179,
      "title": "Incorporating neuro-inspired adaptability for continual learning in artificial intelligence",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Liyuan Wang, Xingxing Zhang, Qian Li, Mingtian Zhang, Hang Su, Jun Zhu, and Yi Zhong. 2023f.",
      "orig_title": "Incorporating neuro-inspired adaptability for continual learning in artificial intelligence",
      "paper_id": "2308.14991v2"
    },
    {
      "index": 180,
      "title": "Resolving Knowledge Conflicts in Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yike Wang, Shangbin Feng, Heng Wang, Weijia Shi, Vidhisha Balachandran, Tianxing He, and Yulia Tsvetkov. 2023g.",
      "orig_title": "Resolving knowledge conflicts in large language models",
      "paper_id": "2310.00935v3"
    },
    {
      "index": 181,
      "title": "Simple synthetic data reduces sycophancy in large language models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jerry Wei, Da Huang, Yifeng Lu, Denny Zhou, and Quoc V Le. 2023.",
      "orig_title": "Simple synthetic data reduces sycophancy in large language models",
      "paper_id": "2308.03958v2"
    },
    {
      "index": 182,
      "title": "Ethical and social risks of harm from language models",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv preprint, abs/",
      "authors": "Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. 2021."
    },
    {
      "index": 183,
      "title": "Sociotechnical Safety Evaluation of Generative AI Systems",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Laura Weidinger, Maribeth Rauh, Nahema Marchal, Arianna Manzini, Lisa Anne Hendricks, Juan Mateos-Garcia, Stevie Bergman, Jackie Kay, Conor Griffin, Ben Bariach, et al. 2023.",
      "orig_title": "Sociotechnical safety evaluation of generative ai systems",
      "paper_id": "2310.11986v2"
    },
    {
      "index": 184,
      "title": "Defending Against Misinformation Attacks in Open-Domain Question Answering",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Orion Weller, Aleem Khan, Nathaniel Weir, Dawn Lawrie, and Benjamin Van Durme. 2022.",
      "orig_title": "Defending against misinformation attacks in open-domain question answering",
      "paper_id": "2212.10002v3"
    },
    {
      "index": 185,
      "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the",
      "authors": "Adina Williams, Nikita Nangia, and Samuel Bowman. 2018.",
      "orig_title": "A broad-coverage challenge corpus for sentence understanding through inference",
      "paper_id": "1704.05426v4"
    },
    {
      "index": 186,
      "title": "Topological analysis of contradictions in text",
      "abstract": "",
      "year": "2022",
      "venue": "Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "authors": "Xiangcheng Wu, Xi Niu, and Ruhani Rahman. 2022."
    },
    {
      "index": 187,
      "title": "Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation",
      "abstract": "",
      "year": "2023",
      "venue": "ICASSP",
      "authors": "Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, and Shlomo Dubnov. 2023.",
      "orig_title": "Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation",
      "paper_id": "2211.06687v4"
    },
    {
      "index": 188,
      "title": "Adaptive chameleon or stubborn sloth: Unraveling the behavior of large language models in knowledge conflicts",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, and Yu Su. 2023."
    },
    {
      "index": 189,
      "title": "Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Nan Xu, Fei Wang, Bangzheng Li, Mingtao Dong, and Muhao Chen. 2022.",
      "orig_title": "Does your model classify entities reasonably? diagnosing and mitigating spurious correlations in entity typing",
      "paper_id": "2205.12640v2"
    },
    {
      "index": 190,
      "title": "The earth is flat because…: Investigating llms’ belief towards misinformation via persuasive conversation",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Rongwu Xu, Brian S Lin, Shujian Yang, Tianqi Zhang, Weiyan Shi, Tianwei Zhang, Zhixuan Fang, Wei Xu, and Han Qiu. 2023."
    },
    {
      "index": 191,
      "title": "Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment",
      "abstract": "",
      "year": "2023",
      "venue": "Findings of the Association for Computational Linguistics: EMNLP",
      "authors": "Boyang Xue, Weichao Wang, Hongru Wang, Fei Mi, Rui Wang, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, and Kam-Fai Wong. 2023.",
      "orig_title": "Improving factual consistency for knowledge-grounded dialogue systems via knowledge enhancement and alignment",
      "paper_id": "2310.08372v3"
    },
    {
      "index": 192,
      "title": "Editing Large Language Models: Problems, Methods, and Opportunities",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, and Ningyu Zhang. 2023.",
      "orig_title": "Editing large language models: Problems, methods, and opportunities",
      "paper_id": "2305.13172v3"
    },
    {
      "index": 193,
      "title": "Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jingwei Yi, Yueqi Xie, Bin Zhu, Keegan Hines, Emre Kiciman, Guangzhong Sun, Xing Xie, and Fangzhao Wu. 2023.",
      "orig_title": "Benchmarking and defending against indirect prompt injection attacks on large language models",
      "paper_id": "2312.14197v4"
    },
    {
      "index": 194,
      "title": "Intuitive or dependent? investigating llms’ robustness to conflicting prompts",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jiahao Ying, Yixin Cao, Kai Xiong, Yidong He, Long Cui, and Yongbin Liu. 2023."
    },
    {
      "index": 195,
      "title": "Generate rather than Retrieve: Large Langu-age Models are Strong Context Generators",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, and Meng Jiang. 2022.",
      "orig_title": "Generate rather than retrieve: Large language models are strong context generators",
      "paper_id": "2209.10063v3"
    },
    {
      "index": 196,
      "title": "Glm-130b: An open bilingual pre-trained model",
      "abstract": "",
      "year": "2022",
      "venue": "The Eleventh International Conference on Learning Representations",
      "authors": "Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022."
    },
    {
      "index": 197,
      "title": "Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the Fourth ACM International Conference on AI in Finance",
      "authors": "Boyu Zhang, Hongyang Yang, Tianyu Zhou, Muhammad Ali Babar, and Xiao-Yang Liu. 2023a.",
      "orig_title": "Enhancing financial sentiment analysis via retrieval augmented large language models",
      "paper_id": "2310.04027v2"
    },
    {
      "index": 198,
      "title": "Video-LLaMA An Instruction-tuned Audio-Visual Language Model for Video Understanding",
      "abstract": "",
      "year": "2023",
      "venue": "Proceedings of the",
      "authors": "Hang Zhang, Xin Li, and Lidong Bing. 2023b.",
      "orig_title": "Video-llama: An instruction-tuned audio-visual language model for video understanding",
      "paper_id": "2306.02858v4"
    },
    {
      "index": 199,
      "title": "SAC3: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Jiaxin Zhang, Zhuohang Li, Kamalika Das, Bradley A Malin, and Sricharan Kumar. 2023c.",
      "orig_title": "Sac3: Reliable hallucination detection in black-box language models via semantic-aware cross-check consistency",
      "paper_id": "2311.01740v2"
    },
    {
      "index": 200,
      "title": "SituatedQA: Incorporating Extra-Linguistic Contexts into QA",
      "abstract": "",
      "year": "2021",
      "venue": "ArXiv preprint, abs/",
      "authors": "Michael JQ Zhang and Eunsol Choi. 2021.",
      "orig_title": "Situatedqa: Incorporating extra-linguistic contexts into qa",
      "paper_id": "2109.06157v1"
    },
    {
      "index": 201,
      "title": "Mitigating Temporal Misalignment by Discarding Outdated Facts",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Michael JQ Zhang and Eunsol Choi. 2023.",
      "orig_title": "Mitigating temporal misalignment by discarding outdated facts",
      "paper_id": "2305.14824v3"
    },
    {
      "index": 202,
      "title": "DialoGPT : Large-Scale Generative Pre-training for Conversational Response Generation",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
      "authors": "Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2020.",
      "orig_title": "DIALOGPT : Large-scale generative pre-training for conversational response generation",
      "paper_id": "1911.00536v3"
    },
    {
      "index": 203,
      "title": "Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi, Freda Shi, and Shuming Shi. 2023d.",
      "orig_title": "Siren’s song in the ai ocean: A survey on hallucination in large language models",
      "paper_id": "2309.01219v2"
    },
    {
      "index": 204,
      "title": "Merging Generated and Retrieved Knowledge for Open-Domain QA",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yunxiang Zhang, Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, and Lu Wang. 2023e.",
      "orig_title": "Merging generated and retrieved knowledge for open-domain qa",
      "paper_id": "2310.14393v1"
    },
    {
      "index": 205,
      "title": "Explainability for large language models: A survey",
      "abstract": "",
      "year": "",
      "venue": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and Mengnan Du. 2023a."
    },
    {
      "index": 206,
      "title": "Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yukun Zhao, Lingyong Yan, Weiwei Sun, Guoliang Xing, Chong Meng, Shuaiqiang Wang, Zhicong Cheng, Zhaochun Ren, and Dawei Yin. 2023b.",
      "orig_title": "Knowing what llms do not know: A simple yet effective self-detection method",
      "paper_id": "2310.17918v2"
    },
    {
      "index": 207,
      "title": "CDConv: A Benchmark for Contradiction Detection in Chinese Conversations",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv preprint, abs/",
      "authors": "Chujie Zheng, Jinfeng Zhou, Yinhe Zheng, Libiao Peng, Zhen Guo, Wenquan Wu, Zhengyu Niu, Hua Wu, and Minlie Huang. 2022.",
      "orig_title": "Cdconv: A benchmark for contradiction detection in chinese conversations",
      "paper_id": "2210.08511v1"
    },
    {
      "index": 208,
      "title": "MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Zexuan Zhong, Zhengxuan Wu, Christopher D Manning, Christopher Potts, and Danqi Chen. 2023.",
      "orig_title": "Mquake: Assessing knowledge editing in language models via multi-hop questions",
      "paper_id": "2305.14795v3"
    },
    {
      "index": 209,
      "title": "LIMA: Less Is More for Alignment",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2023a.",
      "orig_title": "Lima: Less is more for alignment",
      "paper_id": "2305.11206v1"
    },
    {
      "index": 210,
      "title": "A survey of large language models in medicine: Progress, application, and challenge",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Hongjian Zhou, Boyang Gu, Xinyu Zou, Yiru Li, Sam S Chen, Peilin Zhou, Junling Liu, Yining Hua, Chengfeng Mao, Xian Wu, et al. 2023b."
    },
    {
      "index": 211,
      "title": "Synthetic lies: Understanding ai-generated misinformation and evaluating algorithmic and human solutions",
      "abstract": "",
      "year": "2023",
      "venue": "Proceedings of the",
      "authors": "Jiawei Zhou, Yixuan Zhang, Qianni Luo, Andrea G Parker, and Munmun De Choudhury. 2023c."
    },
    {
      "index": 212,
      "title": "Context-faithful Prompting for Large Language Models",
      "abstract": "",
      "year": "",
      "venue": "ArXiv preprint, abs/",
      "authors": "Wenxuan Zhou, Sheng Zhang, Hoifung Poon, and Muhao Chen. 2023d.",
      "orig_title": "Context-faithful prompting for large language models",
      "paper_id": "2303.11315v2"
    },
    {
      "index": 213,
      "title": "ToolQA: A Dataset for LLM Question Answering with External Tools",
      "abstract": "",
      "year": "2023",
      "venue": "ArXiv preprint, abs/",
      "authors": "Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, and Chao Zhang. 2023.",
      "orig_title": "Toolqa: A dataset for llm question answering with external tools",
      "paper_id": "2306.13304v1"
    },
    {
      "index": 214,
      "title": "Detection and resolution of rumours in social media: A survey",
      "abstract": "",
      "year": "2018",
      "venue": "ACM Computing Surveys (CSUR), 51(2):1–36",
      "authors": "Arkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva, Maria Liakata, and Rob Procter. 2018."
    }
  ]
}