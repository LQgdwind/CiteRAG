{
  "paper_id": "2205.01992v3",
  "title": "Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning",
  "abstract": "Abstract.\nThe success of machine learning is fueled by the increasing availability of computing power and large training datasets.\nThe training data is used to learn new models or update existing ones, assuming that it is sufficiently representative of the data that will be encountered at test time.\nThis assumption is challenged by the threat of poisoning, an attack that manipulates the training data to compromise the model’s performance at test time.\nAlthough poisoning has been acknowledged as a relevant threat in industry applications, and a variety of different attacks and defenses have been proposed so far, a complete systematization and critical review of the field is still missing. In this survey, we provide a comprehensive systematization of poisoning attacks and defenses in machine learning, reviewing more than 100 papers published in the field in the last 15 years.\nWe start by categorizing the current threat models and attacks, and then organize existing defenses accordingly.\nWhile we focus mostly on computer-vision applications, we argue that our systematization also encompasses state-of-the-art attacks and defenses for other data modalities.\nFinally, we discuss existing resources for research in poisoning, and shed light on the current limitations and open research questions in this research field.",
  "reference_labels": [
    {
      "index": 0,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 1,
      "title": "VENOMAVE: Clean-Label Poisoning Against Speech Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Hojjat Aghakhani, Thorsten Eisenhofer, Lea Schönherr, Dorothea Kolossa, Thorsten Holz, Christopher Kruegel, and Giovanni Vigna"
    },
    {
      "index": 2,
      "title": "Bullseye Polytope: A Scalable Clean-Label Poisoning Attack with Improved Transferability",
      "abstract": "",
      "year": "2021",
      "venue": "EuroS&P",
      "authors": "Hojjat Aghakhani, Dongyu Meng, Yu-Xiang Wang, Christopher Kruegel, and Giovanni Vigna",
      "orig_title": "Bullseye polytope: A scalable clean-label poisoning attack with improved transferability",
      "paper_id": "2005.00191v3"
    },
    {
      "index": 3,
      "title": "Poisoning Deep Reinforcement Learning Agents with In-Distribution Triggers",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Chace Ashcraft and Kiran Karra",
      "orig_title": "Poisoning Deep Reinforcement Learning Agents with In-Distribution Triggers",
      "paper_id": "2106.07798v1"
    },
    {
      "index": 4,
      "title": "How To Backdoor Federated Learning",
      "abstract": "",
      "year": "2020",
      "venue": "AISTATS",
      "authors": "Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov",
      "orig_title": "How To Backdoor Federated Learning",
      "paper_id": "1807.00459v3"
    },
    {
      "index": 5,
      "title": "Baseline Pruning-Based Approach to Trojan Detection in Neural Networks",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Peter Bajcsy and Michael Majurski",
      "orig_title": "Baseline Pruning-Based Approach to Trojan Detection in Neural Networks",
      "paper_id": "2101.12016v2"
    },
    {
      "index": 6,
      "title": "Defense Against Reward Poisoning Attacks in Reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Kiarash Banihashem, Adish Singla, and Goran Radanovic",
      "orig_title": "Defense Against Reward Poisoning Attacks in Reinforcement Learning",
      "paper_id": "2102.05776v2"
    },
    {
      "index": 7,
      "title": "Detecting poisoning attacks on ML in iot environments",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Int. congress on internet of things, ICIOT 2018",
      "authors": "Nathalie Baracaldo, Bryant Chen, Heiko Ludwig, Amir Safavi, and Rui Zhang"
    },
    {
      "index": 8,
      "title": "A New backdoor attack in CNNs by training set corruption without label poisoning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Int. Conf. on Image Proc., ICIP 2019",
      "authors": "Mauro Barni, Kassem Kallas, and Benedetta Tondi",
      "orig_title": "A New Backdoor Attack in CNNS by Training Set Corruption Without Label Poisoning",
      "paper_id": "1902.11237v1"
    },
    {
      "index": 9,
      "title": "Can ML be secure?",
      "abstract": "",
      "year": "2006",
      "venue": "ACM Symposium on Inf., Computer and Communications Security, ASIACCS",
      "authors": "Marco Barreno, Blaine Nelson, Russell Sears, Anthony D. Joseph, and J. D. Tygar"
    },
    {
      "index": 10,
      "title": "Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks",
      "abstract": "",
      "year": "2017",
      "venue": "ML and Data Mining in Pattern Recognition - 13th Int. Conf., MLDM 2017",
      "authors": "Vahid Behzadan and Arslan Munir",
      "orig_title": "Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks",
      "paper_id": "1701.04143v1"
    },
    {
      "index": 11,
      "title": "Random search for hyper-parameter optimization",
      "abstract": "",
      "year": "2012",
      "venue": "Journal of ML research",
      "authors": "James Bergstra and Yoshua Bengio"
    },
    {
      "index": 12,
      "title": "Analyzing Federated Learning through an Adversarial Lens",
      "abstract": "",
      "year": "2019",
      "venue": "Int. Conf. on ML, ICML 2019",
      "authors": "Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin B. Calo",
      "orig_title": "Analyzing Federated Learning through an Adversarial Lens",
      "paper_id": "1811.12470v4"
    },
    {
      "index": 13,
      "title": "Bagging classifiers for fighting poisoning attacks in adversarial classification tasks",
      "abstract": "",
      "year": "2011",
      "venue": "Int. workshop on multiple classifier Sys.",
      "authors": "Battista Biggio, Igino Corona, Giorgio Fumera, Giorgio Giacinto, and Fabio Roli"
    },
    {
      "index": 14,
      "title": "Evasion Attacks against ML at Test Time",
      "abstract": "",
      "year": "2013",
      "venue": "ML and Knowl. Disc. in Databases - Eur. Conf., ECML PKDD 2013",
      "authors": "Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Srndic, Pavel Laskov, Giorgio Giacinto, and Fabio Roli"
    },
    {
      "index": 15,
      "title": "Support Vector Machines Under Adversarial Label Noise",
      "abstract": "",
      "year": "2011",
      "venue": "ACML2011",
      "authors": "Battista Biggio, Blaine Nelson, and Pavel Laskov"
    },
    {
      "index": 16,
      "title": "Poisoning Attacks against Support Vector Machines",
      "abstract": "",
      "year": "2012",
      "venue": "ICML 2012",
      "authors": "Battista Biggio, Blaine Nelson, and Pavel Laskov"
    },
    {
      "index": 17,
      "title": "Is data clustering in adversarial settings secure?",
      "abstract": "",
      "year": "2013",
      "venue": "ACM Workshop on Art. Intell. and Sec., AISec 2013",
      "authors": "Battista Biggio, Ignazio Pillai, Samuel Rota Bulò, Davide Ariu, Marcello Pelillo, and Fabio Roli"
    },
    {
      "index": 18,
      "title": "Poisoning behavioral malware clustering",
      "abstract": "",
      "year": "2014",
      "venue": "ACM Workshop on Art. Intell. and Sec., AISec 2014",
      "authors": "Battista Biggio, Konrad Rieck, Davide Ariu, Christian Wressnegger, Igino Corona, Giorgio Giacinto, and Fabio Roli"
    },
    {
      "index": 19,
      "title": "Wild patterns: Ten years after the rise of adversarial ML",
      "abstract": "",
      "year": "2018",
      "venue": "Pattern Recognition",
      "authors": "Battista Biggio and Fabio Roli"
    },
    {
      "index": 20,
      "title": "Adversarial Attacks on Node Embeddings via Graph Poisoning",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Aleksandar Bojchevski and Stephan Günnemann",
      "orig_title": "Adversarial Attacks on Node Embeddings via Graph Poisoning",
      "paper_id": "1809.01093v3"
    },
    {
      "index": 21,
      "title": "Strong Data Augmentation Sanitizes Poisoning and Backdoor Attacks Without an Accuracy Tradeoff",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE ICASSP 2021",
      "authors": "Eitan Borgnia, Valeriia Cherepanova, Liam Fowl, Amin Ghiasi, Jonas Geiping, Micah Goldblum, Tom Goldstein, and Arjun Gupta",
      "orig_title": "Strong data augmentation sanitizes poisoning and backdoor attacks without an accuracy tradeoff",
      "paper_id": "2011.09527v1"
    },
    {
      "index": 22,
      "title": "DP-InstaHide: Provably Defusing Poisoning and Backdoor Attacks with Differentially Private Data Augmentations",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Eitan Borgnia, Jonas Geiping, Valeriia Cherepanova, Liam Fowl, Arjun Gupta, Amin Ghiasi, Furong Huang, Micah Goldblum, and Tom Goldstein"
    },
    {
      "index": 23,
      "title": "Understanding Distributed Poisoning Attack in Federated Learning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Int. Conf. on Parallel and Distributed Sys.",
      "authors": "Di Cao, Shan Chang, Zhijian Lin, Guohua Liu, and Donghong Sun"
    },
    {
      "index": 24,
      "title": "On evaluating adversarial robustness",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas Rauber, Dimitris Tsipras, Ian Goodfellow, Aleksander Madry, and Alexey Kurakin"
    },
    {
      "index": 25,
      "title": "Regularization Can Help Mitigate Poisoning Attacks…with the Right Hyperparameters",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Javier Carnerero-Cano, Luis Muñoz-González, Phillippa Spencer, and Emil C Lupu",
      "orig_title": "Regularization Can Help Mitigate Poisoning Attacks… with the Right Hyperparameters",
      "paper_id": "2105.10948v1"
    },
    {
      "index": 26,
      "title": "Adversarial Attacks and Defences: A Survey",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv",
      "authors": "Anirban Chakraborty, Manaar Alam, Vishal Dey, Anupam Chattopadhyay, and Debdeep Mukhopadhyay",
      "orig_title": "Adversarial attacks and defences: A survey",
      "paper_id": "1810.00069v1"
    },
    {
      "index": 27,
      "title": "Property Inference from Poisoning",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Melissa Chase, Esha Ghosh, and Saeed Mahloujifar",
      "orig_title": "Property Inference From Poisoning",
      "paper_id": "2101.11073v1"
    },
    {
      "index": 28,
      "title": "Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv",
      "authors": "Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig, Benjamin Edwards, Taesung Lee, Ian Molloy, and Biplav Srivastava",
      "orig_title": "Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering",
      "paper_id": "1811.03728v1"
    },
    {
      "index": 29,
      "title": "Mitigating backdoor attacks in LSTM-based Text Classification Sys. by Backdoor Keyword Identification",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Chuanshuai Chen and Jiazhu Dai"
    },
    {
      "index": 30,
      "title": "DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks",
      "abstract": "",
      "year": "2019",
      "venue": "Int. Joint Conf. on AI, IJCAI 2019",
      "authors": "Huili Chen, Cheng Fu, Jishen Zhao, and Farinaz Koushanfar"
    },
    {
      "index": 31,
      "title": "ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks Without Training Substitute Models",
      "abstract": "",
      "year": "2017",
      "venue": "ACM Workshop on AI and Security (AISec ’17)",
      "authors": "Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh"
    },
    {
      "index": 32,
      "title": "On Collective Robustness of Bagging Against Data Poisoning",
      "abstract": "",
      "year": "2022",
      "venue": "ICML",
      "authors": "Ruoxin Chen, Zenan Li, Jie Li, Junchi Yan, and Chentao Wu",
      "orig_title": "On Collective Robustness of Bagging Against Data Poisoning",
      "paper_id": "2205.13176v2"
    },
    {
      "index": 33,
      "title": "Targeted backdoor attacks on deep learning systems using data poisoning",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv",
      "authors": "Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song"
    },
    {
      "index": 34,
      "title": "Badnl: Backdoor attacks against nlp models",
      "abstract": "",
      "year": "2021",
      "venue": "ICML Workshop on Adversarial ML",
      "authors": "Xiaoyi Chen, Ahmed Salem, Michael Backes, Shiqing Ma, and Yang Zhang"
    },
    {
      "index": 35,
      "title": "Defending against Backdoor Attack on Deep Neural Networks",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Hao Cheng, Kaidi Xu, Sijia Liu, Pin-Yu Chen, Pu Zhao, and Xue Lin",
      "orig_title": "Defending against backdoor attack on deep neural networks",
      "paper_id": "2002.12162v3"
    },
    {
      "index": 36,
      "title": "Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI Conf. on AI",
      "authors": "Siyuan Cheng, Yingqi Liu, Shiqing Ma, and Xiangyu Zhang",
      "orig_title": "Deep Feature Space Trojan Attack of Neural Networks by Controlled Detoxification",
      "paper_id": "2012.11212v2"
    },
    {
      "index": 37,
      "title": "Sentinet: Detecting localized universal attacks against deep learning systems",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Security and Privacy Workshops, SPW 2020",
      "authors": "Edward Chou, Florian Tramer, and Giancarlo Pellegrino"
    },
    {
      "index": 38,
      "title": "Energy-Latency Attacks via Sponge Poisoning",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Antonio Emanuele Cinà, Ambra Demontis, Battista Biggio, Fabio Roli, and Marcello Pelillo",
      "orig_title": "Energy-Latency Attacks via Sponge Poisoning",
      "paper_id": "2203.08147v5"
    },
    {
      "index": 39,
      "title": "Machine Learning Security against Data Poisoning: Are We There Yet?",
      "abstract": "",
      "year": "2022",
      "venue": "CoRR",
      "authors": "Antonio Emanuele Cinà, Kathrin Grosse, Ambra Demontis, Battista Biggio, Fabio Roli, and Marcello Pelillo",
      "orig_title": "Machine Learning Security against Data Poisoning: Are We There Yet?",
      "paper_id": "2204.05986v3"
    },
    {
      "index": 40,
      "title": "Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence Functions",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Antonio Emanuele Cinà, Kathrin Grosse, Sebastiano Vascon, Ambra Demontis, Battista Biggio, Fabio Roli, and Marcello Pelillo",
      "orig_title": "Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence Functions",
      "paper_id": "2106.07214v4"
    },
    {
      "index": 41,
      "title": "A black-box adversarial attack for poisoning clustering",
      "abstract": "",
      "year": "2022",
      "venue": "Pattern Recognition",
      "authors": "Antonio Emanuele Cinà, Alessandro Torcinovich, and Marcello Pelillo",
      "orig_title": "A black-box adversarial attack for poisoning clustering",
      "paper_id": "2009.05474v4"
    },
    {
      "index": 42,
      "title": "The Hammer and the Nut: Is Bilevel Optimization Really Needed to Poison Linear Classifiers?",
      "abstract": "",
      "year": "2021",
      "venue": "Int. Joint Conf. on Neural Networks, IJCNN 2021",
      "authors": "Antonio Emanuele Cinà, Sebastiano Vascon, Ambra Demontis, Battista Biggio, Fabio Roli, and Marcello Pelillo",
      "orig_title": "The Hammer and the Nut: Is Bilevel Optimization Really Needed to Poison Linear Classifiers?",
      "paper_id": "2103.12399v1"
    },
    {
      "index": 43,
      "title": "Casting out Demons: Sanitizing Training Data for Anomaly Sensors",
      "abstract": "",
      "year": "2008",
      "venue": "IEEE Symposium on Security and Privacy, SP 2008",
      "authors": "G.F. Cretu, A. Stavrou, M.E. Locasto, S.J. Stolfo, and A.D. Keromytis"
    },
    {
      "index": 44,
      "title": "Infinity-Norm Support Vector Machines Against Adversarial Label Contamination",
      "abstract": "",
      "year": "2017",
      "venue": "ITASEC",
      "authors": "Ambra Demontis, Battista Biggio, Giorgio Fumera, Giorgio Giacinto, and Fabio Roli"
    },
    {
      "index": 45,
      "title": "Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks",
      "abstract": "",
      "year": "2019",
      "venue": "USENIX Sec. Symp.",
      "authors": "Ambra Demontis, Marco Melis, Maura Pintor, Matthew Jagielski, Battista Biggio, Alina Oprea, Cristina Nita-Rotaru, and Fabio Roli",
      "orig_title": "Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks",
      "paper_id": "1809.02861v4"
    },
    {
      "index": 46,
      "title": "Sever: A Robust Meta-Algorithm for Stochastic Optimization",
      "abstract": "",
      "year": "2019",
      "venue": "Int. Conf. on ML",
      "authors": "Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Jacob Steinhardt, and Alistair Stewart",
      "orig_title": "Sever: A robust meta-algorithm for stochastic optimization",
      "paper_id": "1803.02815v2"
    },
    {
      "index": 47,
      "title": "Februus: Input Purification Defense Against Trojan Attacks on Deep Neural Network Systems",
      "abstract": "",
      "year": "2020",
      "venue": "Computer Security Applications Conf.",
      "authors": "Bao Gia Doan, Ehsan Abbasnejad, and Damith C Ranasinghe",
      "orig_title": "Februus: Input purification defense against trojan attacks on deep neural network systems",
      "paper_id": "1908.03369v7"
    },
    {
      "index": 48,
      "title": "LIRA: Learnable, Imperceptible and Robust Backdoor Attacks",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE ICCV",
      "authors": "Khoa Doan, Yingjie Lao, Weijie Zhao, and Ping Li"
    },
    {
      "index": 49,
      "title": "Generic Methods for Optimization-Based Modeling",
      "abstract": "",
      "year": "2012",
      "venue": "Int. Conf. on Art. Intell. and Statistics, AISTATS 2012",
      "authors": "Justin Domke"
    },
    {
      "index": 50,
      "title": "Black-box Detection of Backdoor Attacks with Limited Information and Data",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "Yinpeng Dong, Xiao Yang, Zhijie Deng, Tianyu Pang, Zihao Xiao, Hang Su, and Jun Zhu",
      "orig_title": "Black-box Detection of Backdoor Attacks with Limited Information and Data",
      "paper_id": "2103.13127v1"
    },
    {
      "index": 51,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Min Du, Ruoxi Jia, and\nDawn Song. 2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 52,
      "title": "Victoria Krakovna",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Tom Everitt, Victoria\nKrakovna, Laurent Orseau, and Shane\nLegg. 2017."
    },
    {
      "index": 53,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Ji Feng, Qi-Zhi Cai,\nand Zhi-Hua Zhou. 2019.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 54,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "Jiashi Feng, Huan Xu,\nShie Mannor, and Shuicheng Yan.\n2014.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 55,
      "title": "Preventing Unauthorized Use of Proprietary Data: Poisoning for Secure Dataset Release",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv:",
      "authors": "Liam Fowl, Ping-yeh\nChiang, Micah Goldblum, Jonas Geiping,\nArpit Bansal, Wojtek Czaja, and\nTom Goldstein. 2021a.",
      "orig_title": "Preventing unauthorized use of proprietary data: Poisoning for secure dataset release",
      "paper_id": "2103.02683v2"
    },
    {
      "index": 56,
      "title": "Adversarial Examples Make Strong Poisons",
      "abstract": "",
      "year": "",
      "venue": "arXiv:",
      "authors": "Liam Fowl, Micah\nGoldblum, Ping-yeh Chiang, Jonas\nGeiping, Wojtek Czaja, and Tom\nGoldstein. 2021b.",
      "orig_title": "Adversarial Examples Make Strong Poisons",
      "paper_id": "2106.10807v1"
    },
    {
      "index": 57,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Luca Franceschi, Paolo\nFrasconi, Saverio Salzo, Riccardo\nGrazzi, and Massimiliano Pontil.\n2018.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 58,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Christopher Frederickson,\nMichael Moore, Glenn Dawson, and\nRobi Polikar. 2018.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 59,
      "title": "Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive Review",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:",
      "authors": "Yansong Gao, Bao Gia\nDoan, Zhi Zhang, Siqi Ma,\nJiliang Zhang, Anmin Fu,\nSurya Nepal, and Hyoungshick Kim.\n2020.",
      "orig_title": "Backdoor attacks and countermeasures on deep learning: A comprehensive review",
      "paper_id": "2007.10760v3"
    },
    {
      "index": 60,
      "title": "Damith C Ranasinghe",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Yansong Gao, Change Xu,\nDerui Wang, Shiping Chen,\nDamith C Ranasinghe, and Surya Nepal.\n2019."
    },
    {
      "index": 61,
      "title": "What Doesn’t Kill You Makes You Robust (er): Adversarial Training against Poisons and Backdoors",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv:",
      "authors": "Jonas Geiping, Liam Fowl,\nGowthami Somepalli, Micah Goldblum,\nMichael Moeller, and Tom Goldstein.\n2021b."
    },
    {
      "index": 62,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Jonas Geiping, Liam H.\nFowl, W. Ronny Huang, Wojciech Czaja,\nGavin Taylor, Michael Moeller, and\nTom Goldstein. 2021a.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 63,
      "title": "Motivating the Rules of the Game for Adversarial Example Research",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:",
      "authors": "Justin Gilmer, Ryan P\nAdams, Ian Goodfellow, David Andersen,\nand George E Dahl. 2018.",
      "orig_title": "Motivating the rules of the game for adversarial example research",
      "paper_id": "1807.06732v2"
    },
    {
      "index": 64,
      "title": "Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE Transactions on PAMI\n(",
      "authors": "Micah Goldblum, Dimitris\nTsipras, Chulin Xie, Xinyun Chen,\nAvi Schwarzschild, Dawn Song,\nAleksander Madry, Bo Li, and\nTom Goldstein. 2022.",
      "orig_title": "Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses",
      "paper_id": "2012.10544v4"
    },
    {
      "index": 65,
      "title": "Planting undetectable backdoors in machine learning models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv:",
      "authors": "Shafi Goldwasser,\nMichael P Kim, Vinod Vaikuntanathan,\nand Or Zamir. 2022."
    },
    {
      "index": 66,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Ian J. Goodfellow,\nJonathon Shlens, and Christian\nSzegedy. 2015.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 67,
      "title": "Advbox: a toolbox to generate adversarial examples that fool neural networks",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:",
      "authors": "Dou Goodman, Hao Xin,\nWang Yang, Wu Yuesheng,\nXiong Junfeng, and Zhang Huan.\n2020.",
      "orig_title": "Advbox: a toolbox to generate adversarial examples that fool neural networks",
      "paper_id": "2001.05574v5"
    },
    {
      "index": 68,
      "title": "Machine Learning Security in Industry: A Quantitative Survey",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE Transactions on Information Forensics\nand Security (",
      "authors": "Kathrin Grosse, Lukas\nBieringer, Tarek Richard Besold, Battista\nBiggio, and Katharina Krombholz.\n2023.",
      "orig_title": "Machine Learning Security in Industry: A Quantitative Survey",
      "paper_id": "2207.05164v2"
    },
    {
      "index": 69,
      "title": "Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural Networks",
      "abstract": "",
      "year": "2022",
      "venue": "Computers & Security\n(",
      "authors": "Kathrin Grosse, Taesung\nLee, Battista Biggio, Youngja Park,\nMichael Backes, and Ian Molloy.\n2022.",
      "orig_title": "Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural Networks",
      "paper_id": "2006.06721v4"
    },
    {
      "index": 70,
      "title": "Badnets: Identifying vulnerabilities in the ML model supply chain",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv (",
      "authors": "Tianyu Gu, Brendan\nDolan-Gavitt, and Siddharth Garg.\n2017."
    },
    {
      "index": 71,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Junfeng Guo, Ang Li,\nand Cong Liu. 2022.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 72,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Junfeng Guo and Cong\nLiu. 2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 73,
      "title": "TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:",
      "authors": "Wenbo Guo, Lun Wang,\nXinyu Xing, Min Du, and\nDawn Song. 2019.",
      "orig_title": "Tabor: A highly accurate approach to inspecting and restoring trojan backdoors in AI Systems",
      "paper_id": "1908.01763v2"
    },
    {
      "index": 74,
      "title": "Benjamin IP Rubinstein",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Yi Han, David Hubczenko,\nPaul Montague, Olivier De Vel,\nTamas Abraham, Benjamin IP Rubinstein,\nChristopher Leckie, Tansu Alpcan, and\nSarah Erfani. 2020."
    },
    {
      "index": 75,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Jonathan Hayase, Weihao\nKong, Raghav Somani, and Sewoong Oh.\n2021.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 76,
      "title": "Contamination Attacks and Mitigation in Multi-Party ML",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Inf. Proc. Sys., NIPS\n31 (",
      "authors": "Jamie Hayes and Olga\nOhrimenko. 2018."
    },
    {
      "index": 77,
      "title": "On the Effectiveness of Mitigating Data Poisoning Attacks with Gradient Shaping",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:",
      "authors": "Sanghyun Hong, Varun\nChandrasekaran, Yiğitcan Kaya,\nTudor Dumitraş, and Nicolas\nPapernot. 2020.",
      "orig_title": "On the effectiveness of mitigating data poisoning attacks with gradient shaping",
      "paper_id": "2002.11497v2"
    },
    {
      "index": 78,
      "title": "Michael Cogswell",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Xiaoling Hu, Xiao Lin,\nMichael Cogswell, Yi Yao,\nSusmit Jha, and Chao Chen.\n2022."
    },
    {
      "index": 79,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Kunzhe Huang, Yiming Li,\nBaoyuan Wu, Zhan Qin, and\nKui Ren. 2022.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 80,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "W. Ronny Huang, Jonas\nGeiping, Liam Fowl, Gavin Taylor, and\nTom Goldstein. 2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 81,
      "title": "Neuroninspect: Detecting backdoors in neural networks via output explanations",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:",
      "authors": "Xijie Huang, Moustafa\nAlzantot, and Mani Srivastava.\n2019."
    },
    {
      "index": 82,
      "title": "Yunhan Huang and Quanyan Zhu",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Yunhan Huang and Quanyan\nZhu. 2019."
    },
    {
      "index": 83,
      "title": "Cristina Nita-Rotaru",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Matthew Jagielski, Alina\nOprea, Battista Biggio, Chang Liu,\nCristina Nita-Rotaru, and Bo Li.\n2018."
    },
    {
      "index": 84,
      "title": "Niklas Pousette Harger",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Matthew Jagielski, Giorgio\nSeveri, Niklas Pousette Harger, and\nAlina Oprea. 2021."
    },
    {
      "index": 85,
      "title": "Mohammad Samragh",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Mojan Javaheripi, Mohammad\nSamragh, Gregory Fields, Tara Javidi,\nand Farinaz Koushanfar. 2020."
    },
    {
      "index": 86,
      "title": "Certified robustness of nearest neighbors against data poisoning attacks",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv (",
      "authors": "Jinyuan Jia, Xiaoyu Cao,\nand Neil Zhenqiang Gong.\n2020."
    },
    {
      "index": 87,
      "title": "Efficient global optimization of expensive black-box functions",
      "abstract": "",
      "year": "1998",
      "venue": "Journal of Global optimization\n13, 4 (1998),\n455–492",
      "authors": "Donald R Jones, Matthias\nSchonlau, and William J Welch.\n1998."
    },
    {
      "index": 88,
      "title": "Defense against neural trojan attacks: A survey",
      "abstract": "",
      "year": "2021",
      "venue": "Neurocomputing 423\n(",
      "authors": "Sara Kaviani and Insoo\nSohn. 2021."
    },
    {
      "index": 89,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Panagiota Kiourti, Kacper\nWardega, Susmit Jha, and Wenchao Li.\n2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 90,
      "title": "Marius Kloft and Pavel Laskov",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": "Marius Kloft and Pavel\nLaskov. 2010."
    },
    {
      "index": 91,
      "title": "Can You Hear It? Backdoor Attacks via Ultrasonic Triggers",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv (",
      "authors": "Stefanos Koffas, Jing Xu,\nMauro Conti, and Stjepan Picek.\n2021.",
      "orig_title": "Can You Hear It? Backdoor Attacks via Ultrasonic Triggers",
      "paper_id": "2107.14569v3"
    },
    {
      "index": 92,
      "title": "Pang Wei Koh and Percy Liang",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Pang Wei Koh and Percy\nLiang. 2017."
    },
    {
      "index": 93,
      "title": "Stronger Data Poisoning Attacks Break Data Sanitization Defenses",
      "abstract": "",
      "year": "2022",
      "venue": "Machine Learning 111\n(",
      "authors": "Pang Wei Koh, Jacob\nSteinhardt, and Percy Liang.\n2022.",
      "orig_title": "Stronger data poisoning attacks break data sanitization defenses",
      "paper_id": "1811.00741v2"
    },
    {
      "index": 94,
      "title": "Hamed Pirsiavash",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Soheil Kolouri, Aniruddha\nSaha, Hamed Pirsiavash, and Heiko\nHoffmann. 2020."
    },
    {
      "index": 95,
      "title": "Adversarial ML-industry perspectives",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Ram Shankar Siva Kumar,\nMagnus Nyström, John Lambert,\nAndrew Marshall, Mario Goertzel,\nAndi Comissoneru, Matt Swann, and\nSharon Xia. 2020."
    },
    {
      "index": 96,
      "title": "Curie: A method for protecting SVM Classifier from Poisoning Attack",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv:",
      "authors": "Ricky Laishram and\nVir Virander Phoha. 2016.",
      "orig_title": "Curie: A method for protecting SVM Classifier from Poisoning Attack",
      "paper_id": "1606.01584v2"
    },
    {
      "index": 97,
      "title": "Alexander Levine and Soheil Feizi",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Alexander Levine and\nSoheil Feizi. 2021."
    },
    {
      "index": 98,
      "title": "Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization",
      "abstract": "",
      "year": "2017",
      "venue": "The Journal of ML Research\n18, 1 (2017)",
      "authors": "Lisha Li, Kevin Jamieson,\nGiulia DeSalvo, Afshin Rostamizadeh,\nand Ameet Talwalkar. 2017.",
      "orig_title": "Hyperband: A novel bandit-based approach to hyperparameter optimization",
      "paper_id": "1603.06560v4"
    },
    {
      "index": 99,
      "title": "Invisible Backdoor Attacks on Deep Neural Networks via Steganography and Regularization",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Trans. on Dependable and Secure\nComputing PP (09 2020),\n1–1",
      "authors": "Shaofeng Li, Minhui Xue,\nBenjamin Zhao, Haojin Zhu, and\nXinpeng Zhang. 2020b.",
      "orig_title": "Invisible Backdoor Attacks on Deep Neural Networks via Steganography and Regularization",
      "paper_id": "1909.02742v3"
    },
    {
      "index": 100,
      "title": "Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks",
      "abstract": "",
      "year": "2021",
      "venue": "ICLR",
      "authors": "Yige Li, Nodens Koren,\nLingjuan Lyu, Xixiang Lyu,\nBo Li, and Xingjun Ma.\n2021a.",
      "orig_title": "Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks",
      "paper_id": "2101.05930v2"
    },
    {
      "index": 101,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Yuezun Li, Yiming Li,\nBaoyuan Wu, Longkang Li,\nRan He, and Siwei Lyu.\n2021b.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 102,
      "title": "Anti-Backdoor Learning: Training Clean Models on Poisoned Data",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Yige Li, Xixiang Lyu,\nNodens Koren, Lingjuan Lyu,\nBo Li, and Xingjun Ma.\n2021c.",
      "orig_title": "Anti-backdoor learning: Training clean models on poisoned data",
      "paper_id": "2110.11571v3"
    },
    {
      "index": 103,
      "title": "Backdoor Learning: A Survey",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:",
      "authors": "Yiming Li, Baoyuan Wu,\nYong Jiang, Zhifeng Li, and\nShu-Tao Xia. 2020a.",
      "orig_title": "Backdoor learning: A survey",
      "paper_id": "2007.08745v5"
    },
    {
      "index": 104,
      "title": "Rethinking the Trigger of Backdoor Attack",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv (",
      "authors": "Yiming Li, Tongqing Zhai,\nBaoyuan Wu, Yong Jiang,\nZhifeng Li, and Shutao Xia.\n2020c.",
      "orig_title": "Rethinking the trigger of backdoor attack",
      "paper_id": "2004.04692v3"
    },
    {
      "index": 105,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Junyu Lin, Lei Xu,\nYingqi Liu, and Xiangyu Zhang.\n2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 106,
      "title": "Yevgeniy Vorobeychik",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Chang Liu, Bo Li,\nYevgeniy Vorobeychik, and Alina Oprea.\n2017a."
    },
    {
      "index": 107,
      "title": "Brendan Dolan-Gavitt",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Kang Liu, Brendan\nDolan-Gavitt, and Siddharth Garg.\n2018a."
    },
    {
      "index": 108,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Xuanqing Liu, Si Si,\nJerry Zhu, Yang Li, and\nCho-Jui Hsieh. 2019b.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 109,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Yingqi Liu, Wen-Chuan\nLee, Guanhong Tao, Shiqing Ma,\nYousra Aafer, and Xiangyu Zhang.\n2019a.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 110,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Yingqi Liu, Shiqing Ma,\nYousra Aafer, Wen-Chuan Lee,\nJuan Zhai, Weihang Wang, and\nXiangyu Zhang. 2018b.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 111,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Yunfei Liu, Xingjun Ma,\nJames Bailey, and Feng Lu.\n2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 112,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Yuntao Liu, Yang Xie,\nand Ankur Srivastava. 2017b.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 113,
      "title": "Luciano Sanchez Ramos",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Pablo Ribalta Lorenzo,\nJakub Nalepa, Michal Kawulok,\nLuciano Sanchez Ramos, and\nJosé Ranilla Pastor. 2017."
    },
    {
      "index": 114,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Jonathan Lorraine, Paul\nVicol, and David Duvenaud.\n2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 115,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Yuzhe Ma, Kwang-Sung Jun,\nLihong Li, and Xiaojin Zhu.\n2018.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 116,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Yuzhe Ma, Xiaojin Zhu,\nand Justin Hsu. 2019.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 117,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Dougal Maclaurin, David\nDuvenaud, and Ryan P. Adams.\n2015.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 118,
      "title": "Excess capacity and backdoor poisoning",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Inf. Proc. Sys., NeurIPS\n34 (",
      "authors": "Naren Manoj and Avrim\nBlum. 2021."
    },
    {
      "index": 119,
      "title": "Preventing Repeated Real World AI Failures by Cataloging Incidents: The AI Incident Database",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:",
      "authors": "Sean McGregor.\n2020."
    },
    {
      "index": 120,
      "title": "Bhavya Kailkhura",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Akshay Mehra, Bhavya\nKailkhura, Pin-Yu Chen, and Jihun\nHamm. 2021."
    },
    {
      "index": 121,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Shike Mei and Xiaojin\nZhu. 2015.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 122,
      "title": "secml: A Python Library for Secure and Explainable ML",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:",
      "authors": "Marco Melis, Ambra\nDemontis, Maura Pintor, Angelo Sotgiu,\nand Battista Biggio. 2019."
    },
    {
      "index": 123,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Nicolas M. Müller,\nDaniel Kowatsch, and Konstantin\nBöttinger. 2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 124,
      "title": "Vasin Wongrassamee",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Luis Muñoz-González,\nBattista Biggio, Ambra Demontis,\nAndrea Paudice, Vasin Wongrassamee,\nEmil C. Lupu, and Fabio Roli.\n2017."
    },
    {
      "index": 125,
      "title": "Misleading learners: Co-opting your spam filter",
      "abstract": "",
      "year": "2009",
      "venue": "ML in Cyber Trust.\nSpringer, 17–51",
      "authors": "Blaine Nelson, Marco\nBarreno, Fuching Jack Chi, Anthony D\nJoseph, Benjamin IP Rubinstein, Udam\nSaini, Charles Sutton, JD Tygar, and\nKai Xia. 2009."
    },
    {
      "index": 126,
      "title": "Fuching Jack Chi",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": "Blaine Nelson, Marco\nBarreno, Fuching Jack Chi, Anthony D.\nJoseph, Benjamin I. P. Rubinstein, Udam\nSaini, Charles Sutton, J. Doug Tygar,\nand Kai Xia. 2008."
    },
    {
      "index": 127,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": "James Newsome, Brad Karp,\nand Dawn Xiaodong Song. 2006.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 128,
      "title": "Tuan Anh Nguyen and Anh Tran",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Tuan Anh Nguyen and Anh\nTran. 2020."
    },
    {
      "index": 129,
      "title": "Tuan Anh Nguyen and Anh Tuan Tran",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Tuan Anh Nguyen and\nAnh Tuan Tran. 2021."
    },
    {
      "index": 130,
      "title": "Valentina Zantedeschi",
      "abstract": "",
      "year": "2018",
      "venue": "CoRR 1807.01069\n(",
      "authors": "Maria-Irina Nicolae,\nMathieu Sinn, Minh Ngoc Tran,\nBeat Buesser, Ambrish Rawat,\nMartin Wistuba, Valentina Zantedeschi,\nNathalie Baracaldo, Bryant Chen,\nHeiko Ludwig, Ian Molloy, and\nBen Edwards. 2018."
    },
    {
      "index": 131,
      "title": "Transferability in ML: from phenomena to black-box attacks using adversarial samples",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv:",
      "authors": "Nicolas Papernot, Patrick\nMcDaniel, and Ian Goodfellow.\n2016."
    },
    {
      "index": 132,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Nicolas Papernot,\nPatrick D. McDaniel, Ian J. Goodfellow,\nSomesh Jha, Z. Berkay Celik, and\nAnanthram Swami. 2017.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 133,
      "title": "Luis Muñoz-González",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Andrea Paudice, Luis\nMuñoz-González, and Emil C Lupu.\n2018."
    },
    {
      "index": 134,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": "R. Perdisci, D. Dagon,\nWenke Lee, P. Fogla, and\nM. Sharif. 2006.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 135,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Neehar Peri, Neal Gupta,\nW Ronny Huang, Liam Fowl,\nChen Zhu, Soheil Feizi,\nTom Goldstein, and John P Dickerson.\n2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 136,
      "title": "Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2106.09947\n(",
      "authors": "Maura Pintor, Luca\nDemetrio, Angelo Sotgiu, Giovanni Manca,\nAmbra Demontis, Nicholas Carlini,\nBattista Biggio, and Fabio Roli.\n2021.",
      "orig_title": "Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples",
      "paper_id": "2106.09947v3"
    },
    {
      "index": 137,
      "title": "ONION: A Simple and Effective Defense Against Textual Backdoor Attacks",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:",
      "authors": "Fanchao Qi, Yangyi Chen,\nMukai Li, Zhiyuan Liu, and\nMaosong Sun. 2020.",
      "orig_title": "ONION: A Simple and Effective Defense Against Textual Backdoor Attacks",
      "paper_id": "2011.10369v3"
    },
    {
      "index": 138,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Ximing Qiao, Yukun Yang,\nand Hai Li. 2019.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 139,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Amin Rakhsha, Goran\nRadanovic, Rati Devidze, Xiaojin Zhu,\nand Adish Singla. 2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 140,
      "title": "Pradeep Ravikumar",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Elan Rosenfeld, Ezra\nWinston, Pradeep Ravikumar, and Zico\nKolter. 2020."
    },
    {
      "index": 141,
      "title": "Anthony D Joseph",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "Benjamin IP Rubinstein,\nBlaine Nelson, Ling Huang,\nAnthony D Joseph, Shing-hon Lau,\nSatish Rao, Nina Taft, and\nJ Doug Tygar. 2009."
    },
    {
      "index": 142,
      "title": "Akshayvarun Subramanya",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Aniruddha Saha,\nAkshayvarun Subramanya, and Hamed\nPirsiavash. 2020."
    },
    {
      "index": 143,
      "title": "Dynamic backdoor attacks against ML models",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv (",
      "authors": "Ahmed Salem, Rui Wen,\nMichael Backes, Shiqing Ma, and\nYang Zhang. 2020."
    },
    {
      "index": 144,
      "title": "Backdoor suppression in neural networks using input fuzzing and majority voting",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Design & Test 37,\n2 (",
      "authors": "Esha Sarkar, Yousif\nAlkindi, and Michail Maniatakos.\n2020a."
    },
    {
      "index": 145,
      "title": "Hadjer Benkraouda",
      "abstract": "",
      "year": "2020",
      "venue": "arXive:",
      "authors": "Esha Sarkar, Hadjer\nBenkraouda, and Michail Maniatakos.\n2020b."
    },
    {
      "index": 146,
      "title": "John P Dickerson",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Avi Schwarzschild, Micah\nGoldblum, Arjun Gupta, John P Dickerson,\nand Tom Goldstein. 2021."
    },
    {
      "index": 147,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Giorgio Severi, Jim\nMeyer, Scott Coull, and Alina Oprea.\n2021.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 148,
      "title": "Christoph Studer",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Ali Shafahi, W. Ronny\nHuang, Mahyar Najibi, Octavian Suciu,\nChristoph Studer, Tudor Dumitras, and\nTom Goldstein. 2018."
    },
    {
      "index": 149,
      "title": "Arjun Nitin Bhagoji",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Shawn Shan, Arjun Nitin\nBhagoji, Haitao Zheng, and Ben Y\nZhao. 2022."
    },
    {
      "index": 150,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Virat Shejwalkar, Amir\nHoumansadr, Peter Kairouz, and Daniel\nRamage. 2022.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 151,
      "title": "Backdoor Scanning for Deep Neural Networks through K-Arm Optimization",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv:",
      "authors": "Guangyu Shen, Yingqi Liu,\nGuanhong Tao, Shengwei An,\nQiuling Xu, Siyuan Cheng,\nShiqing Ma, and Xiangyu Zhang.\n2021.",
      "orig_title": "Backdoor Scanning for Deep Neural Networks through K-Arm Optimization",
      "paper_id": "2102.05123v3"
    },
    {
      "index": 152,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Reza Shokri et al.\n2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 153,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "David Solans, Battista\nBiggio, and Carlos Castillo.\n2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 154,
      "title": "Robin Sommer and Vern Paxson",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": "Robin Sommer and Vern\nPaxson. 2010."
    },
    {
      "index": 155,
      "title": "Exposing backdoors in robust ML models",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv (",
      "authors": "Ezekiel Soremekun, Sakshi\nUdeshi, Sudipta Chattopadhyay, and\nAndreas Zeller. 2020."
    },
    {
      "index": 156,
      "title": "Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv:",
      "authors": "Hossein Souri, Micah\nGoldblum, Liam Fowl, Rama Chellappa,\nand Tom Goldstein. 2021.",
      "orig_title": "Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch",
      "paper_id": "2106.08970v3"
    },
    {
      "index": 157,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Jacob Steinhardt, Pang Wei\nKoh, and Percy Liang. 2017.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 158,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Octavian Suciu, Radu\nMarginean, Yigitcan Kaya, Hal Daume III,\nand Tudor Dumitras. 2018.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 159,
      "title": "Adversarial Attack and Defense on Graph Data: A Survey",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:",
      "authors": "Lichao Sun, Yingtong Dou,\nCarl Yang, Ji Wang,\nPhilip S Yu, Lifang He, and\nBo Li. 2018.",
      "orig_title": "Adversarial attack and defense on graph data: A survey",
      "paper_id": "1812.10528v4"
    },
    {
      "index": 160,
      "title": "Bhavya Kailkhura",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Mingjie Sun, Zichao Li,\nChaowei Xiao, Haonan Qiu,\nBhavya Kailkhura, Mingyan Liu, and\nBo Li. 2021."
    },
    {
      "index": 161,
      "title": "Can you really backdoor federated learning?",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv (",
      "authors": "Ziteng Sun, Peter\nKairouz, Ananda Theertha Suresh, and\nH Brendan McMahan. 2019."
    },
    {
      "index": 162,
      "title": "On defending against label flipping attacks on malware detection system",
      "abstract": "",
      "year": "2020",
      "venue": "Neural Computing and Applications\n(",
      "authors": "Rahim Taheri, Reza\nJavidan, Mohammad Shojafar, Zahra\nPooranian, Ali Miri, and Mauro Conti.\n2020."
    },
    {
      "index": 163,
      "title": "Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Di Tang, XiaoFeng Wang,\nHaixu Tang, and Kehuan Zhang.\n2021.",
      "orig_title": "Demon in the Variant: Statistical Analysis of {{\\{DNNs}}\\} for Robust Backdoor Contamination Detection",
      "paper_id": "1908.00686v2"
    },
    {
      "index": 164,
      "title": "A Comprehensive Survey on Poisoning Attacks and Countermeasures in Machine Learning",
      "abstract": "",
      "year": "2022",
      "venue": "Comput. Surveys (",
      "authors": "Zhiyi Tian, Lei Cui,\nJie Liang, and Shui Yu.\n2022."
    },
    {
      "index": 165,
      "title": "Mehmet Emre Gursoy",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Vale Tolpegin, Stacey\nTruex, Mehmet Emre Gursoy, and Ling\nLiu. 2020."
    },
    {
      "index": 166,
      "title": "Antonio Torralba and Alexei A Efros",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": "Antonio Torralba and\nAlexei A Efros. 2011."
    },
    {
      "index": 167,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "Florian Tramèr, Fan\nZhang, Ari Juels, Michael K. Reiter,\nand Thomas Ristenpart. 2016.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 168,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Brandon Tran, Jerry Li,\nand Aleksander M\\kadry.\n2018.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 169,
      "title": "Label-Consistent Backdoor Attacks",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:",
      "authors": "Alexander Turner, Dimitris\nTsipras, and Aleksander Madry.\n2019.",
      "orig_title": "Label-consistent backdoor attacks",
      "paper_id": "1912.02771v2"
    },
    {
      "index": 170,
      "title": "Model agnostic defence against backdoor attacks in ML",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:",
      "authors": "Sakshi Udeshi, Shanshan\nPeng, Gerald Woo, Lionell Loh,\nLouth Rawshan, and Sudipta\nChattopadhyay. 2019."
    },
    {
      "index": 171,
      "title": "Prashanth Krishnamurthy",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Akshaj Kumar Veldanda,\nKang Liu, Benjamin Tan,\nPrashanth Krishnamurthy, Farshad\nKhorrami, Ramesh Karri, Brendan\nDolan-Gavitt, and Siddharth Garg.\n2021."
    },
    {
      "index": 172,
      "title": "ConFoc: Content-Focus Protection Against Trojan Attacks on Neural Networks",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv (",
      "authors": "Miguel Villarreal-Vasquez and\nBharat Bhargava. 2020.",
      "orig_title": "Confoc: Content-focus protection against trojan attacks on neural networks",
      "paper_id": "2007.00711v1"
    },
    {
      "index": 173,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Bolun Wang, Yuanshun Yao,\nShawn Shan, Huiying Li,\nBimal Viswanath, Haitao Zheng, and\nBen Y Zhao. 2019.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 174,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Jingkang Wang, Yang Liu,\nand Bo Li. 2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 175,
      "title": "Alexander J Levine",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Wenxiao Wang, Alexander J\nLevine, and Soheil Feizi.\n2022."
    },
    {
      "index": 176,
      "title": "RAB: Provable Robustness Against Backdoor Attacks",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:",
      "authors": "Maurice Weber, Xiaojun\nXu, Bojan Karlas, Ce Zhang, and\nBo Li. 2020.",
      "orig_title": "Rab: Provable robustness against backdoor attacks",
      "paper_id": "2003.08904v8"
    },
    {
      "index": 177,
      "title": "With Great Dispersion Comes Greater Resilience: Efficient Poisoning Attacks and Defenses for Linear Regression Models",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Trans. on Inf. Forensics and Security\n(",
      "authors": "Jialin Wen, Benjamin\nZi Hao Zhao, Minhui Xue, Alina Oprea,\nand Haifeng Qian. 2021.",
      "orig_title": "With Great Dispersion Comes Greater Resilience: Efficient Poisoning Attacks and Defenses for Linear Regression Models",
      "paper_id": "2006.11928v5"
    },
    {
      "index": 178,
      "title": "On the Trade-off between Adversarial and Backdoor Robustness",
      "abstract": "",
      "year": "2020",
      "venue": "Neural Inf. Proc. Sys., NeurIPS\n(",
      "authors": "Cheng-Hsin Weng, Yan-Ting\nLee, and Shan-Hung Brandon Wu.\n2020."
    },
    {
      "index": 179,
      "title": "Josephine Passananti",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Int. Conf. on Computer Vision, ICCV",
      "authors": "Emily Wenger, Josephine\nPassananti, Arjun Nitin Bhagoji, Yuanshun\nYao, Haitao Zheng, and Ben Y. Zhao.\n2021."
    },
    {
      "index": 180,
      "title": "Dongxian Wu and Yisen Wang",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Dongxian Wu and Yisen\nWang. 2021."
    },
    {
      "index": 181,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Zhaohan Xi, Ren Pang,\nShouling Ji, and Ting Wang.\n2021.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 182,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Zhen Xiang, David Miller,\nand George Kesidis. 2022.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 183,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Zhen Xiang, David J\nMiller, and George Kesidis.\n2019.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 184,
      "title": "Detection of Backdoors in Trained Classifiers Without Access to the Training Set",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Trans. on Neural Networks and Learning\nSys. (",
      "authors": "Zhen Xiang, David J\nMiller, and George Kesidis.\n2020.",
      "orig_title": "Detection of Backdoors in Trained Classifiers Without Access to the Training Set",
      "paper_id": "1908.10498v3"
    },
    {
      "index": 185,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Zhen Xiang, David J\nMiller, and George Kesidis.\n2021a.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 186,
      "title": "Reverse Engineering Imperceptible Backdoor Attacks on Deep Neural Networks for Detection and Training Set Cleansing",
      "abstract": "",
      "year": "2021",
      "venue": "Computers & Security\n106 (",
      "authors": "Zhen Xiang, David J\nMiller, and George Kesidis.\n2021b.",
      "orig_title": "Reverse engineering imperceptible backdoor attacks on deep neural networks for detection and training set cleansing",
      "paper_id": "2010.07489v1"
    },
    {
      "index": 187,
      "title": "Characterizing Attacks on Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:",
      "authors": "Chaowei Xiao, Xinlei Pan,\nWarren He, Jian Peng,\nMingjie Sun, Jinfeng Yi,\nMingyan Liu, Bo Li, and\nDawn Song. 2019.",
      "orig_title": "Characterizing attacks on deep reinforcement learning",
      "paper_id": "1907.09470v3"
    },
    {
      "index": 188,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Huang Xiao, Battista\nBiggio, Gavin Brown, Giorgio Fumera,\nClaudia Eckert, and Fabio Roli.\n2015a.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 189,
      "title": "Support Vector Machines under Adversarial Label Contamination",
      "abstract": "",
      "year": "2015",
      "venue": "Neurocomputing 160\n(",
      "authors": "Huang Xiao, Battista\nBiggio, Blaine Nelson, Han Xiao,\nClaudia Eckert, and Fabio Roli.\n2015b.",
      "orig_title": "Support vector machines under adversarial label contamination",
      "paper_id": "2206.00352v1"
    },
    {
      "index": 190,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": "Han Xiao, Huang Xiao,\nand Claudia Eckert. 2012.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 191,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Chulin Xie, Keli Huang,\nPin-Yu Chen, and Bo Li.\n2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 192,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Hang Xu, Rundong Wang,\nLev Raizman, and Zinovi Rabinovich.\n2021b.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 193,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Xiaojun Xu, Qi Wang,\nHuichen Li, Nikita Borisov,\nCarl A. Gunter, and Bo Li.\n2021a.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 194,
      "title": "Generative Poisoning Attack Method Against Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "CoRR abs/1703.01340\n(",
      "authors": "Chaofei Yang, Qing Wu,\nHai Li, and Yiran Chen.\n2017."
    },
    {
      "index": 195,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Yu Yang, Tian Yu Liu,\nand Baharan Mirzasoleiman.\n2022.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 196,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2055",
      "venue": "",
      "authors": "Yuanshun Yao, Huiying Li,\nHaitao Zheng, and Ben Y Zhao.\n2019.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 197,
      "title": "Kota Yoshida and Takeshi Fujino",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Kota Yoshida and Takeshi\nFujino. 2020."
    },
    {
      "index": 198,
      "title": "Thomas P Karnowski",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Steven R Young, Derek C\nRose, Thomas P Karnowski, Seung-Hwan\nLim, and Robert M Patton.\n2015."
    },
    {
      "index": 199,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Yi Zeng, Si Chen,\nWon Park, Zhuoqing Mao,\nMing Jin, and Ruoxi Jia.\n2022.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 200,
      "title": "DeepSweep: An Evaluation Framework for Mitigating DNN Backdoor Attacks using Data Augmentation",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:",
      "authors": "Yi Zeng, Han Qiu,\nShangwei Guo, Tianwei Zhang,\nMeikang Qiu, and Bhavani\nThuraisingham. 2020.",
      "orig_title": "DeepSweep: An Evaluation Framework for Mitigating DNN Backdoor Attacks using Data Augmentation",
      "paper_id": "2012.07006v2"
    },
    {
      "index": 201,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Jiale Zhang, Junjun Chen,\nDi Wu, Bing Chen, and\nShui Yu. 2019.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 202,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Jiale Zhang, Di Wu,\nChengyong Liu, and Bing Chen.\n2020b.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 203,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Rui Zhang and Quanyan\nZhu. 2017.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 204,
      "title": "TAD: Trigger Approximation based Black-box Trojan Detection for AI",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv (",
      "authors": "Xinqiao Zhang, Huili\nChen, and Farinaz Koushanfar.\n2021a.",
      "orig_title": "TAD: Trigger Approximation based Black-box Trojan Detection for AI",
      "paper_id": "2102.01815v3"
    },
    {
      "index": 205,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Xuezhou Zhang, Yuzhe Ma,\nAdish Singla, and Xiaojin Zhu.\n2020a.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 206,
      "title": "Trojaning Language Models for Fun and Profit",
      "abstract": "",
      "year": "2020",
      "venue": "CoRR abs/2008.00312\n(",
      "authors": "Xinyang Zhang, Zheng\nZhang, and Ting Wang. 2020c.",
      "orig_title": "Trojaning Language Models for Fun and Profit",
      "paper_id": "2008.00312v2"
    },
    {
      "index": 207,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Zaixi Zhang, Jinyuan Jia,\nBinghui Wang, and Neil Zhenqiang Gong.\n2021b.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 208,
      "title": "Karthikeyan Natesan Ramamurthy",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Pu Zhao, Pin-Yu Chen,\nPayel Das, Karthikeyan Natesan\nRamamurthy, and Xue Lin.\n2020a."
    },
    {
      "index": 209,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Shihao Zhao, Xingjun Ma,\nXiang Zheng, James Bailey,\nJingjing Chen, and Yu-Gang Jiang.\n2020b.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 210,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Ying Zhao, Junjun Chen,\nJiale Zhang, Di Wu, Jian\nTeng, and Shui Yu. 2019.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 211,
      "title": "Anna Cinzia Squicciarini",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Haoti Zhong, Cong Liao,\nAnna Cinzia Squicciarini, Sencun Zhu,\nand David J. Miller. 2020."
    },
    {
      "index": 212,
      "title": "Christoph Studer",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Chen Zhu, W. Ronny Huang,\nHengduo Li, Gavin Taylor,\nChristoph Studer, and Tom Goldstein.\n2019."
    },
    {
      "index": 213,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Liuwan Zhu, Rui Ning,\nCong Wang, Chunsheng Xin, and\nHongyi Wu. 2020.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 214,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Liuwan Zhu, Rui Ning,\nChunsheng Xin, Chonggang Wang, and\nHongyi Wu. 2021.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 215,
      "title": "Daniel Zügner and Stephan Günnemann",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Daniel Zügner and\nStephan Günnemann. 2019."
    }
  ]
}