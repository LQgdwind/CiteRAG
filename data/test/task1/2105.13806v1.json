{
  "paper_id": "2105.13806v1",
  "title": "DRL: Deep Reinforcement Learning for Intelligent Robot Control– Concept, Literature, and Future",
  "abstract": "Abstract\nCombination of machine learning (for generating machine intelligence),\ncomputer vision (for better environment perception), and\nrobotic systems (for controlled environment interaction)\nmotivates this work\ntoward proposing a vision-based learning framework for intelligent robot control\nas the ultimate goal (vision-based learning robot).\nThis work specifically introduces deep reinforcement learning as the the learning framework,\na General-purpose framework for AI (AGI) meaning application-independent and platform-independent.\nIn terms of robot control, this framework is proposing specifically a high-level control architecture independent of the low-level control,\nmeaning these two required level of control can be developed separately from each other.\nIn this aspect, the high-level control creates the required intelligence for the control of the platform\nusing the recorded low-level controlling data from that same platform generated by a trainer.\nThe recorded low-level controlling data is simply indicating the successful and failed experiences or sequences of experiments conducted by a trainer using the same robotic platform.\nThe sequences of the recorded data are composed of observation data (input sensor), generated reward (feedback value) and action data (output controller).\nFor experimental platform and experiments, vision sensors are used for perception of the environment,\ndifferent kinematic controllers create the required motion commands based on the platform application,\ndeep learning approaches generate the required intelligence,\nand finally reinforcement learning techniques incrementally improve the generated intelligence\nuntil the mission is accomplished by the robot.\nFor deep reinforcement learning, deep Q networks (DQN) [1] using Convolutional Neural Network (CNN) [2] will be used for learning the Q network.\nDeep Q Network approach is applied to the images acquired from our vision devices as input sensors\nto select the maximum rewarded action (best possible move based on our experiences) for our output controller to generate the required kinematics motion.\n\nkeywords\n\nAdvanced Cognitive Robotics, Control Architectures, Computer Vision, Deep Learning, Reinforcement Learning and Machine Learning.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Human-level control through deep reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "Mnih, V. et al."
    },
    {
      "index": 1,
      "title": "Gradient-based learning applied to document recognition",
      "abstract": "",
      "year": "1998",
      "venue": "IEEE",
      "authors": "LeCun, Y., Bottou, L., Bengio, Y. & Haffner, P."
    },
    {
      "index": 2,
      "title": "Stanley: The robot that won the darpa grand challenge",
      "abstract": "",
      "year": "2006",
      "venue": "Journal of field Robotics",
      "authors": "Thrun, S. et al."
    },
    {
      "index": 3,
      "title": "Probabilistic robotics",
      "abstract": "",
      "year": "2005",
      "venue": "MIT press",
      "authors": "Thrun, S., Burgard, W. & Fox, D."
    },
    {
      "index": 4,
      "title": "Junior: The stanford entry in the urban challenge",
      "abstract": "",
      "year": "2008",
      "venue": "Journal of field Robotics",
      "authors": "Montemerlo, M. et al."
    },
    {
      "index": 5,
      "title": "Deep Learning",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "LeCun, Y., Bengio, Y. & Hinton, G.",
      "orig_title": "Deep learning",
      "paper_id": "1807.07987v2"
    },
    {
      "index": 6,
      "title": "The learning machines",
      "abstract": "",
      "year": "2014",
      "venue": "Nature",
      "authors": "Jones, N. et al."
    },
    {
      "index": 7,
      "title": "Learning representations by back-propagating errors",
      "abstract": "",
      "year": "1986",
      "venue": "nature",
      "authors": "Rumelhart, D. E., Hinton, G. E. & Williams, R. J."
    },
    {
      "index": 8,
      "title": "How to do backpropagation in a brain",
      "abstract": "",
      "year": "2007",
      "venue": "NIPS’2007 Deep Learning Workshop",
      "authors": "Hinton, G. E."
    },
    {
      "index": 9,
      "title": "Parallel distributed processing",
      "abstract": "",
      "year": "1988",
      "venue": "",
      "authors": "Rumelhart, D. E., McClelland, J. L., Group, P. R. et al."
    },
    {
      "index": 10,
      "title": "A learning algorithm for boltzmann machines",
      "abstract": "",
      "year": "1985",
      "venue": "Cognitive science",
      "authors": "Ackley, D. H., Hinton, G. E. & Sejnowski, T. J."
    },
    {
      "index": 11,
      "title": "Learning and relearning in boltzmann machines",
      "abstract": "",
      "year": "1986",
      "venue": "Parallel distributed processing: Explorations in the microstructure of cognition. Volume 1: Foundations",
      "authors": "Hinton, G. E. & Sejnowski, T. J."
    },
    {
      "index": 12,
      "title": "Reducing the dimensionality of data with neural networks",
      "abstract": "",
      "year": "2006",
      "venue": "Science",
      "authors": "Hinton, G. E. & Salakhutdinov, R. R."
    },
    {
      "index": 13,
      "title": "A fast learning algorithm for deep belief nets",
      "abstract": "",
      "year": "2006",
      "venue": "Neural computation",
      "authors": "Hinton, G. E., Osindero, S. & Teh, Y.-W."
    },
    {
      "index": 14,
      "title": "Imagenet classification with deep convolutional neural networks",
      "abstract": "",
      "year": "2012",
      "venue": "Advances in neural information processing systems",
      "authors": "Krizhevsky, A., Sutskever, I. & Hinton, G. E."
    },
    {
      "index": 15,
      "title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE Signal Processing Magazine",
      "authors": "Hinton, G. et al."
    },
    {
      "index": 16,
      "title": "Convolutional networks for images, speech, and time series",
      "abstract": "",
      "year": "1995",
      "venue": "The handbook of brain theory and neural networks",
      "authors": "LeCun, Y. & Bengio, Y."
    },
    {
      "index": 17,
      "title": "Learning deep architectures for AI",
      "abstract": "",
      "year": "2009",
      "venue": "Now Publishers Inc",
      "authors": "Bengio, Y."
    },
    {
      "index": 18,
      "title": "Long short-term memory",
      "abstract": "",
      "year": "1997",
      "venue": "Neural computation",
      "authors": "Hochreiter, S. & Schmidhuber, J."
    },
    {
      "index": 19,
      "title": "Multi-column deep neural networks for image classification",
      "abstract": "",
      "year": "2012",
      "venue": "Computer Vision and Pattern Recognition (CVPR), IEEE Conference on",
      "authors": "Ciregan, D., Meier, U. & Schmidhuber, J."
    },
    {
      "index": 20,
      "title": "Deep, big, simple neural nets for handwritten digit recognition",
      "abstract": "",
      "year": "2010",
      "venue": "Neural computation",
      "authors": "Ciresan, D. C., Meier, U., Gambardella, L. M. & Schmidhuber, J."
    },
    {
      "index": 21,
      "title": "Deep learning in neural networks: An overview",
      "abstract": "",
      "year": "2015",
      "venue": "Neural Networks",
      "authors": "Schmidhuber, J."
    },
    {
      "index": 22,
      "title": "Ros: an open-source robot operating system",
      "abstract": "",
      "year": "2009",
      "venue": "ICRA workshop on open source software",
      "authors": "Quigley, M. et al."
    },
    {
      "index": 23,
      "title": "Large scale distributed deep networks",
      "abstract": "",
      "year": "2012",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Dean, J. et al."
    },
    {
      "index": 24,
      "title": "An invitation to imitation",
      "abstract": "",
      "year": "2015",
      "venue": "DTIC Document",
      "authors": "Bagnell, J. A."
    },
    {
      "index": 25,
      "title": "Introduction to reinforcement learning",
      "abstract": "",
      "year": "1998",
      "venue": "MIT Press Cambridge",
      "authors": "Sutton, R. S. & Barto, A. G."
    },
    {
      "index": 26,
      "title": "Reinforcement learning improves behaviour from evaluative feedback",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "Littman, M. L."
    },
    {
      "index": 27,
      "title": "Reinforcement learning in robotics: A survey",
      "abstract": "",
      "year": "2013",
      "venue": "The International Journal of Robotics Research",
      "authors": "Kober, J., Bagnell, J. A. & Peters, J."
    },
    {
      "index": 28,
      "title": "Reinforcement learning in robotics: A survey",
      "abstract": "",
      "year": "2012",
      "venue": "Reinforcement Learning",
      "authors": "Kober, J. & Peters, J."
    },
    {
      "index": 29,
      "title": "On learning navigation behaviors for small mobile robots with reservoir computing architectures",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE transactions on neural networks and learning systems",
      "authors": "Antonelo, E. A. & Schrauwen, B."
    },
    {
      "index": 30,
      "title": "Learning navigation attractors for mobile robots with reinforcement learning and reservoir computing",
      "abstract": "",
      "year": "2011",
      "venue": "X Brazilian Congress on Computational Intelligence (CBIC)",
      "authors": "Antonelo, E. A., Depeweg, S. & Schrauwen, B."
    },
    {
      "index": 31,
      "title": "Reservoir computing architectures for modeling robot navigation systems",
      "abstract": "",
      "year": "2011",
      "venue": "Ghent University",
      "authors": "Antonelo, E."
    },
    {
      "index": 32,
      "title": "Mastering the game of go with deep neural networks and tree search",
      "abstract": "",
      "year": "2016",
      "venue": "Nature",
      "authors": "Silver, D. et al."
    },
    {
      "index": 33,
      "title": "Artificial intelligence: Learning to see and act",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "Schölkopf, B."
    },
    {
      "index": 34,
      "title": "Reinforcement learning improves behaviour from evaluative feedback",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "Littman, M. L."
    },
    {
      "index": 35,
      "title": "Deep reinforcement learning from self-play in imperfect-information games",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Heinrich, J. & Silver, D."
    },
    {
      "index": 36,
      "title": "Deep Reinforcement Learning",
      "abstract": "",
      "year": "2015",
      "venue": "unknown",
      "authors": "Wang, X.",
      "orig_title": "Deep reinforcement learning",
      "paper_id": "1810.06339v1"
    },
    {
      "index": 37,
      "title": "Deep reinforcement learning discovers internal models",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Baram, N., Zahavy, T. & Mannor, S."
    },
    {
      "index": 38,
      "title": "Learning to communicate with deep multi-agent reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Foerster, J. N., Assael, Y. M., de Freitas, N. & Whiteson, S."
    },
    {
      "index": 39,
      "title": "Benchmarking Deep Reinforcement Learning for Continuous Control",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Duan, Y., Chen, X., Houthooft, R., Schulman, J. & Abbeel, P.",
      "orig_title": "Benchmarking deep reinforcement learning for continuous control",
      "paper_id": "1604.06778v3"
    },
    {
      "index": 40,
      "title": "Terrain-adaptive locomotion skills using deep reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "ACM Trans. Graph.",
      "authors": "Peng, X. B., Berseth, G. & van de Panne, M."
    },
    {
      "index": 41,
      "title": "Stereo-based terrain traversability estimation using surface normals",
      "abstract": "",
      "year": "2014",
      "venue": "ISR/Robotik 2014; 41st International Symposium on Robotics",
      "authors": "Dargazany, A. & Berns, K."
    },
    {
      "index": 42,
      "title": "Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Zhao, T. & Eskénazi, M.",
      "orig_title": "Towards end-to-end learning for dialog state tracking and management using deep reinforcement learning",
      "paper_id": "1606.02560v2"
    },
    {
      "index": 43,
      "title": "Deep reinforcement learning with macro-actions",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Durugkar, I. P., Rosenbaum, C., Dernbach, S. & Mahadevan, S."
    },
    {
      "index": 44,
      "title": "Negative learning rates and p-learning",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Merrill, D."
    },
    {
      "index": 45,
      "title": "Progressive Neural Networks",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Rusu, A. A. et al.",
      "orig_title": "Progressive neural networks",
      "paper_id": "1606.04671v4"
    },
    {
      "index": 46,
      "title": "ViZDoom: A Doom-based AI Research Platform for Visual Reinforcement Learning",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Kempka, M., Wydmuch, M., Runc, G., Toczek, J. & Jaskowski, W.",
      "orig_title": "Vizdoom: A doom-based AI research platform for visual reinforcement learning",
      "paper_id": "1605.02097v2"
    },
    {
      "index": 47,
      "title": "A deep hierarchical approach to lifelong learning in minecraft",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Tessler, C., Givony, S., Zahavy, T., Mankowitz, D. J. & Mannor, S."
    },
    {
      "index": 48,
      "title": "Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:1511.03791",
      "authors": "Zhang, F., Leitner, J., Milford, M., Upcroft, B. & Corke, P.",
      "orig_title": "Towards vision-based deep reinforcement learning for robotic motion control",
      "paper_id": "1511.03791v2"
    },
    {
      "index": 49,
      "title": "Intelligent laser welding through representation, prediction, and control learning: An architecture with deep neural networks and reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "Mechatronics",
      "authors": "Günther, J., Pilarski, P. M., Helfrich, G., Shen, H. & Diepold, K."
    },
    {
      "index": 50,
      "title": "First steps towards an intelligent laser welding architecture using deep neural networks and reinforcement learning",
      "abstract": "",
      "year": "2014",
      "venue": "Procedia Technology",
      "authors": "Günther, J., Pilarski, P. M., Helfrich, G., Shen, H. & Diepold, K."
    },
    {
      "index": 51,
      "title": "Weld appearance prediction with {BP} neural network improved by genetic algorithm during disk laser welding",
      "abstract": "",
      "year": "2015",
      "venue": "Journal of Manufacturing Systems",
      "authors": "Zhang, Y., Gao, X. & Katayama, S."
    },
    {
      "index": 52,
      "title": "Unsupervised energy prediction in a smart grid context using reinforcement cross-building transfer learning",
      "abstract": "",
      "year": "2016",
      "venue": "Energy and Buildings",
      "authors": "Mocanu, E., Nguyen, P. H., Kling, W. L. & Gibescu, M."
    },
    {
      "index": 53,
      "title": "Deep direct reinforcement learning for financial signal representation and trading",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Deng, Y., Bao, F., Kong, Y., Ren, Z. & Dai, Q."
    },
    {
      "index": 54,
      "title": "Convolutional Neural Networks For Automatic State-Time Feature Extraction in Reinforcement Learning Applied to Residential Load Control",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Claessens, B. J., Vrancx, P. & Ruelens, F.",
      "orig_title": "Convolutional neural networks for automatic state-time feature extraction in reinforcement learning applied to residential load control",
      "paper_id": "1604.08382v2"
    },
    {
      "index": 55,
      "title": "Simpleds: A simple deep reinforcement learning dialogue system",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Cuayáhuitl, H."
    },
    {
      "index": 56,
      "title": "Using goal-driven deep learning models to understand sensory cortex",
      "abstract": "",
      "year": "2016",
      "venue": "Nature neuroscience",
      "authors": "Yamins, D. L. & DiCarlo, J. J."
    },
    {
      "index": 57,
      "title": "Deep Learning a Grasp Function for Grasping under Gripper Pose Uncertainty",
      "abstract": "",
      "year": "2016",
      "venue": "ArXiv e-prints",
      "authors": "Johns, E., Leutenegger, S. & Davison, A. J.",
      "orig_title": "Deep Learning a Grasp Function for Grasping under Gripper Pose Uncertainty",
      "paper_id": "1608.02239v1"
    },
    {
      "index": 58,
      "title": "Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Levine, S., Pastor, P., Krizhevsky, A. & Quillen, D.",
      "orig_title": "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection",
      "paper_id": "1603.02199v4"
    },
    {
      "index": 59,
      "title": "Unsupervised Learning for Physical Interaction through Video Prediction",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Finn, C., Goodfellow, I. J. & Levine, S.",
      "orig_title": "Unsupervised learning for physical interaction through video prediction",
      "paper_id": "1605.07157v4"
    },
    {
      "index": 60,
      "title": "End-to-End Training of Deep Visuomotor Policies",
      "abstract": "",
      "year": "2016",
      "venue": "Journal of Machine Learning Research",
      "authors": "Levine, S., Finn, C., Darrell, T. & Abbeel, P.",
      "orig_title": "End-to-end training of deep visuomotor policies",
      "paper_id": "1504.00702v5"
    }
  ]
}