{
  "paper_id": "2202.03666v2",
  "title": "Approximating Gradients for Differentiable Quality Diversity in Reinforcement Learning",
  "abstract": "Abstract.\nConsider the problem of training robustly capable agents. One approach is to generate a diverse collection of agent polices. Training can then be viewed as a quality diversity (QD) optimization problem, where we search for a collection of performant policies that are diverse with respect to quantified behavior. Recent work shows that differentiable quality diversity (DQD) algorithms greatly accelerate QD optimization when exact gradients are available. However, agent policies typically assume that the environment is not differentiable. To apply DQD algorithms to training agent policies, we must approximate gradients for performance and behavior. We propose two variants of the current state-of-the-art DQD algorithm that compute gradients via approximation methods common in reinforcement learning (RL). We evaluate our approach on four simulated locomotion tasks. One variant achieves results comparable to the current state-of-the-art in combining QD and RL, while the other performs comparably in two locomotion tasks. These results provide insight into the limitations of current DQD algorithms in domains where gradients must be approximated. Source code is available at https://github.com/icaros-usc/dqd-rl",
  "reference_labels": [
    {
      "index": 0,
      "title": "Bidirectional Relation between CMA Evolution Strategies and Natural Evolution Strategies",
      "abstract": "",
      "year": "2010",
      "venue": "Parallel Problem Solving from Nature, PPSN XI",
      "authors": "Youhei Akimoto, Yuichi Nagata, Isao Ono, and Shigenobu Kobayashi"
    },
    {
      "index": 1,
      "title": "Natural Gradient Works Efficiently in Learning",
      "abstract": "",
      "year": "1998",
      "venue": "Neural Computation",
      "authors": "Shun-ichi Amari"
    },
    {
      "index": 2,
      "title": "Hindsight Experience Replay",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong, Peter Welinder, Bob McGrew, Josh Tobin, OpenAI Pieter Abbeel, and Wojciech Zaremba"
    },
    {
      "index": 3,
      "title": "Evolution strategies – A comprehensive introduction",
      "abstract": "",
      "year": "2002",
      "venue": "Natural Computing",
      "authors": "Hans-Georg Beyer and Hans-Paul Schwefel"
    },
    {
      "index": 4,
      "title": "Mirrored Sampling and Sequential Selection for Evolution Strategies",
      "abstract": "",
      "year": "2010",
      "venue": "Parallel Problem Solving from Nature, PPSN XI",
      "authors": "Dimo Brockhoff, Anne Auger, Nikolaus Hansen, Dirk V. Arnold, and Tim Hohm"
    },
    {
      "index": 5,
      "title": "OpenAI Gym",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba"
    },
    {
      "index": 6,
      "title": "QD-RL: Efficient Mixing of Quality and Diversity in Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "CoRR",
      "authors": "Geoffrey Cideron, Thomas Pierrot, Nicolas Perrin, Karim Beguir, and Olivier Sigaud"
    },
    {
      "index": 7,
      "title": "Faulty Reward Functions in the Wild",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "Jack Clark and Dario Amodei"
    },
    {
      "index": 8,
      "title": "Scaling MAP-Elites to Deep Neuroevolution",
      "abstract": "",
      "year": "2020",
      "venue": "Genetic and Evolutionary Computation Conference (GECCO ’20)",
      "authors": "Cédric Colas, Vashisht Madhavan, Joost Huizinga, and Jeff Clune"
    },
    {
      "index": 9,
      "title": "GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Cédric Colas, Olivier Sigaud, and Pierre-Yves Oudeyer",
      "orig_title": "GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms",
      "paper_id": "1802.05054v5"
    },
    {
      "index": 10,
      "title": "Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Edoardo Conti, Vashisht Madhavan, Felipe Petroski Such, Joel Lehman, Kenneth Stanley, and Jeff Clune",
      "orig_title": "Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents",
      "paper_id": "1712.06560v3"
    },
    {
      "index": 11,
      "title": "PyBullet, a Python module for physics simulation for games, robotics and machine learning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Erwin Coumans and Yunfei Bai"
    },
    {
      "index": 12,
      "title": "Robots that can adapt like animals",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "Antoine Cully, Jeff Clune, Danesh Tarapore, and Jean-Baptiste Mouret"
    },
    {
      "index": 13,
      "title": "A Tutorial on the Cross-Entropy Method",
      "abstract": "",
      "year": "2005",
      "venue": "Annals of Operations Research",
      "authors": "Pieter-Tjerk de Boer, Dirk P. Kroese, Shie Mannor, and Reuven Y. Rubinstein"
    },
    {
      "index": 14,
      "title": "PyBullet Gymperium",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Benjamin Ellenberger"
    },
    {
      "index": 15,
      "title": "Diversity is All You Need: Learning Skills without a Reward Function",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, and Sergey Levine",
      "orig_title": "Diversity is All You Need: Learning Skills without a Reward Function",
      "paper_id": "1802.06070v6"
    },
    {
      "index": 16,
      "title": "A Quality Diversity Approach to Automatically Generating Human-Robot Interaction Scenarios in Shared Autonomy",
      "abstract": "",
      "year": "2021",
      "venue": "Robotics: Science and Systems",
      "authors": "Matthew Fontaine and Stefanos Nikolaidis"
    },
    {
      "index": 17,
      "title": "On the Importance of Environments in Human-Robot Coordination",
      "abstract": "",
      "year": "2021",
      "venue": "Robotics: Science and Systems",
      "authors": "Matthew C. Fontaine, Ya-Chuan Hsu, Yulun Zhang, Bryon Tjanaka, and Stefanos Nikolaidis",
      "orig_title": "On the Importance of Environments in Human-Robot Coordination",
      "paper_id": "2106.10853v2"
    },
    {
      "index": 18,
      "title": "Differentiable Quality Diversity",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Matthew C. Fontaine and Stefanos Nikolaidis",
      "orig_title": "Differentiable Quality Diversity",
      "paper_id": "2106.03894v3"
    },
    {
      "index": 19,
      "title": "Covariance Matrix Adaptation for the Rapid Illumination of Behavior Space",
      "abstract": "",
      "year": "2020",
      "venue": "Genetic and Evolutionary Computation Conference (GECCO ’20)",
      "authors": "Matthew C. Fontaine, Julian Togelius, Stefanos Nikolaidis, and Amy K. Hoover",
      "orig_title": "Covariance Matrix Adaptation for the Rapid Illumination of Behavior Space",
      "paper_id": "1912.02400v2"
    },
    {
      "index": 20,
      "title": "Addressing Function Approximation Error in Actor-Critic Methods",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Scott Fujimoto, Herke van Hoof, and David Meger",
      "orig_title": "Addressing Function Approximation Error in Actor-Critic Methods",
      "paper_id": "1802.09477v3"
    },
    {
      "index": 21,
      "title": "Data-Efficient Design Exploration through Surrogate-Assisted Illumination",
      "abstract": "",
      "year": "2018",
      "venue": "Evolutionary computation",
      "authors": "Adam Gaier, Alexander Asteroth, and Jean-Baptiste Mouret",
      "orig_title": "Data-efficient design exploration through surrogate-assisted illumination",
      "paper_id": "1806.05865v1"
    },
    {
      "index": 22,
      "title": "Discovering Representations for Black-box Optimization",
      "abstract": "",
      "year": "2020",
      "venue": "Genetic and Evolutionary Computation Conference (GECCO ’20)",
      "authors": "Adam Gaier, Alexander Asteroth, and Jean-Baptiste Mouret",
      "orig_title": "Discovering Representations for Black-Box Optimization",
      "paper_id": "2003.04389v2"
    },
    {
      "index": 23,
      "title": "Understanding the difficulty of training deep feedforward neural networks",
      "abstract": "",
      "year": "2010",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "authors": "Xavier Glorot and Yoshua Bengio"
    },
    {
      "index": 24,
      "title": "Procedural Content Generation through Quality Diversity",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Games (CoG)",
      "authors": "Daniele Gravina, Ahmed Khalifa, Antonios Liapis, Julian Togelius, and Georgios N Yannakakis",
      "orig_title": "Procedural content generation through quality diversity",
      "paper_id": "1907.04053v1"
    },
    {
      "index": 25,
      "title": "A Visual Guide to Evolution Strategies",
      "abstract": "",
      "year": "2017",
      "venue": "blog.otoro.net",
      "authors": "David Ha"
    },
    {
      "index": 26,
      "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine",
      "orig_title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
      "paper_id": "1801.01290v2"
    },
    {
      "index": 27,
      "title": "The CMA Evolution Strategy: A Tutorial",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Nikolaus Hansen"
    },
    {
      "index": 28,
      "title": "Deep Reinforcement Learning Doesn’t Work Yet",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Alex Irpan"
    },
    {
      "index": 29,
      "title": "Collaborative Evolutionary Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Machine Learning",
      "authors": "Shauharda Khadka, Somdeb Majumdar, Tarek Nassar, Zach Dwiel, Evren Tumer, Santiago Miret, Yinyin Liu, and Kagan Tumer"
    },
    {
      "index": 30,
      "title": "Evolution-Guided Policy Gradient in Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Shauharda Khadka and Kagan Tumer",
      "orig_title": "Evolution-Guided Policy Gradient in Reinforcement Learning",
      "paper_id": "1805.07917v2"
    },
    {
      "index": 31,
      "title": "Adam: A Method for Stochastic Optimization",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Learning Representations (ICLR)",
      "authors": "Diederik P. Kingma and Jimmy Ba"
    },
    {
      "index": 32,
      "title": "One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Saurabh Kumar, Aviral Kumar, Sergey Levine, and Chelsea Finn"
    },
    {
      "index": 33,
      "title": "ES Is More Than Just a Traditional Finite-Difference Approximator",
      "abstract": "",
      "year": "2018",
      "venue": "Genetic and Evolutionary Computation Conference (GECCO ’18)",
      "authors": "Joel Lehman, Jay Chen, Jeff Clune, and Kenneth O. Stanley",
      "orig_title": "ES is More than Just a Traditional Finite-Difference Approximator",
      "paper_id": "1712.06568v3"
    },
    {
      "index": 34,
      "title": "Abandoning Objectives: Evolution Through the Search for Novelty Alone",
      "abstract": "",
      "year": "2011",
      "venue": "Evolutionary Computation",
      "authors": "Joel Lehman and Kenneth O. Stanley"
    },
    {
      "index": 35,
      "title": "Evolving a Diversity of Virtual Creatures through Novelty Search and Local Competition",
      "abstract": "",
      "year": "2011",
      "venue": "Genetic and Evolutionary Computation Conference (GECCO ’11)",
      "authors": "Joel Lehman and Kenneth O. Stanley"
    },
    {
      "index": 36,
      "title": "InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Yunzhu Li, Jiaming Song, and Stefano Ermon",
      "orig_title": "InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations",
      "paper_id": "1703.08840v2"
    },
    {
      "index": 37,
      "title": "Continuous control with deep reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "International Conference on Learning Representations (ICLR)",
      "authors": "Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra"
    },
    {
      "index": 38,
      "title": "Simple Random Search of Static Linear Policies is Competitive for Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Neural Information Processing Systems (NIPS’18)",
      "authors": "Horia Mania, Aurelia Guy, and Benjamin Recht"
    },
    {
      "index": 39,
      "title": "Illuminating search spaces by mapping elites",
      "abstract": "",
      "year": "2015",
      "venue": "CoRR",
      "authors": "Jean-Baptiste Mouret and Jeff Clune"
    },
    {
      "index": 40,
      "title": "Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping",
      "abstract": "",
      "year": "1999",
      "venue": "International Conference on Machine Learning (ICML ’99)",
      "authors": "Andrew Y. Ng, Daishi Harada, and Stuart J. Russell"
    },
    {
      "index": 41,
      "title": "QDgym",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Olle Nilsson"
    },
    {
      "index": 42,
      "title": "Policy Gradient Assisted MAP-Elites",
      "abstract": "",
      "year": "2021",
      "venue": "Genetic and Evolutionary Computation Conference (GECCO ’21)",
      "authors": "Olle Nilsson and Antoine Cully"
    },
    {
      "index": 43,
      "title": "Solving Rubik’s Cube with a Robot Hand",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint",
      "authors": "OpenAI, Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng, Qiming Yuan, Wojciech Zaremba, and Lei Zhang",
      "orig_title": "Solving Rubik’s Cube with a Robot Hand",
      "paper_id": "1910.07113v1"
    },
    {
      "index": 44,
      "title": "Efficacy of Modern Neuro-Evolutionary Strategies for Continuous Control Optimization",
      "abstract": "",
      "year": "2020",
      "venue": "Frontiers in Robotics and AI",
      "authors": "Paolo Pagliuca, Nicola Milano, and Stefano Nolfi"
    },
    {
      "index": 45,
      "title": "Effective Diversity in Population Based Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Jack Parker-Holder, Aldo Pacchiano, Krzysztof M Choromanski, and Stephen J Roberts",
      "orig_title": "Effective Diversity in Population Based Reinforcement Learning",
      "paper_id": "2002.00632v3"
    },
    {
      "index": 46,
      "title": "Sim-to-Real Transfer of Robotic Control with Dynamics Randomization",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE International Conference on Robotics and Automation (ICRA)",
      "authors": "Xue Bin Peng, Marcin Andrychowicz, Wojciech Zaremba, and Pieter Abbeel",
      "orig_title": "Sim-to-Real Transfer of Robotic Control with Dynamics Randomization",
      "paper_id": "1710.06537v3"
    },
    {
      "index": 47,
      "title": "CEM-RL: Combining evolutionary and gradient-based methods for policy search",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "Pourchot and Sigaud",
      "orig_title": "CEM-RL: Combining evolutionary and gradient-based methods for policy search",
      "paper_id": "1810.01222v3"
    },
    {
      "index": 48,
      "title": "Quality Diversity: A New Frontier for Evolutionary Computation",
      "abstract": "",
      "year": "2016",
      "venue": "Frontiers in Robotics and AI",
      "authors": "Justin K. Pugh, Lisa B. Soros, and Kenneth O. Stanley"
    },
    {
      "index": 49,
      "title": "Policy Manifold Search: Exploring the Manifold Hypothesis for Diversity-Based Neuroevolution",
      "abstract": "",
      "year": "2021",
      "venue": "Genetic and Evolutionary Computation Conference (GECCO ’21)",
      "authors": "Nemanja Rakicevic, Antoine Cully, and Petar Kormushev"
    },
    {
      "index": 50,
      "title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, and Ilya Sutskever"
    },
    {
      "index": 51,
      "title": "Universal Value Function Approximators",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Machine Learning",
      "authors": "Tom Schaul, Daniel Horgan, Karol Gregor, and David Silver"
    },
    {
      "index": 52,
      "title": "Trust Region Policy Optimization",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Machine Learning",
      "authors": "John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz",
      "orig_title": "Trust Region Policy Optimization",
      "paper_id": "1502.05477v5"
    },
    {
      "index": 53,
      "title": "Proximal Policy Optimization Algorithms",
      "abstract": "",
      "year": "2017",
      "venue": "CoRR",
      "authors": "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov"
    },
    {
      "index": 54,
      "title": "Reinforcement Learning: An Introduction (second ed.)",
      "abstract": "",
      "year": "2018",
      "venue": "The MIT Press",
      "authors": "Richard S. Sutton and Andrew G. Barto"
    },
    {
      "index": 55,
      "title": "Guiding Evolutionary Strategies with Off-Policy Actor-Critic",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Autonomous Agents and MultiAgent Systems (AAMAS ’21)",
      "authors": "Yunhao Tang"
    },
    {
      "index": 56,
      "title": "pyribs: A Bare-Bones Python Library for Quality Diversity Optimization",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Bryon Tjanaka, Matthew C. Fontaine, Yulun Zhang, Sam Sommerer, Nathan Dennler, and Stefanos Nikolaidis",
      "orig_title": "pyribs: A bare-bones Python library for quality diversity optimization",
      "paper_id": "2303.00191v2"
    },
    {
      "index": 57,
      "title": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
      "authors": "Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, and Pieter Abbeel",
      "orig_title": "Domain randomization for transferring deep neural networks from simulation to the real world",
      "paper_id": "1703.06907v1"
    },
    {
      "index": 58,
      "title": "Discovering the Elite Hypervolume by Leveraging Interspecies Correlation",
      "abstract": "",
      "year": "2018",
      "venue": "Genetic and Evolutionary Computation Conference (GECCO ’18)",
      "authors": "Vassilis Vassiliades and Jean-Baptiste Mouret"
    },
    {
      "index": 59,
      "title": "Natural Evolution Strategies",
      "abstract": "",
      "year": "2014",
      "venue": "Journal of Machine Learning Research",
      "authors": "Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jan Peters, and Jürgen Schmidhuber"
    },
    {
      "index": 60,
      "title": "Natural Evolution Strategies",
      "abstract": "",
      "year": "2008",
      "venue": "IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)",
      "authors": "Daan Wierstra, Tom Schaul, Jan Peters, and Juergen Schmidhuber"
    },
    {
      "index": 61,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2008",
      "venue": "https://doi.org/10",
      "authors": "Daan Wierstra, Tom\nSchaul, Jan Peters, and Juergen\nSchmidhuber. 2008.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    }
  ]
}