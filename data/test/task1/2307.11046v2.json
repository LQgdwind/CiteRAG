{
  "paper_id": "2307.11046v2",
  "title": "A Definition of Continual Reinforcement Learning",
  "abstract": "Abstract\nIn a standard view of the reinforcement learning problem, an agent's goal is to efficiently identify a policy that maximizes long-term reward.\nHowever, this perspective is based on a restricted view of learning as finding a solution, rather than treating learning as endless adaptation.\nIn contrast, continual reinforcement learning refers to the setting in which the best agents never stop learning. Despite the importance of continual reinforcement learning, the community lacks a simple definition of the problem that highlights its commitments and makes its primary concepts precise and clear.\nTo this end, this paper is dedicated to carefully defining the continual reinforcement learning problem.\nWe formalize the notion of agents that “never stop learning” through a new mathematical language for analyzing and cataloging agents.\nUsing this new language, we define a continual learning agent as one that can be understood as carrying out an implicit search process indefinitely, and continual reinforcement learning as the setting in which the best agents are all continual learning agents.\nWe provide two motivating examples, illustrating that traditional views of multi-task reinforcement learning and continual supervised learning are special cases of our definition.\nCollectively, these definitions and perspectives formalize many intuitive concepts at the heart of learning, and open new research pathways surrounding continual learning agents.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Loss of Plasticity in Continual Deep Reinforcement Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2303.07507",
      "authors": "Zaheer Abbas, Rosie Zhao, Joseph Modayil, Adam White, and Marlos C Machado",
      "orig_title": "Loss of plasticity in continual deep reinforcement learning",
      "paper_id": "2303.07507v1"
    },
    {
      "index": 1,
      "title": "Policy and value transfer in lifelong reinforcement learning",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "David Abel, Yuu Jinnai, Yue Guo, George Konidaris, and Michael L. Littman"
    },
    {
      "index": 2,
      "title": "Safe Policy Search for Lifelong Reinforcement Learning with Sublinear Regret",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Machine Learning",
      "authors": "Haitham Bou Ammar, Rasul Tutunov, and Eric Eaton",
      "orig_title": "Safe policy search for lifelong reinforcement learning with sublinear regret",
      "paper_id": "1505.05798v1"
    },
    {
      "index": 3,
      "title": "A Domain-Agnostic Approach for Characterization of Lifelong Learning Systems",
      "abstract": "",
      "year": "2023",
      "venue": "Neural Networks",
      "authors": "Megan M Baker, Alexander New, Mario Aguilar-Simon, Ziad Al-Halah, Sébastien MR Arnold, Ese Ben-Iwhiwhu, Andrew P Brna, Ethan Brooks, Ryan C Brown, Zachary Daniels, et al.",
      "orig_title": "A domain-agnostic approach for characterization of lifelong learning systems",
      "paper_id": "2301.07799v1"
    },
    {
      "index": 4,
      "title": "Learning with a slowly changing distribution",
      "abstract": "",
      "year": "1992",
      "venue": "Annual Workshop on Computational Learning Theory",
      "authors": "Peter L Bartlett"
    },
    {
      "index": 5,
      "title": "Stochastic multi-armed-bandit problem with non-stationary rewards",
      "abstract": "",
      "year": "2014",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Omar Besbes, Yonatan Gur, and Assaf Zeevi"
    },
    {
      "index": 6,
      "title": "Settling the Reward Hypothesis",
      "abstract": "",
      "year": "2023",
      "venue": "International Conference on Machine Learning",
      "authors": "Michael Bowling, John D. Martin, David Abel, and Will Dabney",
      "orig_title": "Settling the reward hypothesis",
      "paper_id": "2212.10420v2"
    },
    {
      "index": 7,
      "title": "Language Models are Few-Shot Learners",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.",
      "orig_title": "Language models are few-shot learners",
      "paper_id": "2005.14165v4"
    },
    {
      "index": 8,
      "title": "PAC-inspired option discovery in lifelong reinforcement learning",
      "abstract": "",
      "year": "2014",
      "venue": "International Conference on Machine Learning",
      "authors": "Emma Brunskill and Lihong Li"
    },
    {
      "index": 9,
      "title": "Toward an architecture for never-ending language learning",
      "abstract": "",
      "year": "2010",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R Hruschka, and Tom Mitchell"
    },
    {
      "index": 10,
      "title": "Acting optimally in partially observable stochastic domains",
      "abstract": "",
      "year": "1994",
      "venue": "AAAI Conference on Artificiall Intelligence",
      "authors": "Anthony R. Cassandra, Leslie Pack Kaelbling, and Michael L. Littman"
    },
    {
      "index": 11,
      "title": "A strongly asymptotically optimal agent in general environments",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1903.01021",
      "authors": "Michael K Cohen, Elliot Catt, and Marcus Hutter"
    },
    {
      "index": 12,
      "title": "Online learning in Markov decision processes with changing cost sequences",
      "abstract": "",
      "year": "2014",
      "venue": "International Conference on Machine Learning",
      "authors": "Travis Dick, András György, and Csaba Szepesvari"
    },
    {
      "index": 13,
      "title": "Continual Backprop: Stochastic Gradient Descent with Persistent Randomness",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2108.06325",
      "authors": "Shibhansh Dohare, Richard S Sutton, and A Rupam Mahmood",
      "orig_title": "Continual backprop: Stochastic gradient descent with persistent randomness",
      "paper_id": "2108.06325v3"
    },
    {
      "index": 14,
      "title": "Loss of Plasticity in Deep Continual Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.13812",
      "authors": "Shibhansh Dohare, Juan Hernandez-Garcia, Parash Rahman, Richard Sutton, and A Rupam Mahmood",
      "orig_title": "Loss of plasticity in deep continual learning",
      "paper_id": "2306.13812v3"
    },
    {
      "index": 15,
      "title": "Simple Agent, Complex Environment: Efficient Reinforcement Learning with Agent States",
      "abstract": "",
      "year": "2022",
      "venue": "Journal of Machine Learning Research",
      "authors": "Shi Dong, Benjamin Van Roy, and Zhengyuan Zhou",
      "orig_title": "Simple agent, complex environment: Efficient reinforcement learning with agent states",
      "paper_id": "2102.05261v7"
    },
    {
      "index": 16,
      "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "Chelsea Finn, Pieter Abbeel, and Sergey Levine",
      "orig_title": "Model-agnostic meta-learning for fast adaptation of deep networks",
      "paper_id": "1703.03400v3"
    },
    {
      "index": 17,
      "title": "Catastrophic forgetting in connectionist networks",
      "abstract": "",
      "year": "1999",
      "venue": "Trends in cognitive sciences",
      "authors": "Robert M French"
    },
    {
      "index": 18,
      "title": "Essays in positive economics",
      "abstract": "",
      "year": "1953",
      "venue": "University of Chicago press",
      "authors": "Milton Friedman"
    },
    {
      "index": 19,
      "title": "Model-based Lifelong Reinforcement Learning with Bayesian Exploration",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Haotian Fu, Shangqun Yu, Michael Littman, and George Konidaris",
      "orig_title": "Model-based lifelong reinforcement learning with Bayesian exploration",
      "paper_id": "2210.11579v1"
    },
    {
      "index": 20,
      "title": "An empirical investigation of catastrophic forgetting in gradient-based neural networks",
      "abstract": "",
      "year": "2013",
      "venue": "arXiv preprint arXiv:1312.6211",
      "authors": "Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio"
    },
    {
      "index": 21,
      "title": "Embracing change: Continual learning in deep neural networks",
      "abstract": "",
      "year": "2020",
      "venue": "Trends in cognitive sciences",
      "authors": "Raia Hadsell, Dushyant Rao, Andrei A Rusu, and Razvan Pascanu"
    },
    {
      "index": 22,
      "title": "A theory of universal artificial intelligence based on algorithmic complexity",
      "abstract": "",
      "year": "2000",
      "venue": "arXiv preprint cs/0004001",
      "authors": "Marcus Hutter"
    },
    {
      "index": 23,
      "title": "Universal artificial intelligence: Sequential decisions based on algorithmic probability",
      "abstract": "",
      "year": "2004",
      "venue": "Springer Science & Business Media",
      "authors": "Marcus Hutter"
    },
    {
      "index": 24,
      "title": "Towards Continual Reinforcement Learning: A Review and Perspectives",
      "abstract": "",
      "year": "2022",
      "venue": "Journal of Artificial Intelligence Research",
      "authors": "Khimya Khetarpal, Matthew Riemer, Irina Rish, and Doina Precup",
      "orig_title": "Towards continual reinforcement learning: A review and perspectives",
      "paper_id": "2012.13490v2"
    },
    {
      "index": 25,
      "title": "Overcoming catastrophic forgetting in neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "National Academy of Sciences",
      "authors": "James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al.",
      "orig_title": "Overcoming catastrophic forgetting in neural networks",
      "paper_id": "1612.00796v2"
    },
    {
      "index": 26,
      "title": "Continual Learning as Computationally Constrained Reinforcement Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2307.04345",
      "authors": "Saurabh Kumar, Henrik Marklund, Ashish Rao, Yifan Zhu, Hong Jun Jeon, Yueyang Liu, and Benjamin Van Roy",
      "orig_title": "Continual learning as computationally constrained reinforcement learning",
      "paper_id": "2307.04345v3"
    },
    {
      "index": 27,
      "title": "Theory of general reinforcement learning",
      "abstract": "",
      "year": "2014",
      "venue": "PhD thesis, The Australian National University",
      "authors": "Tor Lattimore"
    },
    {
      "index": 28,
      "title": "Nonparametric general reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "PhD thesis, The Australian National University",
      "authors": "Jan Leike"
    },
    {
      "index": 29,
      "title": "Continual Learning for Robotics: Definition, Framework, Learning Strategies, Opportunities and Challenges",
      "abstract": "",
      "year": "2020",
      "venue": "Information fusion",
      "authors": "Timothée Lesort, Vincenzo Lomonaco, Andrei Stoian, Davide Maltoni, David Filliat, and Natalia Díaz-Rodríguez",
      "orig_title": "Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges",
      "paper_id": "1907.00182v3"
    },
    {
      "index": 30,
      "title": "A Definition of Non-Stationary Bandits",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2302.12202",
      "authors": "Yueyang Liu, Benjamin Van Roy, and Kuang Xu",
      "orig_title": "A definition of non-stationary bandits",
      "paper_id": "2302.12202v2"
    },
    {
      "index": 31,
      "title": "Reinforcement Learning, Bit by Bit",
      "abstract": "",
      "year": "2023",
      "venue": "Foundations and Trends in Machine Learning",
      "authors": "Xiuyuan Lu, Benjamin Van Roy, Vikranth Dwaracherla, Morteza Ibrahimi, Ian Osband, and Zheng Wen",
      "orig_title": "Reinforcement learning, bit by bit",
      "paper_id": "2103.04047v8"
    },
    {
      "index": 32,
      "title": "Meta-Gradients in Non-Stationary Environments",
      "abstract": "",
      "year": "2022",
      "venue": "Conference on Lifelong Learning Agents",
      "authors": "Jelena Luketina, Sebastian Flennerhag, Yannick Schroecker, David Abel, Tom Zahavy, and Satinder Singh",
      "orig_title": "Meta-gradients in non-stationary environments",
      "paper_id": "2209.06159v1"
    },
    {
      "index": 33,
      "title": "Understanding Plasticity in Neural Networks",
      "abstract": "",
      "year": "2023",
      "venue": "International Conference on Machine Learning",
      "authors": "Clare Lyle, Zeyu Zheng, Evgenii Nikishin, Bernardo Avila Pires, Razvan Pascanu, and Will Dabney",
      "orig_title": "Understanding plasticity in neural networks",
      "paper_id": "2303.01486v4"
    },
    {
      "index": 34,
      "title": "Online Continual Learning in Image Classification: An Empirical Survey",
      "abstract": "",
      "year": "2022",
      "venue": "Neurocomputing",
      "authors": "Zheda Mai, Ruiwen Li, Jihwan Jeong, David Quispe, Hyunwoo Kim, and Scott Sanner",
      "orig_title": "Online continual learning in image classification: An empirical survey",
      "paper_id": "2101.10423v4"
    },
    {
      "index": 35,
      "title": "Abstractions of general reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "PhD thesis, The Australian National University",
      "authors": "Sultan J Majeed"
    },
    {
      "index": 36,
      "title": "Performance Guarantees for Homomorphisms Beyond Markov Decision Processes",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Sultan Javed Majeed and Marcus Hutter",
      "orig_title": "Performance guarantees for homomorphisms beyond Markov decision processes",
      "paper_id": "1811.03895v1"
    },
    {
      "index": 37,
      "title": "Catastrophic interference in connectionist networks: The sequential learning problem",
      "abstract": "",
      "year": "1989",
      "venue": "Psychology of learning and motivation",
      "authors": "Michael McCloskey and Neal J Cohen"
    },
    {
      "index": 38,
      "title": "Never-ending learning",
      "abstract": "",
      "year": "2018",
      "venue": "Communications of the ACM",
      "authors": "Tom Mitchell, William Cohen, Estevam Hruschka, Partha Talukdar, Bishan Yang, Justin Betteridge, Andrew Carlson, Bhavana Dalvi, Matt Gardner, Bryan Kisiel, et al."
    },
    {
      "index": 39,
      "title": "Online learning of non-stationary sequences",
      "abstract": "",
      "year": "2003",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Claire Monteleoni and Tommi Jaakkola"
    },
    {
      "index": 40,
      "title": "Variational Continual Learning",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Cuong V Nguyen, Yingzhen Li, Thang D Bui, and Richard E Turner",
      "orig_title": "Variational continual learning",
      "paper_id": "1710.10628v3"
    },
    {
      "index": 41,
      "title": "Continual Lifelong Learning with Neural Networks: A Review",
      "abstract": "",
      "year": "2019",
      "venue": "Neural networks",
      "authors": "German I Parisi, Ronald Kemker, Jose L Part, Christopher Kanan, and Stefan Wermter",
      "orig_title": "Continual lifelong learning with neural networks: A review",
      "paper_id": "1802.07569v4"
    },
    {
      "index": 42,
      "title": "Jelly bean world: A testbed for never-ending learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2002.06306",
      "authors": "Emmanouil Antonios Platanios, Abulhair Saparov, and Tom Mitchell"
    },
    {
      "index": 43,
      "title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming",
      "abstract": "",
      "year": "2014",
      "venue": "John Wiley & Sons",
      "authors": "Martin L Puterman"
    },
    {
      "index": 44,
      "title": "Continual Learning In Environments With Polynomial Mixing Times",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Matthew Riemer, Sharath Chandra Raparthy, Ignacio Cases, Gopeshh Subbaraj, Maximilian Puelma Touzel, and Irina Rish",
      "orig_title": "Continual learning in environments with polynomial mixing times",
      "paper_id": "2112.07066v2"
    },
    {
      "index": 45,
      "title": "Continual learning in reinforcement environments",
      "abstract": "",
      "year": "1994",
      "venue": "PhD thesis, The University of Texas at Austin",
      "authors": "Mark B Ring"
    },
    {
      "index": 46,
      "title": "Child: A first step towards continual learning",
      "abstract": "",
      "year": "1997",
      "venue": "Machine Learning",
      "authors": "Mark B Ring"
    },
    {
      "index": 47,
      "title": "Toward a formal framework for continual learning",
      "abstract": "",
      "year": "2005",
      "venue": "NeurIPS Workshop on Inductive Transfer",
      "authors": "Mark B Ring"
    },
    {
      "index": 48,
      "title": "Experience Replay for Continual Learning",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, and Gregory Wayne",
      "orig_title": "Experience replay for continual learning",
      "paper_id": "1811.11682v2"
    },
    {
      "index": 49,
      "title": "Provably bounded-optimal agents",
      "abstract": "",
      "year": "1994",
      "venue": "Journal of Artificial Intelligence Research",
      "authors": "Stuart J Russell and Devika Subramanian"
    },
    {
      "index": 50,
      "title": "ELLA: An efficient lifelong learning algorithm",
      "abstract": "",
      "year": "2013",
      "venue": "International Conference on Machine Learning",
      "authors": "Paul Ruvolo and Eric Eaton"
    },
    {
      "index": 51,
      "title": "Metalearning",
      "abstract": "",
      "year": "2010",
      "venue": "Scholarpedia",
      "authors": "Tom Schaul and Jürgen Schmidhuber"
    },
    {
      "index": 52,
      "title": "Reinforcement learning with self-modifying policies",
      "abstract": "",
      "year": "1998",
      "venue": "Learning to Learn",
      "authors": "Jürgen Schmidhuber, Jieyu Zhao, and Nicol N Schraudolph"
    },
    {
      "index": 53,
      "title": "Progress & Compress: A scalable framework for continual learning",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, and Raia Hadsell",
      "orig_title": "Progress & compress: A scalable framework for continual learning",
      "paper_id": "1805.06370v2"
    },
    {
      "index": 54,
      "title": "Machine lifelong learning: Challenges and benefits for artificial general intelligence",
      "abstract": "",
      "year": "2011",
      "venue": "Conference on Artificial General Intelligence",
      "authors": "Daniel L Silver"
    },
    {
      "index": 55,
      "title": "Introduction: The challenge of reinforcement learning",
      "abstract": "",
      "year": "1992",
      "venue": "Reinforcement Learning",
      "authors": "Richard S Sutton"
    },
    {
      "index": 56,
      "title": "The reward hypothesis, 2004.",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": "Richard S Sutton"
    },
    {
      "index": 57,
      "title": "The Quest for a Common Model of the Intelligent Decision Maker",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2202.13252",
      "authors": "Richard S Sutton",
      "orig_title": "The quest for a common model of the intelligent decision maker",
      "paper_id": "2202.13252v3"
    },
    {
      "index": 58,
      "title": "Reinforcement Learning: An Introduction",
      "abstract": "",
      "year": "2018",
      "venue": "MIT Press",
      "authors": "Richard S Sutton and Andrew G. Barto"
    },
    {
      "index": 59,
      "title": "Transfer learning for reinforcement learning domains: A survey",
      "abstract": "",
      "year": "2009",
      "venue": "Journal of Machine Learning Research",
      "authors": "Matthew E. Taylor and Peter Stone"
    },
    {
      "index": 60,
      "title": "Is learning the n-th thing any easier than learning the first?",
      "abstract": "",
      "year": "1995",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Sebastian Thrun"
    },
    {
      "index": 61,
      "title": "Lifelong learning algorithms",
      "abstract": "",
      "year": "1998",
      "venue": "Learning to Learn",
      "authors": "Sebastian Thrun"
    },
    {
      "index": 62,
      "title": "Lifelong robot learning",
      "abstract": "",
      "year": "1995",
      "venue": "Robotics and autonomous systems",
      "authors": "Sebastian Thrun and Tom M Mitchell"
    },
    {
      "index": 63,
      "title": "Multi-task reinforcement learning: a hierarchical Bayesian approach",
      "abstract": "",
      "year": "2007",
      "venue": "International Conference on Machine learning",
      "authors": "Aaron Wilson, Alan Fern, Soumya Ray, and Prasad Tadepalli"
    }
  ]
}