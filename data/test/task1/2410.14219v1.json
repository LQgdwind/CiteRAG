{
  "paper_id": "2410.14219v1",
  "title": "Formal Explanations for Neuro-Symbolic AI",
  "abstract": "Abstract\nDespite the practical success of Artificial Intelligence (AI), current\nneural AI algorithms face two significant issues.\nFirst, the decisions made by neural architectures are often\nprone to bias and brittleness. Second, when a chain of reasoning is\nrequired, neural systems often perform poorly.\nNeuro-symbolic\nartificial intelligence is a promising approach\nthat tackles these (and other) weaknesses by combining the\npower of neural perception and symbolic reasoning.\nMeanwhile, the success of AI has made it\ncritical to understand its behaviour,\nleading to the development of\nexplainable artificial intelligence (XAI).\nWhile neuro-symbolic AI systems have important advantages over\npurely neural AI, we still need to explain their\nactions, which are obscured by the interactions of the neural and\nsymbolic components.\nTo address the issue, this paper proposes a formal approach to\nexplaining the decisions of neuro-symbolic systems.\nThe approach hinges on the use of formal abductive explanations and\non solving the neuro-symbolic explainability problem hierarchically.\nNamely, it first computes a formal explanation for the symbolic\ncomponent of the system, which serves to identify a subset of the\nindividual parts of neural information that needs to be explained.\nThis is followed by explaining only those individual neural inputs,\nindependently of each other, which facilitates succinctness of\nhierarchical formal explanations and helps to increase the overall\nperformance of the approach.\nExperimental results for a few complex reasoning tasks\ndemonstrate practical efficiency of the proposed approach, in\ncomparison to purely neural systems, from the perspective of\nexplanation size, explanation time, training time, model sizes, and the quality of explanations reported.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Foundations of Databases",
      "abstract": "",
      "year": "1995",
      "venue": "Addison-Wesley",
      "authors": "Serge Abiteboul, Richard Hull and Victor Vianu"
    },
    {
      "index": 1,
      "title": "Measuring Trustworthiness in Neuro-Symbolic Integration",
      "abstract": "",
      "year": "2023",
      "venue": "FedCSIS",
      "authors": "Andrea Agiollo and Andrea Omicini"
    },
    {
      "index": 2,
      "title": "PYLON: A PyTorch Framework for Learning with Constraints",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI",
      "authors": "Kareem Ahmed et al."
    },
    {
      "index": 3,
      "title": "Reachability Analysis for Neural Agent-Environment Systems",
      "abstract": "",
      "year": "2018",
      "venue": "KR",
      "authors": "Michael Akintunde, Alessio Lomuscio, Lalit Maganti and Edoardo Pirovano"
    },
    {
      "index": 4,
      "title": "Explanations for Answer Set Programming",
      "abstract": "",
      "year": "2023",
      "venue": "ICLP",
      "authors": "Mario Alviano, Ly Ly T. Trieu, Tran Cao Son and Marcello Balduccini",
      "orig_title": "Explanations for Answer Set Programming",
      "paper_id": "2308.15879v1"
    },
    {
      "index": 5,
      "title": "Neurosymbolic Reinforcement Learning with Formally Verified Exploration",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Greg Anderson, Abhinav Verma, Isil Dillig and Swarat Chaudhuri",
      "orig_title": "Neurosymbolic Reinforcement Learning with Formally Verified Exploration",
      "paper_id": "2009.12612v2"
    },
    {
      "index": 6,
      "title": "Learning Certifiably Optimal Rule Lists",
      "abstract": "",
      "year": "2017",
      "venue": "KDD",
      "authors": "Elaine Angelino et al."
    },
    {
      "index": 7,
      "title": "Explainable artificial intelligence: an analytical review",
      "abstract": "",
      "year": "2021",
      "venue": "WIREs Data Mining Knowl. Discov.",
      "authors": "Plamen P. Angelov et al."
    },
    {
      "index": 8,
      "title": "PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation",
      "abstract": "",
      "year": "2024",
      "venue": "ASPLOS",
      "authors": "Jason Ansel et al."
    },
    {
      "index": 9,
      "title": "Discovery of Minimal Unsatisfiable Subsets of Constraints Using Hitting Set Dualization",
      "abstract": "",
      "year": "2005",
      "venue": "PADL",
      "authors": "James Bailey and Peter J. Stuckey"
    },
    {
      "index": 10,
      "title": "Ïù∏Í≥µÏßÄÎä• Í∏∞Î∞ò Í≥µÍ≤© Í∑∏ÎûòÌîÑ ÏÉùÏÑ±",
      "abstract": "",
      "year": "2021",
      "venue": "Handbook of Satisfiability: Second Edition",
      "authors": "",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 11,
      "title": "XGBoost: A Scalable Tree Boosting System",
      "abstract": "",
      "year": "2016",
      "venue": "KDD",
      "authors": "Tianqi Chen and Carlos Guestrin",
      "orig_title": "XGBoost: A Scalable Tree Boosting System",
      "paper_id": "1603.02754v3"
    },
    {
      "index": 12,
      "title": "Rule Induction with CN2: Some Recent Improvements",
      "abstract": "",
      "year": "1991",
      "venue": "EWSL",
      "authors": "Peter Clark and Robin Boswell"
    },
    {
      "index": 13,
      "title": "Tesla Model X was in autopilot before fatal crash",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "CNN"
    },
    {
      "index": 14,
      "title": "The MNIST database of handwritten digit images for machine learning research",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE Signal Processing Magazine",
      "authors": "Li Deng"
    },
    {
      "index": 15,
      "title": "Uber Self-Driving Car Crash: What Really Happened",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Forbes"
    },
    {
      "index": 16,
      "title": "Greedy Function Approximation: A Gradient Boosting Machine",
      "abstract": "",
      "year": "2001",
      "venue": "The Annals of Statistics",
      "authors": "Jerome H. Friedman"
    },
    {
      "index": 17,
      "title": "Neurosymbolic AI: The 3^{ùëü‚Å¢ùëë} Wave",
      "abstract": "",
      "year": "2023",
      "venue": "Artif. Intell. Rev.",
      "authors": "Artur Garcez and Luis C. Lamb",
      "orig_title": "Neurosymbolic AI: the 3rd wave",
      "paper_id": "2012.05876v2"
    },
    {
      "index": 18,
      "title": "Explaining and Harnessing Adversarial Examples",
      "abstract": "",
      "year": "2015",
      "venue": "ICLR",
      "authors": "Ian J. Goodfellow, Jonathon Shlens and Christian Szegedy",
      "orig_title": "Explaining and Harnessing Adversarial Examples",
      "paper_id": "1412.6572v3"
    },
    {
      "index": 19,
      "title": "Provenance semirings",
      "abstract": "",
      "year": "2007",
      "venue": "PODS",
      "authors": "Todd J. Green, Gregory Karvounarakis and Val Tannen"
    },
    {
      "index": 20,
      "title": "Matrix analysis",
      "abstract": "",
      "year": "2012",
      "venue": "Cambridge university press",
      "authors": "Roger A Horn and Charles R Johnson"
    },
    {
      "index": 21,
      "title": "The Inadequacy of Shapley Values for Explainability",
      "abstract": "",
      "year": "2023",
      "venue": "CoRR",
      "authors": "Xuanxiang Huang and Jo√£o Marques-Silva",
      "orig_title": "The Inadequacy of Shapley Values for Explainability",
      "paper_id": "2302.08160v1"
    },
    {
      "index": 22,
      "title": "From Robustness to Explainability and Back Again",
      "abstract": "",
      "year": "2023",
      "venue": "CoRR",
      "authors": "Xuanxiang Huang and Joao Marques-Silva",
      "orig_title": "From Robustness to Explainability and Back Again",
      "paper_id": "2306.03048v3"
    },
    {
      "index": 23,
      "title": "Binarized Neural Networks",
      "abstract": "",
      "year": "2016",
      "venue": "NIPS",
      "authors": "Itay Hubara et al."
    },
    {
      "index": 24,
      "title": "Constructing Optimal Binary Decision Trees is NP-Complete",
      "abstract": "",
      "year": "1976",
      "venue": "Inf. Process. Lett.",
      "authors": "Laurent Hyafil and Ronald L. Rivest"
    },
    {
      "index": 25,
      "title": "PySAT: A Python Toolkit for Prototyping with SAT Oracles",
      "abstract": "",
      "year": "2018",
      "venue": "SAT",
      "authors": "Alexey Ignatiev, Antonio Morgado and Joao Marques-Silva"
    },
    {
      "index": 26,
      "title": "Abduction-Based Explanations for Machine Learning Models",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI",
      "authors": "Alexey Ignatiev, Nina Narodytska and Joao Marques-Silva"
    },
    {
      "index": 27,
      "title": "On Relating Explanations and Adversarial Examples",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Alexey Ignatiev, Nina Narodytska and Joao Marques-Silva"
    },
    {
      "index": 28,
      "title": "Smallest MUS Extraction with Minimal Hitting Set Dualization",
      "abstract": "",
      "year": "2015",
      "venue": "CP",
      "authors": "Alexey Ignatiev, Alessandro Previti, Mark H. Liffiton and Joao Marques-Silva"
    },
    {
      "index": 29,
      "title": "From Contrastive to Abductive Explanations and Back Again",
      "abstract": "",
      "year": "2020",
      "venue": "AI*IA",
      "authors": "Alexey Ignatiev, Nina Narodytska, Nicholas Asher and Joao Marques-Silva"
    },
    {
      "index": 30,
      "title": "The Answer Set Programming Paradigm",
      "abstract": "",
      "year": "2016",
      "venue": "AI Mag.",
      "authors": "Tomi Janhunen and Ilkka Niemel√§"
    },
    {
      "index": 31,
      "title": "Symbols as a Lingua Franca for Bridging Human-AI Chasm for Explainable and Advisable AI Systems",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI",
      "authors": "Subbarao Kambhampati et al."
    },
    {
      "index": 32,
      "title": "The Marabou Framework for Verification and Analysis of Deep Neural Networks",
      "abstract": "",
      "year": "2019",
      "venue": "CAV",
      "authors": "Guy Katz et al."
    },
    {
      "index": 33,
      "title": "Interpretable Decision Sets: A Joint Framework for Description and Prediction",
      "abstract": "",
      "year": "2016",
      "venue": "KDD",
      "authors": "Himabindu Lakkaraju, Stephen H. Bach and Jure Leskovec"
    },
    {
      "index": 34,
      "title": "Scallop: A Language for Neurosymbolic Programming",
      "abstract": "",
      "year": "2023",
      "venue": "Proc. ACM Program. Lang.",
      "authors": "Ziyang Li, Jiani Huang and Mayur Naik",
      "orig_title": "Scallop: A Language for Neurosymbolic Programming",
      "paper_id": "2304.04812v1"
    },
    {
      "index": 35,
      "title": "Enumerating Infeasibility: Finding Multiple MUSes Quickly",
      "abstract": "",
      "year": "2013",
      "venue": "CPAIOR",
      "authors": "Mark H. Liffiton and Ammar Malik"
    },
    {
      "index": 36,
      "title": "Fast, flexible MUS enumeration",
      "abstract": "",
      "year": "2016",
      "venue": "Constraints An Int. J.",
      "authors": "Mark H. Liffiton, Alessandro Previti, Ammar Malik and Joao Marques-Silva"
    },
    {
      "index": 37,
      "title": "The Mythos of Model Interpretability",
      "abstract": "",
      "year": "2018",
      "venue": "Commun. ACM",
      "authors": "Zachary C. Lipton",
      "orig_title": "The mythos of model interpretability",
      "paper_id": "1606.03490v3"
    },
    {
      "index": 38,
      "title": "A Unified Approach to Interpreting Model Predictions",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "Scott M. Lundberg and Su-In Lee",
      "orig_title": "A Unified Approach to Interpreting Model Predictions",
      "paper_id": "1705.07874v2"
    },
    {
      "index": 39,
      "title": "Neural probabilistic logic programming in DeepProbLog",
      "abstract": "",
      "year": "2021",
      "venue": "Artif. Intell.",
      "authors": "Robin Manhaeve et al."
    },
    {
      "index": 40,
      "title": "The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",
      "abstract": "",
      "year": "2020",
      "venue": "CoRR",
      "authors": "Gary Marcus"
    },
    {
      "index": 41,
      "title": "Explainability Is Not a Game",
      "abstract": "",
      "year": "2024",
      "venue": "Commun. ACM",
      "authors": "Jo√£o Marques-Silva and Xuanxiang Huang"
    },
    {
      "index": 42,
      "title": "Delivering Trustworthy AI through Formal XAI",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI",
      "authors": "Jo√£o Marques-Silva and Alexey Ignatiev"
    },
    {
      "index": 43,
      "title": "Explanation in Artificial Intelligence: Insights from the Social Sciences",
      "abstract": "",
      "year": "2019",
      "venue": "Artif. Intell.",
      "authors": "Tim Miller",
      "orig_title": "Explanation in artificial intelligence: Insights from the social sciences",
      "paper_id": "1706.07269v3"
    },
    {
      "index": 44,
      "title": "Detect, Understand, Act: A Neuro-symbolic Hierarchical Reinforcement Learning Framework",
      "abstract": "",
      "year": "2022",
      "venue": "Mach. Learn.",
      "authors": "Ludovico Mitchener, David Tuckey, Matthew Crosby and Alessandra Russo"
    },
    {
      "index": 45,
      "title": "Interpretable Machine Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Leanpub",
      "authors": "Christoph Molnar"
    },
    {
      "index": 46,
      "title": "AI, Explain Yourself",
      "abstract": "",
      "year": "2018",
      "venue": "Commun. ACM",
      "authors": "Don Monroe"
    },
    {
      "index": 47,
      "title": "Rectified Linear Units Improve Restricted Boltzmann Machines",
      "abstract": "",
      "year": "2010",
      "venue": "ICML",
      "authors": "Vinod Nair and Geoffrey E. Hinton"
    },
    {
      "index": 48,
      "title": "Verifying Properties of Binarized Deep Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI",
      "authors": "Nina Narodytska et al.",
      "orig_title": "Verifying Properties of Binarized Deep Neural Networks",
      "paper_id": "1709.06662v2"
    },
    {
      "index": 49,
      "title": "Knowledge-Enhanced Neurosymbolic Artificial Intelligence for Cybersecurity and Privacy",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE Internet Comput.",
      "authors": "Aritran Piplai et al."
    },
    {
      "index": 50,
      "title": "Partial MUS Enumeration",
      "abstract": "",
      "year": "2013",
      "venue": "AAAI",
      "authors": "Alessandro Previti and Jo√£o Marques-Silva"
    },
    {
      "index": 51,
      "title": "Machine Bias",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner"
    },
    {
      "index": 52,
      "title": "‚ÄúWhy Should I Trust You?‚Äù Explaining the Predictions of Any Classifier",
      "abstract": "",
      "year": "2016",
      "venue": "KDD",
      "authors": "Marco T√∫lio Ribeiro, Sameer Singh and Carlos Guestrin",
      "orig_title": "Why Should I Trust You?: Explaining the Predictions of Any Classifier",
      "paper_id": "1602.04938v3"
    },
    {
      "index": 53,
      "title": "Anchors: High-Precision Model-Agnostic Explanations",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI",
      "authors": "Marco T√∫lio Ribeiro, Sameer Singh and Carlos Guestrin"
    },
    {
      "index": 54,
      "title": "Learning Decision Lists",
      "abstract": "",
      "year": "1987",
      "venue": "Mach. Learn.",
      "authors": "Ronald L. Rivest"
    },
    {
      "index": 55,
      "title": "An introduction to abstract algebra",
      "abstract": "",
      "year": "2003",
      "venue": "Walter de Gruyter",
      "authors": "Derek JS Robinson"
    },
    {
      "index": 56,
      "title": "Reachability Analysis of Deep Neural Networks with Provable Guarantees",
      "abstract": "",
      "year": "2018",
      "venue": "IJCAI",
      "authors": "Wenjie Ruan, Xiaowei Huang and Marta Kwiatkowska"
    },
    {
      "index": 57,
      "title": "A Symbolic Approach to Explaining Bayesian Network Classifiers",
      "abstract": "",
      "year": "2018",
      "venue": "IJCAI",
      "authors": "Andy Shih, Arthur Choi and Adnan Darwiche",
      "orig_title": "A Symbolic Approach to Explaining Bayesian Network Classifiers",
      "paper_id": "1805.03364v1"
    },
    {
      "index": 58,
      "title": "Intriguing properties of neural networks",
      "abstract": "",
      "year": "2014",
      "venue": "ICLR",
      "authors": "Christian Szegedy et al."
    },
    {
      "index": 59,
      "title": "Tesla driver killed while using autopilot was watching Harry Potter, witness says",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "The Guardian"
    },
    {
      "index": 60,
      "title": "A Theory of the Learnable",
      "abstract": "",
      "year": "1984",
      "venue": "Commun. ACM",
      "authors": "Leslie G. Valiant"
    },
    {
      "index": 61,
      "title": "Knowledge Infusion: In Pursuit of Robustness in Artificial Intelligence",
      "abstract": "",
      "year": "2008",
      "venue": "FSTTCS",
      "authors": "Leslie G. Valiant"
    },
    {
      "index": 62,
      "title": "VeriX: Towards Verified Explainability of Deep Neural Networks",
      "abstract": "",
      "year": "2023",
      "venue": "NeurIPS",
      "authors": "Min Wu, Haoze Wu and Clark W. Barrett"
    }
  ]
}