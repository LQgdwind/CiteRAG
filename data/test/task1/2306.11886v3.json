{
  "paper_id": "2306.11886v3",
  "title": "SPRINT: Scalable Policy Pre-Training via Language Instruction Relabeling",
  "abstract": "Abstract\nPre-training robots with a rich set of skills can substantially accelerate the learning of downstream tasks. Prior works have defined pre-training tasks via natural language instructions, but doing so requires tedious human annotation of hundreds of thousands of instructions. Thus, we propose SPRINT, a scalable offline policy pre-training approach which substantially reduces the human effort needed for pre-training a diverse set of skills. Our method uses two core ideas to automatically expand a base set of pre-training tasks: instruction relabeling via large language models and cross-trajectory skill chaining with offline reinforcement learning. As a result, SPRINT pre-training equips robots with a richer repertoire of skills that can help an agent generalize to new tasks. Experiments in a household simulator and on a real robot kitchen manipulation task show that SPRINT leads to substantially faster learning of new long-horizon tasks than previous pre-training approaches. Website at https://clvrai.com/sprint.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning",
      "abstract": "",
      "year": "1999",
      "venue": "Artificial Intelligence",
      "authors": "Richard S. Sutton, Doina Precup and Satinder Singh"
    },
    {
      "index": 1,
      "title": "Dynamic Movement Primitives - A Framework for Motor Control in Humans and Humanoid Robotics",
      "abstract": "",
      "year": "2006",
      "venue": "Adaptive Motion of Animals and Machines",
      "authors": "Stefan Schaal"
    },
    {
      "index": 2,
      "title": "Learning an embedding space for transferable robot skills",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "Karol Hausman et al."
    },
    {
      "index": 3,
      "title": "Learning Latent Plans from Play",
      "abstract": "",
      "year": "2020",
      "venue": "CoRL",
      "authors": "Corey Lynch et al.",
      "orig_title": "Learning latent plans from play",
      "paper_id": "1903.01973v2"
    },
    {
      "index": 4,
      "title": "Accelerating Reinforcement Learning with Learned Skill Priors",
      "abstract": "",
      "year": "2020",
      "venue": "CoRL",
      "authors": "Karl Pertsch, Youngwoon Lee and Joseph J. Lim",
      "orig_title": "Accelerating Reinforcement Learning with Learned Skill Priors",
      "paper_id": "2010.11944v1"
    },
    {
      "index": 5,
      "title": "Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv",
      "authors": "Tuomas Haarnoja et al.",
      "orig_title": "Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning",
      "paper_id": "2304.13653v2"
    },
    {
      "index": 6,
      "title": "CALVIN: A Benchmark for Language-Conditioned Policy Learning for Long-Horizon Robot Manipulation Tasks",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE Robotics and Automation Letters (RA-L)",
      "authors": "Oier Mees, Lukas Hermann, Erick Rosete-Beas and Wolfram Burgard",
      "orig_title": "CALVIN: A Benchmark for Language-Conditioned Policy Learning for Long-Horizon Robot Manipulation Tasks",
      "paper_id": "2112.03227v4"
    },
    {
      "index": 7,
      "title": "Language Conditioned Imitation Learning over Unstructured Data",
      "abstract": "",
      "year": "2021",
      "venue": "Robotics: Science and Systems",
      "authors": "Corey Lynch and Pierre Sermanet",
      "orig_title": "Language Conditioned Imitation Learning over Unstructured Data",
      "paper_id": "2005.07648v2"
    },
    {
      "index": 8,
      "title": "Interactive Language: Talking to Robots in Real Time",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Corey Lynch et al.",
      "orig_title": "Interactive language: Talking to robots in real time",
      "paper_id": "2210.06407v1"
    },
    {
      "index": 9,
      "title": "RT-1: Robotics Transformer for Real-World Control at Scale",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Anthony Brohan et al.",
      "orig_title": "Rt-1: Robotics transformer for real-world control at scale",
      "paper_id": "2212.06817v2"
    },
    {
      "index": 10,
      "title": "ALFRED A Benchmark for Interpreting Grounded Instructions for Everyday Tasks",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Mohit Shridhar et al.",
      "orig_title": "ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks",
      "paper_id": "1912.01734v2"
    },
    {
      "index": 11,
      "title": "Learning with latent language",
      "abstract": "",
      "year": "2017",
      "venue": "North American Chapter of the Association for Computational Linguistics",
      "authors": "Jacob Andreas, Dan Klein and Sergey Levine"
    },
    {
      "index": 12,
      "title": "R3M: A Universal Visual Representation for Robot Manipulation",
      "abstract": "",
      "year": "2022",
      "venue": "CoRL",
      "authors": "Suraj Nair et al.",
      "orig_title": "R3m: A universal visual representation for robot manipulation",
      "paper_id": "2203.12601v3"
    },
    {
      "index": 13,
      "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Linxi Fan et al."
    },
    {
      "index": 14,
      "title": "Reinforcement learning for mapping instructions to actions",
      "abstract": "",
      "year": "2009",
      "venue": "Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP",
      "authors": "Satchuthananthavale RK Branavan, Harr Chen, Luke Zettlemoyer and Regina Barzilay"
    },
    {
      "index": 15,
      "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "Jacob Andreas, Dan Klein and Sergey Levine",
      "orig_title": "Modular multitask reinforcement learning with policy sketches",
      "paper_id": "1611.01796v2"
    },
    {
      "index": 16,
      "title": "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Wenlong Huang, Pieter Abbeel, Deepak Pathak and Igor Mordatch",
      "orig_title": "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents",
      "paper_id": "2201.07207v2"
    },
    {
      "index": 17,
      "title": "Do As I Can and Not As I Say: Grounding Language in Robotic Affordances",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Michael Ahn et al."
    },
    {
      "index": 18,
      "title": "Inner Monologue: Embodied Reasoning through Planning with Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Wenlong Huang et al.",
      "orig_title": "Inner Monologue: Embodied Reasoning through Planning with Language Models",
      "paper_id": "2207.05608v1"
    },
    {
      "index": 19,
      "title": "ProgPrompt: Generating Situated Robot Task Plans using Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ICRA",
      "authors": "Ishika Singh et al.",
      "orig_title": "Progprompt: Generating situated robot task plans using large language models",
      "paper_id": "2209.11302v1"
    },
    {
      "index": 20,
      "title": "Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven Exploration",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "CÃ©dric Colas et al.",
      "orig_title": "Language as a cognitive tool to imagine goals in curiosity driven exploration",
      "paper_id": "2002.09253v4"
    },
    {
      "index": 21,
      "title": "Higher: Improving instruction following with hindsight generation for experience replay",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Symposium Series on Computational Intelligence (SSCI)",
      "authors": "Geoffrey Cideron, Mathieu Seurin, Florian Strub and Olivier Pietquin"
    },
    {
      "index": 22,
      "title": "Pre-Trained Language Models for Interactive Decision-Making",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Shuang Li et al.",
      "orig_title": "Pre-Trained Language Models for Interactive Decision-Making",
      "paper_id": "2202.01771v4"
    },
    {
      "index": 23,
      "title": "Movement imitation with nonlinear dynamical systems in humanoid robots",
      "abstract": "",
      "year": "2002",
      "venue": "IEEE International Conference on Robotics and Automation",
      "authors": "Auke Jan Ijspeert, Jun Nakanishi and Stefan Schaal"
    },
    {
      "index": 24,
      "title": "Reinforcement learning of motor skills in high dimensions: A path integral approach",
      "abstract": "",
      "year": "2010",
      "venue": "IEEE International Conference on Robotics and Automation",
      "authors": "Evangelos Theodorou, Jonas Buchli and Stefan Schaal"
    },
    {
      "index": 25,
      "title": "Deep Q-learning from Demonstrations",
      "abstract": "",
      "year": "2018",
      "venue": "Association for the Advancement of Artificial Intelligence",
      "authors": "Todd Hester et al.",
      "orig_title": "Deep q-learning from demonstrations",
      "paper_id": "1704.03732v4"
    },
    {
      "index": 26,
      "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Sergey Levine, Aviral Kumar, George Tucker and Justin Fu",
      "orig_title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems",
      "paper_id": "2005.01643v3"
    },
    {
      "index": 27,
      "title": "Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Xue Bin Peng, Aviral Kumar, Grace Zhang and Sergey Levine",
      "orig_title": "Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning",
      "paper_id": "1910.00177v3"
    },
    {
      "index": 28,
      "title": "COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Robot Learning",
      "authors": "Avi Singh et al."
    },
    {
      "index": 29,
      "title": "Accelerating Online Reinforcement Learning with Offline Datasets",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Ashvin Nair, Murtaza Dalal, Abhishek Gupta and Sergey Levine"
    },
    {
      "index": 30,
      "title": "Offline Reinforcement Learning with Implicit Q-Learning",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Learning Representations",
      "authors": "Ilya Kostrikov, Ashvin Nair and Sergey Levine",
      "orig_title": "Offline Reinforcement Learning with Implicit Q-Learning",
      "paper_id": "2110.06169v1"
    },
    {
      "index": 31,
      "title": "RL 2: Fast Reinforcement Learning via Slow Reinforcement Learning",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv",
      "authors": "Yan Duan et al."
    },
    {
      "index": 32,
      "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
      "abstract": "",
      "year": "2017",
      "venue": "ICML",
      "authors": "Chelsea Finn, Pieter Abbeel and Sergey Levine",
      "orig_title": "Model-agnostic meta-learning for fast adaptation of deep networks",
      "paper_id": "1703.03400v3"
    },
    {
      "index": 33,
      "title": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Kate Rakelly et al.",
      "orig_title": "Efficient off-policy meta-reinforcement learning via probabilistic context variables",
      "paper_id": "1903.08254v1"
    },
    {
      "index": 34,
      "title": "Skill-based Meta-Reinforcement Learning",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Learning Representations (ICLR)",
      "authors": "Taewook Nam et al.",
      "orig_title": "Skill-based Meta-Reinforcement Learning",
      "paper_id": "2204.11828v1"
    },
    {
      "index": 35,
      "title": "Variational Option Discovery Algorithms",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv",
      "authors": "Joshua Achiam, Harrison Edwards, Dario Amodei and Pieter Abbeel",
      "orig_title": "Variational Option Discovery Algorithms",
      "paper_id": "1807.10299v1"
    },
    {
      "index": 36,
      "title": "Diversity is All You Need: Learning Skills without a Reward Function",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz and Sergey Levine",
      "orig_title": "Diversity is All You Need: Learning Skills without a Reward Function",
      "paper_id": "1802.06070v6"
    },
    {
      "index": 37,
      "title": "Dynamics-Aware Unsupervised Discovery of Skills",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Archit Sharma et al.",
      "orig_title": "Dynamics-Aware Unsupervised Discovery of Skills",
      "paper_id": "1907.01657v2"
    },
    {
      "index": 38,
      "title": "OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Anurag Ajay et al."
    },
    {
      "index": 39,
      "title": "Parrot: Data-Driven Behavioral Priors for Reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "ICLR",
      "authors": "Avi Singh et al.",
      "orig_title": "Parrot: Data-Driven Behavioral Priors for Reinforcement Learning",
      "paper_id": "2011.10024v1"
    },
    {
      "index": 40,
      "title": "Discovering and Achieving Goals via World Models",
      "abstract": "",
      "year": "2021",
      "venue": "NeurIPS",
      "authors": "Russell Mendonca et al.",
      "orig_title": "Discovering and Achieving Goals via World Models",
      "paper_id": "2110.09514v1"
    },
    {
      "index": 41,
      "title": "Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Machine Learning",
      "authors": "Yevgen Chebotar et al."
    },
    {
      "index": 42,
      "title": "Scaling Robot Learning with Semantically Imagined Experience",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv",
      "authors": "Tianhe Yu et al.",
      "orig_title": "Scaling Robot Learning with Semantically Imagined Experience",
      "paper_id": "2302.11550v1"
    },
    {
      "index": 43,
      "title": "GenAug: Retargeting behaviors to unseen situations via Generative Augmentation",
      "abstract": "",
      "year": "2023",
      "venue": "RSS",
      "authors": "Zoey Chen, Sho Kiami, Abhishek Gupta and Vikash Kumar",
      "orig_title": "GenAug: Retargeting behaviors to unseen situations via Generative Augmentation",
      "paper_id": "2302.06671v2"
    },
    {
      "index": 44,
      "title": "CACTI: A Framework for Scalable Multi-Task Multi-Scene Visual Imitation Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv",
      "authors": "Zhao Mandi et al.",
      "orig_title": "CACTI: A Framework for Scalable Multi-Task Multi-Scene Visual Imitation Learning",
      "paper_id": "2212.05711v2"
    },
    {
      "index": 45,
      "title": "Robotic Skill Acquisition via Instruction Augmentation with Vision-Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "Robotics: Science and Systems",
      "authors": "Ted Xiao et al.",
      "orig_title": "Robotic Skill Acquistion via Instruction Augmentation with Vision-Language Models",
      "paper_id": "2211.11736v3"
    },
    {
      "index": 46,
      "title": "Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "CoRL",
      "authors": "Abhishek Gupta et al.",
      "orig_title": "Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning",
      "paper_id": "1910.11956v1"
    },
    {
      "index": 47,
      "title": "Bridge Data: Boosting Generalization of Robotic Skills with Cross-Domain Datasets",
      "abstract": "",
      "year": "2022",
      "venue": "RSS",
      "authors": "Frederik Ebert et al.",
      "orig_title": "Bridge data: Boosting generalization of robotic skills with cross-domain datasets",
      "paper_id": "2109.13396v1"
    },
    {
      "index": 48,
      "title": "Demonstration-Guided Reinforcement Learning with Learned Skills",
      "abstract": "",
      "year": "2021",
      "venue": "CoRL",
      "authors": "Karl Pertsch, Youngwoon Lee, Yue Wu and Joseph J. Lim",
      "orig_title": "Demonstration-Guided Reinforcement Learning with Learned Skills",
      "paper_id": "2107.10253v1"
    },
    {
      "index": 49,
      "title": "Learning to Achieve Goals",
      "abstract": "",
      "year": "1993",
      "venue": "IJCAI-93",
      "authors": "Leslie Pack Kaelbling"
    },
    {
      "index": 50,
      "title": "Universal Value Function Approximators",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Machine Learning",
      "authors": "Tom Schaul, Daniel Horgan, Karol Gregor and David Silver"
    },
    {
      "index": 51,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv",
      "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova",
      "orig_title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 52,
      "title": "Language Models are Few-Shot Learners",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Tom B. Brown et al.",
      "orig_title": "Language Models are Few-Shot Learners",
      "paper_id": "2005.14165v4"
    },
    {
      "index": 53,
      "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Ben Wang and Aran Komatsuzaki"
    },
    {
      "index": 54,
      "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Jack W. Rae et al.",
      "orig_title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
      "paper_id": "2112.11446v2"
    },
    {
      "index": 55,
      "title": "Training Compute-Optimal Large Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Jordan Hoffmann et al.",
      "orig_title": "Training Compute-Optimal Large Language Models",
      "paper_id": "2203.15556v1"
    },
    {
      "index": 56,
      "title": "OPT: Open Pre-trained Transformer Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Susan Zhang et al.",
      "orig_title": "OPT: Open Pre-trained Transformer Language Models",
      "paper_id": "2205.01068v4"
    },
    {
      "index": 57,
      "title": "PaLM: Scaling Language Modeling with Pathways",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Aakanksha Chowdhery et al.",
      "orig_title": "PaLM: Scaling Language Modeling with Pathways",
      "paper_id": "2204.02311v5"
    },
    {
      "index": 58,
      "title": "LLaMA: Open and Efficient Foundation Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv",
      "authors": "Hugo Touvron et al.",
      "orig_title": "LLaMA: Open and Efficient Foundation Language Models",
      "paper_id": "2302.13971v1"
    },
    {
      "index": 59,
      "title": "Contrastive Learning as Goal-Conditioned Reinforcement Learning",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Benjamin Eysenbach, Tianjun Zhang, Ruslan Salakhutdinov and Sergey Levine",
      "orig_title": "Contrastive Learning as Goal-Conditioned Reinforcement Learning",
      "paper_id": "2206.07568v2"
    },
    {
      "index": 60,
      "title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Tianhe Yu et al.",
      "orig_title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning",
      "paper_id": "1910.10897v2"
    },
    {
      "index": 61,
      "title": "Episodic Transformer for Vision-and-Language Navigation",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "Alexander Pashevich, Cordelia Schmid and Chen Sun"
    },
    {
      "index": 62,
      "title": "CLVR Jaco Play Dataset",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "Shivin Dass et al."
    },
    {
      "index": 63,
      "title": "BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning",
      "abstract": "",
      "year": "2021",
      "venue": "Conference on Robot Learning",
      "authors": "Eric Jang et al."
    },
    {
      "index": 64,
      "title": "Offline RL for Natural Language Generation with Implicit Language Q Learning",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv",
      "authors": "Charlie Snell et al.",
      "orig_title": "Offline RL for Natural Language Generation with Implicit Language Q Learning",
      "paper_id": "2206.11871v2"
    },
    {
      "index": 65,
      "title": "Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv",
      "authors": "Tony Z Zhao, Vikash Kumar, Sergey Levine and Chelsea Finn",
      "orig_title": "Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware",
      "paper_id": "2304.13705v1"
    },
    {
      "index": 66,
      "title": "PATO: Policy Assisted TeleOperation for Scalable Robot Data Collection",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv",
      "authors": "Shivin Dass et al."
    },
    {
      "index": 67,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 68,
      "title": "ImageNet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Jia Deng et al."
    },
    {
      "index": 69,
      "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
      "abstract": "",
      "year": "2019",
      "venue": "Conference on Empirical Methods in Natural Language Processing",
      "authors": "Nils Reimers and Iryna Gurevych",
      "orig_title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
      "paper_id": "1908.10084v1"
    },
    {
      "index": 70,
      "title": "FiLM: Visual Reasoning with a General Conditioning Layer",
      "abstract": "",
      "year": "2018",
      "venue": "Association for the Advancement of Artificial Intelligence",
      "authors": "Ethan Perez et al.",
      "orig_title": "FiLM: Visual Reasoning with a General Conditioning Layer",
      "paper_id": "1709.07871v2"
    }
  ]
}