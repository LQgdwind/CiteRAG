{
  "paper_id": "2008.04200v1",
  "title": "Describe What to Change: A Text-guided Unsupervised Image-to-Image Translation Approach",
  "abstract": "Abstract.\nManipulating visual attributes of images through human-written text is a very challenging task. On the one hand, models have to learn the manipulation without the ground truth of the desired output.\nOn the other hand, models have to deal with the inherent ambiguity of natural language. Previous research usually requires either the user to describe all the characteristics of the desired image or to use richly-annotated image captioning datasets.\nIn this work, we propose a novel unsupervised approach, based on image-to-image translation, that alters the attributes of a given image through a command-like sentence such as “change the hair color to black”. Contrarily to state-of-the-art approaches, our model does not require a human-annotated dataset nor a textual description of all the attributes of the desired image, but only those that have to be modified.\nOur proposed model disentangles the image content from the visual attributes, and it learns to modify the latter using the textual description, before generating a new image from the content and the modified attribute representation.\nBecause text might be inherently ambiguous (blond hair may refer to different shadows of blond, e.g. golden, icy, sandy), our method generates multiple stochastic versions of the same translation.\nExperiments show that the proposed model achieves promising performances on two large-scale public datasets: CelebA and CUB. We believe our approach will pave the way to new avenues of research combining textual and speech commands with visual attributes.",
  "reference_labels": [
    {
      "index": 0,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 1,
      "title": "Wasserstein generative adversarial networks",
      "abstract": "",
      "year": "2017",
      "venue": "ICML",
      "authors": "Martin Arjovsky, Soumith Chintala, and Léon Bottou"
    },
    {
      "index": 2,
      "title": "Layer normalization",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1607.06450",
      "authors": "Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton"
    },
    {
      "index": 3,
      "title": "Semantic Photo Manipulation with a Generative Image Prior",
      "abstract": "",
      "year": "2019",
      "venue": "ACM Transactions on Graphics (TOG)",
      "authors": "David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou, Jun-Yan Zhu, and Antonio Torralba",
      "orig_title": "Semantic photo manipulation with a generative image prior",
      "paper_id": "2005.07727v2"
    },
    {
      "index": 4,
      "title": "Enriching Word Vectors with Subword Information",
      "abstract": "",
      "year": "2017",
      "venue": "Transactions of the Association for Computational Linguistics",
      "authors": "Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov",
      "orig_title": "Enriching Word Vectors with Subword Information",
      "paper_id": "1607.04606v2"
    },
    {
      "index": 5,
      "title": "Language-based image editing with recurrent attentive models",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Jianbo Chen, Yelong Shen, Jianfeng Gao, Jingjing Liu, and Xiaodong Liu"
    },
    {
      "index": 6,
      "title": "Sequential attention gan for interactive image editing via dialogue",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI",
      "authors": "Yu Cheng, Zhe Gan, Yitong Li, Jingjing Liu, and Jianfeng Gao"
    },
    {
      "index": 7,
      "title": "StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo",
      "orig_title": "Stargan: Unified generative adversarial networks for multi-domain image-to-image translation",
      "paper_id": "1711.09020v3"
    },
    {
      "index": 8,
      "title": "StarGAN v2: Diverse Image Synthesis for Multiple Domains",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha",
      "orig_title": "StarGAN v2: Diverse Image Synthesis for Multiple Domains",
      "paper_id": "1912.01865v2"
    },
    {
      "index": 9,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei"
    },
    {
      "index": 10,
      "title": "Tutorial on Variational Autoencoders",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1606.05908",
      "authors": "Carl Doersch",
      "orig_title": "Tutorial on variational autoencoders",
      "paper_id": "1606.05908v3"
    },
    {
      "index": 11,
      "title": "Keep Drawing It: Iterative language-based image generation and editing",
      "abstract": "",
      "year": "2018",
      "venue": "NIPS",
      "authors": "Alaaeldin El-Nouby, Shikhar Sharma, Hannes Schulz, Devon Hjelm, Layla El Asri, Samira Ebrahimi Kahou, Yoshua Bengio, and Graham W Taylor"
    },
    {
      "index": 12,
      "title": "Tell, draw, and repeat: Generating and modifying images based on continual linguistic instruction",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Alaaeldin El-Nouby, Shikhar Sharma, Hannes Schulz, Devon Hjelm, Layla El Asri, Samira Ebrahimi Kahou, Yoshua Bengio, and Graham W Taylor"
    },
    {
      "index": 13,
      "title": "Text-based Editing of Talking-head Video",
      "abstract": "",
      "year": "2019",
      "venue": "ACM Transactions on Graphics (TOG)",
      "authors": "Ohad Fried, Ayush Tewari, Michael Zollhöfer, Adam Finkelstein, Eli Shechtman, Dan B Goldman, Kyle Genova, Zeyu Jin, Christian Theobalt, and Maneesh Agrawala",
      "orig_title": "Text-based editing of talking-head video",
      "paper_id": "1906.01524v1"
    },
    {
      "index": 14,
      "title": "Image-to-image translation for cross-domain disentanglement",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in neural information processing systems",
      "authors": "Abel Gonzalez-Garcia, Joost Van De Weijer, and Yoshua Bengio",
      "orig_title": "Image-to-image translation for cross-domain disentanglement",
      "paper_id": "1805.09730v3"
    },
    {
      "index": 15,
      "title": "Generative adversarial nets",
      "abstract": "",
      "year": "2014",
      "venue": "NIPS",
      "authors": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio"
    },
    {
      "index": 16,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 17,
      "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium",
      "abstract": "",
      "year": "2017",
      "venue": "NIPS",
      "authors": "Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter",
      "orig_title": "Gans trained by a two time-scale update rule converge to a local nash equilibrium",
      "paper_id": "1706.08500v6"
    },
    {
      "index": 18,
      "title": "Long short-term memory",
      "abstract": "",
      "year": "1997",
      "venue": "Neural computation",
      "authors": "Sepp Hochreiter and Jürgen Schmidhuber"
    },
    {
      "index": 19,
      "title": "Arbitrary style transfer in real-time with adaptive instance normalization",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Xun Huang and Serge Belongie"
    },
    {
      "index": 20,
      "title": "Multimodal Unsupervised Image-to-Image Translation",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Xun Huang, Ming-Yu Liu, Serge Belongie, and Jan Kautz",
      "orig_title": "Multimodal unsupervised image-to-image translation",
      "paper_id": "1804.04732v2"
    },
    {
      "index": 21,
      "title": "Image-to-Image Translation with Conditional Adversarial Networks",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros",
      "orig_title": "Image-to-image translation with conditional adversarial networks",
      "paper_id": "1611.07004v3"
    },
    {
      "index": 22,
      "title": "SC-FEGAN: Face Editing Generative Adversarial Network with User’s Sketch and Color",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Youngjoo Jo and Jongyoul Park"
    },
    {
      "index": 23,
      "title": "One Model To Learn Them All",
      "abstract": "",
      "year": "2017",
      "venue": "ArXiV",
      "authors": "Lukasz Kaiser, Aidan N Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion Jones, and Jakob Uszkoreit",
      "orig_title": "One Model To Learn Them All",
      "paper_id": "1706.05137v1"
    },
    {
      "index": 24,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2015",
      "venue": "ICLR",
      "authors": "Diederik P Kingma and Jimmy Ba"
    },
    {
      "index": 25,
      "title": "Controllable Text-to-Image Generation",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1909.07083",
      "authors": "Bowen Li, Xiaojuan Qi, Thomas Lukasiewicz, and Philip HS Torr"
    },
    {
      "index": 26,
      "title": "ManiGAN: Text-Guided Image Manipulation",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1912.06203",
      "authors": "Bowen Li, Xiaojuan Qi, Thomas Lukasiewicz, and Philip HS Torr",
      "orig_title": "ManiGAN: Text-Guided Image Manipulation",
      "paper_id": "1912.06203v2"
    },
    {
      "index": 27,
      "title": "Explicit Induction Bias for Transfer Learning with Convolutional Networks",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "Xuhong LI, Yves GRANDVALET, and Franck DAVOINE"
    },
    {
      "index": 28,
      "title": "StoryGAN: A Sequential Conditional GAN for Story Visualization",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Yitong Li, Zhe Gan, Yelong Shen, Jingjing Liu, Yu Cheng, Yuexin Wu, Lawrence Carin, David Carlson, and Jianfeng Gao",
      "orig_title": "StoryGAN: A Sequential Conditional GAN for Story Visualization",
      "paper_id": "1812.02784v2"
    },
    {
      "index": 29,
      "title": "GMM-UNIT: Unsupervised Multi-Domain and Multi-Modal Image-to-Image Translation via Attribute Gaussian Mixture Modeling",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2003.06788",
      "authors": "Yahui Liu, Marco De Nadai, Jian Yao, Nicu Sebe, Bruno Lepri, and Xavier Alameda-Pineda",
      "orig_title": "GMM-UNIT: Unsupervised Multi-Domain and Multi-Modal Image-to-Image Translation via Attribute Gaussian Mixture Modeling",
      "paper_id": "2003.06788v2"
    },
    {
      "index": 30,
      "title": "Gesture-to-Gesture Translation in the Wild via Category-Independent Conditional Maps",
      "abstract": "",
      "year": "2019",
      "venue": "ACM MM",
      "authors": "Yahui Liu, Marco De Nadai, Gloria Zen, Nicu Sebe, and Bruno Lepri",
      "orig_title": "Gesture-to-gesture translation in the wild via category-independent conditional maps",
      "paper_id": "1907.05916v3"
    },
    {
      "index": 31,
      "title": "Deep learning face attributes in the wild",
      "abstract": "",
      "year": "2015",
      "venue": "ICCV",
      "authors": "Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang"
    },
    {
      "index": 32,
      "title": "Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Qi Mao, Hsin-Ying Lee, Hung-Yu Tseng, Siwei Ma, and Ming-Hsuan Yang",
      "orig_title": "Mode seeking generative adversarial networks for diverse image synthesis",
      "paper_id": "1903.05628v6"
    },
    {
      "index": 33,
      "title": "Least Squares Generative Adversarial Networks",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smolley",
      "orig_title": "Least squares generative adversarial networks",
      "paper_id": "1611.04076v3"
    },
    {
      "index": 34,
      "title": "Unsupervised Attention-guided Image-to-Image Translation",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Youssef Alami Mejjati, Christian Richardt, James Tompkin, Darren Cosker, and Kwang In Kim",
      "orig_title": "Unsupervised attention-guided image-to-image translation",
      "paper_id": "1806.02311v3"
    },
    {
      "index": 35,
      "title": "Conditional Generative Adversarial Nets",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1411.1784",
      "authors": "Mehdi Mirza and Simon Osindero",
      "orig_title": "Conditional generative adversarial nets",
      "paper_id": "1411.1784v1"
    },
    {
      "index": 36,
      "title": "Instance-aware Image-to-Image Translation",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "Sangwoo Mo, Minsu Cho, and Jinwoo Shin"
    },
    {
      "index": 37,
      "title": "Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1907.09358",
      "authors": "Aditya Mogadala, Marimuthu Kalimuthu, and Dietrich Klakow"
    },
    {
      "index": 38,
      "title": "Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language",
      "abstract": "",
      "year": "2018",
      "venue": "NIPS",
      "authors": "Seonghyeon Nam, Yunji Kim, and Seon Joo Kim",
      "orig_title": "Text-adaptive generative adversarial networks: manipulating images with natural language",
      "paper_id": "1810.11919v2"
    },
    {
      "index": 39,
      "title": "Context Encoders: Feature Learning by Inpainting",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros",
      "orig_title": "Context encoders: Feature learning by inpainting",
      "paper_id": "1604.07379v2"
    },
    {
      "index": 40,
      "title": "GANimation: Anatomically-aware Facial Animation from a Single Image",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision (ECCV)",
      "authors": "Albert Pumarola, Antonio Agudo, Aleix M Martinez, Alberto Sanfeliu, and Francesc Moreno-Noguer",
      "orig_title": "Ganimation: Anatomically-aware facial animation from a single image",
      "paper_id": "1807.09251v2"
    },
    {
      "index": 41,
      "title": "MirrorGAN: Learning Text-to-image Generation by Redescription",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Tingting Qiao, Jing Zhang, Duanqing Xu, and Dacheng Tao",
      "orig_title": "MirrorGAN: Learning Text-to-image Generation by Redescription",
      "paper_id": "1903.05854v1"
    },
    {
      "index": 42,
      "title": "Generative Adversarial Text to Image Synthesis",
      "abstract": "",
      "year": "2016",
      "venue": "ICML",
      "authors": "Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee",
      "orig_title": "Generative Adversarial Text to Image Synthesis",
      "paper_id": "1605.05396v2"
    },
    {
      "index": 43,
      "title": "Learning What and Where to Draw",
      "abstract": "",
      "year": "2016",
      "venue": "NIPS",
      "authors": "Scott E Reed, Zeynep Akata, Santosh Mohan, Samuel Tenka, Bernt Schiele, and Honglak Lee",
      "orig_title": "Learning what and where to draw",
      "paper_id": "1610.02454v1"
    },
    {
      "index": 44,
      "title": "Improved Techniques for Training GANs",
      "abstract": "",
      "year": "2016",
      "venue": "NIPS",
      "authors": "Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen",
      "orig_title": "Improved techniques for training gans",
      "paper_id": "1606.03498v1"
    },
    {
      "index": 45,
      "title": "Dropout: a simple way to prevent neural networks from overfitting",
      "abstract": "",
      "year": "2014",
      "venue": "The journal of machine learning research",
      "authors": "Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov"
    },
    {
      "index": 46,
      "title": "Rethinking the inception architecture for computer vision",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna"
    },
    {
      "index": 47,
      "title": "Improved Texture Networks: Maximizing Quality and Diversity in Feed-forward Stylization and Texture Synthesis",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky",
      "orig_title": "Improved texture networks: Maximizing quality and diversity in feed-forward stylization and texture synthesis",
      "paper_id": "1701.02096v2"
    },
    {
      "index": 48,
      "title": "The caltech-ucsd birds-200-2011 dataset",
      "abstract": "",
      "year": "2011",
      "venue": "Technical Report",
      "authors": "Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie"
    },
    {
      "index": 49,
      "title": "Learning to Globally Edit Images with Textual Description",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1810.05786",
      "authors": "Hai Wang, Jason D Williams, and SingBing Kang",
      "orig_title": "Learning to Globally Edit Images with Textual Description",
      "paper_id": "1810.05786v1"
    },
    {
      "index": 50,
      "title": "Empirical Evaluation of Rectified Activations in Convolution Network",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:1505.00853",
      "authors": "Bing Xu, Naiyan Wang, Tianqi Chen, and Mu Li",
      "orig_title": "Empirical evaluation of rectified activations in convolutional network",
      "paper_id": "1505.00853v2"
    },
    {
      "index": 51,
      "title": "AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and Xiaodong He",
      "orig_title": "Attngan: Fine-grained text to image generation with attentional generative adversarial networks",
      "paper_id": "1711.10485v1"
    },
    {
      "index": 52,
      "title": "Boosting Image Captioning with Attributes",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Ting Yao, Yingwei Pan, Yehao Li, Zhaofan Qiu, and Tao Mei",
      "orig_title": "Boosting image captioning with attributes",
      "paper_id": "1611.01646v1"
    },
    {
      "index": 53,
      "title": "StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris N Metaxas",
      "orig_title": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks",
      "paper_id": "1612.03242v2"
    },
    {
      "index": 54,
      "title": "StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks",
      "abstract": "",
      "year": "2018",
      "venue": "TPAMI",
      "authors": "Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris N Metaxas",
      "orig_title": "Stackgan++: Realistic image synthesis with stacked generative adversarial networks",
      "paper_id": "1710.10916v3"
    },
    {
      "index": 55,
      "title": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang",
      "orig_title": "The unreasonable effectiveness of deep features as a perceptual metric",
      "paper_id": "1801.03924v2"
    },
    {
      "index": 56,
      "title": "Pluralistic Image Completion",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Chuanxia Zheng, Tat-Jen Cham, and Jianfei Cai"
    },
    {
      "index": 57,
      "title": "Unpaired image-to-image translation using cycle-consistent adversarial networks",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros"
    },
    {
      "index": 58,
      "title": "Toward Multimodal Image-to-Image Translation",
      "abstract": "",
      "year": "2017",
      "venue": "NIPS",
      "authors": "Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A Efros, Oliver Wang, and Eli Shechtman",
      "orig_title": "Toward multimodal image-to-image translation",
      "paper_id": "1711.11586v4"
    },
    {
      "index": 59,
      "title": "Language-based Colorization of Scene Sketches",
      "abstract": "",
      "year": "2019",
      "venue": "ACM Transactions on Graphics",
      "authors": "Changqing Zou, Haoran Mo, Chengying Gao, Ruofei Du, and Hongbo Fu"
    }
  ]
}