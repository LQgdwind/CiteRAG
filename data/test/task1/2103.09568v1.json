{
  "paper_id": "2103.09568v1",
  "title": "A practical guide to multi-objective reinforcement learning and planning",
  "abstract": "Abstract\nReal-world decision-making tasks are generally complex, requiring trade-offs between multiple, often conflicting, objectives. Despite this, the\nmajority of research in reinforcement learning and decision-theoretic planning either assumes only a single objective, or that multiple objectives can be adequately handled via a simple linear combination. Such approaches may oversimplify the underlying problem and hence produce suboptimal results. This paper serves as a guide to the application of multi-objective methods to difficult problems, and is aimed at researchers who are already familiar with single-objective reinforcement learning and planning methods who wish to adopt a multi-objective perspective on their research, as well as practitioners who encounter multi-objective decision problems in practice. It identifies the factors that may influence the nature of the desired solution, and illustrates by example how these influence the design of multi-objective decision-making systems for complex problems.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Intrinsically motivated hierarchical policy learning in multi-objective markov decision processes",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Cognitive and Developmental Systems",
      "authors": "S. Abdelfattah, K. Merrick, and J. Hu"
    },
    {
      "index": 1,
      "title": "A review of maximum power point tracking algorithms for wind energy systems",
      "abstract": "",
      "year": "2012",
      "venue": "Renewable and Sustainable Energy Reviews",
      "authors": "M. Abdullah, A. Yatim, C. Tan, and R. Saidur"
    },
    {
      "index": 2,
      "title": "Dynamic Weights in Multi-Objective Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Machine Learning",
      "authors": "A. Abels, D. Roijers, T. Lenaerts, A. Nowé, and D. Steckelmacher",
      "orig_title": "Dynamic weights in multi-objective deep reinforcement learning",
      "paper_id": "1809.07803v2"
    },
    {
      "index": 3,
      "title": "Efficient and effective reactive scheduling of manufacturing system using sarsa-multi-objective agents",
      "abstract": "",
      "year": "2008",
      "venue": "MOSIM’08: 7th Conference Internationale de Modelisation et Simulation",
      "authors": "N. Aissani, B. Beldjilali, and D. Trentesaux"
    },
    {
      "index": 4,
      "title": "Coevolutionary multiobjective evolutionary algorithms: Survey of the state-of-the-art",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Transactions on Evolutionary Computation",
      "authors": "L. M. Antonio and C. A. C. Coello"
    },
    {
      "index": 5,
      "title": "Distributed reinforcement learning using bi-directional decision making for multi-criteria control of multi-stage flow systems",
      "abstract": "",
      "year": "2004",
      "venue": "The 8th Conference on Intelligent Autonomous Systems",
      "authors": "K. Aoki, H. Kimura, and S. Kobayashi"
    },
    {
      "index": 6,
      "title": "Correlated equilibrium as an expression of bayesian rationality",
      "abstract": "",
      "year": "1987",
      "venue": "Econometrica: Journal of the Econometric Society",
      "authors": "R. J. Aumann"
    },
    {
      "index": 7,
      "title": "Optimal strategies for multi objective games and their search by evolutionary multi objective optimization",
      "abstract": "",
      "year": "2011",
      "venue": "2011 IEEE Conference on Computational Intelligence and Games (CIG’11)",
      "authors": "G. Avigad, E. Eisenstadt, and M. W. Cohen"
    },
    {
      "index": 8,
      "title": "Successor features for transfer in reinforcement learning",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "A. Barreto, W. Dabney, R. Munos, J. J. Hunt, T. Schaul, H. P. van Hasselt, and D. Silver"
    },
    {
      "index": 9,
      "title": "Learning all optimal policies with multiple criteria",
      "abstract": "",
      "year": "2008",
      "venue": "25th international conference on Machine learning",
      "authors": "L. Barrett and S. Narayanan"
    },
    {
      "index": 10,
      "title": "Aggregation of dependent criteria in multicriteria decision making problems by means of capacities",
      "abstract": "",
      "year": "2019",
      "venue": "23rd International Congress on Modelling and Simulation",
      "authors": "G. Beliakov, S. Bowsell, T. Cao, R. Dazeley, V. Mak-Hau, M.-T. Nguyen, T. Wilkin, and J. Yearwood"
    },
    {
      "index": 11,
      "title": "Universal Successor Features Approximators",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "D. Borsa, A. Barreto, J. Quan, D. J. Mankowitz, H. van Hasselt, R. Munos, D. Silver, and T. Schaul",
      "orig_title": "Universal successor features approximators",
      "paper_id": "1812.07626v1"
    },
    {
      "index": 12,
      "title": "Survey on applications of multi-armed and contextual bandits",
      "abstract": "",
      "year": "2020",
      "venue": "2020 IEEE Congress on Evolutionary Computation (CEC)",
      "authors": "D. Bouneffouf, I. Rish, and C. Aggarwal"
    },
    {
      "index": 13,
      "title": "Probabilistic planning is multi-objective",
      "abstract": "",
      "year": "2007",
      "venue": "Arizona State University, Tech. Rep. ASU-CSE-07-006",
      "authors": "D. Bryce, W. Cushing, and S. Kambhampati"
    },
    {
      "index": 14,
      "title": "On the behaviour of scalarization methods for the engagement of a wet clutch",
      "abstract": "",
      "year": "2013",
      "venue": "2013 12th International Conference on Machine Learning and Applications",
      "authors": "T. Brys, K. Van Moffaert, K. Van Vaerenbergh, and A. Nowé"
    },
    {
      "index": 15,
      "title": "Water reservoir control under economic, social and environmental constraints",
      "abstract": "",
      "year": "2008",
      "venue": "Automatica",
      "authors": "A. Castelletti, F. Pianosi, and R. Soncini-Sessa"
    },
    {
      "index": 16,
      "title": "Tree-based fitted q-iteration for multi-objective markov decision problems",
      "abstract": "",
      "year": "2012",
      "venue": "IJCNN",
      "authors": "A. Castelletti, F. Pianosi, and M. Restelli"
    },
    {
      "index": 17,
      "title": "A multiobjective reinforcement learning approach to water resources systems operation: Pareto frontier approximation in a single run",
      "abstract": "",
      "year": "2013",
      "venue": "Water Resources Research",
      "authors": "A. Castelletti, F. Pianosi, and M. Restelli"
    },
    {
      "index": 18,
      "title": "Combining a gradient-based method and an evolution strategy for multi-objective reinforcement learning",
      "abstract": "",
      "year": "2020",
      "venue": "Applied Intelligence",
      "authors": "D. Chen, Y. Wang, and W. Gao"
    },
    {
      "index": 19,
      "title": "Pareto Monte Carlo Tree Search for Multi-Objective Informative Planning",
      "abstract": "",
      "year": "2019",
      "venue": "Robotics: Science and Systems",
      "authors": "W. Chen and L. Liu",
      "orig_title": "Pareto monte carlo tree search for multi-objective informative planning",
      "paper_id": "2111.01825v1"
    },
    {
      "index": 20,
      "title": "Meta-Learning for Multi-objective Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "2019 IEEE/RSJ International Conference on Intelligent Robots\nand Systems (IROS)",
      "authors": "X. Chen, A. Ghadirzadeh, M. Björkman, and P. Jensfelt.",
      "orig_title": "Meta-learning for multi-objective reinforcement learning",
      "paper_id": "1811.03376v2"
    },
    {
      "index": 21,
      "title": "Algorithms for partially observable Markov decision processes",
      "abstract": "",
      "year": "1988",
      "venue": "PhD thesis, University of British Columbia",
      "authors": "H.-T. Cheng."
    },
    {
      "index": 22,
      "title": "Cooperation and self-interest: Pareto-inefficiency of nash equilibria in finite random games",
      "abstract": "",
      "year": "1998",
      "venue": "Proceedings of the National Academy of Sciences, 95(17):",
      "authors": "J. E. Cohen."
    },
    {
      "index": 23,
      "title": "Memory-based explainable reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "Australasian Joint Conference on Artificial Intelligence",
      "authors": "F. Cruz, R. Dazeley, and P. Vamplew."
    },
    {
      "index": 24,
      "title": "Multi-objective reinforcement learning for reconfiguring data stream analytics on edge computing",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the 48th International Conference on Parallel\nProcessing",
      "authors": "A. da Silva Veith, F. R. de Souza, M. D. de Assunção, L. Lefèvre,\nand J. C. S. dos Anjos."
    },
    {
      "index": 25,
      "title": "A fast and elitist multi-objective genetic algorithm: NSGA-II",
      "abstract": "",
      "year": "2002",
      "venue": "IEEE transactions on evolutionary computation, 6(2):182–197",
      "authors": "K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan."
    },
    {
      "index": 26,
      "title": "A survey on policy search for robotics",
      "abstract": "",
      "year": "2013",
      "venue": "Foundations and Trends® in Robotics,\n2(1–2):1–142",
      "authors": "M. P. Deisenroth, G. Neumann, J. Peters, et al."
    },
    {
      "index": 27,
      "title": "Bounded decentralised coordination over multiple objectives",
      "abstract": "",
      "year": "2011",
      "venue": "Proceedings of the Tenth International Joint Conference on\nAutonomous Agents and Multiagent Systems",
      "authors": "F. Delle Fave, R. Stranders, A. Rogers, and N. Jennings."
    },
    {
      "index": 28,
      "title": "An integrated generation-compensation optimization strategy for enhanced short-term voltage security of large-scale power systems using multi-objective reinforcement learning method",
      "abstract": "",
      "year": "2018",
      "venue": "2018 International Conference on Power System Technology\n(POWERCON)",
      "authors": "Z. Deng and M. Liu."
    },
    {
      "index": 29,
      "title": "Coordinated optimization of generation and compensation to enhance short-term voltage security of power systems using accelerated multi-objective reinforcement learning",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Access, 8:",
      "authors": "Z. Deng, Z. Lu, Z. Guo, W. Yao, W. Zhao, B. Zhou, and C. Hong."
    },
    {
      "index": 30,
      "title": "Dynamic potential-based reward shaping",
      "abstract": "",
      "year": "2012",
      "venue": "Proceedings of the 11th International Conference on\nAutonomous Agents and Multiagent Systems",
      "authors": "S. M. Devlin and D. Kudenko."
    },
    {
      "index": 31,
      "title": "Multiobjective reinforcement learning for reconfigurable adaptive optimal control of manufacturing processes",
      "abstract": "",
      "year": "2018",
      "venue": "2018 International Symposium on Electronics and\nTelecommunications (ISETC)",
      "authors": "J. Dornheim and N. Link."
    },
    {
      "index": 32,
      "title": "Designing multi-objective multi-armed bandits algorithms: A study",
      "abstract": "",
      "year": "2013",
      "venue": "The 2013 International Joint Conference on Neural Networks\n(IJCNN)",
      "authors": "M. M. Drugan and A. Nowe."
    },
    {
      "index": 33,
      "title": "Multi-objective game theoretic scheduling of bag-of-tasks workflows on hybrid clouds",
      "abstract": "",
      "year": "2014",
      "venue": "IEEE Transactions on Cloud Computing, 2(1):29–42",
      "authors": "R. Duan, R. Prodan, and X. Li."
    },
    {
      "index": 34,
      "title": "Inefficiency of smooth market mechanisms",
      "abstract": "",
      "year": "1990",
      "venue": "Journal of Mathematical Economics, 19(3):285–304",
      "authors": "P. Dubey and J. Rogawski."
    },
    {
      "index": 35,
      "title": "Distributed w-learning: Multi-policy optimization in self-organizing systems",
      "abstract": "",
      "year": "2009",
      "venue": "2009 Third IEEE International Conference on Self-Adaptive\nand Self-Organizing Systems",
      "authors": "I. Dusparic and V. Cahill."
    },
    {
      "index": 36,
      "title": "Multi-objective routing in integrated services networks: A game theory approach",
      "abstract": "",
      "year": "1991",
      "venue": "Infocom, volume 91",
      "authors": "A. A. Economides, J. A. Silvester, et al."
    },
    {
      "index": 37,
      "title": "Co-evolution of strategies for multi-objective games under postponed objective preferences",
      "abstract": "",
      "year": "2015",
      "venue": "2015 IEEE Conference on Computational Intelligence and Games\n(CIG)",
      "authors": "E. Eisenstadt, A. Moshaiov, and G. Avigad."
    },
    {
      "index": 38,
      "title": "Parallel reward and punishment control in humans and robots: Safe reinforcement learning using the maxpain algorithm",
      "abstract": "",
      "year": "2017",
      "venue": "2017 Joint IEEE International Conference on Development and\nLearning and Epigenetic Robotics (ICDL-EpiRob)",
      "authors": "S. Elfwing and B. Seymour."
    },
    {
      "index": 39,
      "title": "Tree-based batch mode reinforcement learning",
      "abstract": "",
      "year": "2005",
      "venue": "Journal of Machine Learning Research, 6(Apr):503–556",
      "authors": "D. Ernst, P. Geurts, and L. Wehenkel."
    },
    {
      "index": 40,
      "title": "Indicator-based multi-objective evolutionary algorithms: A comprehensive survey",
      "abstract": "",
      "year": "2020",
      "venue": "ACM Computing Surveys (CSUR), 53(2):1–35",
      "authors": "J. G. Falcón-Cardona and C. A. C. Coello."
    },
    {
      "index": 41,
      "title": "Reinforcement learning for satellite communications: from leo to deep space operations",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Communications Magazine, 57(5):70–75",
      "authors": "P. V. R. Ferreira, R. Paffenroth, A. M. Wyglinski, T. M. Hackett, S. G. Bilen,\nR. C. Reinhart, and D. J. Mortensen."
    },
    {
      "index": 42,
      "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "C. Finn, P. Abbeel, and S. Levine.",
      "orig_title": "Model-agnostic meta-learning for fast adaptation of deep networks",
      "paper_id": "1703.03400v3"
    },
    {
      "index": 43,
      "title": "Multi-criteria reinforcement learning",
      "abstract": "",
      "year": "1998",
      "venue": "ICML, volume 98",
      "authors": "Z. Gábor, Z. Kalmár, and C. Szepesvári."
    },
    {
      "index": 44,
      "title": "Exact methods for computing all lorenz optimal solutions to biobjective problems",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Algorithmic DecisionTheory",
      "authors": "L. Galand and T. Lust."
    },
    {
      "index": 45,
      "title": "A comprehensive survey on safe reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "Journal of Machine Learning Research, 16(1):",
      "authors": "J. Garcıa and F. Fernández."
    },
    {
      "index": 46,
      "title": "Reinforcement learning for MDPs with constraints",
      "abstract": "",
      "year": "2006",
      "venue": "European Conference on Machine Learning, pages 646–653.\nSpringer",
      "authors": "P. Geibel."
    },
    {
      "index": 47,
      "title": "Risk-sensitive reinforcement learning applied to control under constraints",
      "abstract": "",
      "year": "2005",
      "venue": "Journal of Artificial Intelligence Research, 24:81–108",
      "authors": "P. Geibel and F. Wysotzki."
    },
    {
      "index": 48,
      "title": "A dimensionality reduction approach for many-objective markov decision processes: Application to a water reservoir operation problem",
      "abstract": "",
      "year": "2014",
      "venue": "Environmental Modelling & Software, 57:101–114",
      "authors": "M. Giuliani, S. Galelli, and R. Soncini-Sessa."
    },
    {
      "index": 49,
      "title": "Curses, tradeoffs, and scalable management: Advancing evolutionary multiobjective direct policy search to improve water reservoir operations",
      "abstract": "",
      "year": "2016",
      "venue": "Journal of Water Resources Planning and Management,\n142(2):",
      "authors": "M. Giuliani, A. Castelletti, F. Pianosi, E. Mason, and P. M. Reed."
    },
    {
      "index": 50,
      "title": "Applying reinforcement learning to plan manufacturing material handling part 1: Background and formal problem specification",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the",
      "authors": "S. Govindaiah and M. D. Petty."
    },
    {
      "index": 51,
      "title": "Utilitarian mechanism design for multi-objective optimization",
      "abstract": "",
      "year": "2010",
      "venue": "Proceedings of the twenty-first annual ACM-SIAM symposium on\nDiscrete Algorithms, pages 573–584. Society for Industrial and Applied\nMathematics",
      "authors": "F. Grandoni, P. Krysta, S. Leonardi, and C. Ventre."
    },
    {
      "index": 52,
      "title": "A reinforcement learning approach to setting multi-objective goals for energy demand management",
      "abstract": "",
      "year": "2009",
      "venue": "International Journal of Agent Technologies and Systems\n(IJATS), 1(2):55–70",
      "authors": "Y. Guo, A. Zeman, and R. Li."
    },
    {
      "index": 53,
      "title": "Dynamic multi-objective optimisation using deep reinforcement learning: benchmark, algorithm and an application to identify vulnerable zones based on water quality",
      "abstract": "",
      "year": "2019",
      "venue": "Engineering Applications of Artificial Intelligence,\n86:107–135",
      "authors": "M. M. Hasan, K. Lwin, M. Imani, A. Shabut, L. F. Bittencourt, and M. A.\nHossain."
    },
    {
      "index": 54,
      "title": "Double q-learning",
      "abstract": "",
      "year": "2010",
      "venue": "Advances in neural information processing systems,\n23:",
      "authors": "H. Hasselt."
    },
    {
      "index": 55,
      "title": "Distributional monte carlo tree search for risk-aware and multi-objective reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the 20th International Conference on\nAutonomous Agents and MultiAgent Systems, volume",
      "authors": "C. F. Hayes, M. Reymond, D. M. Roijers, E. Howley, and P. Mannion."
    },
    {
      "index": 56,
      "title": "Risk-aware and multi-objective decision making with distributional monte carlo tree search",
      "abstract": "",
      "year": "",
      "venue": "arXiv preprint arXiv:",
      "authors": "C. F. Hayes, M. Reymond, D. M. Roijers, E. Howley, and P. Mannion."
    },
    {
      "index": 57,
      "title": "Multi-objective safe reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "Artificial Life and Robotics",
      "authors": "N. Horie, T. Matsui, K. Moriyama, A. Mutoh, and N. Inuzuka."
    },
    {
      "index": 58,
      "title": "Molecular Design in Synthetically Accessible Chemical Space via Deep Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:",
      "authors": "J. Horwood and E. Noutahi.",
      "orig_title": "Molecular design in synthetically accessible chemical space via deep reinforcement learning",
      "paper_id": "2004.14308v2"
    },
    {
      "index": 59,
      "title": "Dynamic beam hopping method based on multi-objective deep reinforcement learning for next generation satellite broadband systems",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Broadcasting",
      "authors": "X. Hu, Y. Zhang, X. Liao, Z. Liu, W. Wang, and F. M. Ghannouchi."
    },
    {
      "index": 60,
      "title": "Learning Gentle Object Manipulation with Curiosity-Driven Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:",
      "authors": "S. H. Huang, M. Zambelli, J. Kay, M. F. Martins, Y. Tassa, P. M. Pilarski, and\nR. Hadsell.",
      "orig_title": "Learning gentle object manipulation with curiosity-driven deep reinforcement learning",
      "paper_id": "1903.08542v1"
    },
    {
      "index": 61,
      "title": "Multi-criteria coalition formation games",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Algorithmic Decision Theory",
      "authors": "A. Igarashi and D. M. Roijers."
    },
    {
      "index": 62,
      "title": "Inverse reinforcement learning approach for elicitation of preferences in multi-objective sequential optimization",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "A. Ikenaga and S. Arai."
    },
    {
      "index": 63,
      "title": "Queued pareto local search for multi-objective optimization",
      "abstract": "",
      "year": "2014",
      "venue": "International Conference on Parallel Problem Solving from\nNature",
      "authors": "M. Inja, C. Kooijman, M. de Waard, D. M. Roijers, and S. Whiteson."
    },
    {
      "index": 64,
      "title": "An empirical comparison of two common multiobjective reinforcement learning algorithms",
      "abstract": "",
      "year": "2012",
      "venue": "Australasian Joint Conference on Artificial Intelligence",
      "authors": "R. Issabekov and P. Vamplew."
    },
    {
      "index": 65,
      "title": "Multi-objective optimization of radiotherapy: distributed q-learning and agent-based simulation",
      "abstract": "",
      "year": "2017",
      "venue": "Journal of Experimental & Theoretical artificial\nintelligence, 29(5):",
      "authors": "A. Jalalimanesh, H. S. Haghighi, A. Ahmadi, H. Hejazian, and M. Soltani."
    },
    {
      "index": 66,
      "title": "A multi-objective agent-based control approach with application in intelligent traffic signal system",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Intelligent Transportation Systems,\n20(10):",
      "authors": "J. Jin and X. Ma."
    },
    {
      "index": 67,
      "title": "Automated negotiating agents competition (anac)",
      "abstract": "",
      "year": "2017",
      "venue": "Thirty-First AAAI Conference on Artificial Intelligence",
      "authors": "C. M. Jonker, R. Aydoğan, T. Baarslag, K. Fujita, T. Ito, and\nK. Hindriks."
    },
    {
      "index": 68,
      "title": "Explainable reinforcement learning via reward decomposition",
      "abstract": "",
      "year": "2019",
      "venue": "IJCAI/ECAI Workshop on Explainable Artificial Intelligence",
      "authors": "Z. Juozapaitis, A. Koul, A. Fern, M. Erwig, and F. Doshi-Velez."
    },
    {
      "index": 69,
      "title": "Identification and Off-Policy Learning of Multiple Objectives Using Adaptive Clustering",
      "abstract": "",
      "year": "2017",
      "venue": "Neurocomputing, 263:39–47",
      "authors": "T. G. Karimpanal and E. Wilhelm.",
      "orig_title": "Identification and off-policy learning of multiple objectives using adaptive clustering",
      "paper_id": "1705.06342v1"
    },
    {
      "index": 70,
      "title": "Jupyter notebooks - a publishing format for reproducible computational workflows",
      "abstract": "",
      "year": "2016",
      "venue": "F. Loizides and B. Scmidt, editors, Positioning and Power in\nAcademic Publishing: Players, Agents and Agendas, pages 87–90, Netherlands",
      "authors": "T. Kluyver, B. Ragan-Kelley, F. Pérez, B. Granger, M. Bussonnier,\nJ. Frederic, K. Kelley, J. Hamrick, J. Grout, S. Corlay, P. Ivanov, D. Avila,\nS. Abdalla, C. Willing, and J. development team."
    },
    {
      "index": 71,
      "title": "Reinforcement learning for pricing strategy optimization in the insurance industry",
      "abstract": "",
      "year": "2019",
      "venue": "Engineering Applications of Artificial Intelligence,\n80:8–19",
      "authors": "E. Krasheninnikova, J. García, R. Maestre, and F. Fernández."
    },
    {
      "index": 72,
      "title": "Set-valued dynamic treatment regimes for competing outcomes",
      "abstract": "",
      "year": "2014",
      "venue": "Biometrics, 70(1):53–61",
      "authors": "E. B. Laber, D. J. Lizotte, and B. Ferguson."
    },
    {
      "index": 73,
      "title": "Multi-objective ranked bandits for recommender systems",
      "abstract": "",
      "year": "2017",
      "venue": "Neurocomputing, 246:12–24",
      "authors": "A. Lacerda."
    },
    {
      "index": 74,
      "title": "Multi-objective game-theory models for conflict analysis in reservoir watershed management",
      "abstract": "",
      "year": "2012",
      "venue": "Chemosphere, 87(6):608–613",
      "authors": "C.-S. Lee."
    },
    {
      "index": 75,
      "title": "Machine learning for predictive and prescriptive analytics of operational data in smart manufacturing",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Advanced Information Systems\nEngineering",
      "authors": "K. Lepenioti, M. Pertselakis, A. Bousdekis, A. Louca, F. Lampathaki,\nD. Apostolou, G. Mentzas, and S. Anastasiou."
    },
    {
      "index": 76,
      "title": "Many-objective evolutionary algorithms: A survey",
      "abstract": "",
      "year": "2015",
      "venue": "ACM Computing Surveys (CSUR), 48(1):1–35",
      "authors": "B. Li, J. Li, K. Tang, and X. Yao."
    },
    {
      "index": 77,
      "title": "Urban Driving with Multi-Objective Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the 18th International Conference on\nAutonomous Agents and MultiAgent Systems, pages 359–367. International\nFoundation for Autonomous Agents and Multiagent Systems",
      "authors": "C. Li and K. Czarnecki.",
      "orig_title": "Urban driving with multi-objective deep reinforcement learning",
      "paper_id": "1811.08586v2"
    },
    {
      "index": 78,
      "title": "Deep Reinforcement Learning for Multi-objective Optimization",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Cybernetics",
      "authors": "K. Li, T. Zhang, and R. Wang.",
      "orig_title": "Deep reinforcement learning for multiobjective optimization",
      "paper_id": "1906.02386v2"
    },
    {
      "index": 79,
      "title": "Application of game theory based hybrid algorithm for multi-objective integrated process planning and scheduling",
      "abstract": "",
      "year": "2012",
      "venue": "Expert Systems with Applications, 39(1):288–297",
      "authors": "X. Li, L. Gao, and W. Li."
    },
    {
      "index": 80,
      "title": "Continuous control with deep reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:",
      "authors": "T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa,\nD. Silver, and D. Wierstra."
    },
    {
      "index": 81,
      "title": "Efficient reinforcement learning with multiple reward functions for randomized controlled trial analysis",
      "abstract": "",
      "year": "2010",
      "venue": "Proceedings of the 27th International Conference on Machine\nLearning (ICML-10)",
      "authors": "D. J. Lizotte, M. H. Bowling, and S. A. Murphy."
    },
    {
      "index": 82,
      "title": "Universal Successor Representations for Transfer Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:",
      "authors": "C. Ma, J. Wen, and Y. Bengio.",
      "orig_title": "Universal successor representations for transfer reinforcement learning",
      "paper_id": "1804.03758v1"
    },
    {
      "index": 83,
      "title": "Where to add actions in human-in-the-loop reinforcement learning",
      "abstract": "",
      "year": "2017",
      "venue": "AAAI",
      "authors": "T. Mandel, Y.-E. Liu, E. Brunskill, and Z. Popovic."
    },
    {
      "index": 84,
      "title": "Pruning dominated policies in multiobjective Pareto q-learning",
      "abstract": "",
      "year": "2018",
      "venue": "Conference of the Spanish Association for Artificial\nIntelligence",
      "authors": "L. Mandow and J.-L. Pérez-de-la Cruz."
    },
    {
      "index": 85,
      "title": "An experimental review of reinforcement learning algorithms for adaptive traffic signal control",
      "abstract": "",
      "year": "2016",
      "venue": "Autonomic Road Transport Support Systems, pages 47–66.\nSpringer, Cham",
      "authors": "P. Mannion, J. Duggan, and E. Howley."
    },
    {
      "index": 86,
      "title": "Policy invariance under reward transformations for multi-objective reinforcement learning",
      "abstract": "",
      "year": "2017",
      "venue": "Neurocomputing, 263",
      "authors": "P. Mannion, S. Devlin, K. Mason, J. Duggan, and E. Howley."
    },
    {
      "index": 87,
      "title": "Reward shaping for knowledge-based multi-objective multi-agent reinforcement learning",
      "abstract": "",
      "year": "2018",
      "venue": "The Knowledge Engineering Review, 33(e23)",
      "authors": "P. Mannion, S. Devlin, J. Duggan, and E. Howley."
    },
    {
      "index": 88,
      "title": "Exploiting problem decomposition in multi-objective constraint optimization",
      "abstract": "",
      "year": "2009",
      "venue": "International Conference on Principles and Practice of\nConstraint Programming",
      "authors": "R. Marinescu."
    },
    {
      "index": 89,
      "title": "Efficient approximation algorithms for multi-objective constraint optimization",
      "abstract": "",
      "year": "2011",
      "venue": "ADT 2011: Proceedings of the Second International Conference\non Algorithmic Decision Theory",
      "authors": "R. Marinescu."
    },
    {
      "index": 90,
      "title": "Cost efficient distributed load frequency control in power systems",
      "abstract": "",
      "year": "2020",
      "venue": "21st IFAC World Congress, February",
      "authors": "F. Mello, D. Apostolopoulou, and E. Alonso."
    },
    {
      "index": 91,
      "title": "A multi-objective reinforcement learning algorithm for jssp",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Artificial Neural Networks",
      "authors": "B. M. Méndez-Hernández, E. D. Rodríguez-Bazan,\nY. Martinez-Jimenez, P. Libin, and A. Nowé."
    },
    {
      "index": 92,
      "title": "A review on wind turbine control and its associated methods",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of Cleaner Production, 174:945–953",
      "authors": "E. J. N. Menezes, A. M. Araújo, and N. S. B. da Silva."
    },
    {
      "index": 93,
      "title": "Towards a multi-objective reinforcement learning based routing protocol for cognitive radio networks",
      "abstract": "",
      "year": "2018",
      "venue": "2018 International Conference on Smart Communications in\nNetwork Technologies (SaCoNeT)",
      "authors": "C. Messikh and N. Zarour."
    },
    {
      "index": 94,
      "title": "Human-level control through deep reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "nature, 518(",
      "authors": "V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare,\nA. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, et al."
    },
    {
      "index": 95,
      "title": "Lorenz versus pareto dominance in a single machine scheduling problem with rejection",
      "abstract": "",
      "year": "2011",
      "venue": "International Conference on Evolutionary Multi-Criterion\nOptimization",
      "authors": "A. Moghaddam, F. Yalaoui, and L. Amodeo."
    },
    {
      "index": 96,
      "title": "Multi-Objective Deep Reinforcement Learning",
      "abstract": "",
      "year": "2016",
      "venue": "NIPS",
      "authors": "H. Mossalam, Y. M. Assael, D. M. Roijers, and S. Whiteson.",
      "orig_title": "Multi-objective deep reinforcement learning",
      "paper_id": "1610.02707v1"
    },
    {
      "index": 97,
      "title": "Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of Seventh International Conference on Learning\nRepresentations",
      "authors": "A. Nagabandi, I. Clavera, S. Liu, R. S. Fearing, P. Abbeel, S. Levine, and\nC. Finn.",
      "orig_title": "Learning to adapt in dynamic, real-world environments through meta-reinforcement learning",
      "paper_id": "1803.11347v6"
    },
    {
      "index": 98,
      "title": "Non-cooperative games",
      "abstract": "",
      "year": "1951",
      "venue": "Annals of Mathematics, 54(2):286–295",
      "authors": "J. Nash."
    },
    {
      "index": 99,
      "title": "Dynamic preferences in multi-criteria reinforcement learning",
      "abstract": "",
      "year": "2005",
      "venue": "Proceedings of the 22nd international conference on Machine\nlearning",
      "authors": "S. Natarajan and P. Tadepalli."
    },
    {
      "index": 100,
      "title": "A multi-objective deep reinforcement learning framework",
      "abstract": "",
      "year": "2020",
      "venue": "Engineering Applications of Artificial Intelligence,\n96:",
      "authors": "T. T. Nguyen, N. D. Nguyen, P. Vamplew, S. Nahavandi, R. Dazeley, and C. P.\nLim."
    },
    {
      "index": 101,
      "title": "A hybrid decision making model for evaluating land combat vehicle system",
      "abstract": "",
      "year": "2017",
      "venue": "22nd International Congress on Modelling and Simulation,\nMODSIM",
      "authors": "M. Nguyena and T. Caoa."
    },
    {
      "index": 102,
      "title": "DCRAC: Deep conditioned recurrent actor-critic for multi-objective partially observable environments",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the 19th International Conference on\nAutonomous Agents and MultiAgent Systems",
      "authors": "X. Nian, A. A. Irissappane, and D. Roijers."
    },
    {
      "index": 103,
      "title": "Interpretable Multi-Objective Reinforcement Learning through Policy Orchestration",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:",
      "authors": "R. Noothigattu, D. Bouneffouf, N. Mattei, R. Chandra, P. Madan, K. Varshney,\nM. Campbell, M. Singh, and F. Rossi.",
      "orig_title": "Interpretable multi-objective reinforcement learning through policy orchestration",
      "paper_id": "1809.08343v1"
    },
    {
      "index": 104,
      "title": "Modelling transport",
      "abstract": "",
      "year": "2011",
      "venue": "John Wiley & Sons, Chichester, UK, 4 edition",
      "authors": "J. d. D. Ortúzar and L. G. Willumsen."
    },
    {
      "index": 105,
      "title": "Additional planning with multiple objectives for reinforcement learning",
      "abstract": "",
      "year": "2020",
      "venue": "Knowledge-Based Systems, 193:",
      "authors": "A. Pan, W. Xu, L. Wang, and H. Ren."
    },
    {
      "index": 106,
      "title": "Policy gradient approaches for multi-objective sequential decision making",
      "abstract": "",
      "year": "2014",
      "venue": "IJCNN",
      "authors": "S. Parisi, M. Pirotta, N. Smacchia, L. Bascetta, and M. Restelli."
    },
    {
      "index": 107,
      "title": "Multi-objective reinforcement learning through continuous pareto manifold approximation",
      "abstract": "",
      "year": "2016",
      "venue": "J. Artif. Intell. Res., 57:187–227",
      "authors": "S. Parisi, M. Pirotta, and M. Restelli."
    },
    {
      "index": 108,
      "title": "Manifold-based multi-objective policy search with sample reuse",
      "abstract": "",
      "year": "2017",
      "venue": "Neurocomputing, 263:3–14",
      "authors": "S. Parisi, M. Pirotta, and J. Peters."
    },
    {
      "index": 109,
      "title": "Online and offline learning in multi-objective monte carlo tree search",
      "abstract": "",
      "year": "2013",
      "venue": "2013 IEEE Conference on Computational Inteligence in Games\n(CIG)",
      "authors": "D. Perez, S. Samothrakis, and S. Lucas."
    },
    {
      "index": 110,
      "title": "Responsive elastic computing",
      "abstract": "",
      "year": "2009",
      "venue": "Proceedings of the 6th international conference industry\nsession on Grids meets autonomic computing",
      "authors": "J. Perez, C. Germain-Renaud, B. Kégl, and C. Loomis."
    },
    {
      "index": 111,
      "title": "Multi-objective reinforcement learning for responsive grids",
      "abstract": "",
      "year": "2010",
      "venue": "Journal of Grid Computing, 8(3):473–492",
      "authors": "J. Perez, C. Germain-Renaud, B. Kégl, and C. Loomis."
    },
    {
      "index": 112,
      "title": "On finding compromise solutions in multiobjective markov decision processes",
      "abstract": "",
      "year": "2010",
      "venue": "ECAI, volume 215",
      "authors": "P. Perny and P. Weng."
    },
    {
      "index": 113,
      "title": "Approximation of lorenz-optimal solutions in multiobjective markov decision processes",
      "abstract": "",
      "year": "2013",
      "venue": "Proceedings of the 27th AAAI Conference on Artificial\nIntelligence",
      "authors": "P. Perny, P. Weng, J. Goldsmith, and J. Hanna."
    },
    {
      "index": 114,
      "title": "Tree-based fitted q-iteration for multi-objective markov decision processes in water resource management",
      "abstract": "",
      "year": "2013",
      "venue": "Journal of Hydroinformatics, 15(2):258–270",
      "authors": "F. Pianosi, A. Castelletti, and M. Restelli."
    },
    {
      "index": 115,
      "title": "Multi criteria operators for multi-attribute auctions",
      "abstract": "",
      "year": "2012",
      "venue": "International Conference on Modeling Decisions for\nArtificial Intelligence",
      "authors": "A. Pla, B. Lopez, and J. Murillo."
    },
    {
      "index": 116,
      "title": "An energy-aware scheduling algorithm for budget-constrained scientific workflows based on multi-objective reinforcement learning",
      "abstract": "",
      "year": "2020",
      "venue": "The Journal of Supercomputing, 76(1):455–480",
      "authors": "Y. Qin, H. Wang, S. Yi, X. Li, and L. Zhai."
    },
    {
      "index": 117,
      "title": "The robust weighted multi-objective game",
      "abstract": "",
      "year": "2015",
      "venue": "PloS one, 10(9):e",
      "authors": "S. Qu, Y. Ji, and M. Goh."
    },
    {
      "index": 118,
      "title": "A survey and performance evaluation of reinforcement learning based spectrum aware routing in cognitive radio ad hoc networks",
      "abstract": "",
      "year": "2020",
      "venue": "International Journal of Wireless Information Networks,\n27(1):144–163",
      "authors": "R. N. Raj, A. Nayak, and M. S. Kumar."
    },
    {
      "index": 119,
      "title": "Toll-based learning for minimising congestion under heterogeneous preferences",
      "abstract": "",
      "year": "2020",
      "venue": "B. An, N. Yorke-Smith, A. El Fallah Seghrouchni, and\nG. Sukthankar, editors, Proc. of the 19th International Conference on\nAutonomous Agents and Multiagent Systems (AAMAS 2020), pages 1098–1106,\nAuckland, New Zealand, May",
      "authors": "G. de. O. Ramos, R. Rădulescu, A. Nowé, and A. R. Tavares."
    },
    {
      "index": 120,
      "title": "Pedestrian simulation as multi-objective reinforcement learning",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the 18th International Conference on\nIntelligent Virtual Agents",
      "authors": "N. B. Ravichandran, F. Yang, C. Peters, A. Lansner, and P. Herman."
    },
    {
      "index": 121,
      "title": "Optimal reservoir operation using multi-objective evolutionary algorithm",
      "abstract": "",
      "year": "2006",
      "venue": "Water Resources Management, 20(6):861–878",
      "authors": "M. J. Reddy and D. N. Kumar."
    },
    {
      "index": 122,
      "title": "Pareto-dqn: Approximating the pareto front in complex multi-objective decision problems",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the adaptive and learning agents workshop\n(ALA-19) at AAMAS",
      "authors": "M. Reymond and A. Nowé."
    },
    {
      "index": 123,
      "title": "Interactive multi-objective reinforcement learning in multi-armed bandits for any utility function",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the adaptive and learning agents workshop\n(ALA-18) at AAMAS, 07",
      "authors": "D. Roijers, L. Zintgraf, P. Libin, and A. Nowe."
    },
    {
      "index": 124,
      "title": "Multi-Objective Decision-Theoretic Planning",
      "abstract": "",
      "year": "2016",
      "venue": "PhD thesis, University of Amsterdam",
      "authors": "D. M. Roijers."
    },
    {
      "index": 125,
      "title": "Multi-objective decision making",
      "abstract": "",
      "year": "2017",
      "venue": "Synthesis Lectures on Artificial Intelligence and Machine\nLearning, 11(1):1–129",
      "authors": "D. M. Roijers and S. Whiteson."
    },
    {
      "index": 126,
      "title": "A survey of multi-objective sequential decision-making",
      "abstract": "",
      "year": "2013",
      "venue": "Journal of Artificial Intelligence Research, 48:67–113",
      "authors": "D. M. Roijers, P. Vamplew, S. Whiteson, and R. Dazeley."
    },
    {
      "index": 127,
      "title": "Computing convex coverage sets for faster multi-objective coordination",
      "abstract": "",
      "year": "",
      "venue": "Journal of Artificial Intelligence Research, 52:399–443",
      "authors": "D. M. Roijers, S. Whiteson, and F. A. Oliehoek."
    },
    {
      "index": 128,
      "title": "Point-based planning for multi-objective pomdps",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the twenty-fourth international joint\nconference on artificial intelligence (IJCAI), pages 1666–1672",
      "authors": "D. M. Roijers, S. Whiteson, and F. A. Oliehoek."
    },
    {
      "index": 129,
      "title": "Interactive thompson sampling for multi-objective multi-armed bandits",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Algorithmic Decision Theory",
      "authors": "D. M. Roijers, L. M. Zintgraf, and A. Nowé."
    },
    {
      "index": 130,
      "title": "Multi-objective reinforcement learning for the expected utility of the return",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the Adaptive and Learning Agents workshop at\nFAIM, volume",
      "authors": "D. M. Roijers, D. Steckelmacher, and A. Nowé."
    },
    {
      "index": 131,
      "title": "Bootstrapping LPs in value iteration for multi-objective and partially observable MDPs",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the Twenty-Eighth International Conference on\nAutomated Planning and Scheduling (ICAPS), pages 218–226",
      "authors": "D. M. Roijers, E. Walraven, and M. T. J. Spaan."
    },
    {
      "index": 132,
      "title": "Interactive multi-objective reinforcement learning in multi-armed bandits with gaussian process utility models",
      "abstract": "",
      "year": "2020",
      "venue": "ECML-PKDD 2020: Proceedings of the 2020 European Conference\non Machine Learning and Principles and Practice of Knowledge Discovery in\nDatabases",
      "authors": "D. M. Roijers, L. M. Zintgraf, P. Libin, M. Reymond, E. Bargiacchi, and\nA. Nowé."
    },
    {
      "index": 133,
      "title": "Multi-Objective Optimization for Graphical Models",
      "abstract": "",
      "year": "2008",
      "venue": "PhD thesis, Universitat Politècnica de Catalunya, Barcelona",
      "authors": "E. Rollón."
    },
    {
      "index": 134,
      "title": "Bucket elimination for multiobjective optimization problems",
      "abstract": "",
      "year": "2006",
      "venue": "Journal of Heuristics, 12:307–328",
      "authors": "E. Rollón and J. Larrosa."
    },
    {
      "index": 135,
      "title": "Multi-objective russian doll search",
      "abstract": "",
      "year": "2007",
      "venue": "AAAI",
      "authors": "E. Rollon and J. Larrosa."
    },
    {
      "index": 136,
      "title": "Constraint optimization techniques for multiobjective branch and bound search",
      "abstract": "",
      "year": "2008",
      "venue": "International conference on logic programming, ICLP",
      "authors": "E. Rollon and J. Larrosa."
    },
    {
      "index": 137,
      "title": "Toward automated scenario generation with deep reinforcement learning in gift",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the Sixth Annual GIFT User Symposium",
      "authors": "J. Rowe, A. Smith, B. Pokorny, B. Mott, and J. Lester."
    },
    {
      "index": 138,
      "title": "Multi-Objective Multi-Agent Decision Making: A Utility-based Analysis and Survey",
      "abstract": "",
      "year": "",
      "venue": "Autonomous Agents and Multi-Agent Systems, 34(10)",
      "authors": "R. Rădulescu, P. Mannion, D. M. Roijers, and A. Nowé.",
      "orig_title": "Multi-objective multi-agent decision making: a utility-based analysis and survey",
      "paper_id": "1909.02964v1"
    },
    {
      "index": 139,
      "title": "A utility-based analysis of equilibria in multi-objective normal-form games",
      "abstract": "",
      "year": "",
      "venue": "The Knowledge Engineering Review, 35:e32",
      "authors": "R. Rădulescu, P. Mannion, Y. Zhang, D. M. Roijers, and A. Nowé."
    },
    {
      "index": 140,
      "title": "A temporal difference method for multi-objective reinforcement learning",
      "abstract": "",
      "year": "2017",
      "venue": "Neurocomputing, 263:15–25",
      "authors": "M. Ruiz-Montiel, L. Mandow, and J.-L. Pérez-de-la Cruz."
    },
    {
      "index": 141,
      "title": "A multi-objective approach to mitigate negative side effects",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the 29th International Joint Conference on\nArtificial Intelligence",
      "authors": "S. Saisubramanian, E. Kamar, and S. Zilberstein."
    },
    {
      "index": 142,
      "title": "Universal value function approximators",
      "abstract": "",
      "year": "2015",
      "venue": "International conference on machine learning",
      "authors": "T. Schaul, D. Horgan, K. Gregor, and D. Silver."
    },
    {
      "index": 143,
      "title": "Proximal policy optimization algorithms",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:",
      "authors": "J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov."
    },
    {
      "index": 144,
      "title": "Incorporating flood control rule curves of the Columbia River hydroelectric system in a multireservoir reinforcement learning optimization model",
      "abstract": "",
      "year": "2009",
      "venue": "PhD thesis, University of British Columbia",
      "authors": "N. Shabani."
    },
    {
      "index": 145,
      "title": "Learning fair policies in multiobjective (deep) reinforcement learning with average and discounted rewards",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "U. Siddique, P. Weng, and M. Zimmer."
    },
    {
      "index": 146,
      "title": "Evolving policies for multi-reward partially observable markov decision processes (MR-POMDPs)",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the 13th annual conference on Genetic and\nevolutionary computation",
      "authors": "H. Soh and Y. Demiris."
    },
    {
      "index": 147,
      "title": "Multi-reward policies for medical applications: Anthrax attacks and smart wheelchairs",
      "abstract": "",
      "year": "",
      "venue": "Proceedings of the 13th annual conference companion on\nGenetic and evolutionary computation",
      "authors": "H. Soh and Y. Demiris."
    },
    {
      "index": 148,
      "title": "Pareto optimal solutions for network defense strategy selection simulator in multi-objective reinforcement learning",
      "abstract": "",
      "year": "2018",
      "venue": "Applied Sciences, 8(1):136",
      "authors": "Y. Sun, Y. Li, W. Xiong, Z. Yao, K. Moniz, and A. Zahir."
    },
    {
      "index": 149,
      "title": "Reinforcement learning: An introduction",
      "abstract": "",
      "year": "2018",
      "venue": "MIT press",
      "authors": "R. S. Sutton and A. G. Barto."
    },
    {
      "index": 150,
      "title": "Modular Multi-Objective Deep Reinforcement Learning with Decision Values",
      "abstract": "",
      "year": "2018",
      "venue": "Federated conference on computer science and information\nsystems (FedCSIS)",
      "authors": "T. Tajmajer.",
      "orig_title": "Modular multi-objective deep reinforcement learning with decision values",
      "paper_id": "1704.06676v2"
    },
    {
      "index": 151,
      "title": "Accelerating learning in multi-objective systems through transfer learning",
      "abstract": "",
      "year": "2014",
      "venue": "Neural Networks (IJCNN), 2014 International Joint Conference\non",
      "authors": "A. Taylor, I. Dusparic, E. Galván-López, S. Clarke, and V. Cahill."
    },
    {
      "index": 152,
      "title": "Managing power consumption and performance of computing systems using reinforcement learning",
      "abstract": "",
      "year": "2008",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "G. Tesauro, R. Das, H. Chan, J. Kephart, D. Levine, F. Rawson, and C. Lefurgy."
    },
    {
      "index": 153,
      "title": "Constrained Markov decision processes as multi-objective problems",
      "abstract": "",
      "year": "1982",
      "venue": "University of Manchester. Department of Decision Theory",
      "authors": "L. Thomas."
    },
    {
      "index": 154,
      "title": "Many-objective stochastic path finding using reinforcement learning",
      "abstract": "",
      "year": "2017",
      "venue": "Expert Systems with Applications, 72:371–382",
      "authors": "B. Tozer, T. Mazzuchi, and S. Sarkani."
    },
    {
      "index": 155,
      "title": "A survey of multiobjective evolutionary algorithms based on decomposition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Transactions on Evolutionary Computation, 21(3):440–462",
      "authors": "A. Trivedi, D. Srinivasan, K. Sanyal, and A. Ghosh."
    },
    {
      "index": 156,
      "title": "Multi-objective contextual bandit problem with similarity information",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Artificial Intelligence and\nStatistics",
      "authors": "E. Turgay, D. Oner, and C. Tekin."
    },
    {
      "index": 157,
      "title": "On the limitations of scalarisation for multi-objective reinforcement learning of Pareto fronts",
      "abstract": "",
      "year": "2008",
      "venue": "Australasian Joint Conference on Artificial Intelligence",
      "authors": "P. Vamplew, J. Yearwood, R. Dazeley, and A. Berry."
    },
    {
      "index": 158,
      "title": "Constructing stochastic mixture policies for episodic multiobjective reinforcement learning tasks",
      "abstract": "",
      "year": "2009",
      "venue": "Australasian joint conference on artificial intelligence",
      "authors": "P. Vamplew, R. Dazeley, E. Barker, and A. Kelarev."
    },
    {
      "index": 159,
      "title": "Empirical evaluation methods for multiobjective reinforcement learning algorithms",
      "abstract": "",
      "year": "2011",
      "venue": "Machine learning, 84(1-2):51–80",
      "authors": "P. Vamplew, R. Dazeley, A. Berry, R. Issabekov, and E. Dekker."
    },
    {
      "index": 160,
      "title": "Reinforcement learning of Pareto-optimal multiobjective policies using steering",
      "abstract": "",
      "year": "2015",
      "venue": "Australasian Joint Conference on Artificial Intelligence",
      "authors": "P. Vamplew, R. Issabekov, R. Dazeley, and C. Foale."
    },
    {
      "index": 161,
      "title": "Softmax exploration strategies for multiobjective reinforcement learning",
      "abstract": "",
      "year": "",
      "venue": "Neurocomputing, 263:74–86",
      "authors": "P. Vamplew, R. Dazeley, and C. Foale."
    },
    {
      "index": 162,
      "title": "Steering approaches to Pareto-optimal multiobjective reinforcement learning",
      "abstract": "",
      "year": "",
      "venue": "Neurocomputing, 263:26–38",
      "authors": "P. Vamplew, R. Issabekov, R. Dazeley, C. Foale, A. Berry, T. Moore, and\nD. Creighton."
    },
    {
      "index": 163,
      "title": "Human-aligned artificial intelligence is a multiobjective problem",
      "abstract": "",
      "year": "2018",
      "venue": "Ethics and Information Technology, 20(1):27–40",
      "authors": "P. Vamplew, R. Dazeley, C. Foale, S. Firmin, and J. Mummery."
    },
    {
      "index": 164,
      "title": "The impact of environmental stochasticity on value-based multiobjective reinforcement learning",
      "abstract": "",
      "year": "",
      "venue": "Neural Computing and Applications",
      "authors": "P. Vamplew, C. Foale, and R. Dazeley."
    },
    {
      "index": 165,
      "title": "Potential-based multiobjective reinforcement learning approaches to low-impact agents for AI safety",
      "abstract": "",
      "year": "2021",
      "venue": "Engineering Applications of Artificial Intelligence, 100",
      "authors": "P. Vamplew, C. Foale, R. Dazeley, and A. Bignold."
    },
    {
      "index": 166,
      "title": "Yaw-misalignment and its impact on wind turbine loads and wind farm power output",
      "abstract": "",
      "year": "2016",
      "venue": "Journal of Physics: Conference Series, 753(6)",
      "authors": "M. T. van Dijk, J.-W. van Wingerden, T. Ashuri, Y. Li, and M. A. Rotea."
    },
    {
      "index": 167,
      "title": "Multi-objective reinforcement learning using sets of pareto dominating policies",
      "abstract": "",
      "year": "2014",
      "venue": "The Journal of Machine Learning Research, 15(1):",
      "authors": "K. Van Moffaert and A. Nowé."
    },
    {
      "index": 168,
      "title": "Hypervolume-based multi-objective reinforcement learning",
      "abstract": "",
      "year": "",
      "venue": "International Conference on Evolutionary Multi-Criterion\nOptimization",
      "authors": "K. Van Moffaert, M. M. Drugan, and A. Nowé."
    },
    {
      "index": 169,
      "title": "Scalarized multi-objective reinforcement learning: Novel design techniques",
      "abstract": "",
      "year": "2013",
      "venue": "2013 IEEE Symposium on Adaptive Dynamic Programming and\nReinforcement Learning (ADPRL)",
      "authors": "K. Van Moffaert, M. M. Drugan, and A. Nowé."
    },
    {
      "index": 170,
      "title": "A novel adaptive weight selection algorithm for multi-objective multi-agent reinforcement learning",
      "abstract": "",
      "year": "2014",
      "venue": "2014 International joint conference on neural networks\n(IJCNN)",
      "authors": "K. Van Moffaert, T. Brys, A. Chandra, L. Esterle, P. R. Lewis, and A. Nowé."
    },
    {
      "index": 171,
      "title": "Improving wet clutch engagement with reinforcement learning",
      "abstract": "",
      "year": "2012",
      "venue": "The 2012 International Joint Conference on Neural Networks\n(IJCNN)",
      "authors": "K. Van Vaerenbergh, A. Rodríguez, M. Gagliolo, P. Vrancx, A. Nowé,\nJ. Stoev, S. Goossens, G. Pinte, and W. Symens."
    },
    {
      "index": 172,
      "title": "Fleetwide data-enabled reliability improvement of wind turbines",
      "abstract": "",
      "year": "2019",
      "venue": "Renewable and Sustainable Energy Reviews, 109:428–437",
      "authors": "T. Verstraeten, A. Nowé, J. Keller, Y. Guo, S. Sheng, and J. Helsen."
    },
    {
      "index": 173,
      "title": "Multi-Agent Thompson Sampling for Bandit Applications with Sparse Neighbourhood Structures",
      "abstract": "",
      "year": "2020",
      "venue": "Scientific Reports, 10",
      "authors": "T. Verstraeten, E. Bargiacchi, P. J. K. Libin, J. Helsen, D. M. Roijers, and\nA. Nowé.",
      "orig_title": "Multi-agent thompson sampling for bandit applications with sparse neighbourhood structures",
      "paper_id": "1911.10120v2"
    },
    {
      "index": 174,
      "title": "A survey on multi-objective evolutionary algorithms for many-objective problems",
      "abstract": "",
      "year": "2014",
      "venue": "Computational optimization and applications, 58(3):707–756",
      "authors": "C. Von Lücken, B. Barán, and C. Brizuela."
    },
    {
      "index": 175,
      "title": "Moral machines: Teaching robots right from wrong",
      "abstract": "",
      "year": "2008",
      "venue": "Oxford University Press",
      "authors": "W. Wallach and C. Allen."
    },
    {
      "index": 176,
      "title": "Multiobjective reinforcement learning-based intelligent approach for optimization of activation rules in automatic generation control",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Access, 7:",
      "authors": "H. Wang, Z. Lei, X. Zhang, J. Peng, and H. Jiang."
    },
    {
      "index": 177,
      "title": "Multi-objective Monte-Carlo tree search",
      "abstract": "",
      "year": "2012",
      "venue": "volume 25 of Proceedings of Machine Learning Research",
      "authors": "W. Wang and M. Sebag."
    },
    {
      "index": 178,
      "title": "Hypervolume indicator and dominance reward based multi-objective monte-carlo tree search",
      "abstract": "",
      "year": "2013",
      "venue": "Machine learning, 92(2-3):403–429",
      "authors": "W. Wang and M. Sebag."
    },
    {
      "index": 179,
      "title": "Learning multi-objective rewards and user utility function in contextual bandits for personalized ranking",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the 28th International Joint Conference on\nArtificial Intelligence",
      "authors": "N. Wanigasekara, Y. Liang, S. T. Goh, Y. Liu, J. J. Williams, and D. S.\nRosenblum."
    },
    {
      "index": 180,
      "title": "Pareto-optimal transit route planning with multi-objective monte-carlo tree search",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "D. Weng, R. Chen, J. Zhang, J. Bao, Y. Zheng, and Y. Wu."
    },
    {
      "index": 181,
      "title": "Solution procedures for vector criterion Markov decision processes",
      "abstract": "",
      "year": "1980",
      "venue": "Large Scale Systems, 1:129–140",
      "authors": "C. C. White and K. W. Kim."
    },
    {
      "index": 182,
      "title": "Multi-objective infinite-horizon discounted markov decision processes",
      "abstract": "",
      "year": "1982",
      "venue": "Journal of mathematical analysis and applications, 89(2):639–647",
      "authors": "D. White."
    },
    {
      "index": 183,
      "title": "Computing optimal stationary policies for multi-objective markov decision processes",
      "abstract": "",
      "year": "2007",
      "venue": "2007 IEEE International Symposium on Approximate Dynamic\nProgramming and Reinforcement Learning",
      "authors": "M. A. Wiering and E. D. De Jong."
    },
    {
      "index": 184,
      "title": "Model-based multi-objective reinforcement learning",
      "abstract": "",
      "year": "2014",
      "venue": "2014 IEEE Symposium on Adaptive Dynamic Programming and\nReinforcement Learning (ADPRL)",
      "authors": "M. A. Wiering, M. Withagen, and M. M. Drugan."
    },
    {
      "index": 185,
      "title": "Multi-objective pomdps with lexicographic reward preferences",
      "abstract": "",
      "year": "2015",
      "venue": "Twenty-Fourth International Joint Conference on Artificial\nIntelligence",
      "authors": "K. H. Wray and S. Zilberstein."
    },
    {
      "index": 186,
      "title": "Multi-objective mdps with conditional lexicographic reward preferences",
      "abstract": "",
      "year": "2015",
      "venue": "Twenty-ninth AAAI conference on artificial intelligence",
      "authors": "K. H. Wray, S. Zilberstein, and A.-I. Mouaddib."
    },
    {
      "index": 187,
      "title": "Prediction-guided multi-objective reinforcement learning for continuous robot control",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the 37th International Conference on Machine\nLearning",
      "authors": "J. Xu, Y. Tian, P. Ma, D. Rus, S. Sueda, and W. Matusik."
    },
    {
      "index": 188,
      "title": "Knowledge gradient for multi-objective multi-armed bandit algorithms",
      "abstract": "",
      "year": "2014",
      "venue": "ICAART (1)",
      "authors": "S. Q. Yahyaa, M. M. Drugan, and B. Manderick."
    },
    {
      "index": 189,
      "title": "Model-based multi-objective reinforcement learning with unknown weights",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Human-Computer Interaction",
      "authors": "T. Yamaguchi, S. Nagahama, Y. Ichikawa, and K. Takadama."
    },
    {
      "index": 190,
      "title": "MoTiAC: Multi-objective actor-critics for real-time bidding",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:",
      "authors": "C. Yang, J. Lu, X. Gao, H. Liu, Q. Chen, G. Liu, and G. Chen."
    },
    {
      "index": 191,
      "title": "A generalized algorithm for multi-objective reinforcement learning and policy adaptation",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "R. Yang, X. Sun, and K. Narasimhan."
    },
    {
      "index": 192,
      "title": "Multi-objective multiagent credit assignment in reinforcement learning and nsga-ii",
      "abstract": "",
      "year": "2016",
      "venue": "Soft Computing, 20(10):",
      "authors": "L. Yliniemi and K. Tumer."
    },
    {
      "index": 193,
      "title": "Robust multiple objective game theory",
      "abstract": "",
      "year": "2013",
      "venue": "Journal of Optimization Theory and Applications, 159(1):272–280",
      "authors": "H. Yu and H. Liu."
    },
    {
      "index": 194,
      "title": "Relationship Explainable Multi-objective Reinforcement Learning with Semantic Explainability Generation *",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:",
      "authors": "H. Zhan and Y. Cao.",
      "orig_title": "Relationship explainable multi-objective reinforcement learning with semantic explainability generation",
      "paper_id": "1909.12268v1"
    },
    {
      "index": 195,
      "title": "Opponent modelling for reinforcement learning in multi-objective normal form games",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the 19th International Conference on\nAutonomous Agents and MultiAgent Systems",
      "authors": "Y. Zhang, R. Rădulescu, P. Mannion, D. M. Roijers, and A. Nowé."
    },
    {
      "index": 196,
      "title": "Whole building energy model for hvac optimal control: A practical framework based on deep reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "Energy and Buildings, 199:472–490",
      "authors": "Z. Zhang, A. Chong, Y. Pan, C. Zhang, and K. P. Lam."
    },
    {
      "index": 197,
      "title": "Optimization of Molecules via Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "Scientific reports, 9(1):1–10",
      "authors": "Z. Zhou, S. Kearnes, L. Li, R. N. Zare, and P. Riley.",
      "orig_title": "Optimization of molecules via deep reinforcement learning",
      "paper_id": "1810.08678v3"
    },
    {
      "index": 198,
      "title": "Quality assessment of MORL algorithms: A utility-based approach",
      "abstract": "",
      "year": "2015",
      "venue": "Benelearn 2015: Proceedings of the 24th Annual Machine\nLearning Conference of Belgium and the Netherlands",
      "authors": "L. M. Zintgraf, T. V. Kanters, D. M. Roijers, F. Oliehoek, and P. Beau."
    },
    {
      "index": 199,
      "title": "Ordered Preference Elicitation Strategies for Supporting Multi-Objective Decision Making",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the 17th International Conference on\nAutonomous Agents and MultiAgent Systems, pages 1477–1485. International\nFoundation for Autonomous Agents and Multiagent Systems",
      "authors": "L. M. Zintgraf, D. M. Roijers, S. Linders, C. M. Jonker, and A. Nowé.",
      "orig_title": "Ordered preference elicitation strategies for supporting multi-objective decision making",
      "paper_id": "1802.07606v1"
    },
    {
      "index": 200,
      "title": "Quality assessment of pareto set approximations",
      "abstract": "",
      "year": "2008",
      "venue": "Multiobjective Optimization, pages 373–404. Springer",
      "authors": "E. Zitzler, J. Knowles, and L. Thiele."
    }
  ]
}