{
  "paper_id": "2106.06147v3",
  "title": "NAAQA: A Neural Architecture for Acoustic Question Answering",
  "abstract": "Abstract\nThe goal of the Acoustic Question Answering (AQA) task is to answer a free-form text question about the content of an acoustic scene. It was inspired by the Visual Question Answering (VQA) task.\nIn this paper, based on the previously introduced CLEAR dataset, we propose a new benchmark for AQA, namely CLEAR2, that emphasizes the specific challenges of acoustic inputs.\nThese include handling of variable duration scenes, and scenes built with elementary sounds that differ between training and test set.\nWe also introduce NAAQA, a neural architecture that leverages specific properties of acoustic inputs.\nThe use of 1D convolutions in time and frequency to process 2D spectro-temporal representations of acoustic content shows promising results and enables reductions in model complexity.\nWe show that time coordinate maps augment temporal localization capabilities which enhance performance of the network by ∼similar-to\\sim17 percentage points. On the other hand, frequency coordinate maps have little influence on this task.\nNAAQA achieves 79.5% of accuracy on the AQA task with ∼similar-to\\sim4 times fewer parameters than the previously explored VQA model.\nWe evaluate the performance of NAAQA on an independent data set reconstructed from DAQA.\nWe also test the addition of a MALiMo module in our model on both CLEAR2 and DAQA.\nWe provide a detailed analysis of the results for the different question types.\nWe release the code to produce CLEAR2 as well as NAAQA to foster research in this newly emerging machine learning task.",
  "reference_labels": [
    {
      "index": 0,
      "title": "The TREC-8 Question Answering Track Report.",
      "abstract": "",
      "year": "1999",
      "venue": "TREC",
      "authors": "Ellen M Voorhees"
    },
    {
      "index": 1,
      "title": "Building a question answering test collection",
      "abstract": "",
      "year": "2000",
      "venue": "SIGIR",
      "authors": "Ellen M Voorhees and Dawn M Tice"
    },
    {
      "index": 2,
      "title": "Patterns of Potential Answer Expressions as Clues to the Right Answers.",
      "abstract": "",
      "year": "2001",
      "venue": "TREC 500-250",
      "authors": "Martin M Soubbotin and Sergei M Soubbotin"
    },
    {
      "index": 3,
      "title": "Question Answering in Webclopedia.",
      "abstract": "",
      "year": "2000",
      "venue": "TREC",
      "authors": "Eduard H Hovy et al."
    },
    {
      "index": 4,
      "title": "A neural network for factoid question answering over paragraphs",
      "abstract": "",
      "year": "2014",
      "venue": "EMNLP",
      "authors": "Mohit Iyyer et al."
    },
    {
      "index": 5,
      "title": "Learning surface text patterns for a question answering system",
      "abstract": "",
      "year": "2002",
      "venue": "ACL",
      "authors": "Deepak Ravichandran and Eduard Hovy"
    },
    {
      "index": 6,
      "title": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Justin Johnson et al.",
      "orig_title": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning",
      "paper_id": "1612.06890v1"
    },
    {
      "index": 7,
      "title": "VQA: Visual Question Answering",
      "abstract": "",
      "year": "2015",
      "venue": "ICCV",
      "authors": "Stanislaw Antol et al."
    },
    {
      "index": 8,
      "title": "Visual7W: Grounded Question Answering in Images",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Yuke Zhu et al."
    },
    {
      "index": 9,
      "title": "Are you talking to a machine? dataset and methods for multilingual image question",
      "abstract": "",
      "year": "2015",
      "venue": "NeurIPS",
      "authors": "Haoyuan Gao et al."
    },
    {
      "index": 10,
      "title": "Analyzing the Behavior of Visual Question Answering Models",
      "abstract": "",
      "year": "2016",
      "venue": "EMNLP",
      "authors": "Aishwarya Agrawal et al."
    },
    {
      "index": 11,
      "title": "Yin and Yang: Balancing and Answering Binary Visual Questions",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Peng Zhang et al.",
      "orig_title": "Yin and yang: Balancing and answering binary visual questions",
      "paper_id": "1511.05099v5"
    },
    {
      "index": 12,
      "title": "Visual turing test for computer vision systems",
      "abstract": "",
      "year": "2015",
      "venue": "PNAS",
      "authors": "Donald Geman et al."
    },
    {
      "index": 13,
      "title": "Automated question answering from lecture videos: NLP vs. pattern matching",
      "abstract": "",
      "year": "2005",
      "venue": "HICSS",
      "authors": "Jinwei Cao et al."
    },
    {
      "index": 14,
      "title": "Question answering on large news video archive",
      "abstract": "",
      "year": "2003",
      "venue": "ISPA",
      "authors": "Tat-Seng Chua"
    },
    {
      "index": 15,
      "title": "VideoQA: Question Answering on news video",
      "abstract": "",
      "year": "2003",
      "venue": "MM",
      "authors": "Hui Yang et al."
    },
    {
      "index": 16,
      "title": "DeepStory: Video story QA by deep embedded memory networks",
      "abstract": "",
      "year": "2017",
      "venue": "IJCAI",
      "authors": "Kyung-Min Kim et al."
    },
    {
      "index": 17,
      "title": "Movieqa: Understanding stories in movies through question-answering",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Makarand Tapaswi et al."
    },
    {
      "index": 18,
      "title": "A robust passage retrieval algorithm for video question answering",
      "abstract": "",
      "year": "2008",
      "venue": "IEEE T CIRC SYST VID",
      "authors": "Yu-Chieh Wu and Jie-Chi Yang"
    },
    {
      "index": 19,
      "title": "Speech-Based Visual Question Answering",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv abs/1705.00464",
      "authors": "Ted Zhang et al.",
      "orig_title": "Speech-Based Visual Question Answering",
      "paper_id": "1705.00464v2"
    },
    {
      "index": 20,
      "title": "Symbolic Projection for Image Information Retrieval and Spatial Reasoning",
      "abstract": "",
      "year": "1996",
      "venue": "Signal processing and its applications",
      "authors": "Shi-Kuo Chang and Erland Jungert"
    },
    {
      "index": 21,
      "title": "Visual Reasoning with Diagrams",
      "abstract": "",
      "year": "2013",
      "venue": "Studies in Universal Logic",
      "authors": "Amirouche Moktefi and Sun-Joo Shin"
    },
    {
      "index": 22,
      "title": "Sound reasoning (literally): Prospects and Challenges of current acoustic logics",
      "abstract": "",
      "year": "2015",
      "venue": "Logica Universalis",
      "authors": "Marc Champagne"
    },
    {
      "index": 23,
      "title": "Audio Retrieval with Natural Language Queries: A Benchmark Study",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE Transactions on Multimedia",
      "authors": "A. Koepke et al.",
      "orig_title": "Audio Retrieval with Natural Language Queries: A Benchmark Study",
      "paper_id": "2112.09418v2"
    },
    {
      "index": 24,
      "title": "Teaching Argument Diagrams to a Student Who Is Blind",
      "abstract": "",
      "year": "2018",
      "venue": "Diagrams",
      "authors": "Marc Champagne"
    },
    {
      "index": 25,
      "title": "Audio-Visual Classification and Detection of Human Manipulation Actions",
      "abstract": "",
      "year": "2014",
      "venue": "IROS",
      "authors": "Alessandro Pieropan et al."
    },
    {
      "index": 26,
      "title": "CLEAR: A Dataset for Compositional Language and Elementary Acoustic Reasoning",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS Vigil Workshop",
      "authors": "Jérôme Abdelnour et al.",
      "orig_title": "CLEAR: A Dataset for Compositional Language and Elementary Acoustic Reasoning",
      "paper_id": "1811.10561v1"
    },
    {
      "index": 27,
      "title": "FiLM: Visual Reasoning with a General Conditioning Layer",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI",
      "authors": "Ethan Perez et al.",
      "orig_title": "FiLM: Visual Reasoning with a General Conditioning Layer",
      "paper_id": "1709.07871v2"
    },
    {
      "index": 28,
      "title": "Temporal Reasoning via Audio Question Answering",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE-ACM T AUDIO SPE",
      "authors": "Haytham M. Fayek and Justin Johnson",
      "orig_title": "Temporal Reasoning via Audio Question Answering",
      "paper_id": "1911.09655v1"
    },
    {
      "index": 29,
      "title": "Active Mini-Batch Sampling using Repulsive Point Processes",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI",
      "authors": "Cheng Zhang et al."
    },
    {
      "index": 30,
      "title": "Visualizing Data using GTSNE",
      "abstract": "",
      "year": "2008",
      "venue": "JMLR",
      "authors": "Laurens Van Der Maaten and Geoffrey Hinton",
      "orig_title": "Visualizing Data using t-SNE",
      "paper_id": "2108.01301v1"
    },
    {
      "index": 31,
      "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Drew A. Hudson and Christopher D. Manning"
    },
    {
      "index": 32,
      "title": "FVQA: Fact-based Visual Question Answering",
      "abstract": "",
      "year": "2018",
      "venue": "TPAMI",
      "authors": "Peng Wang et al.",
      "orig_title": "FVQA: Fact-Based Visual Question Answering",
      "paper_id": "1606.05433v4"
    },
    {
      "index": 33,
      "title": "OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Kenneth Marino et al.",
      "orig_title": "OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge",
      "paper_id": "1906.00067v2"
    },
    {
      "index": 34,
      "title": "From Recognition to Cognition: Visual Commonsense Reasoning",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Rowan Zellers et al.",
      "orig_title": "From Recognition to Cognition: Visual Commonsense Reasoning",
      "paper_id": "1811.10830v2"
    },
    {
      "index": 35,
      "title": "IQA: Visual Question Answering in Interactive Environments",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Daniel Gordon et al."
    },
    {
      "index": 36,
      "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Yash Goyal et al.",
      "orig_title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
      "paper_id": "1612.00837v3"
    },
    {
      "index": 37,
      "title": "Explicit Bias Discovery in Visual Question Answering Models",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Varun Manjunatha et al."
    },
    {
      "index": 38,
      "title": "Dataset bias: A case study for visual question answering",
      "abstract": "",
      "year": "2019",
      "venue": "ASIS&T",
      "authors": "Anubrata Das et al."
    },
    {
      "index": 39,
      "title": "Don’t Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Aishwarya Agrawal et al.",
      "orig_title": "Don’t Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering",
      "paper_id": "1712.00377v2"
    },
    {
      "index": 40,
      "title": "Compositional Attention Networks for Machine Reasoning",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "Drew Arad Hudson and Christopher D. Manning",
      "orig_title": "Compositional Attention Networks for Machine Reasoning",
      "paper_id": "1803.03067v2"
    },
    {
      "index": 41,
      "title": "Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Ramakrishna Vedantam et al.",
      "orig_title": "Probabilistic Neural Symbolic Models for Interpretable Visual Question Answering",
      "paper_id": "1902.07864v2"
    },
    {
      "index": 42,
      "title": "Language-Conditioned Graph Networks for Relational Reasoning",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Ronghang Hu et al.",
      "orig_title": "Language-Conditioned Graph Networks for Relational Reasoning",
      "paper_id": "1905.04405v2"
    },
    {
      "index": 43,
      "title": "Explainable Neural Computation via Stack Neural Module Networks",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Ronghang Hu et al.",
      "orig_title": "Explainable Neural Computation via Stack Neural Module Networks",
      "paper_id": "1807.08556v3"
    },
    {
      "index": 44,
      "title": "Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Kexin Yi et al.",
      "orig_title": "Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding",
      "paper_id": "1810.02338v2"
    },
    {
      "index": 45,
      "title": "End-to-End Environmental Sound Classification using a 1D Convolutional Neural Network",
      "abstract": "",
      "year": "2019",
      "venue": "Expert Systems with Applications",
      "authors": "Sajjad Abdoli et al.",
      "orig_title": "End-to-end environmental sound classification using a 1D convolutional neural network",
      "paper_id": "1904.08990v1"
    },
    {
      "index": 46,
      "title": "Classifying environmental sounds using image recognition networks",
      "abstract": "",
      "year": "2017",
      "venue": "Procedia Computer Science",
      "authors": "Venkatesh Boddapati et al."
    },
    {
      "index": 47,
      "title": "Raw Waveform-based Audio Classification Using Sample-level CNN Architectures",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv abs/1712.00866",
      "authors": "Jongpil Lee et al.",
      "orig_title": "Raw Waveform-based Audio Classification Using Sample-level CNN Architectures",
      "paper_id": "1712.00866v1"
    },
    {
      "index": 48,
      "title": "Acoustic scene classification using convolutional neural network and multiple-width frequency-delta data augmentation",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv abs/1607.02383",
      "authors": "Yoonchang Han and Kyogu Lee",
      "orig_title": "Acoustic scene classification using convolutional neural network and multiple-width frequency-delta data augmentation",
      "paper_id": "1607.02383v1"
    },
    {
      "index": 49,
      "title": "Deep Learning for Audio-Based Music Classification and Tagging: Teaching Computers to Distinguish Rock from Bach",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Signal Processing Magazine",
      "authors": "Juhan Nam et al."
    },
    {
      "index": 50,
      "title": "CNNs-based Acoustic Scene Classification using Multi-Spectrogram Fusion and Label Expansions",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv abs/1809.01543",
      "authors": "Weiping Zheng et al.",
      "orig_title": "CNNs-based Acoustic Scene Classification using Multi-Spectrogram Fusion and Label Expansions",
      "paper_id": "1809.01543v1"
    },
    {
      "index": 51,
      "title": "Timbre Analysis of Music Audio Signals with Convolutional Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "EUSIPCO",
      "authors": "Jordi Pons et al.",
      "orig_title": "Timbre Analysis of Music Audio Signals with Convolutional Neural Networks",
      "paper_id": "1703.06697v2"
    },
    {
      "index": 52,
      "title": "SECL-UMons Database for Sound Event Classification and Localization",
      "abstract": "",
      "year": "2020",
      "venue": "ICASSP",
      "authors": "Mathilde Brousmiche et al."
    },
    {
      "index": 53,
      "title": "Short-Time Fourier Transform",
      "abstract": "",
      "year": "1987",
      "venue": "Advanced Topics in Signal Processing",
      "authors": "S. Nawab and Thomas F. Quatieri"
    },
    {
      "index": 54,
      "title": "Mel Frequency Cepstral Coefficients for Music Modeling",
      "abstract": "",
      "year": "2000",
      "venue": "ISMIR",
      "authors": "Beth Logan"
    },
    {
      "index": 55,
      "title": "An efficient algorithm for the calculation of a constant Q transform",
      "abstract": "",
      "year": "1992",
      "venue": "JASA",
      "authors": "Judith Brown and Miller Puckette"
    },
    {
      "index": 56,
      "title": "ImageNet classification with deep convolutional neural networks",
      "abstract": "",
      "year": "2012",
      "venue": "NeurIPS",
      "authors": "Alex Krizhevsky et al."
    },
    {
      "index": 57,
      "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
      "abstract": "",
      "year": "2015",
      "venue": "ICLR",
      "authors": "Karen Simonyan and Andrew Zisserman",
      "orig_title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
      "paper_id": "1409.1556v6"
    },
    {
      "index": 58,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Kaiming He et al.",
      "orig_title": "Deep Residual Learning for Image Recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 59,
      "title": "Going deeper with convolutions",
      "abstract": "",
      "year": "2015",
      "venue": "CVPR",
      "authors": "Christian Szegedy et al.",
      "orig_title": "Going Deeper with Convolutions",
      "paper_id": "1409.4842v1"
    },
    {
      "index": 60,
      "title": "CNN architectures for large-scale audio classification",
      "abstract": "",
      "year": "2017",
      "venue": "ICASSP",
      "authors": "Shawn Hershey et al."
    },
    {
      "index": 61,
      "title": "Deep CNN Framework for Audio Event Recognition using Weakly Labeled Web Data",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv abs/1707.02530",
      "authors": "Anurag Kumar and Bhiksha Raj",
      "orig_title": "Deep CNN Framework for Audio Event Recognition using Weakly Labeled Web Data",
      "paper_id": "1707.02530v3"
    },
    {
      "index": 62,
      "title": "Experimenting with musically motivated convolutional neural networks",
      "abstract": "",
      "year": "2016",
      "venue": "CBMI",
      "authors": "Jordi Pons et al."
    },
    {
      "index": 63,
      "title": "An intriguing failing of convolutional neural networks and the CoordConv solution",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Rosanne Liu et al.",
      "orig_title": "An intriguing failing of convolutional neural networks and the coordconv solution",
      "paper_id": "1807.03247v2"
    },
    {
      "index": 64,
      "title": "Receptive-Field-Regularized CNN Variants for Acoustic Scene Classification",
      "abstract": "",
      "year": "2019",
      "venue": "DCASE",
      "authors": "Khaled Koutini et al.",
      "orig_title": "Receptive-Field-Regularized CNN Variants for Acoustic Scene Classification",
      "paper_id": "1909.02859v1"
    },
    {
      "index": 65,
      "title": "A real-time system for measuring sound goodness in instrumental sounds",
      "abstract": "",
      "year": "2015",
      "venue": "AES Convention",
      "authors": "Oriol Romani Picas et al."
    },
    {
      "index": 66,
      "title": "Timbral Models, AudioCommons project, Deliverable D5.7",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Andy Pearce et al."
    },
    {
      "index": 67,
      "title": "Algorithms to measure audio programme loudness and true-peak audio level (ITU-R BS.1770-4)",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "International Telecommunication Union"
    },
    {
      "index": 68,
      "title": "Audio Set: An ontology and human-labeled dataset for audio events",
      "abstract": "",
      "year": "2017",
      "venue": "ICASSP",
      "authors": "Jort F. Gemmeke et al."
    },
    {
      "index": 69,
      "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
      "abstract": "",
      "year": "2015",
      "venue": "ICML",
      "authors": "Sergey Ioffe and Christian Szegedy"
    },
    {
      "index": 70,
      "title": "ImageNet Large Scale Visual Recognition Challenge",
      "abstract": "",
      "year": "2015",
      "venue": "IJCV",
      "authors": "Olga Russakovsky et al.",
      "orig_title": "ImageNet large scale visual recognition challenge",
      "paper_id": "1409.0575v3"
    },
    {
      "index": 71,
      "title": "What is the best multi-stage architecture for object recognition?",
      "abstract": "",
      "year": "2009",
      "venue": "ICCV",
      "authors": "Kevin Jarrett et al."
    },
    {
      "index": 72,
      "title": "Network In Networks",
      "abstract": "",
      "year": "2014",
      "venue": "ICLR",
      "authors": "Min Lin et al."
    },
    {
      "index": 73,
      "title": "A scale for the measurement of the psychological magnitude pitch",
      "abstract": "",
      "year": "1937",
      "venue": "JASA",
      "authors": "Stanley Smith Stevens et al."
    },
    {
      "index": 74,
      "title": "Efficient backprop",
      "abstract": "",
      "year": "2012",
      "venue": "Neural networks: Tricks of the trade",
      "authors": "Yann A LeCun et al."
    }
  ]
}