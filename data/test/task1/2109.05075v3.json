{
  "paper_id": "2109.05075v3",
  "title": "On the Compression of Neural Networks Using ‚Ñì‚ÇÄ-Norm Regularization and Weight Pruning",
  "abstract": "Abstract\nDespite the growing availability of high-capacity computational platforms, implementation complexity still has been a great concern for the real-world deployment of neural networks. This concern is not exclusively due to the huge costs of state-of-the-art network architectures, but also due to the recent push towards edge intelligence and the use of neural networks in embedded applications. In this context, network compression techniques have been gaining interest due to their ability for reducing deployment costs while keeping inference accuracy at satisfactory levels. The present paper is dedicated to the development of a novel compression scheme for neural networks. To this end, a new form of ‚Ñì0subscript‚Ñì0\\ell_{0}-norm-based regularization is firstly developed, which is capable of inducing strong sparseness in the network during training. Then, targeting the smaller weights of the trained network with pruning techniques, smaller yet highly effective networks can be obtained. The proposed compression scheme also involves the use of ‚Ñì2subscript‚Ñì2\\ell_{2}-norm regularization to avoid overfitting as well as fine tuning to improve the performance of the pruned network. Experimental results are presented aiming to show the effectiveness of the proposed scheme as well as to make comparisons with competing approaches.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Deep Learning",
      "abstract": "",
      "year": "2016",
      "venue": "MIT Press",
      "authors": "I. Goodfellow, Y. Bengio, A. Courville",
      "orig_title": "Deep Learning",
      "paper_id": "1807.07987v2"
    },
    {
      "index": 1,
      "title": "Pattern Recognition and Machine Learning",
      "abstract": "",
      "year": "2006",
      "venue": "Springer",
      "authors": "C. M. Bishop"
    },
    {
      "index": 2,
      "title": "Machine Learning: A Probabilistic Perspective",
      "abstract": "",
      "year": "2012",
      "venue": "MIT Press",
      "authors": "K. P. Murphy"
    },
    {
      "index": 3,
      "title": "Deep learning for stock prediction using numerical and textual information",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE/ACIS Int. Conf. Comput. Inf. Sci.",
      "authors": "R. Akita, A. Yoshihara, T. Matsubara, K. Uehara"
    },
    {
      "index": 4,
      "title": "Deep learning for stock market prediction from financial news articles",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Int. Conf. Comput. Intell. and Virtual Env. for Meas. Syst. and Appl.",
      "authors": "M. R. Vargas, B. S. L. P. de Lima, A. G. Evsukoff"
    },
    {
      "index": 5,
      "title": "Forecasting stock prices from the limit order book using convolutional neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Conf. Business Inf.",
      "authors": "A. Tsantekidis, N. Passalis, A. Tefas, J. Kanniainen, M. Gabbouj, A. Iosifidis"
    },
    {
      "index": 6,
      "title": "Deep convolution neural networks for twitter sentiment analysis",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Access",
      "authors": "Z. Jianqiang, G. Xiaolin, Z. Xuejun"
    },
    {
      "index": 7,
      "title": "Deep learning approach for sentiment analysis of short texts",
      "abstract": "",
      "year": "2017",
      "venue": "Int. Conf. Control Automat. Robot. (ICCAR)",
      "authors": "A. Hassan, A. Mahmood"
    },
    {
      "index": 8,
      "title": "Recent Trends in Deep Learning Based Natural Language Processing",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Comput. Intell. Mag.",
      "authors": "T. Young, D. Hazarika, S. Poria, E. Cambria",
      "orig_title": "Recent trends in deep learning based natural language processing",
      "paper_id": "1708.02709v8"
    },
    {
      "index": 9,
      "title": "Deep learning for natural language processing and language modelling",
      "abstract": "",
      "year": "2018",
      "venue": "Signal Process. Algorithms Arch. Arrangements Appl.",
      "authors": "P. K≈Çosowski"
    },
    {
      "index": 10,
      "title": "Speech recognition using deep neural networks: A systematic review",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Access",
      "authors": "A. B. Nassif, I. Shahin, I. Attili, M. Azzeh, K. Shaalan"
    },
    {
      "index": 11,
      "title": "Towards Structured Deep Neural Network for Automatic Speech Recognition",
      "abstract": "",
      "year": "2015",
      "venue": "Workshop on Autom. Speech Recognit. Understanding",
      "authors": "Y.-H. Liao, H.-Y. Lee, L.-S. Lee",
      "orig_title": "Towards structured deep neural network for automatic speech recognition",
      "paper_id": "1511.02506v1"
    },
    {
      "index": 12,
      "title": "Deep neural network-based speech recognition with combination of speaker-class models",
      "abstract": "",
      "year": "2015",
      "venue": "Asia-Pacific Signal Inf. Process. Association Annu. Summit Conf.",
      "authors": "T. Kosaka, K. Konno, M. Kato"
    },
    {
      "index": 13,
      "title": "Gradient-based learning applied to document recognition",
      "abstract": "",
      "year": "1998",
      "venue": "Proc. IEEE",
      "authors": "Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, et al."
    },
    {
      "index": 14,
      "title": "Classifying multi-category images using deep learning: A convolutional neural network model",
      "abstract": "",
      "year": "2017",
      "venue": "Int. Conf. Recent Trends Electron. Inf. Commun. Technol.",
      "authors": "A. Bandhu, S. S. Roy"
    },
    {
      "index": 15,
      "title": "Imagenet classification with deep convolutional neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "Comm. of the ACM",
      "authors": "A. Krizhevsky, I. Sutskever, G. E. Hinton"
    },
    {
      "index": 16,
      "title": "Predicting parameters in deep learning",
      "abstract": "",
      "year": "2013",
      "venue": "Int. Conf. Neural Inf. Proc. Syst.",
      "authors": "M. Denil, B. Shakibi, L. Dinh, M. A. Ranzato, N. de Freitas"
    },
    {
      "index": 17,
      "title": "Low-rank matrix factorization for deep neural network training with high-dimensional output targets",
      "abstract": "",
      "year": "2013",
      "venue": "IEEE Int. Conf. Acoust., Speech, Signal Process.",
      "authors": "T. N. Sainath, B. Kingsbury, V. Sindhwani, E. Arisoy, B. Ramabhadran"
    },
    {
      "index": 18,
      "title": "Efficient and Accurate Approximations of Nonlinear Convolutional Networks",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE Conf. Comput. Vis. Pattern Recog.",
      "authors": "X. Zhang, J. Zou, X. Ming, K. He, J. Sun",
      "orig_title": "Efficient and accurate approximations of nonlinear convolutional networks",
      "paper_id": "1411.4229v1"
    },
    {
      "index": 19,
      "title": "Retrain-free fully connected layer optimization using matrix factorization",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Int. Conf. Image Process.",
      "authors": "Y. Sun, X. Liu, L. Liang"
    },
    {
      "index": 20,
      "title": "Improving the speed of neural networks on cpus",
      "abstract": "",
      "year": "2011",
      "venue": "NIPS2011 Workshop on Deep Learn. Unsupervised Feature Learn.",
      "authors": "V. Vanhoucke, A. Senior, M. Z. Mao"
    },
    {
      "index": 21,
      "title": "Fixed-point feedforward deep neural network design using weights +1, 0, and ‚àí-1",
      "abstract": "",
      "year": "2014",
      "venue": "IEEE Workshop Signal Process. Syst.",
      "authors": "K. Hwang, W. Sung"
    },
    {
      "index": 22,
      "title": "Fixed point optimization of deep convolutional neural networks for object recognition",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE Int. Conf. Acoust., Speech, Signal Process.",
      "authors": "S. Anwar, K. Hwang, W. Sung"
    },
    {
      "index": 23,
      "title": "Optimal brain damage",
      "abstract": "",
      "year": "1989",
      "venue": "Conf. Neural Inf. Process. Syst.",
      "authors": "Y. LeCun, J. S. Denker, S. A. Solla"
    },
    {
      "index": 24,
      "title": "Second order derivatives for network pruning: Optimal brain surgeon",
      "abstract": "",
      "year": "1992",
      "venue": "Conf. Neural Inf. Process. Syst.",
      "authors": "B. Hassibi, D. G. Stork"
    },
    {
      "index": 25,
      "title": "Dynamic Network Surgery for Efficient DNNs",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Y. Guo, A. Yao, Y. Chen",
      "orig_title": "Dynamic network surgery for efficient DNNs",
      "paper_id": "1608.04493v2"
    },
    {
      "index": 26,
      "title": "Exploiting sparseness in deep neural networks for large vocabulary speech recognition",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE Int. Conf. Acoust., Speech, Signal Process.",
      "authors": "D. Yu, F. Seide, G. Li, L. Deng"
    },
    {
      "index": 27,
      "title": "A novel layerwise pruning method for model reduction of fully connected deep neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Int. Conf. Acoust., Speech, Signal Process.",
      "authors": "L. Mauch, B. Yang"
    },
    {
      "index": 28,
      "title": "Data-free parameter pruning for deep neural networks",
      "abstract": "",
      "year": "2015",
      "venue": "CoRR",
      "authors": "S. Srinivas, R. V. Babu"
    },
    {
      "index": 29,
      "title": "Pruning and Quantization for Deep Neural Network Acceleration: A Survey",
      "abstract": "",
      "year": "2021",
      "venue": "Neurocomputing",
      "authors": "T. Liang, J. Glossner, L. Wang, S. Shi, X. Zhang",
      "orig_title": "Pruning and quantization for deep neural network acceleration: A survey",
      "paper_id": "2101.09671v3"
    },
    {
      "index": 30,
      "title": "Methods for pruning deep neural networks",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE Access",
      "authors": "S. Vadera, S. Ameen"
    },
    {
      "index": 31,
      "title": "Learning both Weights and Connections for Efficient Neural Networks",
      "abstract": "",
      "year": "2015",
      "venue": "Conf. Neural Inf. Process. Syst.",
      "authors": "S. Han, J. Pool, J. Tran, W. Dally",
      "orig_title": "Learning both weights and connections for efficient neural network",
      "paper_id": "1506.02626v3"
    },
    {
      "index": 32,
      "title": "Dropneuron: Simplifying the structure of deep neural networks",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "W. Pan, H. Dong, Y. Guo"
    },
    {
      "index": 33,
      "title": "Learning sparse neural networks through l‚Äã_‚Äã0ùëô_0l\\_0 regularization",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint",
      "authors": "C. Louizos, M. Welling, D. P. Kingma"
    },
    {
      "index": 34,
      "title": "Group Sparse Regularization for Deep Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "Neurocomputing",
      "authors": "S. Scardapane, D. Comminiello, A. Hussain, A. Uncini",
      "orig_title": "Group sparse regularization for deep neural networks",
      "paper_id": "1607.00485v1"
    },
    {
      "index": 35,
      "title": "Compressed sensing",
      "abstract": "",
      "year": "2006",
      "venue": "IEEE Trans. Inf. Theory",
      "authors": "D. L. Donoho"
    },
    {
      "index": 36,
      "title": "ùêø‚ÇÄ-ARM: Network Sparsification via Stochastic Binary Optimization",
      "abstract": "",
      "year": "2019",
      "venue": "Joint Eur. Conf. Mach. Learn. Knowl. Discovery in Databases",
      "authors": "Y. Li, S. Ji",
      "orig_title": "L0-arm: Network sparsification via stochastic binary optimization",
      "paper_id": "1904.04432v3"
    },
    {
      "index": 37,
      "title": "A Systematic DNN Weight Pruning Framework using Alternating Direction Method of Multipliers",
      "abstract": "",
      "year": "2018",
      "venue": "Computer Vision ‚Äì ECCV 2018",
      "authors": "T. Zhang, S. Ye, K. Zhang, J. Tang, W. Wen, M. Fardad, Y. Wang",
      "orig_title": "A systematic DNN weight pruning framework using alternating direction method of multipliers",
      "paper_id": "1804.03294v3"
    },
    {
      "index": 38,
      "title": "‚Äùlearning-compression‚Äù algorithms for neural net pruning",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE/CVF Conf. Comput. Vision Pattern Recognit.",
      "authors": "M. A. Carreira-Perpinan, Y. Idelbayev"
    },
    {
      "index": 39,
      "title": "Exploring the effect of l0/l2 regularization in neural network pruning using the LC toolkit",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE Int. Conf. Acoust., Speech, Signal Process.",
      "authors": "Y. Idelbayev, M. A. Carreira-Perpinan"
    },
    {
      "index": 40,
      "title": "L0 norm constraint LMS algorithm for sparse system identification",
      "abstract": "",
      "year": "2009",
      "venue": "IEEE Sig. Process. Lett.",
      "authors": "Y. Gu, J. Jin, S. Mei"
    },
    {
      "index": 41,
      "title": "L0 regularization based fine-grained neural network pruning method",
      "abstract": "",
      "year": "2019",
      "venue": "Int. Conf. Electron., Comput. Artif. Intell.",
      "authors": "Q. Xie, C. Li, B. Diao, Z. An, Y. Xu"
    },
    {
      "index": 42,
      "title": "L0-norm-based sparse representation through alternate projections",
      "abstract": "",
      "year": "2006",
      "venue": "IEEE Int. Conf. Image Process.",
      "authors": "L. Mancera, J. Portilla"
    },
    {
      "index": 43,
      "title": "Caffe: Convolutional Architecture for Fast Feature Embedding",
      "abstract": "",
      "year": "2014",
      "venue": "CoRR",
      "authors": "Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. B. Girshick, S. Guadarrama, T. Darrell",
      "orig_title": "Caffe: Convolutional architecture for fast feature embedding",
      "paper_id": "1408.5093v1"
    },
    {
      "index": 44,
      "title": "What is the state of neural network pruning?",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint",
      "authors": "D. Blalock, J. J. G. Ortiz, J. Frankle, J. Guttag"
    },
    {
      "index": 45,
      "title": "Bayesian Compression for Deep Learning",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "C. Louizos, K. Ullrich, M. Welling",
      "orig_title": "Bayesian compression for deep learning",
      "paper_id": "1705.08665v4"
    },
    {
      "index": 46,
      "title": "Variational Dropout Sparsifies Deep Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "Int. Conf. Mach. Learn.",
      "authors": "D. Molchanov, A. Ashukha, D. Vetrov",
      "orig_title": "Variational dropout sparsifies deep neural networks",
      "paper_id": "1701.05369v3"
    },
    {
      "index": 47,
      "title": "Pruning deep neural networks with ‚Ñì0subscript‚Ñì0\\ell_{0}-constrained optimization",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Int. Conf. Data Mining",
      "authors": "D. T. Phan, L. M. Nguyen, N. H. Nguyen, J. R. Kalagnanam"
    },
    {
      "index": 48,
      "title": "Global Sparse Momentum SGD for Pruning Very Deep Neural Networks",
      "abstract": "",
      "year": "2019",
      "venue": "Int. Conf. Neural Inf. Proc. Syst.",
      "authors": "X. Ding, G. Ding, X. Zhou, Y. Guo, J. Han, J. Liu",
      "orig_title": "Global sparse momentum SGD for pruning very deep neural networks",
      "paper_id": "1909.12778v3"
    },
    {
      "index": 49,
      "title": "Autoprune: Automatic network pruning by regularizing auxiliary parameters",
      "abstract": "",
      "year": "2019",
      "venue": "Int. Conf. Neural Inf. Proc. Syst.",
      "authors": "X. Xiao, Z. Wang"
    },
    {
      "index": 50,
      "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
      "abstract": "",
      "year": "2015",
      "venue": "Int. Conf. Learning Representations",
      "authors": "K. Simonyan, A. Zisserman",
      "orig_title": "Very deep convolutional networks for large-scale image recognition",
      "paper_id": "1409.1556v6"
    },
    {
      "index": 51,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conf. Comput. Vision Pattern Recognit.",
      "authors": "K. He, X. Zhang, S. Ren, J. Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 52,
      "title": "Data-Driven Sparse Structure Selection for Deep Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "Eur. Conf. Comput. Vis. (ECCV)",
      "authors": "Z. Huang, N. Wang",
      "orig_title": "Data-driven sparse structure selection for deep neural networks",
      "paper_id": "1707.01213v3"
    },
    {
      "index": 53,
      "title": "Pruning Filters for Efficient ConvNets",
      "abstract": "",
      "year": "2017",
      "venue": "Int. Conf. Learn. Representations",
      "authors": "H. Li, A. Kadav, I. Durdanovic, H. Samet, H. P. Graf",
      "orig_title": "Pruning filters for efficient ConvNets",
      "paper_id": "1608.08710v3"
    },
    {
      "index": 54,
      "title": "Variational convolutional neural network pruning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conf. Comput. Vis. Pattern Recog.",
      "authors": "C. Zhao, B. Ni, J. Zhang, Q. Zhao, W. Zhang, Q. Tian"
    },
    {
      "index": 55,
      "title": "Play and prune: Adaptive filter pruning for deep model compression",
      "abstract": "",
      "year": "2019",
      "venue": "Int. Joint Conf. Artificial Intelligence",
      "authors": "P. Singh, V. K. Verma, P. Rai, V. P. Namboodiri"
    },
    {
      "index": 56,
      "title": "Redundant feature pruning for accelerated inference in deep neural networks",
      "abstract": "",
      "year": "2019",
      "venue": "Neural Networks",
      "authors": "B. O. Ayinde, T. Inanc, J. M. Zurada"
    },
    {
      "index": 57,
      "title": "Compressing convolutional neural networks via factorized convolutional filters",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conf. Comput. Vis. Pattern Recog.",
      "authors": "T. Li, B. Wu, Y. Yang, Y. Fan, Y. Zhang, W. Liu"
    },
    {
      "index": 58,
      "title": "Rethinking the Smaller-Norm-Less- Informative Assumption in Channel Pruning of Convolution Layers",
      "abstract": "",
      "year": "2018",
      "venue": "Int. Conf. Learn. Representations",
      "authors": "J. Ye, X. Lu, Z. Lin, J. Z. Wang",
      "orig_title": "Rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers",
      "paper_id": "1802.00124v2"
    },
    {
      "index": 59,
      "title": "DHP: Differentiable Meta Pruning via HyperNetworks",
      "abstract": "",
      "year": "2020",
      "venue": "Eur. Conf. Comput. Vision",
      "authors": "Y. Li, S. Gu, K. Zhang, L. Van Gool, R. Timofte",
      "orig_title": "DHP: Differentiable meta pruning via hypernetworks",
      "paper_id": "2003.13683v3"
    },
    {
      "index": 60,
      "title": "Compressing deep networks by neuron agglomerative clustering",
      "abstract": "",
      "year": "2020",
      "venue": "Sensors",
      "authors": "L.-N. Wang, W. Liu, X. Liu, G. Zhong, P. P. Roy, J. Dong, K. Huang"
    }
  ]
}