{
  "paper_id": "2104.08959v2",
  "title": "Non-asymptotic model selection in block-diagonal mixture of polynomial experts models",
  "abstract": "Abstract\nModel selection, via penalized likelihood type criteria, is a standard task in many statistical inference and machine learning problems. Progress has led to deriving criteria with asymptotic consistency results and an increasing emphasis on introducing non-asymptotic criteria.\nWe focus on the problem of modeling non-linear relationships in regression data with potential hidden graph-structured interactions between the high-dimensional predictors, within the mixture of experts modeling framework.\nIn order to deal with such a complex situation, we investigate a block-diagonal localized mixture of polynomial experts (BLoMPE) regression model, which is constructed upon an inverse regression and block-diagonal structures of the Gaussian expert covariance matrices.\nWe introduce a penalized maximum likelihood selection criterion to estimate the unknown conditional density of the regression model.\nThis model selection criterion allows us to handle the challenging problem of inferring the number of mixture components, the degree of polynomial mean functions, and the hidden block-diagonal structures of the covariance matrices, which reduces the number of parameters to be estimated and leads to a trade-off between complexity and sparsity in the model.\nIn particular, we provide a strong theoretical guarantee: a finite-sample oracle inequality satisfied by the penalized maximum likelihood estimator with a Jensen‚ÄìKullback‚ÄìLeibler type loss, to support the introduced non-asymptotic model selection criterion.\nThe penalty shape of this criterion depends on the complexity of the considered random subcollection of BLoMPE models, including the relevant graph structures, the degree of polynomial mean functions, and the number of mixture components.",
  "reference_labels": [
    {
      "index": 0,
      "title": "A new look at the statistical model identification",
      "abstract": "",
      "year": "1974",
      "venue": "IEEE transactions on automatic control",
      "authors": "Akaike, H."
    },
    {
      "index": 1,
      "title": "Model selection and multi-model inference",
      "abstract": "",
      "year": "2004",
      "venue": "Springer-Verlag",
      "authors": "Anderson, D. & Burnham, K."
    },
    {
      "index": 2,
      "title": "Minimal penalties and the slope heuristics: a survey",
      "abstract": "",
      "year": "2019",
      "venue": "Journal de la Soci√©t√© Fran√ßaise de Statistique",
      "authors": "Arlot, S."
    },
    {
      "index": 3,
      "title": "The MDL principle, penalized likelihoods, and statistical risk",
      "abstract": "",
      "year": "2008",
      "venue": "Festschrift in Honor of Jorma Rissanen on the Occasion of his 75th Birthday",
      "authors": "Barron, A.¬†R., Huang, C., Li, J., & Luo, X."
    },
    {
      "index": 4,
      "title": "Slope heuristics: overview and implementation",
      "abstract": "",
      "year": "2012",
      "venue": "Statistics and Computing",
      "authors": "Baudry, J.-P., Maugis, C., & Michel, B."
    },
    {
      "index": 5,
      "title": "Minimal penalties for Gaussian model selection",
      "abstract": "",
      "year": "2007",
      "venue": "Probability theory and related fields",
      "authors": "Birg√©, L. & Massart, P."
    },
    {
      "index": 6,
      "title": "Minimum contrast estimators on sieves: exponential bounds and rates of convergence",
      "abstract": "",
      "year": "1998",
      "venue": "Bernoulli",
      "authors": "Birg√©, L., Massart, P., et¬†al."
    },
    {
      "index": 7,
      "title": "Localised mixtures of experts for mixture of regressions",
      "abstract": "",
      "year": "2003",
      "venue": "Between Data Science and Applied Data Analysis",
      "authors": "Bouchard, G."
    },
    {
      "index": 8,
      "title": "Regularized Estimation and Feature Selection in Mixtures of Gaussian-Gated Experts Models",
      "abstract": "",
      "year": "2019",
      "venue": "Research School on Statistics and Data Science",
      "authors": "Chamroukhi, F., Lecocq, F., & Nguyen, H.¬†D.",
      "orig_title": "Regularized Estimation and Feature Selection in Mixtures of Gaussian-Gated Experts Models",
      "paper_id": "1909.05494v1"
    },
    {
      "index": 9,
      "title": "Conditional density estimation by penalized likelihood model selection and applications",
      "abstract": "",
      "year": "2011",
      "venue": "INRIA",
      "authors": "Cohen, S. & Pennec, E.¬†L."
    },
    {
      "index": 10,
      "title": "Hyper-Spectral Image Analysis With Partially Latent Regression and Spatial Markov Dependencies",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE Journal of Selected Topics in Signal Processing",
      "authors": "Deleforge, A., Forbes, F., Ba, S., & Horaud, R."
    },
    {
      "index": 11,
      "title": "High-dimensional regression with gaussian mixtures and partially-latent response variables",
      "abstract": "",
      "year": "2015",
      "venue": "Statistics and Computing",
      "authors": "Deleforge, A., Forbes, F., & Horaud, R."
    },
    {
      "index": 12,
      "title": "An l1subscriptùëô1l_{1}-oracle inequality for the Lasso in finite mixture of multivariate Gaussian regression",
      "abstract": "",
      "year": "2015",
      "venue": "ESAIM: Probability and Statistics",
      "authors": "Devijver, E."
    },
    {
      "index": 13,
      "title": "Finite mixture regression: A sparse variable selection by model selection for clustering",
      "abstract": "",
      "year": "2015",
      "venue": "Electron. J. Statist.",
      "authors": "Devijver, E."
    },
    {
      "index": 14,
      "title": "Joint rank and variable selection for parsimonious estimation in a high-dimensional finite mixture regression model",
      "abstract": "",
      "year": "2017",
      "venue": "Journal of Multivariate Analysis",
      "authors": "Devijver, E."
    },
    {
      "index": 15,
      "title": "Model-based regression clustering for high-dimensional data: application to functional data",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Data Analysis and Classification",
      "authors": "Devijver, E."
    },
    {
      "index": 16,
      "title": "Block-diagonal covariance selection for high-dimensional Gaussian graphical models",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of the American Statistical Association",
      "authors": "Devijver, E. & Gallopin, M.",
      "orig_title": "Block-Diagonal Covariance Selection for High-Dimensional Gaussian Graphical Models",
      "paper_id": "1511.04033v3"
    },
    {
      "index": 17,
      "title": "Nonlinear network-based quantitative trait prediction from transcriptomic data",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1701.07899",
      "authors": "Devijver, E., Gallopin, M., & Perthame, E."
    },
    {
      "index": 18,
      "title": "Rates of convergence for the Gaussian mixture sieve",
      "abstract": "",
      "year": "2000",
      "venue": "The Annals of Statistics",
      "authors": "Genovese, C.¬†R. & Wasserman, L."
    },
    {
      "index": 19,
      "title": "Molecular classification of cancer: class discovery and class prediction by gene expression monitoring",
      "abstract": "",
      "year": "1999",
      "venue": "Science (New York, N.Y.)",
      "authors": "Golub, T.¬†R., Slonim, D.¬†K., Tamayo, P., Huard, C., Gaasenbeek, M., Mesirov, J.¬†P., Coller, H., Loh, M.¬†L., Downing, J.¬†R., Caligiuri, M.¬†A., Bloomfield, C.¬†D., & Lander, E.¬†S."
    },
    {
      "index": 20,
      "title": "Convergence rates of parameter estimation for some weakly identifiable finite mixtures",
      "abstract": "",
      "year": "2016",
      "venue": "Annals of statistics",
      "authors": "Ho, N., Nguyen, X., et¬†al."
    },
    {
      "index": 21,
      "title": "On strong identifiability and convergence rates of parameter estimation in finite mixtures",
      "abstract": "",
      "year": "2016",
      "venue": "Electronic Journal of Statistics",
      "authors": "Ho, N., Nguyen, X., et¬†al."
    },
    {
      "index": 22,
      "title": "Convergence Rates for Gaussian Mixtures of Experts",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1907.04377",
      "authors": "Ho, N., Yang, C.-Y., & Jordan, M.¬†I.",
      "orig_title": "Convergence Rates for Gaussian Mixtures of Experts",
      "paper_id": "1907.04377v2"
    },
    {
      "index": 23,
      "title": "Local Statistical Modeling via a Cluster-Weighted Approach with Elliptical Distributions",
      "abstract": "",
      "year": "2012",
      "venue": "Journal of Classification",
      "authors": "Ingrassia, S., Minotti, S.¬†C., & Vittadini, G."
    },
    {
      "index": 24,
      "title": "Adaptive Mixtures of Local Experts",
      "abstract": "",
      "year": "1991",
      "venue": "Neural Computation",
      "authors": "Jacobs, R.¬†A., Jordan, M.¬†I., Nowlan, S.¬†J., & Hinton, G.¬†E."
    },
    {
      "index": 25,
      "title": "Hierarchical mixtures-of-experts for exponential family regression models: approximation and maximum likelihood estimation",
      "abstract": "",
      "year": "1999",
      "venue": "Annals of Statistics",
      "authors": "Jiang, W. & Tanner, M.¬†A."
    },
    {
      "index": 26,
      "title": "Hierarchical mixtures of experts and the EM algorithm",
      "abstract": "",
      "year": "1994",
      "venue": "Neural computation",
      "authors": "Jordan, M.¬†I. & Jacobs, R.¬†A."
    },
    {
      "index": 27,
      "title": "New estimation and feature selection methods in mixture-of-experts models",
      "abstract": "",
      "year": "2010",
      "venue": "Canadian Journal of Statistics",
      "authors": "Khalili, A."
    },
    {
      "index": 28,
      "title": "Introduction to Empirical Processes and Semiparametric Inference",
      "abstract": "",
      "year": "2007",
      "venue": "Springer Science & Business Media",
      "authors": "Kosorok, M.¬†R."
    },
    {
      "index": 29,
      "title": "Deep mixture of linear inverse regressions applied to head-pose estimation",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Lathuili√®re, S., Juge, R., Mesejo, P., Mu√±oz-Salinas, R., & Horaud, R."
    },
    {
      "index": 30,
      "title": "A sparse PLS for variable selection when integrating omics data",
      "abstract": "",
      "year": "2008",
      "venue": "Statistical applications in genetics and molecular biology",
      "authors": "L√™ Cao, K.-A., Rossouw, D., Robert-Grani√©, C., & Besse, P."
    },
    {
      "index": 31,
      "title": "Sliced Inverse Regression for Dimension Reduction",
      "abstract": "",
      "year": "1991",
      "venue": "Journal of the American Statistical Association",
      "authors": "Li, K.-C."
    },
    {
      "index": 32,
      "title": "Some Comments on CP",
      "abstract": "",
      "year": "1973",
      "venue": "Technometrics",
      "authors": "Mallows, C.¬†L."
    },
    {
      "index": 33,
      "title": "Concentration Inequalities and Model Selection: Ecole d‚ÄôEt√© de Probabilit√©s de Saint-Flour XXXIII-2003",
      "abstract": "",
      "year": "2007",
      "venue": "Springer",
      "authors": "Massart, P."
    },
    {
      "index": 34,
      "title": "The Lasso as an l1subscriptùëô1l_{1}-ball model selection procedure",
      "abstract": "",
      "year": "2011",
      "venue": "Electronic Journal of Statistics",
      "authors": "Massart, P. & Meynet, C."
    },
    {
      "index": 35,
      "title": "A non asymptotic penalized criterion for Gaussian mixture model selection",
      "abstract": "",
      "year": "2011",
      "venue": "ESAIM: Probability and Statistics",
      "authors": "Maugis, C. & Michel, B."
    },
    {
      "index": 36,
      "title": "Data-driven penalty calibration: A case study for Gaussian mixture model selection",
      "abstract": "",
      "year": "2011",
      "venue": "ESAIM: PS",
      "authors": "Maugis, C. & Michel, B."
    },
    {
      "index": 37,
      "title": "On Convergence Rates of Mixtures of Polynomial Experts",
      "abstract": "",
      "year": "2012",
      "venue": "Neural Computation",
      "authors": "Mendes, E.¬†F. & Jiang, W."
    },
    {
      "index": 38,
      "title": "An l1subscriptùëô1l_{1}-oracle inequality for the Lasso in finite mixture Gaussian regression models",
      "abstract": "",
      "year": "2013",
      "venue": "ESAIM: Probability and Statistics",
      "authors": "Meynet, C."
    },
    {
      "index": 39,
      "title": "Classification using localized mixture of experts",
      "abstract": "",
      "year": "1999",
      "venue": "International Conference on Artificial Neural Networks",
      "authors": "Moerland, P."
    },
    {
      "index": 40,
      "title": "Mixture of Gaussian regressions model with logistic weights, a penalized maximum likelihood approach",
      "abstract": "",
      "year": "2014",
      "venue": "Electronic Journal of Statistics",
      "authors": "Montuelle, L., Le¬†Pennec, E., et¬†al."
    },
    {
      "index": 41,
      "title": "Tumor classification by partial least squares using microarray gene expression data",
      "abstract": "",
      "year": "2002",
      "venue": "Bioinformatics",
      "authors": "Nguyen, D.¬†V. & Rocke, D.¬†M."
    },
    {
      "index": 42,
      "title": "Practical and theoretical aspects of mixture-of-experts modeling: An overview",
      "abstract": "",
      "year": "2018",
      "venue": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery",
      "authors": "Nguyen, H.¬†D. & Chamroukhi, F."
    },
    {
      "index": 43,
      "title": "Approximation results regarding the multiple-output Gaussian gated mixture of linear experts model",
      "abstract": "",
      "year": "2019",
      "venue": "Neurocomputing",
      "authors": "Nguyen, H.¬†D., Chamroukhi, F., & Forbes, F."
    },
    {
      "index": 44,
      "title": "A Universal Approximation Theorem for Mixture-of-Experts Models",
      "abstract": "",
      "year": "2016",
      "venue": "Neural Computation",
      "authors": "Nguyen, H.¬†D., Lloyd-Jones, L.¬†R., & McLachlan, G.¬†J."
    },
    {
      "index": 45,
      "title": "Approximations of conditional probability density functions in Lebesgue spaces via mixture of experts models",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2012.02385",
      "authors": "Nguyen, H.¬†D., Nguyen, T., Chamroukhi, F., & McLachlan, G."
    },
    {
      "index": 46,
      "title": "Approximation of probability density functions via location-scale finite mixtures in Lebesgue spaces",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2008.09787",
      "authors": "Nguyen, T., Chamroukhi, F., Nguyen, H.¬†D., & McLachlan, G.¬†J."
    },
    {
      "index": 47,
      "title": "An l1subscriptùëô1l_{1}-oracle inequality for the Lasso in mixture-of-experts regression models",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2009.10622",
      "authors": "Nguyen, T., Nguyen, H.¬†D., Chamroukhi, F., & McLachlan, G.¬†J."
    },
    {
      "index": 48,
      "title": "A non-asymptotic penalization criterion for model selection in mixture of experts models",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2104.02640",
      "authors": "Nguyen, T.¬†T., Nguyen, H.¬†D., Chamroukhi, F., & Forbes, F."
    },
    {
      "index": 49,
      "title": "Approximation by finite mixtures of continuous density functions that vanish at infinity",
      "abstract": "",
      "year": "2020",
      "venue": "Cogent Mathematics & Statistics",
      "authors": "Nguyen, T.¬†T., Nguyen, H.¬†D., Chamroukhi, F., & McLachlan, G.¬†J."
    },
    {
      "index": 50,
      "title": "Convergence of latent mixing measures in finite and infinite mixture models",
      "abstract": "",
      "year": "2013",
      "venue": "Annals of statistics",
      "authors": "Nguyen, X. et¬†al."
    },
    {
      "index": 51,
      "title": "Approximation of conditional densities by smooth mixtures of regressions",
      "abstract": "",
      "year": "2010",
      "venue": "Annals of statistics",
      "authors": "Norets, A. et¬†al."
    },
    {
      "index": 52,
      "title": "Adaptive Bayesian estimation of conditional densities",
      "abstract": "",
      "year": "2017",
      "venue": "Econometric Theory",
      "authors": "Norets, A. & Pati, D."
    },
    {
      "index": 53,
      "title": "Posterior consistency in conditional density estimation by covariate dependent mixtures",
      "abstract": "",
      "year": "2014",
      "venue": "Econometric Theory",
      "authors": "Norets, A. & Pelenis, J."
    },
    {
      "index": 54,
      "title": "Inverse regression approach to robust nonlinear high-to-low dimensional mapping",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of Multivariate Analysis",
      "authors": "Perthame, E., Forbes, F., & Deleforge, A."
    },
    {
      "index": 55,
      "title": "Structural adaptation in mixture of experts",
      "abstract": "",
      "year": "1996",
      "venue": "International Conference on Pattern Recognition",
      "authors": "Ramamurti, V. & Ghosh, J."
    },
    {
      "index": 56,
      "title": "Use of localized gating in mixture of experts networks",
      "abstract": "",
      "year": "1998",
      "venue": "SPIE",
      "authors": "Ramamurti, V. & Ghosh, J."
    },
    {
      "index": 57,
      "title": "On-line EM algorithm for the normalized gaussian network",
      "abstract": "",
      "year": "2000",
      "venue": "Neural computation",
      "authors": "Sato, M. & Ishii, S."
    },
    {
      "index": 58,
      "title": "Estimating the dimension of a model",
      "abstract": "",
      "year": "1978",
      "venue": "The annals of statistics",
      "authors": "Schwarz, G. et¬†al."
    },
    {
      "index": 59,
      "title": "Weak Convergence and Empirical Processes: With Applications to Statistics Springer Series in Statistics",
      "abstract": "",
      "year": "1996",
      "venue": "Springer",
      "authors": "Van Der¬†Vaart, A. & Wellner, J."
    },
    {
      "index": 60,
      "title": "An Alternative Model for Mixtures of Experts",
      "abstract": "",
      "year": "1995",
      "venue": "Advances in neural information processing systems",
      "authors": "Xu, L., Jordan, M.¬†I., & Hinton, G.¬†E."
    },
    {
      "index": 61,
      "title": "Twenty Years of Mixture of Experts",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Yuksel, S.¬†E., Wilson, J.¬†N., & Gader, P.¬†D."
    }
  ]
}