{
  "paper_id": "2005.07870v4",
  "title": "Learning Transferable Concepts in Deep Reinforcement Learning",
  "abstract": "Abstract\nWhile humans and animals learn incrementally during their lifetimes and exploit their experience to solve new tasks, standard deep reinforcement learning methods specialize to solve only one task at a time. As a result, the information they acquire is hardly reusable in new situations. Here, we introduce a new perspective on the problem of leveraging prior knowledge to solve future tasks. We show that learning discrete representations of sensory inputs can provide a high-level abstraction that is common across multiple tasks, thus facilitating the transference of information. In particular, we show that it is possible to learn such representations by self-supervision, following an information theoretic approach. Our method is able to learn concepts in locomotive and optimal control tasks that increase the sample efficiency in both known and unknown tasks, opening a new path to endow artificial agents with generalization abilities.",
  "reference_labels": [
    {
      "index": 0,
      "title": "An operating cost of learning in Drosophila melanogaster",
      "abstract": "",
      "year": "2004",
      "venue": "Animal Behaviour",
      "authors": "F. Mery and T. J. Kawecki"
    },
    {
      "index": 1,
      "title": "Neuronal energy consumption: biophysics, efficiency and evolution",
      "abstract": "",
      "year": "2016",
      "venue": "Current Opinion in Neurobiology",
      "authors": "J. E. Niven"
    },
    {
      "index": 2,
      "title": "Resilient machines through continuous self-modeling",
      "abstract": "",
      "year": "2006",
      "venue": "Science",
      "authors": "J. Bongard et al."
    },
    {
      "index": 3,
      "title": "Soft Actor-Critic Algorithms and Applications",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:1812.05905",
      "authors": "T. Haarnoja et al.",
      "orig_title": "Soft Actor-Critic Algorithms and Applications",
      "paper_id": "1812.05905v2"
    },
    {
      "index": 4,
      "title": "Human-level control through deep reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "V. Mnih et al."
    },
    {
      "index": 5,
      "title": "Mastering the game of Go without human knowledge",
      "abstract": "",
      "year": "2017",
      "venue": "Nature",
      "authors": "D. Silver et al."
    },
    {
      "index": 6,
      "title": "Learning Dexterous In-Hand Manipulation",
      "abstract": "",
      "year": "2020",
      "venue": "The International Journal of Robotics Research",
      "authors": "O. M. Andrychowicz et al.",
      "orig_title": "Learning dexterous in-hand manipulation",
      "paper_id": "1808.00177v5"
    },
    {
      "index": 7,
      "title": "Robots that can adapt like animals",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "A. Cully et al."
    },
    {
      "index": 8,
      "title": "Comparing continual task learning in minds and machines",
      "abstract": "",
      "year": "2018",
      "venue": "National Academy of Sciences of the United States of America",
      "authors": "T. Flesch et al."
    },
    {
      "index": 9,
      "title": "Quantifying Generalization in Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "36th ICML",
      "authors": "K. Cobbe et al.",
      "orig_title": "Quantifying Generalization in Reinforcement Learning",
      "paper_id": "1812.02341v3"
    },
    {
      "index": 10,
      "title": "Investigating Generalisation in Continuous Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:1902.07015",
      "authors": "C. Zhao et al."
    },
    {
      "index": 11,
      "title": "When Waiting Is Not an Option: Learning Options With a Deliberation Cost",
      "abstract": "",
      "year": "2018",
      "venue": "Thirty-Second AAAI Conference on Artificial Intelligence",
      "authors": "J. Harb et al."
    },
    {
      "index": 12,
      "title": "Benchmarking Deep Reinforcement Learning for Continuous Control",
      "abstract": "",
      "year": "2016",
      "venue": "33rd ICML",
      "authors": "Y. Duan et al.",
      "orig_title": "Benchmarking deep reinforcement learning for continuous control",
      "paper_id": "1604.06778v3"
    },
    {
      "index": 13,
      "title": "Shortcut Learning in Deep Neural Networks",
      "abstract": "",
      "year": "2020",
      "venue": "Nature Machine Intelligence",
      "authors": "R. Geirhos et al.",
      "orig_title": "Shortcut learning in deep neural networks",
      "paper_id": "2004.07780v5"
    },
    {
      "index": 14,
      "title": "Discrete fixed-resolution representations in visual working memory",
      "abstract": "",
      "year": "2008",
      "venue": "Nature",
      "authors": "W. Zhang and S. J. Luck"
    },
    {
      "index": 15,
      "title": "Hierarchical recurrent state space models reveal discrete and continuous dynamics of neural activity in C. elegans",
      "abstract": "",
      "year": "2019",
      "venue": "bioRxiv:10.1101/621540",
      "authors": "S. Linderman et al."
    },
    {
      "index": 16,
      "title": "Unsupervised deep learning identifies semantic disentanglement in single inferotemporal neurons",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:2006.14304",
      "authors": "I. Higgins et al."
    },
    {
      "index": 17,
      "title": "Efficient human-like semantic representations via the Information Bottleneck principle",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:1808.03353",
      "authors": "N. Zaslavsky et al.",
      "orig_title": "Efficient human-like semantic representations via the Information Bottleneck principle",
      "paper_id": "1808.03353v1"
    },
    {
      "index": 18,
      "title": "The evolution of color vision in insects.",
      "abstract": "",
      "year": "2001",
      "venue": "Annual Review of Entomology",
      "authors": "A. D. Briscoe and L. Chittka"
    },
    {
      "index": 19,
      "title": "The Faculty of Language: What Is It, Who Has It, and How Did It Evolve?",
      "abstract": "",
      "year": "2002",
      "venue": "Science",
      "authors": "M. D. Hauser et al."
    },
    {
      "index": 20,
      "title": "Artificial intelligence and the common sense of animals",
      "abstract": "",
      "year": "2020",
      "venue": "Trends in Cognitive Sciences",
      "authors": "M. Shanahan et al."
    },
    {
      "index": 21,
      "title": "Investigating Simple Object Representations in Model-Free Deep Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:2002.06703",
      "authors": "G. Davidson and B. M. Lake",
      "orig_title": "Investigating Simple Object Representations in Model-Free Deep Reinforcement Learning",
      "paper_id": "2002.06703v2"
    },
    {
      "index": 22,
      "title": "Programming backgammon using self-teaching neural nets",
      "abstract": "",
      "year": "2002",
      "venue": "Artificial Intelligence",
      "authors": "G. Tesauro"
    },
    {
      "index": 23,
      "title": "On Inductive Biases in Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:1907.02908",
      "authors": "M. Hessel et al.",
      "orig_title": "On inductive biases in deep reinforcement learning",
      "paper_id": "1907.02908v1"
    },
    {
      "index": 24,
      "title": "Entity Abstraction in Visual Model-Based Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:1910.12827",
      "authors": "R. Veerapaneni et al."
    },
    {
      "index": 25,
      "title": "Unsupervised Learning of Object Keypoints for Perception and Control",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in NeurIPS",
      "authors": "T. D. Kulkarni et al.",
      "orig_title": "Unsupervised Learning of Object Keypoints for Perception and Control",
      "paper_id": "1906.11883v2"
    },
    {
      "index": 26,
      "title": "Generating Diverse High-Fidelity Images with VQ-VAE-2",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in NeurIPS",
      "authors": "A. Razavi et al.",
      "orig_title": "Generating Diverse High-Fidelity Images with VQ-VAE-2",
      "paper_id": "1906.00446v1"
    },
    {
      "index": 27,
      "title": "Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning",
      "abstract": "",
      "year": "1999",
      "venue": "Artificial intelligence",
      "authors": "R. S. Sutton et al."
    },
    {
      "index": 28,
      "title": "The Option-Critic Architecture",
      "abstract": "",
      "year": "2017",
      "venue": "Thirty-First AAAI Conference on Artificial Intelligence",
      "authors": "P.-L. Bacon et al.",
      "orig_title": "The Option-Critic Architecture",
      "paper_id": "1609.05140v2"
    },
    {
      "index": 29,
      "title": "Meta Learning Shared Hierarchies",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "K. Frans et al.",
      "orig_title": "Meta Learning Shared Hierarchies",
      "paper_id": "1710.09767v1"
    },
    {
      "index": 30,
      "title": "Reinforcement Learning with Competitive Ensembles of Information-Constrained Primitives",
      "abstract": "",
      "year": "2020",
      "venue": "ICLR",
      "authors": "A. Goyal et al.",
      "orig_title": "Reinforcement learning with competitive ensembles of information-constrained primitives",
      "paper_id": "1906.10667v1"
    },
    {
      "index": 31,
      "title": "Mastering Atari with Discrete World Models",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:2010.02193",
      "authors": "D. Hafner et al.",
      "orig_title": "Mastering atari with discrete world models",
      "paper_id": "2010.02193v4"
    },
    {
      "index": 32,
      "title": "A survey of generalisation in deep reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv:2111.09794",
      "authors": "R. Kirk et al."
    },
    {
      "index": 33,
      "title": "Transfer Learning for Reinforcement Learning Domains: A survey",
      "abstract": "",
      "year": "2009",
      "venue": "JMLR",
      "authors": "M. E. Taylor and P. Stone"
    },
    {
      "index": 34,
      "title": "Transfer Learning in Deep Reinforcement Learning: A Survey",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:2009.07888",
      "authors": "Z. Zhu et al.",
      "orig_title": "Transfer Learning in Deep Reinforcement Learning: A survey",
      "paper_id": "2009.07888v7"
    },
    {
      "index": 35,
      "title": "Deep latent low-rank representation for face sketch synthesis",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "M. Zhang et al."
    },
    {
      "index": 36,
      "title": "Gradient Surgery for Multi-Task Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in NeurIPS",
      "authors": "T. Yu et al.",
      "orig_title": "Gradient Surgery for Multi-Task Learning",
      "paper_id": "2001.06782v4"
    },
    {
      "index": 37,
      "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
      "abstract": "",
      "year": "2017",
      "venue": "34th ICML",
      "authors": "C. Finn et al.",
      "orig_title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
      "paper_id": "1703.03400v3"
    },
    {
      "index": 38,
      "title": "On First-Order Meta-Learning Algorithms",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:1803.02999",
      "authors": "A. Nichol et al.",
      "orig_title": "On first-order meta-learning algorithms",
      "paper_id": "1803.02999v3"
    },
    {
      "index": 39,
      "title": "Imitation Learning via Off-Policy Distribution Matching",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:1912.05032",
      "authors": "I. Kostrikov et al.",
      "orig_title": "Imitation Learning via Off-Policy Distribution Matching",
      "paper_id": "1912.05032v1"
    },
    {
      "index": 40,
      "title": "Learning Abstract Options",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in NeurIPS",
      "authors": "M. Riemer et al.",
      "orig_title": "Learning Abstract Options",
      "paper_id": "1810.11583v4"
    },
    {
      "index": 41,
      "title": "Diversity is All You Need: Learning Skills without a Reward Function",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "B. Eysenbach et al.",
      "orig_title": "Diversity is All You Need: Learning Skills without a Reward Function",
      "paper_id": "1802.06070v6"
    },
    {
      "index": 42,
      "title": "Reinforcement Learning with Soft State Aggregation",
      "abstract": "",
      "year": "1994",
      "venue": "Advances in NeurIPS",
      "authors": "S. P. Singh et al."
    },
    {
      "index": 43,
      "title": "Towards a Unified Theory of State Abstraction for MDPs",
      "abstract": "",
      "year": "2006",
      "venue": "ISAIM",
      "authors": "L. Li et al."
    },
    {
      "index": 44,
      "title": "State abstraction discovery from irrelevant state variables.",
      "abstract": "",
      "year": "2005",
      "venue": "IJCAI",
      "authors": "N. K. Jong and P. Stone"
    },
    {
      "index": 45,
      "title": "Near optimal behavior via approximate state abstraction",
      "abstract": "",
      "year": "2016",
      "venue": "33th ICML",
      "authors": "D. Abel et al."
    },
    {
      "index": 46,
      "title": "Learning Invariant Representations for Reinforcement Learning without Reconstruction",
      "abstract": "",
      "year": "2021",
      "venue": "ICLR",
      "authors": "A. Zhang et al.",
      "orig_title": "Learning Invariant Representations for Reinforcement Learning without Reconstruction",
      "paper_id": "2006.10742v2"
    },
    {
      "index": 47,
      "title": "Innate ideas revisited: For a principle of persistence in infants’ physical reasoning",
      "abstract": "",
      "year": "2008",
      "venue": "Perspectives on Psychological Science",
      "authors": "R. Baillargeon"
    },
    {
      "index": 48,
      "title": "Eigenforms, Interfaces and Holographic Encoding: Toward an Evolutionary Account of Objects and Spacetime",
      "abstract": "",
      "year": "2017",
      "venue": "Constructivist Foundations",
      "authors": "C. Fields et al."
    },
    {
      "index": 49,
      "title": "Auto-encoding variational bayes",
      "abstract": "",
      "year": "2014",
      "venue": "ICLR",
      "authors": "D. P. Kingma and M. Welling"
    },
    {
      "index": 50,
      "title": "Self-organization in a perceptual network",
      "abstract": "",
      "year": "1988",
      "venue": "Computer",
      "authors": "R. Linsker"
    },
    {
      "index": 51,
      "title": "Learning factorial codes by predictability minimization",
      "abstract": "",
      "year": "1992",
      "venue": "Neural computation",
      "authors": "J. Schmidhuber"
    },
    {
      "index": 52,
      "title": "The information bottleneck method",
      "abstract": "",
      "year": "2000",
      "venue": "arXiv:physics/0004057",
      "authors": "N. Tishby et al."
    },
    {
      "index": 53,
      "title": "Deep Variational Information Bottleneck",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR",
      "authors": "A. A. Alemi et al."
    },
    {
      "index": 54,
      "title": "Action and Perception as Divergence Minimization",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:2009.01791",
      "authors": "D. Hafner et al.",
      "orig_title": "Action and perception as divergence minimization",
      "paper_id": "2009.01791v3"
    },
    {
      "index": 55,
      "title": "InfoBot: Transfer and Exploration via the Information Bottleneck",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "A. Goyal et al.",
      "orig_title": "Infobot: Transfer and exploration via the information bottleneck",
      "paper_id": "1901.10902v5"
    },
    {
      "index": 56,
      "title": "Generalization in Reinforcement Learning with Selective Noise Injection and Information Bottleneck",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in NeurIPS",
      "authors": "M. Igl et al."
    },
    {
      "index": 57,
      "title": "Information theory of decisions and actions",
      "abstract": "",
      "year": "2011",
      "venue": "Perception-action cycle. Springer",
      "authors": "N. Tishby and D. Polani"
    },
    {
      "index": 58,
      "title": "Trading value and information in mdps",
      "abstract": "",
      "year": "2012",
      "venue": "Decision Making with Imperfect Decision Makers. Springer",
      "authors": "J. Rubin et al."
    },
    {
      "index": 59,
      "title": "State abstraction as compression in apprenticeship learning",
      "abstract": "",
      "year": "2019",
      "venue": "Thirty-Third AAAI Conference on Artificial Intelligence",
      "authors": "D. Abel et al."
    },
    {
      "index": 60,
      "title": "Learning State Abstractions for Transfer in Continuous Control",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:2002.05518",
      "authors": "K. Asadi et al.",
      "orig_title": "Learning state abstractions for transfer in continuous control",
      "paper_id": "2002.05518v1"
    },
    {
      "index": 61,
      "title": "Reinforcement Learning: An Introduction",
      "abstract": "",
      "year": "2018",
      "venue": "MIT press",
      "authors": "R. S. Sutton and A. G. Barto"
    },
    {
      "index": 62,
      "title": "Trust Region Policy Optimization",
      "abstract": "",
      "year": "2015",
      "venue": "32nd ICML",
      "authors": "J. Schulman et al.",
      "orig_title": "Trust region policy optimization",
      "paper_id": "1502.05477v5"
    },
    {
      "index": 63,
      "title": "MuJoCo: A physics engine for model-based control",
      "abstract": "",
      "year": "2012",
      "venue": "2012 IEEE/RSJ International Conference on Intelligent Robots and Systems",
      "authors": "E. Todorov et al."
    },
    {
      "index": 64,
      "title": "OpenAI Gym",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv:1606.01540",
      "authors": "G. Brockman et al."
    },
    {
      "index": 65,
      "title": "CARL: A Benchmark for Contextual and Adaptive Reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "NeurIPS 2021 Workshop on Ecological Theory of Reinforcement Learning",
      "authors": "C. Benjamins et al.",
      "orig_title": "CARL: A Benchmark for Contextual and Adaptive Reinforcement Learning",
      "paper_id": "2110.02102v2"
    },
    {
      "index": 66,
      "title": "Dueling Network Architectures for Deep Reinforcement Learning",
      "abstract": "",
      "year": "2016",
      "venue": "33rd ICML",
      "authors": "Z. Wang et al.",
      "orig_title": "Dueling Network Architectures for Deep Reinforcement Learning",
      "paper_id": "1511.06581v3"
    },
    {
      "index": 67,
      "title": "Noisy Networks for Exploration",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "M. Fortunato et al.",
      "orig_title": "Noisy Networks For Exploration",
      "paper_id": "1706.10295v3"
    },
    {
      "index": 68,
      "title": "Exploration by Random Network Distillation",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "Y. Burda et al.",
      "orig_title": "Exploration by random network distillation",
      "paper_id": "1810.12894v1"
    },
    {
      "index": 69,
      "title": "Conceptual representations in mind and brain: Theoretical developments, current evidence and future directions",
      "abstract": "",
      "year": "2012",
      "venue": "Cortex",
      "authors": "M. Kiefer and F. Pulvermüller"
    },
    {
      "index": 70,
      "title": "Learning Independent Causal Mechanisms",
      "abstract": "",
      "year": "2018",
      "venue": "35th ICML",
      "authors": "G. Parascandolo et al.",
      "orig_title": "Learning Independent Causal Mechanisms",
      "paper_id": "1712.00961v5"
    },
    {
      "index": 71,
      "title": "Emergence of Locomotion Behaviours in Rich Environments",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv:1707.02286",
      "authors": "N. Heess et al.",
      "orig_title": "Emergence of locomotion behaviours in rich environments",
      "paper_id": "1707.02286v2"
    },
    {
      "index": 72,
      "title": "Neurogenesis-mediated forgetting minimizes proactive interference",
      "abstract": "",
      "year": "2016",
      "venue": "Nature communications",
      "authors": "J. R. Epp et al."
    },
    {
      "index": 73,
      "title": "Molecular mechanisms of forgetting",
      "abstract": "",
      "year": "2020",
      "venue": "European Journal of Neuroscience",
      "authors": "A. Moreno"
    },
    {
      "index": 74,
      "title": "OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:2010.13611",
      "authors": "A. Ajay et al."
    }
  ]
}