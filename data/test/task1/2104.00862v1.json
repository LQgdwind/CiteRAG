{
  "paper_id": "2104.00862v1",
  "title": "Self-supervised Video Representation Learning by Context and Motion Decoupling",
  "abstract": "Abstract\nA key challenge in self-supervised video representation learning is how to effectively capture motion information besides context bias.\nWhile most existing works implicitly achieve this with video-specific pretext tasks (e.g., predicting clip orders, time arrows, and paces), we develop a method that explicitly decouples motion supervision from context bias through a carefully designed pretext task.\nSpecifically, we take the key frames and motion vectors in compressed videos (e.g., in H.264 format) as the supervision sources for context and motion, respectively, which can be efficiently extracted at over 500 fps on CPU.\nThen we design two pretext tasks that are jointly optimized:\na context matching task where a pairwise contrastive loss is cast between video clip and key frame features;\nand a motion prediction task where clip features, passed through an encoder-decoder network, are used to estimate motion features in a near future.\nThese two tasks use a shared video backbone and separate MLP heads.\nExperiments show that our approach improves the quality of the learned video representation over previous works, where we obtain absolute gains of 16.0%percent16.016.0\\% and 11.1%percent11.111.1\\% in video retrieval recall on UCF101 and HMDB51, respectively.\nMoreover, we find the motion prediction to be a strong regularization for video networks, where using it as an auxiliary task improves the accuracy of action recognition with a margin of 7.4%∼13.8%similar-topercent7.4percent13.87.4\\%\\sim 13.8\\%.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Attention, please: A spatio-temporal transformer for 3d human motion prediction",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Emre Aksan, Peng Cao, Manuel Kaufmann, and Otmar Hilliges"
    },
    {
      "index": 1,
      "title": "Self-Supervised Learning by Cross-Modal Audio-Video Clustering",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Humam Alwassel, Dhruv Mahajan, Lorenzo Torresani, Bernard Ghanem, and Du Tran",
      "orig_title": "Self-supervised learning by cross-modal audio-video clustering",
      "paper_id": "1911.12667v3"
    },
    {
      "index": 2,
      "title": "Self-labelling via simultaneous clustering and representation learning",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Learning Representations (ICLR)",
      "authors": "Yuki M. Asano, Christian Rupprecht, and Andrea Vedaldi",
      "orig_title": "Self-labelling via simultaneous clustering and representation learning",
      "paper_id": "1911.05371v3"
    },
    {
      "index": 3,
      "title": "Delving Deeper into Convolutional Networks for Learning Video Representations",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv",
      "authors": "Nicolas Ballas, Li Yao, Chris Pal, and Aaron Courville",
      "orig_title": "Delving deeper into convolutional networks for learning video representations",
      "paper_id": "1511.06432v4"
    },
    {
      "index": 4,
      "title": "SpeedNet: Learning the Speediness in Videos",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Sagie Benaim, Ariel Ephrat, Oran Lang, Inbar Mosseri, William T Freeman, Michael Rubinstein, Michal Irani, and Tali Dekel",
      "orig_title": "Speednet: Learning the speediness in videos",
      "paper_id": "2004.06130v2"
    },
    {
      "index": 5,
      "title": "High accuracy optical flow estimation based on a theory for warping",
      "abstract": "",
      "year": "2004",
      "venue": "European conference on computer vision",
      "authors": "Thomas Brox, Andrés Bruhn, Nils Papenberg, and Joachim Weickert"
    },
    {
      "index": 6,
      "title": "Improving Spatiotemporal Self-Supervision by Deep Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Uta Buchler, Biagio Brattoli, and Bjorn Ommer",
      "orig_title": "Improving spatiotemporal self-supervision by deep reinforcement learning",
      "paper_id": "1807.11293v1"
    },
    {
      "index": 7,
      "title": "Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and Armand Joulin",
      "orig_title": "Unsupervised learning of visual features by contrasting cluster assignments",
      "paper_id": "2006.09882v5"
    },
    {
      "index": 8,
      "title": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Joao Carreira and Andrew Zisserman",
      "orig_title": "Quo vadis, action recognition? a new model and the kinetics dataset",
      "paper_id": "1705.07750v3"
    },
    {
      "index": 9,
      "title": "A Simple Framework for Contrastive Learning of Visual Representations",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton",
      "orig_title": "A simple framework for contrastive learning of visual representations",
      "paper_id": "2002.05709v3"
    },
    {
      "index": 10,
      "title": "Big Self-Supervised Models are Strong Semi-Supervised Learners",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey Hinton",
      "orig_title": "Big self-supervised models are strong semi-supervised learners",
      "paper_id": "2006.10029v2"
    },
    {
      "index": 11,
      "title": "Improved Baselines with Momentum Contrastive Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He",
      "orig_title": "Improved baselines with momentum contrastive learning",
      "paper_id": "2003.04297v1"
    },
    {
      "index": 12,
      "title": "TPNet: Trajectory Proposal Network for Motion Prediction",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Liangji Fang, Qinhong Jiang, Jianping Shi, and Bolei Zhou",
      "orig_title": "Tpnet: Trajectory proposal network for motion prediction",
      "paper_id": "2004.12255v2"
    },
    {
      "index": 13,
      "title": "Recurrent Network Models for Human Dynamics",
      "abstract": "",
      "year": "2015",
      "venue": "ICCV",
      "authors": "Katerina Fragkiadaki, Sergey Levine, Panna Felsen, and Jitendra Malik",
      "orig_title": "Recurrent network models for human dynamics",
      "paper_id": "1508.00271v2"
    },
    {
      "index": 14,
      "title": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv",
      "authors": "Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He",
      "orig_title": "Accurate, large minibatch sgd: Training imagenet in 1 hour",
      "paper_id": "1706.02677v2"
    },
    {
      "index": 15,
      "title": "Noise-contrastive estimation: A new estimation principle for unnormalized statistical models",
      "abstract": "",
      "year": "2010",
      "venue": "Thirteenth International Conference on Artificial Intelligence and Statistics",
      "authors": "Michael Gutmann and Aapo Hyvärinen"
    },
    {
      "index": 16,
      "title": "Video Representation Learning by Dense Predictive Coding",
      "abstract": "",
      "year": "2019",
      "venue": "Workshop on Large Scale Holistic Video Understanding, ICCV",
      "authors": "Tengda Han, Weidi Xie, and Andrew Zisserman",
      "orig_title": "Video representation learning by dense predictive coding",
      "paper_id": "1909.04656v3"
    },
    {
      "index": 17,
      "title": "Memory-augmented Dense Predictive Coding for Video Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Tengda Han, Weidi Xie, and Andrew Zisserman",
      "orig_title": "Memory-augmented dense predictive coding for video representation learning",
      "paper_id": "2008.01065v1"
    },
    {
      "index": 18,
      "title": "Momentum Contrast for Unsupervised Visual Representation Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick",
      "orig_title": "Momentum contrast for unsupervised visual representation learning",
      "paper_id": "1911.05722v3"
    },
    {
      "index": 19,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 20,
      "title": "Self-Supervised Spatiotemporal Feature Learning via Video Rotation Prediction",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv",
      "authors": "Longlong Jing, Xiaodong Yang, Jingen Liu, and Yingli Tian",
      "orig_title": "Self-supervised spatiotemporal feature learning via video rotation prediction",
      "paper_id": "1811.11387v2"
    },
    {
      "index": 21,
      "title": "Self-Supervised Video Representation Learning with Space-Time Cubic Puzzles",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Dahun Kim, Donghyeon Cho, and In So Kweon",
      "orig_title": "Self-supervised video representation learning with space-time cubic puzzles",
      "paper_id": "1811.09795v1"
    },
    {
      "index": 22,
      "title": "Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Bruno Korbar, Du Tran, and Lorenzo Torresani",
      "orig_title": "Cooperative learning of audio and video models from self-supervised synchronization",
      "paper_id": "1807.00230v2"
    },
    {
      "index": 23,
      "title": "Hmdb: a large video database for human motion recognition",
      "abstract": "",
      "year": "2011",
      "venue": "ICCV",
      "authors": "Hildegard Kuehne, Hueihan Jhuang, Estíbaliz Garrote, Tomaso Poggio, and Thomas Serre"
    },
    {
      "index": 24,
      "title": "Mpeg: A video compression standard for multimedia applications",
      "abstract": "",
      "year": "1991",
      "venue": "Communications of the ACM",
      "authors": "Didier Le Gall"
    },
    {
      "index": 25,
      "title": "Convolution neural network-based lane change intention prediction of surrounding vehicles for acc",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)",
      "authors": "Donghan Lee, Youngwook Paul Kwon, Sara McMains, and J Karl Hedrick"
    },
    {
      "index": 26,
      "title": "Unsupervised Representation Learning by Sorting Sequences",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Hsin-Ying Lee, Jia-Bin Huang, Maneesh Singh, and Ming-Hsuan Yang",
      "orig_title": "Unsupervised representation learning by sorting sequences",
      "paper_id": "1708.01246v1"
    },
    {
      "index": 27,
      "title": "Resound: Towards action recognition without representation bias",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Yingwei Li, Yi Li, and Nuno Vasconcelos"
    },
    {
      "index": 28,
      "title": "Video Cloze Procedure for Self-Supervised Spatio-Temporal Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Dezhao Luo, Chang Liu, Yu Zhou, Dongbao Yang, Can Ma, Qixiang Ye, and Weiping Wang",
      "orig_title": "Video cloze procedure for self-supervised spatio-temporal learning",
      "paper_id": "2001.00294v1"
    },
    {
      "index": 29,
      "title": "Learning Trajectory Dependencies for Human Motion Prediction",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Wei Mao, Miaomiao Liu, Mathieu Salzmann, and Hongdong Li",
      "orig_title": "Learning trajectory dependencies for human motion prediction",
      "paper_id": "1908.05436v3"
    },
    {
      "index": 30,
      "title": "On human motion prediction using recurrent neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Julieta Martinez, Michael J Black, and Javier Romero"
    },
    {
      "index": 31,
      "title": "End-to-End Learning of Visual Representations from Uncurated Instructional Videos",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Antoine Miech, Jean-Baptiste Alayrac, Lucas Smaira, Ivan Laptev, Josef Sivic, and Andrew Zisserman",
      "orig_title": "End-to-end learning of visual representations from uncurated instructional videos",
      "paper_id": "1912.06430v4"
    },
    {
      "index": 32,
      "title": "Shuffle and Learn: Unsupervised Learning using Temporal Order Verification",
      "abstract": "",
      "year": "2016",
      "venue": "European Conference on Computer Vision",
      "authors": "Ishan Misra, C Lawrence Zitnick, and Martial Hebert",
      "orig_title": "Shuffle and learn: unsupervised learning using temporal order verification",
      "paper_id": "1603.08561v2"
    },
    {
      "index": 33,
      "title": "Unsupervised learning of visual representations by solving jigsaw puzzles",
      "abstract": "",
      "year": "2016",
      "venue": "European Conference on Computer Vision",
      "authors": "Mehdi Noroozi and Paolo Favaro"
    },
    {
      "index": 34,
      "title": "Representation Learning with Contrastive Predictive Coding",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv",
      "authors": "Aaron van den Oord, Yazhe Li, and Oriol Vinyals",
      "orig_title": "Representation learning with contrastive predictive coding",
      "paper_id": "1807.03748v2"
    },
    {
      "index": 35,
      "title": "Multi-modal self-supervision from generalized data transformations",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Mandela Patrick, Yuki M Asano, Ruth Fong, João F Henriques, Geoffrey Zweig, and Andrea Vedaldi"
    },
    {
      "index": 36,
      "title": "Evolving Losses for Unsupervised Video Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "AJ Piergiovanni, Anelia Angelova, and Michael S Ryoo",
      "orig_title": "Evolving losses for unsupervised video representation learning",
      "paper_id": "2002.12177v1"
    },
    {
      "index": 37,
      "title": "Spatiotemporal Contrastive Video Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Rui Qian, Tianjian Meng, Boqing Gong, Ming-Hsuan Yang, Huisheng Wang, Serge Belongie, and Yin Cui",
      "orig_title": "Spatiotemporal contrastive video representation learning",
      "paper_id": "2008.03800v4"
    },
    {
      "index": 38,
      "title": "DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Zheng Shou, Xudong Lin, Yannis Kalantidis, Laura Sevilla-Lara, Marcus Rohrbach, Shih-Fu Chang, and Zhicheng Yan",
      "orig_title": "Dmc-net: Generating discriminative motion cues for fast compressed video action recognition",
      "paper_id": "1901.03460v3"
    },
    {
      "index": 39,
      "title": "Two-Stream Convolutional Networks for Action Recognition in Videos",
      "abstract": "",
      "year": "2014",
      "venue": "Advances in neural information processing systems",
      "authors": "Karen Simonyan and Andrew Zisserman",
      "orig_title": "Two-stream convolutional networks for action recognition in videos",
      "paper_id": "1406.2199v2"
    },
    {
      "index": 40,
      "title": "Ucf101: A dataset of 101 human actions classes from videos in the wild",
      "abstract": "",
      "year": "2012",
      "venue": "arXiv",
      "authors": "Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah"
    },
    {
      "index": 41,
      "title": "Learning Video Representations using Contrastive Bidirectional Transformer",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Chen Sun, Fabien Baradel, Kevin Murphy, and Cordelia Schmid",
      "orig_title": "Learning video representations using contrastive bidirectional transformer",
      "paper_id": "1906.05743v2"
    },
    {
      "index": 42,
      "title": "VideoBERT: A Joint Model for Video and Language Representation Learning",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid",
      "orig_title": "Videobert: A joint model for video and language representation learning",
      "paper_id": "1904.01766v2"
    },
    {
      "index": 43,
      "title": "Learning spatiotemporal features with 3d convolutional networks",
      "abstract": "",
      "year": "2015",
      "venue": "ICCV",
      "authors": "Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, and Manohar Paluri"
    },
    {
      "index": 44,
      "title": "A closer look at spatiotemporal convolutions for action recognition",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Du Tran, Heng Wang, Lorenzo Torresani, Jamie Ray, Yann LeCun, and Manohar Paluri"
    },
    {
      "index": 45,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 46,
      "title": "Action Recognition by Dense Trajectories",
      "abstract": "",
      "year": "2011",
      "venue": "IEEE Conference on Computer Vision & Pattern Recognition",
      "authors": "Heng Wang, Alexander Kläser, Cordelia Schmid, and Cheng-Lin Liu"
    },
    {
      "index": 47,
      "title": "Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Jinpeng Wang, Yuting Gao, Ke Li, Xinyang Jiang, Xiaowei Guo, Rongrong Ji, and Xing Sun",
      "orig_title": "Enhancing unsupervised video representation learning by decoupling the scene and the motion",
      "paper_id": "2009.05757v3"
    },
    {
      "index": 48,
      "title": "Self-supervised Video Representation Learning by Pace Prediction",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Jiangliu Wang, Jianbo Jiao, and Yun-Hui Liu",
      "orig_title": "Self-supervised video representation learning by pace prediction",
      "paper_id": "2008.05861v2"
    },
    {
      "index": 49,
      "title": "Self-supervised Temporal Discriminative Learning for Video Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Jinpeng Wang, Yiqi Lin, Andy J Ma, and Pong C Yuen",
      "orig_title": "Self-supervised temporal discriminative learning for video representation learning",
      "paper_id": "2008.02129v1"
    },
    {
      "index": 50,
      "title": "Fast Object Detection in Compressed Video",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Shiyao Wang, Hongchao Lu, and Zhidong Deng",
      "orig_title": "Fast object detection in compressed video",
      "paper_id": "1811.11057v3"
    },
    {
      "index": 51,
      "title": "Compressed video action recognition",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Chao-Yuan Wu, Manzil Zaheer, Hexiang Hu, R Manmatha, Alexander J Smola, and Philipp Krähenbühl"
    },
    {
      "index": 52,
      "title": "Audiovisual SlowFast Networks for Video Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Fanyi Xiao, Yong Jae Lee, Kristen Grauman, Jitendra Malik, and Christoph Feichtenhofer",
      "orig_title": "Audiovisual slowfast networks for video recognition",
      "paper_id": "2001.08740v2"
    },
    {
      "index": 53,
      "title": "Self-supervised spatiotemporal learning via video clip order prediction",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Dejing Xu, Jun Xiao, Zhou Zhao, Jian Shao, Di Xie, and Yueting Zhuang"
    },
    {
      "index": 54,
      "title": "Future Person Localization in First-Person Videos",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Takuma Yagi, Karttikeya Mangalam, Ryo Yonetani, and Yoichi Sato",
      "orig_title": "Future person localization in first-person videos",
      "paper_id": "1711.11217v2"
    },
    {
      "index": 55,
      "title": "Video Representation Learning with Visual Tempo Consistency",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Ceyuan Yang, Yinghao Xu, Bo Dai, and Bolei Zhou",
      "orig_title": "Video representation learning with visual tempo consistency",
      "paper_id": "2006.15489v2"
    },
    {
      "index": 56,
      "title": "Video Playback Rate Perception for Self-supervised Spatio-Temporal Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Yuan Yao, Chang Liu, Dezhao Luo, Yu Zhou, and Qixiang Ye",
      "orig_title": "Video playback rate perception for self-supervised spatio-temporal representation learning",
      "paper_id": "2006.11476v1"
    },
    {
      "index": 57,
      "title": "Spatio-Temporal Graph Transformer Networks for Pedestrian Trajectory Prediction",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Cunjun Yu, Xiao Ma, Jiawei Ren, Haiyu Zhao, and Shuai Yi",
      "orig_title": "Spatio-temporal graph transformer networks for pedestrian trajectory prediction",
      "paper_id": "2005.08514v2"
    },
    {
      "index": 58,
      "title": "A duality based approach for realtime tv-l 1 optical flow",
      "abstract": "",
      "year": "2007",
      "venue": "Joint pattern recognition symposium",
      "authors": "Christopher Zach, Thomas Pock, and Horst Bischof"
    },
    {
      "index": 59,
      "title": "Real-time Action Recognition with Enhanced Motion Vector CNNs",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Bowen Zhang, Limin Wang, Zhe Wang, Yu Qiao, and Hanli Wang",
      "orig_title": "Real-time action recognition with enhanced motion vector cnns",
      "paper_id": "1604.07669v1"
    },
    {
      "index": 60,
      "title": "Real-time action recognition with deeply transferred motion vector cnns",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Transactions on Image Processing",
      "authors": "Bowen Zhang, Limin Wang, Zhe Wang, Yu Qiao, and Hanli Wang"
    }
  ]
}