{
  "paper_id": "2110.07058v3",
  "title": "Ego4D: Around the World in 3,000 Hours of Egocentric Video",
  "abstract": "Abstract\nWe introduce Ego4D, a massive-scale egocentric video dataset and benchmark suite.\nIt offers 3,670 hours of\ndaily-life activity video spanning hundreds of scenarios (household, outdoor, workplace, leisure, etc.) captured by 931 unique camera wearers from 74 worldwide locations and 9 different countries. The approach to collection is designed to uphold rigorous privacy and ethics standards, with consenting participants and robust de-identification procedures where relevant.\nEgo4D dramatically expands the volume of diverse egocentric video footage publicly available to the research community. Portions of the video are accompanied by audio, 3D meshes of the environment, eye gaze,\nstereo, and/or synchronized videos from multiple egocentric cameras at the same event.\nFurthermore, we present a host of new benchmark challenges centered around understanding the first-person visual experience in the past (querying an episodic memory), present (analyzing hand-object manipulation, audio-visual conversation, and social interactions), and future (forecasting activities).\nBy publicly sharing this massive annotated dataset and benchmark suite, we aim to push the frontier of first-person perception. \nProject page: https://ego4d-data.org/",
  "reference_labels": [
    {
      "index": 0,
      "title": "Github repository of the ESPNet model zoo.",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 1,
      "title": "Kaldi English GLM file.",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 2,
      "title": "NIST SRE 2000 Evaluation Plan.",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 3,
      "title": "When will you do what? - Anticipating Temporal Occurrences of Activities",
      "abstract": "",
      "year": "2018",
      "venue": "Computer Vision and Pattern Recognition",
      "authors": "Yazan Abu Farha, Alexander Richard, and Juergen Gall",
      "orig_title": "When will you do what?-anticipating temporal occurrences of activities.",
      "paper_id": "1804.00892v1"
    },
    {
      "index": 4,
      "title": "Deep Audio-Visual Speech Recognition",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE transactions on pattern analysis and machine intelligence",
      "authors": "Triantafyllos Afouras, Joon Son Chung, Andrew Senior, Oriol Vinyals, and Andrew Zisserman",
      "orig_title": "Deep audio-visual speech recognition.",
      "paper_id": "1809.02108v2"
    },
    {
      "index": 5,
      "title": "The Conversation: Deep Audio-Visual Speech Enhancement",
      "abstract": "",
      "year": "2018",
      "venue": "Interspeech",
      "authors": "Triantafyllos Afouras, Joon Son Chung, and Andrew Zisserman",
      "orig_title": "The conversation: Deep audio-visual speech enhancement.",
      "paper_id": "1804.04121v2"
    },
    {
      "index": 6,
      "title": "Self-Supervised Learning of Audio-Visual Objects from Video",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Triantafyllos Afouras, Andrew Owens, Joon Son Chung, and Andrew Zisserman",
      "orig_title": "Self-supervised Learning of Audio-Visual Objects from Video.",
      "paper_id": "2008.04237v1"
    },
    {
      "index": 7,
      "title": "Joint Discovery of Object States and Manipulation Actions",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Jean-Baptiste Alayrac, Josef Sivic, Ivan Laptev, and Simon Lacoste-Julien",
      "orig_title": "Joint discovery of object states and manipulation actions.",
      "paper_id": "1702.02738v3"
    },
    {
      "index": 8,
      "title": "Diagnosing Error in Temporal Action Detectors",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision",
      "authors": "Humam Alwassel, Fabian Caba Heilbron, Victor Escorcia, and Bernard Ghanem",
      "orig_title": "Diagnosing error in temporal action detectors.",
      "paper_id": "1807.10706v1"
    },
    {
      "index": 9,
      "title": "Speaker diarization: A review of recent research.",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE Transactions on audio, speech, and language processing",
      "authors": "Xavier Anguera, Simon Bozonnet, Nicholas Evans, Corinne Fredouille, Gerald Friedland, and Oriol Vinyals"
    },
    {
      "index": 10,
      "title": "Robust speaker diarization for meetings.",
      "abstract": "",
      "year": "2006",
      "venue": "Universitat Politècnica de Catalunya",
      "authors": "Xavier Anguera Miró"
    },
    {
      "index": 11,
      "title": "VQA: Visual Question Answering.",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Computer Vision",
      "authors": "Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi Parikh"
    },
    {
      "index": 12,
      "title": "Multi-modal egocentric activity recognition using audio-visual features.",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1807.00612",
      "authors": "Mehmet Ali Arabacı, Fatih Özkan, Elif Surer, Peter Jančovič, and Alptekin Temizel"
    },
    {
      "index": 13,
      "title": "Objects that Sound",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Relja Arandjelović and Andrew Zisserman",
      "orig_title": "Objects that sound.",
      "paper_id": "1712.06651v2"
    },
    {
      "index": 14,
      "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2006.11477",
      "authors": "Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, and Michael Auli",
      "orig_title": "wav2vec 2.0: A framework for self-supervised learning of speech representations.",
      "paper_id": "2006.11477v3"
    },
    {
      "index": 15,
      "title": "Lending a hand: Detecting hands and recognizing activities in complex egocentric interactions.",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE International Conference on Computer Vision",
      "authors": "Sven Bambach, Stefan Lee, David J. Crandall, and Chen Yu"
    },
    {
      "index": 16,
      "title": "The cocktail party problem: what is it? how can it be solved? and why should animal behaviorists study it?",
      "abstract": "",
      "year": "2008",
      "venue": "Journal of comparative psychology",
      "authors": "Mark A Bee and Christophe Micheyl"
    },
    {
      "index": 17,
      "title": "Multiple object tracking performance metrics and evaluation in a smart room environment.",
      "abstract": "",
      "year": "2006",
      "venue": "Sixth IEEE International Workshop on Visual Surveillance, in conjunction with ECCV",
      "authors": "Keni Bernardin, Alexander Elbs, and Rainer Stiefelhagen"
    },
    {
      "index": 18,
      "title": "Evaluating multiple object tracking performance: the clear mot metrics.",
      "abstract": "",
      "year": "2008",
      "venue": "EURASIP Journal on Image and Video Processing",
      "authors": "Keni Bernardin and Rainer Stiefelhagen"
    },
    {
      "index": 19,
      "title": "First-Person Action-Object Detection with EgoNet",
      "abstract": "",
      "year": "2017",
      "venue": "Robotics: Science and Systems",
      "authors": "Gedas Bertasius, Hyun Soo Park, Stella X. Yu, and Jianbo Shi",
      "orig_title": "First-person action-object detection with egonet.",
      "paper_id": "1603.04908v3"
    },
    {
      "index": 20,
      "title": "Prediction of the leadership style of an emergent leader using audio and visual nonverbal features.",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Transactions on Multimedia",
      "authors": "Cigdem Beyan, Francesca Capozzi, Cristina Becchio, and Vittorio Murino"
    },
    {
      "index": 21,
      "title": "Know Your Surroundings: Exploiting Scene Information for Object Tracking.",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:2003.11014 [cs]",
      "authors": "Goutam Bhat, Martin Danelljan, Luc Van Gool, and Radu Timofte"
    },
    {
      "index": 22,
      "title": "Learning 6d object pose estimation using 3d object coordinates.",
      "abstract": "",
      "year": "2014",
      "venue": "European conference on computer vision",
      "authors": "Eric Brachmann, Alexander Krull, Frank Michel, Stefan Gumhold, Jamie Shotton, and Carsten Rother"
    },
    {
      "index": 23,
      "title": "Language Models are Few-Shot Learners",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei",
      "orig_title": "Language models are few-shot learners",
      "paper_id": "2005.14165v4"
    },
    {
      "index": 24,
      "title": "The yale human grasping dataset: Grasp, object, and task data in household and machine shop environments.",
      "abstract": "",
      "year": "2015",
      "venue": "IJRR",
      "authors": "Ian M Bullock, Thomas Feix, and Aaron M Dollar"
    },
    {
      "index": 25,
      "title": "Understanding hand-object manipulation with grasp types and object attributes.",
      "abstract": "",
      "year": "2016",
      "venue": "RSS",
      "authors": "Minjie Cai, Kris M Kitani, and Yoichi Sato"
    },
    {
      "index": 26,
      "title": "End-to-end object detection with transformers.",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko"
    },
    {
      "index": 27,
      "title": "The AMI meeting corpus: A pre-announcement.",
      "abstract": "",
      "year": "2006",
      "venue": "International workshop on machine learning for multimodal interaction",
      "authors": "Jean Carletta, Simone Ashby, Sebastien Bourban, Mike Flynn, Mael Guillemot, Thomas Hain, Jaroslav Kadlec, Vasilis Karaiskos, Wessel Kraaij, Melissa Kronenthal, et al."
    },
    {
      "index": 28,
      "title": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Joao Carreira and Andrew Zisserman",
      "orig_title": "Quo vadis, action recognition? a new model and the kinetics dataset.",
      "paper_id": "1705.07750v3"
    },
    {
      "index": 29,
      "title": "Procedure Planning in Instructional Videos",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1907.01172",
      "authors": "Chien-Yi Chang, De-An Huang, Danfei Xu, Ehsan Adeli, Li Fei-Fei, and Juan Carlos Niebles",
      "orig_title": "Procedure planning in instructional videos.",
      "paper_id": "1907.01172v3"
    },
    {
      "index": 30,
      "title": "AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1808.00606",
      "authors": "Sourish Chaudhuri, Joseph Roth, Daniel PW Ellis, Andrew Gallagher, Liat Kaver, Radhika Marvin, Caroline Pantofaru, Nathan Reale, Loretta Guarino Reid, Kevin Wilson, et al.",
      "orig_title": "Ava-speech: A densely labeled dataset of speech activity in movies.",
      "paper_id": "1808.00606v2"
    },
    {
      "index": 31,
      "title": "SoundSpaces: Audio-Visual Navigation in 3D Environments",
      "abstract": "",
      "year": "2020",
      "venue": "ECCV",
      "authors": "C. Chen, U. Jain, C. Schissler, S. V. Amengual Gari, Z. Al-Halah, V. Ithapu, P. Robinson, and K. Grauman",
      "orig_title": "Soundspaces: Audio-visual navigation in 3d environments.",
      "paper_id": "1912.11474v3"
    },
    {
      "index": 32,
      "title": "Audio-visual embodied navigation.",
      "abstract": "",
      "year": "2019",
      "venue": "environment",
      "authors": "Changan Chen, Unnat Jain, Carl Schissler, Sebastia Vicenc Amengual Gari, Ziad Al-Halah, Vamsi Krishna Ithapu, Philip Robinson, and Kristen Grauman"
    },
    {
      "index": 33,
      "title": "GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2106.06909",
      "authors": "Guoguo Chen, Shuzhou Chai, Guanbo Wang, Jiayu Du, Wei-Qiang Zhang, Chao Weng, Dan Su, Daniel Povey, Jan Trmal, Junbo Zhang, et al.",
      "orig_title": "Gigaspeech: An evolving, multi-domain asr corpus with 10,000 hours of transcribed audio.",
      "paper_id": "2106.06909v1"
    },
    {
      "index": 34,
      "title": "Microsoft coco captions: Data collection and evaluation server.",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:1504.00325",
      "authors": "Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr Dollár, and C Lawrence Zitnick"
    },
    {
      "index": 35,
      "title": "Detection of eye contact with deep neural networks is as accurate as human experts.",
      "abstract": "",
      "year": "2020",
      "venue": "Nature Communications",
      "authors": "Eunji Chong, Elysha Clark-Whitney, Audrey Southerland, Elizabeth Stubbs, Chanel Miller, Eliana L Ajodan, Melanie R Silverman, Catherine Lord, Agata Rozga, Rebecca M Jones, and James M Rehg"
    },
    {
      "index": 36,
      "title": "Detecting Attended Visual Targets in Video",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Eunji Chong, Yongxin Wang, Nataniel Ruiz, and James M. Rehg",
      "orig_title": "Detecting Attended Visual Targets in Video.",
      "paper_id": "2003.02501v2"
    },
    {
      "index": 37,
      "title": "In defence of metric learning for speaker recognition",
      "abstract": "",
      "year": "2020",
      "venue": "Interspeech",
      "authors": "Joon Son Chung, Jaesung Huh, Seongkyu Mun, Minjae Lee, Hee Soo Heo, Soyeon Choe, Chiheon Ham, Sunghwan Jung, Bong-Jin Lee, and Icksang Han",
      "orig_title": "In defence of metric learning for speaker recognition.",
      "paper_id": "2003.11982v2"
    },
    {
      "index": 38,
      "title": "Spot the conversation: speaker diarisation in the wild",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2007.01216",
      "authors": "Joon Son Chung, Jaesung Huh, Arsha Nagrani, Triantafyllos Afouras, and Andrew Zisserman",
      "orig_title": "Spot the conversation: speaker diarisation in the wild.",
      "paper_id": "2007.01216v3"
    },
    {
      "index": 39,
      "title": "VoxCeleb2: Deep Speaker Recognition",
      "abstract": "",
      "year": "2018",
      "venue": "INTERSPEECH",
      "authors": "J. S. Chung, A. Nagrani, and A. Zisserman",
      "orig_title": "VoxCeleb2: Deep Speaker Recognition.",
      "paper_id": "1806.05622v2"
    },
    {
      "index": 40,
      "title": "Word association norms, mutual information, and lexicography.",
      "abstract": "",
      "year": "1990",
      "venue": "Computational linguistics",
      "authors": "Kenneth Church and Patrick Hanks"
    },
    {
      "index": 41,
      "title": "The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Pattern Analysis & Machine Intelligence",
      "authors": "Dima Damen, Hazel Doughty, Giovanni Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, et al.",
      "orig_title": "The epic-kitchens dataset: Collection, challenges and baselines.",
      "paper_id": "2005.00343v1"
    },
    {
      "index": 42,
      "title": "Rescaling egocentric vision.",
      "abstract": "",
      "year": "2021",
      "venue": "IJCV",
      "authors": "Dima Damen, Hazel Doughty, Giovanni Maria Farinella, , Antonino Furnari, Jian Ma, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, and Michael Wray"
    },
    {
      "index": 43,
      "title": "Scaling egocentric vision: The epic-kitchens dataset.",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision",
      "authors": "Dima Damen, Hazel Doughty, Giovanni Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, and Michael Wray"
    },
    {
      "index": 44,
      "title": "You-Do, I-Learn: Discovering task relevant objects and their modes of interaction from multi-user egocentric video.",
      "abstract": "",
      "year": "2014",
      "venue": "BMVC",
      "authors": "Dima Damen, Teesid Leelasawassuk, Osian Haines, Andrew Calway, and Walterio Mayol-Cuevas"
    },
    {
      "index": 45,
      "title": "You-do, i-learn: Egocentric unsupervised discovery of objects and their modes of interaction towards video-based guidance.",
      "abstract": "",
      "year": "2016",
      "venue": "CVIU",
      "authors": "Dima Damen, Teesid Leelasawassuk, and Walterio Mayol-Cuevas"
    },
    {
      "index": 46,
      "title": "A technique for computer detection and correction of spelling errors.",
      "abstract": "",
      "year": "1964",
      "venue": "Communications of the ACM",
      "authors": "Fred J Damerau"
    },
    {
      "index": 47,
      "title": "Summarization of egocentric videos: A comprehensive survey.",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Transactions on Human-Machine Systems",
      "authors": "Ana Garcia Del Molino, Cheston Tan, Joo-Hwee Lim, and Ah-Hwee Tan"
    },
    {
      "index": 48,
      "title": "ImageNet: A large-scale hierarchical image database.",
      "abstract": "",
      "year": "2009",
      "venue": "CVPR",
      "authors": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei"
    },
    {
      "index": 49,
      "title": "SuperPoint: Self-Supervised Interest Point Detection and Description",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR Workshop",
      "authors": "Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich",
      "orig_title": "Superpoint: Self-supervised interest point detection and description.",
      "paper_id": "1712.07629v4"
    },
    {
      "index": 50,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:1810.04805",
      "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova",
      "orig_title": "Bert: Pre-training of deep bidirectional transformers for language understanding.",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 51,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the 2019 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers), pages 4171–4186,\nMinneapolis, Minnesota, June",
      "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.",
      "orig_title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 52,
      "title": "EasyCom: An Augmented Reality Dataset to Support Algorithms for Easy Communication in Noisy Environments",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:",
      "authors": "Jacob Donley, Vladimir Tourbabin, Jung-Suk Lee, Mark Broyles, Hao Jiang, Jie\nShen, Maja Pantic, Vamsi Krishna Ithapu, and Ravish Mehra.",
      "orig_title": "Easycom: An augmented reality dataset to support algorithms for easy communication in noisy environments",
      "paper_id": "2107.04174v2"
    },
    {
      "index": 53,
      "title": "Boosting Image-based Mutual Gaze Detection using Pseudo 3D Gaze",
      "abstract": "",
      "year": "2021",
      "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence",
      "authors": "Bardia Doosti, Ching-Hui Chen, Raviteja Vemulapalli, Xuhui Jia, Yukun Zhu,\nand Bradley Green.",
      "orig_title": "Boosting image-based mutual gaze detection using pseudo 3d gaze",
      "paper_id": "2010.07811v2"
    },
    {
      "index": 54,
      "title": "Action Modifiers: Learning from Adverbs in Instructional Videos",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:",
      "authors": "Hazel Doughty, Ivan Laptev, Walterio Mayol-Cuevas, and Dima Damen.",
      "orig_title": "Action modifiers: Learning from adverbs in instructional videos",
      "paper_id": "1912.06617v3"
    },
    {
      "index": 55,
      "title": "Is First Person Vision Challenging for Object Tracking?",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF International Conference on Computer Vision\nWorkshops (ICCVW) - Visual Object Tracking Challenge",
      "authors": "Matteo Dunnhofer, Antonino Furnari, Giovanni Maria Farinella, and Christian\nMicheloni.",
      "orig_title": "Is first person vision challenging for object tracking?",
      "paper_id": "2108.13665v1"
    },
    {
      "index": 56,
      "title": "Looking to Listen at the Cocktail Party: A Speaker-Independent Audio-Visual Model for Speech Separation",
      "abstract": "",
      "year": "2018",
      "venue": "SIGGRAPH",
      "authors": "Ariel Ephrat, Inbar Mosseri, Oran Lang, Tali Dekel, Kevin Wilson, Avinatan\nHassidim, William T Freeman, and Michael Rubinstein.",
      "orig_title": "Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation",
      "paper_id": "1804.03619v2"
    },
    {
      "index": 57,
      "title": "Oops! predicting unintentional action in video",
      "abstract": "",
      "year": "2019",
      "venue": "Arxiv",
      "authors": "Dave Epstein, Boyuan Chen, and Carl Vondrick."
    },
    {
      "index": 58,
      "title": "The Second DIHARD Diarization Challenge: Dataset, task, and baselines",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of Interspeech",
      "authors": "N. Ryant et. al.",
      "orig_title": "The Second DIHARD Diarization Challenge: Dataset, task, and baselines",
      "paper_id": "1906.07839v1"
    },
    {
      "index": 59,
      "title": "The pascal visual object classes (voc) challenge",
      "abstract": "",
      "year": "2010",
      "venue": "International journal of computer vision, 88(2):303–338",
      "authors": "Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew\nZisserman."
    },
    {
      "index": 60,
      "title": "Activitynet: A large-scale video benchmark for human activity understanding",
      "abstract": "",
      "year": "2015",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition",
      "authors": "Bernard Ghanem Fabian Caba Heilbron, Victor Escorcia and Juan Carlos Niebles."
    },
    {
      "index": 61,
      "title": "LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking",
      "abstract": "",
      "year": "2019",
      "venue": "2019 IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pages 5369–5378, Long Beach, CA, USA,\nJune",
      "authors": "Heng Fan, Haibin Ling, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin\nBai, Yong Xu, and Chunyuan Liao.",
      "orig_title": "LaSOT: A High-Quality Benchmark for Large-Scale Single Object Tracking",
      "paper_id": "1809.07845v2"
    },
    {
      "index": 62,
      "title": "Multiscale vision transformers",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:",
      "authors": "Haoqi Fan, Bo Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra\nMalik, and Christoph Feichtenhofer."
    },
    {
      "index": 63,
      "title": "CN-Celeb: a challenging Chinese speaker recognition dataset",
      "abstract": "",
      "year": "2020",
      "venue": "ICASSP 2020-2020 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP)",
      "authors": "Yue Fan, JW Kang, LT Li, KC Li, HL Chen, ST Cheng, PY Zhang, ZY Zhou, YQ Cai,\nand Dong Wang.",
      "orig_title": "CN-CELEB: a challenging Chinese speaker recognition dataset",
      "paper_id": "1911.01799v1"
    },
    {
      "index": 64,
      "title": "Dual Attention Guided Gaze Target Detection in the Wild",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition (CVPR 21)",
      "authors": "Yi Fang, Jiapeng Tang, Wang Shen, Wei Shen, Xiao Gu, Li Song, and Guangtao\nZhai."
    },
    {
      "index": 65,
      "title": "Social interactions: A first-person perspective",
      "abstract": "",
      "year": "2012",
      "venue": "CVPR",
      "authors": "Alireza Fathi, Jessica K. Hodgins, and James M. Rehg."
    },
    {
      "index": 66,
      "title": "Social interactions: A first-person perspective",
      "abstract": "",
      "year": "2012",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition (CVPR 12)",
      "authors": "A. Fathi, J. K. Hodgins, and J. M. Rehg."
    },
    {
      "index": 67,
      "title": "Modeling actions through state changes",
      "abstract": "",
      "year": "2013",
      "venue": "CVPR",
      "authors": "A. Fathi and J. Rehg."
    },
    {
      "index": 68,
      "title": "Modeling actions through state changes",
      "abstract": "",
      "year": "2013",
      "venue": "CVPR",
      "authors": "Alireza Fathi and James M Rehg."
    },
    {
      "index": 69,
      "title": "SlowFast Networks for Video Recognition",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.",
      "orig_title": "Slowfast networks for video recognition",
      "paper_id": "1812.03982v3"
    },
    {
      "index": 70,
      "title": "SlowFast Networks for Video Recognition",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the IEEE/CVF international conference on\ncomputer vision",
      "authors": "Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.",
      "orig_title": "Slowfast networks for video recognition",
      "paper_id": "1812.03982v3"
    },
    {
      "index": 71,
      "title": "NIST sclite sscoring toolkit",
      "abstract": "",
      "year": "",
      "venue": "https://github.com/usnistgov/SCTK",
      "authors": "Jonathan Fiscus."
    },
    {
      "index": 72,
      "title": "Datasets for face and object detection in fisheye images",
      "abstract": "",
      "year": "2019",
      "venue": "Data in brief, 27:",
      "authors": "Jianglin Fu, Ivan V Bajić, and Rodney G Vaughan."
    },
    {
      "index": 73,
      "title": "Next-Active-Object prediction from Egocentric Videos",
      "abstract": "",
      "year": "2017",
      "venue": "Journal of Visual Communication and Image Representation,\n49:401–411",
      "authors": "Antonino Furnari, Sebastiano Battiato, Kristen Grauman, and Giovanni Maria\nFarinella.",
      "orig_title": "Next-active-object prediction from egocentric videos",
      "paper_id": "1904.05250v1"
    },
    {
      "index": 74,
      "title": "Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Antonino Furnari and Giovanni Farinella.",
      "orig_title": "Rolling-unrolling lstms for action anticipation from first-person video",
      "paper_id": "2005.02190v2"
    },
    {
      "index": 75,
      "title": "What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Computer Vision",
      "authors": "Antonino Furnari and Giovanni Maria Farinella.",
      "orig_title": "What would you expect? anticipating egocentric actions with rolling-unrolling lstms and modality attention",
      "paper_id": "1905.09035v2"
    },
    {
      "index": 76,
      "title": "RED: Reinforced Encoder-Decoder Networks for Action Anticipation",
      "abstract": "",
      "year": "2017",
      "venue": "BMVC",
      "authors": "Jiyang Gao, Zhenheng Yang, and Ram Nevatia.",
      "orig_title": "Red: Reinforced encoder-decoder networks for action anticipation",
      "paper_id": "1707.04818v1"
    },
    {
      "index": 77,
      "title": "Learning to Separate Object Sounds by Watching Unlabeled Video",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "R. Gao, R. Feris, and K. Grauman.",
      "orig_title": "Learning to separate object sounds by watching unlabeled video",
      "paper_id": "1804.01665v2"
    },
    {
      "index": 78,
      "title": "Learning to Separate Object Sounds by Watching Unlabeled Video",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Ruohan Gao, Rogerio Feris, and Kristen Grauman.",
      "orig_title": "Learning to separate object sounds by watching unlabeled video",
      "paper_id": "1804.01665v2"
    },
    {
      "index": 79,
      "title": "Ruohan Gao and Kristen Grauman",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Ruohan Gao and Kristen Grauman."
    },
    {
      "index": 80,
      "title": "Co-Separating Sounds of Visual Objects",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Ruohan Gao and Kristen Grauman.",
      "orig_title": "Co-separating sounds of visual objects",
      "paper_id": "1904.07750v2"
    },
    {
      "index": 81,
      "title": "VisualVoice: Audio-Visual Speech Separation with Cross-Modal Consistency",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "R. Gao and K. Grauman.",
      "orig_title": "VisualVoice: Audio-visual speech separation with cross-modal consistency",
      "paper_id": "2101.03149v2"
    },
    {
      "index": 82,
      "title": "Audio-visual speaker diarization based on spatiotemporal bayesian fusion",
      "abstract": "",
      "year": "2018",
      "venue": "PAMI",
      "authors": "I. Gebru, S. Ba, X. Li, and R. Horaud."
    },
    {
      "index": 83,
      "title": "Audio-visual speaker diarization based on spatiotemporal bayesian fusion",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n39",
      "authors": "Israel D. Gebru, Silèye Ba, Xiaofei Li, and Radu Horaud."
    },
    {
      "index": 84,
      "title": "Multiview RGB-D Dataset for Object Instance Detection",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "Georgios Georgakis, Md Alimoor Reza, Arsalan Mousavian, Phi-Hung Le, and Jana\nKošecká.",
      "orig_title": "Multiview rgb-d dataset for object instance detection",
      "paper_id": "1609.07826v1"
    },
    {
      "index": 85,
      "title": "Anticipative Video Transformer",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "Rohit Girdhar and Kristen Grauman.",
      "orig_title": "Anticipative video transformer",
      "paper_id": "2106.02036v2"
    },
    {
      "index": 86,
      "title": "Fast R-CNN",
      "abstract": "",
      "year": "2015",
      "venue": "Proceedings of the IEEE international conference on computer\nvision",
      "authors": "Ross Girshick.",
      "orig_title": "Fast r-cnn",
      "paper_id": "1504.08083v2"
    },
    {
      "index": 87,
      "title": "Finding Action Tubes",
      "abstract": "",
      "year": "2015",
      "venue": "2015 IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), pages 759–768, Boston, MA, USA, June 2015.\nIEEE",
      "authors": "Georgia Gkioxari and Jitendra Malik.",
      "orig_title": "Finding action tubes",
      "paper_id": "1411.6031v1"
    },
    {
      "index": 88,
      "title": "Action phases and mind-sets, Handbook of motivation and cognition: Foundations of social behavior",
      "abstract": "",
      "year": "1990",
      "venue": "",
      "authors": "P. Gollwitzer."
    },
    {
      "index": 89,
      "title": "The “something something” video database for learning and evaluating visual common sense",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Raghav Goyal, Samira Ebrahimi Kahou, Vincent Michalski, Joanna Materzynska,\nSusanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos,\nMoritz Mueller-Freitag, et al.",
      "orig_title": "The” something something” video database for learning and evaluating visual common sense",
      "paper_id": "1706.04261v2"
    },
    {
      "index": 90,
      "title": "Bidirectional lstm networks for improved phoneme classification and recognition",
      "abstract": "",
      "year": "2005",
      "venue": "International conference on artificial neural networks",
      "authors": "Alex Graves, Santiago Fernández, and Jürgen Schmidhuber."
    },
    {
      "index": 91,
      "title": "AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition",
      "authors": "Chunhui Gu, Chen Sun, David A Ross, Carl Vondrick, Caroline Pantofaru, Yeqing\nLi, Sudheendra Vijayanarasimhan, George Toderici, Susanna Ricco, Rahul\nSukthankar, et al.",
      "orig_title": "Ava: A video dataset of spatio-temporally localized atomic visual actions",
      "paper_id": "1705.08421v4"
    },
    {
      "index": 92,
      "title": "Conformer: Convolution-augmented Transformer for Speech Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:",
      "authors": "Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu,\nWei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, et al.",
      "orig_title": "Conformer: Convolution-augmented transformer for speech recognition",
      "paper_id": "2005.08100v1"
    },
    {
      "index": 93,
      "title": "Georgia Gkioxari",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:",
      "authors": "Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick."
    },
    {
      "index": 94,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 95,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 96,
      "title": "Detecting the Moment of Completion: Temporal Models for Localising Action Completion",
      "abstract": "",
      "year": "2018",
      "venue": "BMVC",
      "authors": "Farnoosh Heidarivincheh, Majid Mirmehdi, and Dima Damen.",
      "orig_title": "Detecting the moment of completion: Temporal models for localising action completion",
      "paper_id": "1710.02310v1"
    },
    {
      "index": 97,
      "title": "spaCy: Industrial-strength Natural Language Processing in Python, 2020",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Matthew Honnibal, Ines Montani, Sofie Van Landeghem, and Adriane Boyd."
    },
    {
      "index": 98,
      "title": "GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n43(5):",
      "authors": "Lianghua Huang, Xin Zhao, and Kaiqi Huang.",
      "orig_title": "GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild",
      "paper_id": "1810.11981v3"
    },
    {
      "index": 99,
      "title": "Timeception for Complex Action Recognition",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Noureldien Hussein, Efstratios Gavves, and Arnold WM Smeulders.",
      "orig_title": "Timeception for complex action recognition",
      "paper_id": "1812.01289v2"
    },
    {
      "index": 100,
      "title": "Seeing through sounds: Predicting visual semantic segmentation results from multichannel audio signals",
      "abstract": "",
      "year": "2019",
      "venue": "ICASSP 2019-2019 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP)",
      "authors": "Go Irie, Mirela Ostrek, Haochen Wang, Hirokazu Kameoka, Akisato Kimura,\nTakahito Kawanishi, and Kunio Kashino."
    },
    {
      "index": 101,
      "title": "Discovering states and transformations in image collections",
      "abstract": "",
      "year": "2015",
      "venue": "CVPR",
      "authors": "Phillip Isola, Joseph J. Lim, and Edward H. Adelson."
    },
    {
      "index": 102,
      "title": "Discovering states and transformations in image collections",
      "abstract": "",
      "year": "2015",
      "venue": "CVPR",
      "authors": "Phillip Isola, Joseph J Lim, and Edward H Adelson."
    },
    {
      "index": 103,
      "title": "Audio-visual speech recognition using lip information extracted from side-face images",
      "abstract": "",
      "year": "2007",
      "venue": "EURASIP Journal on Audio, Speech, and Music Processing",
      "authors": "Koji Iwano, Tomoaki Yoshinaga, Satoshi Tamura, and Sadaoki Furui."
    },
    {
      "index": 104,
      "title": "Perceiver: General perception with iterative attention",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:",
      "authors": "Andrew Jaegle, Felix Gimeno, Andrew Brock, Andrew Zisserman, Oriol Vinyals, and\nJoao Carreira."
    },
    {
      "index": 105,
      "title": "A multi-view dataset for learning multi-agent multi-task activities",
      "abstract": "",
      "year": "2020",
      "venue": "ECCV",
      "authors": "Baoxiong Jia, Yixin Chen, Siyuan Huang, Yixin Zhu, and Song-Chun Zhu."
    },
    {
      "index": 106,
      "title": "Seeing invisible poses: Estimating 3d body pose from egocentric video",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Hao Jiang and Kristen Grauman."
    },
    {
      "index": 107,
      "title": "The Kinetics Human Action Video Dataset",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:",
      "authors": "Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra\nVijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et al.",
      "orig_title": "The kinetics human action video dataset",
      "paper_id": "1705.06950v1"
    },
    {
      "index": 108,
      "title": "The Kinetics Human Action Video Dataset",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:",
      "authors": "Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra\nVijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et al.",
      "orig_title": "The kinetics human action video dataset",
      "paper_id": "1705.06950v1"
    },
    {
      "index": 109,
      "title": "EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the IEEE International Conference on Computer\nVision",
      "authors": "Evangelos Kazakos, Arsha Nagrani, Andrew Zisserman, and Dima Damen.",
      "orig_title": "Epic-fusion: Audio-visual temporal binding for egocentric action recognition",
      "paper_id": "1908.08498v1"
    },
    {
      "index": 110,
      "title": "Gaze360: Physically Unconstrained Gaze Estimation in the Wild",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the IEEE International Conference on Computer\nVision (ICCV 19)",
      "authors": "Petr Kellnhofer, Simon Stent, Wojciech Matusik, and Antonio Torralba.",
      "orig_title": "Gaze360: Physically Unconstrained Gaze Estimation in the Wild",
      "paper_id": "1910.10088v1"
    },
    {
      "index": 111,
      "title": "JOINT CTC-ATTENTION BASED END-TO-END SPEECH RECOGNITION USING MULTI-TASK LEARNING",
      "abstract": "",
      "year": "2017",
      "venue": "2017 IEEE international conference on acoustics, speech and\nsignal processing (ICASSP)",
      "authors": "Suyoun Kim, Takaaki Hori, and Shinji Watanabe.",
      "orig_title": "Joint ctc-attention based end-to-end speech recognition using multi-task learning",
      "paper_id": "1609.06773v2"
    },
    {
      "index": 112,
      "title": "Activity forecasting",
      "abstract": "",
      "year": "2012",
      "venue": "ECCV",
      "authors": "Kris M. Kitani, Brian Ziebart, James D. Bagnell, and Martial Hebert."
    },
    {
      "index": 113,
      "title": "Testing the correlation of word error rate and perplexity",
      "abstract": "",
      "year": "2002",
      "venue": "Speech Communication, 38(1-2):19–28",
      "authors": "Dietrich Klakow and Jochen Peters."
    },
    {
      "index": 114,
      "title": "Nonverbal Communication in Human Interaction",
      "abstract": "",
      "year": "2014",
      "venue": "Wadsworth Cengage Learning, 8th edition",
      "authors": "Mark L. Knapp, Judith A. Hall, and Terrence G. Horgan."
    },
    {
      "index": 115,
      "title": "Ikeabot: An autonomous multi-robot coordinated furniture assembly system",
      "abstract": "",
      "year": "2013",
      "venue": "2013 IEEE International conference on robotics and\nautomation",
      "authors": "Ross A Knepper, Todd Layton, John Romanishin, and Daniela Rus."
    },
    {
      "index": 116,
      "title": "Auditory distance perception in humans: a review of cues, development, neuronal bases, and effects of sensory loss",
      "abstract": "",
      "year": "2016",
      "venue": "Attention, Perception, & Psychophysics, 78(2):373–395",
      "authors": "Andrew J Kolarik, Brian CJ Moore, Pavel Zahorik, Silvia Cirstea, and Shahina\nPardhan."
    },
    {
      "index": 117,
      "title": "Anticipating human activities using object affordances for reactive robotic response",
      "abstract": "",
      "year": "2016",
      "venue": "Pattern Analysis and Machine Intelligence, 38(1):14–29",
      "authors": "Hema S. Koppula and Ashutosh Saxena."
    },
    {
      "index": 118,
      "title": "Dense-Captioning Events in Videos",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Computer Vision (ICCV)",
      "authors": "Ranjay Krishna, Kenji Hata, Frederic Ren, Li Fei-Fei, and Juan Carlos Niebles.",
      "orig_title": "Dense-captioning events in videos",
      "paper_id": "1705.00754v1"
    },
    {
      "index": 119,
      "title": "Krishnacam: Using a longitudinal, single-person, egocentric dataset for scene understanding tasks",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Winter Conference on Applications of Computer Vision\n(WACV)",
      "authors": "Alexei A. Efros Krishna Kumar Singh, Kayvon Fatahalian."
    },
    {
      "index": 120,
      "title": "The eighth visual object tracking VOT2020 challenge results, 2020",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Matej Kristan, Ales Leonardis, Jiri Matas, Michael Felsberg, Roman Pflugfelder,\nJoni-Kristian Kamarainen, Luka Čehovin Zajc, Martin Danelljan, Alan\nLukezic, Ondrej Drbohlav, Linbo He, Yushan Zhang, Song Yan, Jinyu Yang,\nGustavo Fernandez, and et al."
    },
    {
      "index": 121,
      "title": "Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:",
      "authors": "Taku Kudo and John Richardson."
    },
    {
      "index": 122,
      "title": "The open images dataset v4",
      "abstract": "",
      "year": "2020",
      "venue": "International Journal of Computer Vision, 128(7):1956–1981",
      "authors": "Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ivan Krasin, Jordi\nPont-Tuset, Shahab Kamali, Stefan Popov, Matteo Malloci, Alexander\nKolesnikov, et al."
    },
    {
      "index": 123,
      "title": "Guide to the carnegie mellon university multimodal activity (cmu-mmac) database",
      "abstract": "",
      "year": "2009",
      "venue": "Tech. report CMU-RI-TR-08-22, Robotics Institute, Carnegie\nMellon University",
      "authors": "F. De la Torre, J. Hodgins, J. Montano, S. Valcarcel, R. Forcada, and J. Macey."
    },
    {
      "index": 124,
      "title": "Audio/video fusion for objects recognition",
      "abstract": "",
      "year": "2009",
      "venue": "2009 IEEE/RSJ International Conference on Intelligent Robots\nand Systems",
      "authors": "Loic Lacheze, Yan Guo, Ryad Benosman, Bruno Gas, and Charlie Couverture."
    },
    {
      "index": 125,
      "title": "Unsupervised feature learning for 3d scene labeling",
      "abstract": "",
      "year": "2014",
      "venue": "2014 IEEE International Conference on Robotics and Automation\n(ICRA)",
      "authors": "Kevin Lai, Liefeng Bo, and Dieter Fox."
    },
    {
      "index": 126,
      "title": "A hierarchical representation for future action prediction",
      "abstract": "",
      "year": "2014",
      "venue": "ECCV",
      "authors": "Tian Lan, Tsung-Chuan Chen, and Silvio Savarese."
    },
    {
      "index": 127,
      "title": "Bayesian hmm clustering of x-vector sequences (vbx) in speaker diarization: theory, implementation and analysis on standard tasks",
      "abstract": "",
      "year": "2022",
      "venue": "Computer Speech & Language, 71:",
      "authors": "Federico Landini, Ján Profant, Mireia Diez, and Lukáš Burget."
    },
    {
      "index": 128,
      "title": "Discovering important people and objects for egocentric video summarization",
      "abstract": "",
      "year": "2012",
      "venue": "CVPR",
      "authors": "Y. J. Lee, J. Ghosh, and K. Grauman."
    },
    {
      "index": 129,
      "title": "Discovering important people and objects for egocentric video summarization",
      "abstract": "",
      "year": "2012",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition (CVPR)",
      "authors": "Y. J. Lee, J. Ghosh, and K. Grauman."
    },
    {
      "index": 130,
      "title": "Predicting Important Objects for Egocentric Video Summarization",
      "abstract": "",
      "year": "2015",
      "venue": "IJCV",
      "authors": "Yong Jae Lee and Kristen Grauman.",
      "orig_title": "Predicting important objects for egocentric video summarization",
      "paper_id": "1505.04803v1"
    },
    {
      "index": 131,
      "title": "Connecting meeting behavior with extraversion-a systematic study",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE Transactions on Affective Computing, 3(4):443–455",
      "authors": "Bruno Lepri, Ramanathan Subramanian, Kyriaki Kalimeri, Jacopo Staiano, Fabio\nPianesi, and Nicu Sebe."
    },
    {
      "index": 132,
      "title": "Binary codes capable of correcting deletions, insertions, and reversals",
      "abstract": "",
      "year": "1966",
      "venue": "Soviet physics doklady",
      "authors": "Vladimir I Levenshtein et al."
    },
    {
      "index": 133,
      "title": "Model recommendation with virtual probes for ego-centric hand detection",
      "abstract": "",
      "year": "2013",
      "venue": "ICCV",
      "authors": "Cheng Li and Kris Kitani."
    },
    {
      "index": 134,
      "title": "Learning to predict gaze in egocentric video",
      "abstract": "",
      "year": "2013",
      "venue": "Proceedings of the IEEE International Conference on Computer\nVision",
      "authors": "Yin Li, Alireza Fathi, and James M. Rehg."
    },
    {
      "index": 135,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Y. Li, M. Liu, and J. Rehg.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 136,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Yin Li, Miao Liu, and Jame Rehg.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 137,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the European Conference on Computer Vision\n(ECCV)",
      "authors": "Yin Li, Miao Liu, and James M Rehg.",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 138,
      "title": "Ego-Exo: Transferring Visual Representations from Third-person to First-person Videos",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Yanghao Li, Tushar Nagarajan, Bo Xiong, and Kristen Grauman.",
      "orig_title": "Ego-exo: Transferring visual representations from third-person to first-person videos",
      "paper_id": "2104.07905v1"
    },
    {
      "index": 139,
      "title": "BMN: Boundary-Matching Network for Temporal Action Proposal Generation",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the IEEE/CVF International Conference on\nComputer Vision",
      "authors": "Tianwei Lin, Xiao Liu, Xin Li, Errui Ding, and Shilei Wen.",
      "orig_title": "Bmn: Boundary-matching network for temporal action proposal generation",
      "paper_id": "1907.09702v1"
    },
    {
      "index": 140,
      "title": "BSN: Boundary Sensitive Network for Temporal Action Proposal Generation",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the European Conference on Computer Vision\n(ECCV)",
      "authors": "Tianwei Lin, Xu Zhao, Haisheng Su, Chongjing Wang, and Ming Yang.",
      "orig_title": "Bsn: Boundary sensitive network for temporal action proposal generation",
      "paper_id": "1806.02964v3"
    },
    {
      "index": 141,
      "title": "Feature Pyramid Networks for Object Detection",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv:",
      "authors": "Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan,\nand Serge Belongie.",
      "orig_title": "Feature Pyramid Networks for Object Detection",
      "paper_id": "1612.03144v2"
    },
    {
      "index": 142,
      "title": "Microsoft COCO: Common Objects in Context",
      "abstract": "",
      "year": "2014",
      "venue": "ECCV",
      "authors": "Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva\nRamanan, Piotr Dollár, and C Lawrence Zitnick.",
      "orig_title": "Microsoft COCO: Common objects in context",
      "paper_id": "1405.0312v3"
    },
    {
      "index": 143,
      "title": "Forecasting human-object interaction: joint prediction of motor attention and actions in first person video",
      "abstract": "",
      "year": "2020",
      "venue": "ECCV",
      "authors": "Miao Liu, Siyu Tang, Yin Li, and James M Rehg."
    },
    {
      "index": 144,
      "title": "Future frame prediction for anomaly detection–a new baseline",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition",
      "authors": "Wen Liu, Weixin Luo, Dongze Lian, and Shenghua Gao."
    },
    {
      "index": 145,
      "title": "Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:",
      "authors": "William Lotter, Gabriel Kreiman, and David Cox.",
      "orig_title": "Deep predictive coding networks for video prediction and unsupervised learning",
      "paper_id": "1605.08104v5"
    },
    {
      "index": 146,
      "title": "Personal object discovery in first-person videos",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Cewu Lu, Renjie Liao, and Jiaya Jia."
    },
    {
      "index": 147,
      "title": "Story-driven summarization for egocentric video",
      "abstract": "",
      "year": "2013",
      "venue": "CVPR",
      "authors": "Zheng Lu and Kristen Grauman."
    },
    {
      "index": 148,
      "title": "Joint prediction of activity labels and starting times in untrimmed videos",
      "abstract": "",
      "year": "2017",
      "venue": "Proceedings of the IEEE International Conference on Computer\nVision",
      "authors": "Tahmida Mahmud, Mahmudul Hasan, and Amit K Roy-Chowdhury."
    },
    {
      "index": 149,
      "title": "LAEO-Net++: revisiting people Looking At Each Other in videos",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition",
      "authors": "Manuel J Marin-Jimenez, Vicky Kalogeiton, Pablo Medina-Suarez, and Andrew\nZisserman.",
      "orig_title": "Laeo-net: revisiting people looking at each other in videos",
      "paper_id": "2101.02136v1"
    },
    {
      "index": 150,
      "title": "Detecting people looking at each other in videos",
      "abstract": "",
      "year": "2014",
      "venue": "International Journal of Computer Vision, 106(3):282–296",
      "authors": "Manuel Jesús Marín-Jiménez, Andrew Zisserman, Marcin Eichner, and\nVittorio Ferrari."
    },
    {
      "index": 151,
      "title": "Here’s looking at you, kid",
      "abstract": "",
      "year": "2011",
      "venue": "Detecting people looking at each other in videos. In BMVC, 5",
      "authors": "Manuel J Marín-Jiménez, Andrew Zisserman, and Vittorio Ferrari."
    },
    {
      "index": 152,
      "title": "Deep multi-scale video prediction beyond mean square error",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:",
      "authors": "Michael Mathieu, Camille Couprie, and Yann LeCun.",
      "orig_title": "Deep multi-scale video prediction beyond mean square error",
      "paper_id": "1511.05440v6"
    },
    {
      "index": 153,
      "title": "The AMI meeting corpus",
      "abstract": "",
      "year": "2005",
      "venue": "Proceedings of Measuring Behavior 2005, the 5th International\nConference on Methods and Techniques in Behavioral Research, pages 137–140",
      "authors": "Iain McCowan, Jean Carletta, Wessel Kraaij, Simone Ashby, Sebastien Bourban,\nMike Flynn, Mael Guillemot, Thomas Hain, Jaroslav Kadlec, Vasilis Karaiskos,\nMelissa Kronenthal, Guillaume Lathoud, Mike Lincoln, Agnes Lisowska, Wilfried\nPost, Dennis Reidsma, and Pierre Wellner."
    },
    {
      "index": 154,
      "title": "Deep Template-based Object Instance Detection",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the IEEE/CVF Winter Conference on Applications\nof Computer Vision (WACV)",
      "authors": "Jean-Philippe Mercier, Mathieu Garon, Philippe Giguere, and Jean-Francois\nLalonde.",
      "orig_title": "Deep template-based object instance detection",
      "paper_id": "1911.11822v3"
    },
    {
      "index": 155,
      "title": "An evaluation of psychophysical models of auditory change perception",
      "abstract": "",
      "year": "2008",
      "venue": "Psychological review, 115(4):",
      "authors": "Christophe Micheyl, Christian Kaernbach, and Laurent Demany."
    },
    {
      "index": 156,
      "title": "HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Antoine Miech, Dimitri Zhukov, Jean-Baptiste Alayrac, Makarand Tapaswi, Ivan\nLaptev, and Josef Sivic.",
      "orig_title": "HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips",
      "paper_id": "1906.03327v2"
    },
    {
      "index": 157,
      "title": "From red wine to red tomato: Composition with context",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Ishan Misra, Abhinav Gupta, and Martial Hebert."
    },
    {
      "index": 158,
      "title": "Deep eye contact detector: Robust eye contact bid detection using convolutional neural network",
      "abstract": "",
      "year": "2017",
      "venue": "BMVC",
      "authors": "Yu Mitsuzumi, Atsushi Nakazawa, and Toyoaki Nishida."
    },
    {
      "index": 159,
      "title": "Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Davide Moltisanti, Michael Wray, Walterio Mayol-Cuevas, and Dima Damen.",
      "orig_title": "Trespassing the boundaries: Labelling temporal bounds for object interactions in egocentric video",
      "paper_id": "1703.09026v2"
    },
    {
      "index": 160,
      "title": "Self-Supervised Generation of Spatial Audio for 360∘ Video",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Pedro Morgado, Nono Vasconcelos, Timothy Langlois, and Oliver Wang.",
      "orig_title": "Self-supervised generation of spatial audio for 360∘ video",
      "paper_id": "1809.02587v1"
    },
    {
      "index": 161,
      "title": "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild",
      "abstract": "",
      "year": "2018",
      "venue": "Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair\nWeiss, editors, Computer Vision – ECCV 2018, volume",
      "authors": "Matthias Müller, Adel Bibi, Silvio Giancola, Salman Alsubaihi, and Bernard\nGhanem."
    },
    {
      "index": 162,
      "title": "Grounded Human-Object Interaction Hotspots from Video",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Tushar Nagarajan, Christoph Feichtenhofer, and Kristen Grauman.",
      "orig_title": "Grounded human-object interaction hotspots from video",
      "paper_id": "1812.04558v2"
    },
    {
      "index": 163,
      "title": "Attributes as Operators: Factorizing Unseen Attribute-Object Compositions",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the European Conference on Computer Vision\n(ECCV)",
      "authors": "Tushar Nagarajan and Kristen Grauman.",
      "orig_title": "Attributes as operators: factorizing unseen attribute-object compositions",
      "paper_id": "1803.09851v2"
    },
    {
      "index": 164,
      "title": "VoxCeleb: a large-scale speaker identification dataset",
      "abstract": "",
      "year": "2017",
      "venue": "INTERSPEECH",
      "authors": "A. Nagrani, J. S. Chung, and A. Zisserman.",
      "orig_title": "VoxCeleb: a large-scale speaker identification dataset",
      "paper_id": "1706.08612v2"
    },
    {
      "index": 165,
      "title": "Jointly learning energy expenditures and activities using egocentric multimodal signals",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Katsuyuki Nakamura, Serena Yeung, Alexandre Alahi, and Li Fei-Fei."
    },
    {
      "index": 166,
      "title": "Future event prediction: If and when",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the IEEE Conference on Computer Vision and\nPattern Recognition Workshops",
      "authors": "Lukas Neumann, Andrew Zisserman, and Andrea Vedaldi."
    },
    {
      "index": 167,
      "title": "You2me: Inferring body pose in egocentric video via first and second person interactions",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Evonne Ng, Donglai Xiang, Hanbyul Joo, and Kristen Grauman."
    },
    {
      "index": 168,
      "title": "Direction of arrival based spatial covariance model for blind sound source separation",
      "abstract": "",
      "year": "2014",
      "venue": "IEEE/ACM Transactions on Audio, Speech, and Language\nProcessing, 22(3):727–739",
      "authors": "Joonas Nikunen and Tuomas Virtanen."
    },
    {
      "index": 169,
      "title": "Egocom: A multi-person multi-modal egocentric communications dataset",
      "abstract": "",
      "year": "2020",
      "venue": "PAMI",
      "authors": "C. Northcutt, S. Zha, S. Lovegrove, and R. Newcombe."
    },
    {
      "index": 170,
      "title": "Audio-Visual Scene Analysis with Self-Supervised Multisensory Features",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Andrew Owens and Alexei A Efros.",
      "orig_title": "Audio-visual scene analysis with self-supervised multisensory features",
      "paper_id": "1804.03641v2"
    },
    {
      "index": 171,
      "title": "Automatic mutual gaze detection in face-to-face dyadic interaction videos",
      "abstract": "",
      "year": "2018",
      "venue": "Measuring Behavior",
      "authors": "Cristina Palmero, Elsbeth A van Dam, Sergio Escalera, Mike Kelia, Guido F\nLichtert, Lucas PJJ Noldus, Andrew J Spink, and Astrid van Wieringen."
    },
    {
      "index": 172,
      "title": "SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:",
      "authors": "Daniel S Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D\nCubuk, and Quoc V Le.",
      "orig_title": "Specaugment: A simple data augmentation method for automatic speech recognition",
      "paper_id": "1904.08779v3"
    },
    {
      "index": 173,
      "title": "Egocentric future localization",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "H. S. Park, J.-J. Hwang, Y. Niu, and J. Shi."
    },
    {
      "index": 174,
      "title": "Egocentric future localization",
      "abstract": "",
      "year": "2016",
      "venue": "Conference on Computer Vision and Pattern Recognition\n(CVPR)",
      "authors": "H. S. Park, J.-J. Hwang, Y. Niu, and J. Shi."
    },
    {
      "index": 175,
      "title": "3D social saliency from head-mounted cameras",
      "abstract": "",
      "year": "2012",
      "venue": "Advances in Neural Information Processing Systems, volume 1",
      "authors": "Hyun Soo Park, Eakta Jain, and Yaser Sheikh."
    },
    {
      "index": 176,
      "title": "A Review of Speaker Diarization: Recent Advances with Deep Learning",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:",
      "authors": "Tae Jin Park, Naoyuki Kanda, Dimitrios Dimitriadis, Kyu J Han, Shinji Watanabe,\nand Shrikanth Narayanan.",
      "orig_title": "A review of speaker diarization: Recent advances with deep learning",
      "paper_id": "2101.09624v4"
    },
    {
      "index": 177,
      "title": "Minimum audible angle thresholds for sources varying in both elevation and azimuth",
      "abstract": "",
      "year": "1990",
      "venue": "The Journal of the Acoustical Society of America,\n87(4):",
      "authors": "David R Perrott and Kourosh Saberi."
    },
    {
      "index": 178,
      "title": "Detecting activities of daily living in first-person camera views",
      "abstract": "",
      "year": "2012",
      "venue": "2012 IEEE conference on computer vision and pattern\nrecognition",
      "authors": "Hamed Pirsiavash and Deva Ramanan."
    },
    {
      "index": 179,
      "title": "Detecting activities of daily living in first-person camera views",
      "abstract": "",
      "year": "2012",
      "venue": "Computer Vision and Pattern Recognition (CVPR)",
      "authors": "H. Pirsiavash and D. Ramanan."
    },
    {
      "index": 180,
      "title": "The Kaldi speech recognition toolkit",
      "abstract": "",
      "year": "2011",
      "venue": "IEEE 2011 Workshop on Automatic Speech Recognition and\nUnderstanding",
      "authors": "Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek,\nNagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz, Jan\nSilovsky, Georg Stemmer, and Karel Vesely."
    },
    {
      "index": 181,
      "title": "Task-Driven Modular Networks for Zero-Shot Compositional Learning",
      "abstract": "",
      "year": "2019",
      "venue": "Proceedings of the IEEE International Conference on Computer\nVision",
      "authors": "Senthil Purushwalkam, Maximilian Nickel, Abhinav Gupta, and Marc’Aurelio\nRanzato.",
      "orig_title": "Task-driven modular networks for zero-shot compositional learning",
      "paper_id": "1905.05908v1"
    },
    {
      "index": 182,
      "title": "Egocentric Visitors Localization in Cultural Sites",
      "abstract": "",
      "year": "2019",
      "venue": "Journal on Computing and Cultural Heritage (JOCCH)",
      "authors": "F. Ragusa, A. Furnari, S. Battiato, G. Signorello, and G. M. Farinella.",
      "orig_title": "Egocentric visitors localization in cultural sites",
      "paper_id": "1904.05264v1"
    },
    {
      "index": 183,
      "title": "The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Winter Conference on Application of Computer Vision\n(WACV)",
      "authors": "Francesco Ragusa, Antonino Furnari, Salvatore Livatino, and Giovanni Maria\nFarinella.",
      "orig_title": "The meccano dataset: Understanding human-object interactions from egocentric videos in an industrial-like domain",
      "paper_id": "2010.05654v1"
    },
    {
      "index": 184,
      "title": "Vision Transformers for Dense Prediction",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the IEEE/CVF International Conference on\nComputer Vision",
      "authors": "René Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.",
      "orig_title": "Vision transformers for dense prediction",
      "paper_id": "2103.13413v1"
    },
    {
      "index": 185,
      "title": "Where are they looking?",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Adria Recasens, Aditya Khosla, Carl Vondrick, and Antonio Torralba."
    },
    {
      "index": 186,
      "title": "Yolov3: An incremental improvement",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:",
      "authors": "Joseph Redmon and Ali Farhadi."
    },
    {
      "index": 187,
      "title": "Behavioral Imaging and Autism",
      "abstract": "",
      "year": "2014",
      "venue": "IEEE Pervasive Computing, 13(2):84–87",
      "authors": "James M. Rehg, Agata Rozga, Gregory D. Abowd, and Matthew S. Goodwin."
    },
    {
      "index": 188,
      "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
      "abstract": "",
      "year": "2015",
      "venue": "NeurIPS",
      "authors": "Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.",
      "orig_title": "Faster r-cnn: Towards real-time object detection with region proposal networks",
      "paper_id": "1506.01497v3"
    },
    {
      "index": 189,
      "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in neural information processing systems, 28:91–99",
      "authors": "Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.",
      "orig_title": "Faster r-cnn: Towards real-time object detection with region proposal networks",
      "paper_id": "1506.01497v3"
    },
    {
      "index": 190,
      "title": "Predicting the Future from First Person (Egocentric) Vision: A Survey",
      "abstract": "",
      "year": "2021",
      "venue": "Computer Vision and Image Understanding",
      "authors": "Ivan Rodin, Antonino Furnari, Dimitrios Mavroedis, and Giovanni Maria\nFarinella.",
      "orig_title": "Predicting the future from first person (egocentric) vision: A survey",
      "paper_id": "2107.13411v1"
    },
    {
      "index": 191,
      "title": "AVA-ActiveSpeaker: An Audio-Visual Dataset for Active Speaker Detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:",
      "authors": "Joseph Roth, Sourish Chaudhuri, Ondrej Klejch, Radhika Marvin, Andrew\nGallagher, Liat Kaver, Sharadh Ramaswamy, Arkadiusz Stopczynski, Cordelia\nSchmid, Zhonghua Xi, et al.",
      "orig_title": "Ava-activespeaker: An audio-visual dataset for active speaker detection",
      "paper_id": "1901.01342v2"
    },
    {
      "index": 192,
      "title": "AVA-ActiveSpeaker: An Audio-Visual Dataset for Active Speaker Detection",
      "abstract": "",
      "year": "2020",
      "venue": "ICASSP, IEEE International Conference on Acoustics, Speech\nand Signal Processing - Proceedings, volume 2020-May, pages 4492–4496",
      "authors": "Joseph Roth, Sourish Chaudhuri, Ondrej Klejch, Radhika Marvin, Andrew\nGallagher, Liat Kaver, Sharadh Ramaswamy, Arkadiusz Stopczynski, Cordelia\nSchmid, Zhonghua Xi, and Caroline Pantofaru.",
      "orig_title": "Ava Active Speaker: An Audio-Visual Dataset for Active Speaker Detection",
      "paper_id": "1901.01342v2"
    },
    {
      "index": 193,
      "title": "First-person activity recognition: What are they doing to me?",
      "abstract": "",
      "year": "2013",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition\n(CVPR)",
      "authors": "M. S. Ryoo and L. Matthies."
    },
    {
      "index": 194,
      "title": "SuperGlue: Learning Feature Matching with Graph Neural Networks",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the IEEE/CVF conference on computer vision and\npattern recognition",
      "authors": "Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich.",
      "orig_title": "Superglue: Learning feature matching with graph neural networks",
      "paper_id": "1911.11763v2"
    },
    {
      "index": 195,
      "title": "Structure-from-motion revisited",
      "abstract": "",
      "year": "2016",
      "venue": "Proceedings of the IEEE conference on computer vision and\npattern recognition",
      "authors": "Johannes L Schonberger and Jan-Michael Frahm."
    },
    {
      "index": 196,
      "title": "Learning to Localize Sound Sources in Visual Scenes: Analysis and Applications",
      "abstract": "",
      "year": "2019",
      "venue": "TPAMI",
      "authors": "A. Senocak, T.-H. Oh, J. Kim, M. Yang, and I. S. Kweon.",
      "orig_title": "Learning to localize sound sources in visual scenes: Analysis and applications",
      "paper_id": "1911.09649v1"
    },
    {
      "index": 197,
      "title": "Understanding Human Hands in Contact at Internet Scale",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Dandan Shan, Jiaqi Geng, Michelle Shu, and David Fouhey.",
      "orig_title": "Understanding human hands in contact at internet scale",
      "paper_id": "2006.06669v1"
    },
    {
      "index": 198,
      "title": "Understanding Human Hands in Contact at Internet Scale",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Dandan Shan, Jiaqi Geng, Michelle Shu, and David Fouhey.",
      "orig_title": "Understanding human hands in contact at internet scale",
      "paper_id": "2006.06669v1"
    },
    {
      "index": 199,
      "title": "Learning Semantic Embedding Spaces for Slicing Vegetables",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:",
      "authors": "Mohit Sharma, Kevin Zhang, and Oliver Kroemer.",
      "orig_title": "Learning semantic embedding spaces for slicing vegetables",
      "paper_id": "1904.00303v1"
    },
    {
      "index": 200,
      "title": "Charades-Ego: A Large-Scale Dataset of Paired Third and First Person Videos",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:",
      "authors": "Gunnar A Sigurdsson, Abhinav Gupta, Cordelia Schmid, Ali Farhadi, and Karteek\nAlahari.",
      "orig_title": "Charades-ego: A large-scale dataset of paired third and first person videos",
      "paper_id": "1804.09626v2"
    },
    {
      "index": 201,
      "title": "Indoor segmentation and support inference from rgbd images",
      "abstract": "",
      "year": "2012",
      "venue": "European conference on computer vision, pages 746–760.\nSpringer",
      "authors": "Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus."
    },
    {
      "index": 202,
      "title": "Silero vad: Pre-trained enterprise-grade voice activity detector (VAD), number detector and language classifier",
      "abstract": "",
      "year": "2021",
      "venue": "https://github.com/snakers4/silero-vad",
      "authors": "Silero Team."
    },
    {
      "index": 203,
      "title": "A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos",
      "abstract": "",
      "year": "2018",
      "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern\nRecognition (CVPR)",
      "authors": "Michel Silva, Washington Ramos, João Ferreira, Felipe Chamone, Mario Campos,\nand Erickson R. Nascimento.",
      "orig_title": "A weighted sparse sampling and smoothing frame transition approach for semantic fast-forward first-person videos",
      "paper_id": "1802.08722v4"
    },
    {
      "index": 204,
      "title": "Krishnacam: Using a longitudinal, single-person, egocentric dataset for scene understanding tasks",
      "abstract": "",
      "year": "2016",
      "venue": "WACV",
      "authors": "Krishna Kumar Singh, Kayvon Fatahalian, and Alexei A Efros."
    },
    {
      "index": 205,
      "title": "X-vectors: Robust DNN embeddings for speaker recognition",
      "abstract": "",
      "year": "2018",
      "venue": "2018 IEEE International Conference on Acoustics, Speech and\nSignal Processing (ICASSP)",
      "authors": "David Snyder, Daniel Garcia-Romero, Gregory Sell, Daniel Povey, and Sanjeev\nKhudanpur."
    },
    {
      "index": 206,
      "title": "Ucf101: A dataset of 101 human action classes from videos in the wild",
      "abstract": "",
      "year": "2012",
      "venue": "CRCV-TR-12-01",
      "authors": "Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah."
    },
    {
      "index": 207,
      "title": "Egocentric shopping cart localization",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Pattern Recognition (ICPR)",
      "authors": "Emiliano Spera, Antonino Furnari, Sebastiano Battiato, and Giovanni Maria\nFarinella."
    },
    {
      "index": 208,
      "title": "The replica dataset: A digital replica of indoor spaces",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:",
      "authors": "Julian Straub, Thomas Whelan, Lingni Ma, Yufan Chen, Erik Wijmans, Simon Green,\nJakob J Engel, Raul Mur-Artal, Carl Ren, Shobhit Verma, et al."
    },
    {
      "index": 209,
      "title": "Detecting Engagement in Egocentric Video",
      "abstract": "",
      "year": "2016",
      "venue": "ECCV",
      "authors": "Yu-Chuan Su and Kristen Grauman.",
      "orig_title": "Detecting engagement in egocentric video",
      "paper_id": "1604.00906v1"
    },
    {
      "index": 210,
      "title": "Is Someone Speaking? Exploring Long-term Temporal Features for Audio-visual Active Speaker Detection",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:",
      "authors": "Ruijie Tao, Zexu Pan, Rohan Kumar Das, Xinyuan Qian, Mike Zheng Shou, and\nHaizhou Li.",
      "orig_title": "Is someone speaking? exploring long-term temporal features for audio-visual active speaker detection",
      "paper_id": "2107.06592v2"
    },
    {
      "index": 211,
      "title": "Audio-Visual Event Localization in Unconstrained Videos",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Y. Tian, J. Shi, B. Li, Z. Duan, and C. Xu.",
      "orig_title": "Audio-visual event localization in unconstrained videos",
      "paper_id": "1803.08842v1"
    },
    {
      "index": 212,
      "title": "Episodic and semantic memory",
      "abstract": "",
      "year": "1972",
      "venue": "E. Tulving and W. Donaldson, editors, Organization of\nmemory. Academic Press",
      "authors": "E. Tulving."
    },
    {
      "index": 213,
      "title": "The 20BN-jester Dataset V1",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "TwentyBN."
    },
    {
      "index": 214,
      "title": "Transformation-based models of video sequences",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:",
      "authors": "Joost Van Amersfoort, Anitha Kannan, Marc’Aurelio Ranzato, Arthur Szlam, Du\nTran, and Soumith Chintala."
    },
    {
      "index": 215,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural in processing systems, pages 5998–6008",
      "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 216,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 217,
      "title": "Decomposing Motion and Content for Natural Video Sequence Prediction",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:",
      "authors": "Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, and Honglak Lee.",
      "orig_title": "Decomposing motion and content for natural video sequence prediction",
      "paper_id": "1706.08033v2"
    },
    {
      "index": 218,
      "title": "Anticipating visual representations from unlabeled video",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba."
    },
    {
      "index": 219,
      "title": "Learning a generative model for multi-step human-object interactions from videos",
      "abstract": "",
      "year": "2019",
      "venue": "Eurographics",
      "authors": "He Wang, Sören Pirk, Ersin Yumer, Vladimir G Kim, Ozan Sener, Srinath\nSridhar, and Leonidas J Guibas."
    },
    {
      "index": 220,
      "title": "Temporal Segment Networks: Towards Good Practices for Deep Action Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "ECCV",
      "authors": "Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, and Luc\nVan Gool.",
      "orig_title": "Temporal segment networks: Towards good practices for deep action recognition",
      "paper_id": "1608.00859v1"
    },
    {
      "index": 221,
      "title": "Fast online object tracking and segmentation: A unifying approach, 2019",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Qiang Wang, Li Zhang, Luca Bertinetto, Weiming Hu, and Philip H. S. Torr."
    },
    {
      "index": 222,
      "title": "Actions~ transformations",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Xiaolong Wang, Ali Farhadi, and Abhinav Gupta."
    },
    {
      "index": 223,
      "title": "Non-local Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.",
      "orig_title": "Non-local neural networks",
      "paper_id": "1711.07971v3"
    },
    {
      "index": 224,
      "title": "Alexander Kirillov",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick."
    },
    {
      "index": 225,
      "title": "Audiovisual SlowFast Networks for Video Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:",
      "authors": "Fanyi Xiao, Yong Jae Lee, Kristen Grauman, Jitendra Malik, and Christoph\nFeichtenhofer.",
      "orig_title": "Audiovisual slowfast networks for video recognition",
      "paper_id": "2001.08740v2"
    },
    {
      "index": 226,
      "title": "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in neural information processing systems",
      "authors": "SHI Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and\nWang-chun Woo.",
      "orig_title": "Convolutional lstm network: A machine learning approach for precipitation nowcasting",
      "paper_id": "1506.04214v2"
    },
    {
      "index": 227,
      "title": "Msr-vtt: A large video description dataset for bridging video and language",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE International Conference on Computer Vision and Pattern\nRecognition (CVPR), June",
      "authors": "Jun Xu, Tao Mei, Ting Yao, and Yong Rui."
    },
    {
      "index": 228,
      "title": "G-tad: Sub-graph localization for temporal action detection",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition",
      "authors": "Mengmeng Xu, Chen Zhao, David S Rojas, Ali Thabet, and Bernard Ghanem."
    },
    {
      "index": 229,
      "title": "Future Person Localization in First-Person Videos",
      "abstract": "",
      "year": "2018",
      "venue": "The IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), June",
      "authors": "Takuma Yagi, Karttikeya Mangalam, Ryo Yonetani, and Yoichi Sato.",
      "orig_title": "Future person localization in first-person videos",
      "paper_id": "1711.11217v2"
    },
    {
      "index": 230,
      "title": "Recognizing micro-actions and reactions from paired egocentric videos",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Ryo Yonetani, Kris M. Kitani, and Yoichi Sato."
    },
    {
      "index": 231,
      "title": "Visual motif discovery via first-person vision",
      "abstract": "",
      "year": "2016",
      "venue": "ECCV",
      "authors": "Ryo Yonetani, Kris M Kitani, and Yoichi Sato."
    },
    {
      "index": 232,
      "title": "Deep Layer Aggregation",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the IEEE conference on computer vision and\npattern recognition",
      "authors": "Fisher Yu, Dequan Wang, Evan Shelhamer, and Trevor Darrell.",
      "orig_title": "Deep layer aggregation",
      "paper_id": "1707.06484v3"
    },
    {
      "index": 233,
      "title": "Audio visual attribute discovery for fine-grained object recognition",
      "abstract": "",
      "year": "2018",
      "venue": "Proceedings of the AAAI Conference on Artificial\nIntelligence, volume 32",
      "authors": "Hua Zhang, Xiaochun Cao, and Rui Wang."
    },
    {
      "index": 234,
      "title": "Span-based Localizing Network for Natural Language Video Localization",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 6543–6554, Online, July 2020. Association\nfor Computational Linguistics",
      "authors": "Hao Zhang, Aixin Sun, Wei Jing, and Joey Tianyi Zhou.",
      "orig_title": "Span-based localizing network for natural language video localization",
      "paper_id": "2004.13931v2"
    },
    {
      "index": 235,
      "title": "Learning 2d temporal adjacent networks formoment localization with natural language",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI",
      "authors": "Songyang Zhang, Houwen Peng, Jianlong Fu, and Jiebo Luo."
    },
    {
      "index": 236,
      "title": "Video Self-Stitching Graph Network for Temporal Action Localization",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the IEEE/CVF International Conference on\nComputer Vision",
      "authors": "Chen Zhao, Ali K Thabet, and Bernard Ghanem.",
      "orig_title": "Video self-stitching graph network for temporal action localization",
      "paper_id": "2011.14598v4"
    },
    {
      "index": 237,
      "title": "The Sound of Pixels",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Hang Zhao, Chuang Gan, Andrew Rouditchenko, Carl Vondrick, Josh McDermott, and\nAntonio Torralba.",
      "orig_title": "The sound of pixels",
      "paper_id": "1804.03160v4"
    },
    {
      "index": 238,
      "title": "Temporal Relational Reasoning in Videos",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Bolei Zhou, Alex Andonian, Aude Oliva, and Antonio Torralba.",
      "orig_title": "Temporal relational reasoning in videos",
      "paper_id": "1711.08496v2"
    },
    {
      "index": 239,
      "title": "Embracing Uncertainty: Decoupling and De-bias for Robust Temporal Grounding",
      "abstract": "",
      "year": "2021",
      "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition",
      "authors": "Hao Zhou, Chongyang Zhang, Yan Luo, Yanjun Chen, and Chuanping Hu.",
      "orig_title": "Embracing uncertainty: Decoupling and de-bias for robust temporal grounding",
      "paper_id": "2103.16848v2"
    },
    {
      "index": 240,
      "title": "Objects as Points",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:",
      "authors": "Xingyi Zhou, Dequan Wang, and Philipp Krähenbühl.",
      "orig_title": "Objects as points",
      "paper_id": "1904.07850v2"
    },
    {
      "index": 241,
      "title": "Learning Temporal Transformations From Time-Lapse Videos",
      "abstract": "",
      "year": "2016",
      "venue": "ECCV",
      "authors": "Y. Zhou and T. Berg.",
      "orig_title": "Learning temporal transformations from time-lapse videos",
      "paper_id": "1608.07724v1"
    },
    {
      "index": 242,
      "title": "Temporal perception and prediction in ego-centric video",
      "abstract": "",
      "year": "2015",
      "venue": "ICCV",
      "authors": "Yipin Zhou and Tamara L Berg."
    },
    {
      "index": 243,
      "title": "Learning Temporal Transformations From Time-Lapse Videos",
      "abstract": "",
      "year": "2016",
      "venue": "ECCV",
      "authors": "Yipin Zhou and Tamara L Berg.",
      "orig_title": "Learning temporal transformations from time-lapse videos",
      "paper_id": "1608.07724v1"
    },
    {
      "index": 244,
      "title": "Deep audio-visual learning: A survey",
      "abstract": "",
      "year": "2021",
      "venue": "International Journal of Automation and Computing, pages 1–26",
      "authors": "Hao Zhu, Man-Di Luo, Rui Wang, Ai-Hua Zheng, and Ran He."
    }
  ]
}