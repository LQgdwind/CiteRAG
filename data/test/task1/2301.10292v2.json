{
  "paper_id": "2301.10292v2",
  "title": "Tuning Synaptic Connections instead of Weights by Genetic Algorithm in Spiking Policy Network",
  "abstract": "Abstract\nLearning from the interaction is the primary way biological agents know about the environment and themselves. Modern deep reinforcement learning (DRL) explores a computational approach to learning from interaction and has significantly progressed in solving various tasks.\nHowever, the powerful DRL is still far from biological agents in energy efficiency.\nAlthough the underlying mechanisms are not fully understood, we believe that the integration of spiking communication between neurons and biologically-plausible synaptic plasticity plays a prominent role.\nFollowing this biological intuition, we optimize a spiking policy network (SPN) by a genetic algorithm as an energy-efficient alternative to DRL. Our SPN mimics the sensorimotor neuron pathway of insects and communicates through event-based spikes.\nInspired by biological research that the brain forms memories by forming new synaptic connections and rewires these connections based on new experiences, we tune the synaptic connections instead of weights in SPN to solve given tasks. Experimental results on several robotic control tasks show that our method can achieve the performance level of mainstream DRL methods and exhibit significantly higher energy efficiency.111The source code, saved checkpoints and results are available at¬†https://github.com/BladeDancer957/SPN-GA.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Reinforcement learning: An introduction",
      "abstract": "",
      "year": "2018",
      "venue": "MIT press",
      "authors": "Sutton R S, Barto A G"
    },
    {
      "index": 1,
      "title": "Human-level control through deep reinforcement learning",
      "abstract": "",
      "year": "2015",
      "venue": "nature",
      "authors": "Mnih V, Kavukcuoglu K, Silver D, et al."
    },
    {
      "index": 2,
      "title": "Grandmaster level in StarCraft II using multi-agent reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "Nature",
      "authors": "Vinyals O, Babuschkin I, Czarnecki W M, et al."
    },
    {
      "index": 3,
      "title": "Benchmarking Deep Reinforcement Learning for Continuous Control",
      "abstract": "",
      "year": "2016",
      "venue": "International conference on machine learning",
      "authors": "Duan Y, Chen X, Houthooft R, et al.",
      "orig_title": "Benchmarking deep reinforcement learning for continuous control",
      "paper_id": "1604.06778v3"
    },
    {
      "index": 4,
      "title": "Continuous control with deep reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "ICLR (Poster)",
      "authors": "Lillicrap T P, Hunt J J, Pritzel A, et al."
    },
    {
      "index": 5,
      "title": "Deep Reinforcement Learning with Population-Coded Spiking Neural Network for Continuous Control",
      "abstract": "",
      "year": "2021",
      "venue": "Conference on Robot Learning",
      "authors": "Tang G, Kumar N, Yoo R, et al.",
      "orig_title": "Deep reinforcement learning with population-coded spiking neural network for continuous control",
      "paper_id": "2010.09635v1"
    },
    {
      "index": 6,
      "title": "Learning representations by back-propagating errors",
      "abstract": "",
      "year": "1986",
      "venue": "nature",
      "authors": "Rumelhart D E, Hinton G E, Williams R J"
    },
    {
      "index": 7,
      "title": "Biological networks: an introductory review",
      "abstract": "",
      "year": "2018",
      "venue": "Journal Of Proteomics And Genomics Research",
      "authors": "Salem M S Z"
    },
    {
      "index": 8,
      "title": "Structurally robust biological networks",
      "abstract": "",
      "year": "2011",
      "venue": "BMC systems biology",
      "authors": "Blanchini F, Franco E"
    },
    {
      "index": 9,
      "title": "Biological robustness: paradigms, mechanisms, and systems principles",
      "abstract": "",
      "year": "2012",
      "venue": "Frontiers in genetics",
      "authors": "Whitacre J M"
    },
    {
      "index": 10,
      "title": "An energy budget for signaling in the grey matter of the brain",
      "abstract": "",
      "year": "2001",
      "venue": "Journal of Cerebral Blood Flow & Metabolism",
      "authors": "Attwell D, Laughlin S B"
    },
    {
      "index": 11,
      "title": "Updated energy budgets for neural computation in the neocortex and cerebellum",
      "abstract": "",
      "year": "2012",
      "venue": "Journal of Cerebral Blood Flow & Metabolism",
      "authors": "Howarth C, Gleeson P, Attwell D"
    },
    {
      "index": 12,
      "title": "Neural networks and neuroscience-inspired computer vision",
      "abstract": "",
      "year": "2014",
      "venue": "Current Biology",
      "authors": "Cox D D, Dean T"
    },
    {
      "index": 13,
      "title": "Six-legged walking in insects: how CPGs, peripheral feedback, and descending signals generate coordinated and adaptive motor rhythms",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of neurophysiology",
      "authors": "Bidaye S S, Bockem√ºhl T, B√ºschges A"
    },
    {
      "index": 14,
      "title": "Deep Reinforcement Learning with Spiking Q-learning",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2201.09754",
      "authors": "Chen D, Peng P, Huang T, et al."
    },
    {
      "index": 15,
      "title": "Learning causes synaptogenesis, whereas motor activity causes angiogenesis, in cerebellar cortex of adult rats",
      "abstract": "",
      "year": "1990",
      "venue": "National Academy of Sciences",
      "authors": "Black J E, Isaacs K R, Anderson B J, et al."
    },
    {
      "index": 16,
      "title": "Neuroplasticity subserving motor skill learning",
      "abstract": "",
      "year": "2011",
      "venue": "Neuron",
      "authors": "Dayan E, Cohen L G"
    },
    {
      "index": 17,
      "title": "Motor learning-dependent synaptogenesis is localized to functionally reorganized motor cortex",
      "abstract": "",
      "year": "2002",
      "venue": "Neurobiology of learning and memory",
      "authors": "Kleim J A, Barbay S, Cooper N R, et al."
    },
    {
      "index": 18,
      "title": "Q-learning",
      "abstract": "",
      "year": "1992",
      "venue": "Machine learning",
      "authors": "Watkins C J C H, Dayan P"
    },
    {
      "index": 19,
      "title": "Parameter-exploring policy gradients",
      "abstract": "",
      "year": "2010",
      "venue": "Neural Networks",
      "authors": "Sehnke F, Osendorfer C, R√ºckstie√ü T, et al."
    },
    {
      "index": 20,
      "title": "Proximal policy optimization algorithms",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1707.06347",
      "authors": "Schulman J, Wolski F, Dhariwal P, et al."
    },
    {
      "index": 21,
      "title": "Deep Reinforcement Learning with Double Q-learning",
      "abstract": "",
      "year": "2016",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "Van Hasselt H, Guez A, Silver D",
      "orig_title": "Deep reinforcement learning with double q-learning",
      "paper_id": "1509.06461v3"
    },
    {
      "index": 22,
      "title": "Dueling Network Architectures for Deep Reinforcement Learning",
      "abstract": "",
      "year": "2016",
      "venue": "International conference on machine learning",
      "authors": "Wang Z, Schaul T, Hessel M, et al.",
      "orig_title": "Dueling network architectures for deep reinforcement learning",
      "paper_id": "1511.06581v3"
    },
    {
      "index": 23,
      "title": "The arcade learning environment: An evaluation platform for general agents",
      "abstract": "",
      "year": "2013",
      "venue": "Journal of Artificial Intelligence Research",
      "authors": "Bellemare M G, Naddaf Y, Veness J, et al."
    },
    {
      "index": 24,
      "title": "Asynchronous methods for deep reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "International conference on machine learning",
      "authors": "Mnih V, Badia A P, Mirza M, et al."
    },
    {
      "index": 25,
      "title": "Trust Region Policy Optimization",
      "abstract": "",
      "year": "2015",
      "venue": "International conference on machine learning",
      "authors": "Schulman J, Levine S, Abbeel P, et al.",
      "orig_title": "Trust region policy optimization",
      "paper_id": "1502.05477v5"
    },
    {
      "index": 26,
      "title": "Addressing Function Approximation Error in Actor-Critic Methods",
      "abstract": "",
      "year": "2018",
      "venue": "International conference on machine learning",
      "authors": "Fujimoto S, Hoof H, Meger D",
      "orig_title": "Addressing function approximation error in actor-critic methods",
      "paper_id": "1802.09477v3"
    },
    {
      "index": 27,
      "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
      "abstract": "",
      "year": "2018",
      "venue": "International conference on machine learning",
      "authors": "Haarnoja T, Zhou A, Abbeel P, et al.",
      "orig_title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
      "paper_id": "1801.01290v2"
    },
    {
      "index": 28,
      "title": "Networks of spiking neurons: the third generation of neural network models",
      "abstract": "",
      "year": "1997",
      "venue": "Neural networks",
      "authors": "Maass W"
    },
    {
      "index": 29,
      "title": "Recent Advances and New Frontiers in Spiking Neural Networks",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2204.07050",
      "authors": "Zhang D, Zhang T, Jia S, et al.",
      "orig_title": "Recent Advances and New Frontiers in Spiking Neural Networks",
      "paper_id": "2204.07050v7"
    },
    {
      "index": 30,
      "title": "A spiking neural model for stable reinforcement of synapses based on multiple distal rewards",
      "abstract": "",
      "year": "2013",
      "venue": "Neural Computation",
      "authors": "O‚ÄôBrien M J, Srinivasa N"
    },
    {
      "index": 31,
      "title": "Reinforcement learning in spiking neural networks with stochastic and deterministic synapses",
      "abstract": "",
      "year": "2019",
      "venue": "Neural computation",
      "authors": "Yuan M, Wu X, Yan R, et al."
    },
    {
      "index": 32,
      "title": "Navigating mobile robots to target in near shortest time using reinforcement learning with spiking neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "2017 International Joint Conference on Neural Networks (IJCNN)",
      "authors": "Mahadevuni A, Li P"
    },
    {
      "index": 33,
      "title": "Reinforcement learning in continuous time and space",
      "abstract": "",
      "year": "2000",
      "venue": "Neural computation",
      "authors": "Doya K"
    },
    {
      "index": 34,
      "title": "Reinforcement learning using a continuous time actor-critic framework with spiking neurons",
      "abstract": "",
      "year": "2013",
      "venue": "PLoS computational biology",
      "authors": "Fr√©maux N, Sprekeler H, Gerstner W"
    },
    {
      "index": 35,
      "title": "Reinforcement learning through modulation of spike-timing-dependent synaptic plasticity",
      "abstract": "",
      "year": "2007",
      "venue": "Neural computation",
      "authors": "Florian R V"
    },
    {
      "index": 36,
      "title": "Neuromodulated spike-timing-dependent plasticity, and theory of three-factor learning rules",
      "abstract": "",
      "year": "2016",
      "venue": "Frontiers in neural circuits",
      "authors": "Fr√©maux N, Gerstner W"
    },
    {
      "index": 37,
      "title": "A solution to the learning dilemma for recurrent networks of spiking neurons",
      "abstract": "",
      "year": "2020",
      "venue": "Nature communications",
      "authors": "Bellec G, Scherr F, Subramoney A, et al."
    },
    {
      "index": 38,
      "title": "On-chip trainable hardware-based deep Q-networks approximating a backpropagation algorithm",
      "abstract": "",
      "year": "2021",
      "venue": "Neural Computing and Applications",
      "authors": "Kim J, Kwon D, Woo S Y, et al."
    },
    {
      "index": 39,
      "title": "Porting Deep Spiking Q-Networks to neuromorphic chip Loihi",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Neuromorphic Systems 2021",
      "authors": "Akl M, Sandamirskaya Y, Walter F, et al."
    },
    {
      "index": 40,
      "title": "Human-Level Control through Directly-Trained Deep Spiking Q-Networks",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE Transactions on Cybernetics",
      "authors": "Liu G, Deng W, Xie X, et al.",
      "orig_title": "Human-Level Control Through Directly Trained Deep Spiking QùëÑQ-Networks",
      "paper_id": "2201.07211v3"
    },
    {
      "index": 41,
      "title": "Improved robustness of reinforcement learning policies upon conversion to spiking neuronal network platforms applied to Atari Breakout game",
      "abstract": "",
      "year": "2019",
      "venue": "Neural Networks",
      "authors": "Patel D, Hazan H, Saunders D J, et al.",
      "orig_title": "Improved robustness of reinforcement learning policies upon conversion to spiking neuronal network platforms applied to Atari Breakout game",
      "paper_id": "1903.11012v3"
    },
    {
      "index": 42,
      "title": "Strategy and Benchmark for Converting Deep Q-Networks to Event-Driven Spiking Neural Networks",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "Tan W, Patel D, Kozma R",
      "orig_title": "Strategy and benchmark for converting deep q-networks to event-driven spiking neural networks",
      "paper_id": "2009.14456v2"
    },
    {
      "index": 43,
      "title": "Reinforcement co-Learning of Deep and Spiking Neural Networks for Energy-Efficient Mapless Navigation with Neuromorphic Hardware",
      "abstract": "",
      "year": "2020",
      "venue": "2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
      "authors": "Tang G, Kumar N, Michmizos K P",
      "orig_title": "Reinforcement co-learning of deep and spiking neural networks for energy-efficient mapless navigation with neuromorphic hardware",
      "paper_id": "2003.01157v2"
    },
    {
      "index": 44,
      "title": "Population-coding and dynamic-neurons improved spiking actor network for reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2106.07854",
      "authors": "Zhang D, Zhang T, Jia S, et al."
    },
    {
      "index": 45,
      "title": "Multi-Scale Dynamic Coding Improved Spiking Actor Network for Reinforcement Learning",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Zhang D, Zhang T, Jia S, et al.",
      "orig_title": "Multiscale Dynamic Coding improved Spiking Actor Network for Reinforcement Learning",
      "paper_id": "2106.07854v3"
    },
    {
      "index": 46,
      "title": "Connectome: How the brain‚Äôs wiring makes us who we are",
      "abstract": "",
      "year": "2012",
      "venue": "HMH",
      "authors": "Seung S"
    },
    {
      "index": 47,
      "title": "The complete connectome of a learning and memory centre in an insect brain",
      "abstract": "",
      "year": "2017",
      "venue": "Nature",
      "authors": "Eichler K, Li F, Litwin-Kumar A, et al."
    },
    {
      "index": 48,
      "title": "A connectome of a learning and memory center in the adult Drosophila brain",
      "abstract": "",
      "year": "2017",
      "venue": "Elife",
      "authors": "Takemura S, Aso Y, Hige T, et al."
    },
    {
      "index": 49,
      "title": "Structural properties of the Caenorhabditis elegans neuronal network",
      "abstract": "",
      "year": "2011",
      "venue": "PLoS computational biology",
      "authors": "Varshney L R, Chen B L, Paniagua E, et al."
    },
    {
      "index": 50,
      "title": "The structure of the nervous system of the nematode Caenorhabditis elegans: the mind of a worm",
      "abstract": "",
      "year": "1986",
      "venue": "Phil. Trans. R. Soc. Lond",
      "authors": "White J G, Southgate E, Thomson J N, et al."
    },
    {
      "index": 51,
      "title": "Weight Agnostic Neural Networks",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in neural information processing systems",
      "authors": "Gaier A, Ha D",
      "orig_title": "Weight agnostic neural networks",
      "paper_id": "1906.04358v2"
    },
    {
      "index": 52,
      "title": "Morphometric study of human cerebral cortex development",
      "abstract": "",
      "year": "1990",
      "venue": "Neuropsychologia",
      "authors": "Huttenlocher P R"
    },
    {
      "index": 53,
      "title": "Brain development and the role of experience in the early years",
      "abstract": "",
      "year": "2009",
      "venue": "Zero to three",
      "authors": "Tierney A L, Nelson III C A"
    },
    {
      "index": 54,
      "title": "Neural connections: Some you use, some you lose",
      "abstract": "",
      "year": "1999",
      "venue": "The Phi Delta Kappan",
      "authors": "Bruer J T"
    },
    {
      "index": 55,
      "title": "Theoretical neuroscience: computational and mathematical modeling of neural systems",
      "abstract": "",
      "year": "2003",
      "venue": "Journal of Cognitive Neuroscience",
      "authors": "Dayan P, Abbott L F"
    },
    {
      "index": 56,
      "title": "Truenorth: Design and tool flow of a 65 mw 1 million neuron programmable neurosynaptic chip",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE transactions on computer-aided design of integrated circuits and systems",
      "authors": "Akopyan F, Sawada J, Cassidy A, et al."
    },
    {
      "index": 57,
      "title": "Loihi: A neuromorphic manycore processor with on-chip learning",
      "abstract": "",
      "year": "2018",
      "venue": "Ieee Micro",
      "authors": "Davies M, Srinivasa N, Lin T H, et al."
    },
    {
      "index": 58,
      "title": "Antithetic acceleration of Monte Carlo integration in Bayesian inference",
      "abstract": "",
      "year": "1988",
      "venue": "Journal of Econometrics",
      "authors": "Geweke J"
    },
    {
      "index": 59,
      "title": "Mirrored sampling and sequential selection for evolution strategies",
      "abstract": "",
      "year": "2010",
      "venue": "International Conference on Parallel Problem Solving from Nature",
      "authors": "Brockhoff D, Auger A, Hansen N, et al."
    },
    {
      "index": 60,
      "title": "Evolution strategies as a scalable alternative to reinforcement learning",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1703.03864",
      "authors": "Salimans T, Ho J, Chen X, et al."
    },
    {
      "index": 61,
      "title": "Openai gym",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1606.01540",
      "authors": "Brockman G, Cheung V, Pettersson L, et al."
    },
    {
      "index": 62,
      "title": "Mujoco: A physics engine for model-based control",
      "abstract": "",
      "year": "2012",
      "venue": "2012 IEEE/RSJ international conference on intelligent robots and systems",
      "authors": "Todorov E, Erez T, Tassa Y"
    },
    {
      "index": 63,
      "title": "Openai spinning up",
      "abstract": "",
      "year": "2018",
      "venue": "GitHub, GitHub repository",
      "authors": "Achiam J"
    },
    {
      "index": 64,
      "title": "On-policy trust region policy optimisation with replay buffers",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1901.06212",
      "authors": "Kangin D, Pugeault N"
    },
    {
      "index": 65,
      "title": "Deep Reinforcement Learning that Matters",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "Henderson P, Islam R, Bachman P, et al.",
      "orig_title": "Deep reinforcement learning that matters",
      "paper_id": "1709.06560v3"
    },
    {
      "index": 66,
      "title": "DIET-SNN: A low-latency spiking neural network with direct input encoding and leakage and threshold optimization",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Rathi N, Roy K"
    },
    {
      "index": 67,
      "title": "1.1 computing‚Äôs energy problem (and what we can do about it)",
      "abstract": "",
      "year": "2014",
      "venue": "2014 IEEE International Solid-State Circuits Conference Digest of Technical Papers (ISSCC)",
      "authors": "Horowitz M"
    }
  ]
}