{
  "paper_id": "2107.05825v1",
  "title": "Recent Advances in Leveraging Human Guidance for Sequential Decision-Making Tasks",
  "abstract": "Abstract\nA longstanding goal of artificial intelligence is to create artificial agents capable of learning to perform tasks that require sequential decision making.\nImportantly, while it is the artificial agent that learns and acts, it is still up to humans to specify the particular task to be performed.\nClassical task-specification approaches typically involve humans providing stationary reward functions or explicit demonstrations of the desired tasks.\nHowever, there has recently been a great deal of research energy invested in exploring alternative ways in which humans may guide learning agents that may, e.g., be more suitable for certain tasks or require less human effort.\nThis survey provides a high-level overview of five recent machine learning frameworks that primarily rely on human guidance apart from pre-specified reward functions or conventional, step-by-step action demonstrations.\nWe review the motivation, assumptions, and implementation of each framework, and we discuss possible future research directions.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Apprenticeship learning via inverse reinforcement learning",
      "abstract": "",
      "year": "2004",
      "venue": "Twenty-First International Conference on Machine learning (ICML)",
      "authors": "Abbeel P, Ng AY"
    },
    {
      "index": 1,
      "title": "Autonomous helicopter aerobatics through apprenticeship learning",
      "abstract": "",
      "year": "2010",
      "venue": "The International Journal of Robotics Research",
      "authors": "Abbeel P, Coates A, Ng AY"
    },
    {
      "index": 2,
      "title": "Agent-Agnostic Human-in-the-Loop Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS Workshop on the Future of Interactive Learning Machines",
      "authors": "Abel D, Salvatier J, Stuhlmüller A, Evans O",
      "orig_title": "Agent-agnostic human-in-the-loop reinforcement learning",
      "paper_id": "1701.04079v1"
    },
    {
      "index": 3,
      "title": "Trajectory-tracking and path-following of underactuated autonomous vehicles with parametric modeling uncertainty",
      "abstract": "",
      "year": "2007",
      "venue": "IEEE Transactions on Automatic Control",
      "authors": "Aguiar AP, Hespanha JP"
    },
    {
      "index": 4,
      "title": "Accelerated Robot Learning via Human Brain Signals",
      "abstract": "",
      "year": "2020",
      "venue": "2020 IEEE International Conference on Robotics and Automation (ICRA)",
      "authors": "Akinola I, Wang Z, Shi J, He X, Lapborisuth P, Xu J, Watkins-Valls D, Sajda P, Allen P",
      "orig_title": "Accelerated robot learning via human brain signals",
      "paper_id": "1910.00682v2"
    },
    {
      "index": 5,
      "title": "Programming by feedback",
      "abstract": "",
      "year": "2014",
      "venue": "International Conference on Machine Learning (ICML)",
      "authors": "Akrour R, Schoenauer M, Sebag M, Souplet JC"
    },
    {
      "index": 6,
      "title": "Interactive teaching strategies for agent training",
      "abstract": "",
      "year": "2016",
      "venue": "Twenty-Fifth International Joint Conference on Artificial Intelligence",
      "authors": "Amir O, Kamar E, Kolobov A, Grosz BJ"
    },
    {
      "index": 7,
      "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
      "abstract": "",
      "year": "2017",
      "venue": "34th International Conference on Machine Learning-Volume 70",
      "authors": "Andreas J, Klein D, Levine S",
      "orig_title": "Modular multitask reinforcement learning with policy sketches",
      "paper_id": "1611.01796v2"
    },
    {
      "index": 8,
      "title": "Dqn-tamer: Human-in-the-loop reinforcement learning with intractable feedback",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:181011748",
      "authors": "Arakawa R, Kobayashi S, Unno Y, Tsuboi Y, Maeda Si"
    },
    {
      "index": 9,
      "title": "A survey of robot learning from demonstration",
      "abstract": "",
      "year": "2009",
      "venue": "Robotics and autonomous systems",
      "authors": "Argall BD, Chernova S, Veloso M, Browning B"
    },
    {
      "index": 10,
      "title": "A Survey of Inverse Reinforcement Learning: Challenges, Methods and Progress",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:180606877",
      "authors": "Arora S, Doshi P",
      "orig_title": "A survey of inverse reinforcement learning: Challenges, methods and progress",
      "paper_id": "1806.06877v3"
    },
    {
      "index": 11,
      "title": "Deep Reinforcement Learning from Policy-Dependent Human Feedback",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:190204257",
      "authors": "Arumugam D, Lee JK, Saskin S, Littman ML",
      "orig_title": "Deep reinforcement learning from policy-dependent human feedback",
      "paper_id": "1902.04257v1"
    },
    {
      "index": 12,
      "title": "Playing hard exploration games by watching YouTube",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Aytar Y, Pfaff T, Budden D, Paine T, Wang Z, de Freitas N",
      "orig_title": "Playing hard exploration games by watching youtube",
      "paper_id": "1805.11592v2"
    },
    {
      "index": 13,
      "title": "The Option-Critic Architecture",
      "abstract": "",
      "year": "2017",
      "venue": "Thirty-First AAAI Conference on Artificial Intelligence",
      "authors": "Bacon PL, Harb J, Precup D",
      "orig_title": "The option-critic architecture",
      "paper_id": "1609.05140v2"
    },
    {
      "index": 14,
      "title": "A framework for behavioural cloning",
      "abstract": "",
      "year": "1999",
      "venue": "Machine intelligence",
      "authors": "Bain M, Sommut C"
    },
    {
      "index": 15,
      "title": "Transmission of aggression through imitation of aggressive models",
      "abstract": "",
      "year": "1961",
      "venue": "The Journal of Abnormal and Social Psychology",
      "authors": "Bandura A, Ross D, Ross SA"
    },
    {
      "index": 16,
      "title": "Recent advances in hierarchical reinforcement learning",
      "abstract": "",
      "year": "2003",
      "venue": "Discrete event dynamic systems",
      "authors": "Barto AG, Mahadevan S"
    },
    {
      "index": 17,
      "title": "The arcade learning environment: An evaluation platform for general agents",
      "abstract": "",
      "year": "2013",
      "venue": "Journal of Artificial Intelligence Research",
      "authors": "Bellemare MG, Naddaf Y, Veness J, Bowling M"
    },
    {
      "index": 18,
      "title": "Humanoid robot learning and game playing using pc-based vision",
      "abstract": "",
      "year": "2002",
      "venue": "IEEE/RSJ international conference on intelligent robots and systems",
      "authors": "Bentivegna DC, Ude A, Atkeson CG, Cheng G"
    },
    {
      "index": 19,
      "title": "Learning human ergonomic preferences for handovers",
      "abstract": "",
      "year": "2018",
      "venue": "2018 IEEE International Conference on Robotics and Automation (ICRA)",
      "authors": "Bestick A, Pandya R, Bajcsy R, Dragan AD"
    },
    {
      "index": 20,
      "title": "Preference learning along multiple criteria: A game-theoretic perspective",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Bhatia K, Pananjady A, Bartlett P, Dragan A, Wainwright MJ"
    },
    {
      "index": 21,
      "title": "Batch Active Preference-Based Learning of Reward Functions",
      "abstract": "",
      "year": "2018",
      "venue": "Conference on Robot Learning",
      "authors": "Biyik E, Sadigh D",
      "orig_title": "Batch active preference-based learning of reward functions",
      "paper_id": "1810.04303v1"
    },
    {
      "index": 22,
      "title": "The Green Choice: Learning and Influencing Human Decisions on Shared Roads",
      "abstract": "",
      "year": "2019",
      "venue": "2019 IEEE 58th Conference on Decision and Control (CDC)",
      "authors": "Bıyık E, Lazar DA, Sadigh D, Pedarsani R",
      "orig_title": "The green choice: Learning and influencing human decisions on shared roads",
      "paper_id": "1904.02209v2"
    },
    {
      "index": 23,
      "title": "Active Preference-Based Gaussian Process Regression for Reward Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Robotics: Science and Systems (RSS)",
      "authors": "Biyik E, Huynh N, Kochenderfer MJ, Sadigh D",
      "orig_title": "Active preference-based gaussian process regression for reward learning",
      "paper_id": "2005.02575v2"
    },
    {
      "index": 24,
      "title": "Learning Reward Functions from Diverse Sources of Human Feedback: Optimally Integrating Demonstrations and Preferences",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:200614091",
      "authors": "Bıyık E, Losey DP, Palan M, Landolfi NC, Shevchuk G, Sadigh D",
      "orig_title": "Learning reward functions from diverse sources of human feedback: Optimally integrating demonstrations and preferences",
      "paper_id": "2006.14091v2"
    },
    {
      "index": 25,
      "title": "Infinite time horizon maximum causal entropy inverse reinforcement learning",
      "abstract": "",
      "year": "2014",
      "venue": "53rd IEEE Conference on Decision and Control",
      "authors": "Bloem M, Bambos N"
    },
    {
      "index": 26,
      "title": "End to End Learning for Self-Driving Cars",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:160407316",
      "authors": "Bojarski M, Del Testa D, Dworakowski D, Firner B, Flepp B, Goyal P, Jackel LD, Monfort M, Muller U, Zhang J, et al.",
      "orig_title": "End to end learning for self-driving cars",
      "paper_id": "1604.07316v1"
    },
    {
      "index": 27,
      "title": "Salient Object Detection: A Benchmark",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE transactions on image processing",
      "authors": "Borji A, Cheng MM, Jiang H, Li J",
      "orig_title": "Salient object detection: A benchmark",
      "paper_id": "1501.02741v2"
    },
    {
      "index": 28,
      "title": "Emotion and reinforcement: affective facial expressions facilitate robot learning",
      "abstract": "",
      "year": "2007",
      "venue": "Artifical intelligence for human computing",
      "authors": "Broekens J"
    },
    {
      "index": 29,
      "title": "Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Machine Learning",
      "authors": "Brown D, Goo W, Nagarajan P, Niekum S",
      "orig_title": "Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations",
      "paper_id": "1904.06387v5"
    },
    {
      "index": 30,
      "title": "Preference-based evolutionary direct policy search",
      "abstract": "",
      "year": "2013",
      "venue": "ICRA Workshop on Autonomous Learning",
      "authors": "Busa-Fekete R, Szörényi B, Weng P, Cheng W, Hüllermeier E"
    },
    {
      "index": 31,
      "title": "Intrinsic and extrinsic effects on image memorability",
      "abstract": "",
      "year": "2015",
      "venue": "Vision research",
      "authors": "Bylinskii Z, Isola P, Bainbridge C, Torralba A, Oliva A"
    },
    {
      "index": 32,
      "title": "Mit saliency benchmark",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Bylinskii Z, Judd T, Borji A, Itti L, Durand F, Oliva A, Torralba A"
    },
    {
      "index": 33,
      "title": "Where should saliency models look next?",
      "abstract": "",
      "year": "2016",
      "venue": "European Conference on Computer Vision",
      "authors": "Bylinskii Z, Recasens A, Borji A, Oliva A, Torralba A, Durand F"
    },
    {
      "index": 34,
      "title": "What do different evaluation metrics tell us about saliency models?",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE transactions on pattern analysis and machine intelligence",
      "authors": "Bylinskii Z, Judd T, Oliva A, Torralba A, Durand F",
      "orig_title": "What do different evaluation metrics tell us about saliency models?",
      "paper_id": "1604.03605v2"
    },
    {
      "index": 35,
      "title": "Learning by imitation: A hierarchical approach",
      "abstract": "",
      "year": "1998",
      "venue": "Behavioral and brain sciences",
      "authors": "Byrne RW, Russon AE"
    },
    {
      "index": 36,
      "title": "Incremental learning of gestures by imitation in a humanoid robot",
      "abstract": "",
      "year": "2007",
      "venue": "ACM/IEEE international conference on Human-robot interaction",
      "authors": "Calinon S, Billard A"
    },
    {
      "index": 37,
      "title": "Realtime multi-person 2d pose estimation using part affinity fields",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Cao Z, Simon T, Wei SE, Sheikh Y"
    },
    {
      "index": 38,
      "title": "Trajectory tracking control of a four-wheel differentially driven mobile robot",
      "abstract": "",
      "year": "1999",
      "venue": "1999 IEEE International Conference on Robotics and Automation",
      "authors": "Caracciolo L, De Luca A, Iannitti S"
    },
    {
      "index": 39,
      "title": "Policy shaping with human teachers",
      "abstract": "",
      "year": "2015",
      "venue": "24th International Conference on Artificial Intelligence",
      "authors": "Cederborg T, Grover I, Isbell CL, Thomaz AL"
    },
    {
      "index": 40,
      "title": "Injective State-Image Mapping facilitates Visual Adversarial Imitation Learning",
      "abstract": "",
      "year": "2019",
      "venue": "2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)",
      "authors": "Chaudhury S, Kimura D, Munawar A, Tachibana R",
      "orig_title": "Injective state-image mapping facilitates visual adversarial imitation learning",
      "paper_id": "1810.01108v2"
    },
    {
      "index": 41,
      "title": "Gaze training by modulated dropout improves imitation learning",
      "abstract": "",
      "year": "2019",
      "venue": "2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
      "authors": "Chen Y, Liu C, Tai L, Liu M, Shi BE"
    },
    {
      "index": 42,
      "title": "Robot Navigation in Crowds by Graph Convolutional Networks with Attention Learned from Human Gaze",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Robotics and Automation Letters",
      "authors": "Chen Y, Liu C, Shi BE, Liu M",
      "orig_title": "Robot navigation in crowds by graph convolutional networks with attention learned from human gaze",
      "paper_id": "1909.10400v1"
    },
    {
      "index": 43,
      "title": "Deep Reinforcement Learning from Human Preferences",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Christiano PF, Leike J, Brown T, Martic M, Legg S, Amodei D",
      "orig_title": "Deep reinforcement learning from human preferences",
      "paper_id": "1706.03741v4"
    },
    {
      "index": 44,
      "title": "End-to-end Driving via Conditional Imitation Learning",
      "abstract": "",
      "year": "2018",
      "venue": "2018 IEEE International Conference on Robotics and Automation (ICRA)",
      "authors": "Codevilla F, Miiller M, López A, Koltun V, Dosovitskiy A",
      "orig_title": "End-to-end driving via conditional imitation learning",
      "paper_id": "1710.02410v2"
    },
    {
      "index": 45,
      "title": "Active reward learning from critiques",
      "abstract": "",
      "year": "2018",
      "venue": "2018 IEEE International Conference on Robotics and Automation (ICRA)",
      "authors": "Cui Y, Niekum S"
    },
    {
      "index": 46,
      "title": "The EMPATHIC Framework for Task Learning from Implicit Human Feedback",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:200913649",
      "authors": "Cui Y, Zhang Q, Allievi A, Stone P, Niekum S, Knox WB",
      "orig_title": "The empathic framework for task learning from implicit human feedback",
      "paper_id": "2009.13649v3"
    },
    {
      "index": 47,
      "title": "How do drivers allocate their potential attention? driving fixation prediction via convolutional neural networks",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "Deng T, Yan H, Qin L, Ngo T, Manjunath B"
    },
    {
      "index": 48,
      "title": "Hierarchical reinforcement learning with the maxq value function decomposition",
      "abstract": "",
      "year": "2000",
      "venue": "Journal of artificial intelligence research",
      "authors": "Dietterich TG"
    },
    {
      "index": 49,
      "title": "Learning Actionable Representations from Visual Observations",
      "abstract": "",
      "year": "2018",
      "venue": "2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
      "authors": "Dwibedi D, Tompson J, Lynch C, Sermanet P",
      "orig_title": "Learning actionable representations from visual observations",
      "paper_id": "1808.00928v3"
    },
    {
      "index": 50,
      "title": "Imitating Latent Policies from Observation",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:180507914",
      "authors": "Edwards AD, Sahni H, Schroeker Y, Isbell CL",
      "orig_title": "Imitating latent policies from observation",
      "paper_id": "1805.07914v3"
    },
    {
      "index": 51,
      "title": "Survey of imitation learning for robotic manipulation",
      "abstract": "",
      "year": "2019",
      "venue": "International Journal of Intelligent Robotics and Applications",
      "authors": "Fang B, Jia S, Guo D, Xu M, Wen S, Sun F"
    },
    {
      "index": 52,
      "title": "Pan Z (2009) Motion capture in robotics review. In: 2009 IEEE International Conference on Control and Automation",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": ""
    },
    {
      "index": 53,
      "title": "Abbeel P (2016) Guided cost learning: Deep inverse optimal control via policy optimization. In: International Conference on Machine Learning",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 54,
      "title": "Stoica I (2018) Parametrized hierarchical procedures for neural programming. International Conference on Learning Representations 2018",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 55,
      "title": "Goldberg K (2019) Multi-task hierarchical imitation learning for home automation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 56,
      "title": "Rao RP (2010) Imitation learning with hierarchical actions. In: 2010 IEEE 9th International Conference on Development and Learning",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 57,
      "title": "Levine S (2018) Learning robust rewards with adverserial inverse reinforcement learning. In: International Conference on Learning Representations",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 58,
      "title": "Park SH (2012) Preference-based reinforcement learning: a formal framework and a policy iteration algorithm. Machine learning 89(1-2):123–156",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": ""
    },
    {
      "index": 59,
      "title": "Makar R (2006) Hierarchical multi-agent reinforcement learning. Autonomous Agents and Multi-Agent Systems 13(2):197–229",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": ""
    },
    {
      "index": 60,
      "title": "et al. (2016) A machine learning approach to visual perception of forest trails for mobile robots. IEEE Robotics and Automation Letters 1(2):661–667",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 61,
      "title": "Waytowich NR (2019) Efficiently combining human demonstrations and interventions for safe training of autonomous systems in real-time",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 62,
      "title": "Niekum S (2019) One-shot learning of multi-step tasks from observation via activity localization in auxiliary video",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 63,
      "title": "Bengio Y (2014) Generative adversarial nets. In: Advances in neural information processing systems",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 64,
      "title": "Goswami U (2008) Cognitive development: The learning brain",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 65,
      "title": "Thomaz AL (2013) Policy shaping: Integrating human feedback with reinforcement learning. In: Advances in neural information processing systems",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 66,
      "title": "Lopes M (2014) Interactive learning from unlabeled instructions",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 67,
      "title": "Babuska R (2012) A survey of actor-critic reinforcement learning: Standard and natural policy gradients. IEEE Transactions on Systems",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": ""
    },
    {
      "index": 68,
      "title": "Campbell M (2019) Hybrid reinforcement learning with expert state sequences. In: Proceedings of the AAAI Conference on Artificial Intelligence",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 69,
      "title": "Levine S (2018) Learning invariant feature spaces to transfer skills with reinforcement learning",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 70,
      "title": "Hausman K (2020) Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning. In: Conference on Robot Learning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 71,
      "title": "Russell S (2016) Cooperative inverse reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 72,
      "title": "Stone P (2017) Grounded action transformation for robot learning in simulation",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 73,
      "title": "Lim JJ (2017) Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 74,
      "title": "Pugeault N (2019) Understanding and visualizing deep visual saliency models",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 75,
      "title": "Precup D (2018a) Optiongan: Learning joint reward-policy options using generative adversarial inverse reinforcement learning",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 76,
      "title": "Meger D (2018b) Deep reinforcement learning that matters. In: Proceedings of the AAAI Conference on Artificial Intelligence",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 77,
      "title": "Taylor ME (2019) A survey and critique of multiagent deep reinforcement learning. Autonomous Agents and Multi-Agent Systems 33(6):750–797",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 78,
      "title": "Ermon S (2016) Generative adversarial imitation learning. In: Advances in Neural Information Processing Systems",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 79,
      "title": "Austerweil JL (2016) Showing versus doing: Teaching by demonstration. In: Advances in neural information processing systems",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 80,
      "title": "Komura T (2016) A deep learning framework for character motion synthesis and editing. ACM Transactions on Graphics (TOG) 35(4):138",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 81,
      "title": "Sabharwal A (2017) Tabletgaze: dataset and analysis for unconstrained appearance-based gaze estimation in mobile tablets",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 82,
      "title": "Sato Y (2020) Mutual context network for jointly estimating egocentric gaze and action. IEEE Transactions on Image Processing 29:7795–7806",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 83,
      "title": "Jayne C (2017) Imitation learning: A survey of learning methods. ACM Computing Surveys (CSUR) 50(2):21",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 84,
      "title": "Amodei D (2018) Reward learning from human preferences and demonstrations in atari. In: Advances in Neural Information Processing Systems",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 85,
      "title": "Schaal S (2002) Movement imitation with nonlinear dynamical systems in humanoid robots",
      "abstract": "",
      "year": "2002",
      "venue": "",
      "authors": ""
    },
    {
      "index": 86,
      "title": "Schaal S (2011) Trajectory formation for imitation with nonlinear dynamical systems",
      "abstract": "",
      "year": "2001",
      "venue": "",
      "authors": ""
    },
    {
      "index": 87,
      "title": "Stone P (2001) A social reinforcement learning agent. In: Proceedings of the fifth international conference on Autonomous agents",
      "abstract": "",
      "year": "2001",
      "venue": "",
      "authors": ""
    },
    {
      "index": 88,
      "title": "Niebur E (1998) A model of saliency-based visual attention for rapid scene analysis",
      "abstract": "",
      "year": "1998",
      "venue": "",
      "authors": ""
    },
    {
      "index": 89,
      "title": "et al. (2019) Human-level performance in 3d multiplayer games with population-based reinforcement learning. Science 364(6443):859–865",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 90,
      "title": "Yu Y (2020) Offline imitation learning with a misspecified simulator. Advances in Neural Information Processing Systems 33",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 91,
      "title": "Gay G (2017) Accurately interpreting clickthrough data as implicit feedback. In: ACM SIGIR Forum",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 92,
      "title": "International Foundation for Autonomous Agents and Multiagent Systems",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 93,
      "title": "Dasgupta S (2018) Internal model from observations for reward shaping. arXiv preprint arXiv:180601267",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 94,
      "title": "Sanchez-Gonzalez A",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 95,
      "title": "Stone P (2009) Interactively shaping agents via human reinforcement: The tamer framework",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": ""
    },
    {
      "index": 96,
      "title": "International Foundation for Autonomous Agents and Multiagent Systems",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 97,
      "title": "International Foundation for Autonomous Agents and Multiagent Systems",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": ""
    },
    {
      "index": 98,
      "title": "Peters J (2013) Reinforcement learning in robotics: A survey. The International Journal of Robotics Research 32(11):1238–1274",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 99,
      "title": "Barto A (2012) Robot learning from demonstration by constructing skill trees. The International Journal of Robotics Research 31(3):360–375",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": ""
    },
    {
      "index": 100,
      "title": "URL https://openreview.net/forum?id=Hk4fpoA5Km",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 101,
      "title": "Torralba A (2016) Eye tracking for everyone. In: Proceedings of the IEEE conference on computer vision and pattern recognition",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 102,
      "title": "Goldberg K (2017) Ddco: Discovery of deep continuous options for robot learning from demonstrations. In: Conference on Robot Learning",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 103,
      "title": "Peters J (2015) Towards learning hierarchical skills for multi-phase manipulation tasks",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 104,
      "title": "Tenenbaum J (2016) Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 105,
      "title": "Goldberg K (2016) Robot grasping in clutter: Using a hierarchy of supervisors for learning from demonstrations",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 106,
      "title": "Daumé H (2018) Hierarchical imitation and reinforcement learning. In: International Conference on Machine Learning",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 107,
      "title": "Hinton G (2015) Deep learning. nature 521(7553):436",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 108,
      "title": "Abbeel P (2016) End-to-end training of deep visuomotor policies. The Journal of Machine Learning Research 17(1):1334–1373",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 109,
      "title": "Kushman N (2016a) Neural program lattices. International Conference on Learning Representations 2018",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 110,
      "title": "Hung H (2016b) Using informative behavior to increase engagement while learning from human reward",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 111,
      "title": "Yuille AL (2014) The secrets of salient object segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 112,
      "title": "Rehg JM (2018) In the eye of beholder: Joint learning of gaze and actions in first person video",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 113,
      "title": "Shi BE (2019) A gaze model improves autonomous driving. In: Proceedings of the 11th ACM Symposium on Eye Tracking Research & Applications",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 114,
      "title": "Liu Y (2020) Hilonet: Hierarchical imitation learning from non-aligned observations. arXiv preprint arXiv:201102671",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 115,
      "title": "Levine S (2018) Imitation from observation: Learning to imitate behaviors from raw video via context translation",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 116,
      "title": "Roberts DL (2014) Learning something from nothing: Leveraging implicit human feedback strategies",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 117,
      "title": "Roberts DL (2016) Learning behaviors via human-delivered discrete feedback: modeling implicit feedback strategies to speed up learning",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 118,
      "title": "Littman ML (2017) Interactive learning from policy-dependent human feedback",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 119,
      "title": "Bowling M (2018) Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 120,
      "title": "Sminchisescu C (2014) Actions in the eye: Dynamic gaze datasets and learnt saliency models for visual recognition",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 121,
      "title": "Heess N (2017) Learning human behaviors from motion capture by adversarial imitation. arXiv preprint arXiv:170702201",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 122,
      "title": "Hebert M (2016) Shuffle and learn: unsupervised learning using temporal order verification. In: European conference on computer vision",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 123,
      "title": "et al. (2015) Human-level control through deep reinforcement learning. Nature 518(7540):529–533",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 124,
      "title": "Miller D (2015) Interactive hierarchical task learning from a single demonstration",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 125,
      "title": "Levine S (2018) Data-efficient hierarchical reinforcement learning. In: Advances in neural information processing systems",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 126,
      "title": "Levine S (2017) Combining self-supervised learning and imitation for vision-based rope manipulation",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 127,
      "title": "Chetouani M (2020) Interactively shaping robot behaviour with unlabeled human instructions. Auton Agents Multi Agent Syst 34(2):35",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 128,
      "title": "Kawato M (2004) Learning from demonstration and adaptation of biped locomotion. Robotics and autonomous systems 47(2-3):79–91",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 129,
      "title": "Barto AG (2015) Learning grounded finite-state representations from unstructured demonstrations",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 130,
      "title": "et al. (2018) An algorithmic perspective on imitation learning. Foundations and Trends® in Robotics 7(1-2):1–179",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 131,
      "title": "Sadigh D (2019) Learning reward functions by integrating human demonstrations and preferences. In: Proceedings of Robotics: Science and Systems (RSS)",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 132,
      "title": "(2018) Predicting the driver’s focus of attention: the dr (eye) ve project",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 133,
      "title": "Ferrari V (2014) Training object class detectors from eye tracking data. In: European conference on computer vision",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 134,
      "title": "In: Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 135,
      "title": "Hilliges O (2018) Deep pictorial gaze estimation. In: Proceedings of the European Conference on Computer Vision (ECCV)",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 136,
      "title": "Darrell T (2018) Zero-shot visual imitation. In: International Conference on Learning Representations",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 137,
      "title": "Stone P (2020) Ridm: Reinforced inverse dynamics modeling for learning from a single observed demonstration",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 138,
      "title": "van de Panne M (2018a) Deepmimic: Example-guided deep reinforcement learning of physics-based character skills",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 139,
      "title": "Levine S (2018b) Sfv: Reinforcement learning of physical skills from videos. In: SIGGRAPH Asia 2018 Technical Papers",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 140,
      "title": "Sutton RS (2011) Online human training of a myoelectric prosthesis controller via actor-critic reinforcement learning",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 141,
      "title": "Neumann G (2018) Sample and feedback efficient hierarchical reinforcement learning from human preferences",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 142,
      "title": "Pomerleau DA (1989) Alvinn: An autonomous land vehicle in a neural network",
      "abstract": "",
      "year": "1989",
      "venue": "",
      "authors": ""
    },
    {
      "index": 143,
      "title": "Yip MC (2019) Adversarial imitation via variational inverse reinforcement learning. In: International Conference on Learning Representations",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 144,
      "title": "Malik J (2020) State-only imitation learning for dexterous manipulation. arXiv preprint arXiv:200404650",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 145,
      "title": "Dani A (2018) Gaze and motion information fusion for human intention inference",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 146,
      "title": "De Freitas N (2015) Neural programmer-interpreters. arXiv preprint arXiv:151106279",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 147,
      "title": "Walter MR (2020) Concurrent training improves the performance of behavioral cloning from observation. arXiv preprint arXiv:200801205",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 148,
      "title": "Bagnell D (2010) Efficient reductions for imitation learning",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 149,
      "title": "Bagnell D (2011) A reduction of imitation learning and structured prediction to no-regret online learning",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 150,
      "title": "Seshia SA (2017) Active preference-based learning of reward functions. In: Robotics: Science and Systems",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 151,
      "title": "Niekum S (2020) Efficiently guiding imitation learning algorithms with human gaze. arXiv preprint arXiv:200212500",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 152,
      "title": "Kawaguchi A (2019) Sample efficient imitation learning for continuous control. In: International Conference on Learning Representations",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 153,
      "title": "International Foundation for Autonomous Agents and Multiagent Systems",
      "abstract": "",
      "year": "2069",
      "venue": "",
      "authors": ""
    },
    {
      "index": 154,
      "title": "Schaal S (1999) Is imitation learning the route to humanoid robots? Trends in cognitive sciences 3(6):233–242",
      "abstract": "",
      "year": "1999",
      "venue": "",
      "authors": ""
    },
    {
      "index": 155,
      "title": "Finn C (2020) Reinforcement learning with videos: Combining offline observations with interaction. arXiv preprint arXiv:201106507",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 156,
      "title": "Moritz P (2015) Trust region policy optimization. In: International Conference on Machine Learning",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 157,
      "title": "Brain G (2018) Time-contrastive networks: Self-supervised learning from video",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 158,
      "title": "International Foundation for Autonomous Agents and Multiagent Systems",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 159,
      "title": "Kitani KM (2018) Directed-info gail: Learning hierarchical policies from unsegmented demonstrations using directed information",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 160,
      "title": "Zhuang N (2018) Egocentric activity prediction via event modulated attention. In: Proceedings of the European Conference on Computer Vision (ECCV)",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 161,
      "title": "Webb R (2017) Learning from simulated and unsupervised images through adversarial training",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 162,
      "title": "Stentz A (2010) Learning from demonstration for autonomous navigation in complex unstructured terrain",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 163,
      "title": "Van Den Driessche G",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 164,
      "title": "et al. (2017) Mastering the game of go without human knowledge. Nature 550(7676):354",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 165,
      "title": "et al. (2018) A general reinforcement learning algorithm that masters chess",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 166,
      "title": "Skinner BF (1938) The behavior of organisms: An experimental analysis",
      "abstract": "",
      "year": "1938",
      "venue": "",
      "authors": ""
    },
    {
      "index": 167,
      "title": "Sutskever I (2017) Third-person imitation learning. International Conference on Learning Representations",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 168,
      "title": "Lanz O (2019) Lsta: Long short-term attention for egocentric action recognition",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 169,
      "title": "Bagnell D (2019) Provably efficient imitation learning from observation alone. In: International Conference on Machine Learning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 170,
      "title": "Barto AG (1998) Reinforcement learning: An introduction",
      "abstract": "",
      "year": "1998",
      "venue": "",
      "authors": ""
    },
    {
      "index": 171,
      "title": "Barto AG (2018) Reinforcement learning: An introduction. MIT press",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 172,
      "title": "Singh S (1999) Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning. Artificial intelligence 112(1-2):181–211",
      "abstract": "",
      "year": "1999",
      "venue": "",
      "authors": ""
    },
    {
      "index": 173,
      "title": "Mansour Y (2000) Policy gradient methods for reinforcement learning with function approximation",
      "abstract": "",
      "year": "2000",
      "venue": "",
      "authors": ""
    },
    {
      "index": 174,
      "title": "Borji A (2019) Digging deeper into egocentric gaze prediction. In: 2019 IEEE Winter Conference on Applications of Computer Vision",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 175,
      "title": "Villaseñor-Pineda L (2010) Dynamic reward shaping: training a robot by voice. In: Ibero-American conference on artificial intelligence",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 176,
      "title": "Breazeal C (2008) Teachable robots: Understanding human teaching behavior to build more effective robot learners",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 177,
      "title": "Tassa Y (2012) Mujoco: A physics engine for model-based control. In: 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": ""
    },
    {
      "index": 178,
      "title": "Stone P (2018a) Behavioral cloning from observation. In: Proceedings of the 27th International Joint Conference on Artificial Intelligence",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 179,
      "title": "Stone P (2018b) Generative adversarial imitation from observation. arXiv preprint arXiv:180706158",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 180,
      "title": "Stone P (2019a) Sample-efficient adversarial imitation learning from observation. arXiv preprint arXiv:190607374",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 181,
      "title": "International Foundation for Autonomous Agents and Multiagent Systems",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 182,
      "title": "Stone P (2019c) Imitation learning from video by leveraging proprioception",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 183,
      "title": "Stone P (2019d) Recent advances in imitation learning from observation",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 184,
      "title": "Kavukcuoglu K (2017) Feudal networks for hierarchical reinforcement learning",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 185,
      "title": "et al. (2019) Grandmaster level in starcraft ii using multi-agent reinforcement learning. Nature 575(7782):350–354",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 186,
      "title": "Wei P (2019) 3d human pose machines with self-supervised learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 42(5):1069–1082",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 187,
      "title": "Deng W (2018) Deep visual domain adaptation: A survey. Neurocomputing 312:135–153",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 188,
      "title": "Borji A (2018) Revisiting video saliency: A large-scale benchmark and a new model",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 189,
      "title": "Freitas N (2016) Dueling network architectures for deep reinforcement learning. In: International Conference on Machine Learning",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": ""
    },
    {
      "index": 190,
      "title": "Stone P (2018) Deep tamer: Interactive agent shaping in high-dimensional state spaces",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 191,
      "title": "Dayan P (1992) Q-learning. Machine learning 8(3-4):279–292",
      "abstract": "",
      "year": "1992",
      "venue": "",
      "authors": ""
    },
    {
      "index": 192,
      "title": "Lawhern VJ (2018) Cycle-of-learning for autonomous systems from human interaction. arXiv preprint arXiv:180809572",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 193,
      "title": "Tadepalli P (2012) A bayesian approach for policy learning from trajectory preference queries. In: Advances in neural information processing systems",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": ""
    },
    {
      "index": 194,
      "title": "Neumann G (2016) Model-free preference-based reinforcement learning. In: Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 195,
      "title": "Fürnkranz J (2017) A survey of preference-based reinforcement learning methods. The Journal of Machine Learning Research 18(1):4945–4990",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 196,
      "title": "Bulling A (2015) Rendering of eyes for eye-shape registration and gaze estimation",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 197,
      "title": "Hausman K (2020) Learning to interactively learn and assist. In: Proceedings of the AAAI Conference on Artificial Intelligence",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 198,
      "title": "Ryoo MS (2020) Model-based behavioral cloning with future image similarity learning. In: Conference on Robot Learning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 199,
      "title": "Whitney D (2018) Predicting driver attention in critical situations. In: Asian conference on computer vision",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 200,
      "title": "Whitney D (2020) Periphery-fovea multi-resolution driving model guided by human attention",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 201,
      "title": "Savarese S (2018a) Neural task programming: Learning to generalize across hierarchical tasks",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 202,
      "title": "Sivakumar R (2020) Playing games with implicit human feedback. In: Workshop on Reinforcement Learning in Games",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 203,
      "title": "Zhao Q (2014) Predicting human gaze beyond pixels. Journal of vision 14(1):28–28",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 204,
      "title": "Wu S (2018b) Shared multi-task imitation learning for indoor self-navigation. In: 2018 IEEE Global Communications Conference (GLOBECOM)",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 205,
      "title": "Gao S (2018c) Gaze prediction in dynamic 360 immersive videos. In: proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 206,
      "title": "Gan C (2019) Imitation learning from observations by minimizing inverse dynamics disagreement. In: Advances in Neural Information Processing Systems",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 207,
      "title": "Kim JH (1999) Sliding mode control for trajectory tracking of nonholonomic wheeled mobile robots",
      "abstract": "",
      "year": "1999",
      "venue": "",
      "authors": ""
    },
    {
      "index": 208,
      "title": "Darrell T (2018) Bdd100k: A diverse driving video database with scalable annotation tooling. arXiv preprint arXiv:180504687",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 209,
      "title": "Ballard DH (2018a) Agil: Learning attention from human for visuomotor tasks. In: Proceedings of the European Conference on Computer Vision (ECCV)",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 210,
      "title": "Stone P (2019) Leveraging human guidance for deep reinforcement learning tasks",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 211,
      "title": "Hayhoe M (2020a) Human gaze assisted artificial intelligence: A review. In: IJCAI: proceedings of the conference",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 212,
      "title": "Ballard D (2020b) Atari-head: Atari human eye-tracking and demonstration dataset. In: Proceedings of the AAAI Conference on Artificial Intelligence",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 213,
      "title": "Bulling A (2015) Appearance-based gaze estimation in the wild. In: Proceedings of the IEEE conference on computer vision and pattern recognition",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 214,
      "title": "Bulling A (2017) Mpiigaze: Real-world dataset and deep appearance-based gaze estimation",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 215,
      "title": "Gao S (2018b) Saliency detection in 360 videos. In: Proceedings of the European Conference on Computer Vision (ECCV)",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 216,
      "title": "Efros AA (2017) Unpaired image-to-image translation using cycle-consistent adversarial networks",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 217,
      "title": "Dey AK (2008) Maximum entropy inverse reinforcement learning. In: AAAI",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 218,
      "title": "Dey AK (2010) Modeling interaction via the principle of maximum causal entropy. In: ICML",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 219,
      "title": "International Foundation for Autonomous Agents and Multiagent Systems",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 220,
      "title": "Pinheiro PO (2018) Reinforced imitation learning from observations. NeurIPS 2018 Workshop",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 221,
      "title": "Qu Y (2018) Gaze-informed egocentric action recognition for memory aid systems. IEEE Access 6:12894–12904",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    }
  ]
}