{
  "paper_id": "2110.14378v2",
  "title": "Towards artificial general intelligence via a multimodal foundation model",
  "abstract": "Abstract\nThe fundamental goal of artificial intelligence (AI) is to mimic the core cognitive activities of human. Despite tremendous success in the AI research, most of existing methods have only single-cognitive ability. To overcome this limitation and take a solid step towards artificial general intelligence (AGI), we develop a foundation model pre-trained with huge multimodal data, which can be quickly adapted for various downstream cognitive tasks. To achieve this goal, we propose to pre-train our foundation model by self-supervised learning with weak semantic correlation data crawled from the Internet and show that promising results can be obtained on a wide range of downstream tasks. Particularly, with the developed model-interpretability tools, we demonstrate that strong imagination ability is now possessed by our foundation model. We believe that our work makes a transformative stride towards AGI, from our common practice of “weak or narrow AI” to that of “strong or generalized AI”.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Artificial general intelligence: Concept, state of the art, and future prospects",
      "abstract": "",
      "year": "2014",
      "venue": "Journal of Artificial General Intelligence",
      "authors": "Goertzel, B."
    },
    {
      "index": 1,
      "title": "Deep Learning",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "LeCun, Y., Bengio, Y. & Hinton, G.",
      "orig_title": "Deep learning",
      "paper_id": "1807.07987v2"
    },
    {
      "index": 2,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "He, K., Zhang, X., Ren, S. & Sun, J.",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 3,
      "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1907.11692",
      "authors": "Liu, Y. et al.",
      "orig_title": "RoBERTa: A robustly optimized bert pretraining approach",
      "paper_id": "1907.11692v1"
    },
    {
      "index": 4,
      "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "Wang, A. et al.",
      "orig_title": "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
      "paper_id": "1804.07461v3"
    },
    {
      "index": 5,
      "title": "A simple neural network module for relational reasoning",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Santoro, A. et al."
    },
    {
      "index": 6,
      "title": "On the opportunities and risks of foundation models",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2108.07258",
      "authors": "Bommasani, R. et al."
    },
    {
      "index": 7,
      "title": "10 breakthrough technologies 2021",
      "abstract": "",
      "year": "2021",
      "venue": "https://www.technologyreview.com/2021/02/24/1014369/10-breakthrough-technologies-2021/",
      "authors": "Editors of MIT Technology Review."
    },
    {
      "index": 8,
      "title": "Language Models are Few-Shot Learners",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Brown, T. B. et al.",
      "orig_title": "Language models are few-shot learners",
      "paper_id": "2005.14165v4"
    },
    {
      "index": 9,
      "title": "Invariant visual representation by single neurons in the human brain",
      "abstract": "",
      "year": "2005",
      "venue": "Nature",
      "authors": "Quiroga, R. Q., Reddy, L., Kreiman, G., Koch, C. & Fried, I."
    },
    {
      "index": 10,
      "title": "Explicit encoding of multimodal percepts by single neurons in the human brain",
      "abstract": "",
      "year": "2009",
      "venue": "Current Biology",
      "authors": "Quian Quiroga, R., Kraskov, A., Koch, C. & Fried, I."
    },
    {
      "index": 11,
      "title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Li, X. et al.",
      "orig_title": "Oscar: Object-semantics aligned pre-training for vision-language tasks",
      "paper_id": "2004.06165v5"
    },
    {
      "index": 12,
      "title": "Learning Transferable Visual Models From Natural Language Supervision",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Machine Learning",
      "authors": "Radford, A. et al.",
      "orig_title": "Learning transferable visual models from natural language supervision",
      "paper_id": "2103.00020v1"
    },
    {
      "index": 13,
      "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1908.03557",
      "authors": "Li, L. H., Yatskar, M., Yin, D., Hsieh, C. & Chang, K.",
      "orig_title": "VisualBERT: A simple and performant baseline for vision and language",
      "paper_id": "1908.03557v1"
    },
    {
      "index": 14,
      "title": "Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Li, G., Duan, N., Fang, Y., Gong, M. & Jiang, D.",
      "orig_title": "Unicoder-VL: A universal encoder for vision and language by cross-modal pre-training",
      "paper_id": "1908.06066v3"
    },
    {
      "index": 15,
      "title": "VL-BERT: Pre-training of generic visual-linguistic representations",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Learning Representations",
      "authors": "Su, W. et al."
    },
    {
      "index": 16,
      "title": "UNITER: UNiversal Image-TExt Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Chen, Y.-C. et al.",
      "orig_title": "UNITER: Universal image-text representation learning",
      "paper_id": "1909.11740v3"
    },
    {
      "index": 17,
      "title": "M6: A Chinese Multimodal Pretrainer",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2103.00823",
      "authors": "Lin, J. et al.",
      "orig_title": "M6: A chinese multimodal pretrainer",
      "paper_id": "2103.00823v4"
    },
    {
      "index": 18,
      "title": "Learning fragment self-attention embeddings for image-text matching",
      "abstract": "",
      "year": "2019",
      "venue": "ACM International Conference on Multimedia",
      "authors": "Wu, Y., Wang, S., Song, G. & Huang, Q."
    },
    {
      "index": 19,
      "title": "Imram: Iterative matching with recurrent attention memory for cross-modal image-text retrieval",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Chen, H. et al."
    },
    {
      "index": 20,
      "title": "Similarity Reasoning and Filtration for Image-Text Matching",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Diao, H., Zhang, Y., Ma, L. & Lu, H.",
      "orig_title": "Similarity reasoning and filtration for image-text matching",
      "paper_id": "2101.01368v1"
    },
    {
      "index": 21,
      "title": "Unsupervised Feature Learning via Non-Parametric Instance Discrimination",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Wu, Z., Xiong, Y., Yu, S. X. & Lin, D.",
      "orig_title": "Unsupervised feature learning via non-parametric instance discrimination",
      "paper_id": "1805.01978v1"
    },
    {
      "index": 22,
      "title": "Representation Learning with Contrastive Predictive Coding",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1807.03748",
      "authors": "Oord, A. v. d., Li, Y. & Vinyals, O.",
      "orig_title": "Representation learning with contrastive predictive coding",
      "paper_id": "1807.03748v2"
    },
    {
      "index": 23,
      "title": "Learning deep representations by mutual information estimation and maximization",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "Hjelm, R. D. et al.",
      "orig_title": "Learning deep representations by mutual information estimation and maximization",
      "paper_id": "1808.06670v5"
    },
    {
      "index": 24,
      "title": "Local Aggregation for Unsupervised Learning of Visual Embeddings",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Computer Vision",
      "authors": "Zhuang, C., Zhai, A. L. & Yamins, D.",
      "orig_title": "Local aggregation for unsupervised learning of visual embeddings",
      "paper_id": "1903.12355v2"
    },
    {
      "index": 25,
      "title": "ZeRO-infinity: breaking the GPU memory wall for extreme scale deep learning",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference for High Performance Computing, Networking, Storage and Analysis",
      "authors": "Rajbhandari, S., Ruwase, O., Rasley, J., Smith, S. & He, Y."
    },
    {
      "index": 26,
      "title": "Scaling vision with sparse mixture of experts",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Riquelme, C. et al."
    },
    {
      "index": 27,
      "title": "A Simple Framework for Contrastive Learning of Visual Representations",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "Chen, T., Kornblith, S., Norouzi, M. & Hinton, G.",
      "orig_title": "A simple framework for contrastive learning of visual representations",
      "paper_id": "2002.05709v3"
    },
    {
      "index": 28,
      "title": "Momentum Contrast for Unsupervised Visual Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "He, K., Fan, H., Wu, Y., Xie, S. & Girshick, R.",
      "orig_title": "Momentum contrast for unsupervised visual representation learning",
      "paper_id": "1911.05722v3"
    },
    {
      "index": 29,
      "title": "Bootstrap Your Own Latent A New Approach to Self-Supervised Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Grill, J.-B. et al.",
      "orig_title": "Bootstrap your own latent - a new approach to self-supervised learning",
      "paper_id": "2006.07733v3"
    },
    {
      "index": 30,
      "title": "Exploring Simple Siamese Representation Learning",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Chen, X. & He, K.",
      "orig_title": "Exploring simple siamese representation learning",
      "paper_id": "2011.10566v1"
    },
    {
      "index": 31,
      "title": "Scaling up visual and vision-language representation learning with noisy text supervision",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Machine Learning",
      "authors": "Jia, C. et al."
    },
    {
      "index": 32,
      "title": "Feature visualization",
      "abstract": "",
      "year": "2017",
      "venue": "Distill",
      "authors": "Olah, C., Mordvintsev, A. & Schubert, L."
    },
    {
      "index": 33,
      "title": "Taming Transformers for High-Resolution Image Synthesis",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Esser, P., Rombach, R. & Ommer, B.",
      "orig_title": "Taming transformers for high-resolution image synthesis",
      "paper_id": "2012.09841v3"
    },
    {
      "index": 34,
      "title": "ImageNet Large Scale Visual Recognition Challenge",
      "abstract": "",
      "year": "2015",
      "venue": "International Journal of Computer Vision",
      "authors": "Russakovsky, O. et al.",
      "orig_title": "ImageNet large scale visual recognition challenge",
      "paper_id": "1409.0575v3"
    },
    {
      "index": 35,
      "title": "Bag-of-visual-words and spatial extensions for land-use classification",
      "abstract": "",
      "year": "2010",
      "venue": "International Symposium on Advances in Geographic Information Systems",
      "authors": "Yang, Y. & Newsam, S. D."
    },
    {
      "index": 36,
      "title": "AID: A benchmark data set for performance evaluation of aerial scene classification",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Transactions on Geoscience and Remote Sensing",
      "authors": "Xia, G.-S. et al."
    },
    {
      "index": 37,
      "title": "Zero and Few Shot Learning with Semantic Feature Synthesis and Competitive Learning",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Guan, J. et al.",
      "orig_title": "Zero and few shot learning with semantic feature synthesis and competitive learning",
      "paper_id": "1810.08332v1"
    },
    {
      "index": 38,
      "title": "Zero-shot scene classification for high spatial resolution remote sensing images",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Transactions on Geoscience and Remote Sensing",
      "authors": "Li, A., Lu, Z., Wang, L., Xiang, T. & Wen, J."
    },
    {
      "index": 39,
      "title": "Toutiao text classification dataset",
      "abstract": "",
      "year": "2021",
      "venue": "https://github.com/aceimnorstuvwxz/toutiao-text-classfication-dataset",
      "authors": "Contributors of Toutiao News."
    },
    {
      "index": 40,
      "title": "A comparison and semi-quantitative analysis of words and character-bigrams as features in chinese text categorization",
      "abstract": "",
      "year": "2006",
      "venue": "21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics",
      "authors": "Li, J., Sun, M. & Zhang, X."
    },
    {
      "index": 41,
      "title": "Revisiting Pre-trained Models for Chinese Natural Language Processing",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Empirical Methods in Natural Language Processing: Findings",
      "authors": "Cui, Y. et al.",
      "orig_title": "Revisiting pre-trained models for chinese natural language processing",
      "paper_id": "2004.13922v2"
    },
    {
      "index": 42,
      "title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Machine Learning",
      "authors": "Tan, M. & Le, Q.",
      "orig_title": "EfficientNet: Rethinking model scaling for convolutional neural networks",
      "paper_id": "1905.11946v5"
    },
    {
      "index": 43,
      "title": "Jieba Chinese text segmentation",
      "abstract": "",
      "year": "2020",
      "venue": "https://github.com/fxsjy/jieba",
      "authors": "Sun, J."
    },
    {
      "index": 44,
      "title": "UMAP: Uniform manifold approximation and projection",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of Open Source Software",
      "authors": "McInnes, L., Healy, J., Saul, N. & Großberger, L."
    },
    {
      "index": 45,
      "title": "AI Challenger : A Large-scale Dataset for Going Deeper in Image Understanding",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1711.06475",
      "authors": "Wu, J. et al.",
      "orig_title": "AI challenger: A large-scale dataset for going deeper in image understanding",
      "paper_id": "1711.06475v1"
    },
    {
      "index": 46,
      "title": "Counterfactual VQA: A cause-effect look at language bias",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Niu, Y. et al."
    },
    {
      "index": 47,
      "title": "Visual7W: Grounded question answering in images",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Zhu, Y., Groth, O., Bernstein, M. S. & Fei-Fei, L."
    },
    {
      "index": 48,
      "title": "Microsoft COCO: Common Objects in Context",
      "abstract": "",
      "year": "2014",
      "venue": "European Conference on Computer Vision",
      "authors": "Lin, T.-Y. et al.",
      "orig_title": "Microsoft coco: Common objects in context",
      "paper_id": "1405.0312v3"
    },
    {
      "index": 49,
      "title": "Improving language understanding by generative pre-training",
      "abstract": "",
      "year": "2018",
      "venue": "OpenAI Blog",
      "authors": "Radford, A., Narasimhan, K., Salimans, T. & Sutskever, I."
    },
    {
      "index": 50,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "authors": "Devlin, J., Chang, M., Lee, K. & Toutanova, K.",
      "orig_title": "BERT: pre-training of deep bidirectional transformers for language understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 51,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Vaswani, A. et al.",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 52,
      "title": "Big Transfer (BiT): General Visual Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Kolesnikov, A. et al.",
      "orig_title": "Big Transfer (BiT): General visual representation learning",
      "paper_id": "1912.11370v3"
    },
    {
      "index": 53,
      "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Learning Representations",
      "authors": "Dosovitskiy, A. et al.",
      "orig_title": "An image is worth 16x16 words: Transformers for image recognition at scale",
      "paper_id": "2010.11929v2"
    },
    {
      "index": 54,
      "title": "Rectified linear units improve restricted boltzmann machines",
      "abstract": "",
      "year": "2010",
      "venue": "International Conference on Machine Learning",
      "authors": "Nair, V. & Hinton, G. E."
    },
    {
      "index": 55,
      "title": "Multi-modality cross attention network for image and sentence matching",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Wei, X., Zhang, T., Li, Y., Zhang, Y. & Wu, F."
    },
    {
      "index": 56,
      "title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Anderson, P. et al.",
      "orig_title": "Bottom-up and top-down attention for image captioning and visual question answering",
      "paper_id": "1707.07998v3"
    },
    {
      "index": 57,
      "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ren, S., He, K., Girshick, R. B. & Sun, J.",
      "orig_title": "Faster R-CNN: Towards real-time object detection with region proposal networks",
      "paper_id": "1506.01497v3"
    },
    {
      "index": 58,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Learning Representations",
      "authors": "Kingma, D. P. & Ba, J."
    },
    {
      "index": 59,
      "title": "Generative adversarial nets",
      "abstract": "",
      "year": "2014",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Goodfellow, I. J. et al."
    },
    {
      "index": 60,
      "title": "Neural Discrete Representation Learning",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "van den Oord, A., Vinyals, O. & Kavukcuoglu, K.",
      "orig_title": "Neural discrete representation learning",
      "paper_id": "1711.00937v2"
    },
    {
      "index": 61,
      "title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
      "abstract": "",
      "year": "2014",
      "venue": "Transactions of the Association for Computational Linguistics",
      "authors": "Young, P., Lai, A., Hodosh, M. & Hockenmaier, J."
    },
    {
      "index": 62,
      "title": "Im2text: Describing images using 1 million captioned photographs",
      "abstract": "",
      "year": "2011",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ordonez, V., Kulkarni, G. & Berg, T. L."
    },
    {
      "index": 63,
      "title": "Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning",
      "abstract": "",
      "year": "2018",
      "venue": "56th Annual Meeting of the Association for Computational Linguistics",
      "authors": "Sharma, P., Ding, N., Goodman, S. & Soricut, R."
    }
  ]
}