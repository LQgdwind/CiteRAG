{
  "paper_id": "2105.10762v1",
  "title": "AutoLRS: Automatic Learning-Rate Schedule by Bayesian Optimization on the Fly",
  "abstract": "Abstract\nThe learning rate (LR) schedule is one of the most important hyper-parameters needing careful tuning in training DNNs. However, it is also one of the least automated parts of machine learning systems and usually costs significant manual effort and computing. Though there are pre-defined LR schedules and optimizers with adaptive LR, they introduce new hyperparameters that need to be tuned separately for different tasks/datasets. In this paper, we consider the question: Can we automatically tune the LR over the course of training without human involvement?\nWe propose an efficient method, AutoLRS, which automatically optimizes the LR for each training stage by modeling training dynamics.\nAutoLRS aims to find an LR applied to every œÑùúè\\tau steps that minimizes the resulted validation loss.\nWe solve this black-box optimization on the fly by Bayesian optimization (BO). However, collecting training instances for BO requires a system to evaluate each LR queried by BO‚Äôs acquisition function for œÑùúè\\tau steps, which is prohibitively expensive in practice.\nInstead, we apply each candidate LR for only œÑ‚Ä≤‚â™œÑmuch-less-thansuperscriptùúè‚Ä≤ùúè\\tau^{\\prime}\\ll\\tau steps and train an exponential model to predict the validation loss after œÑùúè\\tau steps. This mutual-training process between BO and the loss-prediction model allows us to limit the training steps invested in the BO search.\nWe demonstrate the advantages and the generality of AutoLRS through extensive experiments of training DNNs for tasks from diverse domains using different optimizers. The LR schedules auto-generated by AutoLRS lead to a speedup of 1.22√ó1.22\\times, 1.43√ó1.43\\times, and 1.5√ó1.5\\times when training ResNet-50, Transformer, and BERT, respectively, compared to the LR schedules in their original papers, and an average speedup of 1.31√ó1.31\\times over state-of-the-art heavily-tuned LR schedules.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in neural information processing systems",
      "authors": "Zeyuan Allen-Zhu, Yuanzhi Li, and Yingyu Liang",
      "orig_title": "Learning and generalization in overparameterized neural networks, going beyond two layers",
      "paper_id": "1811.04918v6"
    },
    {
      "index": 1,
      "title": "A Convergence Theory for Deep Learning via Over-Parameterization",
      "abstract": "",
      "year": "2019",
      "venue": "36th International Conference on Machine Learning",
      "authors": "Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song",
      "orig_title": "A convergence theory for deep learning via over-parameterization",
      "paper_id": "1811.03962v5"
    },
    {
      "index": 2,
      "title": "Parameter adaptation in stochastic optimization",
      "abstract": "",
      "year": "1998",
      "venue": "On-Line Learning in Neural Networks, Publications of the Newton Institute",
      "authors": "Lu√≠s B Almeida, Thibault Langlois, Jos√© D Amaral, and Alexander Plakhov"
    },
    {
      "index": 3,
      "title": "Using confidence bounds for exploitation-exploration trade-offs",
      "abstract": "",
      "year": "2002",
      "venue": "Journal of Machine Learning Research",
      "authors": "Peter Auer"
    },
    {
      "index": 4,
      "title": "Online Learning Rate Adaptation with Hypergradient Descent",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Learning Representations",
      "authors": "Atƒ±lƒ±m G√ºne≈ü Baydin, Robert Cornish, David Mart√≠nez Rubio, Mark Schmidt, and Frank Wood",
      "orig_title": "Online learning rate adaptation with hypergradient descent",
      "paper_id": "1703.04782v3"
    },
    {
      "index": 5,
      "title": "Hyperopt: A python library for optimizing the hyperparameters of machine learning algorithms",
      "abstract": "",
      "year": "2013",
      "venue": "12th Python in science conference",
      "authors": "James Bergstra, Dan Yamins, and David D Cox"
    },
    {
      "index": 6,
      "title": "A statistical method for global optimization",
      "abstract": "",
      "year": "1992",
      "venue": "1992 IEEE International Conference on Systems, Man, and Cybernetics",
      "authors": "Dennis D Cox and Susan John"
    },
    {
      "index": 7,
      "title": "Bayesian optimization meets Bayesian optimal stopping",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Machine Learning",
      "authors": "Zhongxiang Dai, Haibin Yu, Bryan Kian Hsiang Low, and Patrick Jaillet"
    },
    {
      "index": 8,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
      "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova",
      "orig_title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 9,
      "title": "Automatically constructing a corpus of sentential paraphrases",
      "abstract": "",
      "year": "2005",
      "venue": "Third International Workshop on Paraphrasing (IWP2005)",
      "authors": "William B Dolan and Chris Brockett"
    },
    {
      "index": 10,
      "title": "Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves",
      "abstract": "",
      "year": "2015",
      "venue": "IJCAI",
      "authors": "Tobias Domhan, Jost Tobias Springenberg, and Frank Hutter"
    },
    {
      "index": 11,
      "title": "MARTHE: Scheduling the Learning Rate Via Online Hypergradients",
      "abstract": "",
      "year": "2020",
      "venue": "IJCAI-20",
      "authors": "Michele Donini, Luca Franceschi, Orchid Majumder, Massimiliano Pontil, and Paolo Frasconi",
      "orig_title": "MARTHE: Scheduling the learning rate via online hypergradients",
      "paper_id": "1910.08525v4"
    },
    {
      "index": 12,
      "title": "Adaptive subgradient methods for online learning and stochastic optimization",
      "abstract": "",
      "year": "2011",
      "venue": "Journal of Machine Learning Research",
      "authors": "John Duchi, Elad Hazan, and Yoram Singer"
    },
    {
      "index": 13,
      "title": "BOHB: Robust and Efficient Hyperparameter Optimization at Scale",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1807.01774",
      "authors": "Stefan Falkner, Aaron Klein, and Frank Hutter",
      "orig_title": "BOHB: Robust and efficient hyperparameter optimization at scale",
      "paper_id": "1807.01774v1"
    },
    {
      "index": 14,
      "title": "Forward and reverse gradient-based hyperparameter optimization",
      "abstract": "",
      "year": "2017",
      "venue": "34th International Conference on Machine Learning",
      "authors": "Luca Franceschi, Michele Donini, Paolo Frasconi, and Massimiliano Pontil"
    },
    {
      "index": 15,
      "title": "Classes of kernels for machine learning: a statistics perspective",
      "abstract": "",
      "year": "2001",
      "venue": "Journal of machine learning research",
      "authors": "Marc G Genton"
    },
    {
      "index": 16,
      "title": "Deep Learning",
      "abstract": "",
      "year": "2016",
      "venue": "MIT press",
      "authors": "Ian Goodfellow, Yoshua Bengio, and Aaron Courville",
      "orig_title": "Deep Learning",
      "paper_id": "1807.07987v2"
    },
    {
      "index": 17,
      "title": "A closer look at Deep Learning heuristics: Learning rate restarts, warmup and distillation",
      "abstract": "",
      "year": "2019",
      "venue": "international conference on learning representations",
      "authors": "Deepak Akhilesh Gotmare, Shirish Nitish Keskar, Caiming Xiong, and Richard Socher",
      "orig_title": "A closer look at deep learning heuristics: Learning rate restarts, warmup and distillation",
      "paper_id": "1810.13243v1"
    },
    {
      "index": 18,
      "title": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1706.02677",
      "authors": "Priya Goyal, Piotr Doll√°r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He",
      "orig_title": "Accurate, large minibatch SGD: Training ImageNet in 1 hour",
      "paper_id": "1706.02677v2"
    },
    {
      "index": 19,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 20,
      "title": "Identity Mappings in Deep Residual Networks",
      "abstract": "",
      "year": "2016",
      "venue": "European conference on computer vision",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Identity mappings in deep residual networks",
      "paper_id": "1603.05027v3"
    },
    {
      "index": 21,
      "title": "Sequential model-based optimization for general algorithm configuration",
      "abstract": "",
      "year": "2011",
      "venue": "International conference on learning and intelligent optimization",
      "authors": "Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown"
    },
    {
      "index": 22,
      "title": "Population Based Training of Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1711.09846",
      "authors": "Max Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M Czarnecki, Jeff Donahue, Ali Razavi, Oriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, et al.",
      "orig_title": "Population based training of neural networks",
      "paper_id": "1711.09846v2"
    },
    {
      "index": 23,
      "title": "Non-stochastic best arm identification and hyperparameter optimization",
      "abstract": "",
      "year": "2016",
      "venue": "Artificial Intelligence and Statistics",
      "authors": "Kevin Jamieson and Ameet Talwalkar"
    },
    {
      "index": 24,
      "title": "Three Factors Influencing Minima in SGD",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1711.04623",
      "authors": "Stanis≈Çaw Jastrzƒôbski, Zachary Kenton, Devansh Arpit, Nicolas Ballas, Asja Fischer, Yoshua Bengio, and Amos Storkey",
      "orig_title": "Three factors influencing minima in SGD",
      "paper_id": "1711.04623v3"
    },
    {
      "index": 25,
      "title": "How to Escape Saddle Points Efficiently",
      "abstract": "",
      "year": "2017",
      "venue": "34th International Conference on Machine Learning-Volume 70",
      "authors": "Chi Jin, Rong Ge, Praneeth Netrapalli, Sham M Kakade, and Michael I Jordan",
      "orig_title": "How to escape saddle points efficiently",
      "paper_id": "1703.00887v1"
    },
    {
      "index": 26,
      "title": "Deep Learning without Poor Local Minima",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in neural information processing systems",
      "authors": "Kenji Kawaguchi",
      "orig_title": "Deep learning without poor local minima",
      "paper_id": "1605.07110v3"
    },
    {
      "index": 27,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Learning Representations",
      "authors": "Diederick P Kingma and Jimmy Ba"
    },
    {
      "index": 28,
      "title": "Learning curve prediction with Bayesian neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Learning Representations",
      "authors": "A. Klein, Stefan Falkner, Jost Tobias Springenberg, and F. Hutter"
    },
    {
      "index": 29,
      "title": "Learning multiple layers of features from tiny images",
      "abstract": "",
      "year": "2009",
      "venue": "Department of Computer Science, University of Toronto",
      "authors": "A. Krizhevsky and G. Hinton"
    },
    {
      "index": 30,
      "title": "One weird trick for parallelizing convolutional neural networks",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1404.5997",
      "authors": "Alex Krizhevsky",
      "orig_title": "One weird trick for parallelizing convolutional neural networks",
      "paper_id": "1404.5997v2"
    },
    {
      "index": 31,
      "title": "CIFAR-100 (Canadian Institute for Advanced Research)",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton"
    },
    {
      "index": 32,
      "title": "Visualizing the Loss Landscape of Neural Nets",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein",
      "orig_title": "Visualizing the loss landscape of neural nets",
      "paper_id": "1712.09913v3"
    },
    {
      "index": 33,
      "title": "A system for massively parallel hyperparameter tuning",
      "abstract": "",
      "year": "2018",
      "venue": "Conference on Machine Learning and Systems",
      "authors": "Liam Li, KG Jamieson, Afshin Rostamizadeh, Ekaterina Gonina, MH Jonathan Ben-Tzur, B Recht, and A Talwalkar"
    },
    {
      "index": 34,
      "title": "Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization",
      "abstract": "",
      "year": "2017",
      "venue": "Journal of Machine Learning Research",
      "authors": "Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar",
      "orig_title": "Hyperband: A novel bandit-based approach to hyperparameter optimization",
      "paper_id": "1603.06560v4"
    },
    {
      "index": 35,
      "title": "SGDR: Stochastic Gradient Descent with Warm Restarts",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Learning Representations",
      "authors": "Ilya Loshchilov and Frank Hutter",
      "orig_title": "SGDR: stochastic gradient descent with warm restarts",
      "paper_id": "1608.03983v5"
    },
    {
      "index": 36,
      "title": "Probabilistic Line Searches for Stochastic Optimization",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Maren Mahsereci and Philipp Hennig",
      "orig_title": "Probabilistic line searches for stochastic optimization",
      "paper_id": "1502.02846v4"
    },
    {
      "index": 37,
      "title": "Mixed Precision Training",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Learning Representations",
      "authors": "Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu",
      "orig_title": "Mixed precision training",
      "paper_id": "1710.03740v3"
    },
    {
      "index": 38,
      "title": "Step Size Matters in Deep Learning",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Kamil Nar and Shankar Sastry",
      "orig_title": "Step size matters in deep learning",
      "paper_id": "1805.08890v2"
    },
    {
      "index": 39,
      "title": "Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Jack Parker-Holder, Vu Nguyen, and Stephen Roberts",
      "orig_title": "Provably efficient online hyperparameter optimization with population-based bandits",
      "paper_id": "2002.02518v4"
    },
    {
      "index": 40,
      "title": "SQuAD: 100,000+ questions for machine comprehension of text",
      "abstract": "",
      "year": "2016",
      "venue": "2016 Conference on Empirical Methods in Natural Language Processing",
      "authors": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang"
    },
    {
      "index": 41,
      "title": "Gaussian Processes for Machine Learning",
      "abstract": "",
      "year": "2006",
      "venue": "Adaptive Computation and Machine Learning. MIT Press",
      "authors": "CE. Rasmussen and CKI. Williams"
    },
    {
      "index": 42,
      "title": "ImageNet Large Scale Visual Recognition Challenge",
      "abstract": "",
      "year": "2015",
      "venue": "International Journal of Computer Vision (IJCV)",
      "authors": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei",
      "orig_title": "ImageNet Large Scale Visual Recognition Challenge",
      "paper_id": "1409.0575v3"
    },
    {
      "index": 43,
      "title": "No more pesky learning rates",
      "abstract": "",
      "year": "2013",
      "venue": "International Conference on Machine Learning",
      "authors": "Tom Schaul, Sixin Zhang, and Yann LeCun"
    },
    {
      "index": 44,
      "title": "Taking the human out of the loop: A review of Bayesian optimization",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE",
      "authors": "Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P. Adams, and Nando De Freitas"
    },
    {
      "index": 45,
      "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Learning Representations",
      "authors": "Karen Simonyan and Andrew Zisserman",
      "orig_title": "Very deep convolutional networks for large-scale image recognition",
      "paper_id": "1409.1556v6"
    },
    {
      "index": 46,
      "title": "Cyclical learning rates for training neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "2017 IEEE Winter Conference on Applications of Computer Vision (WACV)",
      "authors": "Leslie N Smith"
    },
    {
      "index": 47,
      "title": "A disciplined approach to neural network hyper-parameters: Part 1‚Äìlearning rate, batch size, momentum, and weight decay",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1803.09820",
      "authors": "Leslie N Smith"
    },
    {
      "index": 48,
      "title": "Practical bayesian optimization of machine learning algorithms",
      "abstract": "",
      "year": "2012",
      "venue": "Advances in neural information processing systems",
      "authors": "Jasper Snoek, Hugo Larochelle, and Ryan P Adams"
    },
    {
      "index": 49,
      "title": "Freeze-Thaw Bayesian Optimization",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1406.3896",
      "authors": "Kevin Swersky, Jasper Snoek, and Ryan Prescott Adams",
      "orig_title": "Freeze-thaw bayesian optimization",
      "paper_id": "1406.3896v1"
    },
    {
      "index": 50,
      "title": "Lecture 6.5‚ÄîRmsProp: Divide the gradient by a running average of its recent magnitude",
      "abstract": "",
      "year": "2012",
      "venue": "COURSERA: Neural Networks for Machine Learning",
      "authors": "T. Tieleman and G. Hinton"
    },
    {
      "index": 51,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 52,
      "title": "Neural Network Acceptability Judgments",
      "abstract": "",
      "year": "2019",
      "venue": "Transactions of the Association for Computational Linguistics",
      "authors": "Alex Warstadt, Amanpreet Singh, and Samuel R Bowman",
      "orig_title": "Neural network acceptability judgments",
      "paper_id": "1805.12471v3"
    },
    {
      "index": 53,
      "title": "Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Learning Representations",
      "authors": "Yeming Wen, Paul Vicol, Jimmy Ba, Dustin Tran, and Roger Grosse",
      "orig_title": "Flipout: Efficient pseudo-independent weight perturbations on mini-batches",
      "paper_id": "1803.04386v2"
    },
    {
      "index": 54,
      "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
      "abstract": "",
      "year": "2018",
      "venue": "2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
      "authors": "Adina Williams, Nikita Nangia, and Samuel Bowman",
      "orig_title": "A broad-coverage challenge corpus for sentence understanding through inference",
      "paper_id": "1704.05426v4"
    },
    {
      "index": 55,
      "title": "Understanding short-horizon bias in stochastic meta-optimization",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Learning Representations",
      "authors": "Yuhuai Wu, Mengye Ren, Renjie Liao, and Roger Grosse"
    },
    {
      "index": 56,
      "title": "Adadelta: an adaptive learning rate method",
      "abstract": "",
      "year": "2012",
      "venue": "arXiv preprint arXiv:1212.5701",
      "authors": "Matthew D Zeiler"
    },
    {
      "index": 57,
      "title": "Towards Automated Deep Learning: Efficient Joint Neural Architecture and Hyperparameter Search",
      "abstract": "",
      "year": "2018",
      "venue": "ICML 2018 AutoML Workshop",
      "authors": "Arber Zela, Aaron Klein, Stefan Falkner, and Frank Hutter",
      "orig_title": "Towards automated deep learning: Efficient joint neural architecture and hyperparameter search",
      "paper_id": "1807.06906v1"
    },
    {
      "index": 58,
      "title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
      "abstract": "",
      "year": "2015",
      "venue": "2015 IEEE International Conference on Computer Vision (ICCV)",
      "authors": "Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler"
    },
    {
      "index": 59,
      "title": "BookCorpus website",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Yukun Zhu, Ryan Kiros, Richard Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler"
    }
  ]
}