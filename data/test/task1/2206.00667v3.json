{
  "paper_id": "2206.00667v3",
  "title": "‚ÄúHow Biased are Your Features?‚Äù: Computing Fairness Influence Functions with Global Sensitivity Analysis",
  "abstract": "Abstract\nFairness in machine learning has attained significant focus due to the widespread application in high-stake decision-making tasks. Unregulated machine learning classifiers can exhibit bias towards certain demographic groups in data, thus the quantification and mitigation of classifier bias is a central concern in fairness in machine learning. In this paper, we aim to quantify the influence of different features in a dataset on the bias of a classifier. To do this, we introduce the Fairness Influence Function (FIF). This function breaks down bias into its components among individual features and the intersection of multiple features. The key idea is to represent existing group fairness metrics as the difference of the scaled conditional variances in the classifier‚Äôs prediction and apply a decomposition of variance according to global sensitivity analysis. To estimate FIFs, we instantiate an algorithm ùñ•ùñ∫ùóÇùóãùñ∑ùóâùóÖùñ∫ùóÇùóáùñæùóãùñ•ùñ∫ùóÇùóãùñ∑ùóâùóÖùñ∫ùóÇùóáùñæùóã\\mathsf{FairXplainer} that applies variance decomposition of classifier‚Äôs prediction following local regression. Experiments demonstrate that ùñ•ùñ∫ùóÇùóãùñ∑ùóâùóÖùñ∫ùóÇùóáùñæùóãùñ•ùñ∫ùóÇùóãùñ∑ùóâùóÖùñ∫ùóÇùóáùñæùóã\\mathsf{FairXplainer} captures FIFs of individual feature and intersectional features, provides a better approximation of bias based on FIFs, demonstrates higher correlation of FIFs with fairness interventions, and detects changes in bias due to fairness affirmative/punitive actions in the classifier.\nThe code is available at https://github.com/ReAILe/bias-explainer. The extended version of the paper is at https://arxiv.org/pdf/2206.00667.pdf.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Hiring by algorithm: predicting and preventing disparate impact",
      "abstract": "",
      "year": "2016",
      "venue": "SSRN",
      "authors": "Ifeoma Ajunwa, Sorelle Friedler, Carlos E Scheidegger, and Suresh Venkatasubramanian"
    },
    {
      "index": 1,
      "title": "Machine bias risk assessments in criminal sentencing",
      "abstract": "",
      "year": "2016",
      "venue": "ProPublica",
      "authors": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner"
    },
    {
      "index": 2,
      "title": "Explainability for fair machine learning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Tom Begley, Tobias Schwedes, Christopher Frye, and Ilya Feige",
      "orig_title": "Explainability for fair machine learning",
      "paper_id": "2010.07389v1"
    },
    {
      "index": 3,
      "title": "Ai fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias, Oct 2018",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv",
      "authors": "Rachel K. E. Bellamy, Kuntal Dey, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, Aleksandra Mojsilovic, Seema Nagar, Karthikeyan Natesan Ramamurthy, John Richards, Diptikalyan Saha, Prasanna Sattigeri, Moninder Singh, Kush R. Varshney, and Yunfeng Zhang"
    },
    {
      "index": 4,
      "title": "Fairness seen as global sensitivity analysis",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Cl√©ment B√©nesse, Fabrice Gamboa, Jean-Michel Loubes, and Thibaut Boissin"
    },
    {
      "index": 5,
      "title": "Accuracy and fairness for juvenile justice risk assessments",
      "abstract": "",
      "year": "2019",
      "venue": "Journal of Empirical Legal Studies",
      "authors": "Richard Berk"
    },
    {
      "index": 6,
      "title": "A survey of bias in machine learning through the prism of statistical parity",
      "abstract": "",
      "year": "2021",
      "venue": "The American Statistician",
      "authors": "Philippe Besse, Eustasio del Barrio, Paula Gordaliza, Jean-Michel Loubes, and Laurent Risser"
    },
    {
      "index": 7,
      "title": "Gender shades: Intersectional accuracy disparities in commercial gender classification",
      "abstract": "",
      "year": "2018",
      "venue": "Conference on fairness, accountability and transparency",
      "authors": "Joy Buolamwini and Timnit Gebru"
    },
    {
      "index": 8,
      "title": "Optimized pre-processing for discrimination prevention",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, and Kush R Varshney"
    },
    {
      "index": 9,
      "title": "Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE symposium on security and privacy (SP)",
      "authors": "Anupam Datta, Shayak Sen, and Yair Zick"
    },
    {
      "index": 10,
      "title": "Subroutine package for calculating with b-splines",
      "abstract": "",
      "year": "1971",
      "venue": "Los Alamos National Lab.(LANL)",
      "authors": "Carl de Boor"
    },
    {
      "index": 11,
      "title": "Towards a rigorous science of interpretable machine learning",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv",
      "authors": "Finale Doshi-Velez and Been Kim"
    },
    {
      "index": 12,
      "title": "UCI machine learning repository, 2017",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Dheeru Dua and Casey Graff"
    },
    {
      "index": 13,
      "title": "Fairness through awareness",
      "abstract": "",
      "year": "2012",
      "venue": "3rd innovations in theoretical computer science conference",
      "authors": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel"
    },
    {
      "index": 14,
      "title": "The jackknife estimate of variance",
      "abstract": "",
      "year": "1981",
      "venue": "The Annals of Statistics",
      "authors": "Bradley Efron and Charles Stein"
    },
    {
      "index": 15,
      "title": "Better regulation toolbox, 2021",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "EU Commission"
    },
    {
      "index": 16,
      "title": "Certifying and removing disparate impact",
      "abstract": "",
      "year": "2015",
      "venue": "ACM SIGKDD international conference on knowledge discovery and data mining",
      "authors": "Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian"
    },
    {
      "index": 17,
      "title": "Fairness Metrics: A Comparative Analysis",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE International Conference on Big Data (Big Data)",
      "authors": "Pratyush Garg, John Villasenor, and Virginia Foggo",
      "orig_title": "Fairness metrics: A comparative analysis",
      "paper_id": "2001.07864v2"
    },
    {
      "index": 18,
      "title": "Justicia: A Stochastic SAT Approach to Formally Verify Fairness",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI",
      "authors": "Bishwamittra Ghosh, Debabrota Basu, and Kuldeep S. Meel",
      "orig_title": "Justicia: A stochastic SAT approach to formally verify fairness",
      "paper_id": "2009.06516v2"
    },
    {
      "index": 19,
      "title": "Algorithmic fairness verification with graphical models",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI",
      "authors": "Bishwamittra Ghosh, Debabrota Basu, and Kuldeep S. Meel"
    },
    {
      "index": 20,
      "title": "Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post Hoc Explanations",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Tessa Han, Suraj Srinivas, and Himabindu Lakkaraju",
      "orig_title": "Which explanation should i choose? a function approximation perspective to characterizing post hoc explanations",
      "paper_id": "2206.01254v3"
    },
    {
      "index": 21,
      "title": "Equality of Opportunity in Supervised Learning",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in neural information processing systems",
      "authors": "Moritz Hardt, Eric Price, and Nati Srebro",
      "orig_title": "Equality of opportunity in supervised learning",
      "paper_id": "1610.02413v1"
    },
    {
      "index": 22,
      "title": "SALib: An open-source python library for sensitivity analysis",
      "abstract": "",
      "year": "2017",
      "venue": "The Journal of Open Source Software",
      "authors": "Jon Herman and Will Usher"
    },
    {
      "index": 23,
      "title": "A class of statistics with asymptotically normal distribution",
      "abstract": "",
      "year": "1992",
      "venue": "Breakthroughs in Statistics: Foundations and Basic Theory",
      "authors": "Wassily Hoeffding"
    },
    {
      "index": 24,
      "title": "Human Imperceptible Attacks and Applications to Improve Fairness",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Xinru Hua, Huanzhong Xu, Jose Blanchet, and Viet Nguyen",
      "orig_title": "Human imperceptible attacks and applications to improve fairness",
      "paper_id": "2111.15603v1"
    },
    {
      "index": 25,
      "title": "Data preprocessing techniques for classification without discrimination",
      "abstract": "",
      "year": "2012",
      "venue": "Knowledge and Information Systems",
      "authors": "Faisal Kamiran and Toon Calders"
    },
    {
      "index": 26,
      "title": "Decision theory for discrimination-aware classification",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE 12th International Conference on Data Mining",
      "authors": "Faisal Kamiran, Asim Karim, and Xiangliang Zhang"
    },
    {
      "index": 27,
      "title": "Correlates of perceived fairness and accuracy of performance evaluation",
      "abstract": "",
      "year": "1978",
      "venue": "Journal of Applied psychology",
      "authors": "Frank J Landy, Janet L Barnes, and Kevin R Murphy"
    },
    {
      "index": 28,
      "title": "Global sensitivity analysis for systems with independent and/or correlated inputs",
      "abstract": "",
      "year": "2010",
      "venue": "The journal of physical chemistry A",
      "authors": "Genyuan Li, Herschel Rabitz, Paul E Yelvington, Oluwayemisi O Oluwole, Fred Bacon, Charles E Kolb, and Jacqueline Schoendorf"
    },
    {
      "index": 29,
      "title": "Achieving Fairness at No Utility Cost via Data Reweighing with Influence",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "authors": "Peizhao Li and Hongfu Liu",
      "orig_title": "Achieving fairness at no utility cost via data reweighing with influence",
      "paper_id": "2202.00787v2"
    },
    {
      "index": 30,
      "title": "Smoothing: local regression techniques",
      "abstract": "",
      "year": "2012",
      "venue": "Handbook of computational statistics",
      "authors": "Catherine Loader"
    },
    {
      "index": 31,
      "title": "Local regression and likelihood",
      "abstract": "",
      "year": "2006",
      "venue": "Springer Science & Business Media",
      "authors": "Clive Loader"
    },
    {
      "index": 32,
      "title": "Explaining quantitative measures of fairness",
      "abstract": "",
      "year": "2020",
      "venue": "Fair & Responsible AI Workshop@ CHI2020",
      "authors": "Scott M Lundberg"
    },
    {
      "index": 33,
      "title": "A Unified Approach to Interpreting Model Predictions",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Scott M Lundberg and Su-In Lee",
      "orig_title": "A unified approach to interpreting model predictions",
      "paper_id": "1705.07874v2"
    },
    {
      "index": 34,
      "title": "From local explanations to global understanding with explainable ai for trees",
      "abstract": "",
      "year": "2020",
      "venue": "Nature Machine Intelligence",
      "authors": "Scott M. Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M. Prutkin, Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee"
    },
    {
      "index": 35,
      "title": "Using machine learning in admissions: Reducing human and algorithmic bias in the selection process",
      "abstract": "",
      "year": "2021",
      "venue": "ACM Technical Symposium on Computer Science Education",
      "authors": "Barbara Martinez Neda, Yue Zeng, and Sergio Gago-Masague"
    },
    {
      "index": 36,
      "title": "Ricci v. DeStefano: A masculinities theory analysis",
      "abstract": "",
      "year": "2010",
      "venue": "Harv. JL & Gender",
      "authors": "Ann C McGinley"
    },
    {
      "index": 37,
      "title": "Exacerbating Algorithmic Bias through Fairness Attacks",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Ninareh Mehrabi, Muhammad Naveed, Fred Morstatter, and Aram Galstyan",
      "orig_title": "Exacerbating algorithmic bias through fairness attacks",
      "paper_id": "2012.08723v1"
    },
    {
      "index": 38,
      "title": "Explaining Algorithmic Fairness Through Fairness-Aware Causal Path Decomposition",
      "abstract": "",
      "year": "2021",
      "venue": "ACM SIGKDD Conference on Knowledge Discovery & Data Mining",
      "authors": "Weishen Pan, Sen Cui, Jiang Bian, Changshui Zhang, and Fei Wang",
      "orig_title": "Explaining algorithmic fairness through fairness-aware causal path decomposition",
      "paper_id": "2108.05335v1"
    },
    {
      "index": 39,
      "title": "Scikit-learn: Machine learning in Python",
      "abstract": "",
      "year": "2011",
      "venue": "Journal of Machine Learning Research",
      "authors": "F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay"
    },
    {
      "index": 40,
      "title": "‚ÄúWhy Should I Trust You?‚Äù Explaining the Predictions of Any Classifier",
      "abstract": "",
      "year": "2016",
      "venue": "ACM SIGKDD international conference on knowledge discovery and data mining",
      "authors": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin",
      "orig_title": "Why should i trust you?: Explaining the predictions of any classifier",
      "paper_id": "1602.04938v3"
    },
    {
      "index": 41,
      "title": "The Shapley value: essays in honor of Lloyd S. Shapley",
      "abstract": "",
      "year": "1988",
      "venue": "Cambridge University Press",
      "authors": "Alvin E Roth"
    },
    {
      "index": 42,
      "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
      "abstract": "",
      "year": "2019",
      "venue": "Nature machine intelligence",
      "authors": "Cynthia Rudin"
    },
    {
      "index": 43,
      "title": "Global sensitivity analysis: the primer",
      "abstract": "",
      "year": "2008",
      "venue": "John Wiley & Sons",
      "authors": "Andrea Saltelli, Marco Ratto, Terry Andres, Francesca Campolongo, Jessica Cariboni, Debora Gatelli, Michaela Saisana, and Stefano Tarantola"
    },
    {
      "index": 44,
      "title": "Five ways to ensure that models serve society: a manifesto, 2020",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Andrea Saltelli, Gabriele Bammer, Isabelle Bruno, Erica Charters, Monica Di Fiore, Emmanuel Didier, Wendy Nelson Espeland, John Kay, Samuele Lo Piano, Deborah Mayo, et al."
    },
    {
      "index": 45,
      "title": "Spline functions: basic theory",
      "abstract": "",
      "year": "2007",
      "venue": "Cambridge University Press",
      "authors": "Larry Schumaker"
    },
    {
      "index": 46,
      "title": "Axiomatic Characterization of Data-Driven Influence Measures for Classification",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Jakub Sliwinski, Martin Strobel, and Yair Zick",
      "orig_title": "Axiomatic characterization of data-driven influence measures for classification",
      "paper_id": "1708.02153v2"
    },
    {
      "index": 47,
      "title": "On sensitivity estimation for nonlinear mathematical models",
      "abstract": "",
      "year": "1990",
      "venue": "Matematicheskoe modelirovanie",
      "authors": "Il'ya M Sobol'"
    },
    {
      "index": 48,
      "title": "Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates",
      "abstract": "",
      "year": "2001",
      "venue": "Mathematics and computers in simulation",
      "authors": "Il'ya M Sobol'"
    },
    {
      "index": 49,
      "title": "Multidimensional quadrature formulas and haar functions, 1969",
      "abstract": "",
      "year": "1969",
      "venue": "",
      "authors": "IM Sobol"
    },
    {
      "index": 50,
      "title": "Poisoning Attacks on Algorithmic Fairness",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "David Solans, Battista Biggio, and Carlos Castillo",
      "orig_title": "Poisoning attacks on algorithmic fairness",
      "paper_id": "2004.07401v3"
    },
    {
      "index": 51,
      "title": "Which method predicts recidivism best?: a comparison of statistical, machine learning and data mining predictive models",
      "abstract": "",
      "year": "2013",
      "venue": "Journal of the Royal Statistical Society: Series A (Statistics in Society)",
      "authors": "Nikolaj Tollenaar and PGM Van der Heijden"
    },
    {
      "index": 52,
      "title": "Computational complexity of spline interpolation",
      "abstract": "",
      "year": "1987",
      "venue": "International journal of systems science",
      "authors": "Kazuo Toraichi, Kazuki Katagishi, Iwao Sekita, and Ryoichi Mori"
    },
    {
      "index": 53,
      "title": "Guidance on the development, evaluation, and application of environmental models, 2009",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "U.S. Environmental Protection Agency"
    },
    {
      "index": 54,
      "title": "Fairness definitions explained",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE/ACM International Workshop on Software Fairness (FairWare)",
      "authors": "Sahil Verma and Julia Rubin"
    },
    {
      "index": 55,
      "title": "Towards Intersectionality in Machine Learning: Including More Identities, Handling Underrepresentation, and Performing Evaluation",
      "abstract": "",
      "year": "2022",
      "venue": "ACM Conference on Fairness, Accountability, and Transparency",
      "authors": "Angelina Wang, Vikram V Ramaswamy, and Olga Russakovsky",
      "orig_title": "Towards intersectionality in machine learning: Including more identities, handling underrepresentation, and performing evaluation",
      "paper_id": "2205.04610v1"
    },
    {
      "index": 56,
      "title": "Understanding Instance-Level Impact of Fairness Constraints",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "authors": "Jialu Wang, Xin Eric Wang, and Yang Liu",
      "orig_title": "Understanding instance-level impact of fairness constraints",
      "paper_id": "2206.15437v1"
    },
    {
      "index": 57,
      "title": "Learning fair representations",
      "abstract": "",
      "year": "2013",
      "venue": "International Conference on Machine Learning",
      "authors": "Rich Zemel, Yu Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork"
    },
    {
      "index": 58,
      "title": "Mitigating Unwanted Biases with Adversarial Learning",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI/ACM Conference on AI, Ethics, and Society",
      "authors": "Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell",
      "orig_title": "Mitigating unwanted biases with adversarial learning",
      "paper_id": "1801.07593v1"
    },
    {
      "index": 59,
      "title": "Fairness in decision-making‚Äîthe causal explanation formula",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Junzhe Zhang and Elias Bareinboim"
    },
    {
      "index": 60,
      "title": "FAHT: An Adaptive Fairness-aware Decision Tree Classifier",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Wenbin Zhang and Eirini Ntoutsi",
      "orig_title": "Faht: an adaptive fairness-aware decision tree classifier",
      "paper_id": "1907.07237v1"
    },
    {
      "index": 61,
      "title": "On the relation between accuracy and fairness in binary classification",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv",
      "authors": "Indre Zliobaite",
      "orig_title": "On the relation between accuracy and fairness in binary classification",
      "paper_id": "1505.05723v1"
    }
  ]
}