{
  "paper_id": "2103.14651v2",
  "title": "Local Explanations via Necessity and Sufficiency: Unifying Theory and Practice",
  "abstract": "Abstract\nNecessity and sufficiency are the building blocks of all successful explanations. Yet despite their importance, these notions have been conceptually underdeveloped and inconsistently applied in explainable artificial intelligence (XAI), a fast-growing research area that is so far lacking in firm theoretical foundations. Building on work in logic, probability, and causality, we establish the central role of necessity and sufficiency in XAI, unifying seemingly disparate methods in a single formal framework. We provide a sound and complete algorithm for computing explanatory factors with respect to a given context, and demonstrate its flexibility and competitive performance against state of the art alternatives on various tasks.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Explaining individual predictions when features are dependent: More accurate approximations to Shapley values",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint",
      "authors": "Kjersti Aas, Martin Jullum, and Anders Løland"
    },
    {
      "index": 1,
      "title": "The Hidden Assumptions Behind Counterfactual Explanations and Principal Reasons",
      "abstract": "",
      "year": "2020",
      "venue": "FAT*",
      "authors": "Solon Barocas, Andrew D Selbst, and Manish Raghavan",
      "orig_title": "The Hidden Assumptions behind Counterfactual Explanations and Principal Reasons",
      "paper_id": "1912.04930v1"
    },
    {
      "index": 2,
      "title": "Approximate causal abstraction",
      "abstract": "",
      "year": "2019",
      "venue": "UAI",
      "authors": "Sander Beckers, Frederick Eberhardt, and Joseph Y Halpern"
    },
    {
      "index": 3,
      "title": "Explainable machine learning in deployment",
      "abstract": "",
      "year": "2020",
      "venue": "FAT*",
      "authors": "Umang Bhatt, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly, Yunhan Jia, Joydeep Ghosh, Ruchir Puri, José M F Moura, and Peter Eckersley"
    },
    {
      "index": 4,
      "title": "Natural language processing with Python: Analyzing text with the natural language toolkit",
      "abstract": "",
      "year": "2009",
      "venue": "O’Reilly",
      "authors": "Steven Bird, Ewan Klein, and Edward Loper"
    },
    {
      "index": 5,
      "title": "Contrastivism in Philosophy",
      "abstract": "",
      "year": "2013",
      "venue": "Routledge",
      "authors": "Martijn Blaauw, editor"
    },
    {
      "index": 6,
      "title": "Causal feature learning: an overview",
      "abstract": "",
      "year": "2017",
      "venue": "Behaviormetrika",
      "authors": "Krzysztof Chalupka, Frederick Eberhardt, and Pietro Perona"
    },
    {
      "index": 7,
      "title": "Explanations based on the missing: Towards contrastive explanations with pertinent negatives",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Amit Dhurandhar, Pin-Yu Chen, Ronny Luss, Chun-Chen Tu, Paishun Ting, Karthikeyan Shanmugam, and Payel Das"
    },
    {
      "index": 8,
      "title": "UCI machine learning repository, 2017.",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Dheeru Dua and Casey Graff"
    },
    {
      "index": 9,
      "title": "Explaining data-driven decisions made by AI systems: The counterfactual approach",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint",
      "authors": "C. Fernández-Loría, F. Provost, and X. Han"
    },
    {
      "index": 10,
      "title": "Predictive learning via rule ensembles",
      "abstract": "",
      "year": "2008",
      "venue": "Ann. Appl. Stat.",
      "authors": "Jerome H Friedman and Bogdan E Popescu"
    },
    {
      "index": 11,
      "title": "Explaining Black-Box Algorithms Using Probabilistic Contrastive Counterfactuals",
      "abstract": "",
      "year": "2021",
      "venue": "SIGMOD",
      "authors": "Sainyam Galhotra, Romila Pradhan, and Babak Salimi",
      "orig_title": "Explaining black-box algorithms using probabilistic contrastive counterfactuals",
      "paper_id": "2103.11972v2"
    },
    {
      "index": 12,
      "title": "Extremely randomized trees",
      "abstract": "",
      "year": "2006",
      "venue": "Mach. Learn.",
      "authors": "Pierre Geurts, Damien Ernst, and Louis Wehenkel"
    },
    {
      "index": 13,
      "title": "Beef: Balanced english explanations of forecasts",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Trans. Comput. Soc. Syst.",
      "authors": "Sachin Grover, Chiara Pulice, Gerardo I. Simari, and V. S. Subrahmanian"
    },
    {
      "index": 14,
      "title": "Actual Causality",
      "abstract": "",
      "year": "2016",
      "venue": "The MIT Press",
      "authors": "Joseph Y Halpern"
    },
    {
      "index": 15,
      "title": "Causes and explanations: A structural-model approach. Part I: Causes",
      "abstract": "",
      "year": "2005",
      "venue": "Br. J. Philos. Sci.",
      "authors": "Joseph Y Halpern and Judea Pearl"
    },
    {
      "index": 16,
      "title": "Causes and explanations: A structural-model approach. Part II: Explanations",
      "abstract": "",
      "year": "2005",
      "venue": "Br. J. Philos. Sci.",
      "authors": "Joseph Y Halpern and Judea Pearl"
    },
    {
      "index": 17,
      "title": "Causal Shapley values: Exploiting causal knowledge to explain individual predictions of complex models",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Tom Heskes, Evi Sijben, Ioan Gabriel Bucur, and Tom Claassen"
    },
    {
      "index": 18,
      "title": "Abduction-based explanations for machine learning models",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI",
      "authors": "Alexey Ignatiev, Nina Narodytska, and Joao Marques-Silva"
    },
    {
      "index": 19,
      "title": "Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction",
      "abstract": "",
      "year": "2015",
      "venue": "Cambridge University Press",
      "authors": "Guido W Imbens and Donald B Rubin"
    },
    {
      "index": 20,
      "title": "Norm theory: Comparing reality to its alternatives",
      "abstract": "",
      "year": "1986",
      "venue": "Psychol. Rev.",
      "authors": "Daniel Kahneman and Dale T. Miller"
    },
    {
      "index": 21,
      "title": "A survey of algorithmic recourse: Definitions, formulations, solutions, and prospects",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint",
      "authors": "Amir-Hossein Karimi, Gilles Barthe, Bernhard Schölkopf, and Isabel Valera"
    },
    {
      "index": 22,
      "title": "Algorithmic recourse under imperfect causal knowledge: a probabilistic approach",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Amir-Hossein Karimi, Julius von Kügelgen, Bernhard Schölkopf, and Isabel Valera",
      "orig_title": "Algorithmic recourse under imperfect causal knowledge: A probabilistic approach",
      "paper_id": "2006.06831v3"
    },
    {
      "index": 23,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2015",
      "venue": "The 3rd International Conference for Learning Representations",
      "authors": "Diederik P. Kingma and Jimmy Ba"
    },
    {
      "index": 24,
      "title": "Adult income dataset, 1996.",
      "abstract": "",
      "year": "1996",
      "venue": "",
      "authors": "Ronny Kochavi and Barry Becker"
    },
    {
      "index": 25,
      "title": "Problems with Shapley-value-based explanations as feature importance measures",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Indra Kumar, Suresh Venkatasubramanian, Carlos Scheidegger, and Sorelle Friedler"
    },
    {
      "index": 26,
      "title": "“How do I fool you?”: Manipulating User Trust via Misleading Black Box Explanations",
      "abstract": "",
      "year": "2020",
      "venue": "AIES",
      "authors": "Himabindu Lakkaraju and Osbert Bastani",
      "orig_title": "“How do I fool you?”: Manipulating user trust via misleading black box explanations",
      "paper_id": "1911.06473v1"
    },
    {
      "index": 27,
      "title": "Faithful and customizable explanations of black box models",
      "abstract": "",
      "year": "2019",
      "venue": "AIES",
      "authors": "Himabindu Lakkaraju, Ece Kamar, Rich Caruana, and Jure Leskovec"
    },
    {
      "index": 28,
      "title": "Testing Statistical Hypotheses",
      "abstract": "",
      "year": "2005",
      "venue": "Springer",
      "authors": "E.L. Lehmann and Joseph P. Romano"
    },
    {
      "index": 29,
      "title": "Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model",
      "abstract": "",
      "year": "2015",
      "venue": "Ann. Appl. Stat.",
      "authors": "Benjamin Letham, Cynthia Rudin, Tyler H McCormick, and David Madigan",
      "orig_title": "Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model",
      "paper_id": "1511.01644v1"
    },
    {
      "index": 30,
      "title": "Causation",
      "abstract": "",
      "year": "1973",
      "venue": "J. Philos.",
      "authors": "David Lewis"
    },
    {
      "index": 31,
      "title": "Contrastive explanation",
      "abstract": "",
      "year": "1990",
      "venue": "Royal Inst. Philos. Suppl.",
      "authors": "Peter Lipton"
    },
    {
      "index": 32,
      "title": "The Mythos of Model Interpretability",
      "abstract": "",
      "year": "2018",
      "venue": "Commun. ACM",
      "authors": "Zachary Lipton",
      "orig_title": "The mythos of model interpretability",
      "paper_id": "1606.03490v3"
    },
    {
      "index": 33,
      "title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Schölkopf, and Olivier Bachem",
      "orig_title": "Challenging common assumptions in the unsupervised learning of disentangled representations",
      "paper_id": "1811.12359v4"
    },
    {
      "index": 34,
      "title": "A Unified Approach to Interpreting Model Predictions",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "Scott M Lundberg and Su-In Lee",
      "orig_title": "A unified approach to interpreting model predictions",
      "paper_id": "1705.07874v2"
    },
    {
      "index": 35,
      "title": "Learning word vectors for sentiment analysis",
      "abstract": "",
      "year": "2011",
      "venue": "ACL",
      "authors": "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts"
    },
    {
      "index": 36,
      "title": "Causes and conditions",
      "abstract": "",
      "year": "1965",
      "venue": "Am. Philos. Q.",
      "authors": "J.L. Mackie"
    },
    {
      "index": 37,
      "title": "The Explanation Game: Explaining Machine Learning Models Using Shapley Values",
      "abstract": "",
      "year": "2020",
      "venue": "CD-MAKE",
      "authors": "Luke Merrick and Ankur Taly",
      "orig_title": "The explanation game: Explaining machine learning models using shapley values",
      "paper_id": "1909.08128v3"
    },
    {
      "index": 38,
      "title": "The magical number seven, plus or minus two: Some limits on our capacity for processing information",
      "abstract": "",
      "year": "1955",
      "venue": "Psychol. Rev.",
      "authors": "George A. Miller"
    },
    {
      "index": 39,
      "title": "Explanation in Artificial Intelligence: Insights from the Social Sciences",
      "abstract": "",
      "year": "2019",
      "venue": "Artif. Intell.",
      "authors": "Tim Miller",
      "orig_title": "Explanation in artificial intelligence: Insights from the social sciences",
      "paper_id": "1706.07269v3"
    },
    {
      "index": 40,
      "title": "Interpretable Machine Learning: A Guide for Making Black Box Models Interpretable",
      "abstract": "",
      "year": "2021",
      "venue": "Münich",
      "authors": "Christoph Molnar"
    },
    {
      "index": 41,
      "title": "Towards unifying feature attribution and counterfactual explanations: Different means to the same end",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint",
      "authors": "Ramaravind K. Mothilal, Divyat Mahajan, Chenhao Tan, and Amit Sharma"
    },
    {
      "index": 42,
      "title": "Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations",
      "abstract": "",
      "year": "2020",
      "venue": "FAT*",
      "authors": "Ramaravind K. Mothilal, Amit Sharma, and Chenhao Tan",
      "orig_title": "Explaining machine learning classifiers through diverse counterfactual explanations",
      "paper_id": "1905.07697v2"
    },
    {
      "index": 43,
      "title": "Assessing heuristic machine learning explanations with model counting",
      "abstract": "",
      "year": "2019",
      "venue": "SAT",
      "authors": "Nina Narodytska, Aditya Shrotri, Kuldeep S Meel, Alexey Ignatiev, and Joao Marques-Silva"
    },
    {
      "index": 44,
      "title": "Causality: Models, Reasoning, and Inference",
      "abstract": "",
      "year": "2000",
      "venue": "Cambridge University Press",
      "authors": "Judea Pearl"
    },
    {
      "index": 45,
      "title": "GloVe: Global vectors for word representation",
      "abstract": "",
      "year": "2014",
      "venue": "EMNLP",
      "authors": "Jeffrey Pennington, Richard Socher, and Christopher D Manning"
    },
    {
      "index": 46,
      "title": "A comparison of instance-level counterfactual explanation algorithms for behavioral and textual data: SEDC, LIME-C and SHAP-C",
      "abstract": "",
      "year": "2020",
      "venue": "Adv. Data Anal. Classif.",
      "authors": "Yanou Ramon, David Martens, Foster Provost, and Theodoros Evgeniou"
    },
    {
      "index": 47,
      "title": "Anchors: High-precision model-agnostic explanations",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI",
      "authors": "Marco Túlio Ribeiro, Sameer Singh, and Carlos Guestrin"
    },
    {
      "index": 48,
      "title": "Semantically equivalent adversarial rules for debugging NLP models",
      "abstract": "",
      "year": "2018",
      "venue": "ACL",
      "authors": "Marco Túlio Ribeiro, Sameer Singh, and Carlos Guestrin"
    },
    {
      "index": 49,
      "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
      "abstract": "",
      "year": "2019",
      "venue": "Nat. Mach. Intell.",
      "authors": "Cynthia Rudin"
    },
    {
      "index": 50,
      "title": "A value for n-person games",
      "abstract": "",
      "year": "1953",
      "venue": "Contributions to the Theory of Games",
      "authors": "Lloyd Shapley"
    },
    {
      "index": 51,
      "title": "LIMEtree: Interactively customisable explanations based on local surrogate multi-output regression trees",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint",
      "authors": "Kacper Sokol and Peter Flach"
    },
    {
      "index": 52,
      "title": "SpamAssassin, 2006.",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": "Apache SpamAssassin, 2006."
    },
    {
      "index": 53,
      "title": "The optimal discovery procedure: A new approach to simultaneous significance testing",
      "abstract": "",
      "year": "2007",
      "venue": "J. Royal Stat. Soc. Ser. B Methodol.",
      "authors": "John D Storey"
    },
    {
      "index": 54,
      "title": "The Many Shapley Values for Model Explanation",
      "abstract": "",
      "year": "2019",
      "venue": "ACM",
      "authors": "Mukund Sundararajan and Amir Najmi",
      "orig_title": "The many Shapley values for model explanation",
      "paper_id": "1908.08474v2"
    },
    {
      "index": 55,
      "title": "Probabilities of causation: Bounds and identification",
      "abstract": "",
      "year": "2000",
      "venue": "Ann. Math. Artif. Intell.",
      "authors": "Jin Tian and Judea Pearl"
    },
    {
      "index": 56,
      "title": "Actionable Recourse in Linear Classification",
      "abstract": "",
      "year": "2019",
      "venue": "FAT*",
      "authors": "Berk Ustun, Alexander Spangher, and Yang Liu",
      "orig_title": "Actionable recourse in linear classification",
      "paper_id": "1809.06514v2"
    },
    {
      "index": 57,
      "title": "General theory for interactions in sufficient cause models with dichotomous exposures",
      "abstract": "",
      "year": "2012",
      "venue": "Ann. Stat.",
      "authors": "Tyler J VanderWeele and Thomas S Richardson"
    },
    {
      "index": 58,
      "title": "Empirical and counterfactual conditions for sufficient cause interactions",
      "abstract": "",
      "year": "2008",
      "venue": "Biometrika",
      "authors": "Tyler J VanderWeele and James M Robins"
    },
    {
      "index": 59,
      "title": "Theory of Games and Economic Behavior",
      "abstract": "",
      "year": "1944",
      "venue": "Princeton University Press",
      "authors": "John von Neumann and Oskar Morgenstern"
    },
    {
      "index": 60,
      "title": "Counterfactual explanations without opening the black box: Automated decisions and the GDPR",
      "abstract": "",
      "year": "2018",
      "venue": "Harvard J. Law Technol.",
      "authors": "Sandra Wachter, Brent Mittelstadt, and Chris Russell"
    },
    {
      "index": 61,
      "title": "The explanation game: a formal framework for interpretable machine learning",
      "abstract": "",
      "year": "2020",
      "venue": "Synthese",
      "authors": "David S Watson and Luciano Floridi"
    },
    {
      "index": 62,
      "title": "The What-If Tool: Interactive Probing of Machine Learning Models",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Trans. Vis. Comput. Graph.",
      "authors": "J. Wexler, M. Pushkarna, T. Bolukbasi, M. Wattenberg, F. Viégas, and J. Wilson",
      "orig_title": "The what-if tool: Interactive probing of machine learning models",
      "paper_id": "1907.04135v2"
    },
    {
      "index": 63,
      "title": "Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Xin Zhang, Armando Solar-Lezama, and Rishabh Singh",
      "orig_title": "Interpreting neural network judgments via minimal, stable, and symbolic corrections",
      "paper_id": "1802.07384v2"
    }
  ]
}