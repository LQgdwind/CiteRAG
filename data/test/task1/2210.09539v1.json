{
  "paper_id": "2210.09539v1",
  "title": "Hierarchical Model-Based Imitation Learning for Planning in Autonomous Driving",
  "abstract": "Abstract\nWe demonstrate the first large-scale application of model-based generative adversarial imitation learning (MGAIL) to the task of dense urban self-driving. We augment standard MGAIL using a hierarchical model to enable generalization to arbitrary goal routes, and measure performance using a closed-loop evaluation framework with simulated interactive agents. We train policies from expert trajectories collected from real vehicles driving over 100,000 miles in San Francisco, and demonstrate a steerable policy that can navigate robustly even in a zero-shot setting, generalizing to synthetic scenarios with novel goals that never occurred in real-world driving. We also demonstrate the importance of mixing closed-loop MGAIL losses with open-loop behavior cloning losses, and show our best policy approaches the performance of the expert. We evaluate our imitative model in both average and challenging scenarios, and show how it can serve as a useful prior to plan successful trajectories.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Reward (Mis)design for Autonomous Driving",
      "abstract": "",
      "year": "2021",
      "venue": "CoRR",
      "authors": "W. B. Knox, A. Allievi, H. Banzhaf, F. Schmitt, and P. Stone",
      "orig_title": "Reward (mis)design for autonomous driving",
      "paper_id": "2104.13906v2"
    },
    {
      "index": 1,
      "title": "ALVINN: an autonomous land vehicle in a neural network",
      "abstract": "",
      "year": "1989",
      "venue": "Advances in neural information processing systems 1",
      "authors": "D. A. Pomerleau"
    },
    {
      "index": 2,
      "title": "End to End Learning for Self-Driving Cars",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "M. Bojarski et al.",
      "orig_title": "End to end learning for self-driving cars",
      "paper_id": "1604.07316v1"
    },
    {
      "index": 3,
      "title": "ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "M. Bansal et al.",
      "orig_title": "Chauffeurnet: Learning to drive by imitating the best and synthesizing the worst",
      "paper_id": "1812.03079v1"
    },
    {
      "index": 4,
      "title": "A reduction of imitation learning and structured prediction to no-regret online learning",
      "abstract": "",
      "year": "2011",
      "venue": "AI Stats",
      "authors": "S. Ross et al."
    },
    {
      "index": 5,
      "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "S. Levine, A. Kumar, G. Tucker, and J. Fu",
      "orig_title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems",
      "paper_id": "2005.01643v3"
    },
    {
      "index": 6,
      "title": "End-to-end differentiable adversarial imitation learning",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "N. Baram, O. Anschel, I. Caspi, and S. Mannor"
    },
    {
      "index": 7,
      "title": "Of moments and matching: A game-theoretic framework for closing the imitation gap",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "G. Swamy, S. Choudhury, J. A. Bagnell, and Z. S. Wu"
    },
    {
      "index": 8,
      "title": "Symphony: Learning realistic and diverse agents for autonomous driving simulation",
      "abstract": "",
      "year": "2022",
      "venue": "Robotics and Automation (ICRA), 2022 IEEE International Conference on",
      "authors": "M. Igl, D. Kim, A. Kuefler, P. Mougin, P. Shah, K. Shiarlis, D. Anguelov, M. Palatucci, B. White, and S. Whiteson"
    },
    {
      "index": 9,
      "title": "Integrated Task and Motion Planning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "C. R. Garrett, R. Chitnis, R. Holladay, B. Kim, T. Silver, L. P. Kaelbling, and T. Lozano-Pérez",
      "orig_title": "Integrated task and motion planning",
      "paper_id": "2010.01083v1"
    },
    {
      "index": 10,
      "title": "IRIS: Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data",
      "abstract": "",
      "year": "2020",
      "venue": "2020 IEEE International Conference on Robotics and Automation (ICRA)",
      "authors": "A. Mandlekar et al.",
      "orig_title": "Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data",
      "paper_id": "1911.05321v2"
    },
    {
      "index": 11,
      "title": "Goal-conditioned Imitation Learning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Y. Ding, C. Florensa, M. Phielipp, and P. Abbeel",
      "orig_title": "Goal-conditioned imitation learning",
      "paper_id": "1906.05838v3"
    },
    {
      "index": 12,
      "title": "Causal Confusion in Imitation Learning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "P. de Haan, D. Jayaraman, and S. Levine",
      "orig_title": "Causal confusion in imitation learning",
      "paper_id": "1905.11979v2"
    },
    {
      "index": 13,
      "title": "Autonomy 2.0: Why is self-driving always 5 years away?",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "A. Jain, L. D. Pero, H. Grimmett, and P. Ondruska",
      "orig_title": "Autonomy 2.0: Why is self-driving always 5 years away?",
      "paper_id": "2107.08142v3"
    },
    {
      "index": 14,
      "title": "Algorithms for inverse reinforcement learning",
      "abstract": "",
      "year": "2000",
      "venue": "Proc. 17th International Conf. on Machine Learning",
      "authors": "A. Y. Ng and S. Russell"
    },
    {
      "index": 15,
      "title": "Apprenticeship learning via inverse reinforcement learning",
      "abstract": "",
      "year": "2004",
      "venue": "ICML",
      "authors": "P. Abbeel and A. Y. Ng"
    },
    {
      "index": 16,
      "title": "Learning from Demonstration in the Wild",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "F. Behbahani, K. Shiarlis, X. Chen, V. Kurin, S. Kasewa, C. Stirbu, J. Gomes, S. Paul, F. A. Oliehoek, J. Messias, and S. Whiteson",
      "orig_title": "Learning from demonstration in the wild",
      "paper_id": "1811.03516v2"
    },
    {
      "index": 17,
      "title": "Maximum entropy inverse reinforcement learning",
      "abstract": "",
      "year": "2008",
      "venue": "AAAI",
      "authors": "B. D. Ziebart, A. L. Maas, J. A. Bagnell, and A. K. Dey"
    },
    {
      "index": 18,
      "title": "Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization",
      "abstract": "",
      "year": "2016",
      "venue": "International Conference on Machine Learning",
      "authors": "C. Finn, S. Levine, and P. Abbeel",
      "orig_title": "Guided cost learning: Deep inverse optimal control via policy optimization",
      "paper_id": "1603.00448v3"
    },
    {
      "index": 19,
      "title": "Maximum margin planning",
      "abstract": "",
      "year": "2006",
      "venue": "23rd international conference on Machine learning",
      "authors": "N. D. Ratliff, J. A. Bagnell, and M. A. Zinkevich"
    },
    {
      "index": 20,
      "title": "A survey of robot learning from demonstration",
      "abstract": "",
      "year": "2009",
      "venue": "Rob. Auton. Syst.",
      "authors": "B. D. Argall, S. Chernova, M. Veloso, and B. Browning"
    },
    {
      "index": 21,
      "title": "Imitation learning: A survey of learning methods",
      "abstract": "",
      "year": "2017",
      "venue": "ACM Comput. Surv.",
      "authors": "A. Hussein, M. M. Gaber, E. Elyan, and C. Jayne"
    },
    {
      "index": 22,
      "title": "Shaking the foundations: delusions in sequence models for interaction and control",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "P. A. Ortega et al.",
      "orig_title": "Shaking the foundations: delusions in sequence models for interaction and control",
      "paper_id": "2110.10819v1"
    },
    {
      "index": 23,
      "title": "Generative adversarial imitation learning",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "J. Ho and S. Ermon"
    },
    {
      "index": 24,
      "title": "Learning Robust Rewards with Adversarial Inverse Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "J. Fu, K. Luo, and S. Levine",
      "orig_title": "Learning robust rewards with adversarial inverse reinforcement learning",
      "paper_id": "1710.11248v2"
    },
    {
      "index": 25,
      "title": "InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Y. Li, J. Song, and S. Ermon",
      "orig_title": "Infogail: Interpretable imitation learning from visual demonstrations",
      "paper_id": "1703.08840v2"
    },
    {
      "index": 26,
      "title": "End-to-end Driving via Conditional Imitation Learning",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "F. Codevilla, M. Müller, A. López, V. Koltun, and A. Dosovitskiy",
      "orig_title": "End-to-end driving via conditional imitation learning",
      "paper_id": "1710.02410v2"
    },
    {
      "index": 27,
      "title": "SafetyNet: Safe planning for real-world self-driving vehicles using machine-learned policies",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "M. Vitelli et al.",
      "orig_title": "Safetynet: Safe planning for real-world self-driving vehicles using machine-learned policies",
      "paper_id": "2109.13602v1"
    },
    {
      "index": 28,
      "title": "Learning by cheating",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "D. Chen, B. Zhou, V. Koltun, and P. Krähenbühl",
      "orig_title": "Learning by cheating",
      "paper_id": "1912.12294v1"
    },
    {
      "index": 29,
      "title": "Learning to drive in a day",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "A. Kendall, J. Hawke, D. Janz, P. Mazur, D. Reda, J.-M. Allen, V.-D. Lam, A. Bewley, and A. Shah"
    },
    {
      "index": 30,
      "title": "A survey of motion planning and control techniques for self-driving urban vehicles",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "B. Paden, M. Cap, S. Z. Yong, D. Yershov, and E. Frazzoli"
    },
    {
      "index": 31,
      "title": "MultiPath++: Efficient Information Fusion and Trajectory Aggregation for Behavior Prediction",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "B. Varadarajan et al.",
      "orig_title": "Multipath++: Efficient information fusion and trajectory aggregation for behavior prediction",
      "paper_id": "2111.14973v3"
    },
    {
      "index": 32,
      "title": "Precog: Prediction conditioned on goals in visual multi-agent settings",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "N. Rhinehart, R. McAllister, K. Kitani, and S. Levine"
    },
    {
      "index": 33,
      "title": "Deep Imitative Models for Flexible Inference, Planning, and Control",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "N. Rhinehart, R. McAllister, and S. Levine",
      "orig_title": "Deep imitative models for flexible inference, planning, and control",
      "paper_id": "1810.06544v4"
    },
    {
      "index": 34,
      "title": "Deep Structured Reactive Planning",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "J. Liu, W. Zeng, R. Urtasun, and E. Yumer",
      "orig_title": "Deep structured reactive planning",
      "paper_id": "2101.06832v2"
    },
    {
      "index": 35,
      "title": "MP3: A Unified Model to Map, Perceive, Predict and Plan",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "S. Casas, A. Sadat, and R. Urtasun",
      "orig_title": "Mp3: A unified model to map, perceive, predict and plan",
      "paper_id": "2101.06806v1"
    },
    {
      "index": 36,
      "title": "Large Scale Interactive Motion Forecasting for Autonomous Driving : The Waymo Open Motion Dataset",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "S. Ettinger et al.",
      "orig_title": "Large scale interactive motion forecasting for autonomous driving : The waymo open motion dataset",
      "paper_id": "2104.10133v1"
    },
    {
      "index": 37,
      "title": "End-to-end Interpretable Neural Motion Planner",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "W. Zeng, W. Luo, S. Suo, A. Sadat, B. Yang, S. Casas, and R. Urtasun",
      "orig_title": "End-to-end interpretable neural motion planner",
      "paper_id": "2101.06679v1"
    },
    {
      "index": 38,
      "title": "Scene Transformer: A unified architecture for predicting multiple agent trajectories",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "J. Ngiam et al.",
      "orig_title": "Scene transformer: A unified architecture for predicting multiple agent trajectories",
      "paper_id": "2106.08417v3"
    },
    {
      "index": 39,
      "title": "TrafficSim: Learning to Simulate Realistic Multi-Agent Behaviors",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "S. Suo, S. Regalado, S. Casas, and R. Urtasun",
      "orig_title": "Trafficsim: Learning to simulate realistic multi-agent behaviors",
      "paper_id": "2101.06557v1"
    },
    {
      "index": 40,
      "title": "nuplan: A closed-loop ml-based planning benchmark for autonomous vehicles",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "H. Caesar et al."
    },
    {
      "index": 41,
      "title": "SMARTS: Scalable Multi-Agent Reinforcement Learning Training School for Autonomous Driving",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint",
      "authors": "M. Zhou et al.",
      "orig_title": "Smarts: Scalable multi-agent reinforcement learning training school for autonomous driving",
      "paper_id": "2010.09776v2"
    },
    {
      "index": 42,
      "title": "CARLA: An Open Urban Driving Simulator",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint",
      "authors": "A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V. Koltun",
      "orig_title": "CARLA: An open urban driving simulator",
      "paper_id": "1711.03938v1"
    },
    {
      "index": 43,
      "title": "Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "M. O’Kelly, A. Sinha, H. Namkoong, J. Duchi, and R. Tedrake",
      "orig_title": "Scalable end-to-end autonomous vehicle testing via rare-event simulation",
      "paper_id": "1811.00145v3"
    },
    {
      "index": 44,
      "title": "Virtual to Real Reinforcement Learning for Autonomous Driving",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "X. Pan, Y. You, Z. Wang, and C. Lu",
      "orig_title": "Virtual to real reinforcement learning for autonomous driving",
      "paper_id": "1704.03952v4"
    },
    {
      "index": 45,
      "title": "Driving Policy Transfer via Modularity and Abstraction",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "M. Müller, A. Dosovitskiy, B. Ghanem, and V. Koltun",
      "orig_title": "Driving policy transfer via modularity and abstraction",
      "paper_id": "1804.09364v3"
    },
    {
      "index": 46,
      "title": "Multimodal Motion Prediction with Stacked Transformers",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Y. Liu, J. Zhang, L. Fang, Q. Jiang, and B. Zhou",
      "orig_title": "Multimodal motion prediction with stacked transformers",
      "paper_id": "2103.11624v2"
    },
    {
      "index": 47,
      "title": "Perceiver: General perception with iterative attention",
      "abstract": "",
      "year": "2021",
      "venue": "ICML",
      "authors": "A. Jaegle et al."
    },
    {
      "index": 48,
      "title": "A survey on policy search for robotics",
      "abstract": "",
      "year": "2013",
      "venue": "Foundations and trends in Robotics",
      "authors": "M. P. Deisenroth et al."
    },
    {
      "index": 49,
      "title": "Cognitive models from subcognitive skills",
      "abstract": "",
      "year": "1990",
      "venue": "IEE control engineering series",
      "authors": "D. Michie, M. Bain, and J. Hayes-Miches"
    },
    {
      "index": 50,
      "title": "Variance reduction properties of the reparameterization trick",
      "abstract": "",
      "year": "2019",
      "venue": "AI Stats",
      "authors": "M. Xu et al."
    },
    {
      "index": 51,
      "title": "Computing the shortest path: A* search meets graph theory",
      "abstract": "",
      "year": "2003",
      "venue": "Symposium on Discrete Algorithms",
      "authors": "A. Goldberg and C. Harrelson"
    },
    {
      "index": 52,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "neural information processing systems",
      "authors": "A. Vaswani et al.",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 53,
      "title": "Multi-Head Attention for Multi-Modal Joint Vehicle Motion Forecasting",
      "abstract": "",
      "year": "2020",
      "venue": "ICRA",
      "authors": "J. Mercat et al.",
      "orig_title": "Multi-head attention for multi-modal joint vehicle motion forecasting",
      "paper_id": "1910.03650v3"
    },
    {
      "index": 54,
      "title": "Set transformer: A framework for attention-based permutation-invariant neural networks",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "J. Lee et al."
    },
    {
      "index": 55,
      "title": "Layer normalization",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint",
      "authors": "J. L. Ba, J. R. Kiros, and G. E. Hinton"
    },
    {
      "index": 56,
      "title": "On the properties of neural machine translation: Encoder-decoder approaches",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint",
      "authors": "K. Cho, B. Van Merriënboer, D. Bahdanau, and Y. Bengio"
    },
    {
      "index": 57,
      "title": "Generative Adversarial Imitation from Observation",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint",
      "authors": "F. Torabi, G. Warnell, and P. Stone",
      "orig_title": "Generative adversarial imitation from observation",
      "paper_id": "1807.06158v4"
    },
    {
      "index": 58,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2015",
      "venue": "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings",
      "authors": "D. P. Kingma and J. Ba"
    },
    {
      "index": 59,
      "title": "Concrete Problems in AI Safety",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman, and D. Mané",
      "orig_title": "Concrete problems in ai safety",
      "paper_id": "1606.06565v2"
    }
  ]
}