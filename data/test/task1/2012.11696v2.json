{
  "paper_id": "2012.11696v2",
  "title": "Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge",
  "abstract": "Abstract\nImage captioning has recently demonstrated impressive progress largely owing to the introduction of neural network algorithms trained on curated dataset like MS-COCO.\nOften work in this field is motivated by the promise of deployment of captioning systems in practical applications.\nHowever, the scarcity of data and contexts in many competition datasets renders the utility of systems trained on these datasets limited as an assistive technology in real-world settings, such as helping visually impaired people navigate and accomplish everyday tasks.\nThis gap motivated the introduction of the novel VizWiz dataset, which consists of images taken by the visually impaired and captions that have useful, task-oriented information.\nIn an attempt to help the machine learning computer vision field realize its promise of producing technologies that have positive social impact, the curators of the VizWiz dataset host several competitions, including one for image captioning.\nThis work details the theory and engineering from our winning submission to the 2020 captioning competition.\nOur work provides a step towards improved assistive image captioning systems.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Seeing AI Mobile App",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "AI, M."
    },
    {
      "index": 1,
      "title": "SPICE: Semantic Propositional Image Caption Evaluation",
      "abstract": "",
      "year": "2016",
      "venue": "European Conference on Computer Vision",
      "authors": "Anderson, P., Fernando, B., Johnson, M., Gould, S.",
      "orig_title": "Spice: Semantic propositional image caption evaluation",
      "paper_id": "1607.08822v1"
    },
    {
      "index": 2,
      "title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L.",
      "orig_title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering",
      "paper_id": "1707.07998v3"
    },
    {
      "index": 3,
      "title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang, L.",
      "orig_title": "Bottom-up and top-down attention for image captioning and visual question answering",
      "paper_id": "1707.07998v3"
    },
    {
      "index": 4,
      "title": "What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Computer Vision (ICCV)",
      "authors": "Baek, J., Kim, G., Lee, J., Park, S., Han, D., Yun, S., Lee, H.",
      "orig_title": "What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis",
      "paper_id": "1904.01906v4"
    },
    {
      "index": 5,
      "title": "Character Region Awareness for Text Detection",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Baek, Y., Lee, B., Han, D., Yun, S., Lee, H.",
      "orig_title": "Character Region Awareness for Text Detection",
      "paper_id": "1904.01941v1"
    },
    {
      "index": 6,
      "title": "METEOR: An automatic metric for MT evaluation with improved correlation with human judgments",
      "abstract": "",
      "year": "2005",
      "venue": "ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
      "authors": "Banerjee, S., Lavie, A."
    },
    {
      "index": 7,
      "title": "VizWiz: Nearly Real-Time Answers to Visual Questions",
      "abstract": "",
      "year": "2010",
      "venue": "ACM Symposium on User Interface Software and Technology",
      "authors": "Bigham, J.P., Jayant, C., Ji, H., Little, G., Miller, A., Miller, R.C., Yeh, T."
    },
    {
      "index": 8,
      "title": "Enriching Word Vectors with Subword Information",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1607.04606",
      "authors": "Bojanowski, P., Grave, E., Joulin, A., Mikolov, T.",
      "orig_title": "Enriching word vectors with subword information",
      "paper_id": "1607.04606v2"
    },
    {
      "index": 9,
      "title": "Visual challenges in the everyday lives of blind people",
      "abstract": "",
      "year": "2013",
      "venue": "SIGCHI Conference on Human Factors in Computing Systems",
      "authors": "Brady, E., Morris, M.R., Zhong, Y., White, S., Bigham, J.P."
    },
    {
      "index": 10,
      "title": "B-SCST: Bayesian Self-Critical Sequence Training for Image Captioning",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2004.02435",
      "authors": "Bujimalla, S., Subedar, M., Tickoo, O.",
      "orig_title": "B-SCST: Bayesian Self-Critical Sequence Training for Image Captioning",
      "paper_id": "2004.02435v2"
    },
    {
      "index": 11,
      "title": "Feature Refinement for Common Sense Captioning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Burns, A., Saenko, K., Bryan, P."
    },
    {
      "index": 12,
      "title": "Assessing Image Quality Issues for Real-World Problems",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Chiu, T.Y., Zhao, Y., Gurari, D.",
      "orig_title": "Assessing Image Quality Issues for Real-World Problems",
      "paper_id": "2003.12511v2"
    },
    {
      "index": 13,
      "title": "Towards Diverse and Natural Image Descriptions via a Conditional GAN",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Dai, B., Lin, D., Urtasun, R., Fidler, S.",
      "orig_title": "Towards Diverse and Natural Image Descriptions via a Conditional GAN",
      "paper_id": "1703.06029v3"
    },
    {
      "index": 14,
      "title": "Alleviating Noisy Data in Image Captioning with Cooperative Distillation",
      "abstract": "",
      "year": "2020",
      "venue": "VizWiz Grand Challenge Workshop, CVPR",
      "authors": "Dognin, P., Melnyk, I., Mroueh, Y., Padhi, I., Rigotti, M., Ross, J., Schiff, Y.",
      "orig_title": "Alleviating Noisy Data in Image Captioning with Cooperative Distillation",
      "paper_id": "2012.11691v1"
    },
    {
      "index": 15,
      "title": "Adversarial Semantic Alignment for Improved Image Captions",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Dognin, P., Melnyk, I., Mroueh, Y., Ross, J., Sercu, T.",
      "orig_title": "Adversarial Semantic Alignment for Improved Image Captions",
      "paper_id": "1805.00063v3"
    },
    {
      "index": 16,
      "title": "CapWAP: Captioning with a Purpose",
      "abstract": "",
      "year": "2020",
      "venue": "ACL",
      "authors": "Fisch, A., Lee, K., Chang, M.W., Clark, J.H., Barzilay, R.",
      "orig_title": "CapWAP: Captioning with a Purpose",
      "paper_id": "2011.04264v1"
    },
    {
      "index": 17,
      "title": "Box Features Masking and Bayesian Self-Critical Sequence Training for VizWiz Captions Challenge",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Gan, Z., Lin, K."
    },
    {
      "index": 18,
      "title": "Flask web development: developing web applications with python",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Grinberg, M."
    },
    {
      "index": 19,
      "title": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning",
      "abstract": "",
      "year": "2016",
      "venue": "Annual Meeting of the Association for Computational Linguistics",
      "authors": "Gu, J., Lu, Z., Li, H., Li, V.O.",
      "orig_title": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning",
      "paper_id": "1603.06393v3"
    },
    {
      "index": 20,
      "title": "VizWiz Grand Challenge: Answering Visual Questions from Blind People",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Gurari, D., Li, Q., Stangl, A.J., Guo, A., Lin, C., Grauman, K., Bigham, J.P.",
      "orig_title": "VizWiz Grand Challenge: Answering Visual Questions From Blind People",
      "paper_id": "1802.08218v4"
    },
    {
      "index": 21,
      "title": "Vizwiz Grand Challenge:Caption Images Taken by People Who Are Blind",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Gurari, D., Zhao, Y."
    },
    {
      "index": 22,
      "title": "Captioning Images Taken by People Who Are Blind",
      "abstract": "",
      "year": "2020",
      "venue": "Computer Vision – ECCV",
      "authors": "Gurari, D., Zhao, Y., Zhang, M., Bhattacharya, N.",
      "orig_title": "Captioning Images Taken by People Who Are Blind",
      "paper_id": "2002.08565v2"
    },
    {
      "index": 23,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "He, K., Zhang, X., Ren, S., Sun, J.",
      "orig_title": "Deep Residual Learning for Image Recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 24,
      "title": "Attention on Attention for Image Captioning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Huang, L., Wang, W., Chen, J., Wei, X.Y."
    },
    {
      "index": 25,
      "title": "Watson Text to Speech",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "IBM."
    },
    {
      "index": 26,
      "title": "People with visual impairment training personal object recognizers: Feasibility and challenges",
      "abstract": "",
      "year": "2017",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Kacorri, H., Kitani, K.M., Bigham, J.P., Asakawa, C."
    },
    {
      "index": 27,
      "title": "Spatially Aware Multimodal Transformers for TextVQA",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Kant, Y., Batra, D., Anderson, P., Schwing, A., Parikh, D., Lu, J., Agrawal, H.",
      "orig_title": "Spatially Aware Multimodal Transformers for TextVQA",
      "paper_id": "2007.12146v2"
    },
    {
      "index": 28,
      "title": "Deep Visual-Semantic Alignments for Generating Image Descriptions",
      "abstract": "",
      "year": "2015",
      "venue": "CVPR",
      "authors": "Karpathy, A., Li, F.F.",
      "orig_title": "Deep visual-semantic alignments for generating image descriptions.",
      "paper_id": "1412.2306v2"
    },
    {
      "index": 29,
      "title": "ROUGE: A Package for Automatic Evaluation of Summaries",
      "abstract": "",
      "year": "2004",
      "venue": "ACL-04 Workshop",
      "authors": "Lin, C.Y."
    },
    {
      "index": 30,
      "title": "Microsoft COCO: Common Objects in Context",
      "abstract": "",
      "year": "2014",
      "venue": "EECV",
      "authors": "Lin, T., Maire, M., Belongie, J., Bourdev, D., Girshick, B., Hays, J., Zitnick, L.",
      "orig_title": "Microsoft COCO: Common Objects in Context",
      "paper_id": "1405.0312v3"
    },
    {
      "index": 31,
      "title": "Improved Image Captioning via Policy Gradient optimization of SPIDEr",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Liu, S., Zhu, Z., Ye, N., Guadarrama, S., Murphy, K."
    },
    {
      "index": 32,
      "title": "Neural Baby Talk",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Lu, J., Yang, J., Batra, D., Parikh, D.",
      "orig_title": "Neural Baby Talk",
      "paper_id": "1803.09845v1"
    },
    {
      "index": 33,
      "title": "Winning Google Conceptual captions challenge",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Luo, R., Vered, G., Bracha, L., Chechik, G., Shakhnarovich, G."
    },
    {
      "index": 34,
      "title": "Exploring the Limits of Weakly Supervised Pretraining",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Mahajan, D., Girshick, R., Ramanathan, V., He, K., Paluri, M., Li, Y., van der Maaten, L.",
      "orig_title": "Exploring the Limits of Weakly Supervised Pretraining",
      "paper_id": "1805.00932v1"
    },
    {
      "index": 35,
      "title": "OrCam Wearable Device",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "OrCam."
    },
    {
      "index": 36,
      "title": "X-Linear Attention Networks for Image Captioning",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Pan, Y., Yao, T., Li, Y., Mei, T."
    },
    {
      "index": 37,
      "title": "BLEU: a method for automatic evaluation of machine translation",
      "abstract": "",
      "year": "2002",
      "venue": "Association for Computational Linguistics",
      "authors": "Papineni, K., Roukos, S., Ward, T., Zhu, W.J."
    },
    {
      "index": 38,
      "title": "Sequence Level Training with Recurrent Neural Networks",
      "abstract": "",
      "year": "2015",
      "venue": "ICLR",
      "authors": "Ranzato, M., Chopra, S., Auli, M., Zaremba, W.",
      "orig_title": "Sequence Level Training with Recurrent Neural Networks",
      "paper_id": "1511.06732v7"
    },
    {
      "index": 39,
      "title": "YOLO9000: Better, Faster, Stronger",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "Redmon, J., Farhadi, A.",
      "orig_title": "YOLO9000: Better, Faster, Stronger",
      "paper_id": "1612.08242v1"
    },
    {
      "index": 40,
      "title": "Self-critical Sequence Training for Image Captioning",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Rennie, S.J., Marcheret, E., Mroueh, Y., Ross, J., Goel, V.",
      "orig_title": "Self-Critical Sequence Training for Image Captioning",
      "paper_id": "1612.00563v2"
    },
    {
      "index": 41,
      "title": "NavCog AI Suite case",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Research, I., cmu."
    },
    {
      "index": 42,
      "title": "Get To The Point: Summarization with Pointer-Generator Networks",
      "abstract": "",
      "year": "2017",
      "venue": "Annual Meeting of the Association for Computational Linguistics",
      "authors": "See, A., Liu, P.J., Manning, C.D.",
      "orig_title": "Get To The Point: Summarization with Pointer-Generator Networks",
      "paper_id": "1704.04368v2"
    },
    {
      "index": 43,
      "title": "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning",
      "abstract": "",
      "year": "2018",
      "venue": "ACL",
      "authors": "Sharma, P., Ding, N., Goodman, S., Soricut, R."
    },
    {
      "index": 44,
      "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1703.10476",
      "authors": "Shetty, R., Rohrbach, M., Hendricks, L.A., Fritz, M., Schiele, B.",
      "orig_title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training",
      "paper_id": "1703.10476v2"
    },
    {
      "index": 45,
      "title": "I Hope This Is Helpful: Understanding Crowdworkers’ Challenges and Motivations for an Image Description Task",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. ACM Hum.-Comput. Interact.",
      "authors": "Simons, R.N., Gurari, D., Fleischmann, K.R."
    },
    {
      "index": 46,
      "title": "Towards VQA Models That Can Read",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Singh, A., Natarajan, V., Shah, M., Jiang, Y., Chen, X., Batra, D., Rohrbach, M.",
      "orig_title": "Towards VQA Models That Can Read",
      "paper_id": "1904.08920v2"
    },
    {
      "index": 47,
      "title": "EfficientDet: Scalable and Efficient Object Detection",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Tan, M., Pang, R., Le, Q.V.",
      "orig_title": "EfficientDet: Scalable and Efficient Object Detection",
      "paper_id": "1911.09070v7"
    },
    {
      "index": 48,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Polosukhin, I.",
      "orig_title": "Attention is All you Need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 49,
      "title": "CIDEr: Consensus-based Image Description Evaluation",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Vedantam, R., Lawrence Zitnick, C., Parikh, D.",
      "orig_title": "Cider: Consensus-based image description evaluation",
      "paper_id": "1411.5726v2"
    },
    {
      "index": 50,
      "title": "CIDEr: Consensus-based Image Description Evaluation",
      "abstract": "",
      "year": "2015",
      "venue": "CVPR",
      "authors": "Vedantam, R., Zitnick, C.L., Parikh, D.",
      "orig_title": "CIDEr: Consensus-based image description evaluation.",
      "paper_id": "1411.5726v2"
    },
    {
      "index": 51,
      "title": "Show and Tell: A Neural Image Caption Generator",
      "abstract": "",
      "year": "2015",
      "venue": "CVPR",
      "authors": "Vinyals, O., Toshev, A., Bengio, S., Erhan, D.",
      "orig_title": "Show and Tell: A Neural Image Caption Generator",
      "paper_id": "1411.4555v2"
    },
    {
      "index": 52,
      "title": "Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Vinyals, O., Toshev, A., Bengio, S., Erhan, D.",
      "orig_title": "Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge",
      "paper_id": "1609.06647v1"
    },
    {
      "index": 53,
      "title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning",
      "abstract": "",
      "year": "1992",
      "venue": "Machine learning",
      "authors": "Williams, R.J."
    },
    {
      "index": 54,
      "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.",
      "abstract": "",
      "year": "2015",
      "venue": "ICML",
      "authors": "Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A.C., Salakhutdinov, R., Bengio, Y."
    },
    {
      "index": 55,
      "title": "Show, attend and tell: Neural image caption generation with visual attention",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:1502.03044",
      "authors": "Xu, K., Ba, J., Kiros, R., Courville, A., Salakhutdinov, R., Zemel, R., Bengio, Y."
    },
    {
      "index": 56,
      "title": "Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Yao, T., Pan, Y., Li, Y., Mei, T.",
      "orig_title": "Incorporating copying mechanism in image captioning for learning novel objects",
      "paper_id": "1708.05271v1"
    },
    {
      "index": 57,
      "title": "Vision Skills Needed to Answer Visual Questions",
      "abstract": "",
      "year": "2020",
      "venue": "Proc. ACM Hum.-Comput. Interact.",
      "authors": "Zeng, X., Wang, Y., Chiu, T.Y., Bhattacharya, N., Gurari, D.",
      "orig_title": "Vision Skills Needed to Answer Visual Questions",
      "paper_id": "2010.03160v1"
    },
    {
      "index": 58,
      "title": "BERTScore: Evaluating Text Generation with BERT",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1904.09675",
      "authors": "Zhang, T., Kishore, V., Wu, F., Weinberger, K.Q., Artzi, Y.",
      "orig_title": "Bertscore: Evaluating text generation with bert",
      "paper_id": "1904.09675v3"
    },
    {
      "index": 59,
      "title": "Texygen: A benchmarking platform for text generation models",
      "abstract": "",
      "year": "2018",
      "venue": "ACM SIGIR Conference on Research & Development in Information Retrieval",
      "authors": "Zhu, Y., Lu, S., Zheng, L., Guo, J., Zhang, W., Wang, J., Yu, Y."
    }
  ]
}