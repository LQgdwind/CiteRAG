{
  "paper_id": "2412.14056v1",
  "title": "A Review of Multimodal Explainable Artificial Intelligence: Past, Present and Future",
  "abstract": "Abstract\nArtificial intelligence (AI) has rapidly developed through advancements in computational power and the growth of massive datasets. However, this progress has also heightened challenges in interpreting the “black-box” nature of AI models. To address these concerns, eXplainable AI (XAI) has emerged with a focus on transparency and interpretability to enhance human understanding and trust in AI decision-making processes. In the context of multimodal data fusion and complex reasoning scenarios, the proposal of Multimodal eXplainable AI (MXAI) integrates multiple modalities for prediction and explanation tasks. Meanwhile, the advent of Large Language Models (LLMs) has led to remarkable breakthroughs in natural language processing, yet their complexity has further exacerbated the issue of MXAI. To gain key insights into the development of MXAI methods and provide crucial guidance for building more transparent, fair, and trustworthy AI systems, we review the MXAI methods from a historical perspective and categorize them across four eras: traditional machine learning, deep learning, discriminative foundation models, and generative LLMs. We also review evaluation metrics and datasets used in MXAI research, concluding with a discussion of future challenges and directions. A project related to this review has been created at https://github.com/ShilinSun/mxai_review.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 1,
      "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "ICML",
      "authors": "J. Li, D. Li, S. Savarese, and S. Hoi",
      "orig_title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models",
      "paper_id": "2301.12597v3"
    },
    {
      "index": 2,
      "title": "Chatgpt: Get instant answers, find creative inspiration, learn something new",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "OpenAI"
    },
    {
      "index": 3,
      "title": "Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and Reasoning",
      "abstract": "",
      "year": "2024",
      "venue": "IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)",
      "authors": "E. Sachdeva, N. Agarwal, S. Chundi, S. Roelofs, J. Li, M. Kochenderfer, C. Choi, and B. Dariush",
      "orig_title": "Rank2tell: A multimodal driving dataset for joint importance ranking and reasoning",
      "paper_id": "2309.06597v2"
    },
    {
      "index": 4,
      "title": "Unbox the Black-box for the Medical Explainable AI via Multi-modal and Multi-centre Data Fusion: A Mini-Review, Two Showcases and Beyond",
      "abstract": "",
      "year": "2022",
      "venue": "Information Fusion",
      "authors": "G. Yang, Q. Ye, and J. Xia",
      "orig_title": "Unbox the black-box for the medical explainable ai via multi-modal and multi-centre data fusion: A mini-review, two showcases and beyond",
      "paper_id": "2102.01998v1"
    },
    {
      "index": 5,
      "title": "Multimodal Explainable Artificial Intelligence: A Comprehensive Review of Methodological Advances and Future Research Directions",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.05731",
      "authors": "N. Rodis, C. Sardianos, G. T. Papadopoulos, P. Radoglou-Grammatikis, P. Sarigiannidis, and I. Varlamis",
      "orig_title": "Multimodal explainable artificial intelligence: A comprehensive review of methodological advances and future research directions",
      "paper_id": "2306.05731v2"
    },
    {
      "index": 6,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "CVPR",
      "authors": "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei"
    },
    {
      "index": 7,
      "title": "Visualizing higher-layer features of a deep network",
      "abstract": "",
      "year": "2009",
      "venue": "University of Montreal",
      "authors": "D. Erhan, Y. Bengio, A. Courville, and P. Vincent"
    },
    {
      "index": 8,
      "title": "Beyond intuition: Rethinking token attributions inside transformers",
      "abstract": "",
      "year": "2022",
      "venue": "TMLR",
      "authors": "J. Chen, X. Li, L. Yu, D. Dou, and H. Xiong"
    },
    {
      "index": 9,
      "title": "Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "H. Chefer, S. Gur, and L. Wolf",
      "orig_title": "Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers",
      "paper_id": "2103.15679v1"
    },
    {
      "index": 10,
      "title": "Transformer Interpretability Beyond Attention Visualization",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Chefer, Hila and Gur, Shir and Wolf, Lior",
      "orig_title": "Transformer interpretability beyond attention visualization",
      "paper_id": "2012.09838v2"
    },
    {
      "index": 11,
      "title": "Explainable artificial intelligence (xai): What we know and what is left to attain trustworthy artificial intelligence",
      "abstract": "",
      "year": "2023",
      "venue": "Information Fusion",
      "authors": "S. Ali, T. Abuhmed, S. El-Sappagh, K. Muhammad, J. M. Alonso-Moral, R. Confalonieri, R. Guidotti, J. Del Ser, N. Díaz-Rodríguez, and F. Herrera"
    },
    {
      "index": 12,
      "title": "Rethinking Interpretability in the Era of Large Language Models",
      "abstract": "",
      "year": "2024",
      "venue": "arXiv preprint arXiv:2402.01761",
      "authors": "C. Singh, J. P. Inala, M. Galley, R. Caruana, and J. Gao",
      "orig_title": "Rethinking interpretability in the era of large language models",
      "paper_id": "2402.01761v1"
    },
    {
      "index": 13,
      "title": "Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era",
      "abstract": "",
      "year": "2024",
      "venue": "arXiv preprint arXiv:2403.08946",
      "authors": "X. Wu, H. Zhao, Y. Zhu, Y. Shi, F. Yang, T. Liu, X. Zhai, W. Yao, J. Li, and M. Du",
      "orig_title": "Usable xai: 10 strategies towards exploiting explainability in the llm era",
      "paper_id": "2403.08946v2"
    },
    {
      "index": 14,
      "title": "From Understanding to Utilization: A Survey on Explainability for Large Language Models",
      "abstract": "",
      "year": "2024",
      "venue": "arXiv preprint arXiv:2401.12874",
      "authors": "H. Luo and L. Specia",
      "orig_title": "From understanding to utilization: A survey on explainability for large language models",
      "paper_id": "2401.12874v2"
    },
    {
      "index": 15,
      "title": "Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy",
      "abstract": "",
      "year": "2005",
      "venue": "IEEE Transactions on pattern analysis and machine intelligence",
      "authors": "H. Peng, F. Long, and C. Ding"
    },
    {
      "index": 16,
      "title": "Rule-based learning systems for support vector machines",
      "abstract": "",
      "year": "2006",
      "venue": "Neural Processing Letters",
      "authors": "H. Núñez, C. Angulo, and A. Catala"
    },
    {
      "index": 17,
      "title": "Assessment of landslide susceptibility by decision trees in the metropolitan area of istanbul, turkey",
      "abstract": "",
      "year": "2010",
      "venue": "Mathematical Problems in Engineering",
      "authors": "H. NEFESLİOĞLU, E. Sezer, C. GÖKÇEOĞLU, A. BOZKIR, and T. Duman"
    },
    {
      "index": 18,
      "title": "Mining high-speed data streams",
      "abstract": "",
      "year": "2000",
      "venue": "KDD",
      "authors": "P. Domingos and G. Hulten"
    },
    {
      "index": 19,
      "title": "Auto-encoding variational bayes",
      "abstract": "",
      "year": "2013",
      "venue": "arXiv preprint arXiv:1312.6114",
      "authors": "D. P. Kingma and M. Welling"
    },
    {
      "index": 20,
      "title": "beta-vae: Learning basic visual concepts with a constrained variational framework.",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR (Poster)",
      "authors": "I. Higgins, L. Matthey, A. Pal, C. P. Burgess, X. Glorot, M. M. Botvinick, S. Mohamed, and A. Lerchner"
    },
    {
      "index": 21,
      "title": "Learning Transferable Visual Models From Natural Language Supervision",
      "abstract": "",
      "year": "2021",
      "venue": "ICML",
      "authors": "A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark et al.",
      "orig_title": "Learning transferable visual models from natural language supervision",
      "paper_id": "2103.00020v1"
    },
    {
      "index": 22,
      "title": "Principal component analysis for special types of data.",
      "abstract": "",
      "year": "2002",
      "venue": "Springer",
      "authors": "I. T. Jolliffe"
    },
    {
      "index": 23,
      "title": "Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks",
      "abstract": "",
      "year": "2018",
      "venue": "WACV",
      "authors": "A. Chattopadhay, A. Sarkar, P. Howlader, and V. N. Balasubramanian"
    },
    {
      "index": 24,
      "title": "Multimodal Explainable Artificial Intelligence: A Comprehensive Review of Methodological Advances and Future Research Directions",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.05731",
      "authors": "N. Rodis, C. Sardianos, G. T. Papadopoulos, P. Radoglou-Grammatikis, P. Sarigiannidis, and I. Varlamis",
      "orig_title": "Multimodal explainable artificial intelligence: A comprehensive review of methodological advances and future research directions",
      "paper_id": "2306.05731v2"
    },
    {
      "index": 25,
      "title": "Explainable Generative AI (GenXAI): A Survey, Conceptualization, and Research Agenda",
      "abstract": "",
      "year": "2024",
      "venue": "arXiv preprint arXiv:2404.09554",
      "authors": "J. Schneider",
      "orig_title": "Explainable generative ai (genxai): A survey, conceptualization, and research agenda",
      "paper_id": "2404.09554v1"
    },
    {
      "index": 26,
      "title": "Explainability for large language models: A survey",
      "abstract": "",
      "year": "2024",
      "venue": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "H. Zhao, H. Chen, F. Yang, N. Liu, H. Deng, H. Cai, S. Wang, D. Yin, and M. Du"
    },
    {
      "index": 27,
      "title": "Explainable artificial intelligence (xai) from a user perspective: A synthesis of prior literature and problematizing avenues for future research",
      "abstract": "",
      "year": "2023",
      "venue": "Technological Forecasting and Social Change",
      "authors": "A. K. M. B Haque, A. K. M. N. Islam, and P. Mikalef"
    },
    {
      "index": 28,
      "title": "A systematic review of explainable artificial intelligence models and applications: Recent developments and future trends",
      "abstract": "",
      "year": "2023",
      "venue": "Decision Analytics Journal",
      "authors": "S. A and S. R"
    },
    {
      "index": 29,
      "title": "Explainability of Vision Transformers: A Comprehensive Review and New Perspectives",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2311.06786",
      "authors": "R. Kashefi, L. Barekatain, M. Sabokrou, and F. Aghaeipoor",
      "orig_title": "Explainability of vision transformers: A comprehensive review and new perspectives",
      "paper_id": "2311.06786v1"
    },
    {
      "index": 30,
      "title": "Explainability and evaluation of vision transformers: An in-depth experimental study",
      "abstract": "",
      "year": "2023",
      "venue": "Electronics",
      "authors": "S. Stassin, V. Corduant, S. A. Mahmoudi, and X. Siebert"
    },
    {
      "index": 31,
      "title": "Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE transactions on pattern analysis and machine intelligence",
      "authors": "Y. Rong, T. Leemann, T.-T. Nguyen, L. Fiedler, P. Qian, V. Unhelkar, T. Seidel, G. Kasneci, and E. Kasneci",
      "orig_title": "Towards human-centered explainable ai: A survey of user studies for model explanations",
      "paper_id": "2210.11584v5"
    },
    {
      "index": 32,
      "title": "Explainable ai (xai): A systematic meta-survey of current challenges and future opportunities",
      "abstract": "",
      "year": "2023",
      "venue": "Knowledge-Based Systems",
      "authors": "W. Saeed and C. Omlin"
    },
    {
      "index": 33,
      "title": "A survey on xai and natural language explanations",
      "abstract": "",
      "year": "2023",
      "venue": "Information Processing & Management",
      "authors": "E. Cambria, L. Malandri, F. Mercorio, M. Mezzanzanica, and N. Nobani"
    },
    {
      "index": 34,
      "title": "Knowledge graphs as tools for explainable machine learning: A survey",
      "abstract": "",
      "year": "2022",
      "venue": "Artificial Intelligence",
      "authors": "I. Tiddi and S. Schlobach"
    },
    {
      "index": 35,
      "title": "Explainable ai methods-a brief overview",
      "abstract": "",
      "year": "2022",
      "venue": "International workshop on extending explainable AI beyond deep models and classifiers",
      "authors": "A. Holzinger, A. Saranti, C. Molnar, P. Biecek, and W. Samek"
    },
    {
      "index": 36,
      "title": "Counterfactual explanations and how to find them: literature review and benchmarking",
      "abstract": "",
      "year": "2022",
      "venue": "Data Mining and Knowledge Discovery",
      "authors": "R. Guidotti"
    },
    {
      "index": 37,
      "title": "Explainable ai for time series classification: a review, taxonomy and research directions",
      "abstract": "",
      "year": "2022",
      "venue": "Ieee Access",
      "authors": "A. Theissler, F. Spinnato, U. Schlegel, and R. Guidotti"
    },
    {
      "index": 38,
      "title": "A survey of contrastive and counterfactual explanation generation methods for explainable artificial intelligence",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Access",
      "authors": "I. Stepin, J. M. Alonso, A. Catala, and M. Pereira-Fariña"
    },
    {
      "index": 39,
      "title": "Notions of explainability and evaluation approaches for explainable artificial intelligence",
      "abstract": "",
      "year": "2021",
      "venue": "Information Fusion",
      "authors": "G. Vilone and L. Longo"
    },
    {
      "index": 40,
      "title": "Explainable artificial intelligence: objectives, stakeholders, and future research opportunities",
      "abstract": "",
      "year": "2022",
      "venue": "Information Systems Management",
      "authors": "C. Meske, E. Bunde, J. Schneider, and M. Gersch"
    },
    {
      "index": 41,
      "title": "Explainable ai: A review of machine learning interpretability methods",
      "abstract": "",
      "year": "2020",
      "venue": "Entropy",
      "authors": "P. Linardatos, V. Papastefanopoulos, and S. Kotsiantis"
    },
    {
      "index": 42,
      "title": "Explainable Artificial Intelligence Approaches: A Survey",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2101.09429",
      "authors": "S. R. Islam, W. Eberle, S. K. Ghafoor, and M. Ahmed",
      "orig_title": "Explainable artificial intelligence approaches: A survey",
      "paper_id": "2101.09429v1"
    },
    {
      "index": 43,
      "title": "Argumentation and explainable artificial intelligence: a survey",
      "abstract": "",
      "year": "2021",
      "venue": "The Knowledge Engineering Review",
      "authors": "A. Vassiliades, N. Bassiliades, and T. Patkos"
    },
    {
      "index": 44,
      "title": "A survey on the explainability of supervised machine learning",
      "abstract": "",
      "year": "2021",
      "venue": "Journal of Artificial Intelligence Research",
      "authors": "N. Burkart and M. F. Huber"
    },
    {
      "index": 45,
      "title": "Reviewing the need for explainable artificial intelligence (xai)",
      "abstract": "",
      "year": "2021",
      "venue": "54th Hawaii International Conference on System Sciences (HICSS)",
      "authors": "J. Gerlings, A. Shollo, and I. Constantiou"
    },
    {
      "index": 46,
      "title": "Explainable Artificial Intelligence (XAI): An Engineering Perspective",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2101.03613",
      "authors": "F. Hussain, R. Hussain, and E. Hossain",
      "orig_title": "Explainable artificial intelligence (xai): An engineering perspective",
      "paper_id": "2101.03613v1"
    },
    {
      "index": 47,
      "title": "Interpretable Deep Learning: Interpretation, Interpretability, Trustworthiness, and Beyond",
      "abstract": "",
      "year": "2022",
      "venue": "Knowledge and Information Systems",
      "authors": "X. Li, H. Xiong, X. Li, X. Wu, X. Zhang, J. Liu, J. Bian, and D. Dou",
      "orig_title": "Interpretable deep learning: Interpretation, interpretability, trustworthiness, and beyond",
      "paper_id": "2103.10689v3"
    },
    {
      "index": 48,
      "title": "Minimum redundancy feature selection from microarray gene expression data",
      "abstract": "",
      "year": "2005",
      "venue": "Journal of bioinformatics and computational biology",
      "authors": "C. Ding and H. Peng"
    },
    {
      "index": 49,
      "title": "Feature selection for high-dimensional data—a pearson redundancy based filter",
      "abstract": "",
      "year": "2008",
      "venue": "Computer recognition systems 2",
      "authors": "J. Biesiada and W. Duch"
    },
    {
      "index": 50,
      "title": "“Emotion recognition using brain activity",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 51,
      "title": "“Normalized mutual information feature selection",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": ""
    },
    {
      "index": 52,
      "title": "“Optimization method based extreme learning machine for classification",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 53,
      "title": "“Eye movement analysis for activity recognition using electrooculography",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 54,
      "title": "K. Kreutz-Delgado",
      "abstract": "",
      "year": "2001",
      "venue": "",
      "authors": ""
    },
    {
      "index": 55,
      "title": "“Gene selection for cancer classification using support vector machines",
      "abstract": "",
      "year": "2002",
      "venue": "",
      "authors": ""
    },
    {
      "index": 56,
      "title": "“Feature subset selection for blood pressure classification using orthogonal forward selection",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": ""
    },
    {
      "index": 57,
      "title": "“Feature selection for high-dimensional industrial data.” in ESANN",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 58,
      "title": "” Machine learning",
      "abstract": "",
      "year": "2001",
      "venue": "",
      "authors": ""
    },
    {
      "index": 59,
      "title": "“Exploration of a hybrid feature selection algorithm",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": ""
    },
    {
      "index": 60,
      "title": "“Ant colony optimization for feature selection in face recognition",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 61,
      "title": "“Optimization of intrusion detection through fast hybrid feature selection",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 62,
      "title": "“A wrapper for feature selection based on mutual information",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": ""
    },
    {
      "index": 63,
      "title": "“A hybrid feature selection approach for microarray gene expression data",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": ""
    },
    {
      "index": 64,
      "title": "“Application of a hybrid wavelet feature selection method in the design of a self-paced brain interface system",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": ""
    },
    {
      "index": 65,
      "title": "“Feature subset selection in large dimensionality domains",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 66,
      "title": "“Independent component analysis: algorithms and applications",
      "abstract": "",
      "year": "2000",
      "venue": "",
      "authors": ""
    },
    {
      "index": 67,
      "title": "“A global geometric framework for nonlinear dimensionality reduction",
      "abstract": "",
      "year": "2000",
      "venue": "",
      "authors": ""
    },
    {
      "index": 68,
      "title": "“Nonlinear dimensionality reduction by locally linear embedding",
      "abstract": "",
      "year": "2000",
      "venue": "",
      "authors": ""
    },
    {
      "index": 69,
      "title": "” IEEE transactions on pattern analysis and machine intelligence",
      "abstract": "",
      "year": "2001",
      "venue": "",
      "authors": ""
    },
    {
      "index": 70,
      "title": "“Two-dimensional linear discriminant analysis",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 71,
      "title": "“Two-dimensional linear discriminant analysis of principle component vectors for face recognition",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": ""
    },
    {
      "index": 72,
      "title": "“Visualizing data using t-sne.” Journal of machine learning research",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 73,
      "title": "“A note on two-dimensional linear discriminant analysis",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 74,
      "title": "“Two-dimensional direct and weighted linear discriminant analysis for face recognition",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 75,
      "title": "“On the relationship between feature selection and classification accuracy",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 76,
      "title": "“What is principal component analysis?” Nature biotechnology",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 77,
      "title": "“1d-lda vs. 2d-lda: When is vector-based linear discriminant analysis better than matrix-based?” Pattern Recognition",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 78,
      "title": "“Generalized linear discriminant analysis: a unified framework and efficient model selection",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 79,
      "title": "“Mpca: Multilinear principal component analysis of tensor objects",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 80,
      "title": "“Robust principal component analysis: Exact recovery of corrupted low-rank matrices via convex optimization",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": ""
    },
    {
      "index": 81,
      "title": "“Structured sparse principal component analysis",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 82,
      "title": "“Two-stage image denoising by principal component analysis with local pixel grouping",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 83,
      "title": "“Unsupervised kernel dimension reduction",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 84,
      "title": "Interaction effects in logistic regression. Sage",
      "abstract": "",
      "year": "2001",
      "venue": "",
      "authors": ""
    },
    {
      "index": 85,
      "title": "“Purposeful selection of variables in logistic regression",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 86,
      "title": "“An introduction to logistic regression analysis and reporting",
      "abstract": "",
      "year": "2002",
      "venue": "",
      "authors": ""
    },
    {
      "index": 87,
      "title": "“Logistic regression: Why we cannot do what we think we can do",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 88,
      "title": "“Rocr: visualizing classifier performance in r",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 89,
      "title": "J. del Campo-Ávila",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 90,
      "title": "“Supporting the dynamic evolution of web service protocols in service-oriented architectures",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 91,
      "title": "“Learning to match xml schemas-a decision tree based approach",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": ""
    },
    {
      "index": 92,
      "title": "“An k nn model-based approach and its application in text categorization",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 93,
      "title": "“Application of the ga/knn method to seldi proteomics data",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 94,
      "title": "“The truth is in there-rule extraction from opaque models using genetic programming.” in FLAIRS",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 95,
      "title": "“Rule extraction from support vector machines.” in Esann",
      "abstract": "",
      "year": "2002",
      "venue": "",
      "authors": ""
    },
    {
      "index": 96,
      "title": "“Bayesian models of cognition",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 97,
      "title": "“A bayesian model for repeated measures zero-inflated count data with application to outpatient psychiatric service use",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 98,
      "title": "“Probabilistic climate change predictions applying bayesian model averaging",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": ""
    },
    {
      "index": 99,
      "title": "“Bayesian econometric methods cambridge",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": ""
    },
    {
      "index": 100,
      "title": "“Trust and tam in online shopping: An integrated model",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": ""
    },
    {
      "index": 101,
      "title": "Making things happen: A theory of causal explanation. Oxford university press",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 102,
      "title": "“Explanation and understanding",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": ""
    },
    {
      "index": 103,
      "title": "“Causal inference in statistics: An overview",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": ""
    },
    {
      "index": 104,
      "title": "Statistical learning from a regression perspective. Springer",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 105,
      "title": "“Predictive analytics in information systems research",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 106,
      "title": "“The interplay between theory and method",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": ""
    },
    {
      "index": 107,
      "title": "“To explain or to predict?” 2010",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 108,
      "title": "“Causal inference without counterfactuals",
      "abstract": "",
      "year": "2000",
      "venue": "",
      "authors": ""
    },
    {
      "index": 109,
      "title": "“Evidence-based public health: moving beyond randomized trials",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 110,
      "title": "“Varieties of causal intervention",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 111,
      "title": "“Causal reasoning through intervention",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": ""
    },
    {
      "index": 112,
      "title": "“Toward causal inference with interference",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 113,
      "title": "Causality. Cambridge university press",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": ""
    },
    {
      "index": 114,
      "title": "“Feature deduction and ensemble design of intrusion detection systems",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 115,
      "title": "“Building efficient intrusion detection model based on principal component analysis and c4. 5",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": ""
    },
    {
      "index": 116,
      "title": "“Transferring knowledge by prior feature sampling",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 117,
      "title": "“Density estimation trees",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 118,
      "title": "“Towards an effective cooperation of the user and the computer for classification",
      "abstract": "",
      "year": "2000",
      "venue": "",
      "authors": ""
    },
    {
      "index": 119,
      "title": "“Data mining and visualization for decision support and modeling of public health-care resources",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": ""
    },
    {
      "index": 120,
      "title": "“A bias correction algorithm for the gini variable importance measure in classification trees",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 121,
      "title": "” BMC bioinformatics",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": ""
    },
    {
      "index": 122,
      "title": "“Visualization method and tool for interactive learning of large decision trees",
      "abstract": "",
      "year": "2002",
      "venue": "",
      "authors": ""
    },
    {
      "index": 123,
      "title": "“Analysis and correction of bias in total decrease in node impurity measures for tree-based algorithms",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 124,
      "title": "“Visual classification: an interactive approach to decision tree construction",
      "abstract": "",
      "year": "1999",
      "venue": "",
      "authors": ""
    },
    {
      "index": 125,
      "title": "“Eclectic rule-extraction from support vector machines",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": ""
    },
    {
      "index": 126,
      "title": "“Extracting the knowledge embedded in support vector machines",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 127,
      "title": "“Support vector machines with symbolic interpretation",
      "abstract": "",
      "year": "2002",
      "venue": "",
      "authors": ""
    },
    {
      "index": 128,
      "title": "“Rule extraction from trained support vector machines",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 129,
      "title": "“Rule extraction from linear support vector machines",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 130,
      "title": "“A multiple kernel support vector machine scheme for feature selection and rule extraction from gene expression data of cancer tissue",
      "abstract": "",
      "year": "2007",
      "venue": "",
      "authors": ""
    },
    {
      "index": 131,
      "title": "“Support vector machine interpretation",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": ""
    },
    {
      "index": 132,
      "title": "“Paintingclass: interactive construction",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": ""
    },
    {
      "index": 133,
      "title": "“Linked independent component analysis for multimodal data fusion",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 134,
      "title": "“Simultaneous analysis of coupled data matrices subject to different amounts of noise",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 135,
      "title": "“Multisensor data fusion: A review of the state-of-the-art",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 136,
      "title": "“New algorithm for integration between wireless microwave sensor network and radar for improved rainfall measurement and mapping",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 137,
      "title": "“Multimodal data fusion: an overview of methods",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 138,
      "title": "“Dynamical reconfiguration strategy of a multi sensor data fusion algorithm based on information theory",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 139,
      "title": "“Scalable tensor factorizations for incomplete data",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 140,
      "title": "Show and Tell: A Neural Image Caption Generator",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Show and tell: A neural image caption generator",
      "paper_id": "1411.4555v2"
    },
    {
      "index": 141,
      "title": "Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Multimodal sentiment analysis with word-level fusion and reinforcement learning",
      "paper_id": "1802.00924v1"
    },
    {
      "index": 142,
      "title": "Sequence to Sequence – Video to Text",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Sequence to sequence-video to text",
      "paper_id": "1505.00487v3"
    },
    {
      "index": 143,
      "title": "Human Action Recognition using Factorized Spatio-Temporal Convolutional Networks",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Human action recognition using factorized spatio-temporal convolutional networks",
      "paper_id": "1510.00562v1"
    },
    {
      "index": 144,
      "title": "“Supersparse linear integer models for optimized medical scoring systems",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 145,
      "title": "“Interpretable decision sets: A joint framework for description and prediction",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 146,
      "title": "“Simple rules for complex decisions",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 147,
      "title": "“Interpretability of fuzzy systems: Current research trends and prospects",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 148,
      "title": "“Accurate intelligible models with pairwise interactions",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 149,
      "title": "“Deep inside convolutional networks: Visualising image classification models and saliency maps",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 150,
      "title": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Synthesizing the preferred inputs for neurons in neural networks via deep generator networks",
      "paper_id": "1605.09304v5"
    },
    {
      "index": 151,
      "title": "“Adaptive deconvolutional networks for mid and high level feature learning",
      "abstract": "",
      "year": "2025",
      "venue": "",
      "authors": ""
    },
    {
      "index": 152,
      "title": "“Visualizing and understanding convolutional networks",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 153,
      "title": "Understanding Deep Image Representations by Inverting Them",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Understanding deep image representations by inverting them",
      "paper_id": "1412.0035v1"
    },
    {
      "index": 154,
      "title": "Understanding Neural Networks Through Deep Visualization",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Understanding neural networks through deep visualization",
      "paper_id": "1506.06579v1"
    },
    {
      "index": 155,
      "title": "“Multifaceted feature visualization: Uncovering the different types of features learned by each neuron in deep neural networks",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 156,
      "title": "“Convergent learning: Do different neural networks learn the same representations?” arXiv preprint arXiv:1511.07543",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 157,
      "title": "Understanding Black-box Predictions via Influence Functions",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Understanding black-box predictions via influence functions",
      "paper_id": "1703.04730v3"
    },
    {
      "index": 158,
      "title": "Opening the black box of Deep Neural Networks via Information",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Opening the black box of deep neural networks via information",
      "paper_id": "1703.00810v3"
    },
    {
      "index": 159,
      "title": "The Application of Two-level Attention Models in Deep Convolutional Neural Network for Fine-grained Image Classification",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“The application of two-level attention models in deep convolutional neural network for fine-grained image classification",
      "paper_id": "1411.6447v1"
    },
    {
      "index": 160,
      "title": "Hierarchical Question-Image Co-Attention for Visual Question Answering",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Hierarchical question-image co-attention for visual question answering",
      "paper_id": "1606.00061v5"
    },
    {
      "index": 161,
      "title": "“Human attention in visual question answering: Do humans and deep networks look at the same regions?” Computer Vision and Image Understanding",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 162,
      "title": "“Infogan: Interpretable representation learning by information maximizing generative adversarial nets",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 163,
      "title": "“Vqa: Visual question answering",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 164,
      "title": "Generating Visual Explanations",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Generating visual explanations",
      "paper_id": "1603.08507v1"
    },
    {
      "index": 165,
      "title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Multimodal compact bilinear pooling for visual question answering and visual grounding",
      "paper_id": "1606.01847v3"
    },
    {
      "index": 166,
      "title": "Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Right for the right reasons: Training differentiable models by constraining their explanations",
      "paper_id": "1703.03717v2"
    },
    {
      "index": 167,
      "title": "“Interpretable deep models for icu outcome prediction",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 168,
      "title": "TreeView: Peeking into Deep Neural Networks Via Feature-Space Partitioning",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Treeview: Peeking into deep neural networks via feature-space partitioning",
      "paper_id": "1611.07429v1"
    },
    {
      "index": 169,
      "title": "Explaining NonLinear Classification Decisions with Deep Taylor Decomposition",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Explaining nonlinear classification decisions with deep taylor decomposition",
      "paper_id": "1512.02479v1"
    },
    {
      "index": 170,
      "title": "“Not just a black box: Learning important features through propagating activation differences",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 171,
      "title": "“Axiomatic attribution for deep networks",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 172,
      "title": "Learning how to explain neural networks: PatternNet and PatternAttribution",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Learning how to explain neural networks: Patternnet and patternattribution",
      "paper_id": "1705.05598v2"
    },
    {
      "index": 173,
      "title": "“On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 174,
      "title": "“Why Should I Trust You?” Explaining the Predictions of Any Classifier",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“” why should i trust you?” explaining the predictions of any classifier",
      "paper_id": "1602.04938v3"
    },
    {
      "index": 175,
      "title": "Learning Deep Features for Discriminative Localization",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Learning deep features for discriminative localization",
      "paper_id": "1512.04150v1"
    },
    {
      "index": 176,
      "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Grad-cam: Visual explanations from deep networks via gradient-based localization",
      "paper_id": "1610.02391v4"
    },
    {
      "index": 177,
      "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Explaining recurrent neural network predictions in sentiment analysis",
      "paper_id": "1706.07206v2"
    },
    {
      "index": 178,
      "title": "Visualizing and Understanding Recurrent Networks",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Visualizing and understanding recurrent networks",
      "paper_id": "1506.02078v2"
    },
    {
      "index": 179,
      "title": "Interpretable Recurrent Neural Networks Using Sequential Sparse Recovery",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Interpretable recurrent neural networks using sequential sparse recovery",
      "paper_id": "1611.07252v1"
    },
    {
      "index": 180,
      "title": "“Increasing the interpretability of recurrent neural networks using hidden markov models",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 181,
      "title": "N. Díaz-Rodríguez",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 182,
      "title": "Interweaving Multimodal Interaction with Flexible Unit Visualizations for Data Exploration",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Interweaving multimodal interaction with flexible unit visualizations for data exploration",
      "paper_id": "2004.10428v1"
    },
    {
      "index": 183,
      "title": "“Multimodal data to design visual learning analytics for understanding regulation of learning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 184,
      "title": "An Analysis of Visual Question Answering Algorithms",
      "abstract": "",
      "year": "1973",
      "venue": "",
      "authors": "",
      "orig_title": "“An analysis of visual question answering algorithms",
      "paper_id": "1703.09684v2"
    },
    {
      "index": 185,
      "title": "“Toward explainable affective computing: A review",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 186,
      "title": "EmoCo: Visual Analysis of Emotion Coherence in Presentation Videos",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Emoco: Visual analysis of emotion coherence in presentation videos",
      "paper_id": "1907.12918v2"
    },
    {
      "index": 187,
      "title": "“Emotioncues: Emotion-oriented visual summarization of classroom videos",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 188,
      "title": "DeHumor: Visual Analytics for Decomposing Humor",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "",
      "orig_title": "“Dehumor: Visual analytics for decomposing humor",
      "paper_id": "2107.08356v1"
    },
    {
      "index": 189,
      "title": "“Towards a better gold standard: Denoising and modelling continuous emotion annotations based on feature agglomeration and outlier regularisation",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 190,
      "title": "M. Madadi et al",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 191,
      "title": "“Co-clustering to reveal salient facial features for expression recognition",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 192,
      "title": "“Using a pca-based dataset similarity measure to improve cross-corpus emotion recognition",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 193,
      "title": "“A visual-physiology multimodal system for detecting outlier behavior of participants in a reality tv show",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 194,
      "title": "Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Out of the box: Reasoning with graph convolution nets for factual visual question answering",
      "paper_id": "1811.00538v1"
    },
    {
      "index": 195,
      "title": "“M3gat: A multi-modal",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 196,
      "title": "Explainable Video Action Reasoning via Prior Knowledge and State Transitions",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Explainable video action reasoning via prior knowledge and state transitions",
      "paper_id": "1908.10700v1"
    },
    {
      "index": 197,
      "title": "“Modeling high-order relationships: Brain-inspired hypergraph-induced multimodal-multitask framework for semantic comprehension",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 198,
      "title": "“Enhancing explanations in recommender systems with knowledge graphs",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 199,
      "title": "Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Behind the scene: Revealing the secrets of pre-trained vision-and-language models",
      "paper_id": "2005.07310v2"
    },
    {
      "index": 200,
      "title": "“Probing image-language transformers for verb understanding",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": ""
    },
    {
      "index": 201,
      "title": "UNITER: UNiversal Image-TExt Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Uniter: Universal image-text representation learning",
      "paper_id": "1909.11740v3"
    },
    {
      "index": 202,
      "title": "“Vision-and-language or vision-for-language? on cross-modal influence in multimodal transformers",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": ""
    },
    {
      "index": 203,
      "title": "Learning to Explain: A Model-Agnostic Framework for Explaining Black Box Models",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Learning to explain: A model-agnostic framework for explaining black box models",
      "paper_id": "2310.16584v1"
    },
    {
      "index": 204,
      "title": "CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Clip surgery for better explainability with enhancement in open-vocabulary tasks",
      "paper_id": "2304.05653v2"
    },
    {
      "index": 205,
      "title": "TagCLIP: A Local-to-Global Framework to Enhance Open-Vocabulary Multi-Label Classification of CLIP Without Training",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Tagclip: A local-to-global framework to enhance open-vocabulary multi-label classification of clip without training",
      "paper_id": "2312.12828v1"
    },
    {
      "index": 206,
      "title": "Interpreting CLIP’s Image Representation via Text-Based Decomposition",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Interpreting clip’s image representation via text-based decomposition",
      "paper_id": "2310.05916v4"
    },
    {
      "index": 207,
      "title": "Black-Box Tuning of Vision-Language Models with Effective Gradient Approximation",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Black-box tuning of vision-language models with effective gradient approximation",
      "paper_id": "2312.15901v1"
    },
    {
      "index": 208,
      "title": "“Unveiling hierarchical relationships for social image representation learning",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 209,
      "title": "Multimodal Analogical Reasoning over Knowledge Graphs",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "",
      "orig_title": "“Multimodal analogical reasoning over knowledge graphs",
      "paper_id": "2210.00312v4"
    },
    {
      "index": 210,
      "title": "DKN: Deep Knowledge-Aware Network for News Recommendation",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Dkn: Deep knowledge-aware network for news recommendation",
      "paper_id": "1801.08284v2"
    },
    {
      "index": 211,
      "title": "“Learning heterogeneous knowledge base embeddings for explainable recommendation",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 212,
      "title": "“Knowledge-aware autoencoders for explainable recommender systems",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 213,
      "title": "Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Cross-modal causal relational reasoning for event-level visual question answering",
      "paper_id": "2207.12647v8"
    },
    {
      "index": 214,
      "title": "“Towards causal vqa: Revealing and reducing spurious correlations by invariant and covariant semantic editing",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 215,
      "title": "“Counterfactual vqa: A cause-effect look at language bias",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": ""
    },
    {
      "index": 216,
      "title": "D. Parikh et al",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 217,
      "title": "Interpretable Visual Question Answering by Reasoning on Dependency Trees",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Interpretable visual question answering by reasoning on dependency trees",
      "paper_id": "1809.01810v2"
    },
    {
      "index": 218,
      "title": "“Lcm-captioner: A lightweight text-based image captioning method with collaborative mechanism between vision and text",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 219,
      "title": "Multimodal Research in Vision and Language: A Review of Current and Emerging Trends",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "",
      "orig_title": "“Multimodal research in vision and language: A review of current and emerging trends",
      "paper_id": "2010.09522v2"
    },
    {
      "index": 220,
      "title": "Counterfactual Samples Synthesizing for Robust Visual Question Answering",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Counterfactual samples synthesizing for robust visual question answering",
      "paper_id": "2003.06576v1"
    },
    {
      "index": 221,
      "title": "Question-Conditioned Counterfactual Image Generation for VQA",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Question-conditioned counterfactual image generation for vqa",
      "paper_id": "1911.06352v1"
    },
    {
      "index": 222,
      "title": "Multimodal Explanations by Predicting Counterfactuality in Videos",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Multimodal explanations by predicting counterfactuality in videos",
      "paper_id": "1812.01263v2"
    },
    {
      "index": 223,
      "title": "Generating Counterfactual Explanations with Natural Language",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Generating counterfactual explanations with natural language",
      "paper_id": "1806.09809v1"
    },
    {
      "index": 224,
      "title": "Non-Autoregressive Image Captioning with Counterfactuals-Critical Multi-Agent Learning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Non-autoregressive image captioning with counterfactuals-critical multi-agent learning",
      "paper_id": "2005.04690v1"
    },
    {
      "index": 225,
      "title": "Counterfactual Critic Multi-Agent Training for Scene Graph Generation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Counterfactual critic multi-agent training for scene graph generation",
      "paper_id": "1812.02347v3"
    },
    {
      "index": 226,
      "title": "Bias in Multimodal AI: Testbed for Fair Automatic Recruitment",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Bias in multimodal ai: Testbed for fair automatic recruitment",
      "paper_id": "2004.07173v1"
    },
    {
      "index": 227,
      "title": "“Explicit bias discovery in visual question answering models",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 228,
      "title": "Women also Snowboard: Overcoming Bias in Captioning Models",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Women also snowboard: Overcoming bias in captioning models",
      "paper_id": "1803.09797v4"
    },
    {
      "index": 229,
      "title": "Overcoming Language Priors in Visual Question Answering with Adversarial Regularization",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Overcoming language priors in visual question answering with adversarial regularization",
      "paper_id": "1810.03649v2"
    },
    {
      "index": 230,
      "title": "R. Salakhutdinov",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 231,
      "title": "MultiViz: Towards Visualizing and Understanding Multimodal Models",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "",
      "orig_title": "“Multiviz: Towards visualizing and understanding multimodal models",
      "paper_id": "2207.00056v3"
    },
    {
      "index": 232,
      "title": "VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "",
      "orig_title": "“Vl-interpret: An interactive visualization tool for interpreting vision-language transformers",
      "paper_id": "2203.17247v3"
    },
    {
      "index": 233,
      "title": "R. Salakhutdinov",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": ""
    },
    {
      "index": 234,
      "title": "Towards Better Explanations of Class Activation Mapping",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "",
      "orig_title": "“Towards better explanations of class activation mapping",
      "paper_id": "2102.05228v3"
    },
    {
      "index": 235,
      "title": "“Did the model understand the question?” arXiv preprint arXiv:1805.05492",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 236,
      "title": "“Towards the interpretability of deep learning models for multi-modal neuroimaging: Finding structural changes of the ageing brain",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": ""
    },
    {
      "index": 237,
      "title": "Interpretability for Multimodal Emotion Recognition using Concept Activation Vectors",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "",
      "orig_title": "“Interpretability for multimodal emotion recognition using concept activation vectors",
      "paper_id": "2202.01072v1"
    },
    {
      "index": 238,
      "title": "RISE: Randomized Input Sampling for Explanation of Black-box Models",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Rise: Randomized input sampling for explanation of black-box models",
      "paper_id": "1806.07421v3"
    },
    {
      "index": 239,
      "title": "GPT-4 Technical Report",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Gpt-4 technical report",
      "paper_id": "2303.08774v6"
    },
    {
      "index": 240,
      "title": "LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Lida: A tool for automatic generation of grammar-agnostic visualizations and infographics using large language models",
      "paper_id": "2303.02927v3"
    },
    {
      "index": 241,
      "title": "“Can foundation models wrangle your data?” arXiv preprint arXiv:2205.09911",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": ""
    },
    {
      "index": 242,
      "title": "Benchmarking Large Language Models as AI Research Agents",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Benchmarking large language models as ai research agents",
      "paper_id": "2310.03302v2"
    },
    {
      "index": 243,
      "title": "D. Rifinski Fainman",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 244,
      "title": "Generative Table Pre-training Empowers Models for Tabular Prediction",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Generative table pre-training empowers models for tabular prediction",
      "paper_id": "2305.09696v1"
    },
    {
      "index": 245,
      "title": "Data Science with LLMs and Interpretable Models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Data science with llms and interpretable models",
      "paper_id": "2402.14474v1"
    },
    {
      "index": 246,
      "title": "“Multimodal c4: An open",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 247,
      "title": "J. Parker-Holder",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 248,
      "title": "Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "",
      "orig_title": "“Quality not quantity: On the interaction between dataset design and robustness of clip",
      "paper_id": "2208.05516v4"
    },
    {
      "index": 249,
      "title": "B. Mirzasoleiman",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 250,
      "title": "“Rendering graphs for graph reasoning in multimodal large language models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 251,
      "title": "LLM and GNN are Complementary: Distilling LLM for Multimodal Graph Learning",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Llm and gnn are complementary: Distilling llm for multimodal graph learning",
      "paper_id": "2406.01032v1"
    },
    {
      "index": 252,
      "title": "How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“How multimodal integration boost the performance of llm for optimization: Case study on capacitated vehicle routing problems",
      "paper_id": "2403.01757v1"
    },
    {
      "index": 253,
      "title": "Generative Multimodal Models are In-Context Learners",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Generative multimodal models are in-context learners",
      "paper_id": "2312.13286v2"
    },
    {
      "index": 254,
      "title": "“What makes multimodal in-context learning work?” in Proc. of CVPR",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 255,
      "title": "OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Obelics: An open web-scale filtered dataset of interleaved image-text documents",
      "paper_id": "2306.16527v2"
    },
    {
      "index": 256,
      "title": "S. Sagawa et al",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 257,
      "title": "MM-Narrator: Narrating Long-form Videos withMultimodal In-Context Learning",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Mm-narrator: Narrating long-form videos with multimodal in-context learning",
      "paper_id": "2311.17435v1"
    },
    {
      "index": 258,
      "title": "Beyond task performance: evaluating and reducing the flaws of large multimodal models with in-context learning",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Beyond task performance: Evaluating and reducing the flaws of large multimodal models with in-context learning",
      "paper_id": "2310.00647v2"
    },
    {
      "index": 259,
      "title": "“How does the textual information affect the retrieval of multimodal in-context learning?” arXiv preprint arXiv:2404.12866",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 260,
      "title": "“Chain of thought prompt tuning in vision language models",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 261,
      "title": "Multimodal Chain-of-Thought Reasoning in Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Multimodal chain-of-thought reasoning in language models",
      "paper_id": "2302.00923v5"
    },
    {
      "index": 262,
      "title": "Visual Chain-of-Thought: Bridging Logical Gaps with Multimodal Infillings",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Visual chain of thought: bridging logical gaps with multimodal infillings",
      "paper_id": "2305.02317v3"
    },
    {
      "index": 263,
      "title": "Let’s Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Let’s think frame by frame with vip: A video infilling and prediction dataset for evaluating video chain-of-thought",
      "paper_id": "2305.13903v3"
    },
    {
      "index": 264,
      "title": "Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "",
      "orig_title": "“Contrastive novelty-augmented learning: Anticipating outliers with large language models",
      "paper_id": "2211.15718v2"
    },
    {
      "index": 265,
      "title": "“Does synthetic data generation of llms help clinical text mining?” arXiv preprint arXiv:2303.04360",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 266,
      "title": "“Q: How to specialize large vision-language models to data-scarce vqa tasks? a: Self-train on unlabeled images!” in Proc. of CVPR",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 267,
      "title": "“T-sciq: Teaching multimodal chain-of-thought reasoning via large language model signals for science question answering",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 268,
      "title": "LLM-powered Data Augmentation for Enhanced Crosslingual Performance",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Llm-powered data augmentation for enhanced cross-lingual performance",
      "paper_id": "2305.14288v2"
    },
    {
      "index": 269,
      "title": "Generalized Category Discovery with Large Language Models in the Loop",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Generalized category discovery with large language models in the loop",
      "paper_id": "2312.10897v2"
    },
    {
      "index": 270,
      "title": "“Llava-next: Improved reasoning",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 271,
      "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Llava-med: Training a large language-and-vision assistant for biomedicine in one day",
      "paper_id": "2306.00890v1"
    },
    {
      "index": 272,
      "title": "VideoChat : Chat-Centric Video Understanding",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Videochat: Chat-centric video understanding",
      "paper_id": "2305.06355v2"
    },
    {
      "index": 273,
      "title": "“Dolphins: Multimodal language model for driving",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 274,
      "title": "SALMONN: Towards Generic Hearing Abilities for Large Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Salmonn: Towards generic hearing abilities for large language models",
      "paper_id": "2310.13289v2"
    },
    {
      "index": 275,
      "title": "Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models",
      "paper_id": "2311.07919v2"
    },
    {
      "index": 276,
      "title": "M. Reynolds et al",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": ""
    },
    {
      "index": 277,
      "title": "MM-ReAct : Prompting ChatGPT for Multimodal Reasoning and Action",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Mm-react: Prompting chatgpt for multimodal reasoning and action",
      "paper_id": "2303.11381v1"
    },
    {
      "index": 278,
      "title": "X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“X-llm: Bootstrapping advanced large language models by treating multi-modalities as foreign languages",
      "paper_id": "2305.04160v3"
    },
    {
      "index": 279,
      "title": "X-InstructBLIP: A Framework for aligning X-Modal instruction-aware representations to LLMs and Emergent Cross-modal Reasoning",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“X-instructblip: A framework for aligning x-modal instruction-aware representations to llms and emergent cross-modal reasoning",
      "paper_id": "2311.18799v2"
    },
    {
      "index": 280,
      "title": "AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Anymal: An efficient and scalable any-modality augmented language model",
      "paper_id": "2309.16058v1"
    },
    {
      "index": 281,
      "title": "Probing Multimodal Large Language Models for Global and Local Semantic Representation",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Probing multimodal large language models for global and local semantic representation",
      "paper_id": "2402.17304v3"
    },
    {
      "index": 282,
      "title": "J. Watson-Daniels",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 283,
      "title": "“What is the limitation of multimodal llms? a deeper look into multimodal llms through prompt probing",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 284,
      "title": "Emergent world representations: Exploring a sequence model trained on a synthetic task",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "",
      "orig_title": "“Emergent world representations: Exploring a sequence model trained on a synthetic task",
      "paper_id": "2210.13382v5"
    },
    {
      "index": 285,
      "title": "Probing Multimodal LLMs as World Models for Driving",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Probing multimodal llms as world models for driving",
      "paper_id": "2405.05956v2"
    },
    {
      "index": 286,
      "title": "From Text to Pixel: Advancing Long-Context Understanding in MLLMs",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“From text to pixel: Advancing long-context understanding in mllms",
      "paper_id": "2405.14213v2"
    },
    {
      "index": 287,
      "title": "AGLA: Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Agla: Mitigating object hallucinations in large vision-language models with assembly of global and local attention",
      "paper_id": "2406.12718v3"
    },
    {
      "index": 288,
      "title": "Active Reasoning in an Open-World Environment",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Active reasoning in an open-world environment",
      "paper_id": "2311.02018v1"
    },
    {
      "index": 289,
      "title": "RecKoninG: Reasoning through Dynamic Knowledge Encoding",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Reckoning: reasoning through dynamic knowledge encoding",
      "paper_id": "2305.06349v3"
    },
    {
      "index": 290,
      "title": "Statler: State-Maintaining Language Models for Embodied Reasoning",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Statler: State-maintaining language models for embodied reasoning",
      "paper_id": "2306.17840v4"
    },
    {
      "index": 291,
      "title": "Y. Chebotar et al",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": ""
    },
    {
      "index": 292,
      "title": "plan and select: interactive planning with llms enables open-world multi-task agents",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 293,
      "title": "Knowledge Acquisition Disentanglement for Knowledge-based Visual Question Answering with Large Language Models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Knowledge acquisition disentanglement for knowledge-based visual question answering with large language models",
      "paper_id": "2407.15346v1"
    },
    {
      "index": 294,
      "title": "What if…?: Counterfactual Inception to Mitigate Hallucination Effects in Large Multimodal Models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“What if…?: Counterfactual inception to mitigate hallucination effects in large multimodal models",
      "paper_id": "2403.13513v2"
    },
    {
      "index": 295,
      "title": "“Eyes can deceive: Benchmarking counterfactual reasoning abilities of multi-modal large language models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 296,
      "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks",
      "paper_id": "2307.02477v3"
    },
    {
      "index": 297,
      "title": "What If the TV Was Off? Examining Counterfactual Reasoning Abilities of Multi-modal Language Models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“What if the tv was off? examining counterfactual reasoning abilities of multi-modal language models",
      "paper_id": "2310.06627v4"
    },
    {
      "index": 298,
      "title": "Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Using counterfactual tasks to evaluate the generality of analogical reasoning in large language models",
      "paper_id": "2402.08955v1"
    },
    {
      "index": 299,
      "title": "Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Stop reasoning! when multimodal llms with chain-of-thought reasoning meets adversarial images",
      "paper_id": "2402.14899v3"
    },
    {
      "index": 300,
      "title": "On the Robustness of Large Multimodal Models Against Image Adversarial Attacks",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“On the robustness of large multimodal models against image adversarial attacks",
      "paper_id": "2312.03777v2"
    },
    {
      "index": 301,
      "title": "A Survey on Data Selection for Language Models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“A survey on data selection for language models",
      "paper_id": "2402.16827v3"
    },
    {
      "index": 302,
      "title": "Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Label words are anchors: An information flow perspective for understanding in-context learning",
      "paper_id": "2305.14160v4"
    },
    {
      "index": 303,
      "title": "Link-Context Learning for Multimodal LLMs",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Link-context learning for multimodal llms",
      "paper_id": "2308.07891v1"
    },
    {
      "index": 304,
      "title": "A Survey of Multimodal Large Language Model from A Data-centric Perspective",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“A survey of multimodal large language model from a data-centric perspective",
      "paper_id": "2405.16640v2"
    },
    {
      "index": 305,
      "title": "Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Image-of-thought prompting for visual reasoning refinement in multimodal large language models",
      "paper_id": "2405.13872v2"
    },
    {
      "index": 306,
      "title": "MM-LLMs: Recent Advances in MultiModal Large Language Models",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Mm-llms: Recent advances in multimodal large language models",
      "paper_id": "2401.13601v5"
    },
    {
      "index": 307,
      "title": "Visual Instruction Tuning",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Visual instruction tuning",
      "paper_id": "2304.08485v2"
    },
    {
      "index": 308,
      "title": "LLaVA-MoLE: Sparse Mixture of LoRA Experts for Mitigating Data Conflicts in Instruction Finetuning MLLMs",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Llava-mole: Sparse mixture of lora experts for mitigating data conflicts in instruction finetuning mllms",
      "paper_id": "2401.16160v2"
    },
    {
      "index": 309,
      "title": "Robustness to Spurious Correlations in Text Classification via Automatically Generated Counterfactuals",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "",
      "orig_title": "“Robustness to spurious correlations in text classification via automatically generated counterfactuals",
      "paper_id": "2012.10040v1"
    },
    {
      "index": 310,
      "title": "V. Sindhwani et al",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": ""
    },
    {
      "index": 311,
      "title": "S. Levine et al",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 312,
      "title": "Collaborating with language models for embodied reasoning",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Collaborating with language models for embodied reasoning",
      "paper_id": "2302.00763v1"
    },
    {
      "index": 313,
      "title": "“Hawk: Learning to understand open-world video anomalies",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 314,
      "title": "Multimodal Explanations: Justifying Decisions and Pointing to the Evidence",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Multimodal explanations: Justifying decisions and pointing to the evidence",
      "paper_id": "1802.08129v1"
    },
    {
      "index": 315,
      "title": "“Toward human-understandable",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 316,
      "title": "Personalized Showcases: Generating Multi-Modal Explanations for Recommendations",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Personalized showcases: Generating multi-modal explanations for recommendations",
      "paper_id": "2207.00422v2"
    },
    {
      "index": 317,
      "title": "“A first look: Towards explainable textvqa models via visual and textual explanations",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": ""
    },
    {
      "index": 318,
      "title": "Uncovering What, Why and How: A Comprehensive Benchmark for Causation Understanding of Video Anomaly",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Uncovering what why and how: A comprehensive benchmark for causation understanding of video anomaly",
      "paper_id": "2405.00181v2"
    },
    {
      "index": 319,
      "title": "DocVQA: A Dataset for VQA on Document Images",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "",
      "orig_title": "“Docvqa: A dataset for vqa on document images",
      "paper_id": "2007.00398v3"
    },
    {
      "index": 320,
      "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "",
      "orig_title": "“Learn to explain: Multimodal reasoning via thought chains for science question answering",
      "paper_id": "2209.09513v2"
    },
    {
      "index": 321,
      "title": "“Lora: A logical reasoning augmented dataset for visual question answering",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": ""
    },
    {
      "index": 322,
      "title": "Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "",
      "orig_title": "“Towards end-to-end embodied decision making via multi-modal large language model: Explorations with gpt4-vision and beyond",
      "paper_id": "2310.02071v4"
    },
    {
      "index": 323,
      "title": "Textual Explanations for Self-Driving Vehicles",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Textual explanations for self-driving vehicles",
      "paper_id": "1807.11546v1"
    },
    {
      "index": 324,
      "title": "VAST: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and Dataset",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Vast: A vision-audio-subtitle-text omni-modality foundation model and dataset",
      "paper_id": "2305.18500v2"
    },
    {
      "index": 325,
      "title": "From Recognition to Cognition: Visual Commonsense Reasoning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“From recognition to cognition: Visual commonsense reasoning",
      "paper_id": "1811.10830v2"
    },
    {
      "index": 326,
      "title": "Common Sense Reasoning for Deepfake Detection",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Common sense reasoning for deep fake detection",
      "paper_id": "2402.00126v2"
    },
    {
      "index": 327,
      "title": "Explainable Outfit Recommendation with Joint Outfit Matching and Comment Generation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Explainable outfit recommendation with joint outfit matching and comment generation",
      "paper_id": "1806.08977v3"
    },
    {
      "index": 328,
      "title": "“Reasoner: An explainable recommendation dataset with comprehensive labeling ground truths",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 329,
      "title": "Towards Surveillance Video-and-Language Understanding: New Dataset, Baselines, and Challenges",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Towards surveillance video-and-language understanding: New dataset baselines and challenges",
      "paper_id": "2309.13925v2"
    },
    {
      "index": 330,
      "title": "Hallucination of Multimodal Large Language Models: A Survey",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Hallucination of multimodal large language models: A survey",
      "paper_id": "2404.18930v2"
    },
    {
      "index": 331,
      "title": "인공지능 기반 공격 그래프 생성",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 332,
      "title": "Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“Eyes wide shut? exploring the visual shortcomings of multimodal llms",
      "paper_id": "2401.06209v2"
    },
    {
      "index": 333,
      "title": "V∗: Guided Visual Search as a Core Mechanism in Multimodal LLMs",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": "",
      "orig_title": "“V?: Guided visual search as a core mechanism in multimodal llms",
      "paper_id": "2312.14135v2"
    },
    {
      "index": 334,
      "title": "“Crespr: Modular sparsification of dnns to improve pruning performance and model interpretability",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    },
    {
      "index": 335,
      "title": "“Language is primarily a tool for communication rather than thought",
      "abstract": "",
      "year": "2024",
      "venue": "",
      "authors": ""
    }
  ]
}