{
  "paper_id": "2103.11790v3",
  "title": "Large Pre-trained Language Models Contain Human-like Biases of What is Right and Wrong to Do",
  "abstract": "Abstract\nArtificial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, its variants, GPT-2/3, and others. Using them as pre-trained models and fine-tuning them for specific tasks, researchers have extended state of the art for many NLP tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on unfiltered text corpora suffer from\ndegenerated and biased behaviour.\nWhile this is well established, we show that recent LMs also contain human-like biases of what is right and wrong to do, some form of ethical and moral norms of the society\n—they bring a\n“moral direction” to surface. That is, we show that\nthese norms can be captured geometrically by a direction, which can be computed, e.g., by a PCA, in the embedding space, reflecting well the agreement of phrases to social norms implicitly expressed in the training texts and providing a path for attenuating or even preventing toxic degeneration in LMs. Being able to rate the (non-)normativity of arbitrary phrases without explicitly training the LM for this task, we demonstrate the capabilities of the “moral direction” for guiding (even other) LMs towards producing normative text and showcase it on RealToxicityPrompts testbed, preventing the neural toxic degeneration in GPT-2.",
  "reference_labels": [
    {
      "index": 0,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)",
      "authors": "Devlin, J., Chang, M., Lee, K. & Toutanova, K.",
      "orig_title": "BERT: pre-training of deep bidirectional transformers for language understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 1,
      "title": "Deep contextualized word representations",
      "abstract": "",
      "year": "2018",
      "venue": "Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)",
      "authors": "Peters, M. E. et al.",
      "orig_title": "Deep contextualized word representations",
      "paper_id": "1802.05365v2"
    },
    {
      "index": 2,
      "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems (NeurIPS)",
      "authors": "Yang, Z. et al.",
      "orig_title": "Xlnet: Generalized autoregressive pretraining for language understanding",
      "paper_id": "1906.08237v2"
    },
    {
      "index": 3,
      "title": "Language Models are Few-Shot Learners",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems (NeurIPS)",
      "authors": "Brown, T. B. et al.",
      "orig_title": "Language models are few-shot learners",
      "paper_id": "2005.14165v4"
    },
    {
      "index": 4,
      "title": "Next chapter in artificial writing",
      "abstract": "",
      "year": "2020",
      "venue": "Nature Machine Intelligence",
      "authors": ""
    },
    {
      "index": 5,
      "title": "Assessing BERT’s Syntactic Abilities",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Goldberg, Y.",
      "orig_title": "Assessing bert’s syntactic abilities",
      "paper_id": "1901.05287v1"
    },
    {
      "index": 6,
      "title": "Open Sesame: Getting Inside BERT’s Linguistic Knowledge",
      "abstract": "",
      "year": "2019",
      "venue": "ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
      "authors": "Lin, Y., Tan, Y. & Frank, R.",
      "orig_title": "Open Sesame: Getting inside bert’s linguistic knowledge",
      "paper_id": "1906.01698v1"
    },
    {
      "index": 7,
      "title": "Visualizing and measuring the geometry of BERT",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems (NeurIPS)",
      "authors": "Reif, E. et al."
    },
    {
      "index": 8,
      "title": "Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition",
      "abstract": "",
      "year": "2019",
      "venue": "Transactions of the Association for Computational Linguistics (TACL)",
      "authors": "Shwartz, V. & Dagan, I.",
      "orig_title": "Still a pain in the neck: Evaluating text representations on lexical composition",
      "paper_id": "1902.10618v2"
    },
    {
      "index": 9,
      "title": "What do you learn from context? Probing for sentence structure in contextualized word representations",
      "abstract": "",
      "year": "2019",
      "venue": "7th International Conference on Learning Representations (ICLR)",
      "authors": "Tenney, I. et al.",
      "orig_title": "What do you learn from context? probing for sentence structure in contextualized word representations",
      "paper_id": "1905.06316v1"
    },
    {
      "index": 10,
      "title": "olmpics - on what language model pre-training captures",
      "abstract": "",
      "year": "2020",
      "venue": "Transactions of the Association for Computational Linguistics (TACL)",
      "authors": "Talmor, A., Elazar, Y., Goldberg, Y. & Berant, J."
    },
    {
      "index": 11,
      "title": "How Much Knowledge Can You Pack Into the Parameters of a Language Model?",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "authors": "Roberts, A., Raffel, C. & Shazeer, N.",
      "orig_title": "How much knowledge can you pack into the parameters of a language model?",
      "paper_id": "2002.08910v4"
    },
    {
      "index": 12,
      "title": "Language models as knowledge bases?",
      "abstract": "",
      "year": "2019",
      "venue": "Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "authors": "Petroni, F. et al."
    },
    {
      "index": 13,
      "title": "Doctor gpt-3: hype or reality?",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 14,
      "title": "Realtoxicityprompts: Evaluating neural toxic degeneration in language models",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Empirical Methods in Natural Language Processing: Findings (EMNLP)",
      "authors": "Gehman, S., Gururangan, S., Sap, M., Choi, Y. & Smith, N. A."
    },
    {
      "index": 15,
      "title": "Persistent anti-muslim bias in large language models",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI/ACM Conference on AI, Ethics, and Society (AIES)",
      "authors": "Abid, A., Farooqi, M. & Zou, J."
    },
    {
      "index": 16,
      "title": "Microsoft’s racist chatbot revealed the dangers of online conversation",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 17,
      "title": "On the dangers of stochastic parrots: Can language models be too big?",
      "abstract": "",
      "year": "2021",
      "venue": "ACM Conference on Fairness, Accountability, and Transparency (FAccT)",
      "authors": "Bender, E. M., Gebru, T., McMillan-Major, A. & Shmitchell, S."
    },
    {
      "index": 18,
      "title": "Robo-writers: the rise and risks of language-generating ai",
      "abstract": "",
      "year": "2021",
      "venue": "Nature",
      "authors": "Hutson, M."
    },
    {
      "index": 19,
      "title": "Semantics derived automatically from language corpora contain human-like biases",
      "abstract": "",
      "year": "2017",
      "venue": "Science",
      "authors": "Caliskan, A., Bryson, J. J. & Narayanan, A."
    },
    {
      "index": 20,
      "title": "Man is to computer programmer as woman is to homemaker? Debiasing word embeddings",
      "abstract": "",
      "year": "2016",
      "venue": "Neural information Processing (NeurIPS)",
      "authors": "Bolukbasi, T., Chang, K., Zou, J. Y., Saligrama, V. & Kalai, A. T."
    },
    {
      "index": 21,
      "title": "Mitigating gender bias in natural language processing: Literature review",
      "abstract": "",
      "year": "2019",
      "venue": "57th Annual Meeting of the Association for Computational Linguistics (ACL)",
      "authors": "Sun, T. et al."
    },
    {
      "index": 22,
      "title": "Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks",
      "abstract": "",
      "year": "2020",
      "venue": "58th Annual Meeting of the Association for Computational Linguistics (ACL)",
      "authors": "Gururangan, S. et al.",
      "orig_title": "Don’t stop pretraining: Adapt language models to domains and tasks",
      "paper_id": "2004.10964v3"
    },
    {
      "index": 23,
      "title": "Plug and Play Language Models: a Simple Approach to Controlled Text Generation",
      "abstract": "",
      "year": "2020",
      "venue": "8th International Conference on Learning Representations (ICLR)",
      "authors": "Dathathri, S. et al.",
      "orig_title": "Plug and play language models: A simple approach to controlled text generation",
      "paper_id": "1912.02164v4"
    },
    {
      "index": 24,
      "title": "Reducing Non-Normative Text Generation from Language Models",
      "abstract": "",
      "year": "2020",
      "venue": "13th International Conference on Natural Language Generation",
      "authors": "Peng, X., Li, S., Frazier, S. & Riedl, M.",
      "orig_title": "Reducing non-normative text generation from language models",
      "paper_id": "2001.08764v2"
    },
    {
      "index": 25,
      "title": "Semantics derived automatically from language corpora contain human-like moral choices",
      "abstract": "",
      "year": "2019",
      "venue": "2019 AAAI/ACM Conference on AI, Ethics, and Society (AIES)",
      "authors": "Jentzsch, S., Schramowski, P., Rothkopf, C. A. & Kersting, K."
    },
    {
      "index": 26,
      "title": "The moral choice machine",
      "abstract": "",
      "year": "2020",
      "venue": "Frontiers Artif. Intell.",
      "authors": "Schramowski, P., Turan, C., Jentzsch, S., Rothkopf, C. A. & Kersting, K."
    },
    {
      "index": 27,
      "title": "Ethical theory: an anthology, vol. 13",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": "Shafer-Landau, R."
    },
    {
      "index": 28,
      "title": "Fine-tuning a transformer-based language model to avoid generating non-normative text",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Peng, X., Li, S., Frazier, S. & Riedl, M."
    },
    {
      "index": 29,
      "title": "BERT has a Moral Compass: Improvements of ethical and moral values of machines",
      "abstract": "",
      "year": "2019",
      "venue": "CoRR",
      "authors": "Schramowski, P., Turan, C., Jentzsch, S. F., Rothkopf, C. A. & Kersting, K.",
      "orig_title": "BERT has a moral compass: Improvements of ethical and moral values of machines",
      "paper_id": "1912.05238v1"
    },
    {
      "index": 30,
      "title": "Conscience: The Origins of Moral Intuition",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Churchland, P."
    },
    {
      "index": 31,
      "title": "The neurobiology of conscience",
      "abstract": "",
      "year": "2019",
      "venue": "Nature",
      "authors": "Christakis, N. A."
    },
    {
      "index": 32,
      "title": "A companion to moral anthropology",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": "Fassin, D."
    },
    {
      "index": 33,
      "title": "Normative ethics and metaethics",
      "abstract": "",
      "year": "1967",
      "venue": "Ethics",
      "authors": "Sumner, L. W."
    },
    {
      "index": 34,
      "title": "The Culture of National Security: Norms and Identity in World Politics",
      "abstract": "",
      "year": "1996",
      "venue": "New directions in world politics",
      "authors": "Katzenstein, P., Katzenstein, M., Press, C. U., on International Peace & Security, S. S. R. C. U. C. & (Organization), C."
    },
    {
      "index": 35,
      "title": "The role of a “common is moral” heuristic in the stability and change of moral norms",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of Experimental Psychology: General",
      "authors": "Lindström, B., Jangard, S., Selbing, I. & Olsson, A."
    },
    {
      "index": 36,
      "title": "The Definition of Morality",
      "abstract": "",
      "year": "2020",
      "venue": "Stanford Encyclopedia of Philosophy",
      "authors": "Gert, B. & Gert, J."
    },
    {
      "index": 37,
      "title": "Deontological Ethics",
      "abstract": "",
      "year": "2021",
      "venue": "Stanford Encyclopedia of Philosophy",
      "authors": "Alexander, L. & Moore, M."
    },
    {
      "index": 38,
      "title": "Social Norms",
      "abstract": "",
      "year": "2018",
      "venue": "Stanford Encyclopedia of Philosophy",
      "authors": "Bicchieri, C., Muldoon, R. & Sontuoso, A."
    },
    {
      "index": 39,
      "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
      "abstract": "",
      "year": "2019",
      "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "authors": "Reimers, N. & Gurevych, I.",
      "orig_title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
      "paper_id": "1908.10084v1"
    },
    {
      "index": 40,
      "title": "Universal Sentence Encoder",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Cer, D. et al.",
      "orig_title": "Universal sentence encoder",
      "paper_id": "1803.11175v2"
    },
    {
      "index": 41,
      "title": "Language models are unsupervised multitask learners",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Radford, A. et al."
    },
    {
      "index": 42,
      "title": "Gmail Smart Compose: Real-Time Assisted Writing",
      "abstract": "",
      "year": "2019",
      "venue": "25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD)",
      "authors": "Chen, M. X. et al.",
      "orig_title": "Gmail smart compose: Real-time assisted writing",
      "paper_id": "1906.00080v1"
    },
    {
      "index": 43,
      "title": "Aligning AI With Shared Human Values",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Learning Representations (ICLR)",
      "authors": "Hendrycks, D. et al.",
      "orig_title": "Aligning AI with shared human values",
      "paper_id": "2008.02275v6"
    },
    {
      "index": 44,
      "title": "CTRL: A Conditional Transformer Language Model for Controllable Generation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C. & Socher, R.",
      "orig_title": "CTRL: A conditional transformer language model for controllable generation",
      "paper_id": "1909.05858v2"
    },
    {
      "index": 45,
      "title": "Social Chemistry 101: Learning to Reason about Social and Moral Norms",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "authors": "Forbes, M., Hwang, J. D., Shwartz, V., Sap, M. & Choi, Y.",
      "orig_title": "Social chemistry 101: Learning to reason about social and moral norms",
      "paper_id": "2011.00620v3"
    },
    {
      "index": 46,
      "title": "Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations",
      "abstract": "",
      "year": "2017",
      "venue": "International Joint Conference on Artificial Intelligence (IJCAI)",
      "authors": "Ross, A. S., Hughes, M. C. & Doshi-Velez, F.",
      "orig_title": "Right for the right reasons: Training differentiable models by constraining their explanations",
      "paper_id": "1703.03717v2"
    },
    {
      "index": 47,
      "title": "Explanatory interactive machine learning",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI/ACM Conference on AI, Ethics, and Society (AIES)",
      "authors": "Teso, S. & Kersting, K."
    },
    {
      "index": 48,
      "title": "Making deep neural networks right for the right scientific reasons by interacting with their explanations",
      "abstract": "",
      "year": "2020",
      "venue": "Nature Machine Intelligence",
      "authors": "Schramowski, P. et al.",
      "orig_title": "Making deep neural networks right for the right scientific reasons by interacting with their explanations",
      "paper_id": "2001.05371v4"
    },
    {
      "index": 49,
      "title": "Modelling moral reasoning and ethical responsibility with logic programming",
      "abstract": "",
      "year": "2015",
      "venue": "Logic for Programming, Artificial Intelligence, and Reasoning",
      "authors": "Berreby, F., Bourgne, G. & Ganascia, J.-G."
    },
    {
      "index": 50,
      "title": "Modelling morality with prospective logic",
      "abstract": "",
      "year": "2009",
      "venue": "Int. J. Reason. based Intell. Syst.",
      "authors": "Pereira, L. M. & Saptawijaya, A."
    },
    {
      "index": 51,
      "title": "The logic of universalization guides moral judgment",
      "abstract": "",
      "year": "2020",
      "venue": "Proceedings of the National Academy of Sciences",
      "authors": "Levine, S., Kleiman-Weiner, M., Schulz, L., Tenenbaum, J. & Cushman, F."
    },
    {
      "index": 52,
      "title": "From frequency to meaning: Vector space models of semantics",
      "abstract": "",
      "year": "2010",
      "venue": "Journal of Artificial Intelligence Research (JAIR)",
      "authors": "Turney, P. D. & Pantel, P."
    },
    {
      "index": 53,
      "title": "Distributed representations of words and phrases and their compositionality",
      "abstract": "",
      "year": "2013",
      "venue": "Neural Information Processing Systems (NeurIPS)",
      "authors": "Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S. & Dean, J."
    },
    {
      "index": 54,
      "title": "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data",
      "abstract": "",
      "year": "2017",
      "venue": "2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "authors": "Conneau, A., Kiela, D., Schwenk, H., Barrault, L. & Bordes, A.",
      "orig_title": "Supervised learning of universal sentence representations from natural language inference data",
      "paper_id": "1705.02364v5"
    },
    {
      "index": 55,
      "title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
      "abstract": "",
      "year": "2015",
      "venue": "2015 IEEE International Conference on Computer Vision (ICCV)",
      "authors": "Zhu, Y. et al."
    },
    {
      "index": 56,
      "title": "Perspective api",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": ""
    },
    {
      "index": 57,
      "title": "Visualizing and measuring the geometry of BERT",
      "abstract": "",
      "year": "2019",
      "venue": "Annual Conference on Neural Information Processing Systems (NeurIPS)",
      "authors": "Reif, E. et al."
    },
    {
      "index": 58,
      "title": "Probing BERT in hyperbolic spaces",
      "abstract": "",
      "year": "2021",
      "venue": "9th International Conference on Learning Representations (ICLR)",
      "authors": "Chen, B. et al."
    },
    {
      "index": 59,
      "title": "HoroPCA: Hyperbolic Dimensionality Reduction via Horospherical Projections",
      "abstract": "",
      "year": "2021",
      "venue": "35th International Conference on Machine Learning (ICML)",
      "authors": "Chami, I., Gu, A., Nguyen, D. & Ré, C.",
      "orig_title": "Horopca: Hyperbolic dimensionality reduction via horospherical projections",
      "paper_id": "2106.03306v1"
    },
    {
      "index": 60,
      "title": "Measuring Bias in Contextualized Word Representations",
      "abstract": "",
      "year": "2019",
      "venue": "First Workshop on Gender Bias in Natural Language Processing",
      "authors": "Kurita, K., Vyas, N., Pareek, A., Black, A. W. & Tsvetkov, Y.",
      "orig_title": "Measuring bias in contextualized word representations",
      "paper_id": "1906.07337v1"
    },
    {
      "index": 61,
      "title": "Assessing social and intersectional biases in contextualized word representations",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems (NeurIPS)",
      "authors": "Tan, Y. C. & Celis, L. E."
    },
    {
      "index": 62,
      "title": "Semantics-aware BERT for Language Understanding",
      "abstract": "",
      "year": "2020",
      "venue": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI)",
      "authors": "Zhang, Z. et al.",
      "orig_title": "Semantics-aware BERT for language understanding",
      "paper_id": "1909.02209v3"
    }
  ]
}