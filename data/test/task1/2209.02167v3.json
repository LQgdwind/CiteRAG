{
  "paper_id": "2209.02167v3",
  "title": "Red Teaming with Mind Reading: White-Box Adversarial Policies Against RL Agents",
  "abstract": "Abstract\nAdversarial examples can be useful for identifying vulnerabilities in AI systems before they are deployed. In reinforcement learning (RL), adversarial policies can be developed by training an adversarial agent to minimize a target agent’s rewards. Prior work has studied black-box versions of these attacks where the adversary only observes the world state and treats the target agent as any other part of the environment. However, this does not take into account additional structure in the problem.\nIn this work, we study white-box adversarial policies and show that having access to a target agent’s internal state can be useful for identifying its vulnerabilities. We make two contributions. (1) We introduce white-box adversarial policies where an attacker observes both a target’s internal state and the world state at each timestep. We formulate ways of using these policies to attack agents in 2-player games and text-generating language models. (2) We demonstrate that these policies can achieve higher initial and asymptotic performance against a target agent than black-box controls. Code is available at this https url.",
  "reference_labels": [
    {
      "index": 0,
      "title": "Toxic comment classification challenge",
      "abstract": "",
      "year": "2017",
      "venue": "Kaggle",
      "authors": "C.J. Adams, Jeffrey Sorensen, Julia Elliott, Lucas Dixon, Mark Mcdonald, and Will Cukierski"
    },
    {
      "index": 1,
      "title": "Emergent Complexity via Multi-Agent Competition",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv",
      "authors": "Trapit Bansal, Jakub Pachocki, Szymon Sidor, Ilya Sutskever, and Igor Mordatch",
      "orig_title": "Emergent complexity via multi-agent competition",
      "paper_id": "1710.03748v3"
    },
    {
      "index": 2,
      "title": "Adversarial exploitation of policy imitation",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Vahid Behzadan and William Hsu"
    },
    {
      "index": 3,
      "title": "RL-Based Method for Benchmarking the Adversarial Resilience and Robustness of Deep Reinforcement Learning Policies",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Computer Safety, Reliability, and Security",
      "authors": "Vahid Behzadan and William Hsu",
      "orig_title": "Rl-based method for benchmarking the adversarial resilience and robustness of deep reinforcement learning policies",
      "paper_id": "1906.01110v1"
    },
    {
      "index": 4,
      "title": "A Survey of Black-Box Adversarial Attacks on Computer Vision Models",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, and Arun Balaji Buduru",
      "orig_title": "A survey of black-box adversarial attacks on computer vision models",
      "paper_id": "1912.01667v3"
    },
    {
      "index": 5,
      "title": "Openai gym",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv",
      "authors": "Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba"
    },
    {
      "index": 6,
      "title": "Achilles heels for agi/asi via decision theoretic adversaries",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Stephen Casper"
    },
    {
      "index": 7,
      "title": "A parametric, resource-bounded generalization of löb’s theorem, and a robust cooperation criterion for open-source game theory",
      "abstract": "",
      "year": "2019",
      "venue": "The Journal of Symbolic Logic",
      "authors": "Andrew Critch"
    },
    {
      "index": 8,
      "title": "Cooperative and uncooperative institution designs: Surprises and problems in open-source game theory",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Andrew Critch, Michael Dennis, and Stuart Russell",
      "orig_title": "Cooperative and uncooperative institution designs: Surprises and problems in open-source game theory",
      "paper_id": "2208.07006v1"
    },
    {
      "index": 9,
      "title": "Reducing Exploitability with Population Based Training",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Pavel Czempin and Adam Gleave",
      "orig_title": "Reducing exploitability with population based training",
      "paper_id": "2208.05083v3"
    },
    {
      "index": 10,
      "title": "Using options to improve robustness of imitation learning against adversarial attacks",
      "abstract": "",
      "year": "2021",
      "venue": "Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications III",
      "authors": "Prithviraj Dasgupta"
    },
    {
      "index": 11,
      "title": "Using artificial neural networks to model opponents in texas hold’em",
      "abstract": "",
      "year": "1999",
      "venue": "",
      "authors": "Aaron Davidson"
    },
    {
      "index": 12,
      "title": "Embedded agency",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Abram Demski and Scott Garrabrant"
    },
    {
      "index": 13,
      "title": "Adversarial Attacks on Deep Algorithmic Trading Policies",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Yaser Faghan, Nancirose Piazza, Vahid Behzadan, and Ali Fathi",
      "orig_title": "Adversarial attacks on deep algorithmic trading policies",
      "paper_id": "2010.11388v1"
    },
    {
      "index": 14,
      "title": "Governing ai safety through independent audits",
      "abstract": "",
      "year": "2021",
      "venue": "Nature Machine Intelligence",
      "authors": "Gregory Falco, Ben Shneiderman, Julia Badger, Ryan Carrier, Anton Dahbura, David Danks, Martin Eling, Alwyn Goodloe, Jerry Gupta, Christopher Hart, et al."
    },
    {
      "index": 15,
      "title": "The effect of antagonistic behavior in reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Ted Fujimoto, Timothy Doster, Adam Attarian, Jill Brandenberger, and Nathan Hodas"
    },
    {
      "index": 16,
      "title": "Reward-Free Attacks in Multi-Agent Reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Ted Fujimoto, Timothy Doster, Adam Attarian, Jill Brandenberger, and Nathan Hodas",
      "orig_title": "Reward-free attacks in multi-agent reinforcement learning",
      "paper_id": "2112.00940v1"
    },
    {
      "index": 17,
      "title": "Adversarial Policies: Attacking Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Adam Gleave, Michael Dennis, Neel Kant, Cody Wild, Sergey Levine, and Stuart Russell",
      "orig_title": "Adversarial policies: Attacking deep reinforcement learning",
      "paper_id": "1905.10615v3"
    },
    {
      "index": 18,
      "title": "Gnu general public license",
      "abstract": "",
      "year": "1989",
      "venue": "",
      "authors": "GNU"
    },
    {
      "index": 19,
      "title": "Explaining and Harnessing Adversarial Examples",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv",
      "authors": "Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy",
      "orig_title": "Explaining and harnessing adversarial examples",
      "paper_id": "1412.6572v3"
    },
    {
      "index": 20,
      "title": "Towards Comprehensive Testing on the Robustness of Cooperative Multi-agent Reinforcement Learning",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Jun Guo, Yonghong Chen, Yihang Hao, Zixin Yin, Yin Yu, and Simin Li",
      "orig_title": "Towards comprehensive testing on the robustness of cooperative multi-agent reinforcement learning",
      "paper_id": "2204.07932v1"
    },
    {
      "index": 21,
      "title": "Adversarial policy learning in two-player competitive games",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Machine Learning",
      "authors": "Wenbo Guo, Xian Wu, Sui Huang, and Xinyu Xing"
    },
    {
      "index": 22,
      "title": "Game theory with translucent players",
      "abstract": "",
      "year": "2018",
      "venue": "International Journal of Game Theory",
      "authors": "Joseph Y Halpern and Rafael Pass"
    },
    {
      "index": 23,
      "title": "Opponent Modeling in Deep Reinforcement Learning",
      "abstract": "",
      "year": "2016",
      "venue": "International conference on machine learning",
      "authors": "He He, Jordan Boyd-Graber, Kevin Kwok, and Hal Daumé III",
      "orig_title": "Opponent modeling in deep reinforcement learning",
      "paper_id": "1609.05559v1"
    },
    {
      "index": 24,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 25,
      "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen",
      "orig_title": "Deberta: Decoding-enhanced bert with disentangled attention",
      "paper_id": "2006.03654v6"
    },
    {
      "index": 26,
      "title": "Stable baselines",
      "abstract": "",
      "year": "2018",
      "venue": "GitHub",
      "authors": "Ashley Hill, Antonin Raffin, Maximilian Ernestus, Adam Gleave, Anssi Kanervisto, Rene Traore, Prafulla Dhariwal, Christopher Hesse, Oleg Klimov, Alex Nichol, Matthias Plappert, Alec Radford, John Schulman, Szymon Sidor, and Yuhuai Wu"
    },
    {
      "index": 27,
      "title": "TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Bairu Hou, Jinghan Jia, Yihua Zhang, Guanhua Zhang, Yang Zhang, Sijia Liu, and Shiyu Chang",
      "orig_title": "Textgrad: Advancing robustness evaluation in nlp by gradient-driven optimization",
      "paper_id": "2212.09254v1"
    },
    {
      "index": 28,
      "title": "Adversarial examples are not bugs, they are features",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander Madry"
    },
    {
      "index": 29,
      "title": "Adversarially trained neural policies in the fourier domain",
      "abstract": "",
      "year": "2021",
      "venue": "ICML 2021 Workshop on Adversarial Machine Learning",
      "authors": "Ezgi Korkmaz"
    },
    {
      "index": 30,
      "title": "Investigating Vulnerabilities of Deep Neural Policies",
      "abstract": "",
      "year": "2021",
      "venue": "Uncertainty in Artificial Intelligence",
      "authors": "Ezgi Korkmaz",
      "orig_title": "Investigating vulnerabilities of deep neural policies",
      "paper_id": "2108.13093v1"
    },
    {
      "index": 31,
      "title": "Delving Into Adversarial Attacks on Deep Policies",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv",
      "authors": "Jernej Kos and Dawn Song",
      "orig_title": "Delving into adversarial attacks on deep policies",
      "paper_id": "1705.06452v1"
    },
    {
      "index": 32,
      "title": "Google Research Football: A Novel Reinforcement Learning Environment",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Karol Kurach, Anton Raichuk, Piotr Stańczyk, Michał Zając, Olivier Bachem, Lasse Espeholt, Carlos Riquelme, Damien Vincent, Marcin Michalski, Olivier Bousquet, et al.",
      "orig_title": "Google research football: A novel reinforcement learning environment",
      "paper_id": "1907.11180v2"
    },
    {
      "index": 33,
      "title": "Experimental security research of tesla autopilot",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Tencent Keen Security Lab"
    },
    {
      "index": 34,
      "title": "Adversarial Training for Large Neural Language Models",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Xiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon, and Jianfeng Gao",
      "orig_title": "Adversarial training for large neural language models",
      "paper_id": "2004.08994v2"
    },
    {
      "index": 35,
      "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov",
      "orig_title": "Roberta: A robustly optimized bert pretraining approach",
      "paper_id": "1907.11692v1"
    },
    {
      "index": 36,
      "title": "Evolving explicit opponent models in game playing",
      "abstract": "",
      "year": "2007",
      "venue": "9th annual conference on Genetic and evolutionary computation",
      "authors": "Alan J Lockett, Charles L Chen, and Risto Miikkulainen"
    },
    {
      "index": 37,
      "title": "Certified Adversarial Robustness for Deep Reinforcement Learning",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Robot Learning",
      "authors": "Björn Lütjens, Michael Everett, and Jonathan P How",
      "orig_title": "Certified adversarial robustness for deep reinforcement learning",
      "paper_id": "1910.12908v3"
    },
    {
      "index": 38,
      "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv",
      "authors": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu",
      "orig_title": "Towards deep learning models resistant to adversarial attacks",
      "paper_id": "1706.06083v4"
    },
    {
      "index": 39,
      "title": "Algorithms for inverse reinforcement learning",
      "abstract": "",
      "year": "2000",
      "venue": "Icml",
      "authors": "Andrew Y Ng, Stuart J Russell, et al."
    },
    {
      "index": 40,
      "title": "Robust Deep Reinforcement Learning through Adversarial Loss",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Tuomas Oikarinen, Wang Zhang, Alexandre Megretski, Luca Daniel, and Tsui-Wei Weng",
      "orig_title": "Robust deep reinforcement learning through adversarial loss",
      "paper_id": "2008.01976v2"
    },
    {
      "index": 41,
      "title": "Risk averse robust adversarial reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Robotics and Automation",
      "authors": "Xinlei Pan, Daniel Seita, Yang Gao, and John Canny"
    },
    {
      "index": 42,
      "title": "Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv",
      "authors": "Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow",
      "orig_title": "Transferability in machine learning: from phenomena to black-box attacks using adversarial samples",
      "paper_id": "1605.07277v1"
    },
    {
      "index": 43,
      "title": "Robust Deep Reinforcement Learning with Adversarial Attacks",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv",
      "authors": "Anay Pattanaik, Zhenyi Tang, Shuijing Liu, Gautham Bommannan, and Girish Chowdhary",
      "orig_title": "Robust deep reinforcement learning with adversarial attacks",
      "paper_id": "1712.03632v1"
    },
    {
      "index": 44,
      "title": "Robust Adversarial Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "34th International Conference on Machine Learning",
      "authors": "Lerrel Pinto, James Davidson, Rahul Sukthankar, and Abhinav Gupta",
      "orig_title": "Robust adversarial reinforcement learning",
      "paper_id": "1703.02702v1"
    },
    {
      "index": 45,
      "title": "Anticipatory Counterplanning",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Alberto Pozanco, Susana Fernández, Daniel Borrajo, et al.",
      "orig_title": "Anticipatory counterplanning",
      "paper_id": "2203.16171v1"
    },
    {
      "index": 46,
      "title": "Language models are unsupervised multitask learners",
      "abstract": "",
      "year": "2019",
      "venue": "OpenAI blog",
      "authors": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al."
    },
    {
      "index": 47,
      "title": "Stable-baselines3: Reliable reinforcement learning implementations",
      "abstract": "",
      "year": "2021",
      "venue": "Journal of Machine Learning Research",
      "authors": "Antonin Raffin, Ashley Hill, Adam Gleave, Anssi Kanervisto, Maximilian Ernestus, and Noah Dormann"
    },
    {
      "index": 48,
      "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
      "abstract": "",
      "year": "2019",
      "venue": "2019 Conference on Empirical Methods in Natural Language Processing",
      "authors": "Nils Reimers and Iryna Gurevych",
      "orig_title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
      "paper_id": "1908.10084v1"
    },
    {
      "index": 49,
      "title": "Optimal Attacks on Reinforcement Learning Policies",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Alessio Russo and Alexandre Proutiere",
      "orig_title": "Optimal attacks on reinforcement learning policies",
      "paper_id": "1907.13548v1"
    },
    {
      "index": 50,
      "title": "Improving robustness of deep reinforcement learning agents: Environment attacks based on critic networks",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv",
      "authors": "Lucas Schott, Manon Césaire, Hatem Hajri, and Sylvain Lamprier"
    },
    {
      "index": 51,
      "title": "Proximal policy optimization algorithms",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv",
      "authors": "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov"
    },
    {
      "index": 52,
      "title": "Extending robust adversarial reinforcement learning considering adaptation and diversity",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Hiroaki Shioya, Yusuke Iwasawa, and Yutaka Matsuo"
    },
    {
      "index": 53,
      "title": "Intriguing properties of neural networks",
      "abstract": "",
      "year": "2013",
      "venue": "arXiv",
      "authors": "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus"
    },
    {
      "index": 54,
      "title": "Robustifying reinforcement learning agents via action space adversarial training",
      "abstract": "",
      "year": "2020",
      "venue": "American control conference",
      "authors": "Kai Liang Tan, Yasaman Esfandiari, Xian Yeow Lee, Soumik Sarkar, et al."
    },
    {
      "index": 55,
      "title": "Action Robust Reinforcement Learning and Applications in Continuous Control",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Machine Learning",
      "authors": "Chen Tessler, Yonathan Efroni, and Shie Mannor",
      "orig_title": "Action robust reinforcement learning and applications in continuous control",
      "paper_id": "1901.09184v2"
    },
    {
      "index": 56,
      "title": "The space of transferable adversarial examples",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv",
      "authors": "Florian Tramèr, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick McDaniel"
    },
    {
      "index": 57,
      "title": "Robust Reinforcement Learning using Adversarial Populations",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv",
      "authors": "Eugene Vinitsky, Yuqing Du, Kanaad Parvate, Kathy Jang, Pieter Abbeel, and Alexandre Bayen",
      "orig_title": "Robust reinforcement learning using adversarial populations",
      "paper_id": "2008.01825v2"
    },
    {
      "index": 58,
      "title": "Adversarial policy training against deep reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "USENIX Security Symposium",
      "authors": "Xian Wu, Wenbo Guo, Hua Wei, and Xinyu Xing"
    },
    {
      "index": 59,
      "title": "Robust adversarial reinforcement learning with dissipation inequation constraint",
      "abstract": "",
      "year": "2022",
      "venue": "",
      "authors": "Peng Zhai, Jie Luo, Zhiyan Dong, Lihua Zhang, Shunli Wang, and Dingkang Yang"
    },
    {
      "index": 60,
      "title": "On the stability and convergence of robust adversarial reinforcement learning: A case study on linear quadratic systems",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Kaiqing Zhang, Bin Hu, and Tamer Basar"
    },
    {
      "index": 61,
      "title": "Improving Robustness of Language Models from a Geometry-aware Perspective",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv",
      "authors": "Bin Zhu, Zhaoquan Gu, Le Wang, Jinyin Chen, and Qi Xuan",
      "orig_title": "Improving robustness of language models from a geometry-aware perspective",
      "paper_id": "2204.13309v1"
    },
    {
      "index": 62,
      "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv",
      "authors": "Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and Jingjing Liu",
      "orig_title": "Freelb: Enhanced adversarial training for natural language understanding",
      "paper_id": "1909.11764v5"
    }
  ]
}