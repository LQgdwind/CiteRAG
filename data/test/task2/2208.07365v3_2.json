{
  "paper_id": "2208.07365v3",
  "title": "Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective",
  "sections": {
    "related work": "Unsupervised Video Domain Adaptation. Despite the great progress in image-based UDA, only a few methods have recently attempted video-based UDA. In , a temporal attentive adversarial adaptation network (TA3N) is proposed to integrate a temporal relation module for temporal alignment. Choi et al.  proposed a SAVA method using self-supervised clip order prediction and clip attention-based alignment. Based on a cross-domain co-attention mechanism, the temporal co-attention network TCoN [ref]29 focused on common key frames across domains for better alignment. Luo et al.  pay more attention to the domain-agnostic classifier by using a network topology of the bipartite graph to model the cross-domain correlations. Instead of using adversarial learning, Sahoo et al. [ref]31 developed an end-to-end temporal contrastive learning framework named CoMix with background mixing and target pseudo-labels. Recently, Chen et al.  learned multiple domain discriminators for multi-level temporal attentive features to achieve better alignment, while Turrisi et al. [ref]37 exploited two-headed deep architecture to learn a more robust target classifier by the combination of cross-entropy and contrastive losses. Although these approaches have advanced video-based UDA tasks, they all adopted to align features with diverse information mixed up from a compression perspective, which leaves room for further improvements. Multi-Modal Video Adaptation. Most recently, there are also a few works integrating multiple modality data for video-based UDA. Although we only use the single modality RGB features, we still discuss this multi-modal research line for a complete literature review. The very first work exploring the multi-modal nature of videos for UDA is MM-SADA , where the correspondence of multiple modalities was exploited as a self-supervised alignment in addition to adversarial alignment. A later work, spatial-temporal contrastive domain adaptation (STCDA) , utilized a video-based contrastive alignment as the multi-modal domain metric to measure the video-level discrepancy across domains.  proposed cross-modal and cross-domain contrastive losses to handle feature spaces across modalities and domains.  leveraged both cross-modal complementary and cross-modal consensus to learn the most transferable features through a CIA framework. In , the authors proposed to generate noisy pseudo-labels for the target domain data using the source pre-trained model and select the clean samples in order to increase the quality of the pseudo-labels. Lin et al.  developed a cycle-based approach that alternates between spatial and spatiotemporal learning with knowledge transfer. Generally, all the above methods utilize the flow as the auxiliary modality input. Recently, there are also methods exploring other modalities, for instance, A3R  with audios and MixDANN  with wild data. It is worth noting that the proposed TranSVAE – although only uses single modality RGB features – surprisingly achieves better UDA performance compared with most current state-of-the-art multi-modal methods, which highlights our superiority. Disentanglement.\nFeature disentanglement is a wide and hot research topic. We only focus on works that are closely related to ours. In the image domain, some works consider adaptation from a generative view.  learned a disentangled semantic representation across domains. A similar idea is then applied to graph domain adaptation  and domain generalization .  proposed a novel informative feature disentanglement, equipped with the adversarial network or the metric discrepancy model. Another disentanglement-related topic is sequential data generation. To generate videos, existing works  0  extended VAE to a recurrent form with different recursive structures. In this paper, we present a VAE-based structure to generate cross-domain videos. We aim at tackling video-based UDA from a new perspective: sequential domain disentanglement and transfer."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Contrastively Disentangled Sequential Variational Autoencoder",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Junwen Bai, Weiran Wang, and Carla P Gomes",
      "orig_title": "Contrastively disentangled sequential variational autoencoder",
      "paper_id": "2110.12091v1"
    },
    {
      "index": 1,
      "title": "Mutual information analysis: a comprehensive study",
      "abstract": "",
      "year": "2011",
      "venue": "Journal of Cryptology",
      "authors": "Lejla Batina, Benedikt Gierlichs, Emmanuel Prouff, Matthieu Rivain, François-Xavier Standaert, and Nicolas Veyrat-Charvillon"
    },
    {
      "index": 2,
      "title": "Exploring object relation in mean teacher for cross-domain detection",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Qi Cai, Yingwei Pan, Chong-Wah Ngo, Xinmei Tian, Lingyu Duan, and Ting Yao"
    },
    {
      "index": 3,
      "title": "Learning disentangled semantic representation for domain adaptation",
      "abstract": "",
      "year": "2019",
      "venue": "International Joint Conferences on Artificial Intelligence",
      "authors": "Ruichu Cai, Zijian Li, Pengfei Wei, Jie Qiao, Kun Zhang, and Zhifeng Hao"
    },
    {
      "index": 4,
      "title": "Graph Domain Adaptation: A Generative View",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2106.07482",
      "authors": "Ruichu Cai, Fengzhu Wu, Zijian Li, Pengfei Wei, Lingling Yi, and Kun Zhang",
      "orig_title": "Graph domain adaptation: A generative view",
      "paper_id": "2106.07482v1"
    },
    {
      "index": 5,
      "title": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Joao Carreira and Andrew Zisserman",
      "orig_title": "Quo vadis, action recognition? a new model and the kinetics dataset",
      "paper_id": "1705.07750v3"
    },
    {
      "index": 6,
      "title": "Temporal Attentive Alignment for Large-Scale Video Domain Adaptation",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/CVF International Conference on Computer Vision",
      "authors": "Min-Hung Chen, Zsolt Kira, Ghassan AlRegib, Jaekwon Yoo, Ruxin Chen, and Jian Zheng",
      "orig_title": "Temporal attentive alignment for large-scale video domain adaptation",
      "paper_id": "1907.12743v6"
    },
    {
      "index": 7,
      "title": "Multi-level attentive adversarial learning with temporal dilation for unsupervised video domain adaptation",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Winter Conference on Applications of Computer Vision",
      "authors": "Peipeng Chen, Yuan Gao, and Andy J Ma"
    },
    {
      "index": 8,
      "title": "Isolating sources of disentanglement in variational autoencoders",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ricky TQ Chen, Xuechen Li, Roger B Grosse, and David K Duvenaud"
    },
    {
      "index": 9,
      "title": "Shuffle and attend: Video domain adaptation",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Jinwoo Choi, Gaurav Sharma, Samuel Schulter, and Jia-Bin Huang"
    },
    {
      "index": 10,
      "title": "Scaling egocentric vision: The epic-kitchens dataset",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision",
      "authors": "Dima Damen, Hazel Doughty, Giovanni Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, et al."
    },
    {
      "index": 11,
      "title": "Overcoming label noise for source-free unsupervised video domain adaptation",
      "abstract": "",
      "year": "2022",
      "venue": "Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing",
      "authors": "Avijit Dasgupta, CV Jawahar, and Karteek Alahari"
    },
    {
      "index": 12,
      "title": "Informative feature disentanglement for unsupervised domain adaptation",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Multimedia",
      "authors": "Wanxia Deng, Lingjun Zhao, Qing Liao, Deke Guo, Gangyao Kuang, Dewen Hu, Matti Pietikäinen, and Li Liu"
    },
    {
      "index": 13,
      "title": "Domain-Adversarial Training of Neural Networks",
      "abstract": "",
      "year": "2016",
      "venue": "Journal of Machine Learning Research",
      "authors": "Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky",
      "orig_title": "Domain-adversarial training of neural networks",
      "paper_id": "1505.07818v4"
    },
    {
      "index": 14,
      "title": "Uncertainty-Aware Unsupervised Domain Adaptation in Object Detection",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Multimedia",
      "authors": "Dayan Guan, Jiaxing Huang, Aoran Xiao, Shijian Lu, and Yanpeng Cao",
      "orig_title": "Uncertainty-aware unsupervised domain adaptation in object detection",
      "paper_id": "2103.00236v2"
    },
    {
      "index": 15,
      "title": "DIVA: Domain Invariant Variational Autoencoders",
      "abstract": "",
      "year": "2020",
      "venue": "Medical Imaging with Deep Learning",
      "authors": "Maximilian Ilse, Jakub M Tomczak, Christos Louizos, and Max Welling",
      "orig_title": "Diva: Domain invariant variational autoencoders",
      "paper_id": "1905.10427v2"
    },
    {
      "index": 16,
      "title": "The Kinetics Human Action Video Dataset",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1705.06950",
      "authors": "Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et al.",
      "orig_title": "The kinetics human action video dataset",
      "paper_id": "1705.06950v1"
    },
    {
      "index": 17,
      "title": "Learning cross-modal contrastive features for video domain adaptation",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF International Conference on Computer Vision",
      "authors": "Donghyun Kim, Yi-Hsuan Tsai, Bingbing Zhuang, Xiang Yu, Stan Sclaroff, Kate Saenko, and Manmohan Chandraker"
    },
    {
      "index": 18,
      "title": "ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via Regularized Domain Concatenation",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE International Conference on Robotics and Automation",
      "authors": "Lingdong Kong, Niamul Quader, and Venice Erin Liong",
      "orig_title": "Conda: Unsupervised domain adaptation for lidar segmentation via regularized domain concatenation",
      "paper_id": "2111.15242v3"
    },
    {
      "index": 19,
      "title": "Hmdb: a large video database for human motion recognition",
      "abstract": "",
      "year": "2011",
      "venue": "IEEE/CVF International Conference on Computer Vision",
      "authors": "Hildegard Kuehne, Hueihan Jhuang, Estíbaliz Garrote, Tomaso Poggio, and Thomas Serre"
    },
    {
      "index": 20,
      "title": "Adaptive batch normalization for practical domain adaptation",
      "abstract": "",
      "year": "2018",
      "venue": "Pattern Recognition",
      "authors": "Yanghao Li, Naiyan Wang, Jianping Shi, Xiaodi Hou, and Jiaying Liu"
    },
    {
      "index": 21,
      "title": "Disentangled Sequential Autoencoder",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Yingzhen Li and Stephan Mandt",
      "orig_title": "Disentangled sequential autoencoder",
      "paper_id": "1803.02991v2"
    },
    {
      "index": 22,
      "title": "Cycda: Unsupervised cycle domain adaptation to learn from image to video",
      "abstract": "",
      "year": "2022",
      "venue": "European Conference on Computer Vision",
      "authors": "Wei Lin, Anna Kukleva, Kunyang Sun, Horst Possegger, Hilde Kuehne, and Horst Bischof"
    },
    {
      "index": 23,
      "title": "Segment Any Point Cloud Sequences by Distilling Vision Foundation Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.09347",
      "authors": "Youquan Liu, Lingdong Kong, Jun Cen, Runnan Chen, Wenwei Zhang, Liang Pan, Kai Chen, and Ziwei Liu",
      "orig_title": "Segment any point cloud sequences by distilling vision foundation models",
      "paper_id": "2306.09347v2"
    },
    {
      "index": 24,
      "title": "Deep Transfer Learning with Joint Adaptation Networks",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan",
      "orig_title": "Deep transfer learning with joint adaptation networks",
      "paper_id": "1605.06636v2"
    },
    {
      "index": 25,
      "title": "Adversarial Bipartite Graph Learning for Video Domain Adaptation",
      "abstract": "",
      "year": "2020",
      "venue": "ACM International Conference on Multimedia",
      "authors": "Yadan Luo, Zi Huang, Zijian Wang, Zheng Zhang, and Mahsa Baktashmotlagh",
      "orig_title": "Adversarial bipartite graph learning for video domain adaptation",
      "paper_id": "2007.15829v1"
    },
    {
      "index": 26,
      "title": "The jester dataset: A large-scale video dataset of human gestures",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/CVF International Conference on Computer Vision Workshops",
      "authors": "Joanna Materzynska, Guillaume Berger, Ingo Bax, and Roland Memisevic"
    },
    {
      "index": 27,
      "title": "Multi-Modal Domain Adaptation for Fine-Grained Action Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Jonathan Munro and Dima Damen",
      "orig_title": "Multi-modal domain adaptation for fine-grained action recognition",
      "paper_id": "2001.09691v2"
    },
    {
      "index": 28,
      "title": "Adversarial Cross-Domain Action Recognition with Co-Attention",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Boxiao Pan, Zhangjie Cao, Ehsan Adeli, and Juan Carlos Niebles",
      "orig_title": "Adversarial cross-domain action recognition with co-attention",
      "paper_id": "1912.10405v1"
    },
    {
      "index": 29,
      "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala",
      "orig_title": "Pytorch: An imperative style, high-performance deep learning library",
      "paper_id": "1912.01703v1"
    },
    {
      "index": 30,
      "title": "Contrast and mix: Temporal contrastive video domain adaptation with background mixing",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Aadarsh Sahoo, Rutav Shah, Rameswar Panda, Kate Saenko, and Abir Das"
    },
    {
      "index": 31,
      "title": "Maximum Classifier Discrepancy for Unsupervised Domain Adaptation",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada",
      "orig_title": "Maximum classifier discrepancy for unsupervised domain adaptation",
      "paper_id": "1712.02560v4"
    },
    {
      "index": 32,
      "title": "Multi-Head Distillation for Continual Unsupervised Domain Adaptation in Semantic Segmentation",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Antoine Saporta, Arthur Douillard, Tuan-Hung Vu, Patrick Pérez, and Matthieu Cord",
      "orig_title": "Multi-head distillation for continual unsupervised domain adaptation in semantic segmentation",
      "paper_id": "2204.11667v1"
    },
    {
      "index": 33,
      "title": "Spatio-temporal contrastive domain adaptation for action recognition",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Xiaolin Song, Sicheng Zhao, Jingyu Yang, Huanjing Yue, Pengfei Xu, Runbo Hu, and Hua Chai"
    },
    {
      "index": 34,
      "title": "Ucf101: A dataset of 101 human actions classes from videos in the wild",
      "abstract": "",
      "year": "2012",
      "venue": "arXiv preprint arXiv:1212.0402",
      "authors": "Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah"
    },
    {
      "index": 35,
      "title": "VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Zhan Tong, Yibing Song, Jue Wang, and Limin Wang",
      "orig_title": "Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training",
      "paper_id": "2203.12602v3"
    },
    {
      "index": 36,
      "title": "Dual-head contrastive domain adaptation for video action recognition",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Winter Conference on Applications of Computer Vision",
      "authors": "Victor G Turrisi, Giacomo Zara, Paolo Rota, Thiago Oliveira-Santos, Nicu Sebe, Vittorio Murino, and Elisa Ricci"
    },
    {
      "index": 37,
      "title": "Adversarial Discriminative Domain Adaptation",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell",
      "orig_title": "Adversarial discriminative domain adaptation",
      "paper_id": "1702.05464v1"
    },
    {
      "index": 38,
      "title": "Visualizing Data using GTSNE",
      "abstract": "",
      "year": "2008",
      "venue": "Journal of Machine Learning Research",
      "authors": "Laurens Van der Maaten and Geoffrey Hinton",
      "orig_title": "Visualizing data using t-sne",
      "paper_id": "2108.01301v1"
    },
    {
      "index": 39,
      "title": "VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Limin Wang, Bingkun Huang, Zhiyu Zhao, Zhan Tong, Yinan He, Yi Wang, Yali Wang, and Yu Qiao",
      "orig_title": "Videomae v2: Scaling video masked autoencoders with dual masking",
      "paper_id": "2303.16727v2"
    },
    {
      "index": 40,
      "title": "A Survey of Unsupervised Deep Domain Adaptation",
      "abstract": "",
      "year": "2020",
      "venue": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Garrett Wilson and Diane J Cook",
      "orig_title": "A survey of unsupervised deep domain adaptation",
      "paper_id": "1812.02849v3"
    },
    {
      "index": 41,
      "title": "Dynamic Weighted Learning for Unsupervised Domain Adaptation",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Ni Xiao and Lei Zhang",
      "orig_title": "Dynamic weighted learning for unsupervised domain adaptation",
      "paper_id": "2103.13814v1"
    },
    {
      "index": 42,
      "title": "Interact before align: Leveraging cross-modal knowledge for domain adaptive action recognition",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Lijin Yang, Yifei Huang, Yusuke Sugano, and Yoichi Sato"
    },
    {
      "index": 43,
      "title": "Mix-dann and dynamic-modal-distillation for video domain adaptation",
      "abstract": "",
      "year": "2022",
      "venue": "ACM International Conference on Multimedia",
      "authors": "Yuehao Yin, Bin Zhu, Jingjing Chen, Lechao Cheng, and Yu-Gang Jiang"
    },
    {
      "index": 44,
      "title": "Sc-uda: Style and content gaps aware unsupervised domain adaptation for object detection",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Winter Conference on Applications of Computer Vision",
      "authors": "Fuxun Yu, Di Wang, Yinpeng Chen, Nikolaos Karianakis, Tong Shen, Pei Yu, Dimitrios Lymberopoulos, Sidi Lu, Weisong Shi, and Xiang Chen"
    },
    {
      "index": 45,
      "title": "Unsupervised representation learning with deep convolutional neural network for remote sensing images",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Image and Graphics",
      "authors": "Yang Yu, Zhiqiang Gong, Ping Zhong, and Jiaxin Shan"
    },
    {
      "index": 46,
      "title": "Spectral unsupervised domain adaptation for visual recognition",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Jingyi Zhang, Jiaxing Huang, Zichen Tian, and Shijian Lu"
    },
    {
      "index": 47,
      "title": "Audio-Adaptive Activity Recognition Across Video Domains",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Yunhua Zhang, Hazel Doughty, Ling Shao, and Cees GM Snoek",
      "orig_title": "Audio-adaptive activity recognition across video domains",
      "paper_id": "2203.14240v2"
    },
    {
      "index": 48,
      "title": "Temporal Relational Reasoning in Videos",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision",
      "authors": "Bolei Zhou, Alex Andonian, Aude Oliva, and Antonio Torralba",
      "orig_title": "Temporal relational reasoning in videos",
      "paper_id": "1711.08496v2"
    },
    {
      "index": 49,
      "title": "S3VAE: Self-Supervised Sequential VAE for Representation Disentanglement and Data Generation",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Yizhe Zhu, Martin Renqiang Min, Asim Kadav, and Hans Peter Graf",
      "orig_title": "S3vae: Self-supervised sequential vae for representation disentanglement and data generation",
      "paper_id": "2005.11437v1"
    },
    {
      "index": 50,
      "title": "Unsupervised domain adaptation for semantic segmentation via class-balanced self-training",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision",
      "authors": "Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang"
    }
  ]
}