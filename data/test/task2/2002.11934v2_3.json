{
  "paper_id": "2002.11934v2",
  "title": "Supervised Dimensionality Reduction and Visualization using Centroid-encoder",
  "sections": {
    "autoencoder neural networks": "An autoencoder is a dimension reducing mapping that has been\noptimized to approximate the identity\non a set of training data   .\nThe mapping is modeled as the composition of a dimension reducing\nmapping g𝑔g followed by a dimension increasing reconstruction mapping hℎh, i.e., where the encoder g𝑔g is represented and the decoder hℎh is represented The construction of g𝑔g and hℎh, and hence f𝑓f, is\naccomplished by solving the unconstrained optimization problem for a given set of points X={x1,x2,x3,…}𝑋superscript𝑥1superscript𝑥2superscript𝑥3…X=\\{x^{1},x^{2},x^{3},...\\}. Hence, the autoencoder learns a function f𝑓f such that f​(xi;θ)≈xi𝑓superscript𝑥𝑖𝜃superscript𝑥𝑖f(x^{i};\\theta)\\approx x^{i} where θ𝜃\\theta is the set of model parameters that is found by solving the optimization problem. The encoder map g𝑔g takes the input xisuperscript𝑥𝑖x^{i} and maps it to a latent representation In this paper we are primarily concerned with visualization so we take m=2𝑚2m=2.\nThe decoder ensures that the encoder is faithful to the data point, i.e., it\nserves to reconstruct the reduced point to its original state The parameters θ𝜃\\theta are learned by using error backpropagation  . The details for using multi-layer perceptrons for training autoencoders can be found in . If we restrict g𝑔g and hℎh to be linear transformations then  showed that autoencoder function learns the same subspace of PCA. The nonlinear autoencoder has been proposed as a nonlinear version of PCA\n . If we restrict g𝑔g to be linear and allow hℎh to be nonlinear then the autoencoder\nfits into the blueprint of Whitney’s theorem for manifold embeddings  . Topologically sensitive nonlinear reduction use, e.g., topological circle or sphere encoding neurons 7 8 9 to capture shape in data. The use of shallow architectures was partly motivated by the theoretical\nresult that a neural network with one hidden layer is a universal approximator by 0 1. A probabilistic pre-training approach, known as Restricted Boltzmann Machine (RBM), was introduced  , which initializes the network parameters near to a good solution followed by a nonlinear refinement to further fine-tune the parameters. This break-through opened the window of training neural networks with many hidden layers. Since then deep neural networks (DNN) architecture has been employed to train autoencoders. The pre-training approach was extended further to continuous values by  2. Several other deep autoencoder based model were also proposed to extract sparse features 3 4. The method of denoising autoencoder 5 was introduced to learn latent features by reconstructing an input from it noisy version. Autoencoders can also be trained by stacking multiple convolutional layers as described by 6 7 8. A comprehensive description of autoencoders and their variants can be found in [59, chap. 14]."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "On lines and planes of closest fit to systems of points in space",
      "abstract": "",
      "year": "1901",
      "venue": "Phil. Mag. S.",
      "authors": "Karl Pearson"
    },
    {
      "index": 1,
      "title": "Analysis of a complex of statistical variables into principal components",
      "abstract": "",
      "year": "1933",
      "venue": "Journal of Educational Psychology",
      "authors": "H. Hotelling"
    },
    {
      "index": 2,
      "title": "Principal component analysis: a review and recent developments",
      "abstract": "",
      "year": "2016",
      "venue": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
      "authors": "Ian T Jolliffe and Jorge Cadima"
    },
    {
      "index": 3,
      "title": "Nonlinear principal component analysis using autoassociative neural networks",
      "abstract": "",
      "year": "1991",
      "venue": "AIChE J.",
      "authors": "Mark A. Kramer"
    },
    {
      "index": 4,
      "title": "Autoassociative neural networks",
      "abstract": "",
      "year": "1992",
      "venue": "Comput. Chem. Engng.",
      "authors": "Mark A. Kramer"
    },
    {
      "index": 5,
      "title": "Data compression, feature extraction, and autoassociation in feedforward neural networks",
      "abstract": "",
      "year": "1991",
      "venue": "Artificial Neural Networks",
      "authors": "E. Oja"
    },
    {
      "index": 6,
      "title": "Geometric Data Analysis: An Empirical Approach to Dimensionality Reduction and the Study of Patterns",
      "abstract": "",
      "year": "2001",
      "venue": "Wiley",
      "authors": "M. Kirby"
    },
    {
      "index": 7,
      "title": "A new approach for dimensionality reduction: Theory and algorithms",
      "abstract": "",
      "year": "2000",
      "venue": "SIAM J. of Applied Mathematics",
      "authors": "D.S. Broomhead and M. Kirby"
    },
    {
      "index": 8,
      "title": "The Whitney reduction network: a method for computing autoassociative graphs",
      "abstract": "",
      "year": "2001",
      "venue": "Neural Computation",
      "authors": "D.S. Broomhead and M. Kirby"
    },
    {
      "index": 9,
      "title": "Reducing the dimensionality of data with neural networks",
      "abstract": "",
      "year": "2006",
      "venue": "science",
      "authors": "Geoffrey E Hinton and Ruslan R Salakhutdinov"
    },
    {
      "index": 10,
      "title": "A fast learning algorithm for deep belief nets",
      "abstract": "",
      "year": "2006",
      "venue": "Neural Comput.",
      "authors": "Geoffrey E. Hinton, Simon Osindero, and Yee-Whye Teh"
    },
    {
      "index": 11,
      "title": "Principal Component Analysis",
      "abstract": "",
      "year": "1986",
      "venue": "Springer",
      "authors": "I.T. Jolliffe"
    },
    {
      "index": 12,
      "title": "Karhunen–Loève expansion and factor analysis",
      "abstract": "",
      "year": "1965",
      "venue": "Trans. 4th. Prague Conf. on Inf. Theory, Statist. Decision Functions, and Random Proc.",
      "authors": "S. Watanabe"
    },
    {
      "index": 13,
      "title": "Self-organized formation of topologically correct feature maps",
      "abstract": "",
      "year": "1982",
      "venue": "Biol. Cybern.",
      "authors": "T. Kohonen"
    },
    {
      "index": 14,
      "title": "Multidimensional scaling: I. theory and method",
      "abstract": "",
      "year": "1952",
      "venue": "Psychometrika",
      "authors": "W. S. Torgerson"
    },
    {
      "index": 15,
      "title": "A global geometric framework for nonlinear dimensionality reduction",
      "abstract": "",
      "year": "2000",
      "venue": "Science",
      "authors": "Joshua B. Tenenbaum, Vin de Silva, and John C. Langford"
    },
    {
      "index": 16,
      "title": "Laplacian eigenmaps for dimensionality reduction and data representation",
      "abstract": "",
      "year": "2003",
      "venue": "Neural Comput.",
      "authors": "Mikhail Belkin and Partha Niyogi"
    },
    {
      "index": 17,
      "title": "Nonlinear dimensionality reduction by locally linear embedding",
      "abstract": "",
      "year": "2000",
      "venue": "SCIENCE",
      "authors": "Sam T. Roweis and Lawrence K. Saul"
    },
    {
      "index": 18,
      "title": "Stochastic neighbor embedding",
      "abstract": "",
      "year": "2003",
      "venue": "Advances in Neural Information Processing Systems 15",
      "authors": "Geoffrey E Hinton and Sam T. Roweis"
    },
    {
      "index": 19,
      "title": "An introduction to nonlinear dimensionality reduction by maximum variance unfolding",
      "abstract": "",
      "year": "2006",
      "venue": "21st National Conference on Artificial Intelligence - Volume 2, AAAI’06",
      "authors": "Killan Q. Weinberger and Lawrence K. Saul"
    },
    {
      "index": 20,
      "title": "Visualizing Data using GTSNE",
      "abstract": "",
      "year": "2008",
      "venue": "Journal of Machine Learning Research",
      "authors": "Laurens van der Maaten and Geoffrey Hinton",
      "orig_title": "Visualizing data using t-SNE",
      "paper_id": "2108.01301v1"
    },
    {
      "index": 21,
      "title": "UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1802.03426",
      "authors": "Leland McInnes, John Healy, and James Melville",
      "orig_title": "Umap: Uniform manifold approximation and projection for dimension reduction",
      "paper_id": "1802.03426v3"
    },
    {
      "index": 22,
      "title": "Sparse multidimensional scaling using landmark points",
      "abstract": "",
      "year": "2004",
      "venue": "Technical report, Stanford University",
      "authors": "Vin De Silva and Joshua B Tenenbaum"
    },
    {
      "index": 23,
      "title": "The use of multiple measurements in taxonomic problems",
      "abstract": "",
      "year": "1936",
      "venue": "Annals of Eugenics",
      "authors": "R. A. Fisher"
    },
    {
      "index": 24,
      "title": "Pattern Classification and Scene Analysis",
      "abstract": "",
      "year": "1973",
      "venue": "John Willey & Sons",
      "authors": "R. O. Duda and P. E. Hart"
    },
    {
      "index": 25,
      "title": "Prediction by supervised principal components",
      "abstract": "",
      "year": "2006",
      "venue": "Journal of the American Statistical Association",
      "authors": "Eric Bair, Trevor Hastie, Debashis Paul, and Robert Tibshirani"
    },
    {
      "index": 26,
      "title": "Supervised principal component analysis: Visualization, classification and regression on subspaces and submanifolds",
      "abstract": "",
      "year": "2011",
      "venue": "Pattern Recogn.",
      "authors": "Elnaz Barshan, Ali Ghodsi, Zohreh Azimifar, and Mansoor Zolghadri Jahromi"
    },
    {
      "index": 27,
      "title": "Colored maximum variance unfolding",
      "abstract": "",
      "year": "2007",
      "venue": "NIPS",
      "authors": "Le Song, Alexander J. Smola, Karsten M. Borgwardt, and Arthur Gretton"
    },
    {
      "index": 28,
      "title": "Neighbourhood components analysis",
      "abstract": "",
      "year": "2004",
      "venue": "17th International Conference on Neural Information Processing Systems, NIPS’04",
      "authors": "Jacob Goldberger, Sam Roweis, Geoff Hinton, and Ruslan Salakhutdinov"
    },
    {
      "index": 29,
      "title": "Parametric embedding for class visualization",
      "abstract": "",
      "year": "2007",
      "venue": "Neural Comput.",
      "authors": "Tomoharu Iwata, Kazumi Saito, Naonori Ueda, Sean Stromsten, Thomas L. Griffiths, and Joshua B. Tenenbaum"
    },
    {
      "index": 30,
      "title": "Learning a nonlinear embedding by preserving class neighbourhood structure",
      "abstract": "",
      "year": "2007",
      "venue": "Artificial Intelligence and Statistics",
      "authors": "Ruslan Salakhutdinov and Geoff Hinton"
    },
    {
      "index": 31,
      "title": "Metric learning by collapsing classes",
      "abstract": "",
      "year": "2006",
      "venue": "Advances in neural information processing systems",
      "authors": "Amir Globerson and Sam T Roweis"
    },
    {
      "index": 32,
      "title": "Deep supervised t-distributed embedding",
      "abstract": "",
      "year": "2010",
      "venue": "27th International Conference on Machine Learning (ICML-10)",
      "authors": "Martin R Min, Laurens Maaten, Zineng Yuan, Anthony J Bonner, and Zhaolei Zhang"
    },
    {
      "index": 33,
      "title": "Information retrieval perspective to nonlinear dimensionality reduction for data visualization",
      "abstract": "",
      "year": "2010",
      "venue": "J. Mach. Learn. Res.",
      "authors": "Jarkko Venna, Jaakko Peltonen, Kristian Nybo, Helena Aidos, and Samuel Kaski"
    },
    {
      "index": 34,
      "title": "Supervised isomap based on pairwise constraints",
      "abstract": "",
      "year": "2012",
      "venue": "19th International Conference on Neural Information Processing - Volume Part I, ICONIP’12",
      "authors": "Jian Cheng, Can Cheng, and Yi-nan Guo"
    },
    {
      "index": 35,
      "title": "Enhanced supervised locally linear embedding",
      "abstract": "",
      "year": "2009",
      "venue": "Pattern Recogn. Lett.",
      "authors": "Shi-qing Zhang"
    },
    {
      "index": 36,
      "title": "A supervised non-linear dimensionality reduction approach for manifold learning",
      "abstract": "",
      "year": "2012",
      "venue": "Pattern Recogn.",
      "authors": "B. Raducanu and F. Dornaika"
    },
    {
      "index": 37,
      "title": "Feature extraction with deep neural networks by a generalized discriminant analysis",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE transactions on neural networks and learning systems",
      "authors": "Andre Stuhlsatz, Jens Lippel, and Thomas Zielke"
    },
    {
      "index": 38,
      "title": "Exemplar-centered Supervised Shallow Parametric Data Embedding",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1702.06602",
      "authors": "Martin Renqiang Min, Hongyu Guo, and Dongjin Song",
      "orig_title": "Exemplar-centered supervised shallow parametric data embedding",
      "paper_id": "1702.06602v2"
    },
    {
      "index": 39,
      "title": "Scikit-learn: Machine learning in python",
      "abstract": "",
      "year": "2011",
      "venue": "J. Mach. Learn. Res.",
      "authors": "Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, and Édouard Duchesnay"
    },
    {
      "index": 40,
      "title": "New tools for the visualization of biological pathways",
      "abstract": "",
      "year": "2018",
      "venue": "Methods",
      "authors": "Tomojit Ghosh, Xiaofeng Ma, and Michael Kirby"
    },
    {
      "index": 41,
      "title": "Nonlinear principal component analysis using autoassociative neural networks",
      "abstract": "",
      "year": "1991",
      "venue": "AIChE Journal",
      "authors": "Mark A. Kramer"
    },
    {
      "index": 42,
      "title": "Greedy layer-wise training of deep networks",
      "abstract": "",
      "year": "2006",
      "venue": "19th International Conference on Neural Information Processing Systems, NIPS’06",
      "authors": "Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle"
    },
    {
      "index": 43,
      "title": "Learning internal representations by error propagation",
      "abstract": "",
      "year": "1985",
      "venue": "DTIC Document",
      "authors": "David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams"
    },
    {
      "index": 44,
      "title": "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences",
      "abstract": "",
      "year": "1974",
      "venue": "Harvard University",
      "authors": "P.J. Werbos"
    },
    {
      "index": 45,
      "title": "Neural networks and principal component analysis: Learning from examples without local minima",
      "abstract": "",
      "year": "1989",
      "venue": "Neural Netw.",
      "authors": "P. Baldi and K. Hornik"
    },
    {
      "index": 46,
      "title": "Empirical dynamical system reduction I: Global nonlinear transformations",
      "abstract": "",
      "year": "1999",
      "venue": "Semi-analytic Methods for the Navier–Stokes Equations",
      "authors": "M. Kirby and R. Miranda"
    },
    {
      "index": 47,
      "title": "Circular nodes in neural networks",
      "abstract": "",
      "year": "1996",
      "venue": "Neural Computation",
      "authors": "M. Kirby and R. Miranda"
    },
    {
      "index": 48,
      "title": "Spherical nodes in neural networks with applications",
      "abstract": "",
      "year": "1995",
      "venue": "Intelligent Engineering Through Artificial Neural Networks",
      "authors": "D. Hundley, M. Kirby, and R. Miranda"
    },
    {
      "index": 49,
      "title": "Multilayer feedforward networks are universal approximators",
      "abstract": "",
      "year": "1989",
      "venue": "Neural Netw.",
      "authors": "K. Hornik, M. Stinchcombe, and H. White"
    },
    {
      "index": 50,
      "title": "Approximation by superpositions of a sigmoidal function",
      "abstract": "",
      "year": "1989",
      "venue": "Mathematics of Control, Signals and Systems",
      "authors": "G. Cybenko"
    },
    {
      "index": 51,
      "title": "Greedy layer-wise training of deep networks",
      "abstract": "",
      "year": "2007",
      "venue": "Advances in Neural Information Processing Systems 19",
      "authors": "Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle"
    },
    {
      "index": 52,
      "title": "Sparse feature learning for deep belief networks",
      "abstract": "",
      "year": "2007",
      "venue": "20th International Conference on Neural Information Processing Systems, NIPS’07",
      "authors": "Marc’ Aurelio Ranzato, Y-Lan Boureau, and Yann LeCun"
    },
    {
      "index": 53,
      "title": "Sparse deep belief net model for visual area v2",
      "abstract": "",
      "year": "2008",
      "venue": "Advances in Neural Information Processing Systems 20",
      "authors": "Honglak Lee, Chaitanya Ekanadham, and Andrew Y. Ng"
    },
    {
      "index": 54,
      "title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion",
      "abstract": "",
      "year": "2010",
      "venue": "J. Mach. Learn. Res.",
      "authors": "Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine Manzagol"
    },
    {
      "index": 55,
      "title": "Stacked convolutional auto-encoders for hierarchical feature extraction",
      "abstract": "",
      "year": "2011",
      "venue": "21th International Conference on Artificial Neural Networks - Volume Part I, ICANN’11",
      "authors": "Jonathan Masci, Ueli Meier, Dan Cireşan, and Jürgen Schmidhuber"
    },
    {
      "index": 56,
      "title": "Deep clustering with convolutional autoencoders",
      "abstract": "",
      "year": "2017",
      "venue": "Neural Information Processing",
      "authors": "Xifeng Guo, Xinwang Liu, En Zhu, and Jianping Yin"
    },
    {
      "index": 57,
      "title": "DeepPainter: Painter Classification Using Deep Convolutional Autoencoders",
      "abstract": "",
      "year": "2017",
      "venue": "CoRR",
      "authors": "Eli David and Nathan S. Netanyahu",
      "orig_title": "Deeppainter: Painter classification using deep convolutional autoencoders",
      "paper_id": "1711.08763v1"
    },
    {
      "index": 58,
      "title": "Deep Learning",
      "abstract": "",
      "year": "2016",
      "venue": "MIT Press",
      "authors": "Ian Goodfellow, Yoshua Bengio, and Aaron Courville",
      "orig_title": "Deep Learning",
      "paper_id": "1807.07987v2"
    },
    {
      "index": 59,
      "title": "An algorithm for vector quantization design",
      "abstract": "",
      "year": "1980",
      "venue": "IEEE transactions on Communications",
      "authors": "Y. Linde, A. Buzo, and R. Gray"
    },
    {
      "index": 60,
      "title": "Learning a parametric embedding by preserving local structure",
      "abstract": "",
      "year": "2009",
      "venue": "AISTATS",
      "authors": "Laurens van der Maaten"
    },
    {
      "index": 61,
      "title": "Multiple relational embedding",
      "abstract": "",
      "year": "2004",
      "venue": "17th International Conference on Neural Information Processing Systems, NIPS’04",
      "authors": "Roland Memisevic and Geoffrey Hinton"
    },
    {
      "index": 62,
      "title": "UCI machine learning repository",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Dheeru Dua and Casey Graff"
    },
    {
      "index": 63,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2014",
      "venue": "CoRR",
      "authors": "Diederik P. Kingma and Jimmy Ba"
    }
  ]
}