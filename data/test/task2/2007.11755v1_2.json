{
  "paper_id": "2007.11755v1",
  "title": "History Repeats Itself: Human Motion Prediction via Motion Attention",
  "sections": {
    "evaluation metrics and baselines": "Metrics. For the models that output 3D positions, we report the Mean Per Joint Position Error (MPJPE)  in millimeter, which is commonly used in human pose estimation. For those that predict angles, we follow the standard evaluation protocol  [ref]17 [ref]20 and report the Euclidean distance in Euler angle representation. Baselines. We compare our approach with two RNN-based methods, Res. sup.  and MHU [ref]30, and two feed-forward models, convSeq2Seq [ref]17 and LTD [ref]20, which constitutes the state of the art. The angular results of Res. sup. , convSeq2Seq [ref]17 and MHU on H3.6M are directly taken from the respective paper. For the other results of Res. sup.  and convSeq2Seq [ref]17, we adapt the code provided by the authors for H3.6M to 3D and AMASS. For LTD [ref]20, we rely on the pre-trained models released by the authors for H3.6M, and train their model on AMASS using their official code. While Res. sup. , convSeq2Seq [ref]17 and MHU [ref]30 are all trained to generate 25 future frames, LTD [ref]20 has 3 different models, which we refer to as LTD-50-25 [ref]20, LTD-10-25 [ref]20, and LTD-10-10 [ref]20. The two numbers after the method name indicate the number of observed past frames and that of future frames to predict, respectively, during training. For example, LTD-10-25 [ref]20 means that the model is trained to take the past 10 frames as input to predict the future 25 frames."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "L.: Towards principled methods for training generative adversarial networks. In: ICLR (2017)",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 1,
      "title": "Towards Principled Methods for Training Generative Adversarial Networks",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR",
      "authors": "Arjovsky, M., Bottou, L.",
      "orig_title": "Towards principled methods for training generative adversarial networks",
      "paper_id": "1701.04862v1"
    },
    {
      "index": 2,
      "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "Bahdanau, D., Cho, K., Bengio, Y.",
      "orig_title": "Neural machine translation by jointly learning to align and translate",
      "paper_id": "1409.0473v7"
    },
    {
      "index": 3,
      "title": "Style machines",
      "abstract": "",
      "year": "2000",
      "venue": "27th annual conference on Computer graphics and interactive techniques",
      "authors": "Brand, M., Hertzmann, A."
    },
    {
      "index": 4,
      "title": "Deep representation learning for human motion prediction and classification",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Butepage, J., Black, M.J., Kragic, D., Kjellstrom, H.",
      "orig_title": "Deep representation learning for human motion prediction and classification",
      "paper_id": "1702.07486v2"
    },
    {
      "index": 5,
      "title": "Recurrent Network Models for Human Dynamics",
      "abstract": "",
      "year": "2015",
      "venue": "ICCV",
      "authors": "Fragkiadaki, K., Levine, S., Felsen, P., Malik, J.",
      "orig_title": "Recurrent network models for human dynamics",
      "paper_id": "1508.00271v2"
    },
    {
      "index": 6,
      "title": "Multi-hypothesis motion planning for visual object tracking",
      "abstract": "",
      "year": "2011",
      "venue": "ICCV",
      "authors": "Gong, H., Sim, J., Likhachev, M., Shi, J."
    },
    {
      "index": 7,
      "title": "A neural temporal model for human motion prediction",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Gopalakrishnan, A., Mali, A., Kifer, D., Giles, L., Ororbia, A.G."
    },
    {
      "index": 8,
      "title": "Adversarial geometry-aware human motion prediction",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Gui, L.Y., Wang, Y.X., Liang, X., Moura, J.M."
    },
    {
      "index": 9,
      "title": "Human Motion Prediction via Spatio-Temporal Inpainting",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Hernandez, A., Gall, J., Moreno-Noguer, F.",
      "orig_title": "Human motion prediction via spatio-temporal inpainting",
      "paper_id": "1812.05478v2"
    },
    {
      "index": 10,
      "title": "Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments",
      "abstract": "",
      "year": "2014",
      "venue": "TPAMI",
      "authors": "Ionescu, C., Papava, D., Olaru, V., Sminchisescu, C."
    },
    {
      "index": 11,
      "title": "Structural-rnn: Deep learning on spatio-temporal graphs",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Jain, A., Zamir, A.R., Savarese, S., Saxena, A."
    },
    {
      "index": 12,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2015",
      "venue": "ICLR",
      "authors": "Kingma, D.P., Ba, J."
    },
    {
      "index": 13,
      "title": "Skip-Thought Vectors",
      "abstract": "",
      "year": "2015",
      "venue": "NIPS",
      "authors": "Kiros, R., Zhu, Y., Salakhutdinov, R.R., Zemel, R., Urtasun, R., Torralba, A., Fidler, S.",
      "orig_title": "Skip-thought vectors",
      "paper_id": "1506.06726v1"
    },
    {
      "index": 14,
      "title": "Anticipating human activities for reactive robotic response",
      "abstract": "",
      "year": "2013",
      "venue": "IROS",
      "authors": "Koppula, H.S., Saxena, A."
    },
    {
      "index": 15,
      "title": "Motion graphs",
      "abstract": "",
      "year": "2008",
      "venue": "ACM SIGGRAPH 2008 classes",
      "authors": "Kovar, L., Gleicher, M., Pighin, F."
    },
    {
      "index": 16,
      "title": "Continuous character control with low-dimensional embeddings",
      "abstract": "",
      "year": "2012",
      "venue": "ACM Transactions on Graphics",
      "authors": "Levine, S., Wang, J.M., Haraux, A., Popović, Z., Koltun, V."
    },
    {
      "index": 17,
      "title": "Convolutional Sequence to Sequence Model for Human Dynamics",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Li, C., Zhang, Z., Lee, W.S., Lee, G.H.",
      "orig_title": "Convolutional sequence to sequence model for human dynamics",
      "paper_id": "1805.00655v1"
    },
    {
      "index": 18,
      "title": "SMPL: A skinned multi-person linear model",
      "abstract": "",
      "year": "2015",
      "venue": "ACM Trans. Graphics (SIGGRAPH Asia)",
      "authors": "Loper, M., Mahmood, N., Romero, J., Pons-Moll, G., Black, M.J."
    },
    {
      "index": 19,
      "title": "AMASS: Archive of Motion Capture as Surface Shapes",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Mahmood, N., Ghorbani, N., Troje, N.F., Pons-Moll, G., Black, M.J.",
      "orig_title": "Amass: Archive of motion capture as surface shapes",
      "paper_id": "1904.03278v1"
    },
    {
      "index": 20,
      "title": "Learning Trajectory Dependencies for Human Motion Prediction",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Mao, W., Liu, M., Salzmann, M., Li, H.",
      "orig_title": "Learning trajectory dependencies for human motion prediction",
      "paper_id": "1908.05436v3"
    },
    {
      "index": 21,
      "title": "Recovering accurate 3d human pose in the wild using imus and a moving camera",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "von Marcard, T., Henschel, R., Black, M., Rosenhahn, B., Pons-Moll, G."
    },
    {
      "index": 22,
      "title": "On human motion prediction using recurrent neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Martinez, J., Black, M.J., Romero, J."
    },
    {
      "index": 23,
      "title": "Rectified linear units improve restricted boltzmann machines",
      "abstract": "",
      "year": "2010",
      "venue": "ICML",
      "authors": "Nair, V., Hinton, G.E."
    },
    {
      "index": 24,
      "title": "Automatic differentiation in pytorch",
      "abstract": "",
      "year": "2017",
      "venue": "NIPS-W",
      "authors": "Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., Lerer, A."
    },
    {
      "index": 25,
      "title": "Modeling human motion with quaternion-based neural networks",
      "abstract": "",
      "year": "2019",
      "venue": "IJCV",
      "authors": "Pavllo, D., Feichtenhofer, C., Auli, M., Grangier, D."
    },
    {
      "index": 26,
      "title": "Embodied Hands: Modeling and Capturing Hands and Bodies Together",
      "abstract": "",
      "year": "2017",
      "venue": "ACM Transactions on Graphics (SIGGRAPH Asia)",
      "authors": "Romero, J., Tzionas, D., Black, M.J.",
      "orig_title": "Embodied hands: Modeling and capturing hands and bodies together",
      "paper_id": "2201.02610v1"
    },
    {
      "index": 27,
      "title": "Real-World Repetition Estimation by Div, Grad and Curl",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Runia, T.F., Snoek, C.G., Smeulders, A.W.",
      "orig_title": "Real-world repetition estimation by div, grad and curl",
      "paper_id": "1802.09971v1"
    },
    {
      "index": 28,
      "title": "Implicit probabilistic models of human motion for synthesis and tracking",
      "abstract": "",
      "year": "2002",
      "venue": "ECCV",
      "authors": "Sidenbladh, H., Black, M.J., Sigal, L."
    },
    {
      "index": 29,
      "title": "Generating text with recurrent neural networks",
      "abstract": "",
      "year": "2011",
      "venue": "ICML",
      "authors": "Sutskever, I., Martens, J., Hinton, G.E."
    },
    {
      "index": 30,
      "title": "Long-Term Human Motion Prediction by Modeling Motion Context and Enhancing Motion Dynamic",
      "abstract": "",
      "year": "2018",
      "venue": "IJCAI",
      "authors": "Tang, Y., Ma, L., Liu, W., Zheng, W.S.",
      "orig_title": "Long-term human motion prediction by modeling motion context and enhancing motion dynamics",
      "paper_id": "1805.02513v1"
    },
    {
      "index": 31,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "NIPS",
      "authors": "Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł., Polosukhin, I.",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    }
  ]
}