{
  "paper_id": "2306.14685v4",
  "title": "DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models",
  "sections": {
    "related work": "Sketch Synthesis. Free-hand drawings convey abstract concepts through human visual perception with minimal abstraction. Unlike purely edge-map extraction methods , free-hand sketching aims to present sketches that are abstract in terms of structure  and semantic interpretation5. Therefore, computational sketching methods that aim to mimic human drawing consider a wide range of sketch representations, ranging from those grounded in the edge map of the input image      to those that are more abstract    [ref]7 6 5, which are normally in vector format. Among the works synthesizing vector sketches, CLIPasso 5 and CLIPascene 4 are conditioned on an input image, while the rest are unconditional. Until now, no prior work has explored synthesizing a sketch based on text. Vector Graphics. Our work builds upon the differentiable renderer for vector graphics introduced by Li et al 6. While image generation methods that operate over vector images traditionally require a vector-based dataset, recent work has shown how the differentiable renderer can be used to bypass this limitation 6 4 1 9 9. Furthermore, recent advances in visual text embedding contrastive language-image pre-training (CLIP)7 have enabled a number of successful methods for synthesizing sketches, such as CLIPDraw [ref]7, StyleCLIPDraw 2, CLIP-CLOP 1, and CliPascene 4. A very recent work VectorFusion 3 combine differentiable renderer with diffusion model for vector graphics generation, e.g., iconography and pixel art. Our proposed algorithm, DiffSketcher, shares a similar idea with VectorFusion, but our focus is generating object- and scene-level sketches from a natural language prompt. Diffusion Models. Denoising diffusion probabilistic models (DDPMs) 7 9 1 0, particularly those conditioned on text, have shown promising results in text-to-image synthesis. For example, Classifier-Free Guidance (CFG) 2 has improved sample quality and has been widely used in large-scale diffusion model frameworks, including GLIDE 3, Stable Diffusion 0, DALL·E 2 8, and Imagen 1. However, the majority of images available in web-scale datasets are rasterized, and this work follows the framework of synthesis through optimization, in which images are generated through evaluation-time optimization against a given metric. Our proposed algorithm, DiffSketcher, uses a pre-trained text-to-image diffusion model to synthesize free-hand sketches from natural language input. This is achieved by transferring image synthesis prior information into a differentiable renderer.xc"
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "DoodleFormer: Creative Sketch Drawing with Transformers",
      "abstract": "",
      "year": "2022",
      "venue": "European conference on computer vision (ECCV)",
      "authors": "Ankan Kumar Bhunia, Salman Khan, Hisham Cholakkal, Rao Muhammad Anwer, Fahad Shahbaz Khan, Jorma Laaksonen, and Michael Felsberg",
      "orig_title": "Doodleformer: Creative sketch drawing with transformers",
      "paper_id": "2112.03258v3"
    },
    {
      "index": 1,
      "title": "A computational approach to edge detection",
      "abstract": "",
      "year": "1986",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "John Canny"
    },
    {
      "index": 2,
      "title": "Learning to generate line drawings that convey geometry and semantics",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Caroline Chan, Frédo Durand, and Phillip Isola",
      "orig_title": "Learning to generate line drawings that convey geometry and semantics",
      "paper_id": "2203.12691v3"
    },
    {
      "index": 3,
      "title": "DeepFaceDrawing: Deep Generation of Face Images from Sketches",
      "abstract": "",
      "year": "2020",
      "venue": "ACM Transactions on Graphics (TOG)",
      "authors": "Shu-Yu Chen, Wanchao Su, Lin Gao, Shihong Xia, and Hongbo Fu",
      "orig_title": "Deepfacedrawing: Deep generation of face images from sketches",
      "paper_id": "2006.01047v2"
    },
    {
      "index": 4,
      "title": "Diffusion Models Beat GANs on Image Synthesis",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems (NIPS)",
      "authors": "Prafulla Dhariwal and Alexander Nichol",
      "orig_title": "Diffusion models beat gans on image synthesis",
      "paper_id": "2105.05233v4"
    },
    {
      "index": 5,
      "title": "Taming Transformers for High-Resolution Image Synthesis",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF conference on computer vision and pattern recognition (NIPS)",
      "authors": "Patrick Esser, Robin Rombach, and Bjorn Ommer",
      "orig_title": "Taming transformers for high-resolution image synthesis",
      "paper_id": "2012.09841v3"
    },
    {
      "index": 6,
      "title": "CLIPDraw: Exploring Text-to-Drawing Synthesis through Language-Image Encoders",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems (NIPS)",
      "authors": "Kevin Frans, Lisa Soros, and Olaf Witkowski",
      "orig_title": "CLIPDraw: Exploring text-to-drawing synthesis through language-image encoders",
      "paper_id": "2106.14843v1"
    },
    {
      "index": 7,
      "title": "Creative Sketch Generation",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Learning Representations (ICLR)",
      "authors": "Songwei Ge, Vedanuj Goswami, Larry Zitnick, and Devi Parikh",
      "orig_title": "Creative sketch generation",
      "paper_id": "2011.10039v2"
    },
    {
      "index": 8,
      "title": "A neural representation of sketch drawings",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Learning Representations (ICLR)",
      "authors": "David Ha and Douglas Eck"
    },
    {
      "index": 9,
      "title": "Prompt-to-Prompt Image Editing with Cross Attention Control",
      "abstract": "",
      "year": "2023",
      "venue": "The Eleventh International Conference on Learning Representations (ICLR)",
      "authors": "Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-or",
      "orig_title": "Prompt-to-prompt image editing with cross-attention control",
      "paper_id": "2208.01626v1"
    },
    {
      "index": 10,
      "title": "Denoising Diffusion Probabilistic Models",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems (NIPS)",
      "authors": "Jonathan Ho, Ajay Jain, and Pieter Abbeel",
      "orig_title": "Denoising diffusion probabilistic models",
      "paper_id": "2006.11239v2"
    },
    {
      "index": 11,
      "title": "Classifier-Free Diffusion Guidance",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Jonathan Ho and Tim Salimans",
      "orig_title": "Classifier-free diffusion guidance",
      "paper_id": "2207.12598v1"
    },
    {
      "index": 12,
      "title": "VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Ajay Jain, Amber Xie, and Pieter Abbeel",
      "orig_title": "Vectorfusion: Text-to-svg by abstracting pixel-based diffusion models",
      "paper_id": "2211.11319v1"
    },
    {
      "index": 13,
      "title": "Rethinking Style Transfer: From Pixels to Parameterized Brushstrokes",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Dmytro Kotovenko, Matthias Wright, Arthur Heimbrecht, and Bjorn Ommer",
      "orig_title": "Rethinking style transfer: From pixels to parameterized brushstrokes",
      "paper_id": "2103.17185v1"
    },
    {
      "index": 14,
      "title": "Photo-Sketching: Inferring Contour Drawings from Images",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Winter Conference on Applications of Computer Vision (WACV)",
      "authors": "Mengtian Li, Zhe Lin, Radomir Mech, Ersin Yumer, and Deva Ramanan",
      "orig_title": "Photo-sketching: Inferring contour drawings from images",
      "paper_id": "1901.00542v1"
    },
    {
      "index": 15,
      "title": "Differentiable vector graphics rasterization for editing and learning",
      "abstract": "",
      "year": "2020",
      "venue": "ACM Trans. Graph. (Proc. SIGGRAPH Asia)",
      "authors": "Tzu-Mao Li, Michal Lukáč, Gharbi Michaël, and Jonathan Ragan-Kelley"
    },
    {
      "index": 16,
      "title": "Free-hand sketch synthesis with deformable stroke models",
      "abstract": "",
      "year": "2017",
      "venue": "International Journal of Computer Vision",
      "authors": "Yi Li, Yi-Zhe Song, Timothy M Hospedales, and Shaogang Gong"
    },
    {
      "index": 17,
      "title": "Unsupervised Sketch-to-Photo Synthesis",
      "abstract": "",
      "year": "2020",
      "venue": "Computer Vision–ECCV 2020",
      "authors": "Runtao Liu, Qian Yu, and Stella X Yu",
      "orig_title": "Unsupervised sketch to photo synthesis",
      "paper_id": "1909.08313v3"
    },
    {
      "index": 18,
      "title": "Towards Layer-wise Image Vectorization",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Xu Ma, Yuqian Zhou, Xingqian Xu, Bin Sun, Valerii Filev, Nikita Orlov, Yun Fu, and Humphrey Shi",
      "orig_title": "Towards layer-wise image vectorization",
      "paper_id": "2206.04655v1"
    },
    {
      "index": 19,
      "title": "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis",
      "abstract": "",
      "year": "2021",
      "venue": "Communications of the ACM",
      "authors": "Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng",
      "orig_title": "Nerf: Representing scenes as neural radiance fields for view synthesis",
      "paper_id": "2003.08934v2"
    },
    {
      "index": 20,
      "title": "Clip-clop: Clip-guided collage and photomontage",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Piotr Mirowski, Dylan Banarse, Mateusz Malinowski, Simon Osindero, and Chrisantha Fernando"
    },
    {
      "index": 21,
      "title": "Differentiable image parameterizations",
      "abstract": "",
      "year": "2018",
      "venue": "Distill",
      "authors": "Alexander Mordvintsev, Nicola Pezzotti, Ludwig Schubert, and Chris Olah"
    },
    {
      "index": 22,
      "title": "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning (ICML)",
      "authors": "Alexander Quinn Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob Mcgrew, Ilya Sutskever, and Mark Chen",
      "orig_title": "GLIDE: Towards photorealistic image generation and editing with text-guided diffusion models",
      "paper_id": "2112.10741v3"
    },
    {
      "index": 23,
      "title": "DreamFusion: Text-to-3D using 2D Diffusion",
      "abstract": "",
      "year": "2023",
      "venue": "The Eleventh International Conference on Learning Representations (ICLR)",
      "authors": "Ben Poole, Ajay Jain, Jonathan T. Barron, and Ben Mildenhall",
      "orig_title": "Dreamfusion: Text-to-3d using 2d diffusion",
      "paper_id": "2209.14988v1"
    },
    {
      "index": 24,
      "title": "Compositing digital images",
      "abstract": "",
      "year": "1984",
      "venue": "Conference on Computer Graphics and Interactive Techniques, SIGGRAPH ’84",
      "authors": "Thomas Porter and Tom Duff"
    },
    {
      "index": 25,
      "title": "Sketchlattice: Latticed representation for sketch manipulation",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF International Conference on Computer Vision (ICCV)",
      "authors": "Yonggang Qi, Guoyao Su, Pinaki Nath Chowdhury, Mingkang Li, and Yi-Zhe Song"
    },
    {
      "index": 26,
      "title": "Learning Transferable Visual Models From Natural Language Supervision",
      "abstract": "",
      "year": "2021",
      "venue": "International conference on machine learning",
      "authors": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.",
      "orig_title": "Learning transferable visual models from natural language supervision",
      "paper_id": "2103.00020v1"
    },
    {
      "index": 27,
      "title": "Hierarchical Text-Conditional Image Generation with CLIP Latents",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen",
      "orig_title": "Hierarchical text-conditional image generation with clip latents",
      "paper_id": "2204.06125v1"
    },
    {
      "index": 28,
      "title": "Im2Vec: Synthesizing Vector Graphics without Vector Supervision",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Pradyumna Reddy, Michael Gharbi, Michal Lukac, and Niloy J Mitra",
      "orig_title": "Im2vec: Synthesizing vector graphics without vector supervision",
      "paper_id": "2102.02798v3"
    },
    {
      "index": 29,
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer",
      "orig_title": "High-resolution image synthesis with latent diffusion models",
      "paper_id": "2112.10752v2"
    },
    {
      "index": 30,
      "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems (NIPS)",
      "authors": "Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.",
      "orig_title": "Photorealistic text-to-image diffusion models with deep language understanding",
      "paper_id": "2205.11487v1"
    },
    {
      "index": 31,
      "title": "Styleclipdraw: Coupling content and style in text-to-drawing synthesis",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint",
      "authors": "Peter Schaldenbrand, Zhixuan Liu, and Jean Oh"
    },
    {
      "index": 32,
      "title": "Improved aesthetic predictor",
      "abstract": "",
      "year": "2022",
      "venue": "GitHub",
      "authors": "Christoph Schuhmann"
    },
    {
      "index": 33,
      "title": "LAION-5B: An open large-scale dataset for training next generation image-text models",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al.",
      "orig_title": "Laion-5b: An open large-scale dataset for training next generation image-text models",
      "paper_id": "2210.08402v1"
    },
    {
      "index": 34,
      "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE international conference on computer vision (ICCV)",
      "authors": "Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra",
      "orig_title": "Grad-cam: Visual explanations from deep networks via gradient-based localization",
      "paper_id": "1610.02391v4"
    },
    {
      "index": 35,
      "title": "ClipGen: A Deep Generative Model for Clipart Vectorization and Synthesis",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Visualization and Computer Graphics",
      "authors": "I-Chao Shen and Bing-Yu Chen",
      "orig_title": "Clipgen: A deep generative model for clipart vectorization and synthesis",
      "paper_id": "2106.04912v1"
    },
    {
      "index": 36,
      "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Machine Learning (ICML)",
      "authors": "Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli",
      "orig_title": "Deep unsupervised learning using nonequilibrium thermodynamics",
      "paper_id": "1503.03585v8"
    },
    {
      "index": 37,
      "title": "Denoising diffusion implicit models",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Learning Representations (ICLR)",
      "authors": "Jiaming Song, Chenlin Meng, and Stefano Ermon"
    },
    {
      "index": 38,
      "title": "Generative Modeling by Estimating Gradients of the Data Distribution",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems (NIPS)",
      "authors": "Yang Song and Stefano Ermon",
      "orig_title": "Generative modeling by estimating gradients of the data distribution",
      "paper_id": "1907.05600v3"
    },
    {
      "index": 39,
      "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Learning Representations (ICLR)",
      "authors": "Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole",
      "orig_title": "Score-based generative modeling through stochastic differential equations",
      "paper_id": "2011.13456v2"
    },
    {
      "index": 40,
      "title": "Modern Evolution Strategies for Creativity: Fitting Concrete Images and Abstract Concepts",
      "abstract": "",
      "year": "2022",
      "venue": "Artificial Intelligence in Music, Sound, Art and Design",
      "authors": "Yingtao Tian and David Ha",
      "orig_title": "Modern evolution strategies for creativity: Fitting concrete images and abstract concepts",
      "paper_id": "2109.08857v2"
    },
    {
      "index": 41,
      "title": "Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale",
      "abstract": "",
      "year": "2021",
      "venue": "Conference on Artificial Intelligence (AAAI)",
      "authors": "Zhengyan Tong, Xuanhong Chen, Bingbing Ni, and Xiaohang Wang",
      "orig_title": "Sketch generation with drawing process guided by vector flow and grayscale",
      "paper_id": "2012.09004v1"
    },
    {
      "index": 42,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems (NIPS)",
      "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 43,
      "title": "CLIPascene: Scene Sketching with Different Types and Levels of Abstraction",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Yael Vinker, Yuval Alaluf, Daniel Cohen-Or, and Ariel Shamir",
      "orig_title": "Clipascene: Scene sketching with different types and levels of abstraction",
      "paper_id": "2211.17256v2"
    },
    {
      "index": 44,
      "title": "CLIPasso: Semantically-Aware Object Sketching",
      "abstract": "",
      "year": "2022",
      "venue": "ACM Transactions on Graphics (TOG)",
      "authors": "Yael Vinker, Ehsan Pajouheshgar, Jessica Y Bo, Roman Christian Bachmann, Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, and Ariel Shamir",
      "orig_title": "Clipasso: Semantically-aware object sketching",
      "paper_id": "2202.05822v2"
    },
    {
      "index": 45,
      "title": "Holistically-Nested Edge Detection",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE International Conference on Computer Vision (ICCV)",
      "authors": "Saining Xie and Zhuowen Tu",
      "orig_title": "Holistically-nested edge detection",
      "paper_id": "1504.06375v2"
    },
    {
      "index": 46,
      "title": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang",
      "orig_title": "The unreasonable effectiveness of deep features as a perceptual metric",
      "paper_id": "1801.03924v2"
    }
  ]
}