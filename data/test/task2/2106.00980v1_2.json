{
  "paper_id": "2106.00980v1",
  "title": "End-to-End Hierarchical Relation Extraction for Generic Form Understanding",
  "sections": {
    "i introduction": "Administrative documents are one of the most widely used medium for data storage and communication, which raises the need for an automated solution for form understanding. However, this task remains largely difficult due to the layout variations between forms for different purposes, organizations, etc. Owning to its complexity, classical works like heuristic-based , , or recent deep learning-based methods [ref]3,  often break the problem into several sub-components: text-line detection, entity recognition, relation extraction, etc.\nThe rationale of the division is that we may have better control of the input-output correspondence while cascading information for later steps.\nFollowing [ref]5, the problem of Form Understanding can be formulated as 3 main tasks: Word Grouping, Entity Labeling - detection of questions (keys) and answers (values), and Entity Linking - their linking.\nWithin this scope of this paper, we take another look at this prevalent problem by proposing an end-to-end model to solve both Entity Labeling and Entity Linking task at the same time. Aside from the aforementioned heuristic-based methods for document information extraction (i.e using hand-crafted rules to build up and extract tables and identifying key-value pairs), deep-learning-based methods are also received much attention during the recent years   .\nAlthough deep-learning-based methods have achieved state-of-the-art accuracy recently in both entity segmentation in documents [ref]9, link prediction on large social network graph 0, and matching between human pose joint 1, there have been few works on end-to-end models performing both entity extraction and link prediction of a document at the same time. Our hypothesis is that while being advantageous for intermediate supervision, the division of architecture to different stages are not necessary for optimal speed and performance. As they heavily depend on each other as a flow, if the previous steps like entity recognition do not perform well, it would severely affect the performance of the later entity linking stage by error accumulations. In this paper, we present the extension of Semantic Entity Labeling with relational linking by adapting the Part-Association-Field mechanism for mutual relations extraction among entities.\nOur work is based on the previously proposed Multi-Stage Attentional U-Net (MSAU) architecture [ref]9 for its proven effectiveness in entity segmentation from the char-grid embedding 2. We go beyond its limitation of having no direct supervision from the linking between entities by adding Part-Intensity Fields and Part-Association Fields (PIF-PAF) 3 which results in an additional two-head branch for entity linking and prediction from document images.\nIn addition to original segmentation output, the Part-Intensity Field head produces of confidence score of each entity’s key points, while the Part-Association Fields head allows the associations between entities.\nApart from the major addition of PIF-PAF module, our work also improved upon MSAU by adding Corner Pooling 4 to solve the issue of long-range distance between entities, enabling the wider-range propagation of information both horizontally and vertically.\nThe Coordinate Convolution (CoordConv) 5 is also included to incorporate translational signals to the model.\nThe effectiveness of these modules will be shown in Section IV. We demonstrate the capability of our proposed model on the Form Understanding in Noisy Scanned Documents dataset (FUNDS) [ref]5, focusing on the Entity Labeling and Entity Linking task. While the line of work for Entity Labeling is actively developed in  [ref]9 [ref]3 6, for the combined Entity Labeling and Entity Linking task, the methods reported in [ref]5, 7, 8 only achieved limited performance due to the bottleneck in exploiting both semantic and spatial features and the highly imbalanced links between entities. Under those challenging conditions, experiments demonstrate that our approach outperforms various strong baselines (including Multi-layered Perceptron (MLP) with BERT, recently proposed MSAU [ref]9, LayoutLM 7, and Graph-based methods 9), achieving state-of-the-art performance. In short, we summarize our contribution list: We proposed an end-to-end architecture combining semantic entity extraction and link prediction for form understanding, which incorporates the Part-Association Field and Part-Intensity Field to the baseline MSAU model. We improved upon the original architecture of MSAU by adding Corner Pooling and Coordinate Convolution to aid spatial context modeling, which has been reaffirmed by our empirical experiments. Ablation studies show that utilizing the relations supervision can improve segmentation results for entity extractions in comparison with other baselines. The rest of the paper is organized as follows: Section II describes the related works, followed by that is the proposed method in Section III, the experiments in Section IV."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "PDF-TREX: An approach for recognizing and extracting tables from PDF documents",
      "abstract": "",
      "year": "2009",
      "venue": "ICDR",
      "authors": "Ermelinda Oro and Massimo Ruffolo"
    },
    {
      "index": 1,
      "title": "Information Extraction tasks : a survey",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": "Luisa Simoes, Goncalo; Galhardas, Helena; Coheur"
    },
    {
      "index": 2,
      "title": "Attend, Copy, Parse End-to-end information extraction from documents",
      "abstract": "",
      "year": "2019",
      "venue": "CBDAR",
      "authors": "Rasmus Berg Palm, Florian Laws, and Ole Winther",
      "orig_title": "Attend, Copy, Parse - End-to-end information extraction from documents",
      "paper_id": "1812.07248v3"
    },
    {
      "index": 3,
      "title": "Graph Convolution for Multimodal Information Extraction from Visually Rich Documents",
      "abstract": "",
      "year": "2019",
      "venue": "NAACL",
      "authors": "Xiaojing Liu, Feiyu Gao, Qiong Zhang, and Huasha Zhao",
      "orig_title": "Graph Convolution for Multimodal Information Extraction from Visually Rich Documents",
      "paper_id": "1903.11279v1"
    },
    {
      "index": 4,
      "title": "FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents",
      "abstract": "",
      "year": "2019",
      "venue": "ICDR",
      "authors": "Guillaume Jaume, Hazim Kemal Ekenel, and Jean-Philippe Thiran"
    },
    {
      "index": 5,
      "title": "Image Generation from Scene Graphs",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Justin Johnson, Agrim Gupta, and Li Fei-Fei",
      "orig_title": "Image Generation from Scene Graphs",
      "paper_id": "1804.01622v1"
    },
    {
      "index": 6,
      "title": "Pixels to Graphs by Associative Embedding",
      "abstract": "",
      "year": "2017",
      "venue": "NIPS",
      "authors": "Alejandro Newell and Jia Deng",
      "orig_title": "Pixels to Graphs by Associative Embedding",
      "paper_id": "1706.07365v2"
    },
    {
      "index": 7,
      "title": "Graph R-CNN for Scene Graph Generation",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Jianwei Yang, Jiasen Lu, Stefan Lee, Dhruv Batra, and Devi Parikh",
      "orig_title": "Graph R-CNN for Scene Graph Generation",
      "paper_id": "1808.00191v1"
    },
    {
      "index": 8,
      "title": "End-to-End Information Extraction by Character-Level Embedding and Multi-Stage",
      "abstract": "",
      "year": "2019",
      "venue": "BMVC",
      "authors": "Nguyen Dang Tuan Anh and Nguyen Thanh Dat"
    },
    {
      "index": 9,
      "title": "Link Prediction Based on Graph Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "NIPS",
      "authors": "Muhan Zhang and Yixin Chen",
      "orig_title": "Link Prediction Based on Graph Neural Networks",
      "paper_id": "1802.09691v3"
    },
    {
      "index": 10,
      "title": "Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh"
    },
    {
      "index": 11,
      "title": "Chargrid: Towards Understanding 2D Documents",
      "abstract": "",
      "year": "2018",
      "venue": "EMNLP",
      "authors": "Anoop Raveendra Katti, Christian Reisswig, Cordula Guder, Sebastian Brarda, Steffen Bickel, Johannes Höhne, and Jean Baptiste Faddoul",
      "orig_title": "Chargrid: Towards Understanding 2D Documents",
      "paper_id": "1809.08799v1"
    },
    {
      "index": 12,
      "title": "PifPaf: Composite Fields for Human Pose Estimation",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Sven Kreiss, Lorenzo Bertoni, and Alexandre Alahi",
      "orig_title": "PifPaf: Composite Fields for Human Pose Estimation",
      "paper_id": "1903.06593v2"
    },
    {
      "index": 13,
      "title": "CornerNet: Detecting Objects as Paired Keypoints",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Hei Law and Jia Deng",
      "orig_title": "CornerNet: Detecting Objects as Paired Keypoints",
      "paper_id": "1808.01244v2"
    },
    {
      "index": 14,
      "title": "An intriguing failing of convolutional neural networks and the CoordConv solution",
      "abstract": "",
      "year": "2018",
      "venue": "NIPS",
      "authors": "Rosanne Liu, Joel Lehman, Piero Molino, Felipe Petroski Such, Eric Frank, Alex Sergeev, and Jason Yosinski",
      "orig_title": "An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution",
      "paper_id": "1807.03247v2"
    },
    {
      "index": 15,
      "title": "CloudScan - A Configuration-Free Invoice Analysis System Using Recurrent Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Rasmus Berg Palm, Ole Winther, and Florian Laws"
    },
    {
      "index": 16,
      "title": "LayoutLM: Pre-training of Text and Layout for Document Image Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, and Ming Zhou"
    },
    {
      "index": 17,
      "title": "Towards a Multi-modal, Multi-task Learning based Pre-training Framework for Document Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Subhojeet Pramanik, Shashank Mujumdar, and Hima Patel",
      "orig_title": "Towards a Multi-modal, Multi-task Learning based Pre-training Framework for Document Representation Learning",
      "paper_id": "2009.14457v2"
    },
    {
      "index": 18,
      "title": "Robust Spatial Filtering with Graph Convolutional Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE JSTSP",
      "authors": "Felipe Petroski Such, Shagan Sah, Miguel Alexander Dominguez, Suhas Pillai, Chao Zhang, Andrew Michael, Nathan D. Cahill, and Raymond Ptucha",
      "orig_title": "Robust Spatial Filtering with Graph Convolutional Neural Networks",
      "paper_id": "1703.00792v3"
    },
    {
      "index": 19,
      "title": "High Performance Layout Analysis of Arabic and Urdu Document Images",
      "abstract": "",
      "year": "2011",
      "venue": "ICDR",
      "authors": "Syed Saqib Bukhari, Faisal Shafait, and Thomas M Breuel"
    },
    {
      "index": 20,
      "title": "Textline detection in degraded historical document images",
      "abstract": "",
      "year": "2017",
      "venue": "Eurasip Journal on Image and Video Processing",
      "authors": "Byeongyong Ahn, Jewoong Ryu, Hyung Il Koo, and Nam Ik Cho"
    },
    {
      "index": 21,
      "title": "A graph-theoretic approach to webpage segmentation",
      "abstract": "",
      "year": "2008",
      "venue": "WWW",
      "authors": "Deepayan Chakrabarti, Ravi Kumar, and Kunal Punera"
    },
    {
      "index": 22,
      "title": "Fully Convolutional Networks for Semantic Segmentation",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Jonathan Long, Evan Shelhamer, and Trevor Darrell",
      "orig_title": "Fully convolutional networks for semantic segmentation",
      "paper_id": "1605.06211v1"
    },
    {
      "index": 23,
      "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
      "abstract": "",
      "year": "2015",
      "venue": "MICCAI",
      "authors": "Olaf Ronneberger, Philipp Fischer, and Thomas Brox",
      "orig_title": "U-net: Convolutional networks for biomedical image segmentation",
      "paper_id": "1505.04597v1"
    },
    {
      "index": 24,
      "title": "dhSegment: A generic deep-learning approach for document segmentation",
      "abstract": "",
      "year": "2018",
      "venue": "ICFHR",
      "authors": "Sofia Ares Oliveira, Benoit Seguin, and Frederic Kaplan",
      "orig_title": "dhSegment: A generic deep-learning approach for document segmentation",
      "paper_id": "1804.10371v2"
    },
    {
      "index": 25,
      "title": "An Invoice Reading System Using a Graph Convolutional Network",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "D. Lohani, A. Belaïd, and Y. Belaïd"
    },
    {
      "index": 26,
      "title": "Towards Accurate Multi-person Pose Estimation in the Wild",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "George Papandreou, Tyler Zhu, Nori Kanazawa, Alexander Toshev, Jonathan Tompson, Chris Bregler, and Kevin Murphy",
      "orig_title": "Towards Accurate Multi-person Pose Estimation in the Wild",
      "paper_id": "1701.01779v2"
    },
    {
      "index": 27,
      "title": "Simple Baselines for Human Pose Estimation and Tracking",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Bin Xiao, Haiping Wu, and Yichen Wei",
      "orig_title": "Simple Baselines for Human Pose Estimation and Tracking",
      "paper_id": "1804.06208v2"
    },
    {
      "index": 28,
      "title": "Non-local Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He",
      "orig_title": "Non-local Neural Networks",
      "paper_id": "1711.07971v3"
    },
    {
      "index": 29,
      "title": "CU-Net: Coupled U-Nets",
      "abstract": "",
      "year": "2019",
      "venue": "BMVC",
      "authors": "Zhiqiang Tang, Xi Peng, Shijie Geng, Yizhe Zhu, and Dimitris N. Metaxas",
      "orig_title": "Cu-Net: Coupled U-nets",
      "paper_id": "1808.06521v1"
    },
    {
      "index": 30,
      "title": "Non-local Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He",
      "orig_title": "Non-local Neural Networks",
      "paper_id": "1711.07971v3"
    },
    {
      "index": 31,
      "title": "Deep Neural Networks using Box Convolutions",
      "abstract": "",
      "year": "2018",
      "venue": "NIPS",
      "authors": "Egor Burkov"
    },
    {
      "index": 32,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2018",
      "venue": "NAACL-HLT",
      "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova",
      "orig_title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "paper_id": "1810.04805v2"
    }
  ]
}