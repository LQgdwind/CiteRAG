{
  "paper_id": "2103.01400v4",
  "title": "Smoothness Analysis of Adversarial Training",
  "sections": {
    "experimental setup for evaluation of entropysgd": "This section gives an outline of the experimental conditions for evaluating EnSGD and\nthe details are provided in the supplementary materials.\nOur experimental codes are based on source codes provided by Wu et al. [ref]32,\nand our implementations of EnSGD are based on the codes provided by Chaudhari et al. [ref]3.\nDatasets of the experiments were CIFAR10, CIFAR100 [ref]19, and SVHN .\nWe compared the convergences of adversarial training when using SGD and EnSGD.\nIn addition, we evaluated the combination of EnSGD and AWP [ref]32,\nwhich injects adversarial noise into the parameter to flatten the loss landscape.\nWe used ResNet-18 (RN18)  and WideResNet-34-10 (WRN)  following [ref]32.\nWe used PGD,\nand the hyperparameters for PGD were based on [ref]32.\nThe L∞subscript𝐿L_{\\infty} norm of the perturbation ε=8/255𝜀8255\\varepsilon\\!=\\!8/255 at training time.\nFor EnSGD, we set γ=0.03𝛾0.03\\gamma=0.03, εE=1×10−4subscript𝜀𝐸1superscript104\\varepsilon_{E}=1\\times 10^{-4}, and η=0.1𝜂0.1\\eta=0.1, η′=0.1superscript𝜂′0.1\\eta^{\\prime}=0.1 and\ntuned an iteration L𝐿L in {20,30}2030\\{20,30\\}.\nThe learning rates of SGD and EnSGD are set to 0.1 and divided by 10 at the 100-th and 150-th epoch,\nand we used early stopping by evaluating test robust accuracies against PGD (20-iteration).\nThe hyperparameter of AWP is tuned in {0.01,0.005}0.010.005\\{0.01,0.005\\}.\nFor WRN, we used the same hyperparameters as those of RN18.\nWe trained models three times and\nshow the average and standard deviation of test accuracies.\nNote that we evaluated EnSGD for adversarial training since our analysis focuses on adversarial training\nand also confirmed the effectiveness of EnSGD in TRADES , which is also used for adversarial robustness.\nThe evaluation is provided in the supplementary materials."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Nonlinear programming",
      "abstract": "",
      "year": "1999",
      "venue": "Athena Scientific",
      "authors": "Dimitri P Bertsekas"
    },
    {
      "index": 1,
      "title": "Unlabeled Data Improves Adversarial Robustness",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang",
      "orig_title": "Unlabeled data improves adversarial robustness",
      "paper_id": "1905.13736v4"
    },
    {
      "index": 2,
      "title": "Entropy-sgd: Biasing gradient descent into wide valleys",
      "abstract": "",
      "year": "2019",
      "venue": "Journal of Statistical Mechanics: Theory and Experiment",
      "authors": "Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi, Christian Borgs, Jennifer Chayes, Levent Sagun, and Riccardo Zecchina"
    },
    {
      "index": 3,
      "title": "Parseval Networks: Improving Robustness to Adversarial Examples",
      "abstract": "",
      "year": "2017",
      "venue": "ICML",
      "authors": "Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas Usunier",
      "orig_title": "Parseval networks: Improving robustness to adversarial examples",
      "paper_id": "1704.08847v2"
    },
    {
      "index": 4,
      "title": "Certified Adversarial Robustness via Randomized Smoothing",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Jeremy Cohen, Elan Rosenfeld, and Zico Kolter",
      "orig_title": "Certified adversarial robustness via randomized smoothing",
      "paper_id": "1902.02918v2"
    },
    {
      "index": 5,
      "title": "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Francesco Croce and Matthias Hein"
    },
    {
      "index": 6,
      "title": "Sharp Minima Can Generalize For Deep Nets",
      "abstract": "",
      "year": "2017",
      "venue": "ICML",
      "authors": "Laurent Dinh, Razvan Pascanu, Samy Bengio, and Yoshua Bengio",
      "orig_title": "Sharp minima can generalize for deep nets",
      "paper_id": "1703.04933v2"
    },
    {
      "index": 7,
      "title": "Evaluating and Understanding the Robustness of Adversarial Logit Pairing",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1807.10272",
      "authors": "Logan Engstrom, Andrew Ilyas, and Anish Athalye",
      "orig_title": "Evaluating and understanding the robustness of adversarial logit pairing",
      "paper_id": "1807.10272v2"
    },
    {
      "index": 8,
      "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization",
      "abstract": "",
      "year": "2021",
      "venue": "ICLR",
      "authors": "Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur",
      "orig_title": "Sharpness-aware minimization for efficiently improving generalization",
      "paper_id": "2010.01412v3"
    },
    {
      "index": 9,
      "title": "Explaining and Harnessing Adversarial Examples",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1412.6572",
      "authors": "Ian Goodfellow, Jonathon Shlens, and Christian Szegedy",
      "orig_title": "Explaining and harnessing adversarial examples",
      "paper_id": "1412.6572v3"
    },
    {
      "index": 10,
      "title": "Train faster, generalize better: Stability of stochastic gradient descent",
      "abstract": "",
      "year": "2016",
      "venue": "ICML",
      "authors": "Moritz Hardt, Ben Recht, and Yoram Singer",
      "orig_title": "Train faster, generalize better: Stability of stochastic gradient descent",
      "paper_id": "1509.01240v2"
    },
    {
      "index": 11,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 12,
      "title": "Three Factors Influencing Minima in SGD",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1711.04623",
      "authors": "Stanislaw Jastrzebski, Zachary Kenton, Devansh Arpit, Nicolas Ballas, Asja Fischer, Yoshua Bengio, and Amos Storkey",
      "orig_title": "Three factors influencing minima in sgd",
      "paper_id": "1711.04623v3"
    },
    {
      "index": 13,
      "title": "SciPy: Open source scientific tools for Python, 2001–",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Eric Jones, Travis Oliphant, Pearu Peterson, et al."
    },
    {
      "index": 14,
      "title": "Relationship between nonsmoothness in adversarial training, constraints of attacks, and flatness in the input space",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Sekitoshi Kanai, Masanori Yamada, Hiroshi Takahashi, Yuki Yamanaka, and Yasutoshi Ida"
    },
    {
      "index": 15,
      "title": "Improving Generalization Performance by Switching from Adam to SGD",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1712.07628",
      "authors": "Nitish Shirish Keskar and Richard Socher",
      "orig_title": "Improving generalization performance by switching from adam to sgd",
      "paper_id": "1712.07628v1"
    },
    {
      "index": 16,
      "title": "On large-batch training for deep learning: Generalization gap and sharp minima",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR",
      "authors": "Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang"
    },
    {
      "index": 17,
      "title": "Understanding Catastrophic Overfitting in Single-step Adversarial Training",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI",
      "authors": "Hoki Kim, Woojin Lee, and Jaewook Lee",
      "orig_title": "Understanding catastrophic overfitting in single-step adversarial training",
      "paper_id": "2010.01799v2"
    },
    {
      "index": 18,
      "title": "Learning multiple layers of features from tiny images",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "Alex Krizhevsky and Geoffrey Hinton"
    },
    {
      "index": 19,
      "title": "Adversarial Machine Learning at Scale",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1611.01236",
      "authors": "Alexey Kurakin, Ian Goodfellow, and Samy Bengio",
      "orig_title": "Adversarial machine learning at scale",
      "paper_id": "1611.01236v2"
    },
    {
      "index": 20,
      "title": "Visualizing the Loss Landscape of Neural Nets",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein",
      "orig_title": "Visualizing the loss landscape of neural nets",
      "paper_id": "1712.09913v3"
    },
    {
      "index": 21,
      "title": "On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Chen Liu, Mathieu Salzmann, Tao Lin, Ryota Tomioka, and Sabine Süsstrunk",
      "orig_title": "On the loss landscape of adversarial training: Identifying challenges and how to overcome them",
      "paper_id": "2006.08403v2"
    },
    {
      "index": 22,
      "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu",
      "orig_title": "Towards deep learning models resistant to adversarial attacks",
      "paper_id": "1706.06083v4"
    },
    {
      "index": 23,
      "title": "Reading digits in natural images with unsupervised feature learning",
      "abstract": "",
      "year": "2011",
      "venue": "NIPS Workshop on Deep Learning and Unsupervised Feature Learning",
      "authors": "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng"
    },
    {
      "index": 24,
      "title": "Exploring Generalization in Deep Learning",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "Behnam Neyshabur, Srinadh Bhojanapalli, David Mcallester, and Nati Srebro",
      "orig_title": "Exploring generalization in deep learning",
      "paper_id": "1706.08947v2"
    },
    {
      "index": 25,
      "title": "Distillation as a defense to adversarial perturbations against deep neural networks",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Symposium on Security and Privacy (SP)",
      "authors": "Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami"
    },
    {
      "index": 26,
      "title": "Adversarial Robustness through Local Linearization",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy Dvijotham, Alhussein Fawzi, Soham De, Robert Stanforth, and Pushmeet Kohli",
      "orig_title": "Adversarial robustness through local linearization",
      "paper_id": "1907.02610v2"
    },
    {
      "index": 27,
      "title": "Searching for Activation Functions",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1710.05941",
      "authors": "Prajit Ramachandran, Barret Zoph, and Quoc V. Le",
      "orig_title": "Searching for activation functions",
      "paper_id": "1710.05941v2"
    },
    {
      "index": 28,
      "title": "S-sgd: Symmetrical stochastic gradient descent with weight noise injection for reaching flat minima",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2009.02479",
      "authors": "Wonyong Sung, Iksoo Choi, Jinhwan Park, Seokhyun Choi, and Sungho Shin"
    },
    {
      "index": 29,
      "title": "Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Yusuke Tsuzuku, Issei Sato, and Masashi Sugiyama",
      "orig_title": "Lipschitz-margin training: Scalable certification of perturbation invariance for deep neural networks",
      "paper_id": "1802.04034v3"
    },
    {
      "index": 30,
      "title": "Improving adversarial robustness requires revisiting misclassified examples",
      "abstract": "",
      "year": "2020",
      "venue": "ICLR",
      "authors": "Yisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, and Quanquan Gu"
    },
    {
      "index": 31,
      "title": "Adversarial Weight Perturbation Helps Robust Generalization",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Dongxian Wu, Shu tao Xia, and Yisen Wang",
      "orig_title": "Adversarial weight perturbation helps robust generalization",
      "paper_id": "2004.05884v2"
    },
    {
      "index": 32,
      "title": "On the Noisy Gradient Descent that Generalizes as SGD",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1906.07405",
      "authors": "Jingfeng Wu, Wenqing Hu, Haoyi Xiong, Jun Huan, Vladimir Braverman, and Zhanxing Zhu",
      "orig_title": "On the noisy gradient descent that generalizes as sgd",
      "paper_id": "1906.07405v3"
    },
    {
      "index": 33,
      "title": "Adversarial Training Makes Weight Loss Landscape Sharper in Logistic Regression",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv",
      "authors": "Masanori Yamada, Sekitoshi Kanai, Tomoharu Iwata, Tomokatsu Takahashi, Yuki Yamanka, Hiroshi Takahashi, and Atsutoshi Kumagai",
      "orig_title": "Adversarial training makes weight loss landscape sharper in logistic regression",
      "paper_id": "2102.02950v1"
    },
    {
      "index": 34,
      "title": "Wide Residual Networks",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1605.07146",
      "authors": "Sergey Zagoruyko and Nikos Komodakis",
      "orig_title": "Wide residual networks",
      "paper_id": "1605.07146v4"
    },
    {
      "index": 35,
      "title": "You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, and Bin Dong",
      "orig_title": "You only propagate once: Accelerating adversarial training via maximal principle",
      "paper_id": "1905.00877v6"
    },
    {
      "index": 36,
      "title": "Theoretically Principled Trade-off between Robustness and Accuracy",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan",
      "orig_title": "Theoretically principled trade-off between robustness and accuracy",
      "paper_id": "1901.08573v3"
    },
    {
      "index": 37,
      "title": "Why flatness correlates with generalization for deep neural networks",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2103.06219",
      "authors": "Shuofeng Zhang, Isaac Reid, Guillermo Valle Pérez, and Ard Louis"
    },
    {
      "index": 38,
      "title": "Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Yihan Zhou, Victor Sanches Portella, Mark Schmidt, and Nicholas Harvey",
      "orig_title": "Regret bounds without lipschitz continuity: Online learning with relative-lipschitz losses",
      "paper_id": "2010.12033v2"
    }
  ]
}