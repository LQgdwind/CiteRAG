{
  "paper_id": "2107.04529v1",
  "title": "Entropy, Information, and the Updating of Probabilities",
  "sections": {
    "discussion": "Entropic methods of inference are of general applicability but there exist\nspecial situations ‚Äî such as, for example, those involving large numbers of\nindependent subsystems ‚Äî where inferences can be made by purely\nprobabilistic methods without ever invoking the concept of entropy. In such\ncases one can check (see e.g. in ) that the two methods of calculation are consistent with each other. It\nis significant, however, that alternative entropies such as those proposed in\n do not pass this\ntest , which rules them out as\ntools for updating. Some probability distributions obtained by maximizing the\nalternative entropies have, however, turned out to be physically relevant. It\nis therefore noteworthy that those successful distributions can also be\nderived through more standard application of MaxEnt or ME as advocated in this\nreview [ref]8. In other words, what is being\nruled out are not the distributions themselves, but the alternative entropies\nfrom which they were inferred. Choosing the prior density q‚Äã(x)ùëûùë•q(x) can be tricky. Sometimes symmetry\nconsiderations can be useful but otherwise there is no fixed set of rules to\ntranslate information into a probability distribution except, of course, for\nBayes‚Äô rule and the ME method themselves. What if the prior q‚Äã(x)ùëûùë•q(x) vanishes for some values of xùë•x? S‚Äã[p,q]ùëÜùëùùëûS[p,q] can be\ninfinitely negative when q‚Äã(x)ùëûùë•q(x) vanishes within some region ùíüùíü\\mathcal{D}.\nThis means that the ME method confers an infinite preference on those\ndistributions p‚Äã(x)ùëùùë•p(x) that vanish whenever q‚Äã(x)ùëûùë•q(x) does. One must emphasize that\nthis is as it should be. A similar situation¬†also arises in the context of\nBayes‚Äô theorem where assigning a vanishing prior represents a tremendously\nserious commitment because no amount of data to the contrary would allow us to\nrevise it. In both ME and Bayes updating we should recognize the implications\nof assigning a vanishing prior. Assigning a very low but non-zero prior\nrepresents a safer and possibly less prejudiced representation of one‚Äôs prior beliefs. The ME method allows one to process information in the form of constraints.\nWhen we are confronted with several constraints we must be particularly\ncautious. Should they be processed simultaneously or sequentially? And, if the\nlatter, in what order? The answer depends on the problem at hand . We refer to constraints as commuting when it makes no difference\nwhether they are handled simultaneously or sequentially. The most common\nexample is that of Bayesian updating on the basis of data collected in several\nindependent experiments. In this case the order in which the observed data\nx‚Ä≤={x1‚Ä≤,x2‚Ä≤,‚Ä¶}superscriptùë•‚Ä≤superscriptsubscriptùë•1‚Ä≤superscriptsubscriptùë•2‚Ä≤‚Ä¶x^{\\prime}=\\{x_{1}^{\\prime},x_{2}^{\\prime},\\ldots\\} is processed does not\nmatter for the purpose of inferring Œ∏ùúÉ\\theta. In general, however, constraints\nneed not commute and when this is the case the order in which they are\nprocessed is critical. To decide whether constraints are to be handled sequentially or simultaneously\none must be clear about how the ME method handles constraints. The ME\nmachinery interprets a constraint in a very mechanical way: all distributions\nsatisfying the constraint are in principle allowed while all distributions\nviolating it are ruled out. Therefore, sequential updating is appropriate when\nold constraints become obsolete and are superseded by new information while\nsimultaneous updating is appropriate when old constraints remain valid. The\ntwo cases refer to different states of information and therefore it is to be\nexpected that they will result in different inferences. These comments are\nmeant to underscore the importance of understanding what information is and\nhow it is processed by the ME method; failure to do so will lead to errors\nthat do not reflect a shortcoming of the ME method but rather a misapplication\nof it. Entropy is a tool for reasoning and ‚Äî as with all tools for reasoning or\notherwise ‚Äî it can be misused leading to unsatisfactory results\n. Should that happen, the inevitable questions are ‚Äòwhat\nwent wrong?‚Äô and ‚Äòhow do we fix it?‚Äô It helps to first ask what components of\nthe analysis can be trusted so that the possible mistakes can be looked for\nelsewhere. The answers proposed by the ME method are radically conservative:\nproblems always arise through a wrong choices of variables, or priors, or\nconstraints. Indeed, one should not blame the entropic method for not having\ndiscovered and taken into account relevant information that was not explicitly\nintroduced into the analysis. Indeed, just as one would be very reticent about\nquestioning the basic rules of arithmetic, or the basic rules of calculus, one\nshould not question the basic sum and product rules of the probability\ncalculus and, taking this one step farther, one should not question the\napplicability of entropy as the updating tool. The adoption of this\nconservative approach leads us to reject alternative entropies and quantum\nprobabilities. Fortunately, those constructs are not actually needed ‚Äî as\nmentioned above, those Tsallis distributions that have turned out be useful\ncan be derived with the standard entropic methods [ref]8 and quantum mechanics can be handled within standard\nprobability theory without invoking exotic probabilities [ref]36. I would like to acknowledge many valuable discussions on probability and\nentropy with N. Caticha, A. Giffin, K. Knuth, R. Preuss, C. Rodr√≠guez, J.\nSkilling, and K. Vanslette."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Relative Entropy and Inductive Inference",
      "abstract": "",
      "year": "2004",
      "venue": "Bayesian Inference and Maximum Entropy Methods in Science and Engineering",
      "authors": "A. Caticha"
    },
    {
      "index": 1,
      "title": "Updating Probabilities",
      "abstract": "",
      "year": "2006",
      "venue": "Bayesian Inference and Maximum Entropy Methods in Science and Engineering",
      "authors": "A. Caticha and A. Giffin"
    },
    {
      "index": 2,
      "title": "Information and Entropy",
      "abstract": "",
      "year": "2007",
      "venue": "Bayesian Inference and Maximum Entropy Methods in Science and Engineering",
      "authors": "A. Caticha"
    },
    {
      "index": 3,
      "title": "Towards an Informational Pragmatic Realism",
      "abstract": "",
      "year": "2014",
      "venue": "Mind and Machines",
      "authors": "A. Caticha"
    },
    {
      "index": 4,
      "title": "Entropic Updating of Probabilities and Density Matrices",
      "abstract": "",
      "year": "2017",
      "venue": "Entropy",
      "authors": "K. Vanslette"
    },
    {
      "index": 5,
      "title": "Lectures on Probability, Entropy, and Statistical Physics",
      "abstract": "",
      "year": "2008",
      "venue": "MaxEnt 2008, S√£o Paulo, Brazil",
      "authors": "A. Caticha"
    },
    {
      "index": 6,
      "title": "Entropic Inference and the Foundations of Physics",
      "abstract": "",
      "year": "2012",
      "venue": "EBEB 2012, S√£o Paulo, Brazil",
      "authors": "A. Caticha"
    },
    {
      "index": 7,
      "title": "Entropic Physics: Probability, Entropy, and the Foundations of Physics",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "A. Caticha"
    },
    {
      "index": 8,
      "title": "Ïù∏Í≥µÏßÄÎä• Í∏∞Î∞ò Í≥µÍ≤© Í∑∏ÎûòÌîÑ ÏÉùÏÑ±",
      "abstract": "",
      "year": "1957",
      "venue": "Phys. Rev.",
      "authors": "E. T. Jaynes",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 9,
      "title": "Papers on Probability, Statistics and Statistical Physics",
      "abstract": "",
      "year": "1983",
      "venue": "",
      "authors": "E. T. Jaynes"
    },
    {
      "index": 10,
      "title": "Can the Maximum Entropy Principle be explained as a consistency requirement?",
      "abstract": "",
      "year": "1995",
      "venue": "Studies in History and Philosophy of Modern Physics",
      "authors": "J. Uffink"
    },
    {
      "index": 11,
      "title": "On measures of entropy and information",
      "abstract": "",
      "year": "1961",
      "venue": "Proc. 4th Berkeley Symposium on Mathematical Statistics and Probability",
      "authors": "A. Renyi"
    },
    {
      "index": 12,
      "title": "On Measures of Information and their Characterizations",
      "abstract": "",
      "year": "1975",
      "venue": "",
      "authors": "J. Acz√©l and Z. Dar√≥czy"
    },
    {
      "index": 13,
      "title": "Possible Generalization of Boltzmann-Gibbs Statistics",
      "abstract": "",
      "year": "1988",
      "venue": "J. Stat. Phys.",
      "authors": "C. Tsallis"
    },
    {
      "index": 14,
      "title": "Axiomatic derivation of the Principle of Maximum Entropy and the Principle of Minimum Cross-Entropy",
      "abstract": "",
      "year": "1980",
      "venue": "IEEE Trans. Inf. Theory",
      "authors": "J. E. Shore and R. W. Johnson"
    },
    {
      "index": 15,
      "title": "The Axioms of Maximum Entropy",
      "abstract": "",
      "year": "1988",
      "venue": "Maximum-Entropy and Bayesian Methods in Science and Engineering",
      "authors": "J. Skilling"
    },
    {
      "index": 16,
      "title": "Classic Maximum Entropy",
      "abstract": "",
      "year": "1989",
      "venue": "Maximum Entropy and Bayesian Methods",
      "authors": "J. Skilling"
    },
    {
      "index": 17,
      "title": "On the axiomatic approach to the maximum entropy principle of inference",
      "abstract": "",
      "year": "1986",
      "venue": "Pramana ‚Äì J. Phys.",
      "authors": "S. N. Karbelkar"
    },
    {
      "index": 18,
      "title": "Conceptual Inadequacy of the Shore and Johnson Axioms for Wide Classes of Complex systems",
      "abstract": "",
      "year": "2015",
      "venue": "Entropy",
      "authors": "C. Tsallis"
    },
    {
      "index": 19,
      "title": "Maximum Entropy Principle in Statistical Inference: Case for Non-Shannonian Entropies",
      "abstract": "",
      "year": "2019",
      "venue": "Phys. Rev. Lett.",
      "authors": "P. Jizba and J. Korbel"
    },
    {
      "index": 20,
      "title": "Nonadditive Entropies Yield Probability Distributions with Biases not Warranted by the Data",
      "abstract": "",
      "year": "2013",
      "venue": "Phys. Rev. Lett.",
      "authors": "S. Press√©, K. Ghosh, J. Lee, and K. A. Dill"
    },
    {
      "index": 21,
      "title": "Reply to Tsallis‚Äô ‚ÄúConceptual inadequacy of the Shore and Johnson axioms for wide classes of complex systems",
      "abstract": "",
      "year": "2015",
      "venue": "Entropy",
      "authors": "S. Press√©, K. Ghosh, J. Lee, and K. A. Dill"
    },
    {
      "index": 22,
      "title": "Bayesian Conditionalization and the Principle of Minimum Relative Information",
      "abstract": "",
      "year": "1980",
      "venue": "Brit. J. Phil. Sci.",
      "authors": "P. M. Williams"
    },
    {
      "index": 23,
      "title": "Entropic dynamics and the quantum measurement problem",
      "abstract": "",
      "year": "2012",
      "venue": "Bayesian Inference and Maximum Entropy Methods in Science and Engineering",
      "authors": "D. T. Johnson and A. Caticha"
    },
    {
      "index": 24,
      "title": "Quantum measurement and weak values in entropic quantum dynamics",
      "abstract": "",
      "year": "2017",
      "venue": "AIP Conf. Proc.",
      "authors": "K. Vanslette and A. Caticha"
    },
    {
      "index": 25,
      "title": "Elements of Information Theory",
      "abstract": "",
      "year": "1991",
      "venue": "",
      "authors": "T. Cover and J. Thomas"
    },
    {
      "index": 26,
      "title": "Foundations of Info-Metrics: Modeling, Inference, and Imperfect Information",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "A. Golan"
    },
    {
      "index": 27,
      "title": "Modeling by shortest data description",
      "abstract": "",
      "year": "1978",
      "venue": "Automatica",
      "authors": "J. Rissanen"
    },
    {
      "index": 28,
      "title": "Information is Physical",
      "abstract": "",
      "year": "1991",
      "venue": "Physics Today",
      "authors": "R. Landauer"
    },
    {
      "index": 29,
      "title": "The thermodynamics of computation‚ÄîA review",
      "abstract": "",
      "year": "1982",
      "venue": "Int. J. Th. Phys.",
      "authors": "C. Bennett"
    },
    {
      "index": 30,
      "title": "Notes on Landauer‚Äôs principle, reversible computation, and Maxwell‚Äôs demon",
      "abstract": "",
      "year": "2003",
      "venue": "Studies in History and Philosophy of Modern Physics",
      "authors": "C. Bennett"
    },
    {
      "index": 31,
      "title": "Waiting for Landauer",
      "abstract": "",
      "year": "2011",
      "venue": "Studies in History and Philosophy of Modern Physics",
      "authors": "J. D. Norton"
    },
    {
      "index": 32,
      "title": "The End of the Thermodynamics of Computation:¬†A No-Go Result",
      "abstract": "",
      "year": "2013",
      "venue": "Philosophy of Science",
      "authors": "J. D. Norton"
    },
    {
      "index": 33,
      "title": "Ïù∏Í≥µÏßÄÎä• Í∏∞Î∞ò Í≥µÍ≤© Í∑∏ÎûòÌîÑ ÏÉùÏÑ±",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 34,
      "title": "Entropic dynamics on Gibbs statistical manifolds",
      "abstract": "",
      "year": "2021",
      "venue": "Entropy",
      "authors": "P. Pessoa, F. X. Costa, and A. Caticha"
    },
    {
      "index": 35,
      "title": "The Entropic Dynamics approach to Quantum Mechanics",
      "abstract": "",
      "year": "2019",
      "venue": "Entropy",
      "authors": "A. Caticha"
    },
    {
      "index": 36,
      "title": "Ïù∏Í≥µÏßÄÎä• Í∏∞Î∞ò Í≥µÍ≤© Í∑∏ÎûòÌîÑ ÏÉùÏÑ±",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "",
      "orig_title": "",
      "paper_id": "2311.14342v2"
    },
    {
      "index": 37,
      "title": "Lattice duality: The origin of probability and entropy",
      "abstract": "",
      "year": "2005",
      "venue": "Neurocomputing",
      "authors": "K. H. Knuth"
    },
    {
      "index": 38,
      "title": "Foundations of Inference",
      "abstract": "",
      "year": "2012",
      "venue": "Axioms",
      "authors": "K. H. Knuth, J. Skilling"
    },
    {
      "index": 39,
      "title": "Updating Probabilities with Data and Moments",
      "abstract": "",
      "year": "2007",
      "venue": "Bayesian Inference and Maximum Entropy Methods in Science and Engineering",
      "authors": "A. Giffin and A. Caticha"
    },
    {
      "index": 40,
      "title": "Differential-Geometrical Methods in Statistics",
      "abstract": "",
      "year": "1985",
      "venue": "",
      "authors": "S. Amari"
    },
    {
      "index": 41,
      "title": "Maximum entropy and Bayesian data analysis: entropic prior distributions",
      "abstract": "",
      "year": "2004",
      "venue": "Phys. Rev. E",
      "authors": "A. Caticha and R. Preuss"
    },
    {
      "index": 42,
      "title": "Maximum Probability and Maximum Entropy Methods: Bayesian interpretation",
      "abstract": "",
      "year": "2004",
      "venue": "Bayesian Inference and Maximum Entropy Methods in Science and Engineering",
      "authors": "M. Grendar, Jr. and M. Grendar"
    },
    {
      "index": 43,
      "title": "Tsallis maximum entropy principle and the law of large numbers",
      "abstract": "",
      "year": "2000",
      "venue": "Phys. Rev E",
      "authors": "B.R. La Cour and W. C. Schieve"
    },
    {
      "index": 44,
      "title": "Critique of qùëûq-entropy for thermal statistics",
      "abstract": "",
      "year": "2003",
      "venue": "Phys. Rev E",
      "authors": "M. Nauenberg"
    },
    {
      "index": 45,
      "title": "From Gibbs microcanonical ensemble to Tsallis generalized canonical distribution",
      "abstract": "",
      "year": "1994",
      "venue": "Phys. Lett. A",
      "authors": "A. R. Plastino and A. Plastino"
    },
    {
      "index": 46,
      "title": "Dynamical Foundations of nonextensive Statistical Mechanics",
      "abstract": "",
      "year": "2001",
      "venue": "Phys. Rev. Lett.",
      "authors": "C. Beck"
    },
    {
      "index": 47,
      "title": "Superstatistics",
      "abstract": "",
      "year": "2003",
      "venue": "Physica A",
      "authors": "C. Beck and E.G.D. Cohen"
    },
    {
      "index": 48,
      "title": "Beyond Boltzmann-Gibbs statistics: Maximum entropy hyperensembles out of equilibrium",
      "abstract": "",
      "year": "2007",
      "venue": "Phys. Rev. E",
      "authors": "G. E. Crooks"
    },
    {
      "index": 49,
      "title": "Entropic inference: some pitfalls and paradoxes we can avoid",
      "abstract": "",
      "year": "2013",
      "venue": "Bayesian Inference and Maximum Entropy Methods in Science and Engineering",
      "authors": "A. Caticha"
    },
    {
      "index": 50,
      "title": "The Undivided Universe: an ontological interpretation on quantum theory",
      "abstract": "",
      "year": "1993",
      "venue": "",
      "authors": "D. Bohm and B. J. Hiley"
    },
    {
      "index": 51,
      "title": "On the foundations of decision theory",
      "abstract": "",
      "year": "2017",
      "venue": "Homo Oecon",
      "authors": "K. Binmore"
    },
    {
      "index": 52,
      "title": "Information Theory for Agents in Artificial Intelligence, Psychology, and Economics",
      "abstract": "",
      "year": "2021",
      "venue": "Entropy",
      "authors": "M.S. Harre"
    },
    {
      "index": 53,
      "title": "A Maximum Entropy Model of Bounded Rational Decision-Making with Prior Beliefs and Market Feedback",
      "abstract": "",
      "year": "2021",
      "venue": "Entropy",
      "authors": "B. P. Evans, M. Prokopenko"
    },
    {
      "index": 54,
      "title": "An Entropic framework for Modeling Economies",
      "abstract": "",
      "year": "2014",
      "venue": "Physica A",
      "authors": "A. Caticha and A. Golan"
    }
  ]
}