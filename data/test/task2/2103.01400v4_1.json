{
  "paper_id": "2103.01400v4",
  "title": "Smoothness Analysis of Adversarial Training",
  "sections": {
    "related work": "For improving adversarial robustness, several studies focus on the flatness of the loss landscape in the input data space\nbecause adversarial examples are perturbations in the input space [ref]27  [ref]4 .\nQin et al. [ref]27 have presented a regularization method to flatten the loss landscape with respect to data points.\nLipschitz constraints of the models can also be regarded as methods for flattening the loss in data space  [ref]4.\nFew studies investigate the loss landscape of adversarial training in parameter space\nbecause the relationship between the loss landscape in parameter space and the robustness had not been known before studies of [ref]22 .\nWu et al.  have experimentally shown that adversarial training can sharpen the loss landscape, which degrades generalization performance, and have proposed adversarial weight perturbation (AWP)\nto flatten the adversarial loss.\nSimilarly, Yamada et al.  have investigated the flatness of adversarial loss for logistic regression.\nCompared with these studies, we theoretically investigate the smoothness of adversarial loss with respect to parameters following [ref]22. For standard training of deep neural networks (DNNs),\nKeskar et al.  have shown that large batch training causes the sharp loss landscape, which\ncauses the poor generalization performance.\nNeyshabur et al.  have revealed the relationship between generalization performance and the flatness by using PAC-Bayes.\nA lot of studies have investigated approaches for flattening the loss landscape    3.\nSince the spectral norm of the Hessian matrix is used as a measure of flatness   8,\nthere is a relationship between Lipschitz-smoothness and flatness:\nif a Cssubscript𝐶𝑠C_{s}-Lipschitz gradient ∇θL​(𝜽)subscript∇𝜃𝐿𝜽\\nabla_{\\theta}L(\\bm{\\theta}) is everywhere differentiable,\nwe have where σisubscript𝜎𝑖\\sigma_{i} is the i𝑖i-th largest singular value, and thus, σ1​(⋅)subscript𝜎1⋅\\sigma_{1}(\\cdot) is a spectral norm.\nEquation (75) indicates that smooth functions with small Cssubscript𝐶𝑠C_{s} tend to have small spectral norms of the Hessian matrices, i.e., flat loss landscapes.\nWe further discuss the relationship between flatness and smoothness in the supplementary materials.\nWe focus on EntropySGD since it is a basic method for smoothing the loss."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Nonlinear programming",
      "abstract": "",
      "year": "1999",
      "venue": "Athena Scientific",
      "authors": "Dimitri P Bertsekas"
    },
    {
      "index": 1,
      "title": "Unlabeled Data Improves Adversarial Robustness",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang",
      "orig_title": "Unlabeled data improves adversarial robustness",
      "paper_id": "1905.13736v4"
    },
    {
      "index": 2,
      "title": "Entropy-sgd: Biasing gradient descent into wide valleys",
      "abstract": "",
      "year": "2019",
      "venue": "Journal of Statistical Mechanics: Theory and Experiment",
      "authors": "Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi, Christian Borgs, Jennifer Chayes, Levent Sagun, and Riccardo Zecchina"
    },
    {
      "index": 3,
      "title": "Parseval Networks: Improving Robustness to Adversarial Examples",
      "abstract": "",
      "year": "2017",
      "venue": "ICML",
      "authors": "Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas Usunier",
      "orig_title": "Parseval networks: Improving robustness to adversarial examples",
      "paper_id": "1704.08847v2"
    },
    {
      "index": 4,
      "title": "Certified Adversarial Robustness via Randomized Smoothing",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Jeremy Cohen, Elan Rosenfeld, and Zico Kolter",
      "orig_title": "Certified adversarial robustness via randomized smoothing",
      "paper_id": "1902.02918v2"
    },
    {
      "index": 5,
      "title": "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Francesco Croce and Matthias Hein"
    },
    {
      "index": 6,
      "title": "Sharp Minima Can Generalize For Deep Nets",
      "abstract": "",
      "year": "2017",
      "venue": "ICML",
      "authors": "Laurent Dinh, Razvan Pascanu, Samy Bengio, and Yoshua Bengio",
      "orig_title": "Sharp minima can generalize for deep nets",
      "paper_id": "1703.04933v2"
    },
    {
      "index": 7,
      "title": "Evaluating and Understanding the Robustness of Adversarial Logit Pairing",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1807.10272",
      "authors": "Logan Engstrom, Andrew Ilyas, and Anish Athalye",
      "orig_title": "Evaluating and understanding the robustness of adversarial logit pairing",
      "paper_id": "1807.10272v2"
    },
    {
      "index": 8,
      "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization",
      "abstract": "",
      "year": "2021",
      "venue": "ICLR",
      "authors": "Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur",
      "orig_title": "Sharpness-aware minimization for efficiently improving generalization",
      "paper_id": "2010.01412v3"
    },
    {
      "index": 9,
      "title": "Explaining and Harnessing Adversarial Examples",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1412.6572",
      "authors": "Ian Goodfellow, Jonathon Shlens, and Christian Szegedy",
      "orig_title": "Explaining and harnessing adversarial examples",
      "paper_id": "1412.6572v3"
    },
    {
      "index": 10,
      "title": "Train faster, generalize better: Stability of stochastic gradient descent",
      "abstract": "",
      "year": "2016",
      "venue": "ICML",
      "authors": "Moritz Hardt, Ben Recht, and Yoram Singer",
      "orig_title": "Train faster, generalize better: Stability of stochastic gradient descent",
      "paper_id": "1509.01240v2"
    },
    {
      "index": 11,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 12,
      "title": "Three Factors Influencing Minima in SGD",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1711.04623",
      "authors": "Stanislaw Jastrzebski, Zachary Kenton, Devansh Arpit, Nicolas Ballas, Asja Fischer, Yoshua Bengio, and Amos Storkey",
      "orig_title": "Three factors influencing minima in sgd",
      "paper_id": "1711.04623v3"
    },
    {
      "index": 13,
      "title": "SciPy: Open source scientific tools for Python, 2001–",
      "abstract": "",
      "year": "",
      "venue": "",
      "authors": "Eric Jones, Travis Oliphant, Pearu Peterson, et al."
    },
    {
      "index": 14,
      "title": "Relationship between nonsmoothness in adversarial training, constraints of attacks, and flatness in the input space",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "Sekitoshi Kanai, Masanori Yamada, Hiroshi Takahashi, Yuki Yamanaka, and Yasutoshi Ida"
    },
    {
      "index": 15,
      "title": "Improving Generalization Performance by Switching from Adam to SGD",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1712.07628",
      "authors": "Nitish Shirish Keskar and Richard Socher",
      "orig_title": "Improving generalization performance by switching from adam to sgd",
      "paper_id": "1712.07628v1"
    },
    {
      "index": 16,
      "title": "On large-batch training for deep learning: Generalization gap and sharp minima",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR",
      "authors": "Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang"
    },
    {
      "index": 17,
      "title": "Understanding Catastrophic Overfitting in Single-step Adversarial Training",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI",
      "authors": "Hoki Kim, Woojin Lee, and Jaewook Lee",
      "orig_title": "Understanding catastrophic overfitting in single-step adversarial training",
      "paper_id": "2010.01799v2"
    },
    {
      "index": 18,
      "title": "Learning multiple layers of features from tiny images",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "Alex Krizhevsky and Geoffrey Hinton"
    },
    {
      "index": 19,
      "title": "Adversarial Machine Learning at Scale",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1611.01236",
      "authors": "Alexey Kurakin, Ian Goodfellow, and Samy Bengio",
      "orig_title": "Adversarial machine learning at scale",
      "paper_id": "1611.01236v2"
    },
    {
      "index": 20,
      "title": "Visualizing the Loss Landscape of Neural Nets",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein",
      "orig_title": "Visualizing the loss landscape of neural nets",
      "paper_id": "1712.09913v3"
    },
    {
      "index": 21,
      "title": "On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Chen Liu, Mathieu Salzmann, Tao Lin, Ryota Tomioka, and Sabine Süsstrunk",
      "orig_title": "On the loss landscape of adversarial training: Identifying challenges and how to overcome them",
      "paper_id": "2006.08403v2"
    },
    {
      "index": 22,
      "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu",
      "orig_title": "Towards deep learning models resistant to adversarial attacks",
      "paper_id": "1706.06083v4"
    },
    {
      "index": 23,
      "title": "Reading digits in natural images with unsupervised feature learning",
      "abstract": "",
      "year": "2011",
      "venue": "NIPS Workshop on Deep Learning and Unsupervised Feature Learning",
      "authors": "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng"
    },
    {
      "index": 24,
      "title": "Exploring Generalization in Deep Learning",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "Behnam Neyshabur, Srinadh Bhojanapalli, David Mcallester, and Nati Srebro",
      "orig_title": "Exploring generalization in deep learning",
      "paper_id": "1706.08947v2"
    },
    {
      "index": 25,
      "title": "Distillation as a defense to adversarial perturbations against deep neural networks",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Symposium on Security and Privacy (SP)",
      "authors": "Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami"
    },
    {
      "index": 26,
      "title": "Adversarial Robustness through Local Linearization",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy Dvijotham, Alhussein Fawzi, Soham De, Robert Stanforth, and Pushmeet Kohli",
      "orig_title": "Adversarial robustness through local linearization",
      "paper_id": "1907.02610v2"
    },
    {
      "index": 27,
      "title": "Searching for Activation Functions",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1710.05941",
      "authors": "Prajit Ramachandran, Barret Zoph, and Quoc V. Le",
      "orig_title": "Searching for activation functions",
      "paper_id": "1710.05941v2"
    },
    {
      "index": 28,
      "title": "S-sgd: Symmetrical stochastic gradient descent with weight noise injection for reaching flat minima",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2009.02479",
      "authors": "Wonyong Sung, Iksoo Choi, Jinhwan Park, Seokhyun Choi, and Sungho Shin"
    },
    {
      "index": 29,
      "title": "Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Yusuke Tsuzuku, Issei Sato, and Masashi Sugiyama",
      "orig_title": "Lipschitz-margin training: Scalable certification of perturbation invariance for deep neural networks",
      "paper_id": "1802.04034v3"
    },
    {
      "index": 30,
      "title": "Improving adversarial robustness requires revisiting misclassified examples",
      "abstract": "",
      "year": "2020",
      "venue": "ICLR",
      "authors": "Yisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, and Quanquan Gu"
    },
    {
      "index": 31,
      "title": "Adversarial Weight Perturbation Helps Robust Generalization",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Dongxian Wu, Shu tao Xia, and Yisen Wang",
      "orig_title": "Adversarial weight perturbation helps robust generalization",
      "paper_id": "2004.05884v2"
    },
    {
      "index": 32,
      "title": "On the Noisy Gradient Descent that Generalizes as SGD",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1906.07405",
      "authors": "Jingfeng Wu, Wenqing Hu, Haoyi Xiong, Jun Huan, Vladimir Braverman, and Zhanxing Zhu",
      "orig_title": "On the noisy gradient descent that generalizes as sgd",
      "paper_id": "1906.07405v3"
    },
    {
      "index": 33,
      "title": "Adversarial Training Makes Weight Loss Landscape Sharper in Logistic Regression",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv",
      "authors": "Masanori Yamada, Sekitoshi Kanai, Tomoharu Iwata, Tomokatsu Takahashi, Yuki Yamanka, Hiroshi Takahashi, and Atsutoshi Kumagai",
      "orig_title": "Adversarial training makes weight loss landscape sharper in logistic regression",
      "paper_id": "2102.02950v1"
    },
    {
      "index": 34,
      "title": "Wide Residual Networks",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1605.07146",
      "authors": "Sergey Zagoruyko and Nikos Komodakis",
      "orig_title": "Wide residual networks",
      "paper_id": "1605.07146v4"
    },
    {
      "index": 35,
      "title": "You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, and Bin Dong",
      "orig_title": "You only propagate once: Accelerating adversarial training via maximal principle",
      "paper_id": "1905.00877v6"
    },
    {
      "index": 36,
      "title": "Theoretically Principled Trade-off between Robustness and Accuracy",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan",
      "orig_title": "Theoretically principled trade-off between robustness and accuracy",
      "paper_id": "1901.08573v3"
    },
    {
      "index": 37,
      "title": "Why flatness correlates with generalization for deep neural networks",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2103.06219",
      "authors": "Shuofeng Zhang, Isaac Reid, Guillermo Valle Pérez, and Ard Louis"
    },
    {
      "index": 38,
      "title": "Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Yihan Zhou, Victor Sanches Portella, Mark Schmidt, and Nicholas Harvey",
      "orig_title": "Regret bounds without lipschitz continuity: Online learning with relative-lipschitz losses",
      "paper_id": "2010.12033v2"
    }
  ]
}