{
  "paper_id": "2111.05008v1",
  "title": "Misspecified Gaussian Process Bandit Optimization",
  "sections": {
    "appendix a gp bandits: useful definitions and auxiliary results (realizable setting)": "Assumed observation model. We say a real-valued random variable Xğ‘‹X is Ïƒğœ\\sigma-sub-Gaussian if it its mean is zero and for all Îµâˆˆâ„ğœ€â„\\varepsilon\\in\\mathbb{R} we have At every round tğ‘¡t, the learner selects xtâˆˆDsubscriptğ‘¥ğ‘¡ğ·x_{t}\\in D and observes the noisy function evaluation where we assume {Î·t}t=1Tsuperscriptsubscriptsubscriptğœ‚ğ‘¡ğ‘¡1ğ‘‡\\{\\eta_{t}\\}_{t=1}^{T} are Ïƒğœ\\sigma-sub-Gaussian random variables that are independent over time steps. Such assumptions on the noise variables are frequently used in bandit optimization. Typically, in kernelized bandits, we assume that unknown fâˆˆâ„±kâ€‹(ğ’Ÿ;B)={fâˆˆâ„‹kâ€‹(ğ’Ÿ):â€–fâ€–kâ‰¤B}ğ‘“subscriptâ„±ğ‘˜ğ’Ÿğµconditional-setğ‘“subscriptâ„‹ğ‘˜ğ’Ÿsubscriptnormğ‘“ğ‘˜ğµf\\in{\\cal F}_{k}({\\cal D};B)=\\{f\\in{\\cal H}_{k}({\\cal D}):\\|f\\|_{k}\\leq B\\}, where â„‹kâ€‹(ğ’Ÿ)subscriptâ„‹ğ‘˜ğ’Ÿ{\\cal H}_{k}({\\cal D}) is the reproducing kernel Hilbert space of functions associated with the given positive-definite kernel function. Typically, the learner knows â„±kâ€‹(ğ’Ÿ;B)subscriptâ„±ğ‘˜ğ’Ÿğµ{\\cal F}_{k}({\\cal D};B), meaning that both kâ€‹(â‹…,â‹…)ğ‘˜â‹…â‹…k(\\cdot,\\cdot) and BğµB are considered as input to the learnerâ€™s algorithm. Example kernel functions.\nWe outline some commonly used kernel functions k:ğ’ŸÃ—ğ’Ÿâ†’â„:ğ‘˜â†’ğ’Ÿğ’Ÿâ„k:{\\cal D}\\times{\\cal D}\\to\\mathbb{R}, that we also consider: Linear kernel: klinâ€‹(x,xâ€²)=xTâ€‹xâ€²subscriptğ‘˜linğ‘¥superscriptğ‘¥â€²superscriptğ‘¥ğ‘‡superscriptğ‘¥â€²k_{\\text{lin}}(x,x^{\\prime})=x^{T}x^{\\prime}, Squared exponential kernel: kSEâ€‹(x,xâ€²)=expâ¡(âˆ’â€–xâˆ’xâ€²â€–22â€‹l2)subscriptğ‘˜SEğ‘¥superscriptğ‘¥â€²superscriptnormğ‘¥superscriptğ‘¥â€²22superscriptğ‘™2k_{\\text{SE}}(x,x^{\\prime})=\\exp\\left(-\\dfrac{\\|x-x^{\\prime}\\|^{2}}{2l^{2}}\\right), MatÃ©rn kernel: kMatâ€‹(x,xâ€²)=21âˆ’Î½Î“â€‹(Î½)â€‹(2â€‹Î½â€‹â€–xâˆ’xâ€²â€–l)â€‹JÎ½â€‹(2â€‹Î½â€‹â€–xâˆ’xâ€²â€–l)subscriptğ‘˜Matğ‘¥superscriptğ‘¥â€²superscript21ğœˆÎ“ğœˆ2ğœˆnormğ‘¥superscriptğ‘¥â€²ğ‘™subscriptğ½ğœˆ2ğœˆnormğ‘¥superscriptğ‘¥â€²ğ‘™k_{\\text{Mat}}(x,x^{\\prime})=\\frac{2^{1-\\nu}}{\\Gamma(\\nu)}\\Big{(}\\frac{\\sqrt{2\\nu}\\|x-x^{\\prime}\\|}{l}\\Big{)}J_{\\nu}\\Big{(}\\frac{\\sqrt{2\\nu}\\|x-x^{\\prime}\\|}{l}\\Big{)}, where lğ‘™l denotes the length-scale hyperparameter, Î½>0ğœˆ0\\nu>0 is an additional hyperparameter that dictates the smoothness, and Jâ€‹(Î½)ğ½ğœˆJ(\\nu) and Î“â€‹(Î½)Î“ğœˆ\\Gamma(\\nu) denote the modified Bessel function and the Gamma function, respectively [ref]34. Maximum information gain.\nMaximum information gain is a kernel-dependent quantity that measures the complexity of the given function class. It has first been introduced in , and since then it has been used in numerous works on Gaussian process bandits. Typically, the upper regret bounds in Gaussian process bandits are expressed in terms of this complexity measure. It represents the maximum amount of information that a set of noisy observations can reveal about the unknown fğ‘“f that is sampled from a zero-mean Gaussian process with kernel kğ‘˜k, i.e., fâˆ¼Gâ€‹Pâ€‹(0,k)similar-toğ‘“ğºğ‘ƒ0ğ‘˜f\\sim GP(0,k). More precisely, for a set of sampling points SâŠ‚ğ’Ÿğ‘†ğ’ŸS\\subset{\\cal D}, we use fSsubscriptğ‘“ğ‘†f_{S} to denote a random vector [fâ€‹(x)]xâˆˆSsubscriptdelimited-[]ğ‘“ğ‘¥ğ‘¥ğ‘†[f(x)]_{x\\in S}, and YSsubscriptğ‘Œğ‘†Y_{S} to denote the corresponding noisy observations obtained as YS=fS+Î·Ssubscriptğ‘Œğ‘†subscriptğ‘“ğ‘†subscriptğœ‚ğ‘†Y_{S}=f_{S}+\\eta_{S}, where Î·Sâˆ¼ğ’©â€‹(0,Î»â€‹I)similar-tosubscriptğœ‚ğ‘†ğ’©0ğœ†ğ¼\\eta_{S}\\sim\\mathcal{N}(0,\\lambda I). We note that under this setup after observing YSsubscriptğ‘Œğ‘†Y_{S}, the posterior distribution of fğ‘“f is a Gaussian process with posterior mean and variance that correspond to Eq.Â 8 and Eq.Â 9. The maximum information gain (about fğ‘“f) after observing tğ‘¡t noisy samples is defined as (see ): where Iâ€‹(â‹…,â‹…)ğ¼â‹…â‹…I(\\cdot,\\cdot) denotes the mutual information between random variables, |â‹…||\\cdot| is used to denote a matrix determinant, and Ktsubscriptğ¾ğ‘¡K_{t} is a kernel matrix [kâ€‹(xs,xsâ€²)]s,sâ€²â‰¤tâˆˆâ„tÃ—tsubscriptdelimited-[]ğ‘˜subscriptğ‘¥ğ‘ subscriptğ‘¥superscriptğ‘ â€²ğ‘ superscriptğ‘ â€²ğ‘¡superscriptâ„ğ‘¡ğ‘¡[k(x_{s},x_{s^{\\prime}})]_{s,s^{\\prime}\\leq t}\\in\\mathbb{R}^{t\\times t}. Under the previous setup (GP prior and Gaussian likelihood), the maximum information gain can be expressed in terms of predictive GP variances: The proof of this claim can be found in [40, Lemma 5.3]. It also allows us to rewrite Eq.Â (12) from LemmaÂ 1 in the following frequently used form: Next, we outline an important relation (due to ) frequently used to relate the sum of GP predictive standard deviations with the maximum information gain. We use the formulation that follows from Lemma 4 in : Consider some kernel k:ğ’ŸÃ—ğ’Ÿâ†’â„:ğ‘˜â†’ğ’Ÿğ’Ÿâ„k:{\\cal D}\\times{\\cal D}\\to\\mathbb{R} such that kâ€‹(x,x)â‰¤1ğ‘˜ğ‘¥ğ‘¥1k(x,x)\\leq 1 for every xâˆˆğ’Ÿğ‘¥ğ’Ÿx\\in{\\cal D}, and let fâˆ¼Gâ€‹Pâ€‹(0,k)similar-toğ‘“ğºğ‘ƒ0ğ‘˜f\\sim GP(0,k) be a sample from a zero-mean GP with the corresponding kernel function. Then for any set of queried points {x1,â€¦,xt}subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘¡\\{x_{1},\\dots,x_{t}\\} and Î»>0ğœ†0\\lambda>0, it holds that Finally, we outline bounds on Î³tâ€‹(k,ğ’Ÿ)subscriptğ›¾ğ‘¡ğ‘˜ğ’Ÿ\\gamma_{t}(k,{\\cal D}) for commonly used kernels as provided in . An important observation is that the maximum information gain is sublinear in terms of number of samples tğ‘¡t for these kernels. Let dâˆˆâ„•ğ‘‘â„•d\\in\\mathbb{N} and ğ’ŸâŠ‚â„dğ’Ÿsuperscriptâ„ğ‘‘{\\cal D}\\subset\\mathbb{R}^{d} be a compact and convex set. Consider a kernel k:ğ’ŸÃ—ğ’Ÿâ†’â„:ğ‘˜â†’ğ’Ÿğ’Ÿâ„k:{\\cal D}\\times{\\cal D}\\to\\mathbb{R} such that kâ€‹(x,x)â‰¤1ğ‘˜ğ‘¥ğ‘¥1k(x,x)\\leq 1 for every xâˆˆğ’Ÿğ‘¥ğ’Ÿx\\in{\\cal D}, and let fâˆ¼Gâ€‹Pâ€‹(0,k)similar-toğ‘“ğºğ‘ƒ0ğ‘˜f\\sim GP(0,k) be a sample from a zero-mean Gaussian Process (supported on ğ’Ÿğ’Ÿ{\\cal D}) with the corresponding kernel function. Then in case of Linear kernel: Î³tâ€‹(klin,ğ’Ÿ)=Oâ€‹(dâ€‹logâ¡t)subscriptğ›¾ğ‘¡subscriptğ‘˜linğ’Ÿğ‘‚ğ‘‘ğ‘¡\\gamma_{t}(k_{\\text{lin}},{\\cal D})=O(d\\log t), Squared exponential kernel: Î³tâ€‹(kSE,ğ’Ÿ)=Oâ€‹((logâ¡t)d+1)subscriptğ›¾ğ‘¡subscriptğ‘˜SEğ’Ÿğ‘‚superscriptğ‘¡ğ‘‘1\\gamma_{t}(k_{\\text{SE}},{\\cal D})=O((\\log t)^{d+1}), MatÃ©rn kernel: Î³tâ€‹(kMat,ğ’Ÿ)=Oâ€‹(tdâ€‹(d+1)/(2â€‹Î½+dâ€‹(d+1))â€‹logâ¡t)subscriptğ›¾ğ‘¡subscriptğ‘˜Matğ’Ÿğ‘‚superscriptğ‘¡ğ‘‘ğ‘‘12ğœˆğ‘‘ğ‘‘1ğ‘¡\\gamma_{t}(k_{\\text{Mat}},{\\cal D})=O(t^{d(d+1)/(2\\nu+d(d+1))}\\log t). We also note that the previous rates in case of the MatÃ©rn kernel have been recently improved to:\nOâ€‹(td2â€‹Î½+dâ€‹(logâ¡t)2â€‹Î½2â€‹Î½+d)ğ‘‚superscriptğ‘¡ğ‘‘2ğœˆğ‘‘superscriptğ‘¡2ğœˆ2ğœˆğ‘‘O\\Big{(}t^{\\tfrac{d}{2\\nu+d}}(\\log t)^{\\tfrac{2\\nu}{2\\nu+d}}\\Big{)} in ."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Improved algorithms for linear stochastic bandits",
      "abstract": "",
      "year": "2011",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)",
      "authors": "Yasin Abbasi-Yadkori, DÃ¡vid PÃ¡l, and Csaba SzepesvÃ¡ri"
    },
    {
      "index": 1,
      "title": "Corralling a band of bandit algorithms",
      "abstract": "",
      "year": "2017",
      "venue": "Conference on Learning Theory",
      "authors": "Alekh Agarwal, Haipeng Luo, Behnam Neyshabur, and RobertÂ E Schapire"
    },
    {
      "index": 2,
      "title": "No-Regret Bayesian Optimization with Unknown Hyperparameters",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1901.03357",
      "authors": "Felix Berkenkamp, AngelaÂ P Schoellig, and Andreas Krause",
      "orig_title": "No-regret Bayesian optimization with unknown hyperparameters",
      "paper_id": "1901.03357v2"
    },
    {
      "index": 3,
      "title": "Corruption-tolerant Gaussian process bandit optimization",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Artificial Intelligence and Statistics (AISTATS)",
      "authors": "Ilija Bogunovic, Andreas Krause, and Scarlett Jonathan"
    },
    {
      "index": 4,
      "title": "Adversarially Robust Optimization with Gaussian Processes",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)",
      "authors": "Ilija Bogunovic, Jonathan Scarlett, Stefanie Jegelka, and Volkan Cevher",
      "orig_title": "Adversarially robust optimization with Gaussian processes",
      "paper_id": "1810.10775v2"
    },
    {
      "index": 5,
      "title": "Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)",
      "authors": "Ilija Bogunovic, Jonathan Scarlett, Andreas Krause, and Volkan Cevher",
      "orig_title": "Truncated variance reduction: A unified approach to Bayesian optimization and level-set estimation",
      "paper_id": "1610.07379v1"
    },
    {
      "index": 6,
      "title": "Bayesian optimization of risk measures",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2007.05554",
      "authors": "Sait Cakmak, Raul Astudillo, Peter Frazier, and Enlu Zhou"
    },
    {
      "index": 7,
      "title": "High-dimensional experimental design and kernel bandits",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Machine Learning",
      "authors": "Romain Camilleri, Kevin Jamieson, and Julian Katz-Samuels"
    },
    {
      "index": 8,
      "title": "On Kernelized Multi-armed Bandits",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning (ICML)",
      "authors": "SayakÂ Ray Chowdhury and Aditya Gopalan",
      "orig_title": "On kernelized multi-armed bandits",
      "paper_id": "1704.00445v2"
    },
    {
      "index": 9,
      "title": "Parallel Gaussian process optimization with upper confidence bound and pure exploration",
      "abstract": "",
      "year": "2013",
      "venue": "Joint European Conference on Machine Learning and Knowledge Discovery in Databases",
      "authors": "Emile Contal, David Buffoni, Alexandre Robicquet, and Nicolas Vayatis"
    },
    {
      "index": 10,
      "title": "Regret bounds for deterministic Gaussian process bandits",
      "abstract": "",
      "year": "2012",
      "venue": "arXiv preprint arXiv:1203.2177",
      "authors": "Nando deÂ Freitas, Alex Smola, and Masrour Zoghi"
    },
    {
      "index": 11,
      "title": "Is a good representation sufficient for sample efficient reinforcement learning?",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1910.03016",
      "authors": "SimonÂ S Du, ShamÂ M Kakade, Ruosong Wang, and LinÂ F Yang"
    },
    {
      "index": 12,
      "title": "Streaming kernel regression with provably adaptive mean, variance, and regularization",
      "abstract": "",
      "year": "2018",
      "venue": "The Journal of Machine Learning Research",
      "authors": "Audrey Durand, Odalric-Ambrym Maillard, and Joelle Pineau",
      "orig_title": "Streaming kernel regression with provably adaptive mean, variance, and regularization",
      "paper_id": "1708.00768v1"
    },
    {
      "index": 13,
      "title": "Adapting to misspecification in contextual bandits",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "DylanÂ J Foster, Claudio Gentile, Mehryar Mohri, and Julian Zimmert"
    },
    {
      "index": 14,
      "title": "Beyond UCB: Optimal and efficient contextual bandits with regression oracles",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2002.04926",
      "authors": "DylanÂ J Foster and Alexander Rakhlin"
    },
    {
      "index": 15,
      "title": "Misspecified Linear Bandits",
      "abstract": "",
      "year": "2017",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Avishek Ghosh, SayakÂ Ray Chowdhury, and Aditya Gopalan",
      "orig_title": "Misspecified linear bandits",
      "paper_id": "1704.06880v1"
    },
    {
      "index": 16,
      "title": "Provably Efficient Reinforcement Learning with Linear Function Approximation",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Learning Theory",
      "authors": "Chi Jin, Zhuoran Yang, Zhaoran Wang, and MichaelÂ I Jordan",
      "orig_title": "Provably efficient reinforcement learning with linear function approximation",
      "paper_id": "1907.05388v2"
    },
    {
      "index": 17,
      "title": "Gaussian Processes and Kernel Methods: A Review on Connections and Equivalences",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1807.02582",
      "authors": "Motonobu Kanagawa, Philipp Hennig, Dino Sejdinovic, and BharathÂ K Sriperumbudur",
      "orig_title": "Gaussian processes and kernel methods: A review on connections and equivalences",
      "paper_id": "1807.02582v1"
    },
    {
      "index": 18,
      "title": "The equivalence of two extremum problems",
      "abstract": "",
      "year": "1960",
      "venue": "Canadian Journal of Mathematics",
      "authors": "Jack Kiefer and Jacob Wolfowitz"
    },
    {
      "index": 19,
      "title": "Distributionally robust Bayesian optimization",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2002.09038",
      "authors": "Johannes Kirschner, Ilija Bogunovic, Stefanie Jegelka, and Andreas Krause"
    },
    {
      "index": 20,
      "title": "Stochastic Bandits with Context Distributions",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Johannes Kirschner and Andreas Krause",
      "orig_title": "Stochastic bandits with context distributions",
      "paper_id": "1906.02685v2"
    },
    {
      "index": 21,
      "title": "Contextual Gaussian process bandit optimization",
      "abstract": "",
      "year": "2011",
      "venue": "Advances in Neural Information Processing Systems (NeurIPS)",
      "authors": "Andreas Krause and ChengÂ S Ong"
    },
    {
      "index": 22,
      "title": "Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies",
      "abstract": "",
      "year": "2008",
      "venue": "Journal of Machine Learning Research",
      "authors": "Andreas Krause, Ajit Singh, and Carlos Guestrin"
    },
    {
      "index": 23,
      "title": "Learning with good feature representations in bandits and in RL with a generative model",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "Tor Lattimore, Csaba Szepesvari, and Gellert Weisz"
    },
    {
      "index": 24,
      "title": "A contextual-bandit approach to personalized news article recommendation",
      "abstract": "",
      "year": "2010",
      "venue": "International conference on World Wide Web",
      "authors": "Lihong Li, Wei Chu, John Langford, and RobertÂ E Schapire"
    },
    {
      "index": 25,
      "title": "Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization",
      "abstract": "",
      "year": "2017",
      "venue": "The Journal of Machine Learning Research",
      "authors": "Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar",
      "orig_title": "Hyperband: A novel bandit-based approach to hyperparameter optimization",
      "paper_id": "1603.06560v4"
    },
    {
      "index": 26,
      "title": "Competing Bandits in Matching Markets",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "authors": "LydiaÂ T Liu, Horia Mania, and Michael Jordan",
      "orig_title": "Competing bandits in matching markets",
      "paper_id": "1906.05363v2"
    },
    {
      "index": 27,
      "title": "Universal kernels",
      "abstract": "",
      "year": "2006",
      "venue": "Journal of Machine Learning Research",
      "authors": "CharlesÂ A Micchelli, Yuesheng Xu, and Haizhang Zhang"
    },
    {
      "index": 28,
      "title": "Uncertainty quantification using martingales for misspecified Gaussian processes",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2006.07368",
      "authors": "Willie Neiswanger and Aaditya Ramdas",
      "orig_title": "Uncertainty quantification using martingales for misspecified Gaussian processes",
      "paper_id": "2006.07368v2"
    },
    {
      "index": 29,
      "title": "Efficient and robust algorithms for adversarial linear contextual bandits",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2002.00287",
      "authors": "Gergely Neu and Julia Olkhovskaya",
      "orig_title": "Efficient and robust algorithms for adversarial linear contextual bandits",
      "paper_id": "2002.00287v3"
    },
    {
      "index": 30,
      "title": "Distributionally robust Bayesian quadrature optimization",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2001.06814",
      "authors": "ThanhÂ Tang Nguyen, Sunil Gupta, Huong Ha, Santu Rana, and Svetha Venkatesh"
    },
    {
      "index": 31,
      "title": "Regret Bound Balancing and Elimination for Model Selection in Bandits and RL",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2012.13045",
      "authors": "Aldo Pacchiano, Christoph Dann, Claudio Gentile, and Peter Bartlett",
      "orig_title": "Regret bound balancing and elimination for model selection in bandits and RL",
      "paper_id": "2012.13045v1"
    },
    {
      "index": 32,
      "title": "Model selection in contextual stochastic bandit problems",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2003.01704",
      "authors": "Aldo Pacchiano, MyÂ Phan, Yasin Abbasi-Yadkori, Anup Rao, Julian Zimmert, Tor Lattimore, and Csaba Szepesvari"
    },
    {
      "index": 33,
      "title": "Gaussian processes for machine learning, volumeÂ 1",
      "abstract": "",
      "year": "2006",
      "venue": "MIT press Cambridge",
      "authors": "CarlÂ Edward Rasmussen and ChristopherÂ KI Williams"
    },
    {
      "index": 34,
      "title": "Tight Regret Bounds for Bayesian Optimization in One Dimension",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning (ICML)",
      "authors": "Jonathan Scarlett",
      "orig_title": "Tight regret bounds for Bayesian optimization in one dimension",
      "paper_id": "1805.11792v3"
    },
    {
      "index": 35,
      "title": "Lower Bounds on Regret for Noisy Gaussian Process Bandit Optimization",
      "abstract": "",
      "year": "2017",
      "venue": "Conference on Learning Theory (COLT)",
      "authors": "Jonathan Scarlett, Ilijia Bogunovic, and Volkan Cevher",
      "orig_title": "Lower bounds on regret for noisy Gaussian process bandit optimization",
      "paper_id": "1706.00090v3"
    },
    {
      "index": 36,
      "title": "Quantifying mismatch in Bayesian optimization",
      "abstract": "",
      "year": "2016",
      "venue": "NeurIPS workshop on Bayesian optimization: Black-box optimization and beyond",
      "authors": "Eric Schulz, Maarten Speekenbrink, JosÃ©Â Miguel HernÃ¡ndez-Lobato, Zoubin Ghahramani, and SamuelÂ J Gershman"
    },
    {
      "index": 37,
      "title": "Mixed strategies for robust optimization of unknown objectives",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Artificial Intelligence and Statistics (AISTATS)",
      "authors": "PierÂ Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, and Andreas Krause"
    },
    {
      "index": 38,
      "title": "Gaussian Process Bandits with Adaptive Discretization",
      "abstract": "",
      "year": "2018",
      "venue": "Electronic Journal of Statistics",
      "authors": "Shubhanshu Shekhar and Tara Javidi",
      "orig_title": "Gaussian process bandits with adaptive discretization",
      "paper_id": "1712.01447v2"
    },
    {
      "index": 39,
      "title": "Gaussian process optimization in the bandit setting: No regret and experimental design",
      "abstract": "",
      "year": "2010",
      "venue": "International Conference on Machine Learning (ICML)",
      "authors": "Niranjan Srinivas, Andreas Krause, ShamÂ M Kakade, and Matthias Seeger"
    },
    {
      "index": 40,
      "title": "Safe exploration for optimization with Gaussian processes",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Machine Learning (ICML)",
      "authors": "Yanan Sui, Alkis Gotovos, Joel Burdick, and Andreas Krause"
    },
    {
      "index": 41,
      "title": "From ads to interventions: Contextual bandits in mobile health",
      "abstract": "",
      "year": "2017",
      "venue": "Mobile Health",
      "authors": "Ambuj Tewari and SusanÂ A Murphy"
    },
    {
      "index": 42,
      "title": "On information gain and regret bounds in Gaussian process bandits",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2009.06966",
      "authors": "Sattar Vakili, Kia Khezeli, and Victor Picheny"
    },
    {
      "index": 43,
      "title": "Finite-time analysis of kernelised contextual bandits",
      "abstract": "",
      "year": "2013",
      "venue": "Uncertainty In Artificial Intelligence (UAI)",
      "authors": "Michal Valko, Nathaniel Korda, RÃ©mi Munos, Ilias Flaounas, and Nelo Cristianini"
    },
    {
      "index": 44,
      "title": "Comments on the du-kakade-wang-yang lower bounds",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1911.07910",
      "authors": "Benjamin VanÂ Roy and Shi Dong"
    },
    {
      "index": 45,
      "title": "Theoretical Analysis of Bayesian Optimisation with Unknown Gaussian Process Hyper-Parameters",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1406.7758",
      "authors": "Ziyu Wang and Nando deÂ Freitas",
      "orig_title": "Theoretical analysis of Bayesian optimisation with unknown Gaussian process hyper-parameters",
      "paper_id": "1406.7758v1"
    },
    {
      "index": 46,
      "title": "Convergence Guarantees for Gaussian Process Means With Misspecified Likelihoods and Smoothness",
      "abstract": "",
      "year": "2021",
      "venue": "Journal of Machine Learning Research",
      "authors": "George Wynne, Francois-Xavier Briol, and Mark Girolami",
      "orig_title": "Convergence guarantees for Gaussian process means with misspecified likelihoods and smoothness",
      "paper_id": "2001.10818v3"
    },
    {
      "index": 47,
      "title": "Learning Near Optimal Policies with Low Inherent Bellman Error",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2003.00153",
      "authors": "Andrea Zanette, Alessandro Lazaric, Mykel Kochenderfer, and Emma Brunskill",
      "orig_title": "Learning near optimal policies with low inherent Bellman error",
      "paper_id": "2003.00153v3"
    }
  ]
}