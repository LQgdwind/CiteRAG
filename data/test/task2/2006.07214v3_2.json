{
  "paper_id": "2006.07214v3",
  "title": "Sparse and Continuous Attention Mechanisms",
  "sections": {
    "introduction": "Exponential families are ubiquitous in statistics and machine learning  . They enjoy many useful properties, such as the existence of conjugate priors (crucial in Bayesian inference) and\nthe classical Pitman-Koopman-Darmois theorem   , which states that,\namong families with fixed support (independent of the parameters), exponential families are the only having sufficient statistics of fixed dimension for any number of i.i.d.¬†samples. Departing from exponential families, there has been recent work on discrete, finite-domain distributions with varying and sparse support, via the sparsemax and the entmax transformations [ref]6 [ref]7 [ref]8.\nThose approaches drop the link to exponential families of categorical distributions provided by the softmax transformation, which always yields dense probability mass functions. In contrast, sparsemax and entmax can lead to sparse distributions, whose support is not constant throughout the family. This property has been used  to design sparse attention mechanisms with improved interpretability [ref]8 . However, sparsemax and entmax are so far limited to discrete domains. Can a similar approach be extended to continuous domains? This paper provides that extension and pinpoints a connection with ‚Äúdeformed exponential families‚Äù 0 1 2 and Tsallis statistics 3, leading to Œ±ùõº\\alpha-sparse families (¬ß2).\nWe use this construction to obtain new density families with varying support,\nincluding the truncated parabola and paraboloid distributions (2-sparse counterpart of the Gaussian, ¬ß2.4 and Fig.¬†1). Softmax and its variants are widely used in attention mechanisms, an important component of neural networks 4. Attention-based neural networks can ‚Äúattend‚Äù to finite sets of objects and identify relevant features.\nWe use our extension above to devise new continuous attention mechanisms (¬ß3), which can attend to continuous data streams and to domains that are inherently continuous, such as images. Unlike traditional attention mechanisms, ours are suitable for selecting compact regions, such as 1D-segments or 2D-ellipses. We show that the Jacobian of these transformations are generalized covariances, and we use this fact to obtain efficient backpropagation algorithms (¬ß3.2). As a proof of concept, we apply our models with continuous attention to text classification, machine translation, and visual question answering tasks, with encouraging results (¬ß4)."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Fundamentals of Statistical Exponential Families with Applications in Statistical Decision Theory",
      "abstract": "",
      "year": "1986",
      "venue": "Institute of Mathematical Statistics",
      "authors": "Lawrence D Brown"
    },
    {
      "index": 1,
      "title": "Information and Exponential Families in Statistical Theory",
      "abstract": "",
      "year": "2014",
      "venue": "John Wiley & Sons",
      "authors": "Ole Barndorff-Nielsen"
    },
    {
      "index": 2,
      "title": "Sufficient statistics and intrinsic accuracy",
      "abstract": "",
      "year": "1936",
      "venue": "Mathematical Proceedings of the Cambridge Philosophical Society",
      "authors": "Edwin James George Pitman"
    },
    {
      "index": 3,
      "title": "Sur les lois de probabilit√©a estimation exhaustive",
      "abstract": "",
      "year": "1935",
      "venue": "CR Acad. Sci. Paris",
      "authors": "Georges Darmois"
    },
    {
      "index": 4,
      "title": "On distributions admitting a sufficient statistic",
      "abstract": "",
      "year": "1936",
      "venue": "Transactions of the American Mathematical society",
      "authors": "Bernard Osgood Koopman"
    },
    {
      "index": 5,
      "title": "From softmax to sparsemax: A sparse model of attention and multi-label classification",
      "abstract": "",
      "year": "2016",
      "venue": "ICML",
      "authors": "Andr√© FT Martins and Ram√≥n Fernandez Astudillo"
    },
    {
      "index": 6,
      "title": "Learning with Fenchel-Young Losses",
      "abstract": "",
      "year": "2020",
      "venue": "Journal of Machine Learning Research",
      "authors": "Mathieu Blondel, Andr√© FT Martins, and Vlad Niculae",
      "orig_title": "Learning with fenchel-young losses",
      "paper_id": "1901.02324v2"
    },
    {
      "index": 7,
      "title": "Sparse Sequence-to-Sequence Models",
      "abstract": "",
      "year": "2019",
      "venue": "ACL",
      "authors": "Ben Peters, Vlad Niculae, and Andr√© F.T. Martins",
      "orig_title": "Sparse sequence-to-sequence models",
      "paper_id": "1905.05702v2"
    },
    {
      "index": 8,
      "title": "Adaptively Sparse Transformers",
      "abstract": "",
      "year": "2019",
      "venue": "Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
      "authors": "Gon√ßalo M Correia, Vlad Niculae, and Andr√© FT Martins",
      "orig_title": "Adaptively sparse transformers",
      "paper_id": "1909.00015v2"
    },
    {
      "index": 9,
      "title": "The q-exponential family in statistical physics",
      "abstract": "",
      "year": "2009",
      "venue": "Central European Journal of Physics",
      "authors": "Jan Naudts"
    },
    {
      "index": 10,
      "title": "Generalized Maximum Entropy, Convexity and Machine Learning",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": "Timothy Sears"
    },
    {
      "index": 11,
      "title": "t-logistic regression",
      "abstract": "",
      "year": "2010",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Nan Ding and S.V.N. Vishwanathan"
    },
    {
      "index": 12,
      "title": "Possible generalization of Boltzmann-Gibbs statistics",
      "abstract": "",
      "year": "1988",
      "venue": "Journal of Statistical Physics",
      "authors": "Constantino Tsallis"
    },
    {
      "index": 13,
      "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
      "abstract": "",
      "year": "2015",
      "venue": "ICLR",
      "authors": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio",
      "orig_title": "Neural machine translation by jointly learning to align and translate",
      "paper_id": "1409.0473v7"
    },
    {
      "index": 14,
      "title": "Measure Theory, volume 18",
      "abstract": "",
      "year": "2013",
      "venue": "Springer",
      "authors": "Paul R Halmos"
    },
    {
      "index": 15,
      "title": "Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition",
      "abstract": "",
      "year": "1990",
      "venue": "Neurocomputing",
      "authors": "John S. Bridle"
    },
    {
      "index": 16,
      "title": "Elements of Information Theory",
      "abstract": "",
      "year": "2012",
      "venue": "John Wiley & Sons",
      "authors": "Thomas M Cover and Joy A Thomas"
    },
    {
      "index": 17,
      "title": "Information geometry and its applications, volume 194",
      "abstract": "",
      "year": "2016",
      "venue": "Springer",
      "authors": "Shun-ichi Amari"
    },
    {
      "index": 18,
      "title": "Quantification method of classification processes. concept of structural aùëéa-entropy",
      "abstract": "",
      "year": "1967",
      "venue": "Kybernetika",
      "authors": "Jan Havrda and Franti≈°ek Charv√°t"
    },
    {
      "index": 19,
      "title": "Entropy and diversity",
      "abstract": "",
      "year": "2006",
      "venue": "Oikos",
      "authors": "L. Jost"
    },
    {
      "index": 20,
      "title": "Gini-Simpson index of diversity: a characterization, generalization, and applications",
      "abstract": "",
      "year": "1982",
      "venue": "Utilitas Mathematics",
      "authors": "R.A. Rao"
    },
    {
      "index": 21,
      "title": "Adaptive sparseness using Jeffreys prior",
      "abstract": "",
      "year": "2001",
      "venue": "NeurIPS",
      "authors": "M. Figueiredo"
    },
    {
      "index": 22,
      "title": "Sparse Bayesian learning and the relevance vector machine",
      "abstract": "",
      "year": "2001",
      "venue": "Journal of Machine Learning Research",
      "authors": "M. Tipping"
    },
    {
      "index": 23,
      "title": "Geometry for q-exponential families",
      "abstract": "",
      "year": "2012",
      "venue": "Recent Progress in Differential Geometry and its Related Fields",
      "authors": "Hiroshi Matsuzoe and Atsumi Ohara"
    },
    {
      "index": 24,
      "title": "Geometry of q-exponential family of probability distributions",
      "abstract": "",
      "year": "2011",
      "venue": "Entropy",
      "authors": "Shun-ichi Amari and Atsumi Ohara"
    },
    {
      "index": 25,
      "title": "Non-parametric estimation of a multivariate probability density",
      "abstract": "",
      "year": "1969",
      "venue": "Theory of Probability & Its Applications",
      "authors": "Vassiliy A Epanechnikov"
    },
    {
      "index": 26,
      "title": "End-to-end memory networks",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al."
    },
    {
      "index": 27,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 28,
      "title": "Learning word vectors for sentiment analysis",
      "abstract": "",
      "year": "2011",
      "venue": "NAACL-HLT",
      "authors": "Andrew L Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, and Christopher Potts"
    },
    {
      "index": 29,
      "title": "Overview of the IWSLT 2017 evaluation campaign",
      "abstract": "",
      "year": "2017",
      "venue": "IWSLT",
      "authors": "Mauro Cettolo, Marcello Federico, Luisa Bentivogli, Niehues Jan, St√ºker Sebastian, Sudoh Katsuitho, Yoshino Koichiro, and Federmann Christian"
    },
    {
      "index": 30,
      "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
      "abstract": "",
      "year": "2019",
      "venue": "International Journal of Computer Vision",
      "authors": "Yash Goyal, Tejas Khot, Aishwarya Agrawal, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh",
      "orig_title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering",
      "paper_id": "1612.00837v3"
    },
    {
      "index": 31,
      "title": "Deep Modular Co-Attention Networks for Visual Question Answering",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
      "authors": "Zhou Yu, Jun Yu, Yuhao Cui, Dacheng Tao, and Qi Tian",
      "orig_title": "Deep modular co-attention networks for visual question answering",
      "paper_id": "1906.10770v1"
    },
    {
      "index": 32,
      "title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, and Lei Zhang",
      "orig_title": "Bottom-up and top-down attention for image captioning and visual question answering",
      "paper_id": "1707.07998v3"
    },
    {
      "index": 33,
      "title": "Deep Parametric Continuous Convolutional Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Shenlong Wang, Simon Suo, Wei-Chiu Ma, Andrei Pokrovsky, and Raquel Urtasun",
      "orig_title": "Deep parametric continuous convolutional neural networks",
      "paper_id": "2101.06742v1"
    },
    {
      "index": 34,
      "title": "Schnet: A continuous-filter convolutional neural network for modeling quantum interactions",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "Kristof Sch√ºtt, Pieter-Jan Kindermans, Huziel Enoc Sauceda Felix, Stefan Chmiela, Alexandre Tkatchenko, and Klaus-Robert M√ºller"
    },
    {
      "index": 35,
      "title": "Approximation of dynamical systems by continuous time recurrent neural networks",
      "abstract": "",
      "year": "1993",
      "venue": "Neural networks",
      "authors": "Ken-ichi Funahashi and Yuichi Nakamura"
    },
    {
      "index": 36,
      "title": "Latent ordinary differential equations for irregularly-sampled time series",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Yulia Rubanova, Tian Qi Chen, and David K Duvenaud"
    },
    {
      "index": 37,
      "title": "Neural Ordinary Differential Equations",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in neural information processing systems",
      "authors": "Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud",
      "orig_title": "Neural ordinary differential equations",
      "paper_id": "1806.07366v5"
    },
    {
      "index": 38,
      "title": "Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "Sachin Kumar and Yulia Tsvetkov",
      "orig_title": "Von mises-fisher loss for training sequence to sequence models with continuous outputs",
      "paper_id": "1812.04616v3"
    },
    {
      "index": 39,
      "title": "On the Relationship between Self-Attention and Convolutional Layers",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "Jean-Baptiste Cordonnier, Andreas Loukas, and Martin Jaggi",
      "orig_title": "On the relationship between self-attention and convolutional layers",
      "paper_id": "1911.03584v2"
    },
    {
      "index": 40,
      "title": "Hard-Coded Gaussian Attention for Neural Machine Translation",
      "abstract": "",
      "year": "2020",
      "venue": "Annual Meeting of the Association for Computational Linguistics",
      "authors": "Weiqiu You, Simeng Sun, and Mohit Iyyer",
      "orig_title": "Hard-coded Gaussian attention for neural machine translation",
      "paper_id": "2005.00742v1"
    },
    {
      "index": 41,
      "title": "DRAW: A Recurrent Neural Network For Image Generation",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Machine Learning",
      "authors": "Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Rezende, and Daan Wierstra",
      "orig_title": "Draw: A recurrent neural network for image generation",
      "paper_id": "1502.04623v2"
    },
    {
      "index": 42,
      "title": "Attention is not explanation",
      "abstract": "",
      "year": "2019",
      "venue": "NAACL-HLT",
      "authors": "Sarthak Jain and Byron C Wallace"
    },
    {
      "index": 43,
      "title": "Is Attention Interpretable?",
      "abstract": "",
      "year": "2019",
      "venue": "ACL",
      "authors": "Sofia Serrano and Noah A Smith",
      "orig_title": "Is attention interpretable?",
      "paper_id": "1906.03731v1"
    },
    {
      "index": 44,
      "title": "Attention is not not explanation",
      "abstract": "",
      "year": "2019",
      "venue": "EMNLP-IJCNLP",
      "authors": "Sarah Wiegreffe and Yuval Pinter"
    },
    {
      "index": 45,
      "title": "Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE International Conference on Computer Vision",
      "authors": "Tianlu Wang, Jieyu Zhao, Mark Yatskar, Kai-Wei Chang, and Vicente Ordonez",
      "orig_title": "Balanced datasets are not enough: Estimating and mitigating gender bias in deep image representations",
      "paper_id": "1811.08489v4"
    },
    {
      "index": 46,
      "title": "Energy and Policy Considerations for Deep Learning in NLP",
      "abstract": "",
      "year": "2019",
      "venue": "Annual Meeting of the Association for Computational Linguistics",
      "authors": "Emma Strubell, Ananya Ganesh, and Andrew McCallum",
      "orig_title": "Energy and policy considerations for deep learning in nlp",
      "paper_id": "1906.02243v1"
    },
    {
      "index": 47,
      "title": "Convex Analysis and Monotone Operator Theory in Hilbert Spaces",
      "abstract": "",
      "year": "2011",
      "venue": "Springer",
      "authors": "Heinz Bauschke and Patrick Combettes"
    },
    {
      "index": 48,
      "title": "The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming",
      "abstract": "",
      "year": "1967",
      "venue": "USSR Computational Mathematics and Mathematical Physics",
      "authors": "Lev M Bregman"
    },
    {
      "index": 49,
      "title": "Geometry of escort distributions",
      "abstract": "",
      "year": "2003",
      "venue": "Physical Review E",
      "authors": "Sumiyoshi Abe"
    },
    {
      "index": 50,
      "title": "Information theory and statistical mechanics",
      "abstract": "",
      "year": "1957",
      "venue": "Physical review",
      "authors": "Edwin T Jaynes"
    },
    {
      "index": 51,
      "title": "Neural machine translation of rare words with subword units",
      "abstract": "",
      "year": "2016",
      "venue": "ACL",
      "authors": "Rico Sennrich, Barry Haddow, and Alexandra Birch"
    },
    {
      "index": 52,
      "title": "Joey nmt: A minimalist nmt toolkit for novices",
      "abstract": "",
      "year": "2019",
      "venue": "EMNLP-IJCNLP: System Demonstrations",
      "authors": "Julia Kreutzer, Joost Bastings, and Stefan Riezler"
    },
    {
      "index": 53,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 54,
      "title": "ImageNet Large Scale Visual Recognition Challenge",
      "abstract": "",
      "year": "2015",
      "venue": "International Journal of Computer Vision",
      "authors": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei",
      "orig_title": "ImageNet Large Scale Visual Recognition Challenge",
      "paper_id": "1409.0575v3"
    },
    {
      "index": 55,
      "title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
      "authors": "Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, and Lei Zhang",
      "orig_title": "Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering",
      "paper_id": "1707.07998v3"
    },
    {
      "index": 56,
      "title": "Glove: Global vectors for word representation",
      "abstract": "",
      "year": "2014",
      "venue": "EMNLP",
      "authors": "Jeffrey Pennington, Richard Socher, and Christopher D. Manning"
    }
  ]
}