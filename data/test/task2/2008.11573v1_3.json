{
  "paper_id": "2008.11573v1",
  "title": "Proof.",
  "sections": {
    "i-a preliminaries": "We study sentiment analysis problem in multi-label setting, which has been widely studied in the literature due to its significance in various applications including market research, politics, public health and disaster management   . In particular, we introduce a method for cross-lingual sentiment analysis, which is a harder problem than the standard sentiment analysis problem since one needs to make predictions for various languages including even unseen ones. Cross-lingual sentiment analysis aims to leverage high-quality and abundant resources in English for classification to improve the classification performance of resource-scarce languages . Moreover, we employ data of three languages to obtain the best score in 7 of 9 metrics of Arabic, English and Spanish languages in the SemEval emotion classification . Plutchik [ref]5, in 1980, has created the wheel of emotions in his psychoevolutionary theory of emotion to illustrate his idea of emotion, which is shown in Fig. 1. He suggests eight bipolar primary emotions that appear on the opposite sides of the wheel: joy versus sadness, anger versus fear, disgust versus trust, surprise versus anticipation. The primary emotions are expressed at different intensities and the intermediate emotions occur as a mix of these primary emotions. Moreover, the emotions are non-exclusive in Plutchik’s model as their combinations derive other emotions, and there exist correlations between the emotions, e.g., joy and sadness are represented as the opposite emotions. Following the Plutchik’s theory [ref]5, we formulate the sentiment analysis as the multi-label classification task, in which more than one label can be assigned to a text simultaneously. Yet, the class imbalance is an inherent issue in multi-label classification . Although the class imbalance has been extensively studied for the binary classification setting, it remains a challenge in multi-label classification\n . Furthermore, the tail labels, i.e., the labels with a low number of instances, impact the performance significantly less compared to the common labels when the classes are equally weighted in the multi-label setting due to the rarity of relevant examples and result in suboptimal performance [ref]7. Thus, we introduce a dynamic weighting method to dynamically adjust the class weights during training to remedy the class imbalance. In this article, we introduce a multilingual sentiment analysis framework in multi-label setting on 100 different languages. Our method uses focal loss to enhance the importance of hard examples. We introduce a dynamic weighting method to cope with the label imbalance. We also derive a macro-f1 maximization method within linear time complexity. Our method achieves the best result for 7 out of 9 metrics for the SemEval competition for Arabic, English and Spanish languages . We also demonstrate the performance of our method on cross-lingual combinations of the datasets and assess the performance gains obtained by the components in our method."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Semeval-2018 task 1: Affect in tweets",
      "abstract": "",
      "year": "2018",
      "venue": "International Workshop on Semantic Evaluation (Semeval-2018)",
      "authors": "S. M. Mohammad, F. Bravo-Marquez, M. Salameh, and S. Kiritchenko"
    },
    {
      "index": 1,
      "title": "Sentivec: Learning sentiment-context vector via kernel optimization function for sentiment analysis",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "L. Zhu, W. Li, Y. Shi, and K. Guo"
    },
    {
      "index": 2,
      "title": "Sentiment analysis and opinion mining",
      "abstract": "",
      "year": "2012",
      "venue": "Synthesis Lectures on Human Language Technologies",
      "authors": "B. Liu"
    },
    {
      "index": 3,
      "title": "Coarse alignment of topic and sentiment: A unified model for cross-lingual sentiment classification",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "D. Wang, B. Jing, C. Lu, J. Wu, G. Liu, C. Du, and F. Zhuang"
    },
    {
      "index": 4,
      "title": "A general psychoevolutionary theory of emotion",
      "abstract": "",
      "year": "1980",
      "venue": "Theories of Emotion",
      "authors": "R. Plutchik"
    },
    {
      "index": 5,
      "title": "A Survey on Multi-output Learning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "D. Xu, Y. Shi, I. W. Tsang, Y.-S. Ong, C. Gong, and X. Shen",
      "orig_title": "Survey on multi-output learning",
      "paper_id": "1901.00248v2"
    },
    {
      "index": 6,
      "title": "Does tail label help for large-scale multi-label learning?",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "authors": "T. Wei and Y.-F. Li"
    },
    {
      "index": 7,
      "title": "Deep Learning",
      "abstract": "",
      "year": "2015",
      "venue": "Nature",
      "authors": "Y. LeCun, Y. Bengio, and G. Hinton",
      "orig_title": "Deep learning",
      "paper_id": "1807.07987v2"
    },
    {
      "index": 8,
      "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm",
      "abstract": "",
      "year": "2017",
      "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP)",
      "authors": "B. Felbo, A. Mislove, A. Søgaard, I. Rahwan, and S. Lehmann",
      "orig_title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm",
      "paper_id": "1708.00524v2"
    },
    {
      "index": 9,
      "title": "Practical Text Classification With Large Pre-Trained Language Models",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1812.01207",
      "authors": "N. Kant, R. Puri, N. Yakovenko, and B. Catanzaro",
      "orig_title": "Practical text classification with large pre-trained language models",
      "paper_id": "1812.01207v1"
    },
    {
      "index": 10,
      "title": "Distant supervision for emotion classification with discrete binary values",
      "abstract": "",
      "year": "2013",
      "venue": "International Conference on Intelligent Text Processing and Computational Linguistics",
      "authors": "J. Suttles and N. Ide"
    },
    {
      "index": 11,
      "title": "Learning deep representation for imbalanced classification",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "C. Huang, Y. Li, C. Change Loy, and X. Tang"
    },
    {
      "index": 12,
      "title": "Class-Balanced Loss Based on Effective Number of Samples",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Y. Cui, M. Jia, T.-Y. Lin, Y. Song, and S. Belongie",
      "orig_title": "Class-balanced loss based on effective number of samples",
      "paper_id": "1901.05555v1"
    },
    {
      "index": 13,
      "title": "Learning from imbalanced data sets with weighted cross-entropy function",
      "abstract": "",
      "year": "2019",
      "venue": "Neural Processing Letters",
      "authors": "Y. S. Aurelio, G. M. de Almeida, C. L. de Castro, and A. P. Braga"
    },
    {
      "index": 14,
      "title": "Focal Loss for Dense Object Detection",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE International Conference on Computer Vision",
      "authors": "T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár",
      "orig_title": "Focal loss for dense object detection",
      "paper_id": "1708.02002v2"
    },
    {
      "index": 15,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1810.04805",
      "authors": "J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova",
      "orig_title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 16,
      "title": "Unsupervised Cross-lingual Representation Learning at Scale",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1911.02116",
      "authors": "A. Conneau, K. Khandelwal, N. Goyal, V. Chaudhary, G. Wenzek, F. Guzmán, E. Grave, M. Ott, L. Zettlemoyer, and V. Stoyanov",
      "orig_title": "Unsupervised cross-lingual representation learning at scale",
      "paper_id": "1911.02116v2"
    },
    {
      "index": 17,
      "title": "Ema at semeval-2018 task 1: Emotion mining for arabic",
      "abstract": "",
      "year": "2018",
      "venue": "The 12th International Workshop on Semantic Evaluation",
      "authors": "G. Badaro, O. El Jundi, A. Khaddaj, A. Maarouf, R. Kain, H. Hajj, and W. El-Hajj"
    },
    {
      "index": 18,
      "title": "NTUA-SLP at SemEval-2018 Task 1: Predicting Affective Content in Tweets with Deep Attentive RNNs and Transfer Learning",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1804.06658",
      "authors": "C. Baziotis, N. Athanasiou, A. Chronopoulou, A. Kolovou, G. Paraskevopoulos, N. Ellinas, S. Narayanan, and A. Potamianos",
      "orig_title": "Ntua-slp at semeval-2018 task 1: Predicting affective content in tweets with deep attentive rnns and transfer learning",
      "paper_id": "1804.06658v1"
    },
    {
      "index": 19,
      "title": "Psyml at semeval-2018 task 1: Transfer learning for sentiment and emotion analysis",
      "abstract": "",
      "year": "2018",
      "venue": "The 12th International Workshop on Semantic Evaluation",
      "authors": "G. Gee and E. Wang"
    },
    {
      "index": 20,
      "title": "Aravec: A set of arabic word embedding models for use in arabic nlp",
      "abstract": "",
      "year": "2017",
      "venue": "Procedia Computer Science",
      "authors": "A. B. Mohammad, K. Eissa, and S. El-Beltagy"
    },
    {
      "index": 21,
      "title": "Tw-star at semeval-2018 task 1: Preprocessing impact on multi-label emotion classification",
      "abstract": "",
      "year": "2018",
      "venue": "The 12th International Workshop on Semantic Evaluation",
      "authors": "H. Mulki, C. B. Ali, H. Haddad, and I. Babaoğlu"
    },
    {
      "index": 22,
      "title": "Natural language processing (almost) from scratch",
      "abstract": "",
      "year": "2011",
      "venue": "Journal of Machine Learning Research",
      "authors": "R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa"
    },
    {
      "index": 23,
      "title": "Nistributed representations of words and phrases and their compositionality",
      "abstract": "",
      "year": "2013",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean"
    },
    {
      "index": 24,
      "title": "Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1808.06226",
      "authors": "T. Kudo and J. Richardson"
    },
    {
      "index": 25,
      "title": "Finding structure in time",
      "abstract": "",
      "year": "1990",
      "venue": "Cognitive Science",
      "authors": "J. L. Elman"
    },
    {
      "index": 26,
      "title": "Long short-term memory",
      "abstract": "",
      "year": "1997",
      "venue": "Neural Computation",
      "authors": "S. Hochreiter and J. Schmidhuber"
    },
    {
      "index": 27,
      "title": "Hierarchical attention networks for document classification",
      "abstract": "",
      "year": "2016",
      "venue": "The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
      "authors": "Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy"
    },
    {
      "index": 28,
      "title": "Smart Mining for Deep Metric Learning",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE International Conference on Computer Vision",
      "authors": "B. Harwood, V. Kumar BG, G. Carneiro, I. Reid, and T. Drummond",
      "orig_title": "Smart mining for deep metric learning",
      "paper_id": "1704.01285v3"
    },
    {
      "index": 29,
      "title": "Enriching Word Vectors with Subword Information",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1607.04606",
      "authors": "P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov",
      "orig_title": "Enriching word vectors with subword information",
      "paper_id": "1607.04606v2"
    },
    {
      "index": 30,
      "title": "A context integrated model for multi-label emotion detection",
      "abstract": "",
      "year": "2018",
      "venue": "Procedia Computer Science",
      "authors": "A. E. Samy, S. R. El-Beltagy, and E. Hassanien"
    },
    {
      "index": 31,
      "title": "Hybrid feature model for emotion recognition in arabic text",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Access",
      "authors": "N. Alswaidan and M. E. B. Menai"
    },
    {
      "index": 32,
      "title": "Elirf-upv at irosva: Transformer encoders for spanish irony detection",
      "abstract": "",
      "year": "2019",
      "venue": "IberLEF@SEPLN",
      "authors": "J.-Á. González, L.-F. Hurtado, and F. Pla"
    },
    {
      "index": 33,
      "title": "Optuna: A Next-generation Hyperparameter Optimization Framework",
      "abstract": "",
      "year": "2019",
      "venue": "ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
      "authors": "T. Akiba, S. Sano, T. Yanase, T. Ohta, and M. Koyama",
      "orig_title": "Optuna: A next-generation hyperparameter optimization framework",
      "paper_id": "1907.10902v1"
    },
    {
      "index": 34,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1412.6980",
      "authors": "D. P. Kingma and J. Ba"
    },
    {
      "index": 35,
      "title": "Generating semantic similarity atlas for natural languages",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Spoken Language Technology Workshop (SLT)",
      "authors": "L. K. Senel, İ. Utlu, V. Yücesoy, A. Koc, and T. Cukur"
    },
    {
      "index": 36,
      "title": "Deep learning for extreme multi-label text classification",
      "abstract": "",
      "year": "2017",
      "venue": "International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "authors": "J. Liu, W.-C. Chang, Y. Wu, and Y. Yang"
    }
  ]
}