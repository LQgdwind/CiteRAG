{
  "paper_id": "2301.09619v1",
  "title": "Asymptotic Convergence and Performance of Multi-Agent Q-learning Dynamics",
  "sections": {
    "introduction": "Understanding the behaviour of multi-agent learning systems has been a hallmark problem of game theory and online\nlearning. The requirement is that agents must explore potentially sub-optimal decisions whilst interacting with\nother agents to ultimately maximise their long-term reward. In contrast to online learning with a single agent,\nthis poses a fundamentally non-stationary problem, in which convergence to an equilibrium is not always\nguaranteed. In fact, recent work has consistently found that, when learning on games, agents may present a wide array of\nbehaviours. This includes cycles   , and even chaos    [ref]7 [ref]8. Furthermore, the equilibria of\na game need not be unique, so even if convergence is guaranteed, it may be to one of many (or even a continuum) of\nequilibria. Thus, predicting the behaviour of online learning in games with many players becomes a particularly\nchallenging problem. Yet it remains an important problem to solve. Recent advances in machine learning require training multiple neural\nnetworks for applications to generative models [ref]9 0. In order for such applications to be\nrealised, it is required that that training provably converges to an equilibrium. Of equal importance is that this\nequilibrium be unique, so that the outcome remains consistent regardless of initial conditions.\nA unique equilibrium guarantees not only the reproducibility of the system, but also ensures that desired behaviours will persist, even if the system is perturbed from its desired state.\nSimilarly, the most complex tasks often require the interaction of multiple autonomous agents 1. This again\nrequires that agents are able to reliably equilibrate their behaviour. There is a strong, and ongoing, effort in the research community to understand these learning behaviours, with\npositive convergence results being found in an assortment of game structures. For instance, games with two players\nand two actions are well understood 2 3 4. Beyond this, some of the most\nwidely studied games are potential games, in which agents collaborate to maximise a shared global function, and\nzero sum games (and its network variants), in which agents are in competition. Indeed, it has been found that a\nnumber of learning algorithms, including Fictitious Play 5, Q-Learning 6 7 , Replicator Dynamics 8 9 0 all converge to equilibria (though not always unique) in potential\ngames 1 2. In zero sum games, the former two converge to a unique fixed\npoint 3 4, whereas the latter is known to cycle, always maintaining its distance\nfrom the equilibrium . Outside of this class of games, however, the story becomes much more complicated. A wide array of results show\nlearning algorithms may be chaotic in even the simplest games . Such complex behaviours become even\nmore pronounced as the number of agents in the game increases [ref]7. However, they are also\ninfluenced by the structure of the game and the parameters of the learning algorithm 5. This dichotomy between the range of possible learning behaviours and the convergence\nrequirement of the applications motivate our central question: Are there learning dynamics such that convergence to a unique equilibrium is guaranteed in any game?"
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Cycles in adversarial regularized learning",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "P. Mertikopoulos, C. Papadimitriou, and G. Piliouras",
      "orig_title": "Cycles in adversarial regularized learning",
      "paper_id": "1709.02738v1"
    },
    {
      "index": 1,
      "title": "Poincaré-Bendixson Limit Sets in Multi-Agent Learning; Poincaré-Bendixson Limit Sets in Multi-Agent Learning",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Autonomous Agents and Multiagent Systems",
      "authors": "A. Czechowski and G. Piliouras"
    },
    {
      "index": 2,
      "title": "Cycles of cooperation and defection in imperfect learning",
      "abstract": "",
      "year": "2011",
      "venue": "Journal of Statistical Mechanics: Theory and Experiment",
      "authors": "T. Galla"
    },
    {
      "index": 3,
      "title": "Coupled replicator equations for the dynamics of learning in multiagent systems",
      "abstract": "",
      "year": "2003",
      "venue": "Physical Review E",
      "authors": "Y. Sato and J. P. Crutchfield"
    },
    {
      "index": 4,
      "title": "Chaos in learning a simple two-person game",
      "abstract": "",
      "year": "2002",
      "venue": "National Academy of Sciences of the United States of America",
      "authors": "Y. Sato, E. Akiyama, and J. D. Farmer"
    },
    {
      "index": 5,
      "title": "Complex dynamics in learning complicated games",
      "abstract": "",
      "year": "2013",
      "venue": "National Academy of Sciences of the United States of America",
      "authors": "T. Galla and J. D. Farmer"
    },
    {
      "index": 6,
      "title": "The prevalence of chaotic dynamics in games with many players",
      "abstract": "",
      "year": "2018",
      "venue": "Scientific Reports",
      "authors": "J. B. T. Sanders, J. D. Farmer, and T. Galla"
    },
    {
      "index": 7,
      "title": "Learning in Matrix Games can be Arbitrarily Complex",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "G. P. Andrade, R. Frongillo, M. Belkin, and S. Kpotufe",
      "orig_title": "Learning in Matrix Games can be Arbitrarily Complex",
      "paper_id": "2103.03405v1"
    },
    {
      "index": 8,
      "title": "Mode Regularized Generative Adversarial Networks",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Learning Representations",
      "authors": "T. Che, Y. Li, A. Paul Jacob, Y. Bengio, and W. Li",
      "orig_title": "Mode Regularized Generative Adversarial Networks",
      "paper_id": "1612.02136v5"
    },
    {
      "index": 9,
      "title": "MGAN: Training Generative Adversarial Nets with Multiple Generators",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Learning Representations",
      "authors": "Q. Hoang, T. D. Nguyen, T. Le, and D. Phung",
      "orig_title": "MGAN: Training Generative Adversarial Nets with Multiple Generators",
      "paper_id": "1708.02556v4"
    },
    {
      "index": 10,
      "title": "Swarm Robotics: A Formal Approach",
      "abstract": "",
      "year": "2018",
      "venue": "Springer International Publishing",
      "authors": "H. Hamann"
    },
    {
      "index": 11,
      "title": "Towards a taxonomy of learning dynamics in 2 × 2 games",
      "abstract": "",
      "year": "2022",
      "venue": "Games and Economic Behavior",
      "authors": "M. Pangallo, J. B. Sanders, T. Galla, and J. D. Farmer"
    },
    {
      "index": 12,
      "title": "Fictitious play in 2 • 2 games: a geometric proof of convergence*",
      "abstract": "",
      "year": "1994",
      "venue": "Econ. Theory",
      "authors": "A. I. Metrick and B. Polak"
    },
    {
      "index": 13,
      "title": "Dynamics of Boltzmann Q learning in two-player two-action games",
      "abstract": "",
      "year": "2012",
      "venue": "Physical Review E - Statistical, Nonlinear, and Soft Matter Physics",
      "authors": "A. Kianercy and A. Galstyan"
    },
    {
      "index": 14,
      "title": "Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations",
      "abstract": "",
      "year": "2008",
      "venue": "Cambridge University Press",
      "authors": "Y. Shoham and K. Leyton-Brown"
    },
    {
      "index": 15,
      "title": "Reinforcement Learning: An Introduction",
      "abstract": "",
      "year": "2018",
      "venue": "MIT Press",
      "authors": "R. Sutton and A. Barto"
    },
    {
      "index": 16,
      "title": "An evolutionary dynamical analysis of multi-agent learning in iterated games",
      "abstract": "",
      "year": "2006",
      "venue": "",
      "authors": "K. Tuyls, P. J. T Hoen, and B. Vanschoenwinkel"
    },
    {
      "index": 17,
      "title": "The theory of games and the evolution of animal conflicts",
      "abstract": "",
      "year": "1974",
      "venue": "Journal of Theoretical Biology",
      "authors": "J. Maynard Smith"
    },
    {
      "index": 18,
      "title": "Evolutionary Game Dynamics",
      "abstract": "",
      "year": "2003",
      "venue": "BULLETIN (New Series) OF THE AMERICAN MATHEMATICAL SOCIETY",
      "authors": "J. Hofbauer and K. Sigmund"
    },
    {
      "index": 19,
      "title": "Evolutionary Games and Population Dynamics",
      "abstract": "",
      "year": "1998",
      "venue": "Cambridge University Press",
      "authors": "J. Hofbauer and K. Sigmund"
    },
    {
      "index": 20,
      "title": "On the Rate of Convergence of Continuous-Time Fictitious Play",
      "abstract": "",
      "year": "1998",
      "venue": "Games and Economic Behavior",
      "authors": "C. Harris"
    },
    {
      "index": 21,
      "title": "Exploration-exploitation in multi-agent learning: Catastrophe theory meets game theory",
      "abstract": "",
      "year": "2022",
      "venue": "Artificial Intelligence",
      "authors": "S. Leonardos and G. Piliouras"
    },
    {
      "index": 22,
      "title": "Fictitious play in networks",
      "abstract": "",
      "year": "2020",
      "venue": "Games and Economic Behavior",
      "authors": "C. Ewerhart and K. Valkanova"
    },
    {
      "index": 23,
      "title": "Exploration-Exploitation in Multi-Agent Competition: Convergence with Bounded Rationality",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "S. Leonardos, G. Piliouras, and K. Spendlove",
      "orig_title": "Exploration-Exploitation in Multi-Agent Competition: Convergence with Bounded Rationality",
      "paper_id": "2106.12928v1"
    },
    {
      "index": 24,
      "title": "Best reply structure and equilibrium convergence in generic games",
      "abstract": "",
      "year": "2019",
      "venue": "Science Advances",
      "authors": "M. Pangallo, T. Heinrich, and J. D. Farmer"
    },
    {
      "index": 25,
      "title": "A variational inequality framework for network games: Existence, uniqueness, convergence and sensitivity analysis",
      "abstract": "",
      "year": "2019",
      "venue": "Games and Economic Behavior",
      "authors": "F. Parise and A. Ozdaglar"
    },
    {
      "index": 26,
      "title": "Exponential Convergence of Gradient Methods in Concave Network Zero-Sum Games",
      "abstract": "",
      "year": "2021",
      "venue": "Lecture Notes in Computer Science",
      "authors": "A. Kadan and H. Fu"
    },
    {
      "index": 27,
      "title": "Learning Nash Equilibria in Monotone Games",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Decision and Control",
      "authors": "T. Tatarenko and M. Kamgarpour",
      "orig_title": "Learning Nash Equilibria in Monotone Games",
      "paper_id": "1904.01882v1"
    },
    {
      "index": 28,
      "title": "A Variational Approach to Network Games",
      "abstract": "",
      "year": "2018",
      "venue": "SSRN Electronic Journal",
      "authors": "E. Melo"
    },
    {
      "index": 29,
      "title": "On the Uniqueness of Quantal Response Equilibria and Its Application to Network Games",
      "abstract": "",
      "year": "2021",
      "venue": "SSRN Electronic Journal",
      "authors": "E. Melo"
    },
    {
      "index": 30,
      "title": "Finite-Dimensional Variational Inequalities and Complementarity Problems",
      "abstract": "",
      "year": "2004",
      "venue": "Finite-Dimensional Variational Inequalities and Complementarity Problems",
      "authors": "F. Facchinei and J. S. Pang"
    },
    {
      "index": 31,
      "title": "Learning in games with continuous action sets and unknown payoff functions",
      "abstract": "",
      "year": "2019",
      "venue": "Mathematical Programming",
      "authors": "P. Mertikopoulos and Z. Zhou"
    },
    {
      "index": 32,
      "title": "Bandit Learning in Convex Non-Strictly Monotone Games",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv e-prints",
      "authors": "T. Tatarenko and M. Kamgarpour"
    },
    {
      "index": 33,
      "title": "Penalty-Regulated Dynamics and Robust Learning Procedures in Games",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "P. Coucheney, B. Gaujal, and P. Mertikopoulos"
    },
    {
      "index": 34,
      "title": "Robust Power Management via Learning and Game Design",
      "abstract": "",
      "year": "2021",
      "venue": "Operations Research",
      "authors": "Z. Zhou, P. Mertikopoulos, A. L. Moustakas, N. Bambos, and P. Glynn"
    },
    {
      "index": 35,
      "title": "Gradient-free Online Learning in Games with Delayed Rewards",
      "abstract": "",
      "year": "2020",
      "venue": "37th International Conference on Machine Learning, ICML’20",
      "authors": "A. Héliou, P. Mertikopoulos, and Z. Zhou",
      "orig_title": "Gradient-Free Online Learning in Games with Delayed Rewards",
      "paper_id": "2006.10911v1"
    },
    {
      "index": 36,
      "title": "NO-REGRET LEARNING AND MIXED NASH EQUILIBRIA: THEY DO NOT MIX",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "E.-V. Vlatakis-Gkaragkounis, L. Flokas, T. Lianeas, P. Mertikopoulos, and G. Piliouras",
      "orig_title": "No-Regret Learning and Mixed Nash Equilibria: They Do Not Mix",
      "paper_id": "2010.09514v2"
    },
    {
      "index": 37,
      "title": "LEARNING IN NONATOMIC GAMES, PART I: FINITE ACTION SPACES AND POPULATION GAMES",
      "abstract": "",
      "year": "2022",
      "venue": "Journal of Dynamics and Games",
      "authors": "S. Hadikhanloo, R. Laraki, P. Mertikopoulos, and S. Sorin",
      "orig_title": "Learning in nonatomic games part I Finite action spaces and population games",
      "paper_id": "2107.01595v1"
    },
    {
      "index": 38,
      "title": "Learning in games via reinforcement and regularization",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "P. Mertikopoulos and W. H. Sandholm",
      "orig_title": "Learning in Games via Reinforcement and Regularization",
      "paper_id": "1407.6267v2"
    },
    {
      "index": 39,
      "title": "Behavioural game theory: Thinking, learning and teaching",
      "abstract": "",
      "year": "2004",
      "venue": "Advances in Understanding Strategic Behaviour: Game Theory, Experiments and Bounded Rationality",
      "authors": "C. F. Camerer, T. H. Ho, and J. K. Chong"
    },
    {
      "index": 40,
      "title": "Experience-weighted attraction learning in normal form games",
      "abstract": "",
      "year": "1999",
      "venue": "Econometrica",
      "authors": "C. Camerer and T. H. Ho"
    },
    {
      "index": 41,
      "title": "Online Learning and Online Convex Optimization",
      "abstract": "",
      "year": "2011",
      "venue": "Foundations and Trends in Machine Learning",
      "authors": "S. Shalev-Shwartz"
    },
    {
      "index": 42,
      "title": "Finite composite games: Equilibria and dynamics",
      "abstract": "",
      "year": "2016",
      "venue": "Journal of Dynamics and Games",
      "authors": "S. Sorin and C. Wan"
    },
    {
      "index": 43,
      "title": "Payoff performance of fictitious play",
      "abstract": "",
      "year": "2014",
      "venue": "Journal of Dynamics and Games",
      "authors": "G. Ostrovski and S. van Strien"
    },
    {
      "index": 44,
      "title": "Beyond the Nash Equilibrium Barrier",
      "abstract": "",
      "year": "2011",
      "venue": "Innovations in Computer Science",
      "authors": "R. Kleinberg, K. Ligett, G. Piliouras, and E. Tardos"
    },
    {
      "index": 45,
      "title": "On Last-Iterate Convergence Beyond Zero-Sum Games",
      "abstract": "",
      "year": "2022",
      "venue": "39th International Conference on Machine Learning",
      "authors": "I. Anagnostides, I. Panageas, G. Farina, and T. Sandholm",
      "orig_title": "On Last-Iterate Convergence Beyond Zero-Sum Games",
      "paper_id": "2203.12056v1"
    },
    {
      "index": 46,
      "title": "Best response dynamics for continuous zero–sum games",
      "abstract": "",
      "year": "2005",
      "venue": "Discrete and Continuous Dynamical Systems - B",
      "authors": "J. Hofbauer and S. Sorin"
    },
    {
      "index": 47,
      "title": "Some Topics in Two-Person Games",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in Game Theory. (AM-52)",
      "authors": "L. S. Shapley"
    },
    {
      "index": 48,
      "title": "Mutation-Driven Follow the Regularized Leader for Last-Iterate Convergence in Zero-Sum Games",
      "abstract": "",
      "year": "2022",
      "venue": "Conference on Uncertainty in Artificial Intelligence",
      "authors": "K. Abe, M. Sakamoto, and A. Iwasaki",
      "orig_title": "Mutation-Driven Follow the Regularized Leader for Last-Iterate Convergence in Zero-Sum Games",
      "paper_id": "2206.09254v1"
    }
  ]
}