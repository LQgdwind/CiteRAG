{
  "paper_id": "2002.10451v2",
  "title": "Neural Lyapunov Model Predictive Control: Learning Safe Global Controllers from Sub-optimal Examples",
  "sections": {
    "v related work": "Stability and robustness of MPC and of discounted optimal control have been studied in several prior works¬†   [ref]20  . Numerical stability verification was studied in [ref]5  and, using neural network Lyapunov functions in  [ref]8. Neural Lyapunov controllers were also trained in . MPC solvers based on iterative LQR (iLQR) were introduced in . Sequential Quadratic Program (SQP) was studied in .\nNNs with structural priors have been studied in   .\nValue functions for planning were learned in   .\n[ref]8 learned a NN Lyapunov function and an NN policy with an alternating descent method, initialized using a known stabilizing policy. We remove this assumption and use MPC.\n\nSuboptimality was analysed in¬† for MPC and in 4 for policies. AWR  seeks positive advantage only during the policy update, not for the critic. Gaussian processes models have been studied in¬† ."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Concrete Problems in AI Safety",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1606.06565",
      "authors": "D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman, and D. Man√©",
      "orig_title": "Concrete problems in ai safety",
      "paper_id": "1606.06565v2"
    },
    {
      "index": 1,
      "title": "Model-based reinforcement learning: A survey",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2006.16712",
      "authors": "T. M. Moerland, J. Broekens, and C. M. Jonker"
    },
    {
      "index": 2,
      "title": "Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1811.01848",
      "authors": "K. Lowrey, A. Rajeswaran, S. Kakade, E. Todorov, and I. Mordatch",
      "orig_title": "Plan online, learn offline: Efficient learning and exploration via model-based control",
      "paper_id": "1811.01848v3"
    },
    {
      "index": 3,
      "title": "Nonlinear Control",
      "abstract": "",
      "year": "2014",
      "venue": "Pearson",
      "authors": "H. K. Khalil"
    },
    {
      "index": 4,
      "title": "Sampling driven stability domains computation and predictive control of constrained nonlinear systems",
      "abstract": "",
      "year": "2017",
      "venue": "Ph.D. dissertation",
      "authors": "R. V. Bobiti"
    },
    {
      "index": 5,
      "title": "Sampling‚Äìbased verification of Lyapunov‚Äôs inequality for piecewise continuous nonlinear systems",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1609.00302",
      "authors": "R. Bobiti and M. Lazar",
      "orig_title": "Sampling-based verification of lyapunov‚Äôs inequality for piecewise continuous nonlinear systems",
      "paper_id": "1609.00302v1"
    },
    {
      "index": 6,
      "title": "Safe Model-based Reinforcement Learning with Stability Guarantees",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1705.08551",
      "authors": "F. Berkenkamp, M. Turchetta, A. P. Schoellig, and A. Krause",
      "orig_title": "Safe model-based reinforcement learning with stability guarantees",
      "paper_id": "1705.08551v3"
    },
    {
      "index": 7,
      "title": "Safe Interactive Model-Based Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1911.06556",
      "authors": "M. Gallieri, S. S. M. Salehian, N. E. Toklu, A. Quaglino, J. Masci, J. Koutn√≠k, and F. Gomez",
      "orig_title": "Safe interactive model-based learning",
      "paper_id": "1911.06556v2"
    },
    {
      "index": 8,
      "title": "Neural Lyapunov Control",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2005.00611",
      "authors": "Y.-C. Chang, N. Roohi, and S. Gao",
      "orig_title": "Neural lyapunov control",
      "paper_id": "2005.00611v4"
    },
    {
      "index": 9,
      "title": "Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1910.00177",
      "authors": "X. B. Peng, A. Kumar, G. Zhang, and S. Levine",
      "orig_title": "Advantage-weighted regression: Simple and scalable off-policy reinforcement learning",
      "paper_id": "1910.00177v3"
    },
    {
      "index": 10,
      "title": "Set-Theoretic Methods in Control (Systems & Control: Foundations & Applications)",
      "abstract": "",
      "year": "2007",
      "venue": "Birkh√§user",
      "authors": "F. Blanchini and S. Miani"
    },
    {
      "index": 11,
      "title": "Robust constraint satisfaction: Invariant sets and predictive control",
      "abstract": "",
      "year": "2000",
      "venue": "Ph.D. dissertation",
      "authors": "E. Kerrigan"
    },
    {
      "index": 12,
      "title": "Formal Synthesis of Lyapunov Neural Networks",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Control Systems Letters",
      "authors": "A. Abate, D. Ahmed, M. Giacobbe, and A. Peruffo",
      "orig_title": "Formal synthesis of lyapunov neural networks",
      "paper_id": "2003.08910v2"
    },
    {
      "index": 13,
      "title": "dreach: Œ¥ùõø\\delta-reachability analysis for hybrid systems",
      "abstract": "",
      "year": "2015",
      "venue": "Tools and Algorithms for the Construction and Analysis of Systems",
      "authors": "S. Kong, S. Gao, W. Chen, and E. Clarke"
    },
    {
      "index": 14,
      "title": "Echo State Networks: analysis, training and predictive control",
      "abstract": "",
      "year": "2019",
      "venue": "2019 18th European Control Conference (ECC)",
      "authors": "L. B. Armenio, E. Terzi, M. Farina, and R. Scattolini",
      "orig_title": "Echo state networks: analysis, training and predictive control",
      "paper_id": "1902.01618v1"
    },
    {
      "index": 15,
      "title": "Physics-informed echo state networks for chaotic systems forecasting",
      "abstract": "",
      "year": "2019",
      "venue": "Lecture Notes in Computer Science",
      "authors": "N. A. K. Doan, W. Polifke, and L. Magri"
    },
    {
      "index": 16,
      "title": "Using machine learning to replicate chaotic attractors and calculate lyapunov exponents from data",
      "abstract": "",
      "year": "2017",
      "venue": "Chaos: An Interdisciplinary Journal of Nonlinear Science",
      "authors": "J. Pathak, Z. Lu, B. R. Hunt, M. Girvan, and E. Ott"
    },
    {
      "index": 17,
      "title": "NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv:1804.07209 [cs, stat]",
      "authors": "M. Ciccone, M. Gallieri, J. Masci, C. Osendorfer, and F. Gomez",
      "orig_title": "NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations",
      "paper_id": "1804.07209v4"
    },
    {
      "index": 18,
      "title": "Constrained model predictive control: Stability and optimality",
      "abstract": "",
      "year": "2000",
      "venue": "Automatica",
      "authors": "D. Mayne, J. Rawlings, C. Rao, and P. Scokaert"
    },
    {
      "index": 19,
      "title": "Stable constrained MPC without terminal constraint",
      "abstract": "",
      "year": "2003",
      "venue": "American Control Conference",
      "authors": "D. Limon, T. Alamo, and E. Camacho"
    },
    {
      "index": 20,
      "title": "The Lyapunov Neural Network: Adaptive Stability Certification for Safe Learning of Dynamical Systems",
      "abstract": "",
      "year": "2018",
      "venue": "Conference on Robot Learning",
      "authors": "S. M. Richards, F. Berkenkamp, and A. Krause",
      "orig_title": "The lyapunov neural network: Adaptive stability certification for safe learning of dynamical systems",
      "paper_id": "1808.00924v2"
    },
    {
      "index": 21,
      "title": "Reinforcement learning: An introduction",
      "abstract": "",
      "year": "1998",
      "venue": "MIT press",
      "authors": "R. S. Sutton and A. G. Barto"
    },
    {
      "index": 22,
      "title": "Soft constraints and exact penalty functions in model predictive control",
      "abstract": "",
      "year": "2000",
      "venue": "UKACC International Conference",
      "authors": "E. C. Kerrigan and J. M. Maciejowski"
    },
    {
      "index": 23,
      "title": "Input-to-State Stability: A Unifying Framework for Robust Model Predictive Control",
      "abstract": "",
      "year": "2009",
      "venue": "Nonlinear Model Predictive Control",
      "authors": "D. Limon, T. Alamo, D. M. Raimondo, D. M. de la Pe√±a, J. M. Bravo, A. Ferramosca, and E. F. Camacho"
    },
    {
      "index": 24,
      "title": "LASSO-MPC ‚Äì Predictive Control with ‚Ñì_‚Äã1subscript‚Ñì_1\\ell_{\\_}1-Regularised Least Squares",
      "abstract": "",
      "year": "2016",
      "venue": "Springer-Verlag",
      "authors": "M. Gallieri"
    },
    {
      "index": 25,
      "title": "Lipschitz Continuity in Model-based Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "K. Asadi, D. Misra, and M. Littman",
      "orig_title": "Lipschitz continuity in model-based reinforcement learning",
      "paper_id": "1804.07193v3"
    },
    {
      "index": 26,
      "title": "Differentiable convex optimization layers",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1910.12430",
      "authors": "A. Agrawal, B. Amos, S. Barratt, S. Boyd, S. Diamond, and Z. Kolter"
    },
    {
      "index": 27,
      "title": "Differentiable MPC for End-to-end Planning and Control",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1810.13400",
      "authors": "B. Amos, I. D. J Rodriguez, J. Sacks, B. Boots, and J. Z. Kolter",
      "orig_title": "Differentiable mpc for end-to-end planning and control",
      "paper_id": "1810.13400v3"
    },
    {
      "index": 28,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1412.6980",
      "authors": "D. P. Kingma and J. Ba"
    },
    {
      "index": 29,
      "title": "Constrained Policy Optimization",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1705.10528",
      "authors": "J. Achiam, D. Held, A. Tamar, and P. Abbeel",
      "orig_title": "Constrained policy optimization",
      "paper_id": "1705.10528v1"
    },
    {
      "index": 30,
      "title": "Benchmarking Safe Exploration in Deep Reinforcement Learning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "A. Ray, J. Achiam, and D. Amodei"
    },
    {
      "index": 31,
      "title": "Proximal policy optimization algorithms",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1707.06347",
      "authors": "J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov"
    },
    {
      "index": 32,
      "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1801.01290",
      "authors": "T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine",
      "orig_title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
      "paper_id": "1801.01290v2"
    },
    {
      "index": 33,
      "title": "When to trust your model: Model-based policy optimization",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "M. Janner, J. Fu, M. Zhang, and S. Levine"
    },
    {
      "index": 34,
      "title": "Model Predictive Control Theory and Design",
      "abstract": "",
      "year": "2009",
      "venue": "Nob Hill Pub, Llc",
      "authors": "J. B. Rawlings and D. Q. Mayne"
    },
    {
      "index": 35,
      "title": "Homothetic tube model predictive control",
      "abstract": "",
      "year": "2012",
      "venue": "Automatica",
      "authors": "S. V. Rakoviƒá, B. Kouvaritakis, R. Findeisen, and M. Cannon"
    },
    {
      "index": 36,
      "title": "Stabilization with discounted optimal control",
      "abstract": "",
      "year": "2015",
      "venue": "Systems & Control Letters",
      "authors": "V. Gaitsgory, L. Gr√ºne, and N. Thatcher"
    },
    {
      "index": 37,
      "title": "Synthesis and stabilization of complex behaviors through online trajectory optimization",
      "abstract": "",
      "year": "2012",
      "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems",
      "authors": "Y. Tassa, T. Erez, and E. Todorov"
    },
    {
      "index": 38,
      "title": "Numerical optimization",
      "abstract": "",
      "year": "2006",
      "venue": "Springer Science & Business Media",
      "authors": "J. Nocedal and S. Wright"
    },
    {
      "index": 39,
      "title": "SNODE: Spectral Discretization of Neural ODEs for System Identification",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv:1906.07038 [cs]",
      "authors": "A. Quaglino, M. Gallieri, J. Masci, and J. Koutn√≠k"
    },
    {
      "index": 40,
      "title": "ODE2VAE: Deep generative second order ODEs with Bayesian neural networks",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv:1905.10994 [cs, stat]",
      "authors": "C. Yƒ±ldƒ±z, M. Heinonen, and H. L√§hdesm√§ki"
    },
    {
      "index": 41,
      "title": "Tustin neural networks: a class of recurrent nets for adaptive MPC of mechanical systems",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "S. Pozzoli, M. Gallieri, and R. Scattolini",
      "orig_title": "Tustin neural networks: a class of recurrent nets for adaptive MPC of mechanical systems",
      "paper_id": "1911.01310v1"
    },
    {
      "index": 42,
      "title": "Lvis: learning from value function intervals for contact-aware robot controllers",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Robotics and Automation (ICRA)",
      "authors": "R. Deits, T. Koolen, and R. Tedrake"
    },
    {
      "index": 43,
      "title": "Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1807.01675",
      "authors": "J. Buckman, D. Hafner, G. Tucker, E. Brevdo, and H. Lee",
      "orig_title": "Sample-efficient reinforcement learning with stochastic ensemble value expansion",
      "paper_id": "1807.01675v2"
    },
    {
      "index": 44,
      "title": "On the infinite horizon performance of receding horizon controllers",
      "abstract": "",
      "year": "2008",
      "venue": "IEEE Transactions on Automatic Control",
      "authors": "L. Grune and A. Rantzer"
    },
    {
      "index": 45,
      "title": "Learning-based Model Predictive Control for Safe Exploration",
      "abstract": "",
      "year": "2018",
      "venue": "2018 IEEE Conference on Decision and Control (CDC)",
      "authors": "T. Koller, F. Berkenkamp, M. Turchetta, and A. Krause",
      "orig_title": "Learning-based model predictive control for safe exploration",
      "paper_id": "1803.08287v3"
    },
    {
      "index": 46,
      "title": "Learning-based model predictive control: Toward safe learning in control",
      "abstract": "",
      "year": "2020",
      "venue": "Annual Review of Control, Robotics, and Autonomous Systems",
      "authors": "L. Hewing, K. P. Wabersich, M. Menner, and M. N. Zeilinger"
    },
    {
      "index": 47,
      "title": "Lyapunov Criterion for Stochastic Systems and Its Applications in Distributed Computation",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Automatic Control",
      "authors": "Y. Qin, M. Cao, and B. D. Anderson",
      "orig_title": "Lyapunov criterion for stochastic systems and its applications in distributed computation",
      "paper_id": "1902.04332v1"
    },
    {
      "index": 48,
      "title": "The explicit solution of model predictive control via multiparametric quadratic programming",
      "abstract": "",
      "year": "2000",
      "venue": "American Control Conference",
      "authors": "A. Bemporad, M. Morari, V. Dua, and E. Pistikopoulos"
    },
    {
      "index": 49,
      "title": "Sequential quadratic programming for task plan optimization",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems",
      "authors": "D. Hadfield-Menell, C. Lin, R. Chitnis, S. Russell, and P. Abbeel"
    },
    {
      "index": 50,
      "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1912.01703",
      "authors": "A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga et al.",
      "orig_title": "Pytorch: An imperative style, high-performance deep learning library",
      "paper_id": "1912.01703v1"
    },
    {
      "index": 51,
      "title": "Handbook of marine craft hydrodynamics and motion control",
      "abstract": "",
      "year": "2011",
      "venue": "John Wiley & Sons",
      "authors": "T. I. Fossen"
    },
    {
      "index": 52,
      "title": "Understanding the difficulty of training deep feedforward neural networks",
      "abstract": "",
      "year": "2010",
      "venue": "International Conference on Artificial Intelligence and Statistics (AISTATS)",
      "authors": "X. Glorot and Y. Bengio"
    }
  ]
}