{
  "paper_id": "2006.10564v4",
  "title": "Distribution-free binary classification: prediction sets, confidence intervals and calibration",
  "sections": {
    "other related work": "The problem of assessing the calibration of binary classifiers was first studied in the meteorological and statistics literature¬† [ref]40        ; we refer the reader to the review by¬†Dawid  for more details. These works resulted in two common ways of measuring calibration: reliability diagrams¬† and estimates of the squared expected calibration error (ECE)¬†[ref]40: ùîº‚Äã(f‚Äã(X)‚àíùîº‚Äã[Y‚à£f‚Äã(X)])2ùîºsuperscriptùëìùëãùîºdelimited-[]conditionalùëåùëìùëã2\\smash{\\mathbb{E}(f(X)-\\mathbb{E}\\left[Y\\mid f(X)\\right])^{2}}. Squared ECE can easily be generalized to multiclass settings and some related notions such as absolute deviation ECE and top-label ECE have also been considered, for instance¬†3 . ECE is typically estimated through binning, which provably leads to underestimation of ECE for calibrators with continuous output¬† . Certain methods have been proposed to estimate ECE without binning¬†4 1, but they require distributional assumptions for provability. While these papers have focused on the difficulty of estimating calibration error, ours is the first formal impossibility result for achieving calibration. In particular, Kumar et¬†al. [24, Theorem 4.1] show that the scaling-binning procedure achieves calibration error close to the best within a fixed, regular, injective parametric class. However, as discussed in Section¬†3.3 (after Theorem¬†3), we show that the best predictor in such an injective parametric class is itself not distribution-free calibrated. In summary, our results show not only that (some form of) binning is necessary for distribution-free calibration (Theorem¬†3), but also sufficient (Corollary¬†3). Apart from classical methods for calibration  2 3 , some new methods have been proposed recently, primarily for calibration of deep neural networks¬† 3      0 . These calibration methods perform well in practice but do not have distribution-free guarantees. A calibration framework that generalizes binning and isotonic regression is Venn prediction¬†    ; we briefly discuss this framework and show some connections to our work in Appendix¬†E. Calibration has natural applications in numerous sensitive domains where uncertainty estimation is desirable (healthcare, finance, forecasting). Recently, calibrated classifiers have been used as a part of the pipeline for anomaly detection¬†  and label shift estimation¬†  2."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Adapting to label shift with bias-corrected calibration",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "Amr Alexandari, Anshul Kundaje, and Avanti Shrikumar"
    },
    {
      "index": 1,
      "title": "Tuning bandit algorithms in stochastic environments",
      "abstract": "",
      "year": "2007",
      "venue": "International Conference on Algorithmic Learning Theory",
      "authors": "Jean-Yves Audibert, R√©mi Munos, and Csaba Szepesv√°ri"
    },
    {
      "index": 2,
      "title": "Is distribution-free inference possible for binary regression?",
      "abstract": "",
      "year": "2020",
      "venue": "Electronic Journal of Statistics",
      "authors": "Rina Foygel Barber"
    },
    {
      "index": 3,
      "title": "Discriminative learning for differing training and test distributions",
      "abstract": "",
      "year": "2007",
      "venue": "International Conference on Machine Learning",
      "authors": "Steffen Bickel, Michael Br√ºckner, and Tobias Scheffer"
    },
    {
      "index": 4,
      "title": "Verification of forecasts expressed in terms of probability",
      "abstract": "",
      "year": "1950",
      "venue": "Monthly Weather Review",
      "authors": "Glenn W Brier"
    },
    {
      "index": 5,
      "title": "Estimating reliability and resolution of probability forecasts through decomposition of the empirical score",
      "abstract": "",
      "year": "2012",
      "venue": "Climate dynamics",
      "authors": "Jochen Br√∂cker"
    },
    {
      "index": 6,
      "title": "The well-calibrated Bayesian",
      "abstract": "",
      "year": "1982",
      "venue": "Journal of the American Statistical Association",
      "authors": "A Philip Dawid"
    },
    {
      "index": 7,
      "title": "Probability forecasting",
      "abstract": "",
      "year": "2014",
      "venue": "Wiley StatsRef: Statistics Reference Online",
      "authors": "A Philip Dawid"
    },
    {
      "index": 8,
      "title": "The comparison and evaluation of forecasters",
      "abstract": "",
      "year": "1983",
      "venue": "Journal of the Royal Statistical Society: Series D (The Statistician)",
      "authors": "Morris H DeGroot and Stephen E Fienberg"
    },
    {
      "index": 9,
      "title": "Extension of measures and stochastic equations",
      "abstract": "",
      "year": "1975",
      "venue": "Theory of Probability & Its Applications",
      "authors": "M. P. Ershov"
    },
    {
      "index": 10,
      "title": "A bias-corrected decomposition of the Brier score",
      "abstract": "",
      "year": "2012",
      "venue": "Quarterly Journal of the Royal Meteorological Society",
      "authors": "Christopher AT Ferro and Thomas E Fricker"
    },
    {
      "index": 11,
      "title": "A unified view of label shift estimation",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Saurabh Garg, Yifan Wu, Sivaraman Balakrishnan, and Zachary C Lipton"
    },
    {
      "index": 12,
      "title": "On Calibration of Modern Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger",
      "orig_title": "On calibration of modern neural networks",
      "paper_id": "1706.04599v2"
    },
    {
      "index": 13,
      "title": "Distribution-free binary classification: prediction sets, confidence intervals and calibration",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Chirag Gupta, Aleksandr Podkopaev, and Aaditya Ramdas",
      "orig_title": "Distribution-free binary classification: prediction sets, confidence intervals and calibration",
      "paper_id": "2006.10564v4"
    },
    {
      "index": 14,
      "title": "Nested conformal prediction and quantile out-of-bag ensemble methods",
      "abstract": "",
      "year": "2021",
      "venue": "Pattern Recognition",
      "authors": "Chirag Gupta, Arun K Kuchibhotla, and Aaditya K Ramdas",
      "orig_title": "Nested conformal prediction and quantile out-of-bag ensemble methods",
      "paper_id": "1910.10562v4"
    },
    {
      "index": 15,
      "title": "Deep Anomaly Detection with Outlier Exposure",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "Dan Hendrycks, Mantas Mazeika, and Thomas Dietterich",
      "orig_title": "Deep anomaly detection with outlier exposure",
      "paper_id": "1812.04606v3"
    },
    {
      "index": 16,
      "title": "Time-uniform chernoff bounds via nonnegative supermartingales",
      "abstract": "",
      "year": "2020",
      "venue": "Probability Surveys",
      "authors": "Steven R. Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon"
    },
    {
      "index": 17,
      "title": "Time-uniform, nonparametric, non-asymptotic confidence sequences",
      "abstract": "",
      "year": "2021",
      "venue": "The Annals of Statistics",
      "authors": "Steven R Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon"
    },
    {
      "index": 18,
      "title": "Correcting sample selection bias by unlabeled data",
      "abstract": "",
      "year": "2007",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Jiayuan Huang, Arthur Gretton, Karsten Borgwardt, Bernhard Sch√∂lkopf, and Alex J. Smola"
    },
    {
      "index": 19,
      "title": "A least-squares approach to direct importance estimation",
      "abstract": "",
      "year": "2009",
      "venue": "Journal of Machine Learning Research",
      "authors": "Takafumi Kanamori, Shohei Hido, and Masashi Sugiyama"
    },
    {
      "index": 20,
      "title": "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Alex Kendall and Yarin Gal",
      "orig_title": "What uncertainties do we need in bayesian deep learning for computer vision?",
      "paper_id": "1703.04977v2"
    },
    {
      "index": 21,
      "title": "Accurate uncertainties for deep learning using calibrated regression",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Volodymyr Kuleshov, Nathan Fenner, and Stefano Ermon"
    },
    {
      "index": 22,
      "title": "Beyond sigmoids: How to obtain well-calibrated probabilities from binary classifiers with beta calibration",
      "abstract": "",
      "year": "2017",
      "venue": "Electronic Journal of Statistics",
      "authors": "Meelis Kull, Telmo M. Silva Filho, and Peter Flach"
    },
    {
      "index": 23,
      "title": "Unified uncertainty calibration",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ananya Kumar, Percy S Liang, and Tengyu Ma",
      "orig_title": "Verified uncertainty calibration",
      "paper_id": "2310.01202v2"
    },
    {
      "index": 24,
      "title": "Trainable calibration measures for neural networks from kernel mean embeddings",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Aviral Kumar, Sunita Sarawagi, and Ujjwal Jain"
    },
    {
      "index": 25,
      "title": "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell",
      "orig_title": "Simple and scalable predictive uncertainty estimation using deep ensembles",
      "paper_id": "1612.01474v3"
    },
    {
      "index": 26,
      "title": "Inductive Venn prediction",
      "abstract": "",
      "year": "2015",
      "venue": "Annals of Mathematics and Artificial Intelligence",
      "authors": "Antonis Lambrou, Ilia Nouretdinov, and Harris Papadopoulos"
    },
    {
      "index": 27,
      "title": "Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Learning Representations",
      "authors": "Kimin Lee, Honglak Lee, Kibok Lee, and Jinwoo Shin",
      "orig_title": "Training confidence-calibrated classifiers for detecting out-of-distribution samples",
      "paper_id": "1711.09325v3"
    },
    {
      "index": 28,
      "title": "Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Dimitrios Milios, Raffaello Camoriano, Pietro Michiardi, Lorenzo Rosasco, and Maurizio Filippone",
      "orig_title": "Dirichlet-based gaussian processes for large-scale calibrated classification",
      "paper_id": "1805.10915v1"
    },
    {
      "index": 29,
      "title": "Scalar and vector partitions of the probability score: Part i. two-state situation",
      "abstract": "",
      "year": "1972",
      "venue": "Journal of Applied Meteorology",
      "authors": "Allan H Murphy"
    },
    {
      "index": 30,
      "title": "Scalar and vector partitions of the probability score: Part ii. n-state situation",
      "abstract": "",
      "year": "1972",
      "venue": "Journal of Applied Meteorology",
      "authors": "Allan H Murphy"
    },
    {
      "index": 31,
      "title": "A new vector partition of the probability score",
      "abstract": "",
      "year": "1973",
      "venue": "Journal of applied Meteorology",
      "authors": "Allan H Murphy"
    },
    {
      "index": 32,
      "title": "Verification of probabilistic predictions: A brief review",
      "abstract": "",
      "year": "1967",
      "venue": "Journal of Applied Meteorology",
      "authors": "Allan H Murphy and Edward S Epstein"
    },
    {
      "index": 33,
      "title": "Obtaining well calibrated probabilities using Bayesian binning",
      "abstract": "",
      "year": "2015",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Mahdi Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht"
    },
    {
      "index": 34,
      "title": "Predicting good probabilities with supervised learning",
      "abstract": "",
      "year": "2005",
      "venue": "International Conference on Machine Learning",
      "authors": "Alexandru Niculescu-Mizil and Rich Caruana"
    },
    {
      "index": 35,
      "title": "Inductive confidence machines for regression",
      "abstract": "",
      "year": "2002",
      "venue": "European Conference on Machine Learning",
      "authors": "Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alex Gammerman"
    },
    {
      "index": 36,
      "title": "Calibrated prediction with covariate shift via unsupervised domain adaptation",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "authors": "Sangdon Park, Osbert Bastani, James Weimer, and Insup Lee"
    },
    {
      "index": 37,
      "title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods",
      "abstract": "",
      "year": "1999",
      "venue": "Advances in Large Margin Classifiers",
      "authors": "John C. Platt"
    },
    {
      "index": 38,
      "title": "Adjusting the outputs of a classifier to new a priori probabilities: a simple procedure",
      "abstract": "",
      "year": "2002",
      "venue": "Neural computation",
      "authors": "Marco Saerens, Patrice Latinne, and Christine Decaestecker"
    },
    {
      "index": 39,
      "title": "On subjective probability forecasting",
      "abstract": "",
      "year": "1963",
      "venue": "Journal of Applied Meteorology",
      "authors": "Frederick Sanders"
    },
    {
      "index": 40,
      "title": "Learning for Single-Shot Confidence Calibration in Deep Neural Networks through Stochastic Inferences",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Seonguk Seo, Paul Hongsuck Seo, and Bohyung Han",
      "orig_title": "Learning for single-shot confidence calibration in deep neural networks through stochastic inferences",
      "paper_id": "1809.10877v5"
    },
    {
      "index": 41,
      "title": "Improving predictive inference under covariate shift by weighting the log-likelihood function",
      "abstract": "",
      "year": "2000",
      "venue": "Journal of Statistical Planning and Inference",
      "authors": "Hidetoshi Shimodaira"
    },
    {
      "index": 42,
      "title": "Conformal prediction under covariate shift",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ryan J Tibshirani, Rina Foygel Barber, Emmanuel Candes, and Aaditya Ramdas"
    },
    {
      "index": 43,
      "title": "Calibrating Deep Convolutional Gaussian Processes",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "authors": "Gia-Lac Tran, Edwin V Bonilla, John Cunningham, Pietro Michiardi, and Maurizio Filippone",
      "orig_title": "Calibrating deep convolutional gaussian processes",
      "paper_id": "1805.10522v1"
    },
    {
      "index": 44,
      "title": "Evaluating model calibration in classification",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "authors": "Juozas Vaicenavicius, David Widmann, Carl Andersson, Fredrik Lindsten, Jacob Roll, and Thomas B Sch√∂n"
    },
    {
      "index": 45,
      "title": "Venn-Abers predictors",
      "abstract": "",
      "year": "2014",
      "venue": "Conference on Uncertainty in Artificial Intelligence",
      "authors": "Vladimir Vovk and Ivan Petej"
    },
    {
      "index": 46,
      "title": "Self-calibrating probability forecasting",
      "abstract": "",
      "year": "2004",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Vladimir Vovk, Glenn Shafer, and Ilia Nouretdinov"
    },
    {
      "index": 47,
      "title": "Algorithmic learning in a random world",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": "Vladimir Vovk, Alex Gammerman, and Glenn Shafer"
    },
    {
      "index": 48,
      "title": "Large-scale probabilistic predictors with and without guarantees of validity",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Vladimir Vovk, Ivan Petej, and Valentina Fedorova"
    },
    {
      "index": 49,
      "title": "Non-parametric calibration for classification",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "authors": "Jonathan Wenger, Hedvig Kjellstr√∂m, and Rudolph Triebel"
    },
    {
      "index": 50,
      "title": "Calibration tests in multi-class classification: A unifying framework",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "David Widmann, Fredrik Lindsten, and Dave Zachariah",
      "orig_title": "Calibration tests in multi-class classification: a unifying framework",
      "paper_id": "1910.11385v2"
    },
    {
      "index": 51,
      "title": "Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers",
      "abstract": "",
      "year": "2001",
      "venue": "International Conference on Machine Learning",
      "authors": "Bianca Zadrozny and Charles Elkan"
    },
    {
      "index": 52,
      "title": "Transforming classifier scores into accurate multiclass probability estimates",
      "abstract": "",
      "year": "2002",
      "venue": "International Conference on Knowledge Discovery and Data Mining",
      "authors": "Bianca Zadrozny and Charles Elkan"
    },
    {
      "index": 53,
      "title": "Mix-n-Match: Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "Jize Zhang, Bhavya Kailkhura, and T Han",
      "orig_title": "Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning",
      "paper_id": "2003.07329v2"
    }
  ]
}