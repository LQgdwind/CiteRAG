{
  "paper_id": "2208.07365v3",
  "title": "Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective",
  "sections": {
    "implementation details": "Architecture.\nFollowing the latest works [ref]31 [ref]37, we use I3D [ref]6 as the backbone333The existing widely adopted backbones for video-based UDA include ResNet-101 and I3D. However, more recent backbones, e.g. Transformer-based or VideoMAE-based  , are promising to be used in this task.. However, different from CoMix which jointly trains the backbone, we simply use the pretrained I3D model on Kinetics , provided by [ref]6, to extract RGB features. For the first three benchmarks, RGB features are used as the input of TranSVAE. For Sprites, we use the original image as the input, for the purpose of visualizing the reconstruction and disentanglement results. We use the shared encoder and decoder structures across the source and target domains. For RGB feature inputs, the encoder and decoder are fully connected layers. For original image inputs, the encoder and decoder are the convolution and deconvolution layers (from DCGAN ), respectively. For the TRN model, we directly use the one provided by . Other details on this aspect are placed in Appendix. Configurations.\nOur TranSVAE is implemented with PyTorch¬†. We use Adam with a weight decay of 1‚Äãe‚àí41superscriptùëí41e^{-4} as the optimizer. The learning rate is initially set to be 1‚Äãe‚àí31superscriptùëí31e^{-3} and follows a commonly used decreasing strategy in . The batch size and the learning epoch are uniformly set to be 128 and 1,000, respectively, for all the experiments. We uniformly set 100 epochs of training under only source supervision and involved the target pseudo-labels afterward. Following the common protocol in video-based UDA [ref]37, we perform hyperparameter selection on the validation set. The specific hyperparameters used for each task can be found in the Appendix. NVIDIA A100 GPUs are used for all experiments. Kindly refer to our Appendix for all other details. Competitors.\nWe compared methods from three lines. We first consider the source-only (ùíÆonlysubscriptùíÆonly\\mathcal{S}_{\\text{only}}) and supervised-target (ùíØsupsubscriptùíØsup\\mathcal{T}_{\\text{sup}}) which uses only labeled source data and only labeled target data, respectively. These two baselines serve as the lower and upper bounds for our tasks. Secondly, we consider five popular image-based UDA methods by simply ignoring temporal information, namely DANN , JAN , ADDA , AdaBN , and MCD . Lastly and most importantly, we compare recent SoTA video-based UDA methods, including TA3N , SAVA , TCoN , ABG , CoMix [ref]31, CO2A [ref]37, and MA2L-TD . All these methods use single modality features. We directly quote numbers reported in published papers whenever possible. There exist recent works conducting video-based UDA using multi-modal data, e.g. RGB + Flow. Although TranSVAE solely uses RGB features, we still take this set of methods into account. Specifically, we consider MM-SADA , STCDA , CMCD , A3R , CleanAdapt , CycDA , MixDANN  and CIA ."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Contrastively Disentangled Sequential Variational Autoencoder",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Junwen Bai, Weiran Wang, and Carla¬†P Gomes",
      "orig_title": "Contrastively disentangled sequential variational autoencoder",
      "paper_id": "2110.12091v1"
    },
    {
      "index": 1,
      "title": "Mutual information analysis: a comprehensive study",
      "abstract": "",
      "year": "2011",
      "venue": "Journal of Cryptology",
      "authors": "Lejla Batina, Benedikt Gierlichs, Emmanuel Prouff, Matthieu Rivain, Fran√ßois-Xavier Standaert, and Nicolas Veyrat-Charvillon"
    },
    {
      "index": 2,
      "title": "Exploring object relation in mean teacher for cross-domain detection",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Qi¬†Cai, Yingwei Pan, Chong-Wah Ngo, Xinmei Tian, Lingyu Duan, and Ting Yao"
    },
    {
      "index": 3,
      "title": "Learning disentangled semantic representation for domain adaptation",
      "abstract": "",
      "year": "2019",
      "venue": "International Joint Conferences on Artificial Intelligence",
      "authors": "Ruichu Cai, Zijian Li, Pengfei Wei, Jie Qiao, Kun Zhang, and Zhifeng Hao"
    },
    {
      "index": 4,
      "title": "Graph Domain Adaptation: A Generative View",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2106.07482",
      "authors": "Ruichu Cai, Fengzhu Wu, Zijian Li, Pengfei Wei, Lingling Yi, and Kun Zhang",
      "orig_title": "Graph domain adaptation: A generative view",
      "paper_id": "2106.07482v1"
    },
    {
      "index": 5,
      "title": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Joao Carreira and Andrew Zisserman",
      "orig_title": "Quo vadis, action recognition? a new model and the kinetics dataset",
      "paper_id": "1705.07750v3"
    },
    {
      "index": 6,
      "title": "Temporal Attentive Alignment for Large-Scale Video Domain Adaptation",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/CVF International Conference on Computer Vision",
      "authors": "Min-Hung Chen, Zsolt Kira, Ghassan AlRegib, Jaekwon Yoo, Ruxin Chen, and Jian Zheng",
      "orig_title": "Temporal attentive alignment for large-scale video domain adaptation",
      "paper_id": "1907.12743v6"
    },
    {
      "index": 7,
      "title": "Multi-level attentive adversarial learning with temporal dilation for unsupervised video domain adaptation",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Winter Conference on Applications of Computer Vision",
      "authors": "Peipeng Chen, Yuan Gao, and Andy¬†J Ma"
    },
    {
      "index": 8,
      "title": "Isolating sources of disentanglement in variational autoencoders",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ricky¬†TQ Chen, Xuechen Li, Roger¬†B Grosse, and David¬†K Duvenaud"
    },
    {
      "index": 9,
      "title": "Shuffle and attend: Video domain adaptation",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Jinwoo Choi, Gaurav Sharma, Samuel Schulter, and Jia-Bin Huang"
    },
    {
      "index": 10,
      "title": "Scaling egocentric vision: The epic-kitchens dataset",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision",
      "authors": "Dima Damen, Hazel Doughty, Giovanni¬†Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, et¬†al."
    },
    {
      "index": 11,
      "title": "Overcoming label noise for source-free unsupervised video domain adaptation",
      "abstract": "",
      "year": "2022",
      "venue": "Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing",
      "authors": "Avijit Dasgupta, CV¬†Jawahar, and Karteek Alahari"
    },
    {
      "index": 12,
      "title": "Informative feature disentanglement for unsupervised domain adaptation",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Multimedia",
      "authors": "Wanxia Deng, Lingjun Zhao, Qing Liao, Deke Guo, Gangyao Kuang, Dewen Hu, Matti Pietik√§inen, and Li¬†Liu"
    },
    {
      "index": 13,
      "title": "Domain-Adversarial Training of Neural Networks",
      "abstract": "",
      "year": "2016",
      "venue": "Journal of Machine Learning Research",
      "authors": "Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran√ßois Laviolette, Mario Marchand, and Victor Lempitsky",
      "orig_title": "Domain-adversarial training of neural networks",
      "paper_id": "1505.07818v4"
    },
    {
      "index": 14,
      "title": "Uncertainty-Aware Unsupervised Domain Adaptation in Object Detection",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Multimedia",
      "authors": "Dayan Guan, Jiaxing Huang, Aoran Xiao, Shijian Lu, and Yanpeng Cao",
      "orig_title": "Uncertainty-aware unsupervised domain adaptation in object detection",
      "paper_id": "2103.00236v2"
    },
    {
      "index": 15,
      "title": "DIVA: Domain Invariant Variational Autoencoders",
      "abstract": "",
      "year": "2020",
      "venue": "Medical Imaging with Deep Learning",
      "authors": "Maximilian Ilse, Jakub¬†M Tomczak, Christos Louizos, and Max Welling",
      "orig_title": "Diva: Domain invariant variational autoencoders",
      "paper_id": "1905.10427v2"
    },
    {
      "index": 16,
      "title": "The Kinetics Human Action Video Dataset",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1705.06950",
      "authors": "Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et¬†al.",
      "orig_title": "The kinetics human action video dataset",
      "paper_id": "1705.06950v1"
    },
    {
      "index": 17,
      "title": "Learning cross-modal contrastive features for video domain adaptation",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF International Conference on Computer Vision",
      "authors": "Donghyun Kim, Yi-Hsuan Tsai, Bingbing Zhuang, Xiang Yu, Stan Sclaroff, Kate Saenko, and Manmohan Chandraker"
    },
    {
      "index": 18,
      "title": "ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via Regularized Domain Concatenation",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE International Conference on Robotics and Automation",
      "authors": "Lingdong Kong, Niamul Quader, and Venice¬†Erin Liong",
      "orig_title": "Conda: Unsupervised domain adaptation for lidar segmentation via regularized domain concatenation",
      "paper_id": "2111.15242v3"
    },
    {
      "index": 19,
      "title": "Hmdb: a large video database for human motion recognition",
      "abstract": "",
      "year": "2011",
      "venue": "IEEE/CVF International Conference on Computer Vision",
      "authors": "Hildegard Kuehne, Hueihan Jhuang, Est√≠baliz Garrote, Tomaso Poggio, and Thomas Serre"
    },
    {
      "index": 20,
      "title": "Adaptive batch normalization for practical domain adaptation",
      "abstract": "",
      "year": "2018",
      "venue": "Pattern Recognition",
      "authors": "Yanghao Li, Naiyan Wang, Jianping Shi, Xiaodi Hou, and Jiaying Liu"
    },
    {
      "index": 21,
      "title": "Disentangled Sequential Autoencoder",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "Yingzhen Li and Stephan Mandt",
      "orig_title": "Disentangled sequential autoencoder",
      "paper_id": "1803.02991v2"
    },
    {
      "index": 22,
      "title": "Cycda: Unsupervised cycle domain adaptation to learn from image to video",
      "abstract": "",
      "year": "2022",
      "venue": "European Conference on Computer Vision",
      "authors": "Wei Lin, Anna Kukleva, Kunyang Sun, Horst Possegger, Hilde Kuehne, and Horst Bischof"
    },
    {
      "index": 23,
      "title": "Segment Any Point Cloud Sequences by Distilling Vision Foundation Models",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2306.09347",
      "authors": "Youquan Liu, Lingdong Kong, Jun Cen, Runnan Chen, Wenwei Zhang, Liang Pan, Kai Chen, and Ziwei Liu",
      "orig_title": "Segment any point cloud sequences by distilling vision foundation models",
      "paper_id": "2306.09347v2"
    },
    {
      "index": 24,
      "title": "Deep Transfer Learning with Joint Adaptation Networks",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "Mingsheng Long, Han Zhu, Jianmin Wang, and Michael¬†I Jordan",
      "orig_title": "Deep transfer learning with joint adaptation networks",
      "paper_id": "1605.06636v2"
    },
    {
      "index": 25,
      "title": "Adversarial Bipartite Graph Learning for Video Domain Adaptation",
      "abstract": "",
      "year": "2020",
      "venue": "ACM International Conference on Multimedia",
      "authors": "Yadan Luo, Zi¬†Huang, Zijian Wang, Zheng Zhang, and Mahsa Baktashmotlagh",
      "orig_title": "Adversarial bipartite graph learning for video domain adaptation",
      "paper_id": "2007.15829v1"
    },
    {
      "index": 26,
      "title": "The jester dataset: A large-scale video dataset of human gestures",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/CVF International Conference on Computer Vision Workshops",
      "authors": "Joanna Materzynska, Guillaume Berger, Ingo Bax, and Roland Memisevic"
    },
    {
      "index": 27,
      "title": "Multi-Modal Domain Adaptation for Fine-Grained Action Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Jonathan Munro and Dima Damen",
      "orig_title": "Multi-modal domain adaptation for fine-grained action recognition",
      "paper_id": "2001.09691v2"
    },
    {
      "index": 28,
      "title": "Adversarial Cross-Domain Action Recognition with Co-Attention",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Boxiao Pan, Zhangjie Cao, Ehsan Adeli, and Juan¬†Carlos Niebles",
      "orig_title": "Adversarial cross-domain action recognition with co-attention",
      "paper_id": "1912.10405v1"
    },
    {
      "index": 29,
      "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu¬†Fang, Junjie Bai, and Soumith Chintala",
      "orig_title": "Pytorch: An imperative style, high-performance deep learning library",
      "paper_id": "1912.01703v1"
    },
    {
      "index": 30,
      "title": "Contrast and mix: Temporal contrastive video domain adaptation with background mixing",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Aadarsh Sahoo, Rutav Shah, Rameswar Panda, Kate Saenko, and Abir Das"
    },
    {
      "index": 31,
      "title": "Maximum Classifier Discrepancy for Unsupervised Domain Adaptation",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada",
      "orig_title": "Maximum classifier discrepancy for unsupervised domain adaptation",
      "paper_id": "1712.02560v4"
    },
    {
      "index": 32,
      "title": "Multi-Head Distillation for Continual Unsupervised Domain Adaptation in Semantic Segmentation",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Antoine Saporta, Arthur Douillard, Tuan-Hung Vu, Patrick P√©rez, and Matthieu Cord",
      "orig_title": "Multi-head distillation for continual unsupervised domain adaptation in semantic segmentation",
      "paper_id": "2204.11667v1"
    },
    {
      "index": 33,
      "title": "Spatio-temporal contrastive domain adaptation for action recognition",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Xiaolin Song, Sicheng Zhao, Jingyu Yang, Huanjing Yue, Pengfei Xu, Runbo Hu, and Hua Chai"
    },
    {
      "index": 34,
      "title": "Ucf101: A dataset of 101 human actions classes from videos in the wild",
      "abstract": "",
      "year": "2012",
      "venue": "arXiv preprint arXiv:1212.0402",
      "authors": "Khurram Soomro, Amir¬†Roshan Zamir, and Mubarak Shah"
    },
    {
      "index": 35,
      "title": "VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training",
      "abstract": "",
      "year": "2022",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Zhan Tong, Yibing Song, Jue Wang, and Limin Wang",
      "orig_title": "Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training",
      "paper_id": "2203.12602v3"
    },
    {
      "index": 36,
      "title": "Dual-head contrastive domain adaptation for video action recognition",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Winter Conference on Applications of Computer Vision",
      "authors": "Victor¬†G Turrisi, Giacomo Zara, Paolo Rota, Thiago Oliveira-Santos, Nicu Sebe, Vittorio Murino, and Elisa Ricci"
    },
    {
      "index": 37,
      "title": "Adversarial Discriminative Domain Adaptation",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell",
      "orig_title": "Adversarial discriminative domain adaptation",
      "paper_id": "1702.05464v1"
    },
    {
      "index": 38,
      "title": "Visualizing Data using GTSNE",
      "abstract": "",
      "year": "2008",
      "venue": "Journal of Machine Learning Research",
      "authors": "Laurens Van¬†der Maaten and Geoffrey Hinton",
      "orig_title": "Visualizing data using t-sne",
      "paper_id": "2108.01301v1"
    },
    {
      "index": 39,
      "title": "VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking",
      "abstract": "",
      "year": "2023",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Limin Wang, Bingkun Huang, Zhiyu Zhao, Zhan Tong, Yinan He, Yi¬†Wang, Yali Wang, and Yu¬†Qiao",
      "orig_title": "Videomae v2: Scaling video masked autoencoders with dual masking",
      "paper_id": "2303.16727v2"
    },
    {
      "index": 40,
      "title": "A Survey of Unsupervised Deep Domain Adaptation",
      "abstract": "",
      "year": "2020",
      "venue": "ACM Transactions on Intelligent Systems and Technology",
      "authors": "Garrett Wilson and Diane¬†J Cook",
      "orig_title": "A survey of unsupervised deep domain adaptation",
      "paper_id": "1812.02849v3"
    },
    {
      "index": 41,
      "title": "Dynamic Weighted Learning for Unsupervised Domain Adaptation",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Ni¬†Xiao and Lei Zhang",
      "orig_title": "Dynamic weighted learning for unsupervised domain adaptation",
      "paper_id": "2103.13814v1"
    },
    {
      "index": 42,
      "title": "Interact before align: Leveraging cross-modal knowledge for domain adaptive action recognition",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Lijin Yang, Yifei Huang, Yusuke Sugano, and Yoichi Sato"
    },
    {
      "index": 43,
      "title": "Mix-dann and dynamic-modal-distillation for video domain adaptation",
      "abstract": "",
      "year": "2022",
      "venue": "ACM International Conference on Multimedia",
      "authors": "Yuehao Yin, Bin Zhu, Jingjing Chen, Lechao Cheng, and Yu-Gang Jiang"
    },
    {
      "index": 44,
      "title": "Sc-uda: Style and content gaps aware unsupervised domain adaptation for object detection",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Winter Conference on Applications of Computer Vision",
      "authors": "Fuxun Yu, Di¬†Wang, Yinpeng Chen, Nikolaos Karianakis, Tong Shen, Pei Yu, Dimitrios Lymberopoulos, Sidi Lu, Weisong Shi, and Xiang Chen"
    },
    {
      "index": 45,
      "title": "Unsupervised representation learning with deep convolutional neural network for remote sensing images",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Image and Graphics",
      "authors": "Yang Yu, Zhiqiang Gong, Ping Zhong, and Jiaxin Shan"
    },
    {
      "index": 46,
      "title": "Spectral unsupervised domain adaptation for visual recognition",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Jingyi Zhang, Jiaxing Huang, Zichen Tian, and Shijian Lu"
    },
    {
      "index": 47,
      "title": "Audio-Adaptive Activity Recognition Across Video Domains",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Yunhua Zhang, Hazel Doughty, Ling Shao, and Cees¬†GM Snoek",
      "orig_title": "Audio-adaptive activity recognition across video domains",
      "paper_id": "2203.14240v2"
    },
    {
      "index": 48,
      "title": "Temporal Relational Reasoning in Videos",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision",
      "authors": "Bolei Zhou, Alex Andonian, Aude Oliva, and Antonio Torralba",
      "orig_title": "Temporal relational reasoning in videos",
      "paper_id": "1711.08496v2"
    },
    {
      "index": 49,
      "title": "S3VAE: Self-Supervised Sequential VAE for Representation Disentanglement and Data Generation",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Yizhe Zhu, Martin¬†Renqiang Min, Asim Kadav, and Hans¬†Peter Graf",
      "orig_title": "S3vae: Self-supervised sequential vae for representation disentanglement and data generation",
      "paper_id": "2005.11437v1"
    },
    {
      "index": 50,
      "title": "Unsupervised domain adaptation for semantic segmentation via class-balanced self-training",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision",
      "authors": "Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang"
    }
  ]
}