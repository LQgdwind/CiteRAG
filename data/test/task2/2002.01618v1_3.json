{
  "paper_id": "2002.01618v1",
  "title": "Crowdsourcing the Perception of Machine Teaching",
  "sections": {
    "what are non-expertsâ€™ teaching and debugging strategies?": "We explore how variation666A preliminary analysis of this appears in a work-in-progressÂ [ref]30., inconsistency, and other attributes manifest on participantsâ€™ image sets when they are first called to train the object recognizer on objects of their choice. Incorporating diversity in teaching. Diversity plays an important role in machine learningÂ . When incorporated in the teaching set, it ensures that examples can provide more discriminatory information to help the model learn. By looking at participantsâ€™ photos (results in FigureÂ 7) and by reading their responses, we find that the majority of the participants share this intuition, but not all. In detail, 23 participants (age 21â€“60, Î¼ğœ‡\\mu=37.57, Ïƒğœ\\sigma=9.87) did not include any kind of variation in their TR1 teaching set â€“ 3 of them reported never having heard of machine learning, 12 had heard of it but did not know what it does, and 8 had a broad understanding of what it is and what it does. Immediately after training, when asked about what they considered important, 5 participants referred to the need for consistency, which in this context contradicts the way machines and people learn. For instance, P6 said â€œI figured I needed to be consistent when I took the picture so they looked similar.â€ and P30 â€œKeeping the pictures the same.â€ Others, who did not consider this type of consistency, mentioned that it is important to have a good quality photo where the object is well framed (4) with visible labels (8) and images that are clear (6) with ample light (2). Without even having tested their model, P2 said: â€œGetting different angles and perspectives so the trainer could recognize it more easilyâ€ â€“ a contradiction to their initial teaching set that had no variation. We observed that in TR2, P2 reflected on this observation and varied both the object size and viewpoint. Only two other participants from this group did so as well, P5 and P18. They said having the â€œname and color inâ€ is important in TR1 but also varied the camera distance (P5) and angle (P18) in TR2. However, the majority of participants (N=77ğ‘77N=77) diversified examples in their first attempt. They varied either size (N=65ğ‘65N=65) or viewpoint (N=63ğ‘63N=63), with some considering location (N=39ğ‘39N=39) and illumination (N=19ğ‘19N=19). Light exposure was least diverse (N=4ğ‘4N=4). Looking at responses on important considerations for training, many participants (N=52ğ‘52N=52) mentioned these strategies777All questions, instructions, and prompts prior to training were carefully edited not to prime participants towards our coding attributes. and reflected on the need for diversity with concrete terms such as â€œdifferentâ€, â€œvariousâ€, â€œallâ€, â€œmanyâ€, â€œmultipleâ€, â€œeveryâ€, â€œvarietyâ€, and â€œdifferenceâ€ combined with â€œanglesâ€, â€œviewsâ€, â€œsidesâ€, â€œfacetsâ€, â€œbackgroundâ€, â€œlightingâ€, â€œdistanceâ€, and â€œpositioningâ€. These terms correspond to the four dimensions of our coding scheme informed from prior work on visual object understandingÂ , highlighting that humansâ€™ strategies for machine teaching parallel their own abilities. However, only 11 participants (age: Î¼=34,Ïƒ=8.71formulae-sequenceğœ‡34ğœ8.71\\mu=34,\\sigma=8.71) incorporated diversity in their teaching set across all four dimensions â€“ 3 reported having heard of machine learning with no further understanding, and 8 had a broad understanding of what it is and what it does. Being fair and consistent between classes. Model consistency across classes is a desirable trait in machine learning with many social implications for fairness, whose definition is still being debated in the community (e.g.,Â  ). There is anecdotal evidence on non-experts learning to balance class proportions in the training set over multiple iterationsÂ  . By keeping the number of training examples constant, we look into their behavior across other potential disparate treatments.\nGiven that many participants considered diversity important for good performance, we explore how fair888In this work classes are object instances that fall within the same category and consequently share similarities such as shape, size, and material in the context of the decision making task of incorporating variation. Thus, we consider â€œindividual fairnessâ€Â , where â€œsimilar individuals should be treated similarlyâ€, and explore whether object instances within a category are being treated the same by a participant when introducing variation in the training photos. (i.e., consistent) they are in incorporating diversity across their three objects, with results shown in FigureÂ 7. Beyond the 23 participants who did not introduce any variation for any object, we find that there were 30 other participants that were consistent. This is promising, especially since this included participants from all levels of familiarity with machine learning: not familiar at all (N=1ğ‘1N=1), slightly familiar (N=11ğ‘11N=11), somewhat familiar (N=17ğ‘17N=17), and the only participant in our study that reported being extremely familiar (N=1ğ‘1N=1). While none of these participants explicitly mentioned consistency as important, we find that more than half of them (N=16ğ‘16N=16) continued doing so in their second attempt at training, in TR2. For the remaining 47 participants, their inconsistencies were found in variations related to all four dimensions: object size (N=21ğ‘21N=21), viewpoint (N=31ğ‘31N=31), location (N=10ğ‘10N=10), and illumination (N=5ğ‘5N=5). Deciding what to show in the teaching set. We analyze the fine-grained count attributes in teaching and training sets (FigureÂ 8) to uncover common teaching patterns across participants. Khan et al.Â  observed that one of the most prominent teaching strategies for a binary classification task among non-experts, called the extreme strategy, is consistent with the â€œcurriculum learningâ€ principleÂ  , where participants start with the most extreme examples and continue with those closer to the decision boundary999In the Khan et al.Â  study participants did not generate the examples but they ordered them as most representative of the two classes and chose to teach one by one using all of them or a subset.. While our batch teaching task does not allow for a similar sequential analysis, we find that almost all participants (N=98ğ‘98N=98) included the logo (or label) of objects in their teaching sets; on average 84.9% (Sâ€‹D=25.0ğ‘†ğ·25.0SD=25.0) of any participantsâ€™ images included logos. This indicates that participants understand that logos and labels tend to include the most discriminatory features, which serve as the most extreme examples. Then, through variation they add less discriminative viewpoints that are closer to the decision boundary. Indeed, 18 participants explicitly mentioned logos or labels being important in training. For instance, P36 said â€œâ€¦ trying to have a constant label viewâ€ and P46 â€œâ€¦ a clear shot of the front of the package with minimal background interference.â€ When looking deeper at these responses though, we find that many of the participants assumed that the machine would read the text. For example, P28 said â€œIt [the model] recognizing the different cereals by nameâ€ and P44 â€œGetting a clear shot where the writing and the size are clear.â€ In terms of the background, we find that the majority were textured (N=66ğ‘66N=66) or cluttered (N=62ğ‘62N=62), while many used plain (N=48ğ‘48N=48) and a few none at all (N=11ğ‘11N=11) â€“ the latter two are preferred since very few varied the object location. We observe that 26 participants included their hands in the photos. The presence of hands has been leveraged to better distinguish objects by modeling the contextual relationship between grasp types and object attributesÂ  or to estimate the object of interest in a clutter environmentÂ  . However, given this studyâ€™s fine-grained task, the grasp is expected to be similar across object of the same category. Thus, the presence of the hand doesnâ€™t really help, especially if it is not applied consistently across classes. More surprisingly, we observe that 8 participants reshaped their objects, e.g., opened the lid, and 4 decided to train on the content of the object as well, e.g., cinnamon powder. When asked what is important for training, one of these participants, P76, said: â€œGetting lots of different angles and different ways the spice could be portrayed.â€ In general, there were not many photos with quality issues. Participants took clear photos in most cases and many of them mentioned the importance of image quality in their responses, but some (N=36ğ‘36N=36) mistakenly took a few blurry photos. Also, objects sometimes appeared too small (N=17ğ‘17N=17) and occasionally the light was dim (N=9ğ‘9N=9). Debugging and including edge cases in testing. When asked to evaluate their model in TS1, many participants (N=30ğ‘30N=30)\ndid not diversify their images at all â€“ 2 of them reported never having heard of machine learning, 17 had heard of it but didnâ€™t know what it does, and 11 had a broad understanding of what it is and what it does. This means that they did not check whether the recognizer is robust. We also find that compared to training, fewer participants diversify their testing set across object size (N=57ğ‘57N=57), viewpoint (N=49ğ‘49N=49), location (N=21ğ‘21N=21) and illumination (N=6ğ‘6N=6). This could be explained by many factors such as: smaller number of photos in testing (15) compared to training (90); difficulty in conceptualizing robustness; assumptions about machineâ€™s generalizing capabilities; not anticipating future uses of the model under different circumstances; or simply minimizing efforts for this HIT. Logos were still included by the majority of the participants (N=98ğ‘98N=98) and the same number of participants (N=11ğ‘11N=11) took photos that did not include any background, keeping their testing data consistent with their training examples. Similar to what Zimmermann et al.Â  observed, participants â€œenacted [testing] practices wherein their models appeared to have high reliability but questionable validity.â€ We also find that participants took fewer photos with plain background (W=756ğ‘Š756W=756, Z=2.17ğ‘2.17Z=2.17, p=.030ğ‘.030p=.030, r=0.15ğ‘Ÿ0.15r=0.15), and objects that were too small (W=126.5ğ‘Š126.5W=126.5, Z=2.61ğ‘2.61Z=2.61, p=.011ğ‘.011p=.011, r=0.18ğ‘Ÿ0.18r=0.18) using a Wilcoxon signed rank test. None of the interesting object reshaping, or content images present in training, carried over to testing; a similar behavior to Kacorri et al.Â , with â€œexaggeratedâ€ variation in training unobserved in testing."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda",
      "abstract": "",
      "year": "2018",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Ashraf Abdul, Jo Vermeulen, Danding Wang, BrianÂ Y. Lim, and Mohan Kankanhalli"
    },
    {
      "index": 1,
      "title": "A new look at the statistical model identification",
      "abstract": "",
      "year": "1974",
      "venue": "IEEE Trans. Automat. Control",
      "authors": "H. Akaike"
    },
    {
      "index": 2,
      "title": "Power to the People: The Role of Humans in Interactive Machine Learning",
      "abstract": "",
      "year": "2014",
      "venue": "AI Magazine",
      "authors": "Saleema Amershi, Maya Cakmak, WilliamÂ Bradley Knox, and Todd Kulesza"
    },
    {
      "index": 3,
      "title": "Guidelines for Human-AI Interaction",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, PaulÂ N. Bennett, Kori Inkpen, and et al."
    },
    {
      "index": 4,
      "title": "Machine bias: Thereâ€™s software used across the country to predict future criminals. And itâ€™s biased against blacks",
      "abstract": "",
      "year": "2016",
      "venue": "ProPublica",
      "authors": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner"
    },
    {
      "index": 5,
      "title": "Browsable Web APIs for Flask",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": "Flask API"
    },
    {
      "index": 6,
      "title": "Big dataâ€™s disparate impact",
      "abstract": "",
      "year": "2016",
      "venue": "Cal. L. Rev.",
      "authors": "Solon Barocas and AndrewÂ D Selbst"
    },
    {
      "index": 7,
      "title": "Curriculum Learning",
      "abstract": "",
      "year": "2009",
      "venue": "International Conference on Machine Learning",
      "authors": "Yoshua Bengio, JÃ©rÃ´me Louradour, Ronan Collobert, and Jason Weston"
    },
    {
      "index": 8,
      "title": "Critical Questions for Big Data",
      "abstract": "",
      "year": "2012",
      "venue": "Information, Communication & Society",
      "authors": "danah boyd and Kate Crawford"
    },
    {
      "index": 9,
      "title": "A Personalizable Mobile Sound Detector App Design for Deaf and Hard-of-Hearing Users",
      "abstract": "",
      "year": "2016",
      "venue": "ACM SIGACCESS Conference on Computers and Accessibility",
      "authors": "Danielle Bragg, Nicholas Huynh, and RichardÂ E. Ladner"
    },
    {
      "index": 10,
      "title": "Using thematic analysis in psychology",
      "abstract": "",
      "year": "2006",
      "venue": "Qualitative Research in Psychology",
      "authors": "Virginia Braun and Victoria Clarke"
    },
    {
      "index": 11,
      "title": "Amazonâ€™s mechanical Turk: A new source of inexpensive, yet high-quality, data?",
      "abstract": "",
      "year": "2011",
      "venue": "Perspectives on Psychological Science",
      "authors": "Michael Buhrmester, Tracy Kwang, and Samuel D. Gosling"
    },
    {
      "index": 12,
      "title": "Understanding hand-object manipulation by modeling the contextual relationship between actions, grasp types and object attributes",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Minjie Cai, Kris Kitani, and Yoichi Sato"
    },
    {
      "index": 13,
      "title": "AI Now 2017 Report",
      "abstract": "",
      "year": "2017",
      "venue": "AI Now Institute at New York University",
      "authors": "Alex Campolo, Madelyn Sanfilippo, Meredith Whittaker, and Kate Crawford"
    },
    {
      "index": 14,
      "title": "European Union General Data Protection Regulation (GDPR)",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "European Commision"
    },
    {
      "index": 15,
      "title": "S.1108 - Algorithmic Accountability Act of 2019",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "US Congress"
    },
    {
      "index": 16,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "CVPR",
      "authors": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei"
    },
    {
      "index": 17,
      "title": "Algorithmic accountability reporting: On the investigation of black boxes",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "Nicholas Diakopoulos"
    },
    {
      "index": 18,
      "title": "Teaching and learning of robot tasks via observation of human performance",
      "abstract": "",
      "year": "2004",
      "venue": "Robotics and Autonomous Systems",
      "authors": "RÃ¼diger Dillmann"
    },
    {
      "index": 19,
      "title": "Fairness through Awareness",
      "abstract": "",
      "year": "2012",
      "venue": "Innovations in Theoretical Computer Science Conference",
      "authors": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel"
    },
    {
      "index": 20,
      "title": "Interactive Machine Learning",
      "abstract": "",
      "year": "2003",
      "venue": "International Conference on Intelligent User Interfaces",
      "authors": "JerryÂ Alan Fails and DanÂ R. Olsen"
    },
    {
      "index": 21,
      "title": "Human Model Evaluation in Interactive Supervised Learning",
      "abstract": "",
      "year": "2011",
      "venue": "SIGCHI Conference on Human Factors in Computing Systems",
      "authors": "Rebecca Fiebrink, PerryÂ R. Cook, and Dan Trueman"
    },
    {
      "index": 22,
      "title": "Diversity in Machine Learning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Access",
      "authors": "Z. Gong, P. Zhong, and W. Hu",
      "orig_title": "Diversity in Machine Learning",
      "paper_id": "1807.01477v2"
    },
    {
      "index": 23,
      "title": "Explainable Artificial Intelligence (XAI)",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "David Gunning"
    },
    {
      "index": 24,
      "title": "A Data-Driven Analysis of Workersâ€™ Earnings on Amazon Mechanical Turk",
      "abstract": "",
      "year": "2018",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Kotaro Hara, Abigail Adams, Kristy Milland, Saiph Savage, Chris Callison-Burch, and JeffreyÂ P. Bigham"
    },
    {
      "index": 25,
      "title": "Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design",
      "abstract": "",
      "year": "2010",
      "venue": "SIGCHI Conference on Human Factors in Computing Systems",
      "authors": "Jeffrey Heer and Michael Bostock"
    },
    {
      "index": 26,
      "title": "Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Tom Hitron, Yoav Orlev, Iddo Wald, Ariel Shamir, Hadas Erel, and Oren Zuckerman"
    },
    {
      "index": 27,
      "title": "Incentivizing High Quality Crowdwork",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on World Wide Web",
      "authors": "Chien-Ju Ho, Aleksandrs Slivkins, Siddharth Suri, and JenniferÂ Wortman Vaughan",
      "orig_title": "Incentivizing High Quality Crowdwork",
      "paper_id": "1503.05897v1"
    },
    {
      "index": 28,
      "title": "Exploring Machine Teaching for Object Recognition with the Crowd",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Jonggi Hong, Kyungjun Lee, June Xu, and Hernisa Kacorri"
    },
    {
      "index": 29,
      "title": "Gesture imitation using machine learning techniques",
      "abstract": "",
      "year": "2012",
      "venue": "Signal Processing and Communications Applications Conference",
      "authors": "I.Â I. Itauma, H. Kivrak, and H. Kose"
    },
    {
      "index": 30,
      "title": "Becoming the Expert - Interactive Multi-Class Machine Teaching",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "E. Johns, O.Â M. Aodha, and G.Â J. Brostow",
      "orig_title": "Becoming the expert - interactive multi-class machine teaching",
      "paper_id": "1504.07575v1"
    },
    {
      "index": 31,
      "title": "Teachable Machines for Accessibility",
      "abstract": "",
      "year": "2017",
      "venue": "SIGACCESS Access. Comput.",
      "authors": "Hernisa Kacorri"
    },
    {
      "index": 32,
      "title": "Teachable machines for accessibility",
      "abstract": "",
      "year": "2017",
      "venue": "ACM SIGACCESS Accessibility and Computing",
      "authors": "Hernisa Kacorri"
    },
    {
      "index": 33,
      "title": "People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges",
      "abstract": "",
      "year": "2017",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Hernisa Kacorri, KrisÂ M. Kitani, JeffreyÂ P. Bigham, and Chieko Asakawa"
    },
    {
      "index": 34,
      "title": "How Do Humans Teach: On Curriculum Learning and Teaching Dimension",
      "abstract": "",
      "year": "2011",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Faisal Khan, Bilge Mutlu, and Jerry Zhu"
    },
    {
      "index": 35,
      "title": "Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-User Expectations of AI Systems",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Rafal Kocielnik, Saleema Amershi, and PaulÂ N. Bennett"
    },
    {
      "index": 36,
      "title": "Teachable machine",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "GoogleÂ Creative Lab"
    },
    {
      "index": 37,
      "title": "Revisiting Blind Photography in the Context of Teachable Object Recognizers",
      "abstract": "",
      "year": "2019",
      "venue": "ACM SIGACCESS Conference on Computers and Accessibility",
      "authors": "Kyungjun Lee, Jonggi Hong, Simone Pimento, Ebrima Jarjue, and Hernisa Kacorri"
    },
    {
      "index": 38,
      "title": "Hands Holding Clues for Object Recognition in Teachable Machines",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Kyungjun Lee and Hernisa Kacorri"
    },
    {
      "index": 39,
      "title": "Learning the easy things first: Self-paced visual category discovery",
      "abstract": "",
      "year": "2011",
      "venue": "CVPR",
      "authors": "Y.Â J. Lee and K. Grauman"
    },
    {
      "index": 40,
      "title": "TurkPrime.com: A versatile crowdsourcing data acquisition platform for the behavioral sciences",
      "abstract": "",
      "year": "2017",
      "venue": "Behavior Research Methods",
      "authors": "Leib Litman, Jonathan Robinson, and Tzvi Abberbock"
    },
    {
      "index": 41,
      "title": "Conducting behavioral research on Amazonâ€™s Mechanical Turk",
      "abstract": "",
      "year": "2012",
      "venue": "Behavior Research Methods",
      "authors": "Winter Mason and Siddharth Suri"
    },
    {
      "index": 42,
      "title": "A Survey on Bias and Fairness in Machine Learning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan",
      "orig_title": "A Survey on Bias and Fairness in Machine Learning",
      "paper_id": "1908.09635v3"
    },
    {
      "index": 43,
      "title": "FAT* tutorial: 21 fairness definitions and their politics",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Arvind Narayanan"
    },
    {
      "index": 44,
      "title": "Visual object understanding",
      "abstract": "",
      "year": "2004",
      "venue": "Nature Reviews Neuroscience",
      "authors": "ThomasÂ J Palmeri and Isabel Gauthier"
    },
    {
      "index": 45,
      "title": "A Survey on Transfer Learning",
      "abstract": "",
      "year": "2010",
      "venue": "IEEE Transactions on Knowledge and Data Engineering",
      "authors": "S.Â J. Pan and Q. Yang"
    },
    {
      "index": 46,
      "title": "Running experiments on amazon mechanical turk",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": "Gabriele Paolacci, Jesse Chandler, and PanagiotisÂ G Ipeirotis"
    },
    {
      "index": 47,
      "title": "Teachable interfaces for individuals with dysarthric speech and severe physical disabilities",
      "abstract": "",
      "year": "1998",
      "venue": "AAAI Workshop on Integrating Artificial Intelligence and Assistive Technology",
      "authors": "Rupal Patel and Deb Roy"
    },
    {
      "index": 48,
      "title": "Beyond the Turk: Alternative platforms for crowdsourcing behavioral research",
      "abstract": "",
      "year": "2017",
      "venue": "Journal of Experimental Social Psychology",
      "authors": "Eyal Peer, Laura Brandimarte, Sonam Samat, and Alessandro Acquisti"
    },
    {
      "index": 49,
      "title": "Direct Manipulation vs. Interface Agents",
      "abstract": "",
      "year": "1997",
      "venue": "Interactions",
      "authors": "Ben Shneiderman and Pattie Maes"
    },
    {
      "index": 50,
      "title": "Machine Teaching A New Paradigm for Building Machine Learning Systems",
      "abstract": "",
      "year": "2017",
      "venue": "CoRR",
      "authors": "PatriceÂ Y. Simard, Saleema Amershi, DavidÂ Maxwell Chickering, AliciaÂ Edelman Pelton, Soroush Ghorashi, Christopher Meek, Gonzalo Ramos, Jina Suh, Johan Verwey, Mo Wang, and John Wernsing",
      "orig_title": "Machine Teaching: A New Paradigm for Building Machine Learning Systems",
      "paper_id": "1707.06742v3"
    },
    {
      "index": 51,
      "title": "Common (Mis)Beliefs about Memory: A Replication and Comparison of Telephone and Mechanical Turk Survey Methods",
      "abstract": "",
      "year": "2012",
      "venue": "PLOS ONE",
      "authors": "DanielÂ J. Simons and ChristopherÂ F. Chabris"
    },
    {
      "index": 52,
      "title": "Crowdsourcing Samples in Cognitive Science",
      "abstract": "",
      "year": "2017",
      "venue": "Trends in Cognitive Sciences",
      "authors": "Neil Stewart, Jesse Chandler, and Gabriele Paolacci"
    },
    {
      "index": 53,
      "title": "Plans and situated actions: The problem of human-machine communication",
      "abstract": "",
      "year": "1987",
      "venue": "Cambridge university press",
      "authors": "LucyÂ A Suchman"
    },
    {
      "index": 54,
      "title": "Meta-Transfer Learning for Few-Shot Learning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Qianru Sun, Yaoyao Liu, Tat-Seng Chua, and Bernt Schiele",
      "orig_title": "Meta-transfer learning for few-shot learning",
      "paper_id": "1812.02391v3"
    },
    {
      "index": 55,
      "title": "XPLAIN: a system for creating and explaining expert consulting programs",
      "abstract": "",
      "year": "1983",
      "venue": "Artificial Intelligence",
      "authors": "WilliamÂ R. Swartout"
    },
    {
      "index": 56,
      "title": "Rethinking the Inception Architecture for Computer Vision",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna"
    },
    {
      "index": 57,
      "title": "Teachable robots: Understanding human teaching behavior to build more effective robot learners",
      "abstract": "",
      "year": "2008",
      "venue": "Artificial Intelligence",
      "authors": "AndreaÂ L. Thomaz and Cynthia Breazeal"
    },
    {
      "index": 58,
      "title": "Making Better Use of the Crowd: How Crowdsourcing Can Advance Machine Learning Research",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of Machine Learning Research",
      "authors": "JenniferÂ Wortman Vaughan"
    },
    {
      "index": 59,
      "title": "Trick Me If You Can: Human-in-the-loop Generation of Adversarial Question Answering Examples",
      "abstract": "",
      "year": "2019",
      "venue": "Transactions of the Association for Computational Linguistics",
      "authors": "Eric Wallace, Pedro Rodriguez, Shi Feng, Ikuya Yamada, and Jordan Boyd-Graber"
    },
    {
      "index": 60,
      "title": "Designing Theory-Driven User-Centric Explainable AI",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Danding Wang, Qian Yang, Ashraf Abdul, and BrianÂ Y. Lim"
    },
    {
      "index": 61,
      "title": "Intelligible Artificial Intelligence",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint",
      "authors": "DanielÂ S Weld and Gagan Bansal"
    },
    {
      "index": 62,
      "title": "Grounding Interactive Machine Learning Tool Design in How Non-Experts Actually Build Models",
      "abstract": "",
      "year": "2018",
      "venue": "Designing Interactive Systems Conference",
      "authors": "Qian Yang, Jina Suh, Nan-Chen Chen, and Gonzalo Ramos"
    },
    {
      "index": 63,
      "title": "An Overview of Machine Teaching",
      "abstract": "",
      "year": "2018",
      "venue": "CoRR",
      "authors": "Xiaojin Zhu, Adish Singla, Sandra Zilles, and AnnaÂ N. Rafferty",
      "orig_title": "An Overview of Machine Teaching",
      "paper_id": "1801.05927v1"
    },
    {
      "index": 64,
      "title": "Youth Learning Machine Learning through Building Models of Athletic Moves",
      "abstract": "",
      "year": "2019",
      "venue": "ACM International Conference on Interaction Design and Children",
      "authors": "Abigail Zimmermann-Niefield, Makenna Turner, Bridget Murphy, ShaunÂ K. Kane, and R.Â Benjamin Shapiro"
    },
    {
      "index": 65,
      "title": "Abigail Zimmermann-Niefield",
      "abstract": "",
      "year": "2019",
      "venue": "DOI:http://dx.doi.org/10",
      "authors": "Abigail Zimmermann-Niefield, Makenna Turner, Bridget Murphy, ShaunÂ K.\nKane, and R.Â Benjamin Shapiro. 2019."
    }
  ]
}