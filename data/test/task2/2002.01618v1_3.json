{
  "paper_id": "2002.01618v1",
  "title": "Crowdsourcing the Perception of Machine Teaching",
  "sections": {
    "what are non-experts’ teaching and debugging strategies?": "We explore how variation666A preliminary analysis of this appears in a work-in-progress [ref]30., inconsistency, and other attributes manifest on participants’ image sets when they are first called to train the object recognizer on objects of their choice. Incorporating diversity in teaching. Diversity plays an important role in machine learning . When incorporated in the teaching set, it ensures that examples can provide more discriminatory information to help the model learn. By looking at participants’ photos (results in Figure 7) and by reading their responses, we find that the majority of the participants share this intuition, but not all. In detail, 23 participants (age 21–60, μ𝜇\\mu=37.57, σ𝜎\\sigma=9.87) did not include any kind of variation in their TR1 teaching set – 3 of them reported never having heard of machine learning, 12 had heard of it but did not know what it does, and 8 had a broad understanding of what it is and what it does. Immediately after training, when asked about what they considered important, 5 participants referred to the need for consistency, which in this context contradicts the way machines and people learn. For instance, P6 said “I figured I needed to be consistent when I took the picture so they looked similar.” and P30 “Keeping the pictures the same.” Others, who did not consider this type of consistency, mentioned that it is important to have a good quality photo where the object is well framed (4) with visible labels (8) and images that are clear (6) with ample light (2). Without even having tested their model, P2 said: “Getting different angles and perspectives so the trainer could recognize it more easily” – a contradiction to their initial teaching set that had no variation. We observed that in TR2, P2 reflected on this observation and varied both the object size and viewpoint. Only two other participants from this group did so as well, P5 and P18. They said having the “name and color in” is important in TR1 but also varied the camera distance (P5) and angle (P18) in TR2. However, the majority of participants (N=77𝑁77N=77) diversified examples in their first attempt. They varied either size (N=65𝑁65N=65) or viewpoint (N=63𝑁63N=63), with some considering location (N=39𝑁39N=39) and illumination (N=19𝑁19N=19). Light exposure was least diverse (N=4𝑁4N=4). Looking at responses on important considerations for training, many participants (N=52𝑁52N=52) mentioned these strategies777All questions, instructions, and prompts prior to training were carefully edited not to prime participants towards our coding attributes. and reflected on the need for diversity with concrete terms such as “different”, “various”, “all”, “many”, “multiple”, “every”, “variety”, and “difference” combined with “angles”, “views”, “sides”, “facets”, “background”, “lighting”, “distance”, and “positioning”. These terms correspond to the four dimensions of our coding scheme informed from prior work on visual object understanding , highlighting that humans’ strategies for machine teaching parallel their own abilities. However, only 11 participants (age: μ=34,σ=8.71formulae-sequence𝜇34𝜎8.71\\mu=34,\\sigma=8.71) incorporated diversity in their teaching set across all four dimensions – 3 reported having heard of machine learning with no further understanding, and 8 had a broad understanding of what it is and what it does. Being fair and consistent between classes. Model consistency across classes is a desirable trait in machine learning with many social implications for fairness, whose definition is still being debated in the community (e.g.,  ). There is anecdotal evidence on non-experts learning to balance class proportions in the training set over multiple iterations  . By keeping the number of training examples constant, we look into their behavior across other potential disparate treatments.\nGiven that many participants considered diversity important for good performance, we explore how fair888In this work classes are object instances that fall within the same category and consequently share similarities such as shape, size, and material in the context of the decision making task of incorporating variation. Thus, we consider “individual fairness” , where “similar individuals should be treated similarly”, and explore whether object instances within a category are being treated the same by a participant when introducing variation in the training photos. (i.e., consistent) they are in incorporating diversity across their three objects, with results shown in Figure 7. Beyond the 23 participants who did not introduce any variation for any object, we find that there were 30 other participants that were consistent. This is promising, especially since this included participants from all levels of familiarity with machine learning: not familiar at all (N=1𝑁1N=1), slightly familiar (N=11𝑁11N=11), somewhat familiar (N=17𝑁17N=17), and the only participant in our study that reported being extremely familiar (N=1𝑁1N=1). While none of these participants explicitly mentioned consistency as important, we find that more than half of them (N=16𝑁16N=16) continued doing so in their second attempt at training, in TR2. For the remaining 47 participants, their inconsistencies were found in variations related to all four dimensions: object size (N=21𝑁21N=21), viewpoint (N=31𝑁31N=31), location (N=10𝑁10N=10), and illumination (N=5𝑁5N=5). Deciding what to show in the teaching set. We analyze the fine-grained count attributes in teaching and training sets (Figure 8) to uncover common teaching patterns across participants. Khan et al.  observed that one of the most prominent teaching strategies for a binary classification task among non-experts, called the extreme strategy, is consistent with the “curriculum learning” principle  , where participants start with the most extreme examples and continue with those closer to the decision boundary999In the Khan et al.  study participants did not generate the examples but they ordered them as most representative of the two classes and chose to teach one by one using all of them or a subset.. While our batch teaching task does not allow for a similar sequential analysis, we find that almost all participants (N=98𝑁98N=98) included the logo (or label) of objects in their teaching sets; on average 84.9% (S​D=25.0𝑆𝐷25.0SD=25.0) of any participants’ images included logos. This indicates that participants understand that logos and labels tend to include the most discriminatory features, which serve as the most extreme examples. Then, through variation they add less discriminative viewpoints that are closer to the decision boundary. Indeed, 18 participants explicitly mentioned logos or labels being important in training. For instance, P36 said “… trying to have a constant label view” and P46 “… a clear shot of the front of the package with minimal background interference.” When looking deeper at these responses though, we find that many of the participants assumed that the machine would read the text. For example, P28 said “It [the model] recognizing the different cereals by name” and P44 “Getting a clear shot where the writing and the size are clear.” In terms of the background, we find that the majority were textured (N=66𝑁66N=66) or cluttered (N=62𝑁62N=62), while many used plain (N=48𝑁48N=48) and a few none at all (N=11𝑁11N=11) – the latter two are preferred since very few varied the object location. We observe that 26 participants included their hands in the photos. The presence of hands has been leveraged to better distinguish objects by modeling the contextual relationship between grasp types and object attributes  or to estimate the object of interest in a clutter environment  . However, given this study’s fine-grained task, the grasp is expected to be similar across object of the same category. Thus, the presence of the hand doesn’t really help, especially if it is not applied consistently across classes. More surprisingly, we observe that 8 participants reshaped their objects, e.g., opened the lid, and 4 decided to train on the content of the object as well, e.g., cinnamon powder. When asked what is important for training, one of these participants, P76, said: “Getting lots of different angles and different ways the spice could be portrayed.” In general, there were not many photos with quality issues. Participants took clear photos in most cases and many of them mentioned the importance of image quality in their responses, but some (N=36𝑁36N=36) mistakenly took a few blurry photos. Also, objects sometimes appeared too small (N=17𝑁17N=17) and occasionally the light was dim (N=9𝑁9N=9). Debugging and including edge cases in testing. When asked to evaluate their model in TS1, many participants (N=30𝑁30N=30)\ndid not diversify their images at all – 2 of them reported never having heard of machine learning, 17 had heard of it but didn’t know what it does, and 11 had a broad understanding of what it is and what it does. This means that they did not check whether the recognizer is robust. We also find that compared to training, fewer participants diversify their testing set across object size (N=57𝑁57N=57), viewpoint (N=49𝑁49N=49), location (N=21𝑁21N=21) and illumination (N=6𝑁6N=6). This could be explained by many factors such as: smaller number of photos in testing (15) compared to training (90); difficulty in conceptualizing robustness; assumptions about machine’s generalizing capabilities; not anticipating future uses of the model under different circumstances; or simply minimizing efforts for this HIT. Logos were still included by the majority of the participants (N=98𝑁98N=98) and the same number of participants (N=11𝑁11N=11) took photos that did not include any background, keeping their testing data consistent with their training examples. Similar to what Zimmermann et al.  observed, participants “enacted [testing] practices wherein their models appeared to have high reliability but questionable validity.” We also find that participants took fewer photos with plain background (W=756𝑊756W=756, Z=2.17𝑍2.17Z=2.17, p=.030𝑝.030p=.030, r=0.15𝑟0.15r=0.15), and objects that were too small (W=126.5𝑊126.5W=126.5, Z=2.61𝑍2.61Z=2.61, p=.011𝑝.011p=.011, r=0.18𝑟0.18r=0.18) using a Wilcoxon signed rank test. None of the interesting object reshaping, or content images present in training, carried over to testing; a similar behavior to Kacorri et al. , with “exaggerated” variation in training unobserved in testing."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda",
      "abstract": "",
      "year": "2018",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Ashraf Abdul, Jo Vermeulen, Danding Wang, Brian Y. Lim, and Mohan Kankanhalli"
    },
    {
      "index": 1,
      "title": "A new look at the statistical model identification",
      "abstract": "",
      "year": "1974",
      "venue": "IEEE Trans. Automat. Control",
      "authors": "H. Akaike"
    },
    {
      "index": 2,
      "title": "Power to the People: The Role of Humans in Interactive Machine Learning",
      "abstract": "",
      "year": "2014",
      "venue": "AI Magazine",
      "authors": "Saleema Amershi, Maya Cakmak, William Bradley Knox, and Todd Kulesza"
    },
    {
      "index": 3,
      "title": "Guidelines for Human-AI Interaction",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N. Bennett, Kori Inkpen, and et al."
    },
    {
      "index": 4,
      "title": "Machine bias: There’s software used across the country to predict future criminals. And it’s biased against blacks",
      "abstract": "",
      "year": "2016",
      "venue": "ProPublica",
      "authors": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner"
    },
    {
      "index": 5,
      "title": "Browsable Web APIs for Flask",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": "Flask API"
    },
    {
      "index": 6,
      "title": "Big data’s disparate impact",
      "abstract": "",
      "year": "2016",
      "venue": "Cal. L. Rev.",
      "authors": "Solon Barocas and Andrew D Selbst"
    },
    {
      "index": 7,
      "title": "Curriculum Learning",
      "abstract": "",
      "year": "2009",
      "venue": "International Conference on Machine Learning",
      "authors": "Yoshua Bengio, Jérôme Louradour, Ronan Collobert, and Jason Weston"
    },
    {
      "index": 8,
      "title": "Critical Questions for Big Data",
      "abstract": "",
      "year": "2012",
      "venue": "Information, Communication & Society",
      "authors": "danah boyd and Kate Crawford"
    },
    {
      "index": 9,
      "title": "A Personalizable Mobile Sound Detector App Design for Deaf and Hard-of-Hearing Users",
      "abstract": "",
      "year": "2016",
      "venue": "ACM SIGACCESS Conference on Computers and Accessibility",
      "authors": "Danielle Bragg, Nicholas Huynh, and Richard E. Ladner"
    },
    {
      "index": 10,
      "title": "Using thematic analysis in psychology",
      "abstract": "",
      "year": "2006",
      "venue": "Qualitative Research in Psychology",
      "authors": "Virginia Braun and Victoria Clarke"
    },
    {
      "index": 11,
      "title": "Amazon’s mechanical Turk: A new source of inexpensive, yet high-quality, data?",
      "abstract": "",
      "year": "2011",
      "venue": "Perspectives on Psychological Science",
      "authors": "Michael Buhrmester, Tracy Kwang, and Samuel D. Gosling"
    },
    {
      "index": 12,
      "title": "Understanding hand-object manipulation by modeling the contextual relationship between actions, grasp types and object attributes",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Minjie Cai, Kris Kitani, and Yoichi Sato"
    },
    {
      "index": 13,
      "title": "AI Now 2017 Report",
      "abstract": "",
      "year": "2017",
      "venue": "AI Now Institute at New York University",
      "authors": "Alex Campolo, Madelyn Sanfilippo, Meredith Whittaker, and Kate Crawford"
    },
    {
      "index": 14,
      "title": "European Union General Data Protection Regulation (GDPR)",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "European Commision"
    },
    {
      "index": 15,
      "title": "S.1108 - Algorithmic Accountability Act of 2019",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "US Congress"
    },
    {
      "index": 16,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "CVPR",
      "authors": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei"
    },
    {
      "index": 17,
      "title": "Algorithmic accountability reporting: On the investigation of black boxes",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "Nicholas Diakopoulos"
    },
    {
      "index": 18,
      "title": "Teaching and learning of robot tasks via observation of human performance",
      "abstract": "",
      "year": "2004",
      "venue": "Robotics and Autonomous Systems",
      "authors": "Rüdiger Dillmann"
    },
    {
      "index": 19,
      "title": "Fairness through Awareness",
      "abstract": "",
      "year": "2012",
      "venue": "Innovations in Theoretical Computer Science Conference",
      "authors": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel"
    },
    {
      "index": 20,
      "title": "Interactive Machine Learning",
      "abstract": "",
      "year": "2003",
      "venue": "International Conference on Intelligent User Interfaces",
      "authors": "Jerry Alan Fails and Dan R. Olsen"
    },
    {
      "index": 21,
      "title": "Human Model Evaluation in Interactive Supervised Learning",
      "abstract": "",
      "year": "2011",
      "venue": "SIGCHI Conference on Human Factors in Computing Systems",
      "authors": "Rebecca Fiebrink, Perry R. Cook, and Dan Trueman"
    },
    {
      "index": 22,
      "title": "Diversity in Machine Learning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Access",
      "authors": "Z. Gong, P. Zhong, and W. Hu",
      "orig_title": "Diversity in Machine Learning",
      "paper_id": "1807.01477v2"
    },
    {
      "index": 23,
      "title": "Explainable Artificial Intelligence (XAI)",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "David Gunning"
    },
    {
      "index": 24,
      "title": "A Data-Driven Analysis of Workers’ Earnings on Amazon Mechanical Turk",
      "abstract": "",
      "year": "2018",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Kotaro Hara, Abigail Adams, Kristy Milland, Saiph Savage, Chris Callison-Burch, and Jeffrey P. Bigham"
    },
    {
      "index": 25,
      "title": "Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design",
      "abstract": "",
      "year": "2010",
      "venue": "SIGCHI Conference on Human Factors in Computing Systems",
      "authors": "Jeffrey Heer and Michael Bostock"
    },
    {
      "index": 26,
      "title": "Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Tom Hitron, Yoav Orlev, Iddo Wald, Ariel Shamir, Hadas Erel, and Oren Zuckerman"
    },
    {
      "index": 27,
      "title": "Incentivizing High Quality Crowdwork",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on World Wide Web",
      "authors": "Chien-Ju Ho, Aleksandrs Slivkins, Siddharth Suri, and Jennifer Wortman Vaughan",
      "orig_title": "Incentivizing High Quality Crowdwork",
      "paper_id": "1503.05897v1"
    },
    {
      "index": 28,
      "title": "Exploring Machine Teaching for Object Recognition with the Crowd",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Jonggi Hong, Kyungjun Lee, June Xu, and Hernisa Kacorri"
    },
    {
      "index": 29,
      "title": "Gesture imitation using machine learning techniques",
      "abstract": "",
      "year": "2012",
      "venue": "Signal Processing and Communications Applications Conference",
      "authors": "I. I. Itauma, H. Kivrak, and H. Kose"
    },
    {
      "index": 30,
      "title": "Becoming the Expert - Interactive Multi-Class Machine Teaching",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "E. Johns, O. M. Aodha, and G. J. Brostow",
      "orig_title": "Becoming the expert - interactive multi-class machine teaching",
      "paper_id": "1504.07575v1"
    },
    {
      "index": 31,
      "title": "Teachable Machines for Accessibility",
      "abstract": "",
      "year": "2017",
      "venue": "SIGACCESS Access. Comput.",
      "authors": "Hernisa Kacorri"
    },
    {
      "index": 32,
      "title": "Teachable machines for accessibility",
      "abstract": "",
      "year": "2017",
      "venue": "ACM SIGACCESS Accessibility and Computing",
      "authors": "Hernisa Kacorri"
    },
    {
      "index": 33,
      "title": "People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges",
      "abstract": "",
      "year": "2017",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Hernisa Kacorri, Kris M. Kitani, Jeffrey P. Bigham, and Chieko Asakawa"
    },
    {
      "index": 34,
      "title": "How Do Humans Teach: On Curriculum Learning and Teaching Dimension",
      "abstract": "",
      "year": "2011",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Faisal Khan, Bilge Mutlu, and Jerry Zhu"
    },
    {
      "index": 35,
      "title": "Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-User Expectations of AI Systems",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Rafal Kocielnik, Saleema Amershi, and Paul N. Bennett"
    },
    {
      "index": 36,
      "title": "Teachable machine",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Google Creative Lab"
    },
    {
      "index": 37,
      "title": "Revisiting Blind Photography in the Context of Teachable Object Recognizers",
      "abstract": "",
      "year": "2019",
      "venue": "ACM SIGACCESS Conference on Computers and Accessibility",
      "authors": "Kyungjun Lee, Jonggi Hong, Simone Pimento, Ebrima Jarjue, and Hernisa Kacorri"
    },
    {
      "index": 38,
      "title": "Hands Holding Clues for Object Recognition in Teachable Machines",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Kyungjun Lee and Hernisa Kacorri"
    },
    {
      "index": 39,
      "title": "Learning the easy things first: Self-paced visual category discovery",
      "abstract": "",
      "year": "2011",
      "venue": "CVPR",
      "authors": "Y. J. Lee and K. Grauman"
    },
    {
      "index": 40,
      "title": "TurkPrime.com: A versatile crowdsourcing data acquisition platform for the behavioral sciences",
      "abstract": "",
      "year": "2017",
      "venue": "Behavior Research Methods",
      "authors": "Leib Litman, Jonathan Robinson, and Tzvi Abberbock"
    },
    {
      "index": 41,
      "title": "Conducting behavioral research on Amazon’s Mechanical Turk",
      "abstract": "",
      "year": "2012",
      "venue": "Behavior Research Methods",
      "authors": "Winter Mason and Siddharth Suri"
    },
    {
      "index": 42,
      "title": "A Survey on Bias and Fairness in Machine Learning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan",
      "orig_title": "A Survey on Bias and Fairness in Machine Learning",
      "paper_id": "1908.09635v3"
    },
    {
      "index": 43,
      "title": "FAT* tutorial: 21 fairness definitions and their politics",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Arvind Narayanan"
    },
    {
      "index": 44,
      "title": "Visual object understanding",
      "abstract": "",
      "year": "2004",
      "venue": "Nature Reviews Neuroscience",
      "authors": "Thomas J Palmeri and Isabel Gauthier"
    },
    {
      "index": 45,
      "title": "A Survey on Transfer Learning",
      "abstract": "",
      "year": "2010",
      "venue": "IEEE Transactions on Knowledge and Data Engineering",
      "authors": "S. J. Pan and Q. Yang"
    },
    {
      "index": 46,
      "title": "Running experiments on amazon mechanical turk",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": "Gabriele Paolacci, Jesse Chandler, and Panagiotis G Ipeirotis"
    },
    {
      "index": 47,
      "title": "Teachable interfaces for individuals with dysarthric speech and severe physical disabilities",
      "abstract": "",
      "year": "1998",
      "venue": "AAAI Workshop on Integrating Artificial Intelligence and Assistive Technology",
      "authors": "Rupal Patel and Deb Roy"
    },
    {
      "index": 48,
      "title": "Beyond the Turk: Alternative platforms for crowdsourcing behavioral research",
      "abstract": "",
      "year": "2017",
      "venue": "Journal of Experimental Social Psychology",
      "authors": "Eyal Peer, Laura Brandimarte, Sonam Samat, and Alessandro Acquisti"
    },
    {
      "index": 49,
      "title": "Direct Manipulation vs. Interface Agents",
      "abstract": "",
      "year": "1997",
      "venue": "Interactions",
      "authors": "Ben Shneiderman and Pattie Maes"
    },
    {
      "index": 50,
      "title": "Machine Teaching A New Paradigm for Building Machine Learning Systems",
      "abstract": "",
      "year": "2017",
      "venue": "CoRR",
      "authors": "Patrice Y. Simard, Saleema Amershi, David Maxwell Chickering, Alicia Edelman Pelton, Soroush Ghorashi, Christopher Meek, Gonzalo Ramos, Jina Suh, Johan Verwey, Mo Wang, and John Wernsing",
      "orig_title": "Machine Teaching: A New Paradigm for Building Machine Learning Systems",
      "paper_id": "1707.06742v3"
    },
    {
      "index": 51,
      "title": "Common (Mis)Beliefs about Memory: A Replication and Comparison of Telephone and Mechanical Turk Survey Methods",
      "abstract": "",
      "year": "2012",
      "venue": "PLOS ONE",
      "authors": "Daniel J. Simons and Christopher F. Chabris"
    },
    {
      "index": 52,
      "title": "Crowdsourcing Samples in Cognitive Science",
      "abstract": "",
      "year": "2017",
      "venue": "Trends in Cognitive Sciences",
      "authors": "Neil Stewart, Jesse Chandler, and Gabriele Paolacci"
    },
    {
      "index": 53,
      "title": "Plans and situated actions: The problem of human-machine communication",
      "abstract": "",
      "year": "1987",
      "venue": "Cambridge university press",
      "authors": "Lucy A Suchman"
    },
    {
      "index": 54,
      "title": "Meta-Transfer Learning for Few-Shot Learning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Qianru Sun, Yaoyao Liu, Tat-Seng Chua, and Bernt Schiele",
      "orig_title": "Meta-transfer learning for few-shot learning",
      "paper_id": "1812.02391v3"
    },
    {
      "index": 55,
      "title": "XPLAIN: a system for creating and explaining expert consulting programs",
      "abstract": "",
      "year": "1983",
      "venue": "Artificial Intelligence",
      "authors": "William R. Swartout"
    },
    {
      "index": 56,
      "title": "Rethinking the Inception Architecture for Computer Vision",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna"
    },
    {
      "index": 57,
      "title": "Teachable robots: Understanding human teaching behavior to build more effective robot learners",
      "abstract": "",
      "year": "2008",
      "venue": "Artificial Intelligence",
      "authors": "Andrea L. Thomaz and Cynthia Breazeal"
    },
    {
      "index": 58,
      "title": "Making Better Use of the Crowd: How Crowdsourcing Can Advance Machine Learning Research",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of Machine Learning Research",
      "authors": "Jennifer Wortman Vaughan"
    },
    {
      "index": 59,
      "title": "Trick Me If You Can: Human-in-the-loop Generation of Adversarial Question Answering Examples",
      "abstract": "",
      "year": "2019",
      "venue": "Transactions of the Association for Computational Linguistics",
      "authors": "Eric Wallace, Pedro Rodriguez, Shi Feng, Ikuya Yamada, and Jordan Boyd-Graber"
    },
    {
      "index": 60,
      "title": "Designing Theory-Driven User-Centric Explainable AI",
      "abstract": "",
      "year": "2019",
      "venue": "CHI Conference on Human Factors in Computing Systems",
      "authors": "Danding Wang, Qian Yang, Ashraf Abdul, and Brian Y. Lim"
    },
    {
      "index": 61,
      "title": "Intelligible Artificial Intelligence",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint",
      "authors": "Daniel S Weld and Gagan Bansal"
    },
    {
      "index": 62,
      "title": "Grounding Interactive Machine Learning Tool Design in How Non-Experts Actually Build Models",
      "abstract": "",
      "year": "2018",
      "venue": "Designing Interactive Systems Conference",
      "authors": "Qian Yang, Jina Suh, Nan-Chen Chen, and Gonzalo Ramos"
    },
    {
      "index": 63,
      "title": "An Overview of Machine Teaching",
      "abstract": "",
      "year": "2018",
      "venue": "CoRR",
      "authors": "Xiaojin Zhu, Adish Singla, Sandra Zilles, and Anna N. Rafferty",
      "orig_title": "An Overview of Machine Teaching",
      "paper_id": "1801.05927v1"
    },
    {
      "index": 64,
      "title": "Youth Learning Machine Learning through Building Models of Athletic Moves",
      "abstract": "",
      "year": "2019",
      "venue": "ACM International Conference on Interaction Design and Children",
      "authors": "Abigail Zimmermann-Niefield, Makenna Turner, Bridget Murphy, Shaun K. Kane, and R. Benjamin Shapiro"
    },
    {
      "index": 65,
      "title": "Abigail Zimmermann-Niefield",
      "abstract": "",
      "year": "2019",
      "venue": "DOI:http://dx.doi.org/10",
      "authors": "Abigail Zimmermann-Niefield, Makenna Turner, Bridget Murphy, Shaun K.\nKane, and R. Benjamin Shapiro. 2019."
    }
  ]
}