{
  "paper_id": "2308.03572v5",
  "title": "Provably Efficient Learning in Partially Observable Contextual Bandit",
  "sections": {
    "task 1: transfer from contextual bandit to mab": "We first consider an off-policy learning problem between an contextual bandit expert and a MAB agent.\nContextual bandits   [ref]4 is a variation of MAB where the expert can observe extra contextual information Wğ‘ŠW associated with the reward signal Yğ‘ŒY.\nThe expert follows certain policy and summarizes its experiences as the joint distribution F^â€‹(a,y,w)^ğ¹ğ‘ğ‘¦ğ‘¤\\hat{F}(a,y,w).\nHowever, there exists a latent confounder Uğ‘ˆU that affects the causal effects between actions and rewards, making the observed contextual bandit model incomplete.\nThe agent, who is observing the expert interacting with the environment,\nwants to be more efficient and reuse the observed F^â€‹(a,y,w)^ğ¹ğ‘ğ‘¦ğ‘¤\\hat{F}(a,y,w) with the help of extra prior knowledge about Uğ‘ˆU, i.e., F^â€‹(u)^ğ¹ğ‘¢\\hat{F}(u),\nto find the optimal policy faster. Causal bounds.\nThis transfer scenario is depicted in FigureÂ 1,\nwhere the actions Ağ´A, outcomes Yğ‘ŒY, context Wğ‘ŠW and Uğ‘ˆU,\nand causal structures used by the expert and the agent are identical.\nIn the first task, the MAB agent is unable to observe contexts,\nbut we will also examine the case where the agent can partially observe contexts in the task 2 and 3.\nThe missing contexts may be due to privacy protection or legal restrictions.\nAs the new agent cannot observe Wğ‘ŠW or Uğ‘ˆU, its objective is to minimize regret as defined in equation (1). One can find the optimal action dâ€‹oâ€‹(A=aâˆ—)ğ‘‘ğ‘œğ´superscriptğ‘do(A=a^{*}) by evaluating ğ”¼â€‹[Y|dâ€‹oâ€‹(a)]ğ”¼delimited-[]conditionalğ‘Œğ‘‘ğ‘œğ‘\\mathbb{E}[Y|do(a)].\nTherefore, the off-policy learning problem is equivalent to identifying the causal effect ğ”¼â€‹[Y|dâ€‹oâ€‹(a)]ğ”¼delimited-[]conditionalğ‘Œğ‘‘ğ‘œğ‘\\mathbb{E}[Y|do(a)] given the observational distribution Fâ€‹(a,y,w)ğ¹ğ‘ğ‘¦ğ‘¤{F}(a,y,w) and prior knowledge Fâ€‹(u)ğ¹ğ‘¢F(u).\nAlthough Uğ‘ˆU is unobserved during online learning, its distribution can be usually known regardless of the model itself (e.g., Uğ‘ˆU stands for gender, gene\ntype, blood type, or age). Alternatively, if costs permit, one can estimate Fâ€‹(u)ğ¹ğ‘¢{F}(u) by re-testing within a small sampled sub-population.\nHowever, even though WâˆªUğ‘Šğ‘ˆW\\cup U is assumed to be sufficient,\nthe causal effects of the action Ağ´A on the reward Yğ‘ŒY is non-identifiable from incomplete experiences Fâ€‹(a,y,w)ğ¹ğ‘ğ‘¦ğ‘¤{F}(a,y,w) and Fâ€‹(u)ğ¹ğ‘¢{F}(u),\nbecause the back-door path Aâ†Uâ†’Yâ†ğ´ğ‘ˆâ†’ğ‘ŒA\\leftarrow U\\rightarrow Y is still unblocked.\nThis means that the causal effects of Ağ´A on Yğ‘ŒY cannot be estimated without bias, regardless of sample size. However, we can tight obtain bounds on the causal effects via an optimization problem when given a prior distribution Fâ€‹(u)ğ¹ğ‘¢F(u) and Fâ€‹(a,y,w)ğ¹ğ‘ğ‘¦ğ‘¤F(a,y,w).\nThe optimization problem is as follows: Here, the sup/inf is taken over all causal models â„³â„³\\mathcal{M}, and Fâ„³subscriptğ¹â„³F_{\\mathcal{M}} represents the distributions in the causal model â„³â„³\\mathcal{M}.\nDenote the solutions to (4) as hâ€‹(a)â„ğ‘h(a) and lâ€‹(a)ğ‘™ğ‘l(a), respectively.\nSince the optimization is performed over all compatible causal models, the resulting bounds are guaranteed to be tight.\nIt is worth noting that the sufficient and necessary condition for causal identification is that hâ€‹(a)â„ğ‘h(a) is equal to lâ€‹(a)ğ‘™ğ‘l(a).\nWe provide a formal statement of this result in the appendix.\nThis idea is similar to that proposed in other works, such as  [ref]42 . In Theorem 3.1, we provide a specific version of the optimization problem (4) to obtain bounds on the causal effects of actions on rewards.\nWe consider the estimation error Ïµitalic-Ïµ\\epsilon and distinguish between known and unknown variables by using F^^ğ¹\\hat{F} to represent the observed distributions and Fğ¹F to represent the unknown variables. Given a causal diagram ğ’¢ğ’¢\\mathcal{G} and a distribution compatible with ğ’¢ğ’¢\\mathcal{G}, let {W,U}ğ‘Šğ‘ˆ\\{W,U\\} be a set of variables satisfying\nthe back-door criterion in ğ’¢ğ’¢\\mathcal{G} relative to an ordered pair (A,Y)ğ´ğ‘Œ(A,Y), where {W,U}ğ‘Šğ‘ˆ\\{W,U\\} is partially observable, i.e., only\nprobabilities F^â€‹(a,y,w)^ğ¹ğ‘ğ‘¦ğ‘¤\\hat{F}(a,y,w) and F^â€‹(u)^ğ¹ğ‘¢\\hat{F}(u) with the maximum estimation error Ïµitalic-Ïµ\\epsilon,\nthe causal effects of Ağ´A on Yğ‘ŒY are then bounded as follows: where lâ€‹(a0)ğ‘™subscriptğ‘0l(a_{0}) and hâ€‹(a0)â„subscriptğ‘0h(a_{0}) are solutions to the following functional optimization problem for any given a0subscriptğ‘0a_{0} Here the inf/sup is taken with respect to all unknown cumulative distribution functions Fâ€‹(a,y,w,u)ğ¹ğ‘ğ‘¦ğ‘¤ğ‘¢F(a,y,w,u), Fâ€‹(a,w,u)ğ¹ğ‘ğ‘¤ğ‘¢F(a,w,u), Fâ€‹(y|a,w,u)ğ¹conditionalğ‘¦ğ‘ğ‘¤ğ‘¢F(y|a,w,u), Fâ€‹(w,u)ğ¹ğ‘¤ğ‘¢F(w,u), Fâ€‹(a,y,w)ğ¹ğ‘ğ‘¦ğ‘¤F(a,y,w) and Fâ€‹(u)ğ¹ğ‘¢F(u). The functional optimization problem presented in Theorem 3.1 provides tight lower and upper bounds on the average causal effect lâ€‹(a0)ğ‘™subscriptğ‘0l(a_{0}) and hâ€‹(a0)â„subscriptğ‘0h(a_{0}), respectively,\nfor any given a0âˆˆğ’œsubscriptğ‘0ğ’œa_{0}\\in\\mathcal{A}.\nOur results generalize those of 9 to random variables with estimation error,\nwhile 9 only considers the case of discrete random variables without estimation error.\nMoreover, this optimization problem can be applied to both parametric and non-parametric cases. It is essential to consider constraints for all aâˆˆğ’œğ‘ğ’œa\\in\\mathcal{A}, rather than just the given a0subscriptğ‘0a_{0} of interest,\nas only considering constraints for a0subscriptğ‘0a_{0} would result in non-tight bounds.\nAs an example, the optimal solutions generated by the non-linear optimization problem in 9 may not belong to any valid causal models,\nleading to non-tight bounds.\nTherefore, one need to consider all values of the given random variable Xğ‘‹X to obtain tight bounds,\neven if only causal bounds under a specific intervention dâ€‹oâ€‹(X=x)ğ‘‘ğ‘œğ‘‹ğ‘¥do(X=x) are required. The original optimization problem is challenging to solve due to its inefficiency and intractability.\nFirstly, the functional constraints for unknown distributions make the optimization problem intractable.\nSecondly, solving a non-linear optimization problem can often get trapped in local optima.\nIn some cases, narrow causal bounds that do not include the true causal effects may lead to critical false decisions.\nTo overcome these challenges, it is necessary to approximate the problem to make it easier to solve and to obtain global solutions with high probability. The optimization problem can be naturally simplified by probability mass functions for discrete random variables with bounded support.\nTo extend this approach to general random variables, we only consider random variables with bounded support\nand discretize ğ’œğ’œ\\mathcal{A}, ğ’²ğ’²\\mathcal{W}, ğ’°ğ’°\\mathcal{U}, and ğ’´ğ’´\\mathcal{Y} into nğ’œsubscriptğ‘›ğ’œn_{\\mathcal{A}}, nğ’²subscriptğ‘›ğ’²n_{\\mathcal{W}}, nğ’°subscriptğ‘›ğ’°n_{\\mathcal{U}}, and nğ’´subscriptğ‘›ğ’´n_{\\mathcal{Y}} disjoint blocks, respectively.\nFor random variables that take in finite values,\nthey have natural discretization.\nWe first define and then integrate both sides of the first equality over ğ’œisubscriptğ’œğ‘–\\mathcal{A}_{i}, ğ’´jsubscriptğ’´ğ‘—\\mathcal{Y}_{j}, and ğ’²ksubscriptğ’²ğ‘˜\\mathcal{W}_{k} to obtain This allows us to reformulate the first equality in terms of integration instead of the original pointwise equality. As the discretization becomes finer,\ni.e., dâ€‹iâ€‹aâ€‹mâ€‹(ğ’œi)ğ‘‘ğ‘–ğ‘ğ‘šsubscriptğ’œğ‘–diam(\\mathcal{A}_{i}), dâ€‹iâ€‹aâ€‹mâ€‹(ğ’´j)ğ‘‘ğ‘–ğ‘ğ‘šsubscriptğ’´ğ‘—diam(\\mathcal{Y}_{j}), dâ€‹iâ€‹aâ€‹mâ€‹(ğ’²k)ğ‘‘ğ‘–ğ‘ğ‘šsubscriptğ’²ğ‘˜diam(\\mathcal{W}_{k}), and dâ€‹iâ€‹aâ€‹mâ€‹(ğ’°l)ğ‘‘ğ‘–ğ‘ğ‘šsubscriptğ’°ğ‘™diam(\\mathcal{U}_{l}) approach zero for all (i,j,k,l)ğ‘–ğ‘—ğ‘˜ğ‘™(i,j,k,l),\nthe approximation error converges to zero for good distributions.\nFor discrete and finite random variables,\nthe number of constraints is finite so the approximation error can be exactly zero for natural discretization.\nThe other equalities hold naturally if the first constraint is satisfied.\nFor the constraints for all uâˆˆğ’°ğ‘¢ğ’°u\\in\\mathcal{U},\nwe integrate these constraints using the same approach as Compared with the original functional constraints in distributions, the linear constraints for xiâ€‹jâ€‹kâ€‹lsubscriptğ‘¥ğ‘–ğ‘—ğ‘˜ğ‘™x_{ijkl} are much easier to handle. After discretization, the objective of the original optimization problem is where yjsubscriptğ‘¦ğ‘—y_{j} is chosen to be âˆ«yâˆˆğ’´jyâ€‹ğ‘‘yâˆ«yâˆˆğ’´jğ‘‘ysubscriptğ‘¦subscriptğ’´ğ‘—ğ‘¦differential-dğ‘¦subscriptğ‘¦subscriptğ’´ğ‘—differential-dğ‘¦\\frac{\\int_{y\\in\\mathcal{Y}_{j}}ydy}{\\int_{y\\in\\mathcal{Y}_{j}}dy},\nas this option can reduce the approximation error (see the appendix for more details).\nIf ğ’´jsubscriptğ’´ğ‘—\\mathcal{Y}_{j} is an interval, then the above choice of yjsubscriptğ‘¦ğ‘—y_{j} is just the midpoint of ğ’´jsubscriptğ’´ğ‘—\\mathcal{Y}_{j}, The first transfer learning task requires obtaining causal bounds from the number of nğ’œsubscriptğ‘›ğ’œn_{\\mathcal{A}} optimization problems.\nSince every optimization problem shares the same feasible region, it is efficient to solve all optimization problems in a unified way.\nTo obtain the global solutions, we use Monto-Carlo method to approximate the above discrete optimization problem. Monte-Carlo algorithm.\nMonte Carlo (MC) algorithms are a key approach for sampling causal models subject to constraints.\nHowever, efficiently sampling probability tables with row and column constraints can be challenging.\nAfter discretization, the problem of sampling xiâ€‹jâ€‹kâ€‹lsubscriptğ‘¥ğ‘–ğ‘—ğ‘˜ğ‘™x_{ijkl} is equivalent to sampling from a simplex ğ’Ÿğ’Ÿ\\mathcal{D} defined by the linear constraints Let Similarly, we can define Î¸lsubscriptğœƒğ‘™\\theta_{l} and Î¸^lsubscript^ğœƒğ‘™\\hat{\\theta}_{l}, so we rewrite the linear equations as The overall equalities provide nğ’œâ€‹nğ’´â€‹nğ’²+nğ’°âˆ’1subscriptğ‘›ğ’œsubscriptğ‘›ğ’´subscriptğ‘›ğ’²subscriptğ‘›ğ’°1n_{\\mathcal{A}}n_{\\mathcal{Y}}n_{\\mathcal{W}}+n_{\\mathcal{U}}-1 linearly independent constraints,\nas both types of equalities imply âˆ‘iâ€‹jâ€‹kâ€‹lxiâ€‹jâ€‹kâ€‹l=1subscriptğ‘–ğ‘—ğ‘˜ğ‘™subscriptğ‘¥ğ‘–ğ‘—ğ‘˜ğ‘™1\\sum_{ijkl}x_{ijkl}=1.\nSince there are nğ’œâ€‹nğ’´â€‹nğ’²â€‹nğ’°subscriptğ‘›ğ’œsubscriptğ‘›ğ’´subscriptğ‘›ğ’²subscriptğ‘›ğ’°n_{\\mathcal{A}}n_{\\mathcal{Y}}n_{\\mathcal{W}}n_{\\mathcal{U}} unknown variables,\nwe need to determine the value of nğ’œâ€‹nğ’´â€‹nğ’²â€‹nğ’°âˆ’nğ’œâ€‹nğ’´â€‹nğ’²âˆ’nğ’°+1subscriptğ‘›ğ’œsubscriptğ‘›ğ’´subscriptğ‘›ğ’²subscriptğ‘›ğ’°subscriptğ‘›ğ’œsubscriptğ‘›ğ’´subscriptğ‘›ğ’²subscriptğ‘›ğ’°1n_{\\mathcal{A}}n_{\\mathcal{Y}}n_{\\mathcal{W}}n_{\\mathcal{U}}-n_{\\mathcal{A}}n_{\\mathcal{Y}}n_{\\mathcal{W}}-n_{\\mathcal{U}}+1\nunknowns. Directly sampling xiâ€‹jâ€‹kâ€‹lsubscriptğ‘¥ğ‘–ğ‘—ğ‘˜ğ‘™x_{ijkl} from distributions supported on  01  and rejecting invalid samples that do not satisfy the inequality constraints can be sample-inefficient.\nTo address this issue, we can incorporate inequalities to shrink the support of each unknown variable. For instance, Li and Pearl 9 proposed using the bounds and in their optimization problem.\nHowever, the support of each unknown xiâ€‹jâ€‹kâ€‹lsubscriptğ‘¥ğ‘–ğ‘—ğ‘˜ğ‘™x_{ijkl} in 9: [maxâ¡{0,Î¸iâ€‹jâ€‹k+Î¸lâˆ’1},minâ¡{Î¸iâ€‹jâ€‹k,Î¸l}]0subscriptğœƒğ‘–ğ‘—ğ‘˜subscriptğœƒğ‘™1subscriptğœƒğ‘–ğ‘—ğ‘˜subscriptğœƒğ‘™[\\max\\{0,\\theta_{ijk}+\\theta_{l}-1\\},\\min\\{\\theta_{ijk},\\theta_{l}\\}],\nis not as tight as those found by solving the linear programming problem (9): Clearly, the solutions generated by 9 may not satisfy all the constraints in (6),\nwhich further contributes to the lack of tightness in their approach.\nWe provide evidence for this claim by reporting the proportion of valid samples obtained with different sample spaces in TableÂ 5 for the example discussed in SectionÂ 4. We also report the simulation results in SectionÂ 4 for causal bounds,\nwhich evidently support our arguments. While the individual bounds for xiâ€‹jâ€‹kâ€‹lsubscriptğ‘¥ğ‘–ğ‘—ğ‘˜ğ‘™x_{ijkl} obtained by (9) are tight,\nthe sample efficiency is still unsatisfactory.\nTo improve sample efficiency, we introduce the sampling algorithm based on sequential LP.\nSuppose that we find a linearly independent variable index set S:={n1,n2,â‹¯,n|S|}assignğ‘†subscriptğ‘›1subscriptğ‘›2â‹¯subscriptğ‘›ğ‘†S:=\\{n_{1},n_{2},\\cdots,n_{|S|}\\} with cardinality nğ’œâ€‹nğ’´â€‹nğ’²â€‹nğ’°âˆ’nğ’œâ€‹nğ’´â€‹nğ’²âˆ’nğ’°+1subscriptğ‘›ğ’œsubscriptğ‘›ğ’´subscriptğ‘›ğ’²subscriptğ‘›ğ’°subscriptğ‘›ğ’œsubscriptğ‘›ğ’´subscriptğ‘›ğ’²subscriptğ‘›ğ’°1n_{\\mathcal{A}}n_{\\mathcal{Y}}n_{\\mathcal{W}}n_{\\mathcal{U}}-n_{\\mathcal{A}}n_{\\mathcal{Y}}n_{\\mathcal{W}}-n_{\\mathcal{U}}+1 of (8).\nFor the first variable xn1subscriptğ‘¥subscriptğ‘›1x_{n_{1}},\nwe solve (9) to find its support [ln1,hn1]subscriptğ‘™subscriptğ‘›1subscriptâ„subscriptğ‘›1[l_{n_{1}},h_{n_{1}}],\nand we sample a x^n1subscript^ğ‘¥subscriptğ‘›1\\hat{x}_{n_{1}} from a user-given distribution truncated to [ln1,hn1]subscriptğ‘™subscriptğ‘›1subscriptâ„subscriptğ‘›1[l_{n_{1}},h_{n_{1}}].\nThen, for the nisubscriptğ‘›ğ‘–n_{i} step, the previous values of xn1,â‹¯,xniâˆ’1subscriptğ‘¥subscriptğ‘›1â‹¯subscriptğ‘¥subscriptğ‘›ğ‘–1x_{n_{1}},\\cdots,x_{n_{i-1}} have been determined by sampling.\nWe add the constraints for xnjsubscriptğ‘¥subscriptğ‘›ğ‘—x_{n_{j}}, j=1,2,â‹¯,iâˆ’1ğ‘—12â‹¯ğ‘–1j=1,2,\\cdots,i-1, where it is equal to its corresponding value.\nTogether with new constraints in (9), we can find a support [lni,hni]subscriptğ‘™subscriptğ‘›ğ‘–subscriptâ„subscriptğ‘›ğ‘–[l_{n_{i}},h_{n_{i}}]\nand sample a valid value for xnisubscriptğ‘¥subscriptğ‘›ğ‘–x_{n_{i}} by solving where x^njsubscript^ğ‘¥subscriptğ‘›ğ‘—\\hat{x}_{n_{j}} is a sampled value for xnjsubscriptğ‘¥subscriptğ‘›ğ‘—x_{n_{j}}.\nAfter |S|ğ‘†|S| steps, the remaining xiâ€‹jâ€‹kâ€‹lsubscriptğ‘¥ğ‘–ğ‘—ğ‘˜ğ‘™x_{ijkl} with its index (i,j,k,l)âˆ‰Sğ‘–ğ‘—ğ‘˜ğ‘™ğ‘†(i,j,k,l)\\notin S can be solved by linear equations (8).\nThese sequential LP steps ensure that we always find valid samples in the simplex defined by (9). Sequentially solving LPs and sampling components of ğ±ğ±\\mathbf{x} induce a distribution supported on the simplex defined by (â€‹9â€‹)italic-(9italic-)\\eqref{eq: linear programming to find support}.\nAlthough this is the most computationally extensive step, it can significantly improve the sample efficiency.\nIn comparison, the sample efficiency of directly sampling xiâ€‹jâ€‹kâ€‹lsubscriptğ‘¥ğ‘–ğ‘—ğ‘˜ğ‘™x_{ijkl} from distributions supported on  01  or using the bounds proposed in 9 is much lower,\nas shown in Table 5.\nWe will discuss our sampling method on general simplex in appendix. The remaining concern is the estimation error in RHS of (6).\nDenote Since Î¸iâ€‹jâ€‹kâˆˆ subscriptğœƒğ‘–ğ‘—ğ‘˜01\\theta_{ijk}\\in , the variance of one sample is at most 1414\\frac{1}{4}.\nIf Î¸iâ€‹jâ€‹ksubscriptğœƒğ‘–ğ‘—ğ‘˜{\\theta}_{ijk} has nğ‘›n i.i.d. samples, then its largest variance of Î¸^iâ€‹jâ€‹ksubscript^ğœƒğ‘–ğ‘—ğ‘˜\\hat{\\theta}_{ijk} is 14â€‹n14ğ‘›\\frac{1}{4n}.\nWe can simply set Ïµ=12â€‹nitalic-Ïµ12ğ‘›\\epsilon=\\frac{1}{2\\sqrt{n}} if nğ‘›n is given.\nWe can sample Î¸lsubscriptğœƒğ‘™\\theta_{l} and Î¸iâ€‹jâ€‹ksubscriptğœƒğ‘–ğ‘—ğ‘˜\\theta_{ijk} from distributions with known parameters Î¸^lsubscript^ğœƒğ‘™\\hat{\\theta}_{l} and Î¸^iâ€‹jâ€‹ksubscript^ğœƒğ‘–ğ‘—ğ‘˜\\hat{\\theta}_{ijk}: For example, if one want to reflect the concentration property,\nthen one can choose the truncate Gaussian distribution ğ’©â€‹(Î¸^x,14â€‹nx)ğ’©subscript^ğœƒğ‘¥14subscriptğ‘›ğ‘¥\\mathcal{N}(\\hat{\\theta}_{x},\\frac{1}{4n_{x}}) for x=iâ€‹jâ€‹kğ‘¥ğ‘–ğ‘—ğ‘˜x=ijk or x=lğ‘¥ğ‘™x=l.\nIf one expects the worst cases, then one can choose the uniform distribution for Î¸xsubscriptğœƒğ‘¥\\theta_{x} with discrepancy parameter Ïµitalic-Ïµ\\epsilon. The optimization problem (4) after discretization is If all referred random variables are discrete, the optimization (12) can be exactly the same as (4) for natural discretization.\nFor general random variables, it is still an open problem that whether the solution to (12) will converge to\nthe solution to (4) as the discretization becomes finer.\nHowever, we have the following probability convergence results for variables ğ±:=(xiâ€‹jâ€‹kâ€‹l)assignğ±subscriptğ‘¥ğ‘–ğ‘—ğ‘˜ğ‘™\\mathbf{x}:=(x_{ijkl}).\nDenote the solutions to (12) as l^â€‹(a)^ğ‘™ğ‘\\hat{l}(a) and h^â€‹(a)^â„ğ‘\\hat{h}(a).\nFor simplicity, we denote the induced sampling measure for ğ±ğ±\\mathbf{x} as â„™ssubscriptâ„™ğ‘ \\mathbb{P}_{s}.\nThe existence and uniqueness can be easily proved by Kolmogorovâ€™s extension theorem. Assume that\nthe sampling measure â„™ssubscriptâ„™ğ‘ \\mathbb{P}_{s} satisfies âˆ€ğ±âˆˆğ’Ÿfor-allğ±ğ’Ÿ\\forall\\mathbf{x}\\in\\mathcal{D}, and âˆ€Î´>0for-allğ›¿0\\forall\\delta>0, where â„¬â€‹(ğ±,Î´)â„¬ğ±ğ›¿\\mathcal{B}(\\mathbf{x},\\delta) is a ball centered at ğ±ğ±\\mathbf{x} with radius Î´ğ›¿\\delta.\nIf the discrepancy parameter is set to 00,\nthen b(1)â€‹(a)subscriptğ‘1ğ‘b_{(1)}(a) converges to l^â€‹(a)^ğ‘™ğ‘\\hat{l}(a) in probability\nand b(B)â€‹(a)subscriptğ‘ğµğ‘b_{(B)}(a) converges to h^â€‹(a)^â„ğ‘\\hat{h}(a) in probability for Bâ†’âˆâ†’ğµB\\to\\infty. The condition â„™sâ€‹(â„¬â€‹(ğ±,Î´)âˆ©ğ’Ÿ)>0subscriptâ„™ğ‘ â„¬ğ±ğ›¿ğ’Ÿ0\\mathbb{P}_{s}(\\mathcal{B}(\\mathbf{x},\\delta)\\cap\\mathcal{D})>0 means that\nthe sampling distribution can cover all feasible models.\nThis condition can be satisfied by various continuous distributions such as the uniform distribution, truncated Gaussian distribution, and others. Similar to [ref]42, we can establish a concentration result for our sampling algorithm using Chernoffâ€™s bound.\nHowever, this result is not as useful as PropositionÂ 3.1.\nFirstly, the concentration property relies on the distribution of causal bounds,\nwhich is often complex and difficult to know in practice.\nSecondly, people are usually more interested in convergence results than concentration results in approximation problems.\nFor example, if one has several lâ€‹(a)ğ‘™ğ‘l(a) samples, it is more reasonable to use the minimum value among them rather than the average results. Regarding other statistical properties,\nMosteller  shows that if the distribution on causal bounds Fbâ€‹(x)subscriptğ¹ğ‘ğ‘¥F_{b}(x) is continuous and has a density pbâ€‹(x)subscriptğ‘ğ‘ğ‘¥p_{b}(x),\nthen the qğ‘q-th quantile b[Bâ€‹q]subscriptğ‘delimited-[]ğµğ‘b_{[Bq]} asymptotically follows the normal distribution ğ’©â€‹(Fbâˆ’1â€‹(q),qâ€‹(1âˆ’q)Bâ€‹[pbâ€‹(Fbâˆ’1â€‹(q))]2)ğ’©superscriptsubscriptğ¹ğ‘1ğ‘ğ‘1ğ‘ğµsuperscriptdelimited-[]subscriptğ‘ğ‘superscriptsubscriptğ¹ğ‘1ğ‘2\\mathcal{N}(F_{b}^{-1}(q),\\frac{q(1-q)}{B[p_{b}(F_{b}^{-1}(q))]^{2}}). To accelerate the convergence speed of AlgorithmÂ 1,\nwe can incorporate an optimization procedure OPT(min/max, object, feasible domain ğ’Ÿğ’Ÿ\\mathcal{D}, initial guess ğ±0subscriptğ±0\\mathbf{x}_{0}).\nThe optimization procedure OPT takes as input the objective function to minimize/maximize, the feasible domain ğ’Ÿğ’Ÿ\\mathcal{D}, and an initial guess ğ±0subscriptğ±0\\mathbf{x}_{0}.\nThe procedure OPT seeks to find local optima ğ±lâ€‹oâ€‹câˆˆğ’Ÿsubscriptğ±ğ‘™ğ‘œğ‘ğ’Ÿ\\mathbf{x}_{loc}\\in\\mathcal{D} that optimizes the objective function locally.\nSpecifically, in each iteration of AlgorithmÂ 1, we use the sampled value ğ±ğ±\\mathbf{x} as the initial guess ğ±0subscriptğ±0\\mathbf{x}_{0} and feed it to OPT.\nThe output of OPT is then used as the updated estimate of causal bounds.\nThe modified algorithm with OPT can be found in the appendix.\nBy leveraging the optimization procedure, we can further enhance the result in PropositionÂ 3.1 under mild assumptions on OPT. Assume that\nthe sampling measure â„™ssubscriptâ„™ğ‘ \\mathbb{P}_{s} satisfies âˆ€ğ±âˆˆğ’Ÿfor-allğ±ğ’Ÿ\\forall\\mathbf{x}\\in\\mathcal{D}, and âˆ€Î´>0for-allğ›¿0\\forall\\delta>0, where â„¬â€‹(ğ±,Î´)â„¬ğ±ğ›¿\\mathcal{B}(\\mathbf{x},\\delta) is a ball centered at ğ±ğ±\\mathbf{x} with radius Î´ğ›¿\\delta.\nGiven a deterministic procedure OPT which satisfies for any local optima ğ±lâ€‹oâ€‹csubscriptğ±ğ‘™ğ‘œğ‘\\mathbf{x}_{loc},\nthere exists Î´>0ğ›¿0\\delta>0 such that for any initial guess ğ±0âˆˆâ„¬â€‹(ğ±lâ€‹oâ€‹c,Î´)âˆ©ğ’Ÿsubscriptğ±0â„¬subscriptğ±ğ‘™ğ‘œğ‘ğ›¿ğ’Ÿ\\mathbf{x}_{0}\\in\\mathcal{B}(\\mathbf{x}_{loc},\\delta)\\cap\\mathcal{D},\nOPT can output ğ±lâ€‹oâ€‹csubscriptğ±ğ‘™ğ‘œğ‘\\mathbf{x}_{loc} as a result.\nIf the discrepancy parameter is set to 00,\nthen b(1)â€‹(a)subscriptğ‘1ğ‘b_{(1)}(a) and b(B)â€‹(a)subscriptğ‘ğµğ‘b_{(B)}(a) converge almost surely to l^â€‹(a)^ğ‘™ğ‘\\hat{l}(a) and h^â€‹(a)^â„ğ‘\\hat{h}(a) for Bâ†’âˆâ†’ğµB\\to\\infty, respectively. This result suggests that the modified algorithm with OPT can converge to the optimal solution with higher rate,\nand the convergence speed can be accelerated compared to the original algorithm.\nIntuitively, the optimization procedure OPT makes the probability Fbsubscriptğ¹ğ‘F_{b} concentrate at local optima rather than spread over the whole feasible domain.\nAdditionally, optimization procedures can usually work effectively at local regions and guarantee local optimality for sufficiently close initial guesses.\nTherefore, the assumption on OPT is not so strict. MAB.\nWe now consider the first transfer learning task for |ğ’œ|<âˆğ’œ|\\mathcal{A}|<\\infty.\nThe algorithm proceeds as follows:\nfirst, we remove any arm ağ‘a for which hâ€‹(a)<maxiâˆˆğ’œâ¡lâ€‹(i)â„ğ‘subscriptğ‘–ğ’œğ‘™ğ‘–h(a)<\\max_{i\\in\\mathcal{A}}l(i).\nNext, we truncate the upper confidence bound Uaâ€‹(t)subscriptğ‘ˆğ‘ğ‘¡U_{a}(t) for the remaining actions using their respective causal bounds.\nSpecifically, we define the truncated upper confidence bound as U^aâ€‹(t)=minâ¡{Uaâ€‹(t),hâ€‹(a)}subscript^ğ‘ˆğ‘ğ‘¡subscriptğ‘ˆğ‘ğ‘¡â„ğ‘\\hat{U}_{a}(t)=\\min\\{U_{a}(t),h(a)\\}.\nThe algorithm then chooses the action with the highest truncated UCB and update the average reward of the chosen action. Consider a |ğ’œ|ğ’œ|\\mathcal{A}|-MAB problem with rewards bounded in  01 .\nFor each arm aâˆˆğ’œğ‘ğ’œa\\in\\mathcal{A}, its expected reward Î¼asubscriptğœ‡ğ‘\\mu_{a} is bounded by [lâ€‹(a),hâ€‹(a)]ğ‘™ğ‘â„ğ‘[l(a),h(a)].\nThen in the AlgorithmÂ 2, the number of draws ğ”¼â€‹[Naâ€‹(T)]ğ”¼delimited-[]subscriptğ‘ğ‘ğ‘‡\\mathbb{E}[N_{a}(T)] for any sub-optimal arm is upper bounded as: As a simple corollary, the minimax upper bound is ğ’ªâ€‹(|ğ’œâˆ—~|â€‹Tâ€‹logâ¡T)ğ’ª~superscriptğ’œğ‘‡ğ‘‡\\mathcal{O}(\\sqrt{|\\widetilde{\\mathcal{A}^{*}}|T\\log T}),\nwhich also matches the lower bound Î©â€‹(|ğ’œâˆ—~|â€‹T)Î©~superscriptğ’œğ‘‡\\Omega(\\sqrt{|\\widetilde{\\mathcal{A}^{*}}|T}) in transfer learning setting (see more details in appendix)."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Contextual bandit learning with predictable rewards",
      "abstract": "",
      "year": "2012",
      "venue": "Artificial Intelligence and Statistics",
      "authors": "A. Agarwal, M. DudÃ­k, S. Kale, J. Langford, and R. Schapire"
    },
    {
      "index": 1,
      "title": "Bandits with unobserved confounders: A causal approach",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "E. Bareinboim, A. Forney, and J. Pearl"
    },
    {
      "index": 2,
      "title": "Transfer Learning for Contextual Multi-armed Bandits",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2211.12612",
      "authors": "C. Cai, T. T. Cai, and H. Li",
      "orig_title": "Transfer learning for contextual multi-armed bandits",
      "paper_id": "2211.12612v2"
    },
    {
      "index": 3,
      "title": "Contextual bandits with linear payoff functions",
      "abstract": "",
      "year": "2011",
      "venue": "Fourteenth International Conference on Artificial Intelligence and Statistics",
      "authors": "W. Chu, L. Li, L. Reyzin, and R. Schapire"
    },
    {
      "index": 4,
      "title": "Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "C. Dann, T. V. Marinov, M. Mohri, and J. Zimmert",
      "orig_title": "Beyond value-function gaps: Improved instance-dependent regret bounds for episodic reinforcement learning",
      "paper_id": "2107.01264v2"
    },
    {
      "index": 5,
      "title": "An automated approach to causal inference in discrete settings",
      "abstract": "",
      "year": "2023",
      "venue": "Journal of the American Statistical Association",
      "authors": "G. Duarte, N. Finkelstein, D. Knox, J. Mummolo, and I. Shpitser"
    },
    {
      "index": 6,
      "title": "Minimax theorems",
      "abstract": "",
      "year": "1953",
      "venue": "National Academy of Sciences of the United States of America",
      "authors": "K. Fan"
    },
    {
      "index": 7,
      "title": "Beyond ucb: Optimal and efficient contextual bandits with regression oracles",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "D. Foster and A. Rakhlin"
    },
    {
      "index": 8,
      "title": "Practical Contextual Bandits with Regression Oracles",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "D. Foster, A. Agarwal, M. DudÃ­k, H. Luo, and R. Schapire",
      "orig_title": "Practical contextual bandits with regression oracles",
      "paper_id": "1803.01088v1"
    },
    {
      "index": 9,
      "title": "Instance-dependent complexity of contextual bandits and reinforcement learning: A disagreement-based perspective",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2010.03104",
      "authors": "D. J. Foster, A. Rakhlin, D. Simchi-Levi, and Y. Xu"
    },
    {
      "index": 10,
      "title": "Dual Instrumental Method for Confounded Kernelized Bandits",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2209.03224",
      "authors": "X. Gong and J. Zhang",
      "orig_title": "Dual instrumental method for confounded kernelized bandits",
      "paper_id": "2209.03224v1"
    },
    {
      "index": 11,
      "title": "Provably efficient offline reinforcement learning for partially observable Markov decision processes",
      "abstract": "",
      "year": "2022",
      "venue": "39th International Conference on Machine Learning",
      "authors": "H. Guo, Q. Cai, Y. Zhang, Z. Yang, and Z. Wang"
    },
    {
      "index": 12,
      "title": "Provably Efficient Reinforcement Learning with Linear Function Approximation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "C. Jin, Z. Yang, Z. Wang, and M. I. Jordan",
      "orig_title": "Provably efficient reinforcement learning with linear function approximation",
      "paper_id": "1907.05388v2"
    },
    {
      "index": 13,
      "title": "Instrument-armed bandits",
      "abstract": "",
      "year": "2018",
      "venue": "Algorithmic Learning Theory",
      "authors": "N. Kallus"
    },
    {
      "index": 14,
      "title": "Causal Bandits: Learning Good Interventions via Causal Inference",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "F. Lattimore, T. Lattimore, and M. D. Reid",
      "orig_title": "Causal bandits: Learning good interventions via causal inference",
      "paper_id": "1606.03203v1"
    },
    {
      "index": 15,
      "title": "Bandit algorithms",
      "abstract": "",
      "year": "2020",
      "venue": "Cambridge University Press",
      "authors": "T. Lattimore and C. SzepesvÃ¡ri"
    },
    {
      "index": 16,
      "title": "Sequential transfer in multi-armed bandit with finite set of models",
      "abstract": "",
      "year": "2013",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "A. Lazaric, E. Brunskill, et al."
    },
    {
      "index": 17,
      "title": "Probabilities of causation with nonbinary treatment and effect",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2208.09568",
      "authors": "A. Li and J. Pearl"
    },
    {
      "index": 18,
      "title": "Bounds on Causal Effects and Application to High Dimensional Data",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "A. Li and J. Pearl",
      "orig_title": "Bounds on causal effects and application to high dimensional data",
      "paper_id": "2106.12121v1"
    },
    {
      "index": 19,
      "title": "Unit Selection with Nonbinary Treatment and Effect",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2208.09569",
      "authors": "A. Li and J. Pearl",
      "orig_title": "Unit selection with nonbinary treatment and effect",
      "paper_id": "2208.09569v1"
    },
    {
      "index": 20,
      "title": "Learning probabilities of causation from finite population data",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2210.08453",
      "authors": "A. Li, S. Jiang, Y. Sun, and J. Pearl"
    },
    {
      "index": 21,
      "title": "Epsilon-identifiability of causal quantities",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2301.12022",
      "authors": "A. Li, S. Mueller, and J. Pearl"
    },
    {
      "index": 22,
      "title": "A contextual-bandit approach to personalized news article recommendation",
      "abstract": "",
      "year": "2010",
      "venue": "19th international conference on World wide web",
      "authors": "L. Li, W. Chu, J. Langford, and R. E. Schapire"
    },
    {
      "index": 23,
      "title": "Transferable contextual bandit for cross-domain recommendation",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "B. Liu, Y. Wei, Y. Zhang, Z. Yan, and Q. Yang"
    },
    {
      "index": 24,
      "title": "Learning without knowing: Unobserved context in continuous transfer reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "Learning for Dynamics and Control",
      "authors": "C. Liu, Y. Zhang, Y. Shen, and M. M. Zavlanos"
    },
    {
      "index": 25,
      "title": "Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "M. Lu, Y. Min, Z. Wang, and Z. Yang",
      "orig_title": "Pessimism in the face of confounders: Provably efficient offline reinforcement learning in partially observable markov decision processes",
      "paper_id": "2205.13589v3"
    },
    {
      "index": 26,
      "title": "On some useful â€œinefficientâ€ statistics",
      "abstract": "",
      "year": "2006",
      "venue": "Springer",
      "authors": "F. Mosteller"
    },
    {
      "index": 27,
      "title": "A regret bound for greedy partially observed stochastic contextual bandits",
      "abstract": "",
      "year": "2022",
      "venue": "Decision Awareness in Reinforcement Learning Workshop at ICML",
      "authors": "H. Park and M. K. S. Faradonbeh"
    },
    {
      "index": 28,
      "title": "Analysis of Thompson Sampling for Partially Observable Contextual Multi-Armed Bandits",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Control Systems Letters",
      "authors": "H. Park and M. K. S. Faradonbeh",
      "orig_title": "Analysis of thompson sampling for partially observable contextual multi-armed bandits",
      "paper_id": "2110.12175v2"
    },
    {
      "index": 29,
      "title": "Causal inference in statistics: An overview",
      "abstract": "",
      "year": "2009",
      "venue": "Statistics surveys",
      "authors": "J. Pearl"
    },
    {
      "index": 30,
      "title": "The book of why",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of MultiDisciplinary Evaluation",
      "authors": "S. Powell"
    },
    {
      "index": 31,
      "title": "A Minimax Learning Approach to Off-Policy Evaluation in Confounded Partially Observable Markov Decision Processes",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "authors": "C. Shi, M. Uehara, J. Huang, and N. Jiang",
      "orig_title": "A minimax learning approach to off-policy evaluation in confounded partially observable markov decision processes",
      "paper_id": "2111.06784v4"
    },
    {
      "index": 32,
      "title": "Scalable Computation of Causal Bounds",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "authors": "M. Shridharan and G. Iyengar",
      "orig_title": "Scalable computation of causal bounds",
      "paper_id": "2308.02709v1"
    },
    {
      "index": 33,
      "title": "Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability",
      "abstract": "",
      "year": "2021",
      "venue": "Mathematics of Operations Research",
      "authors": "D. Simchi-Levi and Y. Xu"
    },
    {
      "index": 34,
      "title": "Bandits with Partially Observable Confounded Data",
      "abstract": "",
      "year": "2021",
      "venue": "Uncertainty in Artificial Intelligence",
      "authors": "G. Tennenholtz, U. Shalit, S. Mannor, and Y. Efroni",
      "orig_title": "Bandits with partially observable confounded data",
      "paper_id": "2006.06731v2"
    },
    {
      "index": 35,
      "title": "A general identification condition for causal effects",
      "abstract": "",
      "year": "2002",
      "venue": "Aaai/iaai",
      "authors": "J. Tian and J. Pearl"
    },
    {
      "index": 36,
      "title": "Provably efficient reinforcement learning in partially observable dynamical systems",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv",
      "authors": "M. Uehara, A. Sekhari, J. D. Lee, N. Kallus, and W. Sun"
    },
    {
      "index": 37,
      "title": "Provably Efficient Causal Reinforcement Learning with Confounded Observational Data",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "L. Wang, Z. Yang, and Z. Wang",
      "orig_title": "Provably efficient causal reinforcement learning with confounded observational data",
      "paper_id": "2006.12311v1"
    },
    {
      "index": 38,
      "title": "Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "L. Xu, H. Kanagawa, and A. Gretton",
      "orig_title": "Deep proxy causal learning and its application to confounded bandit policy evaluation",
      "paper_id": "2106.03907v5"
    },
    {
      "index": 39,
      "title": "Transfer learning in multi-armed bandit: a causal approach",
      "abstract": "",
      "year": "2017",
      "venue": "16th Conference on Autonomous Agents and MultiAgent Systems",
      "authors": "J. Zhang and E. Bareinboim"
    },
    {
      "index": 40,
      "title": "Bounding causal effects on continuous outcome",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "J. Zhang and E. Bareinboim"
    },
    {
      "index": 41,
      "title": "Partial Counterfactual Identification from Observational and Experimental Data",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "authors": "J. Zhang, J. Tian, and E. Bareinboim",
      "orig_title": "Partial counterfactual identification from observational and experimental data",
      "paper_id": "2110.05690v1"
    },
    {
      "index": 42,
      "title": "A Comprehensive Survey on Transfer Learning",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE",
      "authors": "F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, and Q. He",
      "orig_title": "A comprehensive survey on transfer learning",
      "paper_id": "1911.02685v3"
    }
  ]
}