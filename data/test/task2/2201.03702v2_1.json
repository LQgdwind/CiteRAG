{
  "paper_id": "2201.03702v2",
  "title": "Learning Logic Programs From Noisy Failures",
  "sections": {
    "motivation": "A major goal for AI is to achieve human-like intelligence through the imitation of our cognitive abilities [ref]23. To this end, AI systems often aim to mimic our automatic inductive capacity in which previous (background) knowledge and prior observations are used to infer upon new observations  - a complex task having applications in numerous domains such as image classification  and autonomous navigation [ref]5. Notably, humans have the innate ability to filter out outlying or incorrect observations, naturally and accurately handling noisy data or incomplete sets of background knowledge. Many machine learning (ML) systems have been implemented to achieve this inductive behavior, capable of identifying patterns among millions of often noisy datapoints. However, traditional ML methods such as neural networks are typically incapable of expressing their models in forms which are easily comprehensible to humans. Additionally, the knowledge learned by many of these systems lacks transferability and cannot be applied to similar problems. For example, an AI system such as AlphaGo  which has learned to effectively play the game of Go on a standard 19×19191919\\times 19 size board may struggle greatly on a board of different size. Without comprehensibility and transferability, these systems fail to achieve true levels of human cognition [ref]23 . Inductive Logic Programming  however has been an approach more capable of meeting these additional requirements. Inductive logic programming (ILP) is a form of ML wherein a logic program which defines a target predicate is learned given positive and negative examples of the predicate and background knowledge (BK). The target predicate, BK, and examples are represented as logical statements, typically as logic programs in a language such as Prolog whose notation we will use throughout this paper. More precisely, BK defines predicates and ground-truth atoms that the system may use to define the target predicate program. The aim of the system is to learn a program (or hypothesis) that correctly generalizes as many examples as possible, i.e., entails as many positive examples as possible and does not entail as many negative examples as possible. Consider Michalski’s trains problem consisting of 5 trains moving eastbound and 5 moving westbound. We will use this example throughout the paper and Figure 1.1 below visually depicts the original problem. Each train is comprised of a locomotive pulling a variable number of cars, each with distinct characteristics such as length, number of wheels, shape, number of cargo loads, shape of loads, etc. The goal of the problem is to identify a set of one or more rules which distinguishes the eastbound trains from the westbound. For instance, a solution to the original problem shown in Figure 1.1 would be the following rule: if a train has a car which is short, has two wheels, and its roof is closed, then it is eastbound and otherwise it is westbound. This problem is easily described in an ILP setting by letting one set of trains, say eastbound, represent positive examples and westbound trains represent negative examples. BK here defines each train and its characteristics with logical predicates for length, number of wheels, shape, etc. Hypotheses to these problems can be easily described using these logical predicates. For example, the rule above would be written as: eastbound(A) :- has__\\_car(A,B), short(B), two__\\_wheels(B), roof__\\_closed(B). Here, the hypothesis is claiming that any eastbound train A must have a car B and B must be short, have two wheels, and its roof must be closed. While most modern ILP systems are able to effectively learn classifiers to solve the original trains problem, more complicated variations have been used to compare system capabilities and predictive accuracies. A strong motivation behind ILP methods is the high level of comprehensibility possessed by logic programs that they return when compared to traditional ML models. Programs described by programming languages possess semantics interpretable by both humans and computers. This falls in line with Michie’s  strong criterion for machine learning and highly explainable AI whereas traditional ML methods often focus solely on improving the weak criterion, i.e., predictive accuracy. Work in this area of ultra-strong machine learning  has demonstrated how human understanding of a system can be improved by better understanding the program, thus motivating this desire for comprehensibility. The symbolic nature of the logic programs not only increases their comprehensibility but also allows for ease of lifelong learning and knowledge transfer    0, an essential criteria for human-like AI. Models can be easily reused and complex models can be built up from solving smaller problems whose logic programs are simply placed in the BK. ILP also constitutes a form of code synthesis having applications in code completion, automated programming, and novel program invention. Additionally, unlike many traditional machine learning approaches, ILP can generalize exceptionally well with just a few examples . At it’s core, the problem of ILP is efficiently searching the set of all possible hypotheses, the hypothesis space, which is typically very large. Current ILP systems take many approaches to this problem including but not limited to set covering techniques     5, meta-level encodings 4  , and neural networks 7, each with various tradeoffs. Simultaneously, as most machine learning methods must, these systems often navigate the issue of noisy datasets (i.e., misclassified examples). While some systems such as TILDE , Progol , and Aleph 5 are naturally built to withstand noise to varying degrees, they struggle with building recursive programs, often vital for constructing optimal solutions. Others such as ILASP  and Metagol  are inherently incapable of generalizing with noisy data - noise being commonly ignored by ILP systems in exchange for soundness or optimality. However in exchange, ILASP and Metagol are both capable of generating recursive programs and possess varying levels of predicate invention wherein new predicates are created by the system and defined using BK. These both are useful in constructing compact and often optimal solutions. Handling noise is a fundamental issue in machine learning as real-world data is typically endowed with misclassifications and human-errors. As such, machine learning approaches should be able to handle this noise as well as possible, though this problem is never trivial to solve. Popper 3 is an ILP system which takes a unique approach of learning from failures (LFF). Popper uses a three stage loop: generate, test, and constrain. However, unlike other three stage approaches , Popper uses theta-subsumption  in conjunction with failed hypotheses to constraint the hypothesis space. Rather than building up a solution to the problem, Popper essentially narrows down the possible solutions significantly enough that the hypothesis space can be efficiently searched. In the generate stage, Popper generates a program or hypothesis from the hypothesis space which satisfies a set of hypothesis constraints and subsequently tests the hypothesis against training examples in the test stage. Successful hypotheses are return as solution programs while failed ones are used to generate further hypothesis constraints for subsequent iterations. While Popper’s approach has notable strengths over some existing techniques such as ease of generating recursive programs, it is completely unable to handle noise. Programs generated by Popper necessarily entail all positive examples and no negative ones, clearly overfitting in the presence of any missclassified data. It is the objective of this project to modify Popper’s approach to allow it to generalize better to noisy datasets without compromising its overall performance capabilities."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Efficient program synthesis using constraint satisfaction in inductive logic programming",
      "abstract": "",
      "year": "2013",
      "venue": "J. Mach. Learn. Res., 14(1):",
      "authors": "John Ahlgren and Shiu Yin Yuen."
    },
    {
      "index": 1,
      "title": "Efficient program synthesis using constraint satisfaction in inductive logic programming",
      "abstract": "",
      "year": "2013",
      "venue": "J. Mach. Learn. Res.",
      "authors": "John Ahlgren and Shiu Yin Yuen"
    },
    {
      "index": 2,
      "title": "Improving numerical reasoning capabilities of inductive logic programming systems",
      "abstract": "",
      "year": "2004",
      "venue": "Advances in Artificial Intelligence - IBERAMIA 2004, 9th Ibero-American Conference on AI",
      "authors": "Alexessander Alves, Rui Camacho, and Eugénio C. Oliveira"
    },
    {
      "index": 3,
      "title": "Learning through hypothesis refinement using answer set programming",
      "abstract": "",
      "year": "2013",
      "venue": "Inductive Logic Programming - 23rd International Conference, ILP 2013",
      "authors": "Duangtida Athakravi, Domenico Corapi, Krysia Broda, and Alessandra Russo"
    },
    {
      "index": 4,
      "title": "Top-down induction of first-order logical decision trees",
      "abstract": "",
      "year": "1998",
      "venue": "Artif. Intell.",
      "authors": "Hendrik Blockeel and Luc De Raedt"
    },
    {
      "index": 5,
      "title": "End to End Learning for Self-Driving Cars",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, and Karol Zieba",
      "orig_title": "End to end learning for self-driving cars",
      "paper_id": "1604.07316v1"
    },
    {
      "index": 6,
      "title": "Refining complete hypotheses in ILP",
      "abstract": "",
      "year": "1999",
      "venue": "Inductive Logic Programming, 9th International Workshop, ILP-99",
      "authors": "Ivan Bratko"
    },
    {
      "index": 7,
      "title": "Inductive logic programming in answer set programming",
      "abstract": "",
      "year": "2011",
      "venue": "Inductive Logic Programming - 21st International Conference, ILP 2011",
      "authors": "Domenico Corapi, Alessandra Russo, and Emil Lupu"
    },
    {
      "index": 8,
      "title": "Efficiently learning efficient programs",
      "abstract": "",
      "year": "2017",
      "venue": "PhD thesis, Imperial College London, UK",
      "authors": "Andrew Cropper"
    },
    {
      "index": 9,
      "title": "Playgol: Learning programs through play",
      "abstract": "",
      "year": "2019",
      "venue": "Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019",
      "authors": "Andrew Cropper"
    },
    {
      "index": 10,
      "title": "Forgetting to Learn Logic Programs",
      "abstract": "",
      "year": "2020",
      "venue": "Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020",
      "authors": "Andrew Cropper",
      "orig_title": "Forgetting to learn logic programs",
      "paper_id": "1911.06643v1"
    },
    {
      "index": 11,
      "title": "Turning 30: New ideas in inductive logic programming",
      "abstract": "",
      "year": "2020",
      "venue": "Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020",
      "authors": "Andrew Cropper, Sebastijan Dumancic, and Stephen H. Muggleton"
    },
    {
      "index": 12,
      "title": "Inductive general game playing",
      "abstract": "",
      "year": "2020",
      "venue": "Mach. Learn.",
      "authors": "Andrew Cropper, Richard Evans, and Mark Law"
    },
    {
      "index": 13,
      "title": "Learning programs by learning from failures",
      "abstract": "",
      "year": "2021",
      "venue": "Mach. Learn.",
      "authors": "Andrew Cropper and Rolf Morel"
    },
    {
      "index": 14,
      "title": "Learning higher-order logic programs",
      "abstract": "",
      "year": "2020",
      "venue": "Mach. Learn.",
      "authors": "Andrew Cropper, Rolf Morel, and Stephen Muggleton"
    },
    {
      "index": 15,
      "title": "Logical reduction of metarules",
      "abstract": "",
      "year": "2020",
      "venue": "Mach. Learn.",
      "authors": "Andrew Cropper and Sophie Tourret"
    },
    {
      "index": 16,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2009)",
      "authors": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei"
    },
    {
      "index": 17,
      "title": "Learning Explanatory Rules from Noisy Data",
      "abstract": "",
      "year": "2018",
      "venue": "J. Artif. Intell. Res.",
      "authors": "Richard Evans and Edward Grefenstette",
      "orig_title": "Learning explanatory rules from noisy data",
      "paper_id": "1711.04574v2"
    },
    {
      "index": 18,
      "title": "The international general game playing competition",
      "abstract": "",
      "year": "2013",
      "venue": "AI Mag.",
      "authors": "Michael R. Genesereth and Yngvi Björnsson"
    },
    {
      "index": 19,
      "title": "Minimum Description Length Revisited",
      "abstract": "",
      "year": "2019",
      "venue": "International Journal of Mathematics for Industry",
      "authors": "Peter Grünwald and Teemu Roos",
      "orig_title": "Minimum description length revisited",
      "paper_id": "1908.08484v2"
    },
    {
      "index": 20,
      "title": "Exploiting Answer Set Programming with External Sources for Meta-Interpretive Learning",
      "abstract": "",
      "year": "2018",
      "venue": "Theory Pract. Log. Program.",
      "authors": "Tobias Kaminski, Thomas Eiter, and Katsumi Inoue",
      "orig_title": "Exploiting answer set programming with external sources for meta-interpretive learning",
      "paper_id": "1805.00068v1"
    },
    {
      "index": 21,
      "title": "Np-completeness of the set unification and matching problems",
      "abstract": "",
      "year": "1986",
      "venue": "8th International Conference on Automated Deduction",
      "authors": "Deepak Kapur and Paliath Narendran"
    },
    {
      "index": 22,
      "title": "Mcnemar test",
      "abstract": "",
      "year": "2014",
      "venue": "Wiley StatsRef: Statistics Reference Online",
      "authors": "Peter A Lachenbruch"
    },
    {
      "index": 23,
      "title": "Building Machines That Learn and Think Like People",
      "abstract": "",
      "year": "2016",
      "venue": "CoRR",
      "authors": "Brenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman",
      "orig_title": "Building machines that learn and think like people",
      "paper_id": "1604.00289v3"
    },
    {
      "index": 24,
      "title": "Inductive learning of answer set programs",
      "abstract": "",
      "year": "2018",
      "venue": "PhD thesis, Imperial College London, UK",
      "authors": "Mark Law"
    },
    {
      "index": 25,
      "title": "Inductive learning of answer set programs",
      "abstract": "",
      "year": "2014",
      "venue": "Logics in Artificial Intelligence - 14th European Conference, JELIA 2014",
      "authors": "Mark Law, Alessandra Russo, and Krysia Broda"
    },
    {
      "index": 26,
      "title": "Inductive Learning of Answer Set Programs from Noisy Examples",
      "abstract": "",
      "year": "2018",
      "venue": "CoRR",
      "authors": "Mark Law, Alessandra Russo, and Krysia Broda",
      "orig_title": "Inductive learning of answer set programs from noisy examples",
      "paper_id": "1808.08441v1"
    },
    {
      "index": 27,
      "title": "Bias reformulation for one-shot function induction",
      "abstract": "",
      "year": "2014",
      "venue": "ECAI 2014 - 21st European Conference on Artificial Intelligence",
      "authors": "Dianhuan Lin, Eyal Dechter, Kevin Ellis, Joshua B. Tenenbaum, and Stephen Muggleton"
    },
    {
      "index": 28,
      "title": "Machine learning in the next five years",
      "abstract": "",
      "year": "1988",
      "venue": "Third European Working Session on Learning, EWSL 1988",
      "authors": "Donald Michie"
    },
    {
      "index": 29,
      "title": "A bounded search space of clausal theories",
      "abstract": "",
      "year": "1999",
      "venue": "Inductive Logic Programming, 9th International Workshop, ILP-99",
      "authors": "Herman Midelfart"
    },
    {
      "index": 30,
      "title": "Machine learning, International Edition",
      "abstract": "",
      "year": "1997",
      "venue": "McGraw-Hill Series in Computer Science. McGraw-Hill",
      "authors": "Tom M. Mitchell"
    },
    {
      "index": 31,
      "title": "Never-ending learning",
      "abstract": "",
      "year": "2018",
      "venue": "Commun. ACM",
      "authors": "Tom M. Mitchell, William W. Cohen, Estevam R. Hruschka Jr., Partha P. Talukdar, Bo Yang, Justin Betteridge, Andrew Carlson, Bhavana Dalvi Mishra, Matt Gardner, Bryan Kisiel, Jayant Krishnamurthy, Ni Lao, Kathryn Mazaitis, Thahir Mohamed, Ndapandula Nakashole, Emmanouil A. Platanios, Alan Ritter, Mehdi Samadi, Burr Settles, Richard C. Wang, Derry Wijaya, Abhinav Gupta, Xinlei Chen, Abulhair Saparov, Malcolm Greaves, and Joel Welling"
    },
    {
      "index": 32,
      "title": "Inductive logic programming",
      "abstract": "",
      "year": "1991",
      "venue": "New Gener. Comput.",
      "authors": "Stephen Muggleton"
    },
    {
      "index": 33,
      "title": "Inverse entailment and progol",
      "abstract": "",
      "year": "1995",
      "venue": "New Gener. Comput.",
      "authors": "Stephen Muggleton"
    },
    {
      "index": 34,
      "title": "Meta-interpretive learning from noisy images",
      "abstract": "",
      "year": "2018",
      "venue": "Mach. Learn.",
      "authors": "Stephen Muggleton, Wang-Zhou Dai, Claude Sammut, Alireza Tamaddoni-Nezhad, Jing Wen, and Zhi-Hua Zhou"
    },
    {
      "index": 35,
      "title": "Meta-interpretive learning of higher-order dyadic datalog: predicate invention revisited",
      "abstract": "",
      "year": "2015",
      "venue": "Mach. Learn.",
      "authors": "Stephen H. Muggleton, Dianhuan Lin, and Alireza Tamaddoni-Nezhad"
    },
    {
      "index": 36,
      "title": "Ultra-strong machine learning: comprehensibility of programs learned with ILP",
      "abstract": "",
      "year": "2018",
      "venue": "Mach. Learn.",
      "authors": "Stephen H. Muggleton, Ute Schmid, Christina Zeller, Alireza Tamaddoni-Nezhad, and Tarek R. Besold"
    },
    {
      "index": 37,
      "title": "Foundations of inductive logic programming, volume 1228",
      "abstract": "",
      "year": "1997",
      "venue": "Springer Science & Business Media",
      "authors": "Shan-Hwei Nienhuys-Cheng and Ronald De Wolf"
    },
    {
      "index": 38,
      "title": "Automatic methods of inductive inference",
      "abstract": "",
      "year": "1972",
      "venue": "PhD thesis, The University of Edinburgh",
      "authors": "Gordon Plotkin"
    },
    {
      "index": 39,
      "title": "Induction of decision trees",
      "abstract": "",
      "year": "1986",
      "venue": "Mach. Learn.",
      "authors": "J. Ross Quinlan"
    },
    {
      "index": 40,
      "title": "Learning logical definitions from relations",
      "abstract": "",
      "year": "1990",
      "venue": "Mach. Learn.",
      "authors": "J. Ross Quinlan"
    },
    {
      "index": 41,
      "title": "Inferring decision trees using the minimum description length principle",
      "abstract": "",
      "year": "1989",
      "venue": "Inf. Comput.",
      "authors": "J. Ross Quinlan and Ronald L. Rivest"
    },
    {
      "index": 42,
      "title": "Modeling by shortest data description",
      "abstract": "",
      "year": "1978",
      "venue": "Autom.",
      "authors": "Jorma Rissanen"
    },
    {
      "index": 43,
      "title": "Best-Effort Inductive Logic Programming via Fine-grained Cost-based Hypothesis Generation The Inspire System at the Inductive Logic Programming Competition",
      "abstract": "",
      "year": "2018",
      "venue": "Mach. Learn.",
      "authors": "Peter Schüller and Mishal Benz",
      "orig_title": "Best-effort inductive logic programming via fine-grained cost-based hypothesis generation - the inspire system at the inductive logic programming competition",
      "paper_id": "1707.02729v2"
    },
    {
      "index": 44,
      "title": "Mastering the game of go with deep neural networks and tree search",
      "abstract": "",
      "year": "2016",
      "venue": "Nat.",
      "authors": "David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Vedavyas Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis"
    },
    {
      "index": 45,
      "title": "The aleph manual",
      "abstract": "",
      "year": "2001",
      "venue": "Machine Learning at the Computing Laboratory, Oxford University",
      "authors": "Ashwin Srinivasan"
    }
  ]
}