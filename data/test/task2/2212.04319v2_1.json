{
  "paper_id": "2212.04319v2",
  "title": "On the Robustness of Normalizing Flows for Inverse Problems in Imaging",
  "sections": {
    "introduction": "Deep learning techniques have demonstrated great potential for solving ill-posed inverse problems in imaging¬† . Among them, conditional normalizing flow (NF)-based methods have a unique advantage over other deep learning methods, which is the capability of generating diverse solutions for a given input. Conditional NFs¬† have been explored for various inverse problems in imaging such as\nsuper-resolution space generation¬†  0     0, low-light image enhancement¬†5 , guided image generation¬† 7, image dehazing¬†, denoising¬†  and inpainting¬†. Most of these prior works with conditional NFs for image processing and low-level computer vision have focused on excellent performance with diverse solutions. Existing conditional NFs for inverse problems in imaging occasionally generate unintended erroneous image samples. In super-resolution space generation, similar artifacts were observed in multiple independent works¬† 0. For example, Song et al. reported that those artifacts occurred for more than 2% of all test images¬†0 and we confirmed that these artifacts occasionally appear as illustrated in the top row of Figure¬†1.\nUnintended artifacts were also observed in another computer vision task with conditional NFs.\nIn low-light image enhancement¬†5, we also revealed that black regions with ùô∏ùöóùöèùô∏ùöóùöè\\mathtt{Inf} values sometimes occur for certain conditional inputs as we sample diverse images as in the bottom row of Figure¬†1.\nIn unconditional NFs, such as Glow¬†6, similar artifacts called ‚Äúexploding inverse‚Äù were observed¬†, which were known to occasionally occur only when the training and test sets come from different distributions (e.g., training with CIFAR-10¬†, testing with tinyImageNet¬†9). However, in conditional NFs for inverse problems in imaging, artifacts may sometimes occur even when the training and test sets follow the same distribution, suggesting that the existing ‚Äúexploding inverse‚Äù is insufficient to explain this phenomenon. In this work, we address the robustness issue for solving inverse problems in imaging using conditional NFs by investigating the origins of these artifacts and proposing how to avoid them.\nFirstly, we empirically and theoretically reveal that artifacts arising from conditional NFs for inverse problems are caused by a mechanism very similar to that of unconditional NFs‚Äô exploding inverses¬†. This implies that although the conditional inputs that yielded exploding inverses are sampled from the same distribution as the training dataset, they may be out-of-distribution (OOD) data from the perspective of the conditioning network. We then validate this remark (Remark 1) by showing that the probability of causing erroneous pixels is highly correlated with a Mahalanobis distance-based OOD score¬† for inverse problems. Lastly, based on our investigations, we propose another remark (Remark 2) on how to avoid the exploding inverses in conditional NFs for inverse problems in imaging. As a simple remedy to meet the criteria of our remark, we suggest substituting the affine coupling layers with the modified rational-quadratic (RQ) spline coupling layers¬† in NFs, to encourage the robustness of generated image samples. Our experimental results demonstrated that our suggested methods effectively suppressed exploding inverses often occurring in conditional NFs for super-resolution space generation and low-light image enhancement.\nThe contributions of this paper are summarized as follows:\n Revealing theoretically and experimentally that exploding inverses also occur in conditional affine coupling flows for inverse problems occasionally, even when the training and test dataset are sampled from the same distribution.\n Investigating that conditional inputs for yielding exploding inverses are out-of-distribution, from the perspective of the conditioning network, for normalizing flows (NFs) of inverse problems in imaging. Proposing a remark on how to avoid the exploding inverses in conditional NFs and demonstrating how to use it by considering other factors such as performance. Demonstrating that the proposed method effectively suppressed erroneous samples in 2D toy experiment, super-resolution space generation and low-light image enhancement.\n"
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Noise Flow: Noise Modeling with Conditional Normalizing Flows",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Abdelrahman Abdelhamed, Marcus¬†A. Brubaker, and Michael¬†S. Brown",
      "orig_title": "Noise flow: Noise modeling with conditional normalizing flows",
      "paper_id": "1908.08453v1"
    },
    {
      "index": 1,
      "title": "Ntire 2017 challenge on single image super-resolution: Dataset and study",
      "abstract": "",
      "year": "2017",
      "venue": "CVPRW",
      "authors": "Eirikur Agustsson and Radu Timofte"
    },
    {
      "index": 2,
      "title": "Guided Image Generation with Conditional Invertible Neural Networks",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1907.02392",
      "authors": "Lynton Ardizzone, Carsten L√ºth, Jakob Kruse, Carsten Rother, and Ullrich K√∂the",
      "orig_title": "Guided image generation with conditional invertible neural networks",
      "paper_id": "1907.02392v3"
    },
    {
      "index": 3,
      "title": "Understanding and mitigating exploding inverses in invertible neural networks",
      "abstract": "",
      "year": "2021",
      "venue": "AISTATS",
      "authors": "Jens Behrmann, Paul Vicol, Kuan-Chieh Wang, Roger Grosse, and Joern-Henrik Jacobsen"
    },
    {
      "index": 4,
      "title": "NICE: Non-linear Independent Components Estimation",
      "abstract": "",
      "year": "2015",
      "venue": "ICLR (Workshop)",
      "authors": "Laurent Dinh, David Krueger, and Yoshua Bengio",
      "orig_title": "NICE: non-linear independent components estimation",
      "paper_id": "1410.8516v6"
    },
    {
      "index": 5,
      "title": "Density estimation using Real NVP",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR (Poster)",
      "authors": "Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio",
      "orig_title": "Density estimation using real NVP",
      "paper_id": "1605.08803v3"
    },
    {
      "index": 6,
      "title": "Invertible generative modeling using linear rational splines",
      "abstract": "",
      "year": "2020",
      "venue": "AISTATS",
      "authors": "Hadi¬†Mohaghegh Dolatabadi, Sarah Erfani, and Christopher Leckie"
    },
    {
      "index": 7,
      "title": "Neural spline flows",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Conor Durkan, Artur Bekasov, Iain Murray, and George Papamakarios"
    },
    {
      "index": 8,
      "title": "Cubic-Spline Flows",
      "abstract": "",
      "year": "2019",
      "venue": "ICML Workshop on Invertible Neural Nets and Normalizing Flows",
      "authors": "Conor Durkan, Artur Bekasovs, Iain Murray, and Georgios Papamakarios",
      "orig_title": "Cubic-spline flows",
      "paper_id": "1906.02145v1"
    },
    {
      "index": 9,
      "title": "Flow-based unconstrained lip to speech generation",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI",
      "authors": "Jinzheng He, Zhou Zhao, Yi Ren, Jinglin Liu, Baoxing Huai, and Nicholas¬†Jing Yuan"
    },
    {
      "index": 10,
      "title": "Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Jonathan Ho, Xi Chen, Aravind Srinivas, Yan Duan, and Pieter Abbeel",
      "orig_title": "Flow++: Improving flow-based generative models with variational dequantization and architecture design",
      "paper_id": "1902.00275v2"
    },
    {
      "index": 11,
      "title": "Single image super-resolution from transformed self-exemplars",
      "abstract": "",
      "year": "2015",
      "venue": "CVPR",
      "authors": "Jia-Bin Huang, Abhishek Singh, and Narendra Ahuja"
    },
    {
      "index": 12,
      "title": "Srflow-da: Super-resolution using normalizing flow with deep convolutional block",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Younghyun Jo, Sejong Yang, and Seon¬†Joo Kim"
    },
    {
      "index": 13,
      "title": "Noise Conditional Flow Model for Learning the Super-Resolution Space",
      "abstract": "",
      "year": "2021",
      "venue": "CVPRW",
      "authors": "Younggeun Kim and Donghee Son",
      "orig_title": "Noise conditional flow model for learning the super-resolution space",
      "paper_id": "2106.04428v1"
    },
    {
      "index": 14,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2015",
      "venue": "ICLR",
      "authors": "Diederik¬†P Kingma and Jimmy Ba"
    },
    {
      "index": 15,
      "title": "Glow: Generative Flow with Invertible 1√ó1 Convolutions",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Durk¬†P Kingma and Prafulla Dhariwal",
      "orig_title": "Glow: Generative flow with invertible 1x1 convolutions",
      "paper_id": "1807.03039v2"
    },
    {
      "index": 16,
      "title": "Improved variational inference with inverse autoregressive flow",
      "abstract": "",
      "year": "2016",
      "venue": "NIPS",
      "authors": "Durk¬†P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling"
    },
    {
      "index": 17,
      "title": "Auto-encoding variational bayes",
      "abstract": "",
      "year": "2014",
      "venue": "ICLR",
      "authors": "Diederik¬†P. Kingma and Max Welling"
    },
    {
      "index": 18,
      "title": "Why Normalizing Flows Fail to Detect Out-of-Distribution Data",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Polina Kirichenko, Pavel Izmailov, and Andrew¬†G Wilson",
      "orig_title": "Why normalizing flows fail to detect out-of-distribution data",
      "paper_id": "2006.08545v1"
    },
    {
      "index": 19,
      "title": "Smooth Normalizing Flows",
      "abstract": "",
      "year": "2021",
      "venue": "NeurIPS",
      "authors": "Jonas K√∂hler, Andreas Kr√§mer, and Frank No√©",
      "orig_title": "Smooth normalizing flows",
      "paper_id": "2110.00351v2"
    },
    {
      "index": 20,
      "title": "Learning multiple layers of features from tiny images",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "Alex Krizhevsky, Geoffrey Hinton, et¬†al."
    },
    {
      "index": 21,
      "title": "A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin",
      "orig_title": "A simple unified framework for detecting out-of-distribution samples and adversarial attacks",
      "paper_id": "1807.03888v2"
    },
    {
      "index": 22,
      "title": "Hierarchical Conditional Flow: A Unified Framework for Image Super-Resolution and Image Rescaling",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Jingyun Liang, Andreas Lugmayr, Kai Zhang, Martin Danelljan, Luc Van¬†Gool, and Radu Timofte",
      "orig_title": "Hierarchical conditional flow: A unified framework for image super-resolution and image rescaling",
      "paper_id": "2108.05301v1"
    },
    {
      "index": 23,
      "title": "Benchmarking low-light image enhancement and beyond",
      "abstract": "",
      "year": "2021",
      "venue": "IJCV",
      "authors": "Jiaying Liu, Xu Dejia, Wenhan Yang, Minhao Fan, and Haofeng Huang"
    },
    {
      "index": 24,
      "title": "Deep learning face attributes in the wild",
      "abstract": "",
      "year": "2015",
      "venue": "ICCV",
      "authors": "Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang"
    },
    {
      "index": 25,
      "title": "Structured Output Learning with Conditional Generative Flows",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI",
      "authors": "You Lu and Bert Huang",
      "orig_title": "Structured output learning with conditional generative flows",
      "paper_id": "1905.13288v3"
    },
    {
      "index": 26,
      "title": "Using deep neural networks for inverse problems in imaging: Beyond analytical methods",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Signal Processing Magazine",
      "authors": "Alice Lucas, Michael Iliadis, Rafael Molina, and Aggelos¬†K. Katsaggelos"
    },
    {
      "index": 27,
      "title": "SRFlow: Learning the Super-Resolution Space with Normalizing Flow",
      "abstract": "",
      "year": "2020",
      "venue": "ECCV",
      "authors": "Andreas Lugmayr, Martin Danelljan, Luc¬†Van Gool, and Radu Timofte",
      "orig_title": "Srflow: Learning the super-resolution space with normalizing flow",
      "paper_id": "2006.14200v2"
    },
    {
      "index": 28,
      "title": "Ntire 2021 learning the super-resolution space challenge",
      "abstract": "",
      "year": "2021",
      "venue": "CVPRW",
      "authors": "Andreas Lugmayr, Martin Danelljan, and Radu Timofte"
    },
    {
      "index": 29,
      "title": "Ntire 2022 challenge on learning the super-resolution space",
      "abstract": "",
      "year": "2022",
      "venue": "CVPRW",
      "authors": "Andreas Lugmayr, Martin Danelljan, Radu Timofte, Kang-wook Kim, Younggeun Kim, Jae-young Lee, Zechao Li, Jinshan Pan, Dongseok Shim, Ki-Ung Song, et¬†al."
    },
    {
      "index": 30,
      "title": "Normalizing Flow as a Flexible Fidelity Objective for Photo-Realistic Super-resolution",
      "abstract": "",
      "year": "2022",
      "venue": "WACV",
      "authors": "Andreas Lugmayr, Martin Danelljan, Fisher Yu, Luc Van¬†Gool, and Radu Timofte",
      "orig_title": "Normalizing flow as a flexible fidelity objective for photo-realistic super-resolution",
      "paper_id": "2111.03649v1"
    },
    {
      "index": 31,
      "title": "Neural importance sampling",
      "abstract": "",
      "year": "2019",
      "venue": "ACM Transactions on Graphics (TOG)",
      "authors": "Thomas M√ºller, Brian McWilliams, Fabrice Rousselle, Markus Gross, and Jan Nov√°k"
    },
    {
      "index": 32,
      "title": "Deep learning techniques for inverse problems in imaging",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Journal on Selected Areas in Information Theory",
      "authors": "Gregory Ongie, Ajil Jalal, Christopher¬†A. Metzler, Richard¬†G. Baraniuk, Alexandros¬†G. Dimakis, and Rebecca Willett"
    },
    {
      "index": 33,
      "title": "Normalizing Flows for Probabilistic Modeling and Inference",
      "abstract": "",
      "year": "2021",
      "venue": "Journal of Machine Learning Research",
      "authors": "George Papamakarios, Eric¬†T Nalisnick, Danilo¬†Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan",
      "orig_title": "Normalizing flows for probabilistic modeling and inference",
      "paper_id": "1912.02762v2"
    },
    {
      "index": 34,
      "title": "Masked Autoregressive Flow for Density Estimation",
      "abstract": "",
      "year": "2017",
      "venue": "NIPS",
      "authors": "George Papamakarios, Theo Pavlakou, and Iain Murray",
      "orig_title": "Masked autoregressive flow for density estimation",
      "paper_id": "1705.07057v4"
    },
    {
      "index": 35,
      "title": "WaveGlow: A Flow-based Generative Network for Speech Synthesis",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE ICASSP",
      "authors": "Ryan Prenger, Rafael Valle, and Bryan Catanzaro",
      "orig_title": "Waveglow: A flow-based generative network for speech synthesis",
      "paper_id": "1811.00002v1"
    },
    {
      "index": 36,
      "title": "C-Flow: Conditional Generative Flow Models for Images and 3D Point Clouds",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Albert Pumarola, Stefan Popov, Francesc Moreno-Noguer, and Vittorio Ferrari",
      "orig_title": "C-flow: Conditional generative flow models for images and 3d point clouds",
      "paper_id": "1912.07009v2"
    },
    {
      "index": 37,
      "title": "Variational inference with normalizing flows",
      "abstract": "",
      "year": "2015",
      "venue": "ICML",
      "authors": "Danilo Rezende and Shakir Mohamed"
    },
    {
      "index": 38,
      "title": "Normalizing Flows on Tori and Spheres",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Danilo¬†Jimenez Rezende, George Papamakarios, S√©bastien Racaniere, Michael Albergo, Gurtej Kanwar, Phiala Shanahan, and Kyle Cranmer",
      "orig_title": "Normalizing flows on tori and spheres",
      "paper_id": "2002.02428v2"
    },
    {
      "index": 39,
      "title": "FS-NCSR: Increasing Diversity of the Super-Resolution Space via Frequency Separation and Noise-Conditioned Normalizing Flow",
      "abstract": "",
      "year": "2022",
      "venue": "CVPRW",
      "authors": "Ki-Ung Song, Dongseok Shim, Kang-wook Kim, Jae-young Lee, and Younggeun Kim",
      "orig_title": "Fs-ncsr: Increasing diversity of the super-resolution space via frequency separation and noise-conditioned normalizing flow",
      "paper_id": "2204.09679v1"
    },
    {
      "index": 40,
      "title": "Generative Flows with Invertible Attentions",
      "abstract": "",
      "year": "2022",
      "venue": "CVPR",
      "authors": "Rhea¬†Sanjay Sukthanker, Zhiwu Huang, Suryansh Kumar, Radu Timofte, and Luc Van¬†Gool",
      "orig_title": "Generative flows with invertible attentions",
      "paper_id": "2106.03959v4"
    },
    {
      "index": 41,
      "title": "Ntire 2017 challenge on single image super-resolution: Methods and results",
      "abstract": "",
      "year": "2017",
      "venue": "CVPRW",
      "authors": "Radu Timofte, Eirikur Agustsson, Luc Van¬†Gool, Ming-Hsuan Yang, and Lei Zhang"
    },
    {
      "index": 42,
      "title": "Learning Diverse Tone Styles for Image Retouching",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2207.05430",
      "authors": "Haolin Wang, Jiawei Zhang, Ming Liu, Xiaohe Wu, and Wangmeng Zuo",
      "orig_title": "Learning diverse tone styles for image retouching",
      "paper_id": "2207.05430v2"
    },
    {
      "index": 43,
      "title": "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks",
      "abstract": "",
      "year": "2018",
      "venue": "ECCVW",
      "authors": "Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Yu Qiao, and Chen¬†Change Loy",
      "orig_title": "Esrgan: Enhanced super-resolution generative adversarial networks",
      "paper_id": "1809.00219v2"
    },
    {
      "index": 44,
      "title": "Low-Light Image Enhancement with Normalizing Flow",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI",
      "authors": "Yufei Wang, Renjie Wan, Wenhan Yang, Haoliang Li, Lap-Pui Chau, and Alex¬†C Kot",
      "orig_title": "Low-light image enhancement with normalizing flow",
      "paper_id": "2109.05923v1"
    },
    {
      "index": 45,
      "title": "Deep Retinex Decomposition for Low-Light Enhancement",
      "abstract": "",
      "year": "2018",
      "venue": "BMVC",
      "authors": "Chen Wei, Wenjing Wang, Wenhan Yang, and Jiaying Liu",
      "orig_title": "Deep retinex decomposition for low-light enhancement",
      "paper_id": "1808.04560v1"
    },
    {
      "index": 46,
      "title": "Stochastic Normalizing Flows",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Hao Wu, Jonas K√∂hler, and Frank No√©",
      "orig_title": "Stochastic normalizing flows",
      "paper_id": "2002.09547v2"
    },
    {
      "index": 47,
      "title": "Bin-flow: Bidirectional normalizing flow for robust image dehazing",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE Transactions on Image Processing",
      "authors": "Yiqiang Wu, Dapeng Tao, Yibing Zhan, and Chenyang Zhang"
    },
    {
      "index": 48,
      "title": "Learning from massive noisy labeled data for image classification",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang"
    },
    {
      "index": 49,
      "title": "Revisiting single image super-resolution under internet environment: blur kernels and reconstruction algorithms",
      "abstract": "",
      "year": "2015",
      "venue": "Pacific Rim Conference on Multimedia",
      "authors": "Kai Zhang, Xiaoyu Zhou, Hongzhi Zhang, and Wangmeng Zuo"
    }
  ]
}