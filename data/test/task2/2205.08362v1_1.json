{
  "paper_id": "2205.08362v1",
  "title": "LPC-AD: Fast and Accurate Multivariate Time Series Anomaly Detection via Latent Predictive Coding",
  "sections": {
    "related works": "MTS anomaly detection is a challenging problem, and\nit has been studied extensively.\nFrom a methodological perspective,\nprevious works can be categorized into two research lines,\ni.e., (1) classical methods and (2) deep learning based methods.\nNotable classical methods include\n     ,\njust to name a few.\nOne limitation of classical methods is that the expressiveness is low,\nresulting low anomaly detection accuracy .\nDeep learning based methods address this limitation.\nOur work falls into the research line of deep learning based methods.\nMethodologically, previous works on deep learning based\nMTS anomaly detection methods\ncan be categorized into four groups:\n(1) forecasting based methods, (2) reconstruction based methods,\n(3) hybrid methods combining forecasting and reconstruction\n,\nand\n (4) miscellaneous methods.\n Forecasting based MTS anomaly detection methods    [ref]13 \nuse a prediction function to capture normal spatial and temporal\ndependence in MTS,\nand they identify abnormal dependence, i.e., report anomaly,\nwhen the prediction error is relatively large.\nThe LSTM-AD  uses a stacked LSTM to\npredict future data points from historical data points.\nIt uses the likelihood of the prediction error to quantify the anomaly\nscore of a data point,\nand it reports an anomaly whenever the anomaly score exceeds a given alert threshold.\nChauhan et al. applied the LSTM-AD to detect anomalies in electrocardiography time series .\nBontemps et al.  used the vanilla LSTM for forecasting\nand quantified the anomaly score via the prediction errors of several steps.\nLSTM-NDT[ref]13 also uses the vanilla LSTM for forecasting and uses the prediction error of\na data point to quantify the anomaly score.\nIt develops a non-parameterized method to select the alert threshold.\nHowever, the detection accuracy of\nthese LSTM based MTS anomaly detection methods\n   [ref]13\nis not high enough, because LSTM alone lacks expressiveness to capture complex dependence in MTS [ref]37.\nDeng et al.  proposed\na graph neural network to capture spatial dependence\nof multi-time series explicitly\nand used a graph attention network to predict future data points\nfrom historical data points.\nHowever, the graph attention network makes this method\nunable to capture long-term dependence well.\nThese forecasting based methods have a relatively fast training speed,\nbut their detection accuracy is greatly outperformed by reconstruction\nbased methods   [ref]37. Reconstruction based methods\ncapture the normal spatial and temporal dependence in multi-time series\nvia a low dimensional latent representation,\nand they identify abnormal dependence, i.e., report anomaly,\nwhen the reconstruction from the low dimensional latent representation differs from the actual observation.\nFrom a model architecture’s perspective,\nprevious works can be categorized into\nautoencoder based ones [ref]4   [ref]37  \nand variational autoencoder based ones     . Autoencoder (AE) based methods.\nThe EncDec-AD \ninstantiates the autoencoder architecture with the vanilla LSTM for MTS\nanomaly detection.\nThe reconstruction error of a data point quantifies the anomaly score,\nand EncDec-AD reports an anomaly whenever the anomaly score exceeds a given threshold.\nThe MSCRED  improves the expressiveness of EncDec-AD.\nIt uses a convolutional network to capture spatial dependence and\na convolutional LSTM to capture temporal dependence.\nHowever, it is time-consuming to train the model, and it requires\na large amount of training data to fit the model well.\nRecent autoencoder based methods [ref]4  [ref]37\ncontribute simple models with a fast training speed,\nwhile retaining a fairly high detection accuracy.\nThe openGauss  instantiates the autoencoder architecture with\na tree-based LSTM for MTS anomaly detection.\nIt has a fast training speed and low memory requirement.\nUSAD [ref]4 further improves the\ntraining speed via adversarial training.\nIt has one simple encoder and two decoders.\nTwo decoders share the same encoder, and\nthe purpose of two decoders is to enable adversarial training,\nwhich amplifies the temporal anomaly.\nThe encoder and two decoders are composed of several linear layers,\nenabling a fast training speed.\nHowever, simple linear layers cannot capture temporal dependence well\nbecause they can not process longer input.\nTranAD [ref]37 replaced the linear layer of USAD\nwith transformer network\nto capture temporal dependence better.\nTranAD contributes a slightly more sophisticated model than USAD.\nIt is shown to have a higher detection accuracy than USAD,\nwhile retaining a fast training speed.\nCompared to these works, our work presents a new architecture,\nwhich combines autoencoder,\npredictive coding and randomized perturbation.\nFurthermore, our work outperforms them in both training speed\nand detection accuracy. Variational autoencoder (VAE) based methods.:\nThe Donut  extends the vanilla VAE by\nchanging the linear layers to represent the variance of latent variables to\na layer with the soft plus operation.\nThe LSTM-VAE  instantiates the VAE architecture by\nreplacing the feed-forward network of VAE with a vanilla LSTM network to\ncapture the temporal dependence in MTS.\nTo improve the expressiveness of Donut and LSTM-VAE,\nOmniAnomaly  changes the latent variables’ distribution of\nLSTM-VAE from standard Gaussian distribution\nto a more sophisticated distribution.\nThe sophisticated distribution in OmniAnomaly is a combination of\na linear Gaussian state space model \nand a normalizing flow .\nOmniAnomaly further uses latent variable linking to enhance the temporal dependence between latent variables.\nInterFusion  improves OmniAnomaly by\nusing an anomaly pre-filtering algorithm to filter out potential anomalous data in the training set.\nIt also compresses the multi-time series\nvia two-view embedding.\nTo better capture spatial dependence in MTS,\nthe SDFVAE \ninstantiates the VAE architecture with a convolutional neural network, a BiLSTM, and recurrent VAE.\nAlthough OmniAnomaly, InterFusion and SDFVAE have high expressiveness\nbecause of their sophisticated models,\ntheir training processes are very resource-intensive and time-consuming.\nDifferent from them, our work is an autoencoder based method,\nand it outperforms them in both training speed\nand detection accuracy. Hybrid methods combine forecasting-based methods and reconstruction based methods\nin the sense that they jointly optimize a forecasting model and a reconstruction model.\nThey attempt to overcome the shortcomings that forecasting based methods\nand reconstruction based methods suffer on their own .\nOne notable architecture of hybrid methods is proposed by Srivastava et al. \nThis architecture contains one encoder and two decoders sharing the same encoder.\nOne of the decoders is designed for forecasting purposes,\nand the other is designed for reconstruction purposes.\nIn the seminal work on this architecture, Srivastava et al. \ninstantiated this architecture with the vanilla LSTM.\nMedel et al.  instantiated this architecture\nwith convolutional LSTM to have a high expressiveness capability.\nZhao et al.  instantiated this architecture\nwith a 3D convolutional neural network\nfor better detection of video series anomalies.\nThese methods are mainly designed for video series,\nand they do not capture the spatial and temporal dependence in multi-time series well.\nThe MTAD-GAT  is composed of a graph attention network for forecasting,\nwhich captures the spatial dependence,\nand a vanilla VAE for reconstruction, which captures the likelihood of a data point.\nIt jointly optimizes those two models and quantifies the anomaly score with\nboth the prediction error and the reconstruction error for anomaly detection.\nThe CAEM  is composed of a convolutional autoencoder\nfor reconstruction and a BiLSTM for forecasting.\nIt also jointly optimizes those two models and quantifies the anomaly score with\nboth the prediction error and the reconstruction error for anomaly detection.\nHowever, these methods have a high computational cost in training\nand low scalability for high-dimensional datasets.\nThey are outperformed by autencoder based methods\nlike TranAD [ref]37. Miscellaneous methods refer to notable related works that do not fall into the above research lines.\nThe DAGMM  is composed of a simple autoencoder model for dimensionality reduction\nand a Gaussian Mixture Model  for density estimation.\nThe density estimated by the GMM is used to predict the next data point.\nHowever, it is computationally expensive for training and unable to capture the spatial-temporal dependence well.\nRen et al.  proposed estimators for the implicit likelihoods of GANs,\nand they showed that such estimators could be applied to detect anomalies\nin multi-time series data.\nThe MAD-GAN  instantiated the vanilla GAN architecture with LSTM-RNN.\nKoopman operator is a classical method in control theory .\nIt has a similar idea of latent predictive coding.\nTheoretically, in an infinite-dimensional latent state space,\nthe next state can be a linear function of the states in a recent time window .\nIn particular, when we instantiate the predictor in our LPC-AD architecture as a linear function,\nwe get a deep Koopman operator .\nFor practical applications where we cannot have finite-dimensional states,\nnon-linear predictor function is needed for state transitions in latent space.\nThis is validated by our experiment in Figure 11,\nwhere we observe that using non-linear predictor functions\nimproves the accuracy of anomaly detection. Last, in terms of design objective, our work is closely related to USAD [ref]4 and TranAD [ref]37.\nTo the best of our knowledge, USAD and TranAD are the only two works that\naim to reduce training time while retaining a fairly high detection accuracy.\nWe proposed a generic architecture and show that simple instantiations of this\narchitecture can outperform USAD and TranAD in training speed\nand outperform SOAT methods (including sophisticated models) in detection accuracy.\nThe design of our architecture reveals new insights in exploring latent predictive coding\nand randomized perturbation for MTS anomaly detection."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Perturbation techniques in online learning and optimization",
      "abstract": "",
      "year": "2016",
      "venue": "Perturbations, Optimization, and Statistics",
      "authors": "J. Abernethy, C. Lee, and A. Tewari"
    },
    {
      "index": 1,
      "title": "Wadi: a water distribution testbed for research in the design of secure cyber physical systems",
      "abstract": "",
      "year": "2017",
      "venue": "3rd International Workshop on Cyber-Physical Systems for Smart Water Networks",
      "authors": "C. M. Ahmed, V. R. Palleti, and A. P. Mathur"
    },
    {
      "index": 2,
      "title": "Adaptive predictive coding of speech signals",
      "abstract": "",
      "year": "1970",
      "venue": "Bell System Technical Journal",
      "authors": "B. S. Atal and M. R. Schroeder"
    },
    {
      "index": 3,
      "title": "Usad: unsupervised anomaly detection on multivariate time series",
      "abstract": "",
      "year": "2020",
      "venue": "26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
      "authors": "J. Audibert, P. Michiardi, F. Guyard, S. Marti, and M. A. Zuluaga"
    },
    {
      "index": 4,
      "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1409.0473",
      "authors": "D. Bahdanau, K. Cho, and Y. Bengio",
      "orig_title": "Neural machine translation by jointly learning to align and translate",
      "paper_id": "1409.0473v7"
    },
    {
      "index": 5,
      "title": "Efficient anomaly detection by isolation using nearest neighbour ensemble",
      "abstract": "",
      "year": "2014",
      "venue": "2014 IEEE International conference on data mining workshop",
      "authors": "T. R. Bandaragoda, K. M. Ting, D. Albrecht, F. T. Liu, and J. R. Wells"
    },
    {
      "index": 6,
      "title": "Collective anomaly detection based on long short-term memory recurrent neural networks",
      "abstract": "",
      "year": "2016",
      "venue": "International conference on future data and security engineering",
      "authors": "L. Bontemps, V. L. Cao, J. McDermott, and N.-A. Le-Khac"
    },
    {
      "index": 7,
      "title": "Anomaly detection in ecg time signals via deep long short-term memory networks",
      "abstract": "",
      "year": "2015",
      "venue": "2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)",
      "authors": "S. Chauhan and L. Vig"
    },
    {
      "index": 8,
      "title": "Sdfvae: Static and dynamic factorized vae for anomaly detection of multivariate cdn kpis",
      "abstract": "",
      "year": "2021",
      "venue": "Web Conference 2021",
      "authors": "L. Dai, T. Lin, C. Liu, B. Jiang, Y. Liu, Z. Xu, and Z.-L. Zhang"
    },
    {
      "index": 9,
      "title": "Graph Neural Network-Based Anomaly Detection in Multivariate Time Series",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "A. Deng and B. Hooi",
      "orig_title": "Graph neural network-based anomaly detection in multivariate time series",
      "paper_id": "2106.06947v1"
    },
    {
      "index": 10,
      "title": "Unsupervised Visual Representation Learning by Context Prediction",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE international conference on computer vision",
      "authors": "C. Doersch, A. Gupta, and A. A. Efros",
      "orig_title": "Unsupervised visual representation learning by context prediction",
      "paper_id": "1505.05192v3"
    },
    {
      "index": 11,
      "title": "Hitanomaly: Hierarchical transformers for anomaly detection in system log",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Network and Service Management",
      "authors": "S. Huang, Y. Liu, C. Fung, R. He, Y. Zhao, H. Yang, and Z. Luan"
    },
    {
      "index": 12,
      "title": "Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding",
      "abstract": "",
      "year": "2018",
      "venue": "24th ACM SIGKDD international conference on knowledge discovery & data mining",
      "authors": "K. Hundman, V. Constantinou, C. Laporte, I. Colwell, and T. Soderstrom",
      "orig_title": "Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding",
      "paper_id": "1802.04431v3"
    },
    {
      "index": 13,
      "title": "Elle: Inferring Isolation Anomalies from Experimental Observations",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2003.10554",
      "authors": "K. Kingsbury and P. Alvaro",
      "orig_title": "Elle: Inferring isolation anomalies from experimental observations",
      "paper_id": "2003.10554v1"
    },
    {
      "index": 14,
      "title": "Linear gaussian state space modeling",
      "abstract": "",
      "year": "1996",
      "venue": "Smoothness priors analysis of time series",
      "authors": "G. Kitagawa and W. Gersch"
    },
    {
      "index": 15,
      "title": "MAD-GAN: Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Artificial Neural Networks",
      "authors": "D. Li, D. Chen, B. Jin, L. Shi, J. Goh, and S.-K. Ng",
      "orig_title": "Mad-gan: Multivariate anomaly detection for time series data with generative adversarial networks",
      "paper_id": "1901.04997v1"
    },
    {
      "index": 16,
      "title": "opengauss: An autonomous database system",
      "abstract": "",
      "year": "2021",
      "venue": "VLDB Endowment",
      "authors": "G. Li, X. Zhou, J. Sun, X. Yu, Y. Han, L. Jin, W. Li, T. Wang, and S. Li"
    },
    {
      "index": 17,
      "title": "Multivariate time series anomaly detection and interpretation using hierarchical inter-metric and temporal embedding",
      "abstract": "",
      "year": "2021",
      "venue": "27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining",
      "authors": "Z. Li, Y. Zhao, J. Han, Y. Su, R. Jiao, X. Wen, and D. Pei"
    },
    {
      "index": 18,
      "title": "MicroHECL: High-Efficient Root Cause Localization in Large-Scale Microservice Systems",
      "abstract": "",
      "year": "2021",
      "venue": "2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
      "authors": "D. Liu, C. He, X. Peng, F. Lin, C. Zhang, S. Gong, Z. Li, J. Ou, and Z. Wu",
      "orig_title": "Microhecl: high-efficient root cause localization in large-scale microservice systems",
      "paper_id": "2103.01782v1"
    },
    {
      "index": 19,
      "title": "Isolation forest",
      "abstract": "",
      "year": "2008",
      "venue": "2008 eighth ieee international conference on data mining",
      "authors": "F. T. Liu, K. M. Ting, and Z.-H. Zhou"
    },
    {
      "index": 20,
      "title": "Deep learning for universal linear embeddings of nonlinear dynamics",
      "abstract": "",
      "year": "2018",
      "venue": "Nature communications",
      "authors": "B. Lusch, J. N. Kutz, and S. L. Brunton",
      "orig_title": "Deep learning for universal linear embeddings of nonlinear dynamics",
      "paper_id": "1712.09707v2"
    },
    {
      "index": 21,
      "title": "Diagnosing root causes of intermittent slow queries in cloud databases",
      "abstract": "",
      "year": "2020",
      "venue": "VLDB Endowment",
      "authors": "M. Ma, Z. Yin, S. Zhang, S. Wang, C. Zheng, X. Jiang, H. Hu, C. Luo, Y. Li, N. Qiu, et al."
    },
    {
      "index": 22,
      "title": "Lstm-based encoder-decoder for multi-sensor anomaly detection",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1607.00148",
      "authors": "P. Malhotra, A. Ramakrishnan, G. Anand, L. Vig, P. Agarwal, and G. Shroff"
    },
    {
      "index": 23,
      "title": "Swat: A water treatment testbed for research and training on ics security",
      "abstract": "",
      "year": "2016",
      "venue": "2016 international workshop on cyber-physical systems for smart water networks (CySWater)",
      "authors": "A. P. Mathur and N. O. Tippenhauer"
    },
    {
      "index": 24,
      "title": "Anomaly detection in video using predictive convolutional long short-term memory networks",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1612.00390",
      "authors": "J. R. Medel and A. Savakis"
    },
    {
      "index": 25,
      "title": "Localizing failure root causes in a microservice through causality inference",
      "abstract": "",
      "year": "2020",
      "venue": "2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS)",
      "authors": "Y. Meng, S. Zhang, Y. Sun, R. Zhang, Z. Hu, Y. Zhang, C. Jia, Z. Wang, and D. Pei"
    },
    {
      "index": 26,
      "title": "Efficient estimation of word representations in vector space",
      "abstract": "",
      "year": "2013",
      "venue": "arXiv preprint arXiv:1301.3781",
      "authors": "T. Mikolov, K. Chen, G. Corrado, and J. Dean"
    },
    {
      "index": 27,
      "title": "A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-based Variational Autoencoder",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Robotics and Automation Letters",
      "authors": "D. Park, Y. Hoshi, and C. C. Kemp",
      "orig_title": "A multimodal anomaly detector for robot-assisted feeding using an lstm-based variational autoencoder",
      "paper_id": "1711.00614v1"
    },
    {
      "index": 28,
      "title": "An overview of anomaly detection techniques: Existing solutions and latest technological trends",
      "abstract": "",
      "year": "2007",
      "venue": "Computer networks",
      "authors": "A. Patcha and J.-M. Park"
    },
    {
      "index": 29,
      "title": "A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1704.02971",
      "authors": "Y. Qin, D. Song, H. Chen, W. Cheng, G. Jiang, and G. Cottrell",
      "orig_title": "A dual-stage attention-based recurrent neural network for time series prediction",
      "paper_id": "1704.02971v4"
    },
    {
      "index": 30,
      "title": "Estimate the implicit likelihoods of gans with application to anomaly detection",
      "abstract": "",
      "year": "2020",
      "venue": "Web Conference 2020",
      "authors": "S. Ren, D. Li, Z. Zhou, and P. Li"
    },
    {
      "index": 31,
      "title": "Gaussian mixture models",
      "abstract": "",
      "year": "2009",
      "venue": "Encyclopedia of biometrics",
      "authors": "D. A. Reynolds"
    },
    {
      "index": 32,
      "title": "Variational inference with normalizing flows",
      "abstract": "",
      "year": "2015",
      "venue": "International conference on machine learning",
      "authors": "D. Rezende and S. Mohamed"
    },
    {
      "index": 33,
      "title": "Anomaly detection using autoencoders with nonlinear dimensionality reduction",
      "abstract": "",
      "year": "2014",
      "venue": "MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, MLSDA’14",
      "authors": "M. Sakurada and T. Yairi"
    },
    {
      "index": 34,
      "title": "Unsupervised learning of video representations using lstms",
      "abstract": "",
      "year": "2015",
      "venue": "International conference on machine learning",
      "authors": "N. Srivastava, E. Mansimov, and R. Salakhudinov"
    },
    {
      "index": 35,
      "title": "Robust anomaly detection for multivariate time series through stochastic recurrent neural network",
      "abstract": "",
      "year": "2019",
      "venue": "25th ACM SIGKDD international conference on knowledge discovery & data mining",
      "authors": "Y. Su, Y. Zhao, C. Niu, R. Liu, W. Sun, and D. Pei"
    },
    {
      "index": 36,
      "title": "TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate Time Series Data",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2201.07284",
      "authors": "S. Tuli, G. Casale, and N. R. Jennings",
      "orig_title": "Tranad: Deep transformer networks for anomaly detection in multivariate time series data",
      "paper_id": "2201.07284v6"
    },
    {
      "index": 37,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 38,
      "title": "Real-time sensor anomaly detection and recovery in connected automated vehicle sensors",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE transactions on intelligent transportation systems",
      "authors": "Y. Wang, N. Masoud, and A. Khojandi"
    },
    {
      "index": 39,
      "title": "Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications",
      "abstract": "",
      "year": "2018",
      "venue": "2018 world wide web conference",
      "authors": "H. Xu, W. Chen, N. Zhao, Z. Li, J. Bu, Z. Li, Y. Liu, Y. Zhao, D. Pei, Y. Feng, et al."
    },
    {
      "index": 40,
      "title": "Arima based network anomaly detection",
      "abstract": "",
      "year": "2010",
      "venue": "2010 Second International Conference on Communication Software and Networks",
      "authors": "A. H. Yaacob, I. K. Tan, S. F. Chien, and H. K. Tan"
    },
    {
      "index": 41,
      "title": "A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "C. Zhang, D. Song, Y. Chen, X. Feng, C. Lumezanu, W. Cheng, J. Ni, B. Zong, H. Chen, and N. V. Chawla",
      "orig_title": "A deep neural network for unsupervised anomaly detection and diagnosis in multivariate time series data",
      "paper_id": "1811.08055v1"
    },
    {
      "index": 42,
      "title": "Colorful Image Colorization",
      "abstract": "",
      "year": "2016",
      "venue": "European conference on computer vision",
      "authors": "R. Zhang, P. Isola, and A. A. Efros",
      "orig_title": "Colorful image colorization",
      "paper_id": "1603.08511v5"
    },
    {
      "index": 43,
      "title": "Multivariate Time-series Anomaly Detection via Graph Attention Network",
      "abstract": "",
      "year": "2020",
      "venue": "2020 IEEE International Conference on Data Mining (ICDM)",
      "authors": "H. Zhao, Y. Wang, J. Duan, C. Huang, D. Cao, Y. Tong, B. Xu, J. Bai, J. Tong, and Q. Zhang",
      "orig_title": "Multivariate time-series anomaly detection via graph attention network",
      "paper_id": "2009.02040v1"
    },
    {
      "index": 44,
      "title": "Spatio-temporal autoencoder for video anomaly detection",
      "abstract": "",
      "year": "2017",
      "venue": "25th ACM international conference on Multimedia",
      "authors": "Y. Zhao, B. Deng, C. Shen, Y. Liu, H. Lu, and X.-S. Hua"
    },
    {
      "index": 45,
      "title": "Deep autoencoding gaussian mixture model for unsupervised anomaly detection",
      "abstract": "",
      "year": "2018",
      "venue": "International conference on learning representations",
      "authors": "B. Zong, Q. Song, M. R. Min, W. Cheng, C. Lumezanu, D. Cho, and H. Chen"
    }
  ]
}