{
  "paper_id": "2010.09672v2",
  "title": "Multi-Stage Fusion for One-Click Segmentation",
  "sections": {
    "related works": "As an essential building block of image/video editing applications, interactive segmentation and dates back decades . The latest methods  [ref]2 [ref]4  [ref]7 integrate deep architectures\nsuch as FCN-8s  or DeepLab  . Most of these approaches integrate user cues in the input stage. The clicks are transformed into ‘guidance’ maps and appended to the three-channel colour image input before being passed through a CNN  [ref]2 [ref]4. Early Interactive Instance Segmentation approaches used graph-cuts  , geodesics, or a combination . These methods’ performance is limited as they separate the foreground and background based on low-level colour and texture features. Consequently, for scenes where foreground and background are similar in appearance, or lighting and contrast is low, more labelling effort from the users to achieve good segmentations [ref]2. Recently, deep convolutional neural networks   have been incorporated into interactive segmentation frameworks. Initially, [ref]2 used Euclidean distance-based guidance maps to represent user-provided clicks and are passed along with the input RGB image through a fully convolutional network. Subsequent works made extensions with newer CNN architectures , iterative training procedures  and structure-aware guidance maps [ref]4. These works share a structural similarity: the guidance maps are concatenated with the RGB image as additional channels at the first (input) layer. We refer to this form of structure as early fusion (see Fig. 2(a)). Architecture-wise, early fusion is simple and easy to train; however, user inputs’ influence gets diminished through the layers. \n Tap-and-Shoot Segmentation was introduced by , and refers to the one-click interactive setting. One assumes that during image capture, the user taps the touchscreen (once) on the foreground object of interest, from which one can directly segment the object of interest.   uses early fusion; it transforms the user tap into a guidance map via two shortest-path minimizations and then concatenates the map to the input image. The authors validate only on simple datasets such as ECSSD 6 and MSRA10K 7, where the images contain a single dominant foreground object. As we show later in our benchmarks (see Table 1), these datasets are so simplistic that properly trained networks with no user input can also generate high-quality segmentation masks which are comparable or even surpass the results reported by . \n Feature Fusion in Deep Architectures is an efficient way to leverage complementary information, either from different modalities 8, or different levels of abstraction 9. Element-wise multiplication [ref]7 and addition   are two common operations applied for fusing multiple channels. Other strategies include ‘skip’ connections , where features from earlier layers are concatenated with the features extracted from the deeper layers. Recently, a few interactive instance segmentation works have begun exploring outside of the early-fusion paradigm to integrate user guidance  [ref]7. However, these approaches are heavy in their computational footprint, as they increase the number of parameters to be learned by order of hundred of millions [ref]7. Dilution of input information is common-place in deep CNNs as the input gets processed several blocks of convolution . Feature fusion helps preserve input information by reducing the layers of abstraction between the user interaction and the segmentation output."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Tap and shoot segmentation",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI",
      "authors": "Ding-Jie Chen, Jui-Ting Chien, Hwann-Tzong Chen, and Long-Wen Chang"
    },
    {
      "index": 1,
      "title": "Deep interactive object selection",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Ning Xu, Brian Price, Scott Cohen, Jimei Yang, and Thomas S Huang"
    },
    {
      "index": 2,
      "title": "Iteratively Trained Interactive Segmentation",
      "abstract": "",
      "year": "2018",
      "venue": "BMVC",
      "authors": "Sabarinath Mahadevan, Paul Voigtlaender, and Bastian Leibe",
      "orig_title": "Iteratively trained interactive segmentation",
      "paper_id": "1805.04398v1"
    },
    {
      "index": 3,
      "title": "Content-aware multi-level guidance for interactive instance segmentation",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Soumajit Majumder and Angela Yao"
    },
    {
      "index": 4,
      "title": "A Fully Convolutional Two-Stream Fusion Network for Interactive Image Segmentation",
      "abstract": "",
      "year": "2019",
      "venue": "Neural Networks",
      "authors": "Yang Hu, Andrea Soltoggio, Russell Lock, and Steve Carter",
      "orig_title": "A fully convolutional two-stream fusion network for interactive image segmentation",
      "paper_id": "1807.02480v2"
    },
    {
      "index": 5,
      "title": "Semantic Image Synthesis with Spatially-Adaptive Normalization",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu",
      "orig_title": "Semantic image synthesis with spatially-adaptive normalization",
      "paper_id": "1903.07291v2"
    },
    {
      "index": 6,
      "title": "Few-Shot Segmentation Propagation with Guided Networks",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1806.07373",
      "authors": "Kate Rakelly, Evan Shelhamer, Trevor Darrell, Alexei A Efros, and Sergey Levine",
      "orig_title": "Few-shot segmentation propagation with guided networks",
      "paper_id": "1806.07373v1"
    },
    {
      "index": 7,
      "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1409.1556",
      "authors": "Karen Simonyan and Andrew Zisserman",
      "orig_title": "Very deep convolutional networks for large-scale image recognition",
      "paper_id": "1409.1556v6"
    },
    {
      "index": 8,
      "title": "Intelligent scissors for image composition",
      "abstract": "",
      "year": "1995",
      "venue": "SIGGRAPH",
      "authors": "Eric. N. Mortensen and William. A. Barrett"
    },
    {
      "index": 9,
      "title": "Fully Convolutional Networks for Semantic Segmentation",
      "abstract": "",
      "year": "2015",
      "venue": "CVPR",
      "authors": "Jonathan Long, Evan Shelhamer, and Trevor Darrell",
      "orig_title": "Fully convolutional networks for semantic segmentation",
      "paper_id": "1605.06211v1"
    },
    {
      "index": 10,
      "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam",
      "orig_title": "Encoder-decoder with atrous separable convolution for semantic image segmentation",
      "paper_id": "1802.02611v3"
    },
    {
      "index": 11,
      "title": "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs",
      "abstract": "",
      "year": "2018",
      "venue": "TPAMI",
      "authors": "Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille"
    },
    {
      "index": 12,
      "title": "Interactive graph cuts for optimal boundary & region segmentation of objects in nd images",
      "abstract": "",
      "year": "2001",
      "venue": "ICCV",
      "authors": "Yuri Y Boykov and M-P Jolly"
    },
    {
      "index": 13,
      "title": "Grabcut: Interactive foreground extraction using iterated graph cuts",
      "abstract": "",
      "year": "2004",
      "venue": "ACM transactions on graphics (TOG)",
      "authors": "Carsten Rother, Vladimir Kolmogorov, and Andrew Blake"
    },
    {
      "index": 14,
      "title": "Geodesic star convexity for interactive image segmentation",
      "abstract": "",
      "year": "2010",
      "venue": "CVPR",
      "authors": "Varun Gulshan, Carsten Rother, Antonio Criminisi, Andrew Blake, and Andrew Zisserman"
    },
    {
      "index": 15,
      "title": "Hierarchical image saliency detection on extended cssd",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE TPAMI",
      "authors": "Jianping Shi, Qiong Yan, Li Xu, and Jiaya Jia"
    },
    {
      "index": 16,
      "title": "Global contrast based salient region detection",
      "abstract": "",
      "year": "2014",
      "venue": "IEEE TPAMI",
      "authors": "Ming-Ming Cheng, Niloy J Mitra, Xiaolei Huang, Philip HS Torr, and Shi-Min Hu"
    },
    {
      "index": 17,
      "title": "Temporal Multimodal Fusion for Video Emotion Classification in the Wild",
      "abstract": "",
      "year": "2017",
      "venue": "19th ACM International Conference on Multimodal Interaction",
      "authors": "Valentin Vielzeuf, Stéphane Pateux, and Frédéric Jurie",
      "orig_title": "Temporal multimodal fusion for video emotion classification in the wild",
      "paper_id": "1709.07200v1"
    },
    {
      "index": 18,
      "title": "A late fusion cnn for digital matting",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Yunke Zhang, Lixue Gong, Lubin Fan, Peiran Ren, Qixing Huang, Hujun Bao, and Weiwei Xu"
    },
    {
      "index": 19,
      "title": "Nuclei segmentation via a deep panoptic model with semantic feature fusion",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI",
      "authors": "Dongnan Liu, Donghao Zhang, Yang Song, Chaoyi Zhang, Fan Zhang, Lauren O’Donnell, and Weidong Cai"
    },
    {
      "index": 20,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 21,
      "title": "Pyramid Scene Parsing Network",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia",
      "orig_title": "Pyramid scene parsing network",
      "paper_id": "1612.01105v2"
    },
    {
      "index": 22,
      "title": "Squeeze-and-Excitation Networks",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Jie Hu, Li Shen, and Gang Sun",
      "orig_title": "Squeeze-and-excitation networks",
      "paper_id": "1709.01507v4"
    },
    {
      "index": 23,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "CVPR",
      "authors": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei"
    },
    {
      "index": 24,
      "title": "Microsoft COCO: Common Objects in Context",
      "abstract": "",
      "year": "2014",
      "venue": "ECCV",
      "authors": "Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick",
      "orig_title": "Microsoft COCO: Common objects in context",
      "paper_id": "1405.0312v3"
    },
    {
      "index": 25,
      "title": "Large-scale interactive object segmentation with human annotators",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Rodrigo Benenson, Stefan Popov, and Vittorio Ferrari",
      "orig_title": "Large-scale interactive object segmentation with human annotators",
      "paper_id": "1903.10830v2"
    },
    {
      "index": 26,
      "title": "A comparative evaluation of interactive segmentation algorithms",
      "abstract": "",
      "year": "2010",
      "venue": "Pattern Recognition",
      "authors": "Kevin McGuinness and Noel E O’connor"
    },
    {
      "index": 27,
      "title": "The pascal visual object classes (voc) challenge",
      "abstract": "",
      "year": "2010",
      "venue": "IJCV",
      "authors": "Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman"
    },
    {
      "index": 28,
      "title": "Semantic contours from inverse detectors",
      "abstract": "",
      "year": "2011",
      "venue": "ICCV",
      "authors": "Bharath Hariharan, Pablo Arbelaez, Lubomir Bourdev, Subhransu Maji, and Jitendra Malik"
    },
    {
      "index": 29,
      "title": "Geodesic matting: A framework for fast interactive image and video segmentation and matting",
      "abstract": "",
      "year": "2009",
      "venue": "IJCV",
      "authors": "Xue Bai and Guillermo Sapiro"
    }
  ]
}