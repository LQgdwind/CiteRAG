{
  "paper_id": "2210.06455v2",
  "title": "Token-Label Alignment for Vision Transformers",
  "sections": {
    "related work": "Vision Transformer.\nTransformers have been widely used in natural language processing and achieved great success on many language tasks.\nRecently, Vision Transformers (ViTs) have aroused extensive interest in computer vision due to their competitive performance compared with CNNs 6 [ref]40 [ref]29 .\nDosovitskiy et al. 6 firstly introduced transformers into the image classification task.\nThey split the input image into non-overlapped patches and then feed them into the transformer encoders.\nLiu et al. [ref]29 proposed a shifted windowing scheme to produce hierarchical feature maps suitable for dense prediction tasks.\nThe great potential of vision transformer has motivated its adaptation to many challenging tasks including object detection   , segmentation  , image enhancement   and video understanding  . Recently, some efforts have been devoted to producing better training targets to improve the performance of vision transformers  .\nFor example, DeiT [ref]40 introduces a knowledge distillation procedure to reduce the training cost of ViTs and achieves a better accuracy/speed trade-off.\nTokenLabeling  employs a pretrained teacher annotator to predict a label for each token for dense knowledge distillation.\nDifferently, we do not require a pretrained network to obtain the training targets.\nOur TL-Align maintains an aligned label for each token layer by layer and can be trained efficiently in an end-to-end manner. Data Mixing Strategy.\nAs an important type of data augmentation, data mixing strategies have demonstrated a consistent improvement in the generalization performance of CNNs.\nZhang et al. 0 first proposed to combine a training pair to create augmented samples for model regularization.\nThey perform linear interpolations on both the input images and associated targets.\nFollowing MixUp, CutMix  also utilizes the mixture of two input images but adopts a region copy-and-paste operation.\nLater methods including Puzzle Mix , SaliencyMix  and Attentive CutMix  leverage the salient regions for informative mixture generation.\nRecently, Yang et al.  proposed a RecursiveMix strategy which employs the historical input-prediction-label triplets for scale-invariant feature learning.\nDespite the better performance, a drawback of these methods is the heavily increased training cost due to the saliency extraction or historical information exploitation. Most existing data mixing methods are originally designed for CNNs, and their effectiveness on ViTs has not been well explored.\nTransMix  uses the class attention map at the last layer to re-weight the mixing targets and assumes the output tokens to keep spatial correspondence with the input tokens.\nHowever, we identify a token fluctuation phenomenon for ViTs which may cause a mismatch between tokens and labels, leading to inaccurate label assignments in both the original CutMix and TransMix.\nTo address this, we propose to align the label and token space by tracing their correspondence in a layerwise manner."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "ViViT: A Video Vision Transformer",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Lučić, and Cordelia Schmid",
      "orig_title": "Vivit: A video vision transformer",
      "paper_id": "2103.15691v2"
    },
    {
      "index": 1,
      "title": "Layer normalization",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv",
      "authors": "Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton"
    },
    {
      "index": 2,
      "title": "BEiT: BERT Pre-Training of Image Transformers",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint",
      "authors": "Hangbo Bao, Li Dong, and Furu Wei",
      "orig_title": "Beit: Bert pre-training of image transformers",
      "paper_id": "2106.08254v2"
    },
    {
      "index": 3,
      "title": "Cascade R-CNN: Delving into High Quality Object Detection",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Zhaowei Cai and Nuno Vasconcelos",
      "orig_title": "Cascade r-cnn: Delving into high quality object detection",
      "paper_id": "1712.00726v1"
    },
    {
      "index": 4,
      "title": "End-to-end object detection with transformers",
      "abstract": "",
      "year": "2020",
      "venue": "ECCV",
      "authors": "Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko"
    },
    {
      "index": 5,
      "title": "Pre-trained image processing transformer",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Hanting Chen, Yunhe Wang, Tianyu Guo, Chang Xu, Yiping Deng, Zhenhua Liu, Siwei Ma, Chunjing Xu, Chao Xu, and Wen Gao"
    },
    {
      "index": 6,
      "title": "Transmix: Attend to mix for vision transformers",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint",
      "authors": "Jie-Neng Chen, Shuyang Sun, Ju He, Philip Torr, Alan Yuille, and Song Bai"
    },
    {
      "index": 7,
      "title": "The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy",
      "abstract": "",
      "year": "2022",
      "venue": "CVPR",
      "authors": "Tianlong Chen, Zhenyu Zhang, Yu Cheng, Ahmed Awadallah, and Zhangyang Wang",
      "orig_title": "The principle of diversity: Training stronger vision transformers calls for reducing all levels of redundancy",
      "paper_id": "2203.06345v1"
    },
    {
      "index": 8,
      "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation",
      "abstract": "",
      "year": "2021",
      "venue": "NeurIPS",
      "authors": "Bowen Cheng, Alexander G Schwing, and Alexander Kirillov",
      "orig_title": "Per-pixel classification is not all you need for semantic segmentation",
      "paper_id": "2107.06278v2"
    },
    {
      "index": 9,
      "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers",
      "abstract": "",
      "year": "2021",
      "venue": "NeurIPS",
      "authors": "Xiangxiang Chu, Zhi Tian, Yuqing Wang, Bo Zhang, Haibing Ren, Xiaolin Wei, Huaxia Xia, and Chunhua Shen",
      "orig_title": "Twins: Revisiting the design of spatial attention in vision transformers",
      "paper_id": "2104.13840v4"
    },
    {
      "index": 10,
      "title": "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks",
      "abstract": "",
      "year": "2020",
      "venue": "International conference on machine learning",
      "authors": "Francesco Croce and Matthias Hein"
    },
    {
      "index": 11,
      "title": "Dynamic detr: End-to-end object detection with dynamic attention",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "Xiyang Dai, Yinpeng Chen, Jianwei Yang, Pengchuan Zhang, Lu Yuan, and Lei Zhang"
    },
    {
      "index": 12,
      "title": "Up-detr: Unsupervised pre-training for object detection with transformers",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Zhigang Dai, Bolun Cai, Yugeng Lin, and Junying Chen"
    },
    {
      "index": 13,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "CVPR",
      "authors": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei"
    },
    {
      "index": 14,
      "title": "Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs",
      "abstract": "",
      "year": "2022",
      "venue": "CVPR",
      "authors": "Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, and Jian Sun",
      "orig_title": "Scaling up your kernels to 31x31: Revisiting large kernel design in cnns",
      "paper_id": "2203.06717v4"
    },
    {
      "index": 15,
      "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "abstract": "",
      "year": "2020",
      "venue": "ICLR",
      "authors": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al.",
      "orig_title": "An image is worth 16x16 words: Transformers for image recognition at scale",
      "paper_id": "2010.11929v2"
    },
    {
      "index": 16,
      "title": "Visual Attention Network",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, and Shi-Min Hu",
      "orig_title": "Visual attention network",
      "paper_id": "2202.09741v5"
    },
    {
      "index": 17,
      "title": "Masked autoencoders are scalable vision learners",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick"
    },
    {
      "index": 18,
      "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF International Conference on Computer Vision",
      "authors": "Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al.",
      "orig_title": "The many faces of robustness: A critical analysis of out-of-distribution generalization",
      "paper_id": "2006.16241v3"
    },
    {
      "index": 19,
      "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint",
      "authors": "Dan Hendrycks and Thomas Dietterich",
      "orig_title": "Benchmarking neural network robustness to common corruptions and perturbations",
      "paper_id": "1903.12261v1"
    },
    {
      "index": 20,
      "title": "Natural Adversarial Examples",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song",
      "orig_title": "Natural adversarial examples",
      "paper_id": "1907.07174v4"
    },
    {
      "index": 21,
      "title": "All tokens matter: Token labeling for training better vision transformers",
      "abstract": "",
      "year": "2021",
      "venue": "NeurIPS",
      "authors": "Zi-Hang Jiang, Qibin Hou, Li Yuan, Daquan Zhou, Yujun Shi, Xiaojie Jin, Anran Wang, and Jiashi Feng"
    },
    {
      "index": 22,
      "title": "Puzzle mix: Exploiting saliency and local statistics for optimal mixup",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Jang-Hyun Kim, Wonho Choo, and Hyun Oh Song"
    },
    {
      "index": 23,
      "title": "3d object representations for fine-grained categorization",
      "abstract": "",
      "year": "2013",
      "venue": "ICCVW",
      "authors": "Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei"
    },
    {
      "index": 24,
      "title": "Learning multiple layers of features from tiny images",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "Alex Krizhevsky, Geoffrey Hinton, et al."
    },
    {
      "index": 25,
      "title": "On Efficient Transformer-Based Image Pre-training for Low-Level Vision",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint",
      "authors": "Wenbo Li, Xin Lu, Jiangbo Lu, Xiangyu Zhang, and Jiaya Jia",
      "orig_title": "On efficient transformer and image pre-training for low-level vision",
      "paper_id": "2112.10175v2"
    },
    {
      "index": 26,
      "title": "Not All Pixels Are Equal: Difficulty-Aware Semantic Segmentation via Deep Layer Cascade",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Xiaoxiao Li, Ziwei Liu, Ping Luo, Chen Change Loy, and Xiaoou Tang",
      "orig_title": "Not all pixels are equal: Difficulty-aware semantic segmentation via deep layer cascade",
      "paper_id": "1704.01344v1"
    },
    {
      "index": 27,
      "title": "Microsoft COCO: Common Objects in Context",
      "abstract": "",
      "year": "2014",
      "venue": "ECCV",
      "authors": "Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick",
      "orig_title": "Microsoft coco: Common objects in context",
      "paper_id": "1405.0312v3"
    },
    {
      "index": 28,
      "title": "Swin transformer: Hierarchical vision transformer using shifted windows",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo"
    },
    {
      "index": 29,
      "title": "A ConvNet for the 2020s",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, and Saining Xie",
      "orig_title": "A convnet for the 2020s",
      "paper_id": "2201.03545v2"
    },
    {
      "index": 30,
      "title": "Video swin transformer",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint",
      "authors": "Ze Liu, Jia Ning, Yue Cao, Yixuan Wei, Zheng Zhang, Stephen Lin, and Han Hu"
    },
    {
      "index": 31,
      "title": "Automated flower classification over a large number of classes",
      "abstract": "",
      "year": "2008",
      "venue": "Indian Conference on Computer Vision, Graphics and Image Processing",
      "authors": "Maria-Elena Nilsback and Andrew Zisserman"
    },
    {
      "index": 32,
      "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
      "abstract": "",
      "year": "2019",
      "venue": "NIPS",
      "authors": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al.",
      "orig_title": "Pytorch: An imperative style, high-performance deep learning library",
      "paper_id": "1912.01703v1"
    },
    {
      "index": 33,
      "title": "Do ImageNet Classifiers Generalize to ImageNet?",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Machine Learning",
      "authors": "Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar",
      "orig_title": "Do imagenet classifiers generalize to imagenet?",
      "paper_id": "1902.10811v2"
    },
    {
      "index": 34,
      "title": "ImageNet Large Scale Visual Recognition Challenge",
      "abstract": "",
      "year": "2015",
      "venue": "IJCV",
      "authors": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al.",
      "orig_title": "Imagenet large scale visual recognition challenge",
      "paper_id": "1409.0575v3"
    },
    {
      "index": 35,
      "title": "Segmenter: Transformer for Semantic Segmentation",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "Robin Strudel, Ricardo Garcia, Ivan Laptev, and Cordelia Schmid",
      "orig_title": "Segmenter: Transformer for semantic segmentation",
      "paper_id": "2105.05633v3"
    },
    {
      "index": 36,
      "title": "An image patch is a wave: Quantum inspired vision mlp",
      "abstract": "",
      "year": "2022",
      "venue": "CVPR",
      "authors": "Yehui Tang, Kai Han, Jianyuan Guo, Chang Xu, Yanxi Li, Chao Xu, and Yunhe Wang"
    },
    {
      "index": 37,
      "title": "MLP-Mixer: An all-MLP Architecture for Vision",
      "abstract": "",
      "year": "2021",
      "venue": "NeurIPS",
      "authors": "Ilya O Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Thomas Unterthiner, Jessica Yung, Andreas Steiner, Daniel Keysers, Jakob Uszkoreit, et al.",
      "orig_title": "Mlp-mixer: An all-mlp architecture for vision",
      "paper_id": "2105.01601v4"
    },
    {
      "index": 38,
      "title": "ResMLP: Feedforward networks for image classification with data-efficient training",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint",
      "authors": "Hugo Touvron, Piotr Bojanowski, Mathilde Caron, Matthieu Cord, Alaaeldin El-Nouby, Edouard Grave, Gautier Izacard, Armand Joulin, Gabriel Synnaeve, Jakob Verbeek, et al.",
      "orig_title": "Resmlp: Feedforward networks for image classification with data-efficient training",
      "paper_id": "2105.03404v2"
    },
    {
      "index": 39,
      "title": "Training data-efficient image transformers & distillation through attention",
      "abstract": "",
      "year": "2021",
      "venue": "ICML",
      "authors": "Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Hervé Jégou",
      "orig_title": "Training data-efficient image transformers & distillation through attention",
      "paper_id": "2012.12877v2"
    },
    {
      "index": 40,
      "title": "DeiT III: Revenge of the ViT",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Hugo Touvron, Matthieu Cord, and Hervé Jégou",
      "orig_title": "Deit iii: Revenge of the vit",
      "paper_id": "2204.07118v1"
    },
    {
      "index": 41,
      "title": "Saliencymix: A saliency guided data augmentation strategy for better regularization",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint",
      "authors": "AFM Uddin, Mst Monira, Wheemyung Shin, TaeChoong Chung, Sung-Ho Bae, et al."
    },
    {
      "index": 42,
      "title": "Manifold Mixup: Better Representations by Interpolating Hidden States",
      "abstract": "",
      "year": "2019",
      "venue": "ICML",
      "authors": "Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas, David Lopez-Paz, and Yoshua Bengio",
      "orig_title": "Manifold mixup: Better representations by interpolating hidden states",
      "paper_id": "1806.05236v7"
    },
    {
      "index": 43,
      "title": "Attentive CutMix: An Enhanced Data Augmentation Approach for Deep Learning Based Image Classification",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint",
      "authors": "Devesh Walawalkar, Zhiqiang Shen, Zechun Liu, and Marios Savvides",
      "orig_title": "Attentive cutmix: An enhanced data augmentation approach for deep learning based image classification",
      "paper_id": "2003.13048v2"
    },
    {
      "index": 44,
      "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions",
      "abstract": "",
      "year": "2021",
      "venue": "ICCV",
      "authors": "Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, and Ling Shao",
      "orig_title": "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions",
      "paper_id": "2102.12122v2"
    },
    {
      "index": 45,
      "title": "Activemlp: An mlp-like architecture with active token mixer",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Guoqiang Wei, Zhizheng Zhang, Cuiling Lan, Yan Lu, and Zhibo Chen"
    },
    {
      "index": 46,
      "title": "Pytorch image models",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Ross Wightman"
    },
    {
      "index": 47,
      "title": "RecursiveMix: Mixed Learning with History",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint",
      "authors": "Lingfeng Yang, Xiang Li, Borui Zhao, Renjie Song, and Jian Yang",
      "orig_title": "Recursivemix: Mixed learning with history",
      "paper_id": "2203.06844v1"
    },
    {
      "index": 48,
      "title": "Cutmix: Regularization strategy to train strong classifiers with localizable features",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo"
    },
    {
      "index": 49,
      "title": "mixup: Beyond Empirical Risk Minimization",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz",
      "orig_title": "mixup: Beyond empirical risk minimization",
      "paper_id": "1710.09412v2"
    },
    {
      "index": 50,
      "title": "Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip HS Torr, et al."
    },
    {
      "index": 51,
      "title": "Semantic understanding of scenes through the ade20k dataset",
      "abstract": "",
      "year": "2019",
      "venue": "IJCV",
      "authors": "Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso, and Antonio Torralba"
    },
    {
      "index": 52,
      "title": "Deformable DETR: Deformable Transformers for End-to-End Object Detection",
      "abstract": "",
      "year": "2020",
      "venue": "ICLR",
      "authors": "Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai",
      "orig_title": "Deformable detr: Deformable transformers for end-to-end object detection",
      "paper_id": "2010.04159v4"
    }
  ]
}