{
  "paper_id": "2106.00980v1",
  "title": "End-to-End Hierarchical Relation Extraction for Generic Form Understanding",
  "sections": {
    "ii related work": "Our works focus on incorporating both information extraction from document images and Entity Linking into one model. The former consists of several sub-themes: heuristic methods, semantic segmentation on images, graph-based information extraction.\nThe Entity Linking part of our model in particular also incorporates techniques from human pose estimation and keypoints association, which we will describe briefly below and in detail in Section III. Heuristic methods: Heuristic methods for structured data extraction are either concerned with the layout analysis problem before the information extraction, the first stage (Word Grouping) or the third stage (Entity Linking).\nPrior to the information extraction stage,   tries to build up the components using carefully designed feature engineering (ridges and whitespaces , connected component analysis ) for text lines segmentation from images.\nThis step is important because its performance determines the accuracy for the rest of the pipeline, less-precise segmentation requires more robustness (for over/under segmentation errors) in later steps.\nHeuristic methods for table segmentation and extraction   can be used in either the first or the third step in form understanding task.\nWhile  separated table detection tasks into specific stages: Clustering words to text lines, merging text lines into tables by heuristic rules (Same task as Word-Grouping ).  represents text lines as graph nodes and finds the linking between them by calculating the edged-weights (the cost of two nodes belonging to the same types).\nSince these algorithms are designed tailoring a certain condition (i.e specific type of forms, layouts, required information), their scalability/generalizability towards large datasets is limited.\nThe MSAU [ref]9 and our model, however, are based on character-level mask, which leads to naturally more robust to these kinds of errors [ref]9, the deep segmentation model also improves generalizability. Deep learning-based segmentation and Link prediction:\nEarly work in information extraction from document images formalize the problem as a segmentation problem based on either Fully Convolutional Networks  or U-Net   applied fully convolutional network to directly segment regions of interest from historical documents.\n proposed architecture takes the spatial structure into account by using convolutional operations on the concatenated document text and image modalities, the text modality is represented by embedding the extracted text in a spatial grid.\nOur work built upon [ref]9 is more aligned with recent end-to-end systems incorporating both semantic structure and spatial image features 2 6.\nSimilar to [ref]9, char-grid 2 is also employed instead of sub-word, word, or sentence level embedding.\nThe character-level embedding has two advantages: embedding character-level is less memory-consuming and has been proven to be robust against potential accumulated text-line OCR and segmentation errors [ref]9. Information extraction with Graph Neural Networks:\nRecently, there are several works on modeling the entity’s relationship based on graph convolution networks  [ref]26 which have achieved promising results.\n introduced edge embeddings into the graph convolution network, which models the relationship between vertices directly while both works [ref]26 used the nearest spatial distanced entity as a key to determining the linking for graph building. Graph Neural Networks in general, have also been used for link-prediction problems (which is close to the Entity Linking stage) 0.\nHowever, to the best of our knowledge, there have not been any attempts to incorporate both the tasks of information extraction (formalized as node classification in  [ref]26), and Entity Linking.\nWe believe that this line of direction is very potential due to the capability of incorporating both semantic, spatial information. However, the implementation of these methods, have yet to reach the best possible performance under the condition of erroneous output from earlier steps (text lines recognition and optical character recognition).\nThe char-grid 2 is naturally robust to these types of errors as stated in [ref]9, this is the reason we chose to develop our work of Entity Linking upon the line of segmentation over char-grid. Human pose estimation: As mentioned earlier, our improvement for the incorporation of Entity Linking is highly relevant to the technique used in Human Pose Estimation, applied in a sense that linking between entities can be similar to linking between joints of human poses.\nIn the context of human pose estimation, there are mainly two approaches: top-down and bottom-up. The top-down approach starts by identifying and localizing individual person instances, followed by single pose estimation  .\nAlthough this approach makes the human pose estimation is more straightforward, it might not be applicable to our case because unlike human joints which are often close to each other, key-value pairs can be distanced apart.\nFurthermore, a single key in our case can match multiple values, making the process of pinpointing accurately bounding box of all pairs complicated due to overlapping. Hence we found this is not for capturing the entity’s relation in the documents. In the bottom-up approach, some recent works use greedy decoders in combination with additional tools to generate person instance as in  propose associative embedding to identify key points from the same person, 1 use Part Affinity Fields to infer human poses. Inspired from 1 the PIF-PAF 3 incorporates human body parts with a Part-Association field, which yields better quality results, and drastically reduces prediction time. The characteristic of this method involving bipartite matching, we believe, is similar to the match between key-value pairs. Inspired from this line of work, we incorporate Part-Association Fields as part of the model to encode of joint association all entities in the document. In short, we built our work upon the line of deep-learning-based models, in particular, MSAU [ref]9. Considering the advantageous characteristics of Part-Association Fields in matching human joints, we incorporated the technique into our model for end-to-end key-value detection and matching.\nOn top of that, as we consider key-point is a text line’s corner to localize and the text-line size of text-lines can vary greatly or be occluded, also does the translational information (i.e Title is likely on top of the page). Of which, Corner Pooling from the work of Corner Net 4 has been proven to be useful in dealing with text line size variations. For the incorporation of translational information, which is potentially useful for link-prediction, Coordinate Convolution 5 mechanism has also been proven to be effective. We incorporate both of these 5 4, in our model as described in Section III."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "PDF-TREX: An approach for recognizing and extracting tables from PDF documents",
      "abstract": "",
      "year": "2009",
      "venue": "ICDR",
      "authors": "Ermelinda Oro and Massimo Ruffolo"
    },
    {
      "index": 1,
      "title": "Information Extraction tasks : a survey",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": "Luisa Simoes, Goncalo; Galhardas, Helena; Coheur"
    },
    {
      "index": 2,
      "title": "Attend, Copy, Parse End-to-end information extraction from documents",
      "abstract": "",
      "year": "2019",
      "venue": "CBDAR",
      "authors": "Rasmus Berg Palm, Florian Laws, and Ole Winther",
      "orig_title": "Attend, Copy, Parse - End-to-end information extraction from documents",
      "paper_id": "1812.07248v3"
    },
    {
      "index": 3,
      "title": "Graph Convolution for Multimodal Information Extraction from Visually Rich Documents",
      "abstract": "",
      "year": "2019",
      "venue": "NAACL",
      "authors": "Xiaojing Liu, Feiyu Gao, Qiong Zhang, and Huasha Zhao",
      "orig_title": "Graph Convolution for Multimodal Information Extraction from Visually Rich Documents",
      "paper_id": "1903.11279v1"
    },
    {
      "index": 4,
      "title": "FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents",
      "abstract": "",
      "year": "2019",
      "venue": "ICDR",
      "authors": "Guillaume Jaume, Hazim Kemal Ekenel, and Jean-Philippe Thiran"
    },
    {
      "index": 5,
      "title": "Image Generation from Scene Graphs",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Justin Johnson, Agrim Gupta, and Li Fei-Fei",
      "orig_title": "Image Generation from Scene Graphs",
      "paper_id": "1804.01622v1"
    },
    {
      "index": 6,
      "title": "Pixels to Graphs by Associative Embedding",
      "abstract": "",
      "year": "2017",
      "venue": "NIPS",
      "authors": "Alejandro Newell and Jia Deng",
      "orig_title": "Pixels to Graphs by Associative Embedding",
      "paper_id": "1706.07365v2"
    },
    {
      "index": 7,
      "title": "Graph R-CNN for Scene Graph Generation",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Jianwei Yang, Jiasen Lu, Stefan Lee, Dhruv Batra, and Devi Parikh",
      "orig_title": "Graph R-CNN for Scene Graph Generation",
      "paper_id": "1808.00191v1"
    },
    {
      "index": 8,
      "title": "End-to-End Information Extraction by Character-Level Embedding and Multi-Stage",
      "abstract": "",
      "year": "2019",
      "venue": "BMVC",
      "authors": "Nguyen Dang Tuan Anh and Nguyen Thanh Dat"
    },
    {
      "index": 9,
      "title": "Link Prediction Based on Graph Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "NIPS",
      "authors": "Muhan Zhang and Yixin Chen",
      "orig_title": "Link Prediction Based on Graph Neural Networks",
      "paper_id": "1802.09691v3"
    },
    {
      "index": 10,
      "title": "Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh"
    },
    {
      "index": 11,
      "title": "Chargrid: Towards Understanding 2D Documents",
      "abstract": "",
      "year": "2018",
      "venue": "EMNLP",
      "authors": "Anoop Raveendra Katti, Christian Reisswig, Cordula Guder, Sebastian Brarda, Steffen Bickel, Johannes Höhne, and Jean Baptiste Faddoul",
      "orig_title": "Chargrid: Towards Understanding 2D Documents",
      "paper_id": "1809.08799v1"
    },
    {
      "index": 12,
      "title": "PifPaf: Composite Fields for Human Pose Estimation",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Sven Kreiss, Lorenzo Bertoni, and Alexandre Alahi",
      "orig_title": "PifPaf: Composite Fields for Human Pose Estimation",
      "paper_id": "1903.06593v2"
    },
    {
      "index": 13,
      "title": "CornerNet: Detecting Objects as Paired Keypoints",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Hei Law and Jia Deng",
      "orig_title": "CornerNet: Detecting Objects as Paired Keypoints",
      "paper_id": "1808.01244v2"
    },
    {
      "index": 14,
      "title": "An intriguing failing of convolutional neural networks and the CoordConv solution",
      "abstract": "",
      "year": "2018",
      "venue": "NIPS",
      "authors": "Rosanne Liu, Joel Lehman, Piero Molino, Felipe Petroski Such, Eric Frank, Alex Sergeev, and Jason Yosinski",
      "orig_title": "An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution",
      "paper_id": "1807.03247v2"
    },
    {
      "index": 15,
      "title": "CloudScan - A Configuration-Free Invoice Analysis System Using Recurrent Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Rasmus Berg Palm, Ole Winther, and Florian Laws"
    },
    {
      "index": 16,
      "title": "LayoutLM: Pre-training of Text and Layout for Document Image Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, and Ming Zhou"
    },
    {
      "index": 17,
      "title": "Towards a Multi-modal, Multi-task Learning based Pre-training Framework for Document Representation Learning",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Subhojeet Pramanik, Shashank Mujumdar, and Hima Patel",
      "orig_title": "Towards a Multi-modal, Multi-task Learning based Pre-training Framework for Document Representation Learning",
      "paper_id": "2009.14457v2"
    },
    {
      "index": 18,
      "title": "Robust Spatial Filtering with Graph Convolutional Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE JSTSP",
      "authors": "Felipe Petroski Such, Shagan Sah, Miguel Alexander Dominguez, Suhas Pillai, Chao Zhang, Andrew Michael, Nathan D. Cahill, and Raymond Ptucha",
      "orig_title": "Robust Spatial Filtering with Graph Convolutional Neural Networks",
      "paper_id": "1703.00792v3"
    },
    {
      "index": 19,
      "title": "High Performance Layout Analysis of Arabic and Urdu Document Images",
      "abstract": "",
      "year": "2011",
      "venue": "ICDR",
      "authors": "Syed Saqib Bukhari, Faisal Shafait, and Thomas M Breuel"
    },
    {
      "index": 20,
      "title": "Textline detection in degraded historical document images",
      "abstract": "",
      "year": "2017",
      "venue": "Eurasip Journal on Image and Video Processing",
      "authors": "Byeongyong Ahn, Jewoong Ryu, Hyung Il Koo, and Nam Ik Cho"
    },
    {
      "index": 21,
      "title": "A graph-theoretic approach to webpage segmentation",
      "abstract": "",
      "year": "2008",
      "venue": "WWW",
      "authors": "Deepayan Chakrabarti, Ravi Kumar, and Kunal Punera"
    },
    {
      "index": 22,
      "title": "Fully Convolutional Networks for Semantic Segmentation",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "authors": "Jonathan Long, Evan Shelhamer, and Trevor Darrell",
      "orig_title": "Fully convolutional networks for semantic segmentation",
      "paper_id": "1605.06211v1"
    },
    {
      "index": 23,
      "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
      "abstract": "",
      "year": "2015",
      "venue": "MICCAI",
      "authors": "Olaf Ronneberger, Philipp Fischer, and Thomas Brox",
      "orig_title": "U-net: Convolutional networks for biomedical image segmentation",
      "paper_id": "1505.04597v1"
    },
    {
      "index": 24,
      "title": "dhSegment: A generic deep-learning approach for document segmentation",
      "abstract": "",
      "year": "2018",
      "venue": "ICFHR",
      "authors": "Sofia Ares Oliveira, Benoit Seguin, and Frederic Kaplan",
      "orig_title": "dhSegment: A generic deep-learning approach for document segmentation",
      "paper_id": "1804.10371v2"
    },
    {
      "index": 25,
      "title": "An Invoice Reading System Using a Graph Convolutional Network",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "D. Lohani, A. Belaïd, and Y. Belaïd"
    },
    {
      "index": 26,
      "title": "Towards Accurate Multi-person Pose Estimation in the Wild",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "George Papandreou, Tyler Zhu, Nori Kanazawa, Alexander Toshev, Jonathan Tompson, Chris Bregler, and Kevin Murphy",
      "orig_title": "Towards Accurate Multi-person Pose Estimation in the Wild",
      "paper_id": "1701.01779v2"
    },
    {
      "index": 27,
      "title": "Simple Baselines for Human Pose Estimation and Tracking",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Bin Xiao, Haiping Wu, and Yichen Wei",
      "orig_title": "Simple Baselines for Human Pose Estimation and Tracking",
      "paper_id": "1804.06208v2"
    },
    {
      "index": 28,
      "title": "Non-local Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He",
      "orig_title": "Non-local Neural Networks",
      "paper_id": "1711.07971v3"
    },
    {
      "index": 29,
      "title": "CU-Net: Coupled U-Nets",
      "abstract": "",
      "year": "2019",
      "venue": "BMVC",
      "authors": "Zhiqiang Tang, Xi Peng, Shijie Geng, Yizhe Zhu, and Dimitris N. Metaxas",
      "orig_title": "Cu-Net: Coupled U-nets",
      "paper_id": "1808.06521v1"
    },
    {
      "index": 30,
      "title": "Non-local Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He",
      "orig_title": "Non-local Neural Networks",
      "paper_id": "1711.07971v3"
    },
    {
      "index": 31,
      "title": "Deep Neural Networks using Box Convolutions",
      "abstract": "",
      "year": "2018",
      "venue": "NIPS",
      "authors": "Egor Burkov"
    },
    {
      "index": 32,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2018",
      "venue": "NAACL-HLT",
      "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova",
      "orig_title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "paper_id": "1810.04805v2"
    }
  ]
}