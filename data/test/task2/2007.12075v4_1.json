{
  "paper_id": "2007.12075v4",
  "title": "Representation Sharing for Fast Object Detector Search and Beyond",
  "sections": {
    "introduction": "Object detection is a fundamental task in computer vision  [ref]25 8   [ref]24   , but it remains challenging due to the large variation in object scales.\nTo handle the scale variation, a straightforward method is to utilize multi-scale image inputs  , which usually lacks efficiency. A line of more efficient methods is to tackle the scale variation on the intermediate features [ref]25 8. For example, Feature\nPyramid Networks (FPN) 8 is a representative work that implements the detection of objects with different scales in multiple levels of feature pyramids.\nOn the other hand, recent works also attempt to improve the detectors from the perspective of receptive fields (RFs) [ref]24 . They enhance the scale-awareness of the detectors by having multi-branch transformations with different combinations of kernel sizes and/or dilation rates. Then the features of different RFs are aggregated to enrich the information of different scales at each spatial location. An object detector often has a backbone network followed by the detection-specific sub-networks (i.e. heads), which play an important role in object detection. The sub-networks compute the deep features which are used to directly predict the object category, localization and size.\nUnlike two-stage detectors in which the sub-networks operate on the fixed-size feature maps computed from each object proposal, generated by a region proposal network with ROI-pooling , the sub-networks in one-stage detectors should be capable of ‘looking for’ objects of arbitrary sizes directly.\nIt becomes more challenging for an anchor-free detector. Because the multi-scale anchor boxes can be considered as a way to explicitly handle various sizes and shapes of objects,\nwhereas an anchor-free detector only predicts a single object at each spatial location, without any prior information about the object size.\nTherefore, for one-stage detectors, especially the anchor-free ones, the capability of the sub-networks for capturing the objects with large scale variation becomes the key.\nIn this work, we aim to enhance the power of the sub-networks in one-stage detectors, by searching for the optimal combination of the RFs and convolutions in a learning-based manner. Neural Architecture Search (NAS) has gained increasing attention.\nIt transfers the task of neural networks design from a heuristics-guided process to an optimization problem.\nRecently, it has been shown that NAS can achieve prominent results on object detection      .\nIn most of the work, the operations in the search space are directly extended from those used for image classification   with limited variation on dilation rates. Therefore, their search spaces with respect to transformations are relatively limited, as listed in Table 1.\nApart from the combination of RFs, we also investigate the importance of the diversity of the transformations in NAS search space for object detection.\nHowever, searching through such a large number of candidate transformations can be computationally expensive,\nespecially for the RL-based   and EA-based  approaches.\nAdditionally, this problem can be more significant for object detection than image classification, due to the more complicated pipelines with larger input images. To this end, we propose a computation-friendly method, named Fast And Diverse (FAD), to search for the task-specific sub-networks in one-stage object detectors.\nFAD consists of a designed search space and an efficient search algorithm.\nWe first design a rich set of diverse transformations tailored for object detection, covering multiple RFs and various convolution types. To learn the optimal combinations more efficiently, a search method via representation sharing (RepShare) is proposed accordingly.\nBy sharing intermediate representations, the proposed RepShare significantly reduces the searching time and memory cost for the architecture search.\nFurthermore, we propose an efficient method to reduce the interference between the transformations sharing the same representations, and at the same time, alleviate the degradation of search quality caused by RepShare. To demonstrate the effectiveness of the proposed method, we redesign the sub-networks for modern one-stage object detectors and propose a searchable module for replacement.\nThe architecture search for the module is extremely efficient using our FAD,\nwhich is more than 25×25\\times faster than the fastest NAS approach for object detectors so far, while achieving a comparable AP improvement (see Table 1).\nWith ResNeXt-101  as the backbone, our FAD detector achieves 46.446.446.4 AP on the MS-COCO  test-dev set using a single model under single-scale testing, without using any additional regularization or modules (e.g. deformable conv ).\nMoreover, we show that FAD can also benefit more challenging tasks, such as instance segmentation.\nThe contributions of this work are summarized as: We present a novel method, named Fast And Diverse (FAD), to search meaningful transformations in the task-specific sub-networks for one-stage object detection.\nThe search space is designed specifically for object detection, and we empirically investigate the importance of the RFs coverage and convolution types for object detection. We propose an efficient search method with a novel representation sharing (RepShare) algorithm, which can significantly reduce the search cost in both time and memory usage, e.g. being more than 25×25\\times faster than all previous methods.\nTo ensure the search quality, a new method is introduced to decouple the transformation selection from the shared representations. To evaluate our methods, we design a searchable module for one-stage object detection and instance segmentation. Extensive experiments show that our FAD detector obtains consistent performance improvements on different detection frameworks with various backbones, and even has fewer parameters."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "DetNAS: Backbone Search for Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1903.10979",
      "authors": "Chen, Y., Yang, T., Zhang, X., Meng, G., Pan, C., Sun, J.",
      "orig_title": "DetNAS: Backbone search for object detection",
      "paper_id": "1903.10979v4"
    },
    {
      "index": 1,
      "title": "R-FCN: Object Detection via Region-based Fully Convolutional Networks",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in neural information processing systems",
      "authors": "Dai, J., Li, Y., He, K., Sun, J.",
      "orig_title": "R-FCN: Object detection via region-based fully convolutional networks",
      "paper_id": "1605.06409v3"
    },
    {
      "index": 2,
      "title": "Deformable convolutional networks",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE international conference on computer vision",
      "authors": "Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y."
    },
    {
      "index": 3,
      "title": "CenterNet: Keypoint Triplets for Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE International Conference on Computer Vision",
      "authors": "Duan, K., Bai, S., Xie, L., Qi, H., Huang, Q., Tian, Q.",
      "orig_title": "CenterNet: Keypoint triplets for object detection",
      "paper_id": "1904.08189v3"
    },
    {
      "index": 4,
      "title": "The pascal visual object classes (VOC) challenge",
      "abstract": "",
      "year": "2010",
      "venue": "International journal of computer vision",
      "authors": "Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A."
    },
    {
      "index": 5,
      "title": "DropBlock: A regularization method for convolutional networks",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Ghiasi, G., Lin, T.Y., Le, Q.V.",
      "orig_title": "DropBlock: A regularization method for convolutional networks",
      "paper_id": "1810.12890v1"
    },
    {
      "index": 6,
      "title": "NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Ghiasi, G., Lin, T.Y., Le, Q.V.",
      "orig_title": "NAS-FPN: Learning scalable feature pyramid architecture for object detection",
      "paper_id": "1904.07392v1"
    },
    {
      "index": 7,
      "title": "A comparative analysis of selection schemes used in genetic algorithms",
      "abstract": "",
      "year": "1991",
      "venue": "Foundations of genetic algorithms",
      "authors": "Goldberg, D.E., Deb, K."
    },
    {
      "index": 8,
      "title": "Hit-Detector: Hierarchical Trinity Architecture Search for Object Detection",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Guo, J., Han, K., Wang, Y., Zhang, C., Yang, Z., Wu, H., Chen, X., Xu, C.",
      "orig_title": "Hit-Detector: Hierarchical trinity architecture search for object detection",
      "paper_id": "2003.11818v1"
    },
    {
      "index": 9,
      "title": "Mask R-CNN",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE international conference on computer vision",
      "authors": "He, K., Gkioxari, G., Dollár, P., Girshick, R.",
      "orig_title": "Mask R-CNN",
      "paper_id": "1703.06870v3"
    },
    {
      "index": 10,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "He, K., Zhang, X., Ren, S., Sun, J.",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 11,
      "title": "Mobilenets: Efficient convolutional neural networks for mobile vision applications",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1704.04861",
      "authors": "Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H."
    },
    {
      "index": 12,
      "title": "Mask Scoring R-CNN",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Huang, Z., Huang, L., Gong, Y., Huang, C., Wang, X.",
      "orig_title": "Mask scoring R-CNN",
      "paper_id": "1903.00241v1"
    },
    {
      "index": 13,
      "title": "Learning multiple layers of features from tiny images",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "Krizhevsky, A., Hinton, G., et al."
    },
    {
      "index": 14,
      "title": "CornerNet: Detecting Objects as Paired Keypoints",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision (ECCV)",
      "authors": "Law, H., Deng, J.",
      "orig_title": "CornerNet: Detecting objects as paired keypoints",
      "paper_id": "1808.01244v2"
    },
    {
      "index": 15,
      "title": "Scale-aware trident networks for object detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1901.01892",
      "authors": "Li, Y., Chen, Y., Wang, N., Zhang, Z."
    },
    {
      "index": 16,
      "title": "Computation Reallocation for Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1912.11234",
      "authors": "Liang, F., Lin, C., Guo, R., Sun, M., Wu, W., Yan, J., Ouyang, W.",
      "orig_title": "Computation reallocation for object detection",
      "paper_id": "1912.11234v1"
    },
    {
      "index": 17,
      "title": "Feature Pyramid Networks for Object Detection",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Lin, T.Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie, S.",
      "orig_title": "Feature pyramid networks for object detection",
      "paper_id": "1612.03144v2"
    },
    {
      "index": 18,
      "title": "Focal Loss for Dense Object Detection",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE international conference on computer vision",
      "authors": "Lin, T.Y., Goyal, P., Girshick, R., He, K., Dollár, P.",
      "orig_title": "Focal loss for dense object detection",
      "paper_id": "1708.02002v2"
    },
    {
      "index": 19,
      "title": "Microsoft COCO: Common Objects in Context",
      "abstract": "",
      "year": "2014",
      "venue": "European conference on computer vision",
      "authors": "Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L.",
      "orig_title": "Microsoft COCO: Common objects in context",
      "paper_id": "1405.0312v3"
    },
    {
      "index": 20,
      "title": "Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Liu, C., Chen, L.C., Schroff, F., Adam, H., Hua, W., Yuille, A.L., Fei-Fei, L.",
      "orig_title": "Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation",
      "paper_id": "1901.02985v2"
    },
    {
      "index": 21,
      "title": "Progressive neural architecture search",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision (ECCV)",
      "authors": "Liu, C., Zoph, B., Neumann, M., Shlens, J., Hua, W., Li, L.J., Fei-Fei, L., Yuille, A., Huang, J., Murphy, K."
    },
    {
      "index": 22,
      "title": "DARTS: Differentiable architecture search",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1806.09055",
      "authors": "Liu, H., Simonyan, K., Yang, Y."
    },
    {
      "index": 23,
      "title": "Receptive Field Block Net for Accurate and Fast Object Detection",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision (ECCV)",
      "authors": "Liu, S., Huang, D., et al.",
      "orig_title": "Receptive field block net for accurate and fast object detection",
      "paper_id": "1711.07767v3"
    },
    {
      "index": 24,
      "title": "SSD: Single Shot MultiBox Detector",
      "abstract": "",
      "year": "2016",
      "venue": "European conference on computer vision",
      "authors": "Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., Berg, A.C.",
      "orig_title": "SSD: Single shot multibox detector",
      "paper_id": "1512.02325v5"
    },
    {
      "index": 25,
      "title": "Neural Architecture Optimization",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in neural information processing systems",
      "authors": "Luo, R., Tian, F., Qin, T., Chen, E., Liu, T.Y.",
      "orig_title": "Neural architecture optimization",
      "paper_id": "1808.07233v5"
    },
    {
      "index": 26,
      "title": "Efficient Neural Architecture Transformation Search in Channel-Level for Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1909.02293",
      "authors": "Peng, J., Sun, M., Zhang, Z., Tan, T., Yan, J.",
      "orig_title": "Efficient neural architecture transformation searchin channel-level for object detection",
      "paper_id": "1909.02293v1"
    },
    {
      "index": 27,
      "title": "Efficient Neural Architecture Search via Parameter Sharing",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1802.03268",
      "authors": "Pham, H., Guan, M.Y., Zoph, B., Le, Q.V., Dean, J.",
      "orig_title": "Efficient neural architecture search via parameter sharing",
      "paper_id": "1802.03268v2"
    },
    {
      "index": 28,
      "title": "Regularized Evolution for Image Classifier Architecture Search",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Real, E., Aggarwal, A., Huang, Y., Le, Q.V.",
      "orig_title": "Regularized evolution for image classifier architecture search",
      "paper_id": "1802.01548v7"
    },
    {
      "index": 29,
      "title": "Large-Scale Evolution of Image Classifiers",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y.L., Tan, J., Le, Q.V., Kurakin, A.",
      "orig_title": "Large-scale evolution of image classifiers",
      "paper_id": "1703.01041v2"
    },
    {
      "index": 30,
      "title": "YOLOv3: An incremental improvement",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1804.02767",
      "authors": "Redmon, J., Farhadi, A."
    },
    {
      "index": 31,
      "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in neural information processing systems",
      "authors": "Ren, S., He, K., Girshick, R., Sun, J.",
      "orig_title": "Faster R-CNN: Towards real-time object detection with region proposal networks",
      "paper_id": "1506.01497v3"
    },
    {
      "index": 32,
      "title": "Rigid-motion scattering for image classification",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "Sifre, L., Mallat, S."
    },
    {
      "index": 33,
      "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1409.1556",
      "authors": "Simonyan, K., Zisserman, A.",
      "orig_title": "Very deep convolutional networks for large-scale image recognition",
      "paper_id": "1409.1556v6"
    },
    {
      "index": 34,
      "title": "An analysis of scale invariance in object detection snip",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Singh, B., Davis, L.S."
    },
    {
      "index": 35,
      "title": "SNIPER: Efficient Multi-Scale Training",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in neural information processing systems",
      "authors": "Singh, B., Najibi, M., Davis, L.S.",
      "orig_title": "SNIPER: Efficient multi-scale training",
      "paper_id": "1805.09300v3"
    },
    {
      "index": 36,
      "title": "Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1904.02877",
      "authors": "Stamoulis, D., Ding, R., Wang, D., Lymberopoulos, D., Priyantha, B., Liu, J., Marculescu, D.",
      "orig_title": "Single-Path NAS: Designing hardware-efficient convnets in less than 4 hours",
      "paper_id": "1904.02877v1"
    },
    {
      "index": 37,
      "title": "Going deeper with convolutions",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.",
      "orig_title": "Going deeper with convolutions",
      "paper_id": "1409.4842v1"
    },
    {
      "index": 38,
      "title": "FCOS: Fully Convolutional One-Stage Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1904.01355",
      "authors": "Tian, Z., Shen, C., Chen, H., He, T.",
      "orig_title": "Fcos: Fully convolutional one-stage object detection",
      "paper_id": "1904.01355v5"
    },
    {
      "index": 39,
      "title": "NAS-FCOS: Fast neural architecture search for object detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1906.04423",
      "authors": "Wang, N., Gao, Y., Chen, H., Wang, P., Tian, Z., Shen, C."
    },
    {
      "index": 40,
      "title": "Group Normalization",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision (ECCV)",
      "authors": "Wu, Y., He, K.",
      "orig_title": "Group normalization",
      "paper_id": "1803.08494v3"
    },
    {
      "index": 41,
      "title": "Aggregated Residual Transformations for Deep Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Xie, S., Girshick, R., Dollár, P., Tu, Z., He, K.",
      "orig_title": "Aggregated residual transformations for deep neural networks",
      "paper_id": "1611.05431v2"
    },
    {
      "index": 42,
      "title": "Auto-FPN: Automatic network architecture adaptation for object detection beyond classification",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE International Conference on Computer Vision",
      "authors": "Xu, H., Yao, L., Zhang, W., Liang, X., Li, Z."
    },
    {
      "index": 43,
      "title": "SM-NAS: Structural-to-Modular Neural Architecture Search for Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1911.09929",
      "authors": "Yao, L., Xu, H., Zhang, W., Liang, X., Li, Z.",
      "orig_title": "SM-NAS: Structural-to-modular neural architecture search for object detection",
      "paper_id": "1911.09929v2"
    },
    {
      "index": 44,
      "title": "Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Zhang, S., Chi, C., Yao, Y., Lei, Z., Li, S.Z.",
      "orig_title": "Bridging the gap between anchor-based and anchor-free detection via adaptive training sample selection",
      "paper_id": "1912.02424v4"
    },
    {
      "index": 45,
      "title": "FreeAnchor: Learning to Match Anchors for Visual Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "Neural Information Processing Systems",
      "authors": "Zhang, X., Wan, F., Liu, C., Ji, R., Ye, Q.",
      "orig_title": "FreeAnchor: Learning to match anchors for visual object detection",
      "paper_id": "1909.02466v2"
    },
    {
      "index": 46,
      "title": "Soft Anchor-Point Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1911.12448",
      "authors": "Zhu, C., Chen, F., Shen, Z., Savvides, M.",
      "orig_title": "Soft anchor-point object detection",
      "paper_id": "1911.12448v2"
    },
    {
      "index": 47,
      "title": "Feature Selective Anchor-Free Module for Single-Shot Object Detection",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1903.00621",
      "authors": "Zhu, C., He, Y., Savvides, M.",
      "orig_title": "Feature selective anchor-free module for single-shot object detection",
      "paper_id": "1903.00621v1"
    },
    {
      "index": 48,
      "title": "Neural Architecture Search with Reinforcement Learning",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1611.01578",
      "authors": "Zoph, B., Le, Q.V.",
      "orig_title": "Neural architecture search with reinforcement learning",
      "paper_id": "1611.01578v2"
    }
  ]
}