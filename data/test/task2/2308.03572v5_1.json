{
  "paper_id": "2308.03572v5",
  "title": "Provably Efficient Learning in Partially Observable Contextual Bandit",
  "sections": {
    "related work": "Our work is related to prior research on causal bounds.\nIn , a general calculus known as do-calculus is developed for identifying causal effects using probabilistic tools.\nFor non-identifiable causal problems, Tian and Pearl  derives a model-free causal bound.\nZhang and Bareinboim  formulates a linear programming approach to obtain a causal bound in a discrete setting,\nwhile Shridharan and Iyengar  makes this approach scalable.\nLi and Pearl [ref]18  extend these methods to non-binary outcomes,\nand Zhang and Bareinboim [ref]41 employs instrumental variables to extend them to continuous outcomes.\nHowever, these LP-based methods may not be tight and rely on structural assumptions on hidden confounders.\nLi and Pearl  is the first to consider partially observable back-door and front-door criteria and employs a non-linear optimization problem to compute causal bounds.\nNonetheless, solving a non-linear optimization problem is computationally intensive and may get trapped in local optima.\nDuarte et al.  summarize these optimization-based methods and provides an automated approach to causal inference in discrete settings.\nZhang et al. [ref]42 employ a Markov Chain Monte Carlo (MCMC) method to approximate causal bounds using observational and experimental data.\nHowever, this method is not directly applicable in our setting because the agent in our scenario has access to partial knowledge about latent confounders,\nwhereas Zhang et al. [ref]42 make structural assumptions on latent confounders.\nAs a result, Zhang et al. [ref]42 only need sample a random vector from Dirichlet distributions\nwhile we need to sample constrained table from distributions supported on more complex simplex. Our work is also closely linked to transfer learning.\nZhang and Bareinboim , Lazaric et al.  investigate transfer learning in multi-armed bandit problems.\nCai et al.  examine transfer learning in contextual bandits with covariate shift,\nwhere two tasks share the same reward function (causal effects) across two bandits.\nLiu et al.  apply transfer learning techniques in recommendation systems.\nLiu et al.  extend the ideas in  [ref]41 to reinforcement learning settings.\nA similar work is 5, which uses a partially missing offline dataset to enhance the performance of online learning in linear bandits.\nThough several papers   investigate partially observable contextual bandits,\nwe found few papers focusing on transfer learning in partially observable contextual bandits. Partially Observable Markov decision process (POMDP), including general partially observable dynamical systems 7, also shares the similarity with our setting.\nResearchers have developed various methods to address causal inference in POMDPs.\nFor example, Guo et al.  use instrumental variables to identify causal effects,\nwhile Shi et al. 2, Lu et al.  extend this approach to general proxy variables in offline policy evaluation.\nIn online reinforcement learning, Jin et al. , Wang et al. 8 use the backdoor criterion to explicitly adjust for confounding bias when confounders are fully observable.\nThey also incorporate uncertainty from partially observable confounders into the Bellman equation and demonstrate provably optimal learning with linear function approximation in both fully and partially observable tasks.\nHowever, due to the complexity of reinforcement learning, transfer learning in POMDPs with the general function approximation still remains unknown.\nIn our task 3, we address the problem of partially observable contextual bandit with the general function approximation under realizability assumption,\nwhich shows the potential to generalize to POMDPs and other related settings."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Contextual bandit learning with predictable rewards",
      "abstract": "",
      "year": "2012",
      "venue": "Artificial Intelligence and Statistics",
      "authors": "A. Agarwal, M. Dudík, S. Kale, J. Langford, and R. Schapire"
    },
    {
      "index": 1,
      "title": "Bandits with unobserved confounders: A causal approach",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "E. Bareinboim, A. Forney, and J. Pearl"
    },
    {
      "index": 2,
      "title": "Transfer Learning for Contextual Multi-armed Bandits",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2211.12612",
      "authors": "C. Cai, T. T. Cai, and H. Li",
      "orig_title": "Transfer learning for contextual multi-armed bandits",
      "paper_id": "2211.12612v2"
    },
    {
      "index": 3,
      "title": "Contextual bandits with linear payoff functions",
      "abstract": "",
      "year": "2011",
      "venue": "Fourteenth International Conference on Artificial Intelligence and Statistics",
      "authors": "W. Chu, L. Li, L. Reyzin, and R. Schapire"
    },
    {
      "index": 4,
      "title": "Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Learning",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "C. Dann, T. V. Marinov, M. Mohri, and J. Zimmert",
      "orig_title": "Beyond value-function gaps: Improved instance-dependent regret bounds for episodic reinforcement learning",
      "paper_id": "2107.01264v2"
    },
    {
      "index": 5,
      "title": "An automated approach to causal inference in discrete settings",
      "abstract": "",
      "year": "2023",
      "venue": "Journal of the American Statistical Association",
      "authors": "G. Duarte, N. Finkelstein, D. Knox, J. Mummolo, and I. Shpitser"
    },
    {
      "index": 6,
      "title": "Minimax theorems",
      "abstract": "",
      "year": "1953",
      "venue": "National Academy of Sciences of the United States of America",
      "authors": "K. Fan"
    },
    {
      "index": 7,
      "title": "Beyond ucb: Optimal and efficient contextual bandits with regression oracles",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "D. Foster and A. Rakhlin"
    },
    {
      "index": 8,
      "title": "Practical Contextual Bandits with Regression Oracles",
      "abstract": "",
      "year": "2018",
      "venue": "International Conference on Machine Learning",
      "authors": "D. Foster, A. Agarwal, M. Dudík, H. Luo, and R. Schapire",
      "orig_title": "Practical contextual bandits with regression oracles",
      "paper_id": "1803.01088v1"
    },
    {
      "index": 9,
      "title": "Instance-dependent complexity of contextual bandits and reinforcement learning: A disagreement-based perspective",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2010.03104",
      "authors": "D. J. Foster, A. Rakhlin, D. Simchi-Levi, and Y. Xu"
    },
    {
      "index": 10,
      "title": "Dual Instrumental Method for Confounded Kernelized Bandits",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2209.03224",
      "authors": "X. Gong and J. Zhang",
      "orig_title": "Dual instrumental method for confounded kernelized bandits",
      "paper_id": "2209.03224v1"
    },
    {
      "index": 11,
      "title": "Provably efficient offline reinforcement learning for partially observable Markov decision processes",
      "abstract": "",
      "year": "2022",
      "venue": "39th International Conference on Machine Learning",
      "authors": "H. Guo, Q. Cai, Y. Zhang, Z. Yang, and Z. Wang"
    },
    {
      "index": 12,
      "title": "Provably Efficient Reinforcement Learning with Linear Function Approximation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "C. Jin, Z. Yang, Z. Wang, and M. I. Jordan",
      "orig_title": "Provably efficient reinforcement learning with linear function approximation",
      "paper_id": "1907.05388v2"
    },
    {
      "index": 13,
      "title": "Instrument-armed bandits",
      "abstract": "",
      "year": "2018",
      "venue": "Algorithmic Learning Theory",
      "authors": "N. Kallus"
    },
    {
      "index": 14,
      "title": "Causal Bandits: Learning Good Interventions via Causal Inference",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "F. Lattimore, T. Lattimore, and M. D. Reid",
      "orig_title": "Causal bandits: Learning good interventions via causal inference",
      "paper_id": "1606.03203v1"
    },
    {
      "index": 15,
      "title": "Bandit algorithms",
      "abstract": "",
      "year": "2020",
      "venue": "Cambridge University Press",
      "authors": "T. Lattimore and C. Szepesvári"
    },
    {
      "index": 16,
      "title": "Sequential transfer in multi-armed bandit with finite set of models",
      "abstract": "",
      "year": "2013",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "A. Lazaric, E. Brunskill, et al."
    },
    {
      "index": 17,
      "title": "Probabilities of causation with nonbinary treatment and effect",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2208.09568",
      "authors": "A. Li and J. Pearl"
    },
    {
      "index": 18,
      "title": "Bounds on Causal Effects and Application to High Dimensional Data",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "A. Li and J. Pearl",
      "orig_title": "Bounds on causal effects and application to high dimensional data",
      "paper_id": "2106.12121v1"
    },
    {
      "index": 19,
      "title": "Unit Selection with Nonbinary Treatment and Effect",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2208.09569",
      "authors": "A. Li and J. Pearl",
      "orig_title": "Unit selection with nonbinary treatment and effect",
      "paper_id": "2208.09569v1"
    },
    {
      "index": 20,
      "title": "Learning probabilities of causation from finite population data",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2210.08453",
      "authors": "A. Li, S. Jiang, Y. Sun, and J. Pearl"
    },
    {
      "index": 21,
      "title": "Epsilon-identifiability of causal quantities",
      "abstract": "",
      "year": "2023",
      "venue": "arXiv preprint arXiv:2301.12022",
      "authors": "A. Li, S. Mueller, and J. Pearl"
    },
    {
      "index": 22,
      "title": "A contextual-bandit approach to personalized news article recommendation",
      "abstract": "",
      "year": "2010",
      "venue": "19th international conference on World wide web",
      "authors": "L. Li, W. Chu, J. Langford, and R. E. Schapire"
    },
    {
      "index": 23,
      "title": "Transferable contextual bandit for cross-domain recommendation",
      "abstract": "",
      "year": "2018",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "B. Liu, Y. Wei, Y. Zhang, Z. Yan, and Q. Yang"
    },
    {
      "index": 24,
      "title": "Learning without knowing: Unobserved context in continuous transfer reinforcement learning",
      "abstract": "",
      "year": "2021",
      "venue": "Learning for Dynamics and Control",
      "authors": "C. Liu, Y. Zhang, Y. Shen, and M. M. Zavlanos"
    },
    {
      "index": 25,
      "title": "Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes",
      "abstract": "",
      "year": "2023",
      "venue": "",
      "authors": "M. Lu, Y. Min, Z. Wang, and Z. Yang",
      "orig_title": "Pessimism in the face of confounders: Provably efficient offline reinforcement learning in partially observable markov decision processes",
      "paper_id": "2205.13589v3"
    },
    {
      "index": 26,
      "title": "On some useful “inefficient” statistics",
      "abstract": "",
      "year": "2006",
      "venue": "Springer",
      "authors": "F. Mosteller"
    },
    {
      "index": 27,
      "title": "A regret bound for greedy partially observed stochastic contextual bandits",
      "abstract": "",
      "year": "2022",
      "venue": "Decision Awareness in Reinforcement Learning Workshop at ICML",
      "authors": "H. Park and M. K. S. Faradonbeh"
    },
    {
      "index": 28,
      "title": "Analysis of Thompson Sampling for Partially Observable Contextual Multi-Armed Bandits",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Control Systems Letters",
      "authors": "H. Park and M. K. S. Faradonbeh",
      "orig_title": "Analysis of thompson sampling for partially observable contextual multi-armed bandits",
      "paper_id": "2110.12175v2"
    },
    {
      "index": 29,
      "title": "Causal inference in statistics: An overview",
      "abstract": "",
      "year": "2009",
      "venue": "Statistics surveys",
      "authors": "J. Pearl"
    },
    {
      "index": 30,
      "title": "The book of why",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of MultiDisciplinary Evaluation",
      "authors": "S. Powell"
    },
    {
      "index": 31,
      "title": "A Minimax Learning Approach to Off-Policy Evaluation in Confounded Partially Observable Markov Decision Processes",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "authors": "C. Shi, M. Uehara, J. Huang, and N. Jiang",
      "orig_title": "A minimax learning approach to off-policy evaluation in confounded partially observable markov decision processes",
      "paper_id": "2111.06784v4"
    },
    {
      "index": 32,
      "title": "Scalable Computation of Causal Bounds",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "authors": "M. Shridharan and G. Iyengar",
      "orig_title": "Scalable computation of causal bounds",
      "paper_id": "2308.02709v1"
    },
    {
      "index": 33,
      "title": "Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability",
      "abstract": "",
      "year": "2021",
      "venue": "Mathematics of Operations Research",
      "authors": "D. Simchi-Levi and Y. Xu"
    },
    {
      "index": 34,
      "title": "Bandits with Partially Observable Confounded Data",
      "abstract": "",
      "year": "2021",
      "venue": "Uncertainty in Artificial Intelligence",
      "authors": "G. Tennenholtz, U. Shalit, S. Mannor, and Y. Efroni",
      "orig_title": "Bandits with partially observable confounded data",
      "paper_id": "2006.06731v2"
    },
    {
      "index": 35,
      "title": "A general identification condition for causal effects",
      "abstract": "",
      "year": "2002",
      "venue": "Aaai/iaai",
      "authors": "J. Tian and J. Pearl"
    },
    {
      "index": 36,
      "title": "Provably efficient reinforcement learning in partially observable dynamical systems",
      "abstract": "",
      "year": "2022",
      "venue": "ArXiv",
      "authors": "M. Uehara, A. Sekhari, J. D. Lee, N. Kallus, and W. Sun"
    },
    {
      "index": 37,
      "title": "Provably Efficient Causal Reinforcement Learning with Confounded Observational Data",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "L. Wang, Z. Yang, and Z. Wang",
      "orig_title": "Provably efficient causal reinforcement learning with confounded observational data",
      "paper_id": "2006.12311v1"
    },
    {
      "index": 38,
      "title": "Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation",
      "abstract": "",
      "year": "2021",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "L. Xu, H. Kanagawa, and A. Gretton",
      "orig_title": "Deep proxy causal learning and its application to confounded bandit policy evaluation",
      "paper_id": "2106.03907v5"
    },
    {
      "index": 39,
      "title": "Transfer learning in multi-armed bandit: a causal approach",
      "abstract": "",
      "year": "2017",
      "venue": "16th Conference on Autonomous Agents and MultiAgent Systems",
      "authors": "J. Zhang and E. Bareinboim"
    },
    {
      "index": 40,
      "title": "Bounding causal effects on continuous outcome",
      "abstract": "",
      "year": "2021",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "J. Zhang and E. Bareinboim"
    },
    {
      "index": 41,
      "title": "Partial Counterfactual Identification from Observational and Experimental Data",
      "abstract": "",
      "year": "2022",
      "venue": "International Conference on Machine Learning",
      "authors": "J. Zhang, J. Tian, and E. Bareinboim",
      "orig_title": "Partial counterfactual identification from observational and experimental data",
      "paper_id": "2110.05690v1"
    },
    {
      "index": 42,
      "title": "A Comprehensive Survey on Transfer Learning",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE",
      "authors": "F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, and Q. He",
      "orig_title": "A comprehensive survey on transfer learning",
      "paper_id": "1911.02685v3"
    }
  ]
}