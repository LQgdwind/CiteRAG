{
  "paper_id": "2211.01146v3",
  "title": "DynamicISP: Dynamically Controlled Image Signal Processor for Image Recognition",
  "sections": {
    "ablation studies on human detection": "Various ablation studies are performed using the human detection RAW\ndataset [ref]48. We evaluate with the following\nsetting if not specified. TTFNet [ref]22 with ResNet18\n backbone is used as the detector. The entire pipeline\nis trained for 24 epochs with Adam optimizer \nfrom randomly initialized weights using a cosine decay learning rate\nschedule (0.001 magnitudes) whose maximum and minimum learning rates\nare 1e-3 and 1e-6 with a linear warmup for the first 1,000 iterations\n. The controller's learning rate is multiplied\nby 0.1 from the base learning rate. After that, the model is additionally\ntrained for 24 epochs with the same learning rate scheduling, but\nthe ISP and controller are frozen the samely with NeuralAE [ref]32.\nThis procedure slightly improves the accuracy from simple 48-epoch\ntraining. The input size is set to (576,‚Äâ352,‚Äâ3)5763523\\left(576,\\,352,\\,3\\right),\nand Rawgment [ref]48 is applied to bridge the\ndomain gap between the training data and challenging test data. During\nthe training phase, the identical frame is input twice instead of\nusing the continuous frame as described in Section 3.2\ndue to the rough frame rate of about 1 fps. In the evaluation phase,\non the other hand, we try both sequential input and identical input.\nWe set the channel size of the latent variable in the proposed controller\nas 256. The accuracy is evaluated with the average AP@0.5:0.95 \nscores of four-time experiments with different random seeds. We add each proposed component one by one to the NeuralAE controller\n[ref]32 to control two ISPs. One consisting of only\nGM and the other consisting of DN, SN, GM, and CS. The reason we do\nnot use AG is that we tried to control AG, but for some reason, it\nfailed on this dataset. The result is shown in Table 1. Even when controlling only the GM, the complexity of the GM function\nmakes it difficult to control with the NeuralAE method. The parameter\ninitializer (PI) contributes significantly to alleviate the difficulty;\nwithout PI, the detector's backbone has to deal with the pixel distributions\nbefore and after ISP, degrading detection performance. A detailed\nablation study of the PI is shown in Table 2.\nWe compare three types of PIs. One is a uniform sampling from (pl,n,m‚Äãi‚Äãn,pl,n,m‚Äãa‚Äãx)subscriptùëùùëôùëõùëöùëñùëõsubscriptùëùùëôùëõùëöùëéùë•\\left(p_{l,n,min},\\,p_{l,n,max}\\right);\nit learns how to control from all possible parameters. Another adds\nGaussian noise to the running mean of the previously used parameters\nby tracking the running mean and running variance of used parameters\nin the second frame. The last approach is our best method, which memorizes\nthe parameters for the 500 most recent data in a buffer and randomly\nadopts the value in the first frame. It takes into account correlations\nbetween parameters and does not approximate a Gaussian distribution,\nthus covering more necessary and sufficient parameter regions. Our\nbuffer memory automatically fits the search space to the minimum required,\nalthough it can still make the controller stable to the drastic environmental\nchange. The buffer memory creates a situation where the environment\nis changed from day to night in a one-time step. The residual output format of parameters (RO) further eases\nthe difficulty of controlling complex functions by making the controller\noutput the difference from the averaging good parameters for the entire\ndataset. For the normal RO, the static ISP parameter obtained by differentiable\ntuning in Table 3 is used as a constant\npl,n^^subscriptùëùùëôùëõ\\hat{p_{l,n}}. On the other hand, pl,n^^subscriptùëùùëôùëõ\\hat{p_{l,n}} in RO+ is jointly\noptimized with the dynamic ISP control from scratch. The gain from\nRO to RO+ is thought to be because the averaging good parameters for\nthe static ISP and DynamicISP is different. RO+ is practical as the\nparameters are tuned automatically. For multi-layer control, the latent update style controller\n(LU) further improves the accuracy. All-at-one estimation of all the\nparameters in the multi-layers is difficult and the proposed LU successfully\ndisentangles the problem setting. The proposed dynamic control is compared to static tuning approaches.\nIn this comparison, we use an ISP containing only a GM tone mapping\nfunction because tone mapping is known to have the biggest impact\non machine vision . One of the static tuning\napproaches for comparison is a grid search [ref]48.\nIn this approach, the detector is trained per searched parameters.\nSince it takes a huge time to train the detector per parameter set\nof large search space, it searches for one parameter of the simplest\ngamma function y=x1ùë¶superscriptùë•1y=x^{\\frac{1}{\\text{}}}. The other\nis a differentiable tuning approach to train the ISP and detector\nend-to-end [ref]48. Table 3\nshows the effectiveness of our dynamic control. Although both static\nISPs are optimized for machine vision, they are just optimal for the\nentire dataset and not optimal for each image. The experiments above are conducted by inputting identical images\ntwice instead of sequential input. We now check the availability of\nsequential inference without twice input. In this setting, optimal\nparameters for the previous frame are used, resulting in possibly\nsuboptimal. The result is shown in Table 4.\nContrary to expectations, a slight improvement is observed, and it\nmight come from the fact that the twice input case is evaluated under\nsevere settings. The initial parameters are set as the moving average\nof the parameters in the training phase and are far from the optimal\nparameters per image. On the other hand, in the sequential settings,\nthe previous parameters can be already decent values since consecutive\nframes are similar. From this experiment, efficient inference without\ninput twice is proved to be possible. Additionally, since the dataset\nis captured at about 1 fps, and about half of it is taken with a shaken\ncamera, consecutive frames may have some disparities. Inference at\nhigher frame rates might further improve the performance of sequential\ninference. The computational efficiency is evaluated by profiling the FLOPS of\neach component. As listed in Table 5,\nthe computational cost of our ISP controller is lightweight enough\nto be ignored compared with the detector despite our choice of a lightweight\nTTFNet detector with a ResNet18 backbone. Although our proposed LU\nhas a complicated computational graph as shown in Fig. 2,\nthe computational cost does not change very much (an increase of about\n4e-5 GFLOPS per each ISP function) thanks to the lightweight design\nwith 1-D latent variable manipulations. The computational cost of\nthe detector in the input twice setting is not doubled from other\nsettings because the whole part of the calculation for the first input\nis not needed. If ISP functions are lightweight classical functions,\nthe dynamic ISP control can be efficient even as a single image detector\nwith the inputting twice setting. ‚ô£‚ô£\\clubsuit: The original augmentation in stead of Rawgment[ref]48\nis used. ‚Ä†‚Ä†\\dagger: Full version of NeuralAE including Global Feature\nBranch, which is a histgram-based encoder to support Semantic\nFeature Branch. ‚ô†‚ô†\\spadesuit: Our implementations of DN and SN have a lot of duplicate\ncalculations and are not optimized. Various evaluations are performed against the state-of-the-art. The\nlatency is measured on an RTX2080 GPU. The result is shown in Table\n6. One category for comparison is DNN-based encoder-decoder ISPs. The\nproblem with the DNN ISP is that there are no input and ground truth\npairs to train them. As pointed out in ,\ncreating clean ground truth for challenging noisy/blurry environment\ndata is difficult. So, three kinds of DNN ISPs are tried. One is UNet(s);\nan UNet  based ISP , and the ISP and detector\nare trained end-to-end from scratch. It means that the ISP is trained\nonly with the detection loss. The second is AW+sGM+UNet(f); a fixed\nstate-of-ther-art UNet ISP trained for dark environments \nis used following auto-white balance (AWB) and simple gamma (sGM).\nThe AWB and sGM are identical to the preprocessing pipeline of the\ntrained UNet. In this setting, the UNet ISP is trained with paired\ndata for dark environments proposed in .\nThe third is AW+sGM+UNet(p); end-to-end training is performed from\nthe pre-trained UNet ISP's weight to tune it to the target sensor\nand downstream detector. The other category is classical function-based ISPs. As for NeuralAE,\nwe do not convert the images to those taken with lower-quality sensors\nas the original paper did to make a fair comparison and use our ISP\nfunctions because the details are missing. Comparing DNN ISP and classical\nISPs, the tuned classical ISPs outperform the existing state-of-the-art\nDNN ISPs in challenging environments despite the low computational\ncost. One of the reasons should be the lack of paired data for the\ntarget dataset to train the DNN ISPs, but it is difficult to create\nground truth images for challenging RAW data. ISPs that do not require\npaired data and can be optimized with downstream task loss must be\nuseful. As to NeuralAE [ref]32, we try two of its\nproposed encoders, Semantic Feature Branch and Global\nFeature Branch. Our Global Feature Branch implementation uses\nthe histc() function implemented in Pytroch \nto generate multiple histograms of the image, but it is time-consuming.\nSo we only use Semantic Feature Branch in our method. We also\ntried further tuning from the well-trained diff. tuning (GM) [ref]32\nweight using Hardware-in-the-loop [ref]48, but\nit did not improve accuracy due to overfitting the training data.\nAlthough we use vanilla CMA-ES in the Hardware-in-the-loop due to\nthe missing information about the modifications, it should be no problem\nsince only three parameters in the GM function are the target for\nthe optimization. Comparing ours with both categories, our method achieves the best\naccuracy in spite of the low computational cost. Especially, compared\nwith diff. tuning, ours further improved detection accuracy with a\nlittle computational gain. While our computational cost and inference\nspeed are almost unchanged compared to static ISP (diff. tuning),\nthe number of parameters is increased. This is because the fully connected\nlayers whose channel sizes are 1024 in the Semantic Feature\nBranch have many parameters despite a few computational costs. If\nthe target device is constrained by the number of parameters, we can\nreduce their channel sizes. It is not a bottleneck, but an enough\nlarge value of 256 is also set for the channel size for latent variable\nin LU since the computational cost hardly increases. Although NeuralAE\nalso controls the exposure function, it is a simple function. Instead,\nours enables the control of complicated functions and yields more\nsuitable images for the downstream detector like Fig. 4."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Cross-camera convolutional color constancy",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF International Conference on Computer Vision",
      "authors": "Mahmoud Afifi, Jonathan¬†T Barron, Chloe LeGendre, Yun-Ta Tsai, and Francois Bleibel"
    },
    {
      "index": 1,
      "title": "Unprocessing Images for Learned Raw Denoising",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Tim Brooks, Ben Mildenhall, Tianfan Xue, Jiawen Chen, Dillon Sharlet, and Jonathan¬†T Barron",
      "orig_title": "Unprocessing images for learned raw denoising",
      "paper_id": "1811.11127v1"
    },
    {
      "index": 2,
      "title": "Reconfiguring the imaging pipeline for computer vision",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE International Conference on Computer Vision",
      "authors": "Mark Buckler, Suren Jayasuriya, and Adrian Sampson"
    },
    {
      "index": 3,
      "title": "Learning to see in the dark",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Chen Chen, Qifeng Chen, Jia Xu, and Vladlen Koltun"
    },
    {
      "index": 4,
      "title": "Hinet: Half instance normalization network for image restoration",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Liangyu Chen, Xin Lu, Jie Zhang, Xiaojie Chu, and Chengpeng Chen"
    },
    {
      "index": 5,
      "title": "Dynamic Convolution: Attention over Convolution Kernels",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Yinpeng Chen, Xiyang Dai, Mengchen Liu, Dongdong Chen, Lu Yuan, and Zicheng Liu",
      "orig_title": "Dynamic convolution: Attention over convolution kernels",
      "paper_id": "1912.03458v2"
    },
    {
      "index": 6,
      "title": "Dynamic ReLU",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Yinpeng Chen, Xiyang Dai, Mengchen Liu, Dongdong Chen, Lu Yuan, and Zicheng Liu",
      "orig_title": "Dynamic relu",
      "paper_id": "2003.10027v2"
    },
    {
      "index": 7,
      "title": "Model-Based Image Signal Processors via Learnable Dictionaries",
      "abstract": "",
      "year": "2022",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Marcos¬†V Conde, Steven McDonagh, Matteo Maggioni, Ales Leonardis, and Eduardo P√©rez-Pellitero",
      "orig_title": "Model-based image signal processors via learnable dictionaries",
      "paper_id": "2201.03210v1"
    },
    {
      "index": 8,
      "title": "Dirty pixels: Towards end-to-end image processing and perception",
      "abstract": "",
      "year": "2021",
      "venue": "ACM Transactions on Graphics (TOG)",
      "authors": "Steven Diamond, Vincent Sitzmann, Frank Julca-Aguilar, Stephen Boyd, Gordon Wetzstein, and Felix Heide"
    },
    {
      "index": 9,
      "title": "Zero-Reference Deep Curve Estimation for Low-Light Image Enhancement",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Chunle Guo, Chongyi Li, Jichang Guo, Chen¬†Change Loy, Junhui Hou, Sam Kwong, and Runmin Cong",
      "orig_title": "Zero-reference deep curve estimation for low-light image enhancement",
      "paper_id": "2001.06826v2"
    },
    {
      "index": 10,
      "title": "Isp4ml: The role of image signal processing in efficient deep learning vision systems",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Pattern Recognition (ICPR)",
      "authors": "Patrick Hansen, Alexey Vilkin, Yury Krustalev, James Imber, Dumidu Talagala, David Hanwell, Matthew Mattina, and Paul¬†N Whatmough"
    },
    {
      "index": 11,
      "title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE international conference on computer vision",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun"
    },
    {
      "index": 12,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 13,
      "title": "Optimization of the isp parameters of a camera through differential evolution",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Access",
      "authors": "Luis¬†V Hevia, Miguel¬†A Patricio, Jose√©¬†M Molina, and Antonio Berlanga"
    },
    {
      "index": 14,
      "title": "Crafting object detection in very low light",
      "abstract": "",
      "year": "2021",
      "venue": "British Machine Vision Virtual Conference",
      "authors": "Yang Hong, Kaixuan Wei, Linwei Chen, and Ying Fu"
    },
    {
      "index": 15,
      "title": "Enlightengan: Deep light enhancement without paired supervision",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Image Processing",
      "authors": "Yifan Jiang, Xinyu Gong, Ding Liu, Yu Cheng, Chen Fang, Xiaohui Shen, Jianchao Yang, Pan Zhou, and Zhangyang Wang"
    },
    {
      "index": 16,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1412.6980",
      "authors": "Diederik¬†P Kingma and Jimmy Ba"
    },
    {
      "index": 17,
      "title": "Restoring extremely dark images in real time",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Mohit Lamba and Kaushik Mitra"
    },
    {
      "index": 18,
      "title": "Microsoft COCO: Common Objects in Context",
      "abstract": "",
      "year": "2014",
      "venue": "European conference on computer vision",
      "authors": "Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll√°r, and C¬†Lawrence Zitnick",
      "orig_title": "Microsoft coco: Common objects in context",
      "paper_id": "1405.0312v3"
    },
    {
      "index": 19,
      "title": "Darts: Differentiable architecture search",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1806.09055",
      "authors": "Hanxiao Liu, Karen Simonyan, and Yiming Yang"
    },
    {
      "index": 20,
      "title": "Deep-flexisp: A three-stage framework for night photography rendering",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Shuai Liu, Chaoyu Feng, Xiaotao Wang, Hao Wang, Ran Zhu, Yongqiang Li, and Lei Lei"
    },
    {
      "index": 21,
      "title": "Training-time-friendly network for real-time object detection",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "Zili Liu, Tu Zheng, Guodong Xu, Zheng Yang, Haifeng Liu, and Deng Cai"
    },
    {
      "index": 22,
      "title": "SGDR: Stochastic Gradient Descent with Warm Restarts",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1608.03983",
      "authors": "Ilya Loshchilov and Frank Hutter",
      "orig_title": "Sgdr: Stochastic gradient descent with warm restarts",
      "paper_id": "1608.03983v5"
    },
    {
      "index": 23,
      "title": "Mbllen: Low-light image/video enhancement using cnns",
      "abstract": "",
      "year": "2018",
      "venue": "BMVC",
      "authors": "Feifan Lv, Feng Lu, Jianhua Wu, and Chongsoon Lim"
    },
    {
      "index": 24,
      "title": "Toward Fast, Flexible, and Robust Low-Light Image Enhancement",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Long Ma, Tengyu Ma, Risheng Liu, Xin Fan, and Zhongxuan Luo",
      "orig_title": "Toward fast, flexible, and robust low-light image enhancement",
      "paper_id": "2204.10137v1"
    },
    {
      "index": 25,
      "title": "Theory of edge detection",
      "abstract": "",
      "year": "1980",
      "venue": "Royal Society of London. Series B. Biological Sciences",
      "authors": "David Marr and Ellen Hildreth"
    },
    {
      "index": 26,
      "title": "Dancing under the stars: video denoising in starlight",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Kristina Monakhova, Stephan¬†R Richter, Laura Waller, and Vladlen Koltun"
    },
    {
      "index": 27,
      "title": "GenISP: Neural ISP for Low-Light Machine Cognition",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Igor Morawski, Yu-An Chen, Yu-Sheng Lin, Shusil Dangi, Kai He, and Winston¬†H Hsu",
      "orig_title": "Genisp: Neural isp for low-light machine cognition",
      "paper_id": "2205.03688v1"
    },
    {
      "index": 28,
      "title": "Hardware-in-the-loop end-to-end optimization of camera image processing pipelines",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Ali Mosleh, Avinash Sharma, Emmanuel Onzon, Fahim Mannan, Nicolas Robidoux, and Felix Heide"
    },
    {
      "index": 29,
      "title": "Automatic isp image quality tuning using nonlinear optimization",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE International Conference on Image Processing (ICIP)",
      "authors": "Jun Nishimura, Timo Gerasimow, Rao Sushma, Aleksandar Sutic, Chyuan-Tyng Wu, and Gilad Michael"
    },
    {
      "index": 30,
      "title": "Degree-of-linear-polarization-based color constancy",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Taishi Ono, Yuhi Kondo, Legong Sun, Teppei Kurita, and Yusuke Moriuchi"
    },
    {
      "index": 31,
      "title": "Neural auto-exposure for high-dynamic range object detection",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Emmanuel Onzon, Fahim Mannan, and Felix Heide"
    },
    {
      "index": 32,
      "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
      "abstract": "",
      "year": "2019",
      "venue": "Advances in neural information processing systems",
      "authors": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et¬†al.",
      "orig_title": "Pytorch: An imperative style, high-performance deep learning library",
      "paper_id": "1912.01703v1"
    },
    {
      "index": 33,
      "title": "Automatic image quality tuning framework for optimization of isp parameters based on multi-stage optimization approach",
      "abstract": "",
      "year": "2021",
      "venue": "Electronic Imaging",
      "authors": "G Pavithra and Bhat Radhesh"
    },
    {
      "index": 34,
      "title": "Day-to-Night Image Synthesis for Training Nighttime Neural ISPs",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Abhijith Punnappurath, Abdullah Abuolaim, Abdelrahman Abdelhamed, Alex Levinshtein, and Michael¬†S Brown",
      "orig_title": "Day-to-night image synthesis for training nighttime neural isps",
      "paper_id": "2206.02715v1"
    },
    {
      "index": 35,
      "title": "High dynamic range imaging: acquisition, display, and image-based lighting",
      "abstract": "",
      "year": "2010",
      "venue": "Morgan Kaufmann",
      "authors": "Erik Reinhard, Wolfgang Heidrich, Paul Debevec, Sumanta Pattanaik, Greg Ward, and Karol Myszkowski"
    },
    {
      "index": 36,
      "title": "End-to-end high dynamic range camera pipeline optimization",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Nicolas Robidoux, Luis E¬†Garcia Capel, Dong-eun Seo, Avinash Sharma, Federico Ariza, and Felix Heide"
    },
    {
      "index": 37,
      "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
      "abstract": "",
      "year": "2015",
      "venue": "Medical Image Computing and Computer-Assisted Intervention‚ÄìMICCAI",
      "authors": "Olaf Ronneberger, Philipp Fischer, and Thomas Brox",
      "orig_title": "U-net: Convolutional networks for biomedical image segmentation",
      "paper_id": "1505.04597v1"
    },
    {
      "index": 38,
      "title": "ISP Distillation",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2101.10203",
      "authors": "Eli Schwartz, Alex Bronstein, and Raja Giryes",
      "orig_title": "Isp distillation",
      "paper_id": "2101.10203v3"
    },
    {
      "index": 39,
      "title": "On the psychophysical law",
      "abstract": "",
      "year": "1957",
      "venue": "Psychological review",
      "authors": "Stanley¬†S Stevens"
    },
    {
      "index": 40,
      "title": "Bilateral filtering for gray and color images",
      "abstract": "",
      "year": "1998",
      "venue": "Sixth international conference on computer vision",
      "authors": "Carlo Tomasi and Roberto Manduchi"
    },
    {
      "index": 41,
      "title": "Hyperparameter optimization in black-box image processing using differentiable proxies",
      "abstract": "",
      "year": "2019",
      "venue": "ACM Trans. Graph.",
      "authors": "Ethan Tseng, Felix Yu, Yuting Yang, Fahim Mannan, Karl¬†ST Arnaud, Derek Nowrouzezahrai, Jean-Fran√ßois Lalonde, and Felix Heide"
    },
    {
      "index": 42,
      "title": "MAXIM: Multi-Axis MLP for Image Processing",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, and Yinxiao Li",
      "orig_title": "Maxim: Multi-axis mlp for image processing",
      "paper_id": "2201.02973v2"
    },
    {
      "index": 43,
      "title": "Deep Retinex Decomposition for Low-Light Enhancement",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1808.04560",
      "authors": "Chen Wei, Wenjing Wang, Wenhan Yang, and Jiaying Liu",
      "orig_title": "Deep retinex decomposition for low-light enhancement",
      "paper_id": "1808.04560v1"
    },
    {
      "index": 44,
      "title": "Deblurring via Stochastic Refinement",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Jay Whang, Mauricio Delbracio, Hossein Talebi, Chitwan Saharia, Alexandros¬†G Dimakis, and Peyman Milanfar",
      "orig_title": "Deblurring via stochastic refinement",
      "paper_id": "2112.02475v2"
    },
    {
      "index": 45,
      "title": "VisionISP: Repurposing the Image Signal Processor for Computer Vision Applications",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE International Conference on Image Processing (ICIP)",
      "authors": "Chyuan-Tyng Wu, Leo¬†F Isikdogan, Sushma Rao, Bhavin Nayak, Timo Gerasimow, Aleksandar Sutic, Liron Ain-kedem, and Gilad Michael",
      "orig_title": "Visionisp: Repurposing the image signal processor for computer vision applications",
      "paper_id": "1911.05931v1"
    },
    {
      "index": 46,
      "title": "Condconv: Conditionally parameterized convolutions for efficient inference",
      "abstract": "",
      "year": "2019",
      "venue": "Neural Information Processing Systems",
      "authors": "Brandon Yang, Gabriel Bender, Quoc¬†V Le, and Jiquan Ngiam"
    },
    {
      "index": 47,
      "title": "Rawgment: Noise-accounted raw augmentation enables recognition in a wide variety of environments",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2210.16046",
      "authors": "Masakazu Yoshimura, Junji Otsuka, Atsushi Irie, and Takeshi Ohashi"
    },
    {
      "index": 48,
      "title": "ReconfigISP: Reconfigurable Camera Image Processing Pipeline",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE/CVF International Conference on Computer Vision",
      "authors": "Ke Yu, Zexian Li, Yue Peng, Chen¬†Change Loy, and Jinwei Gu",
      "orig_title": "Reconfigisp: Reconfigurable camera image processing pipeline",
      "paper_id": "2109.04760v1"
    },
    {
      "index": 49,
      "title": "Pixel screening based intermediate correction for blind deblurring",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Meina Zhang, Yingying Fang, Guoxi Ni, and Tieyong Zeng"
    },
    {
      "index": 50,
      "title": "IDR: Self-Supervised Image Denoising via Iterative Data Refinement",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Yi Zhang, Dasong Li, Ka¬†Lung Law, Xiaogang Wang, Hongwei Qin, and Hongsheng Li",
      "orig_title": "Idr: Self-supervised image denoising via iterative data refinement",
      "paper_id": "2111.14358v2"
    },
    {
      "index": 51,
      "title": "Kindling the Darkness: A Practical Low-light Image Enhancer",
      "abstract": "",
      "year": "2019",
      "venue": "ACM international conference on multimedia",
      "authors": "Yonghua Zhang, Jiawan Zhang, and Xiaojie Guo",
      "orig_title": "Kindling the darkness: A practical low-light image enhancer",
      "paper_id": "1905.04161v1"
    },
    {
      "index": 52,
      "title": "Objects as Points",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1904.07850",
      "authors": "Xingyi Zhou, Dequan Wang, and Philipp Kr√§henb√ºhl",
      "orig_title": "Objects as points",
      "paper_id": "1904.07850v2"
    }
  ]
}