{
  "paper_id": "2212.14674v1",
  "title": "A Comprehensive Gold Standard and Benchmark for Comics Text Detection and Recognition",
  "sections": {
    "introduction": "Comics are a multimodal structure and medium that use writing and images in a spectrum, from purely images to purely writing, to convey a story or an idea. Comics are at the intersection of education 0, sociocultural studies [ref]4, linguistics and cognitive sciences  . Understanding comics can help advance progress in these fields. Additionally, methods developed for processing and understanding comics can be applied to other forms of ”Visual Language,” including but not limited to cave paintings, mangas, graphic novels, and comics . The unique structure of comics can be analyzed at the low-level and high-level. At the low-level, natural language processing techniques can extract text from dialogues, narratives, and onomatopoeias. Computer vision methods can detect and segment motion lines, characters, and the location of objects and components   [ref]17 . At the high-level, the relationships between characters, storytelling, narrative understanding, inter-panel and intra-panel events must be studied. While the high-level features of natural images and scenes are widely studied , the same cannot be said for comics. This is due to the great variety of comics across time, location, and different styles and the lack of annotated data (see Table 1 for an overview of datasets). The limited availability of datasets in this domain can also be attributed to copyright and access rights challenges. The amount of annotated data creates a bottleneck for studies on comics using deep learning methods. Although there have been works on panel and speech bubble detection and segmentation, such as in   [ref]17 , and onomatopoeia detection and recognition, such as in , the only extensive dataset with OCR-extracted comics texts is called COMICS 1. However, when the text quality of the COMICS dataset is measured over a sample, it can be seen as unreliable (see Subsection 3.1 and Table 12). There is a limited amount of study on the OCR of dialogue and narrative texts in comics to produce high-quality text data. In [ref]17, such a pipeline was presented, but the data and models could not be shared due to copyright issues. This study presents a pipeline for OCR of comics, allowing us to extract text from speech bubbles in panels. This pipeline can also be used for general OCR purposes. We use the COMICS dataset 1 to curate a reliable and comprehensive dataset of American golden age comics. These comics are uniform, allowing our work to be directly applied to previous studies in the literature. We inspect the reported and unreported problems in the COMICS dataset and develop separate solutions for text detection and recognition using the MMOCR toolbox 6. To improve the performance of text detection and recognition, we follow a loop of annotating panels and speech bubbles, training models and evaluating them using ground-truth data. Once we have achieved stable performance with the trained models, we select the best end-to-end text detection and recognition model pair to process the COMICS dataset and extract OCR texts. Finally, we apply post-processing techniques to correct systematic errors in the OCR data and create the COMICS TEXT+ dataset. Our contributions can be summarized as follows: We release a substantially improved version of the COMICS dataset OCR results, called COMICS Text+, which significantly outperforms its predecessor in terms of text quality, with a word accuracy improvement from 0.13 to 0.40. It is the best quality and most comprehensive publicly available dataset, with over two million transcriptions of textboxes. We release text detection and text recognition datasets created from Golden Age comics called respectively, COMICS Text+: Detection and COMICS Text+: Recognition along with ground truth data to validate end-to-end OCR pipelines. COMICS Text+: Detection contains more than 20,000 annotations from 1112 images. Whereas, COMICS Text+: Recognition contains more than 17,000 annotations from 1006 images. We train and evaluate the performance of 14 text detection and 10 text recognition models on COMICS Text+ datasets and analyze the effects of training size on performance. Our results show that text detection models are the bottleneck for OCR studies of comics, (see Figure 6) but their performance improves significantly after 200 textbox annotations. We present fine-tuned text detection and recognition models, based on FCENet  and MASTER 5, respectively, that have been trained on the COMICS Text+: Detection & Recognition datasets. There are no other publicly available models and datasets of this specific type, so we hope this work will serve as a baseline for future studies and lower the barrier to entry for those interested in this domain. We share an annotation tool forked from LabelMe . Since LabelMe does not allow the use of models to get predictions, we improved it by enabling it to use text detection and text recognition models to aid and speed up the annotation process. Our tool converts annotations into text detection, and recognition datasets used to create COMICS Text+: Detection & Recognition datasets. By providing this tool, we hope to make it easier for other researchers to create high-quality datasets for training and evaluating OCR models and can help to advance the state of the art in this field. The comics processing backbone for cloze-style tasks proposed in the COMICS dataset is reproduced, and the reproduced model is trained using both COMICS and COMICS TEXT+ datasets. The test results of the two models are compared, and it is shown that the model trained with COMICS TEXT+ outperforms the other model and achieves state-of-the-art results on most cloze-style tasks."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Building a Manga Dataset ”Manga109” with Annotations for Multimedia Applications",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE MultiMedia",
      "authors": "Aizawa, K., Fujimoto, A., Otsubo, A., Ogawa, T., Matsui, Y., Tsubota, K., Ikuta, H.",
      "orig_title": "Building a manga dataset “manga109” with annotations for multimedia applications",
      "paper_id": "2005.04425v2"
    },
    {
      "index": 1,
      "title": "An overview of comics research in computer science",
      "abstract": "",
      "year": "2017",
      "venue": "IAPR International Conference on Document Analysis and Recognition",
      "authors": "Augereau, O., Iwata, M., Kise, K."
    },
    {
      "index": 2,
      "title": "COO: Comic Onomatopoeia Dataset for Recognizing Arbitrary or Truncated Texts",
      "abstract": "",
      "year": "2022",
      "venue": "arXiv preprint arXiv:2207.04675",
      "authors": "Baek, J., Matsui, Y., Aizawa, K.",
      "orig_title": "Coo: Comic onomatopoeia dataset for recognizing arbitrary or truncated texts",
      "paper_id": "2207.04675v1"
    },
    {
      "index": 3,
      "title": "Producing comics culture: a sociological approach to the study of comics",
      "abstract": "",
      "year": "2010",
      "venue": "Journal of Graphic Novels and Comics",
      "authors": "Brienza, C."
    },
    {
      "index": 4,
      "title": "Text Recognition in the Wild: A Survey",
      "abstract": "",
      "year": "2021",
      "venue": "ACM Computing Surveys (CSUR)",
      "authors": "Chen, X., Jin, L., Zhu, Y., Luo, C., Wang, T.",
      "orig_title": "Text recognition in the wild: A survey",
      "paper_id": "2005.03492v3"
    },
    {
      "index": 5,
      "title": "The Visual Language of Comics: Introduction to the Structure and Cognition of Sequential Images",
      "abstract": "",
      "year": "2013",
      "venue": "A&C Black",
      "authors": "Cohn, N."
    },
    {
      "index": 6,
      "title": "Deformable convolutional networks",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE international conference on computer vision",
      "authors": "Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., Wei, Y."
    },
    {
      "index": 7,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "Devlin, J., Chang, M.W., Lee, K., Toutanova, K.",
      "orig_title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 8,
      "title": "The graphic narrative corpus (gnc): design, annotation, and analysis for the digital humanities",
      "abstract": "",
      "year": "2017",
      "venue": "IAPR international conference on document analysis and recognition",
      "authors": "Dunst, A., Hartel, R., Laubrock, J."
    },
    {
      "index": 9,
      "title": "Read like humans: Autonomous, bidirectional and iterative language modeling for scene text recognition",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Fang, S., Xie, H., Wang, Y., Mao, Z., Zhang, Y."
    },
    {
      "index": 10,
      "title": "Brown corpus manual",
      "abstract": "",
      "year": "1979",
      "venue": "Letters to the Editor",
      "authors": "Francis, W.N., Kucera, H."
    },
    {
      "index": 11,
      "title": "Unconstrained Text Detection in Manga: a New Dataset and Baseline",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Gobbo, J.D., Matuk Herrera, R.",
      "orig_title": "Unconstrained text detection in manga: A new dataset and baseline",
      "paper_id": "2009.04042v1"
    },
    {
      "index": 12,
      "title": "Contextual Spell Check",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "Goel, R."
    },
    {
      "index": 13,
      "title": "Icdar2017 robust reading challenge on coco-text",
      "abstract": "",
      "year": "2017",
      "venue": "IAPR International Conference on Document Analysis and Recognition",
      "authors": "Gomez, R., Shi, B., Gomez, L., Numann, L., Veit, A., Matas, J., Belongie, S., Karatzas, D."
    },
    {
      "index": 14,
      "title": "ebdtheque: a representative database of comics",
      "abstract": "",
      "year": "2013",
      "venue": "International Conference on Document Analysis and Recognition",
      "authors": "Guérin, C., Rigaud, C., Mercier, A., Ammar-Boudjelal, F., Bertet, K., Bouju, A., Burie, J.C., Louis, G., Ogier, J.M., Revel, A."
    },
    {
      "index": 15,
      "title": "Synthetic Data for Text Localisation in Natural Images",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "Gupta, A., Vedaldi, A., Zisserman, A.",
      "orig_title": "Synthetic data for text localisation in natural images",
      "paper_id": "1604.06646v1"
    },
    {
      "index": 16,
      "title": "An ocr pipeline and semantic text analysis for comics",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Pattern Recognition",
      "authors": "Hartel, R., Dunst, A."
    },
    {
      "index": 17,
      "title": "Mask R-CNN",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE International Conference on Computer Vision",
      "authors": "He, K., Gkioxari, G., Dollár, P., Girshick, R.",
      "orig_title": "Mask r-cnn",
      "paper_id": "1703.06870v3"
    },
    {
      "index": 18,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "He, K., Zhang, X., Ren, S., Sun, J.",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 19,
      "title": "Using comics-based representations of teaching, and technology, to bring practice to teacher education courses",
      "abstract": "",
      "year": "2011",
      "venue": "ZDM",
      "authors": "Herbst, P., Chazan, D., Chen, C.L., Chieu, V.M., Weiss, M."
    },
    {
      "index": 20,
      "title": "The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels in Comic Book Narratives",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Iyyer, M., Manjunatha, V., Guha, A., Vyas, Y., Boyd-Graber, J., au2, H.D.I., Davis, L.",
      "orig_title": "The amazing mysteries of the gutter: Drawing inferences between panels in comic book narratives",
      "paper_id": "1611.05118v2"
    },
    {
      "index": 21,
      "title": "Discourse-Level Language Understanding with Deep Learning",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "Iyyer, M.N."
    },
    {
      "index": 22,
      "title": "Reading Text in the Wild with Convolutional Neural Networks",
      "abstract": "",
      "year": "2016",
      "venue": "International Journal of Computer Vision",
      "authors": "Jaderberg, M., Simonyan, K., Vedaldi, A., Zisserman, A.",
      "orig_title": "Reading text in the wild with convolutional neural networks",
      "paper_id": "1412.1842v1"
    },
    {
      "index": 23,
      "title": "NeuSpell: A Neural Spelling Correction Toolkit",
      "abstract": "",
      "year": "2020",
      "venue": "Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
      "authors": "Jayanthi, S.M., Pruthi, D., Neubig, G.",
      "orig_title": "NeuSpell: A neural spelling correction toolkit",
      "paper_id": "2010.11085v1"
    },
    {
      "index": 24,
      "title": "Icdar 2015 competition on robust reading",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Document Analysis and Recognition",
      "authors": "Karatzas, D., Gomez-Bigorda, L., Nicolaou, A., Ghosh, S., Bagdanov, A., Iwamura, M., Matas, J., Neumann, L., Chandrasekhar, V.R., Lu, S., et al."
    },
    {
      "index": 25,
      "title": "MMOCR: A Comprehensive Toolbox for Text Detection, Recognition and Understanding",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2108.06543",
      "authors": "Kuang, Z., Sun, H., Li, Z., Yue, X., Lin, T.H., Chen, J., Wei, H., Zhu, Y., Gao, T., Zhang, W., Chen, K., Zhang, W., Lin, D.",
      "orig_title": "Mmocr: A comprehensive toolbox for text detection, recognition and understanding",
      "paper_id": "2108.06543v1"
    },
    {
      "index": 26,
      "title": "Computational approaches to comics analysis",
      "abstract": "",
      "year": "2020",
      "venue": "Topics in cognitive science",
      "authors": "Laubrock, J., Dunst, A."
    },
    {
      "index": 27,
      "title": "On Recognizing Texts of Arbitrary Shapes with 2D Self-Attention",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops",
      "authors": "Lee, J., Park, S., Baek, J., Oh, S.J., Kim, S., Lee, H.",
      "orig_title": "On recognizing texts of arbitrary shapes with 2d self-attention",
      "paper_id": "1910.04396v1"
    },
    {
      "index": 28,
      "title": "Show, Attend and Read: A Simple and Strong Baseline for Irregular Text Recognition",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Li, H., Wang, P., Shen, C., Zhang, G.",
      "orig_title": "Show, attend and read: A simple and strong baseline for irregular text recognition",
      "paper_id": "1811.00751v2"
    },
    {
      "index": 29,
      "title": "TextBoxes++: A Single-Shot Oriented Scene Text Detector",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE transactions on image processing",
      "authors": "Liao, M., Shi, B., Bai, X.",
      "orig_title": "Textboxes++: A single-shot oriented scene text detector",
      "paper_id": "1801.02765v3"
    },
    {
      "index": 30,
      "title": "TextBoxes: A Fast Text Detector with a Single Deep Neural Network",
      "abstract": "",
      "year": "2017",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "Liao, M., Shi, B., Bai, X., Wang, X., Liu, W.",
      "orig_title": "Textboxes: A fast text detector with a single deep neural network",
      "paper_id": "1611.06779v1"
    },
    {
      "index": 31,
      "title": "Real-time Scene Text Detection with Differentiable Binarization",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Liao, M., Wan, Z., Yao, C., Chen, K., Bai, X.",
      "orig_title": "Real-time scene text detection with differentiable binarization",
      "paper_id": "1911.08947v2"
    },
    {
      "index": 32,
      "title": "Real-Time Scene Text Detection with Differentiable Binarization and Adaptive Scale Fusion",
      "abstract": "",
      "year": "2022",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "authors": "Liao, M., Zou, Z., Wan, Z., Yao, C., Bai, X.",
      "orig_title": "Real-time scene text detection with differentiable binarization and adaptive scale fusion",
      "paper_id": "2202.10304v1"
    },
    {
      "index": 33,
      "title": "TextSnake: A Flexible Representation for Detecting Text of Arbitrary Shapes",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Long, S., Ruan, J., Zhang, W., He, X., Wu, W., Yao, C.",
      "orig_title": "Textsnake: A flexible representation for detecting text of arbitrary shapes",
      "paper_id": "1807.01544v2"
    },
    {
      "index": 34,
      "title": "MASTER: Multi-aspect non-local network for scene text recognition",
      "abstract": "",
      "year": "2021",
      "venue": "Pattern Recognition",
      "authors": "Lu, N., Yu, W., Qi, X., Chen, Y., Gong, P., Xiao, R., Bai, X."
    },
    {
      "index": 35,
      "title": "Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes",
      "abstract": "",
      "year": "2018",
      "venue": "European Conference on Computer Vision (ECCV)",
      "authors": "Lyu, P., Liao, M., Yao, C., Wu, W., Bai, X.",
      "orig_title": "Mask textspotter: An end-to-end trainable neural network for spotting text with arbitrary shapes",
      "paper_id": "1807.02242v2"
    },
    {
      "index": 36,
      "title": "Image Segmentation Using Deep Learning: A Survey",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE transactions on pattern analysis and machine intelligence",
      "authors": "Minaee, S., Boykov, Y.Y., Porikli, F., Plaza, A.J., Kehtarnavaz, N., Terzopoulos, D.",
      "orig_title": "Image segmentation using deep learning: A survey",
      "paper_id": "2001.05566v5"
    },
    {
      "index": 37,
      "title": "Digital comics image indexing based on deep learning",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of Imaging",
      "authors": "Nguyen, N.V., Rigaud, C., Burie, J.C."
    },
    {
      "index": 38,
      "title": "Comic mtl: optimized multi-task learning for comic book image analysis",
      "abstract": "",
      "year": "2019",
      "venue": "International Journal on Document Analysis and Recognition (IJDAR)",
      "authors": "Nguyen, N.V., Rigaud, C., Burie, J.C."
    },
    {
      "index": 39,
      "title": "Icdar 2021 competition on multimodal emotion recognition on comics scenes",
      "abstract": "",
      "year": "2021",
      "venue": "International Conference on Document Analysis and Recognition",
      "authors": "Nguyen, N.V., Vu, X.S., Rigaud, C., Jiang, L., Burie, J.C."
    },
    {
      "index": 40,
      "title": "Speech balloon and speaker association for comics and manga understanding",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Document Analysis and Recognition",
      "authors": "Rigaud, C., Le Thanh, N., Burie, J.C., Ogier, J.M., Iwata, M., Imazu, E., Kise, K."
    },
    {
      "index": 41,
      "title": "Toward speech text recognition for comic books",
      "abstract": "",
      "year": "2016",
      "venue": "International Workshop on coMics ANalysis, Processing and Understanding",
      "authors": "Rigaud, C., Pal, S., Burie, J.C., Ogier, J.M."
    },
    {
      "index": 42,
      "title": "NRTR: A No-Recurrence Sequence-to-Sequence Model For Scene Text Recognition",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Document Analysis and Recognition",
      "authors": "Sheng, F., Chen, Z., Xu, B.",
      "orig_title": "Nrtr: A no-recurrence sequence-to-sequence model for scene text recognition",
      "paper_id": "1806.00926v2"
    },
    {
      "index": 43,
      "title": "Detecting oriented text in natural images by linking segments",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "Shi, B., Bai, X., Belongie, S."
    },
    {
      "index": 44,
      "title": "An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE transactions on pattern analysis and machine intelligence",
      "authors": "Shi, B., Bai, X., Yao, C."
    },
    {
      "index": 45,
      "title": "Robust Scene Text Recognition with Automatic Rectification",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "Shi, B., Wang, X., Lyu, P., Yao, C., Bai, X.",
      "orig_title": "Robust scene text recognition with automatic rectification",
      "paper_id": "1603.03915v2"
    },
    {
      "index": 46,
      "title": "Seglink++: Detecting dense and arbitrary-shaped scene text by instance-aware component grouping",
      "abstract": "",
      "year": "2019",
      "venue": "Pattern recognition",
      "authors": "Tang, J., Yang, Z., Wang, Y., Zheng, Q., Xu, Y., Bai, X."
    },
    {
      "index": 47,
      "title": "labelme: Image polygonal annotation with python",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "Wada, K."
    },
    {
      "index": 48,
      "title": "Shape Robust Text Detection with Progressive Scale Expansion Network",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "authors": "Wang, W., Xie, E., Li, X., Hou, W., Lu, T., Yu, G., Shao, S.",
      "orig_title": "Shape robust text detection with progressive scale expansion network",
      "paper_id": "1806.02559v1"
    },
    {
      "index": 49,
      "title": "Efficient and Accurate Arbitrary-Shaped Text Detection with Pixel Aggregation Network",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Wang, W., Xie, E., Song, X., Zang, Y., Wang, W., Lu, T., Yu, G., Shen, C.",
      "orig_title": "Efficient and accurate arbitrary-shaped text detection with pixel aggregation network",
      "paper_id": "1908.05900v2"
    },
    {
      "index": 50,
      "title": "Calamari - A High-Performance Tensorflow-based Deep Learning Package for Optical Character Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "Digital Humanities Quarterly",
      "authors": "Wick, C., Reul, C., Puppe, F."
    },
    {
      "index": 51,
      "title": "DeRPN: Taking a further step toward more general object detection",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "Xie, L., Liu, Y., Jin, L., Xie, Z.",
      "orig_title": "Derpn: Taking a further step toward more general object detection",
      "paper_id": "1811.06700v1"
    },
    {
      "index": 52,
      "title": "RobustScanner: Dynamically Enhancing Positional Clues for Robust Text Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "European Conference on Computer Vision",
      "authors": "Yue, X., Kuang, Z., Lin, C., Sun, H., Zhang, W.",
      "orig_title": "Robustscanner: Dynamically enhancing positional clues for robust text recognition",
      "paper_id": "2007.07542v2"
    },
    {
      "index": 53,
      "title": "Detecting Curve Text in the Wild: New Dataset and New Solution",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1712.02170",
      "authors": "Yuliang, L., Lianwen, J., Shuaitao, Z., Sheng, Z.",
      "orig_title": "Detecting curve text in the wild: New dataset and new solution",
      "paper_id": "1712.02170v1"
    },
    {
      "index": 54,
      "title": "Deep relational reasoning graph network for arbitrary shape text detection",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "Zhang, S.X., Zhu, X., Hou, J.B., Liu, C., Yang, C., Wang, H., Yin, X.C."
    },
    {
      "index": 55,
      "title": "Fourier Contour Embedding for Arbitrary-Shaped Text Detection",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Zhu, Y., Chen, J., Liang, L., Kuang, Z., Jin, L., Zhang, W.",
      "orig_title": "Fourier contour embedding for arbitrary-shaped text detection",
      "paper_id": "2104.10442v2"
    }
  ]
}