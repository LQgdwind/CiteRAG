{
  "paper_id": "2003.01200v4",
  "title": "Natural Language Processing Advancements By Deep Learning: A Survey",
  "sections": {
    "v-g document summarization": "Document summarization refers to a set of problems involving generation of summary sentences given one or multiple documents as input. Generally, text summarization fits into two categories: Extractive Summarization, where the goal is to identify the most salient sentences in the document and return them as the summary. Abstractive Summarization, where the goal is to generate summary sentences from scratch; they may contain novel words that do not appear in the original document. Each of these methods has its own advantages and disadvantages.\nExtractive summarization is prone to generate long and sometimes overlapping summary sentences; however, the result reflects the author’s mode of expression.\nAbstractive methods generate a shorter summary but they are hard to train. There is a vast amount of research on the topic of text summarization using extractive and abstractive methods.\nAs one of the earliest works on using neural networks for extractive summarization,  [ref]196 proposed a framework that used a ranking technique to extract the most salient sentences in the input.\nThis model was improved by  which used a document-level encoder to represent sentences, and a classifier to rank these sentences.\nOn the other hand, in abstractive summarization, it was   which, for the first time, used attention over a sequence-to-sequence (seq2seq) model for the problem of headline generation.\nHowever, since simple attention models perform worse than extractive models, therefore more effective attention models such as graph-based attention  and transformers [ref]173 have been proposed for this task.\nTo further improve abstractive text summarization models,   proposed the first pointer-generator model and applied it to the DeepMind QA dataset .\nAs a result of this work, the CNN/Daily Mail dataset emerged which is now one of the widely used datasets for the summarization task.\nA copy mechanism was also adopted by  for similar tasks.\nBut their analysis reveals a key problem with attention-based encoder-decoder models: they often generate unusual summaries consisting of repeated phrases.\nRecently,   reached state-of-the-art results on the abstractive text summarization using a similar framework.\nThey alleviated the unnatural summaries by avoiding generating unknown tokens and replacing these words with tokens from the input article.\nLater, researchers moved their focus to methods that use sentence-embedding to first select the most salient sentence in the document and then change them to make them more abstractive [ref]203 .\nIn these models, salient sentences are extracted first and then a paraphrasing model is used to make them abstractive.\nThe extraction employs a sentence classifier or ranker while the abstractor tries to remove the extra information in a sentence and present it as a shorter summary.\nFast-RL [ref]203 is the first framework in this family of works.\nIn Fast-RL, the extractor is pre-trained to select salient sentences and the abstractor is pre-trained using a pointer-generator model to generate paraphrases.\nFinally, to merge these two non-differentiable components, they propose using Actor-Critic Q-learning methods in which the actor receives a single document and generates the output while the critic evaluates the output based on comparison with the ground-truth summary. Though the standard way to evaluate the performance of summarization models is with ROUGE  and BLEU , there are major problems with such measures.\nFor instance, the ROUGE measure focuses on the number of shared n-grams between two sentences.\nSuch a method incorrectly assigns a low score to an abstractive summary that uses different words yet provides an excellent paraphrase that humans would rate highly.\nClearly, better automated evaluation methods are needed in such cases. There are additional problems with current summarization models.\nShi et al.  provides a comprehensive survey on text summarization.  provides a recent survey on summarization methods.  provides an advanced composite deep learning model, based on LSTMs and Restricted Boltzmann Machine, for multi-doc opinion summarization. A very influential recent work, , introduces Hibert ( HIerachical  Bidirectional  Encoder  Representations from  Transformers) as a pre-trained initialization for document summarization and report state-of-the-art performance."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Foundations of statistical natural language processing",
      "abstract": "",
      "year": "1999",
      "venue": "MIT Press",
      "authors": "C. D. Manning, C. D. Manning, and H. Schütze"
    },
    {
      "index": 1,
      "title": "Character-level convolutional networks for text classification",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in neural information processing systems",
      "authors": "X. Zhang, J. Zhao, and Y. LeCun"
    },
    {
      "index": 2,
      "title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1406.1078",
      "authors": "K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio"
    },
    {
      "index": 3,
      "title": "Deep learning in clinical natural language processing: a methodical review",
      "abstract": "",
      "year": "2020",
      "venue": "Journal of the American Medical Informatics Association",
      "authors": "S. Wu, K. Roberts, S. Datta, J. Du, Z. Ji, Y. Si, S. Soni, Q. Wang, Q. Wei, Y. Xiang, B. Zhao, and H. Xu"
    },
    {
      "index": 4,
      "title": "A unified architecture for natural language processing: Deep neural networks with multitask learning",
      "abstract": "",
      "year": "2008",
      "venue": "25th international conference on Machine learning",
      "authors": "R. Collobert and J. Weston"
    },
    {
      "index": 5,
      "title": "Large-scale video classification with convolutional neural networks",
      "abstract": "",
      "year": "2014",
      "venue": "IEEE conference on Computer Vision and Pattern Recognition",
      "authors": "A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei"
    },
    {
      "index": 6,
      "title": "Learning and transferring mid-level image representations using convolutional neural networks",
      "abstract": "",
      "year": "2014",
      "venue": "IEEE conference on Computer Vision and Pattern Recognition",
      "authors": "M. Oquab, L. Bottou, I. Laptev, and J. Sivic"
    },
    {
      "index": 7,
      "title": "Learning from simulated and unsupervised images through adversarial training",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "A. Shrivastava, T. Pfister, O. Tuzel, J. Susskind, W. Wang, and R. Webb"
    },
    {
      "index": 8,
      "title": "Deep Learning for Computer Vision: A Brief Review",
      "abstract": "",
      "year": "2018",
      "venue": "Computational Intelligence and Neuroscience",
      "authors": "A. Voulodimos, N. Doulamis, A. Doulamis, and E. Protopapadakis"
    },
    {
      "index": 9,
      "title": "Deep learning vs. traditional computer vision",
      "abstract": "",
      "year": "2020",
      "venue": "Advances in Computer Vision",
      "authors": "N. O’Mahony, S. Campbell, A. Carvalho, S. Harapanahalli, G. V. Hernandez, L. Krpalkova, D. Riordan, and J. Walsh"
    },
    {
      "index": 10,
      "title": "Towards end-to-end speech recognition with recurrent neural networks",
      "abstract": "",
      "year": "2014",
      "venue": "International Conference on Machine Learning",
      "authors": "A. Graves and N. Jaitly"
    },
    {
      "index": 11,
      "title": "Deep Speech 2: End-to-End Speech Recognition in English and Mandarin",
      "abstract": "",
      "year": "2016",
      "venue": "ICML",
      "authors": "D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, Q. Cheng, G. Chen, et al.",
      "orig_title": "Deep speech 2: End-to-end speech recognition in English and Mandarin",
      "paper_id": "1512.02595v1"
    },
    {
      "index": 12,
      "title": "Deep learning for NLP and speech recognition",
      "abstract": "",
      "year": "2019",
      "venue": "Springer",
      "authors": "U. Kamath, J. Liu, and J. Whitaker"
    },
    {
      "index": 13,
      "title": "Learning character-level representations for part-of-speech tagging",
      "abstract": "",
      "year": "2014",
      "venue": "31st International Conference on Machine Learning (ICML-14)",
      "authors": "C. D. Santos and B. Zadrozny"
    },
    {
      "index": 14,
      "title": "Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1604.05529",
      "authors": "B. Plank, A. Søgaard, and Y. Goldberg",
      "orig_title": "Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss",
      "paper_id": "1604.05529v3"
    },
    {
      "index": 15,
      "title": "Part-of-speech tagging from 97% to 100%: is it time for some linguistics?",
      "abstract": "",
      "year": "2011",
      "venue": "International Conference on Intelligent Text Processing and Computational Linguistics",
      "authors": "C. D. Manning"
    },
    {
      "index": 16,
      "title": "Deep learning techniques for part of speech tagging by natural language processing",
      "abstract": "",
      "year": "2020",
      "venue": "2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA)",
      "authors": "R. D. Deshmukh and A. Kiwelekar"
    },
    {
      "index": 17,
      "title": "Neural Architectures for Named Entity Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1603.01360",
      "authors": "G. Lample, M. Ballesteros, S. Subramanian, K. Kawakami, and C. Dyer",
      "orig_title": "Neural architectures for named entity recognition",
      "paper_id": "1603.01360v3"
    },
    {
      "index": 18,
      "title": "Named entity recognition with bidirectional LSTM-CNNs",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:1511.08308",
      "authors": "J. P. Chiu and E. Nichols"
    },
    {
      "index": 19,
      "title": "A Survey on Recent Advances in Named Entity Recognition from Deep Learning models",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1910.11470",
      "authors": "V. Yadav and S. Bethard",
      "orig_title": "A survey on recent advances in named entity recognition from deep learning models",
      "paper_id": "1910.11470v1"
    },
    {
      "index": 20,
      "title": "A Survey on Deep Learning for Named Entity Recognition",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Knowledge and Data Engineering",
      "authors": "J. Li, A. Sun, J. Han, and C. Li",
      "orig_title": "A survey on deep learning for named entity recognition",
      "paper_id": "1812.09449v3"
    },
    {
      "index": 21,
      "title": "End-to-end learning of semantic role labeling using recurrent neural networks",
      "abstract": "",
      "year": "2015",
      "venue": "53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
      "authors": "J. Zhou and W. Xu"
    },
    {
      "index": 22,
      "title": "A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1701.02593",
      "authors": "D. Marcheggiani, A. Frolov, and I. Titov",
      "orig_title": "A simple and accurate syntax-agnostic neural model for dependency-based semantic role labeling",
      "paper_id": "1701.02593v2"
    },
    {
      "index": 23,
      "title": "Deep semantic role labeling: What works and what’s next",
      "abstract": "",
      "year": "2017",
      "venue": "55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
      "authors": "L. He, K. Lee, M. Lewis, and L. Zettlemoyer"
    },
    {
      "index": 24,
      "title": "Syntax-aware Multilingual Semantic Role Labeling",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1909.00310",
      "authors": "S. He, Z. Li, and H. Zhao",
      "orig_title": "Syntax-aware multilingual semantic role labeling",
      "paper_id": "1909.00310v3"
    },
    {
      "index": 25,
      "title": "Recent Trends in Deep Learning Based Natural Language Processing",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE Computational Intelligence Magazine",
      "authors": "T. Young, D. Hazarika, S. Poria, and E. Cambria",
      "orig_title": "Recent trends in deep learning based natural language processing",
      "paper_id": "1708.02709v8"
    },
    {
      "index": 26,
      "title": "Natural language processing (NLP) in management research: A literature review",
      "abstract": "",
      "year": "2020",
      "venue": "Journal of Management Analytics",
      "authors": "Y. Kang, Z. Cai, C.-W. Tan, Q. Huang, and H. Liu"
    },
    {
      "index": 27,
      "title": "What exactly is artificial intelligence, anyway?.",
      "abstract": "",
      "year": "2018",
      "venue": "Wall Street Journal Online Article",
      "authors": "T. Greenwald"
    },
    {
      "index": 28,
      "title": "Critical analysis of big data challenges and analytical methods",
      "abstract": "",
      "year": "2017",
      "venue": "Journal of Business Research",
      "authors": "U. Sivarajah, M. M. Kamal, Z. Irani, and V. Weerakkody"
    },
    {
      "index": 29,
      "title": "A Critical Review of Recurrent Neural Networks for Sequence Learning",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:1506.00019",
      "authors": "Z. C. Lipton, J. Berkowitz, and C. Elkan",
      "orig_title": "A critical review of recurrent neural networks for sequence learning",
      "paper_id": "1506.00019v4"
    },
    {
      "index": 30,
      "title": "Convolutional Neural Networks for Sentence Classification",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1408.5882",
      "authors": "Y. Kim",
      "orig_title": "Convolutional neural networks for sentence classification",
      "paper_id": "1408.5882v2"
    },
    {
      "index": 31,
      "title": "Parsing natural scenes and natural language with recursive neural networks",
      "abstract": "",
      "year": "2011",
      "venue": "28th international conference on machine learning (ICML-11)",
      "authors": "R. Socher, C. C. Lin, C. Manning, and A. Y. Ng"
    },
    {
      "index": 32,
      "title": "Imagenet classification with deep convolutional neural networks",
      "abstract": "",
      "year": "2012",
      "venue": "Advances in neural information processing systems",
      "authors": "A. Krizhevsky, I. Sutskever, and G. E. Hinton"
    },
    {
      "index": 33,
      "title": "Deep convolutional neural networks for sentiment analysis of short texts",
      "abstract": "",
      "year": "2014",
      "venue": "COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
      "authors": "C. dos Santos and M. Gatti"
    },
    {
      "index": 34,
      "title": "Effective use of word order for text categorization with convolutional neural networks",
      "abstract": "",
      "year": "2014",
      "venue": "arXiv preprint arXiv:1412.1058",
      "authors": "R. Johnson and T. Zhang"
    },
    {
      "index": 35,
      "title": "Semi-supervised Convolutional Neural Networks for Text Categorization via Region Embedding",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in neural information processing systems",
      "authors": "R. Johnson and T. Zhang",
      "orig_title": "Semi-supervised convolutional neural networks for text categorization via region embedding",
      "paper_id": "1504.01255v3"
    },
    {
      "index": 36,
      "title": "Relation classification via convolutional deep neural network",
      "abstract": "",
      "year": "2014",
      "venue": "COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
      "authors": "D. Zeng, K. Liu, S. Lai, G. Zhou, and J. Zhao"
    },
    {
      "index": 37,
      "title": "Relation extraction: Perspective from convolutional neural networks",
      "abstract": "",
      "year": "2015",
      "venue": "1st Workshop on Vector Space Modeling for Natural Language Processing",
      "authors": "T. H. Nguyen and R. Grishman"
    },
    {
      "index": 38,
      "title": "Recurrent neural network based language model",
      "abstract": "",
      "year": "2010",
      "venue": "Eleventh Annual Conference of the International Speech Communication Association",
      "authors": "T. Mikolov, M. Karafiát, L. Burget, J. Černockỳ, and S. Khudanpur"
    },
    {
      "index": 39,
      "title": "Long short-term memory",
      "abstract": "",
      "year": "1997",
      "venue": "Neural computation",
      "authors": "S. Hochreiter and J. Schmidhuber"
    },
    {
      "index": 40,
      "title": "Generative adversarial nets",
      "abstract": "",
      "year": "2014",
      "venue": "Advances in neural information processing systems",
      "authors": "I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio"
    },
    {
      "index": 41,
      "title": "Wasserstein t-SNE",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1701.07875",
      "authors": "M. Arjovsky, S. Chintala, and L. Bottou",
      "orig_title": "Wasserstein gan",
      "paper_id": "2205.07531v2"
    },
    {
      "index": 42,
      "title": "Infogan: Interpretable representation learning by information maximizing generative adversarial nets",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in neural information processing systems",
      "authors": "X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel"
    },
    {
      "index": 43,
      "title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:1511.06434",
      "authors": "A. Radford, L. Metz, and S. Chintala",
      "orig_title": "Unsupervised representation learning with deep convolutional generative adversarial networks",
      "paper_id": "1511.06434v2"
    },
    {
      "index": 44,
      "title": "Progressive Growing of GANs for Improved Quality, Stability, and Variation",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1710.10196",
      "authors": "T. Karras, T. Aila, S. Laine, and J. Lehtinen",
      "orig_title": "Progressive growing of GANs for improved quality, stability, and variation",
      "paper_id": "1710.10196v3"
    },
    {
      "index": 45,
      "title": "GRAPPA-GANs for Parallel MRI Reconstruction",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2101.03135",
      "authors": "N. Tavaf, A. Torfi, K. Ugurbil, and P.-F. Van de Moortele",
      "orig_title": "GRAPPA-GANs for Parallel MRI Reconstruction",
      "paper_id": "2101.03135v2"
    },
    {
      "index": 46,
      "title": "Seqgan: Sequence generative adversarial nets with policy gradient",
      "abstract": "",
      "year": "2017",
      "venue": "Thirty-First AAAI Conference on Artificial Intelligence",
      "authors": "L. Yu, W. Zhang, J. Wang, and Y. Yu"
    },
    {
      "index": 47,
      "title": "Adversarial Learning for Neural Dialogue Generation",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1701.06547",
      "authors": "J. Li, W. Monroe, T. Shi, S. Jean, A. Ritter, and D. Jurafsky",
      "orig_title": "Adversarial learning for neural dialogue generation",
      "paper_id": "1701.06547v5"
    },
    {
      "index": 48,
      "title": "Thumbs up?: sentiment classification using machine learning techniques",
      "abstract": "",
      "year": "2002",
      "venue": "ACL-02 conference on Empirical methods in natural language processing-Volume 10",
      "authors": "B. Pang, L. Lee, and S. Vaithyanathan"
    },
    {
      "index": 49,
      "title": "Distributional structure",
      "abstract": "",
      "year": "1954",
      "venue": "Word",
      "authors": "Z. S. Harris"
    },
    {
      "index": 50,
      "title": "“A neural probabilistic language model",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": ""
    },
    {
      "index": 51,
      "title": "Distributed Representations of Sentences and Documents",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "",
      "orig_title": "“Distributed representations of sentences and documents",
      "paper_id": "1405.4053v2"
    },
    {
      "index": 52,
      "title": "“Distributed representations of words and phrases and their compositionality",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 53,
      "title": "Skip-Thought Vectors",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Skip-thought vectors",
      "paper_id": "1506.06726v1"
    },
    {
      "index": 54,
      "title": "“Efficient estimation of word representations in vector space",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 55,
      "title": "LAP LAMBERT Academic Publishing, 2015",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "G. Lebanon et al., Riemannian geometry and statistical machine\nlearning."
    },
    {
      "index": 56,
      "title": "Cambridge University Press, 2014",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "J. Leskovec, A. Rajaraman, and J. D. Ullman, Mining of massive datasets."
    },
    {
      "index": 57,
      "title": "“Neural network methods for natural language processing",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 58,
      "title": "“A character-based convolutional neural network for language-agnostic Twitter sentiment analysis",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 59,
      "title": "Enriching Word Vectors with Subword Information",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Enriching word vectors with subword information",
      "paper_id": "1607.04606v2"
    },
    {
      "index": 60,
      "title": "Compositional Morphology for Word Representations and Language Modelling",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "",
      "orig_title": "“Compositional morphology for word representations and language modelling",
      "paper_id": "1405.4273v1"
    },
    {
      "index": 61,
      "title": "Get To The Point: Summarization with Pointer-Generator Networks",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Get to the point: Summarization with pointer-generator networks",
      "paper_id": "1704.04368v2"
    },
    {
      "index": 62,
      "title": "A Deep Reinforced Model for Abstractive Summarization",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“A deep reinforced model for abstractive summarization",
      "paper_id": "1705.04304v3"
    },
    {
      "index": 63,
      "title": "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Scheduled sampling for sequence prediction with recurrent neural networks",
      "paper_id": "1506.03099v3"
    },
    {
      "index": 64,
      "title": "A Continuous Relaxation of Beam Search for End-to-end Training of Neural Sequence Models",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“A continuous relaxation of beam search for end-to-end training of neural sequence models",
      "paper_id": "1708.00111v2"
    },
    {
      "index": 65,
      "title": "Stochastic Beams and Where to Find Them: The Gumbel-Top-𝑘 Trick for Sampling Sequences Without Replacement",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Stochastic beams and where to find them: The gumbel-top-k trick for sampling sequences without replacement",
      "paper_id": "1903.06059v2"
    },
    {
      "index": 66,
      "title": "“Rouge: A package for automatic evaluation of summaries",
      "abstract": "",
      "year": "2004",
      "venue": "",
      "authors": ""
    },
    {
      "index": 67,
      "title": "“BLEU: a method for automatic evaluation of machine translation",
      "abstract": "",
      "year": "2002",
      "venue": "",
      "authors": ""
    },
    {
      "index": 68,
      "title": "“METEOR: An automatic metric for MT evaluation with improved correlation with human judgments",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 69,
      "title": "“Deep reinforcement learning for sequence to sequence models",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 70,
      "title": "Sequence Level Training with Recurrent Neural Networks",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Sequence level training with recurrent neural networks",
      "paper_id": "1511.06732v7"
    },
    {
      "index": 71,
      "title": "“Reinforcement learning neural Turing machines-revised",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 72,
      "title": "“Simple statistical gradient-following algorithms for connectionist reinforcement learning",
      "abstract": "",
      "year": "1992",
      "venue": "",
      "authors": ""
    },
    {
      "index": 73,
      "title": "Reinforcement learning: An introduction",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction."
    },
    {
      "index": 74,
      "title": "” Machine Learning",
      "abstract": "",
      "year": "1992",
      "venue": "",
      "authors": ""
    },
    {
      "index": 75,
      "title": "“Search-based structured prediction",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": ""
    },
    {
      "index": 76,
      "title": "End-to-End Training of Deep Visuomotor Policies",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“End-to-end training of deep visuomotor policies",
      "paper_id": "1504.00702v5"
    },
    {
      "index": 77,
      "title": "“Recurrent models of visual attention",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 78,
      "title": "Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Utilizing BERT for aspect-based sentiment analysis via constructing auxiliary sentence",
      "paper_id": "1903.09588v1"
    },
    {
      "index": 79,
      "title": "“Evaluation of NLP systems",
      "abstract": "",
      "year": "2010",
      "venue": "",
      "authors": ""
    },
    {
      "index": 80,
      "title": "“Ask me anything: Dynamic memory networks for natural language processing",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 81,
      "title": "Bidirectional LSTM-CRF Models for Sequence Tagging",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Bidirectional LSTM-CRF models for sequence tagging",
      "paper_id": "1508.01991v1"
    },
    {
      "index": 82,
      "title": "Globally Normalized Transition-Based Neural Networks",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Globally normalized transition-based neural networks",
      "paper_id": "1603.06042v2"
    },
    {
      "index": 83,
      "title": "“Part-of-speech tagging of building codes empowered by deep learning and transformational rules",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": ""
    },
    {
      "index": 84,
      "title": "Empower Sequence Labeling with Task-Aware Neural Language Model",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Empower sequence labeling with task-aware neural language model",
      "paper_id": "1709.04109v4"
    },
    {
      "index": 85,
      "title": "R. Salakhutdinov",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 86,
      "title": "End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF",
      "paper_id": "1603.01354v5"
    },
    {
      "index": 87,
      "title": "“Robust multilingual part-of-speech tagging via adversarial training",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 88,
      "title": "“Finding function in form: Compositional character models for open vocabulary word representation",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 89,
      "title": "“Contextual string embeddings for sequence labeling",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 90,
      "title": "Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Morphosyntactic tagging with a Meta-BiLSTM model over context sensitive token encodings",
      "paper_id": "1805.08237v1"
    },
    {
      "index": 91,
      "title": "“Joint RNN-based greedy parsing and word composition",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 92,
      "title": "“Deep neural networks for syntactic parsing of morphologically rich languages",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 93,
      "title": "“What do recurrent neural network grammars learn about syntax?",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 94,
      "title": "“In-order transition-based constituent parsing",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 95,
      "title": "“Improving neural parsing by disentangling model combination and reranking effects",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 96,
      "title": "Constituency Parsing with a Self-Attentive Encoder",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Constituency parsing with a self-attentive encoder",
      "paper_id": "1805.01052v1"
    },
    {
      "index": 97,
      "title": "“A fast and accurate dependency parser using neural networks",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 98,
      "title": "Deep Biaffine Attention for Neural Dependency Parsing",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Deep biaffine attention for neural dependency parsing",
      "paper_id": "1611.01734v3"
    },
    {
      "index": 99,
      "title": "Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Simple and accurate dependency parsing using bidirectional LSTM feature representations",
      "paper_id": "1603.04351v3"
    },
    {
      "index": 100,
      "title": "Transition-Based Dependency Parsing with Stack Long Short-Term Memory",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Transition-based dependency parsing with stack long short-term memory",
      "paper_id": "1505.08075v1"
    },
    {
      "index": 101,
      "title": "“Deep learning for natural language parsing",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 102,
      "title": "“Parsing clinical text using the state-of-the-art deep learning based parsers: a systematic comparison",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 103,
      "title": "Efficient Second-Order TreeCRF for Neural Dependency Parsing",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Efficient second-order treecrf for neural dependency parsing",
      "paper_id": "2005.00975v2"
    },
    {
      "index": 104,
      "title": "Deep Biaffine Attention for Neural Dependency Parsing",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Deep biaffine attention for neural dependency parsing",
      "paper_id": "1611.01734v3"
    },
    {
      "index": 105,
      "title": "“Deep semantic role labeling with self-attention",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 106,
      "title": "Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Encoding sentences with graph convolutional networks for semantic role labeling",
      "paper_id": "1703.04826v4"
    },
    {
      "index": 107,
      "title": "Linguistically-Informed Self-Attention for Semantic Role Labeling",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Linguistically-informed self-attention for semantic role labeling",
      "paper_id": "1804.08199v3"
    },
    {
      "index": 108,
      "title": "Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Jointly predicting predicates and arguments in neural semantic role labeling",
      "paper_id": "1805.04787v2"
    },
    {
      "index": 109,
      "title": "Deep contextualized word representations",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Deep contextualized word representations",
      "paper_id": "1802.05365v2"
    },
    {
      "index": 110,
      "title": "“Deep semantic role labeling with self-attention",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 111,
      "title": "“Dependency or span",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 112,
      "title": "“Towards robust linguistic analysis using OntoNotes",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 113,
      "title": "“A convolutional neural network for modelling sentences",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 114,
      "title": "“Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 115,
      "title": "“Hierarchical attention networks for document classification",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 116,
      "title": "“Recurrent convolutional neural networks for text classification",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 117,
      "title": "A C-LSTM Neural Network for Text Classification",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“A C-LSTM neural network for text classification",
      "paper_id": "1511.08630v2"
    },
    {
      "index": 118,
      "title": "Deep Learning Based Text Classification: A Comprehensive Review",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Deep learning based text classification: A comprehensive review",
      "paper_id": "2004.03705v3"
    },
    {
      "index": 119,
      "title": "“A comparative review on deep learning models for text classification",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 120,
      "title": "Very Deep Convolutional Networks for Text Classification",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Very deep convolutional networks for text classification",
      "paper_id": "1606.01781v2"
    },
    {
      "index": 121,
      "title": "“Deep pyramid convolutional neural networks for text categorization",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 122,
      "title": "Supervised and Semi-Supervised Text Categorization using LSTM for Region Embeddings",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Supervised and semi-supervised text categorization using LSTM for region embeddings",
      "paper_id": "1602.02373v2"
    },
    {
      "index": 123,
      "title": "Universal Language Model Fine-tuning for Text Classification",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Universal language model fine-tuning for text classification",
      "paper_id": "1801.06146v5"
    },
    {
      "index": 124,
      "title": "“Natural language processing (almost) from scratch",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 125,
      "title": "“Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 126,
      "title": "NeuroNER: an easy-to-use program for named-entity recognition based on neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“NeuroNER: an easy-to-use program for named-entity recognition based on neural networks",
      "paper_id": "1705.05487v1"
    },
    {
      "index": 127,
      "title": "Cloze-driven Pretraining of Self-attention Networks",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Cloze-driven pretraining of self-attention networks",
      "paper_id": "1903.07785v1"
    },
    {
      "index": 128,
      "title": "“Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": ""
    },
    {
      "index": 129,
      "title": "Semi-Supervised Sequence Modeling with Cross-View Training",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Semi-supervised sequence modeling with cross-view training",
      "paper_id": "1809.08370v1"
    },
    {
      "index": 130,
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“BERT: Pre-training of deep bidirectional transformers for language understanding",
      "paper_id": "1810.04805v2"
    },
    {
      "index": 131,
      "title": "“Semantic compositionality through recursive matrix-vector spaces",
      "abstract": "",
      "year": "2012",
      "venue": "",
      "authors": ""
    },
    {
      "index": 132,
      "title": "“Semantic relation extraction using sequential and tree-structured lstm with attention",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 133,
      "title": "more context and more openness: A review and outlook for relation extraction",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 134,
      "title": "“Deep reinforcement learning for mention-ranking coreference models",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 135,
      "title": "“Higher-order coreference resolution with coarse-to-fine inference",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 136,
      "title": "“End-to-end deep reinforcement learning based coreference resolution",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 137,
      "title": "CorefQA: Coreference Resolution as Query-based Span Prediction",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Corefqa: Coreference resolution as query-based span prediction",
      "paper_id": "1911.01746v4"
    },
    {
      "index": 138,
      "title": "“Event extraction via dynamic multi-pooling convolutional neural networks",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 139,
      "title": "“Graph convolutional networks with argument-aware pooling for event detection",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 140,
      "title": "“Joint entity and event extraction with generative adversarial imitation learning",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 141,
      "title": "“A novel joint biomedical event extraction framework via two-level modeling of documents",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": ""
    },
    {
      "index": 142,
      "title": "“Sentiment analysis: Capturing favorability using natural language processing",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": ""
    },
    {
      "index": 143,
      "title": "“Mining the peanut gallery: Opinion extraction and semantic classification of product reviews",
      "abstract": "",
      "year": "2003",
      "venue": "",
      "authors": ""
    },
    {
      "index": 144,
      "title": "“Application of deep learning approaches for sentiment analysis",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 145,
      "title": "“Sentiment analysis using deep learning architectures: a review",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 146,
      "title": "“Document modeling with gated recurrent neural network for sentiment classification",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 147,
      "title": "“Domain adaptation for large-scale sentiment classification: A deep learning approach",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 148,
      "title": "“Lstm with sentence representations for document-level sentiment classification",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 149,
      "title": "“A cnn-bilstm model for document-level sentiment analysis",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 150,
      "title": "“Semi-supervised recursive autoencoders for predicting sentiment distributions",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 151,
      "title": "“Predicting polarities of tweets by composing word embeddings with long short-term memory",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 152,
      "title": "“Recursive deep models for semantic compositionality over a sentiment treebank",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 153,
      "title": "“Classification of sentence level sentiment analysis using cloud machine learning techniques",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 154,
      "title": "” Information Processing & Management",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 155,
      "title": "“Attention-based LSTM for aspect-level sentiment classification",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 156,
      "title": "“Sentic lstm: a hybrid network for targeted aspect-based sentiment analysis",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 157,
      "title": "BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“BERT post-training for review reading comprehension and aspect-based sentiment analysis",
      "paper_id": "1904.02232v2"
    },
    {
      "index": 158,
      "title": "Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Double embeddings and CNN-based sequence labeling for aspect extraction",
      "paper_id": "1805.04601v1"
    },
    {
      "index": 159,
      "title": "“Deep learning for aspect-based sentiment analysis: a comparative review",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 160,
      "title": "“A multi-layer dual attention deep learning model with refined word embeddings for aspect-based sentiment analysis",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 161,
      "title": "“A novel aspect-guided deep transition model for aspect based sentiment analysis",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 162,
      "title": "Prentice Hall, 2008",
      "abstract": "",
      "year": "2008",
      "venue": "",
      "authors": "D. Jurafsky and J. H. Martin, Speech and Language Processing."
    },
    {
      "index": 163,
      "title": "“Recurrent continuous translation models",
      "abstract": "",
      "year": "2013",
      "venue": "",
      "authors": ""
    },
    {
      "index": 164,
      "title": "“Machine translation using deep learning: An overview",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 165,
      "title": "“A survey of deep learning techniques for neural machine translation",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 166,
      "title": "“The Georgetown-IBM experiment",
      "abstract": "",
      "year": "1955",
      "venue": "",
      "authors": ""
    },
    {
      "index": 167,
      "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": "",
      "orig_title": "“Neural machine translation by jointly learning to align and translate",
      "paper_id": "1409.0473v7"
    },
    {
      "index": 168,
      "title": "B. Van Merriënboer",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 169,
      "title": "“Sequence to sequence learning with neural networks",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 170,
      "title": "Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Google’s neural machine translation system: Bridging the gap between human and machine translation",
      "paper_id": "1609.08144v2"
    },
    {
      "index": 171,
      "title": "“Convolutional sequence to sequence learning",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 172,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 173,
      "title": "Weighted Transformer Network for Machine Translation",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Weighted transformer network for machine translation",
      "paper_id": "1711.02132v1"
    },
    {
      "index": 174,
      "title": "Self-Attention with Relative Position Representations",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Self-attention with relative position representations",
      "paper_id": "1803.02155v2"
    },
    {
      "index": 175,
      "title": "Understanding Back-Translation at Scale",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Understanding back-translation at scale",
      "paper_id": "1808.09381v2"
    },
    {
      "index": 176,
      "title": "Massively Multilingual Neural Machine Translation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Massively multilingual neural machine translation",
      "paper_id": "1903.00089v3"
    },
    {
      "index": 177,
      "title": "Incorporating BERT into Neural Machine Translation",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Incorporating bert into neural machine translation",
      "paper_id": "2002.06823v1"
    },
    {
      "index": 178,
      "title": "M. Ghazvininejad",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 179,
      "title": "Robust Neural Machine Translation with Doubly Adversarial Inputs",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Robust neural machine translation with doubly adversarial inputs",
      "paper_id": "1906.02443v1"
    },
    {
      "index": 180,
      "title": "Bridging the Gap between Training and Inference for Neural Machine Translation",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Bridging the gap between training and inference for neural machine translation",
      "paper_id": "1906.02448v2"
    },
    {
      "index": 181,
      "title": "Towards Making the Most of BERT in Neural Machine Translation",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": "",
      "orig_title": "“Towards making the most of bert in neural machine translation",
      "paper_id": "1908.05672v5"
    },
    {
      "index": 182,
      "title": "“Question answering with subgraph embeddings",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 183,
      "title": "“Baseball: an automatic question-answerer",
      "abstract": "",
      "year": "1961",
      "venue": "",
      "authors": ""
    },
    {
      "index": 184,
      "title": "“IBM’s statistical question answering system",
      "abstract": "",
      "year": "2000",
      "venue": "",
      "authors": ""
    },
    {
      "index": 185,
      "title": "“Question answering passage retrieval using dependency relations",
      "abstract": "",
      "year": "2005",
      "venue": "",
      "authors": ""
    },
    {
      "index": 186,
      "title": "“Convolutional neural tensor network architecture for community-based question answering",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 187,
      "title": "“A machine learning approach to answering questions for reading comprehension tests",
      "abstract": "",
      "year": "2000",
      "venue": "",
      "authors": ""
    },
    {
      "index": 188,
      "title": "Dynamic Coattention Networks for Question Answering",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Dynamic coattention networks for question answering",
      "paper_id": "1611.01604v4"
    },
    {
      "index": 189,
      "title": "C. Lawrence Zitnick",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 190,
      "title": "Ask Your Neurons: A Neural-based Approach to Answering Questions about Images",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“Ask your neurons: A neural-based approach to answering questions about images",
      "paper_id": "1505.01121v3"
    },
    {
      "index": 191,
      "title": "attend and answer: Exploring question-guided spatial attention for visual question answering",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 192,
      "title": "Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Human attention in visual question answering: Do humans and deep networks look at the same regions?",
      "paper_id": "1606.03556v2"
    },
    {
      "index": 193,
      "title": "BLOCK: Bilinear Superdiagonal Fusion for Visual Question Answering and Visual Relationship Detection",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "",
      "orig_title": "“Block: Bilinear superdiagonal fusion for visual question answering and visual relationship detection",
      "paper_id": "1902.00038v2"
    },
    {
      "index": 194,
      "title": "“Self-critical reasoning for robust visual question answering",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 195,
      "title": "SummaRuNNer: A Recurrent Neural Network based Sequence Model for Extractive Summarization of Documents",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“SummaRuNNer: A recurrent neural network based sequence model for extractive summarization of documents",
      "paper_id": "1611.04230v1"
    },
    {
      "index": 196,
      "title": "Ranking Sentences for Extractive Summarization with Reinforcement Learning",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Ranking sentences for extractive summarization with reinforcement learning",
      "paper_id": "1802.08636v2"
    },
    {
      "index": 197,
      "title": "“A neural attention model for abstractive sentence summarization",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 198,
      "title": "“Abstractive document summarization with a graph-based attentional neural model",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": ""
    },
    {
      "index": 199,
      "title": "“Abstractive text summarization using sequence-to-sequence RNNs and beyond",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 200,
      "title": "“Teaching machines to read and comprehend",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 201,
      "title": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Incorporating copying mechanism in sequence-to-sequence learning",
      "paper_id": "1603.06393v3"
    },
    {
      "index": 202,
      "title": "Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Fast abstractive summarization with reinforce-selected sentence rewriting",
      "paper_id": "1805.11080v1"
    },
    {
      "index": 203,
      "title": "Neural Document Summarization by Jointly Learning to Score and Select Sentences",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Neural document summarization by jointly learning to score and select sentences",
      "paper_id": "1807.02305v1"
    },
    {
      "index": 204,
      "title": "Neural Abstractive Text Summarization with Sequence-to-Sequence Models",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Neural abstractive text summarization with sequence-to-sequence models",
      "paper_id": "1812.02303v4"
    },
    {
      "index": 205,
      "title": "“Multi-document summarization via deep learning techniques: A survey",
      "abstract": "",
      "year": "2020",
      "venue": "",
      "authors": ""
    },
    {
      "index": 206,
      "title": "“A hybrid deep learning architecture for opinion-oriented multi-document summarization based on multi-feature fusion",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": ""
    },
    {
      "index": 207,
      "title": "“Hibert: Document level pre-training of hierarchical bidirectional transformers for document summarization",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 208,
      "title": "“Dialogue systems for intelligent human computer interactions",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": ""
    },
    {
      "index": 209,
      "title": "“Multi-domain joint semantic frame parsing using bi-directional RNN-LSTM",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 210,
      "title": "Understanding Chatbot-mediated Task Management",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Understanding chatbot-mediated task management",
      "paper_id": "1802.03109v1"
    },
    {
      "index": 211,
      "title": "Goal-Oriented Chatbot Dialog Management Bootstrapping with Transfer Learning",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": "",
      "orig_title": "“Goal-oriented chatbot dialog management bootstrapping with transfer learning",
      "paper_id": "1802.00500v2"
    },
    {
      "index": 212,
      "title": "“Deep reinforcement learning for dialogue generation",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 213,
      "title": "A Network-based End-to-End Trainable Task-oriented Dialogue System",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“A network-based end-to-end trainable task-oriented dialogue system",
      "paper_id": "1604.04562v3"
    },
    {
      "index": 214,
      "title": "“End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 215,
      "title": "“End-to-end memory networks",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 216,
      "title": "Learning End-to-End Goal-Oriented Dialog",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": "",
      "orig_title": "“Learning end-to-end goal-oriented dialog",
      "paper_id": "1605.07683v4"
    },
    {
      "index": 217,
      "title": "“Data-driven response generation in social media",
      "abstract": "",
      "year": "2011",
      "venue": "",
      "authors": ""
    },
    {
      "index": 218,
      "title": "“An information retrieval approach to short text conversation",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 219,
      "title": "“Convolutional neural network architectures for matching natural language sentences",
      "abstract": "",
      "year": "2014",
      "venue": "",
      "authors": ""
    },
    {
      "index": 220,
      "title": "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“The Ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems",
      "paper_id": "1506.08909v3"
    },
    {
      "index": 221,
      "title": "“Learning to respond with deep neural networks for retrieval-based human-computer conversation system",
      "abstract": "",
      "year": "2016",
      "venue": "",
      "authors": ""
    },
    {
      "index": 222,
      "title": "“Multi-turn response selection for chatbots with deep attention matching network",
      "abstract": "",
      "year": "2018",
      "venue": "",
      "authors": ""
    },
    {
      "index": 223,
      "title": "“Generating sentences from a continuous space",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 224,
      "title": "Adversarial Evaluation of Dialogue Models",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "",
      "orig_title": "“Adversarial evaluation of dialogue models",
      "paper_id": "1701.08198v1"
    },
    {
      "index": 225,
      "title": "A Neural Conversational Model",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "",
      "orig_title": "“A neural conversational model",
      "paper_id": "1506.05869v3"
    }
  ]
}