{
  "paper_id": "2308.02182v3",
  "title": "AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification",
  "sections": {
    "ii-a neural architecture search": "NAS  leverages a controller Recurrent Neural Network (RNN) to generate\nneural network architectures.\nFigure 1 shows an architecture generated by NAS that consists of convolutional layers only, where a layer in the Convolutional Neural Network (CNN) is described by a sequence of tokens. Each token determines a separate characteristic of the convolutional layer, such as filter size and stride. The different compositions and permutations of the sequences determine the model architectures that can be generated, which represents the search space. In NAS, a controller RNN is trained using Reinforcement Learning (RL),\nwhere the actions are the choice of tokens while the reward signal is the validation accuracy of the model, i.e., the sequence of tokens. RL consists of a series of trials, where a child model is created by sampling the parameter values generated by the RNN at the end of each trial. As shown in Figure 2, a sampled model is trained and evaluated on a dataset per trial to compute the reward, which makes NAS computationally expensive. The RL algorithm described above operates within a space of possible sequences. This space is decided by the set of possible tokens that the controller RNN can generate at each time step. It is up to the domain expert to determine the set of possible tokens for RNN, which is similar to the set of words in the dictionary of a language generator. Researchers in  proposed two different search spaces for creating both CNNs and RNNs. The authors increased the complexity of the convolutional models by introducing anchor points (cf. Figure 1) into the search space, which determines the probability of having skip connections between a layer and its previous layers. This allowed the architecture to contain branching or skip connections similar to the ones in ResNet . Their results showed that the generated CNN models perform within an error rate of 1% from the state-of-the-art image classifiers on the CIFAR-10 dataset [ref]17. The high performance is attributed to training 12,800 architectures using 800 GPUs for concurrent training, which makes their approach very resource-intensive. Authors in  enhanced the set of tokens, i.e., architecture building blocks that the RNN generates in . Their enhancement is based on the observation that state-of-the-art image classifier architectures have repeated network motifs, i.e., small building blocks in the architecture’s graph that are replicated. Their proposed search space consists of a sequence of Normal and Reduction cells, in which only the Reduction cells reduce the size of the feature map. Between different architectures in the search space there is variation in the interior structure of the Normal and Reduction cells. Each cell is made up of a constant number of network motifs, where each motif consists of two inputs fed into two blocks that are aggregated. The types of blocks (e.g., separable convolution, identity, 1x1 convolution) and the aggregation function (e.g., add, concatenate) are determined by the controller RNN along with the connections between the motifs. Their method performed slightly better than the best recorded performance on CIFAR-10, with the added benefit of being transferable to the larger ImageNet dataset [ref]19 despite the computational complexity of NAS. The authors leveraged a transfer learning approach to speed up child model training and promote transferability. Both previous approaches suffer from high computational complexity. To address this problem,  improved NAS’s time complexity by a factor of 1000 and achieved an error rate of within 0.3% of NAS. To make this happen, the authors employed parameter sharing among all child models, which is inspired by transfer learning  and multi-task learning . The authors named their approach Efficient Neural Architecture Search (ENAS). ENAS uses a more restrictive search space, where only the child models that can be represented by a directed acyclic graph are considered. Moreover, their micro search space is without non-separable convolutional blocks. The results of the micro search space are then compared to those of the search space in NAS. Our proposed novel search space is inspired by the search space in ENAS. The choice of the search algorithm has also been explored in NAS, where some works leveraged RL while others resorted to Evolutionary Algorithms (EAs). Outside the realm of NAS,  proposed Monte Carlo Tree Search (MCTS) that extended the well-known Multi-armed Bandit technique in RL to tree-structured search spaces. This inspired an interesting approach in  that improved the controller by using MCTS to find the best architecture hyper-parameters. Using MCTS with Upper Confidence bound applied to Trees (UCT)\nis known to balance exploitation and exploration in the searching process and overcome possible sub-optimal solutions.\nThe main idea is to use MCTS to find the model’s hyper-parameters in a layer-by-layer fashion in the child model descriptions. Selection, Expansion, Playout with simulation, and Backpropagation are the main steps of MCTS. To reliably estimate the search directions in MCTS, the child models are trained multiple times. The authors suggested using simulation to estimate the child model’s accuracy, such that the child model is trained only once on the dataset, as opposed to multiple times, which saves on training time. The model’s accuracy is then estimated by aggregating the training and simulation results. EAs are an alternate to RL for searching the neural architecture search space [ref]24 . Authors in [ref]24 evolved an initial population of strings representing neural architectures by using a tournament selection algorithm, where after each pairwise comparison the worse individual dies and the better one mutates. The fitness of each string is determined by the respective architecture’s validation accuracy after being trained on a dataset. Similar to , researchers in  used an EA to search the NASNet search space. The authors used a tournament selection algorithm similar to [ref]24 and introduced the concept of aging to individuals. Comparing their algorithm to the RL baseline, they showed that their EA achieves a higher accuracy faster than the RL-based method, however, both methods converged to the same accuracy asymptote. The authors argued that the EA-based method is more relevant in larger search spaces where reaching the optimal solution may be resource intensive. We compare the EA algorithm in  to other search algorithms over our search space in Section IV."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Mobile encrypted traffic classification using deep learning: Experimental evaluation, lessons learned, and challenges",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Network and Service Management",
      "authors": "G. Aceto, D. Ciuonzo, A. Montieri, and A. Pescapé"
    },
    {
      "index": 1,
      "title": "Deep packet: A novel approach for encrypted traffic classification using deep learning",
      "abstract": "",
      "year": "2020",
      "venue": "Soft Computing",
      "authors": "M. Lotfollahi, M. Jafari Siavoshani, R. Shirali Hossein Zade, and M. Saberian"
    },
    {
      "index": 2,
      "title": "Fs-net: A flow sequence network for encrypted traffic classification",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Conference On Computer Communications (INFOCOM)",
      "authors": "C. Liu, L. He, G. Xiong, Z. Cao, and Z. Li"
    },
    {
      "index": 3,
      "title": "Seq2img: A sequence-to-image based approach towards ip traffic classification using convolutional neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE International conference on big data (big data)",
      "authors": "Z. Chen, K. He, J. Li, and Y. Geng"
    },
    {
      "index": 4,
      "title": "Traffic classification in an increasingly encrypted web",
      "abstract": "",
      "year": "2022",
      "venue": "Commun. ACM",
      "authors": "I. Akbari, M. A. Salahuddin, L. Ven, N. Limam, R. Boutaba, B. Mathieu, S. Moteau, and S. Tuffin"
    },
    {
      "index": 5,
      "title": "Deep inside tor: Exploring website fingerprinting attacks on tor traffic in realistic settings",
      "abstract": "",
      "year": "2022",
      "venue": "International Conf. on Computer and Knowledge Engineering",
      "authors": "A. Khajehpour, F. Zandi et al."
    },
    {
      "index": 6,
      "title": "Fstc: Dynamic category adaptation for encrypted network traffic classification",
      "abstract": "",
      "year": "2023",
      "venue": "2023 IFIP Networking Conference (IFIP Networking)",
      "authors": "N. Malekghaini, H. Tsang, M. A. Salahuddin, N. Limam, and R. Boutaba"
    },
    {
      "index": 7,
      "title": "A look behind the curtain: traffic classification in an increasingly encrypted web",
      "abstract": "",
      "year": "2021",
      "venue": "ACM on Measurement and Analysis of Computing Systems",
      "authors": "I. Akbari, M. A. Salahuddin, L. Ven, N. Limam, R. Boutaba, B. Mathieu, S. Moteau, and S. Tuffin"
    },
    {
      "index": 8,
      "title": "Data drift in dl: Lessons learned from encrypted traffic classification",
      "abstract": "",
      "year": "2022",
      "venue": "IFIP Networking Conference (IFIP Networking)",
      "authors": "N. Malekghaini, E. Akbari, M. A. Salahuddin, N. Limam, R. Boutaba, B. Mathieu, S. Moteau, and S. Tuffin"
    },
    {
      "index": 9,
      "title": "Deep learning for encrypted traffic classification in the face of data drift: An empirical study",
      "abstract": "",
      "year": "2023",
      "venue": "Computer Networks",
      "authors": "N. Malekghaini, E. Akbari et al."
    },
    {
      "index": 10,
      "title": "Metalearning",
      "abstract": "",
      "year": "2010",
      "venue": "Scholarpedia",
      "authors": "T. Schaul and J. Schmidhuber"
    },
    {
      "index": 11,
      "title": "Learning to learn using gradient descent",
      "abstract": "",
      "year": "2001",
      "venue": "International conference on artificial neural networks",
      "authors": "S. Hochreiter, A. S. Younger, and P. R. Conwell"
    },
    {
      "index": 12,
      "title": "Neural Architecture Search: A Survey",
      "abstract": "",
      "year": "2019",
      "venue": "The Journal of Machine Learning Research",
      "authors": "T. Elsken, J. H. Metzen, and F. Hutter",
      "orig_title": "Neural architecture search: A survey",
      "paper_id": "1808.05377v3"
    },
    {
      "index": 13,
      "title": "Neural Architecture Search with Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings",
      "authors": "B. Zoph and Q. V. Le",
      "orig_title": "Neural architecture search with reinforcement learning",
      "paper_id": "1611.01578v2"
    },
    {
      "index": 14,
      "title": "Efficient and robust automated machine learning",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "M. Feurer, A. Klein, K. Eggensperger, J. Springenberg, M. Blum, and F. Hutter"
    },
    {
      "index": 15,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "K. He, X. Zhang, S. Ren, and J. Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 16,
      "title": "Learning multiple layers of features from tiny images",
      "abstract": "",
      "year": "2009",
      "venue": "",
      "authors": "A. Krizhevsky, G. Hinton et al."
    },
    {
      "index": 17,
      "title": "Learning Transferable Architectures for Scalable Image Recognition",
      "abstract": "",
      "year": "2018",
      "venue": "IEEE conference on computer vision and pattern recognition",
      "authors": "B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le",
      "orig_title": "Learning transferable architectures for scalable image recognition",
      "paper_id": "1707.07012v4"
    },
    {
      "index": 18,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
      "authors": "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei"
    },
    {
      "index": 19,
      "title": "Efficient Neural Architecture Search via Parameter Sharing",
      "abstract": "",
      "year": "2018",
      "venue": "International conference on machine learning",
      "authors": "H. Pham, M. Guan, B. Zoph, Q. Le, and J. Dean",
      "orig_title": "Efficient neural architecture search via parameters sharing",
      "paper_id": "1802.03268v2"
    },
    {
      "index": 20,
      "title": "An overview of multi-task learning in deep neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "",
      "authors": "S. Ruder"
    },
    {
      "index": 21,
      "title": "Bandit based monte-carlo planning",
      "abstract": "",
      "year": "2006",
      "venue": "European conference on machine learning",
      "authors": "L. Kocsis and C. Szepesvári"
    },
    {
      "index": 22,
      "title": "Neural Architecture Search using Deep Neural Networks and Monte Carlo Tree Search",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "L. Wang, Y. Zhao, Y. Jinnai, Y. Tian, and R. Fonseca",
      "orig_title": "Neural architecture search using deep neural networks and monte carlo tree search",
      "paper_id": "1805.07440v5"
    },
    {
      "index": 23,
      "title": "Large-Scale Evolution of Image Classifiers",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Machine Learning",
      "authors": "E. Real, S. Moore, A. Selle, S. Saxena, Y. L. Suematsu, J. Tan, Q. V. Le, and A. Kurakin",
      "orig_title": "Large-scale evolution of image classifiers",
      "paper_id": "1703.01041v2"
    },
    {
      "index": 24,
      "title": "Regularized Evolution for Image Classifier Architecture Search",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI conference on artificial intelligence",
      "authors": "E. Real, A. Aggarwal, Y. Huang, and Q. V. Le",
      "orig_title": "Regularized evolution for image classifier architecture search",
      "paper_id": "1802.01548v7"
    },
    {
      "index": 25,
      "title": "Website fingerprinting: attacking popular privacy enhancing technologies with the multinomial naïve-bayes classifier",
      "abstract": "",
      "year": "2009",
      "venue": "ACM workshop on Cloud computing security",
      "authors": "D. Herrmann, R. Wendolsky, and H. Federrath"
    },
    {
      "index": 26,
      "title": "A preliminary performance comparison of five machine learning algorithms for practical ip traffic flow classification",
      "abstract": "",
      "year": "2006",
      "venue": "ACM SIGCOMM Computer Communication Review",
      "authors": "N. Williams, S. Zander, and G. Armitage"
    },
    {
      "index": 27,
      "title": "A comprehensive survey on machine learning for networking: evolution, applications and research opportunities",
      "abstract": "",
      "year": "2018",
      "venue": "Journal of Internet Services and Applications",
      "authors": "R. Boutaba, M. A. Salahuddin, N. Limam, S. Ayoubi, N. Shahriar, F. Estrada-Solano, and O. M. Caicedo"
    },
    {
      "index": 28,
      "title": "End-to-end encrypted traffic classification with one-dimensional convolution neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "2017 IEEE international conference on intelligence and security informatics (ISI)",
      "authors": "W. Wang, M. Zhu, J. Wang, X. Zeng, and Z. Yang"
    },
    {
      "index": 29,
      "title": "Flowpic: Encrypted internet traffic classification is as easy as image recognition",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)",
      "authors": "T. Shapira and Y. Shavitt"
    },
    {
      "index": 30,
      "title": "Fs-net: A flow sequence network for encrypted traffic classification",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE INFOCOM 2019-IEEE Conference On Computer Communications",
      "authors": "C. Liu, L. He, G. Xiong, Z. Cao, and Z. Li"
    },
    {
      "index": 31,
      "title": "Mimetic: Mobile encrypted traffic classification using multimodal deep learning",
      "abstract": "",
      "year": "2019",
      "venue": "Computer networks",
      "authors": "G. Aceto, D. Ciuonzo, A. Montieri, and A. Pescapè"
    },
    {
      "index": 32,
      "title": "ET-BERT: A Contextualized Datagram Representation with Pre-training Transformers for Encrypted Traffic Classification",
      "abstract": "",
      "year": "2022",
      "venue": "ACM Web Conference 2022, WWW ’22",
      "authors": "X. Lin, G. Xiong, G. Gou, Z. Li, J. Shi, and J. Yu",
      "orig_title": "Et-bert: A contextualized datagram representation with pre-training transformers for encrypted traffic classification",
      "paper_id": "2202.06335v2"
    },
    {
      "index": 33,
      "title": "Large-scale Mobile App Identification Using Deep Learning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Access",
      "authors": "S. Rezaei, B. Kroencke, and X. Liu",
      "orig_title": "Large-scale mobile app identification using deep learning",
      "paper_id": "1910.02350v2"
    },
    {
      "index": 34,
      "title": "Characterization of encrypted and vpn traffic using time-related",
      "abstract": "",
      "year": "2016",
      "venue": "2nd international conference on information systems security and privacy (ICISSP)",
      "authors": "G. Draper-Gil, A. H. Lashkari, M. S. I. Mamun, and A. A. Ghorbani"
    },
    {
      "index": 35,
      "title": "Characterization of tor traffic using time based features",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Information Systems Security and Privacy",
      "authors": "A. H. Lashkari, G. D. Gil, M. S. I. Mamun, and A. A. Ghorbani"
    },
    {
      "index": 36,
      "title": "How to achieve high classification accuracy with just a few labels: A semi-supervised approach using sampled packets",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1812.09761",
      "authors": "S. Rezaei and X. Liu"
    },
    {
      "index": 37,
      "title": "Deep Learning and Zero-Day Traffic Classification: Lessons learned from a commercial-grade dataset",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE Transactions on Network and Service Management",
      "authors": "L. Yang, A. Finamore, F. Jun, and D. Rossi",
      "orig_title": "Deep learning and zero-day traffic classification: Lessons learned from a commercial-grade dataset",
      "paper_id": "2104.03182v2"
    },
    {
      "index": 38,
      "title": "New directions in automated traffic analysis",
      "abstract": "",
      "year": "2021",
      "venue": "ACM SIGSAC Conference on Computer and Communications Security",
      "authors": "J. Holland, P. Schmitt, N. Feamster, and P. Mittal"
    },
    {
      "index": 39,
      "title": "Ggfast: Automating generation of flexible network traffic classifiers",
      "abstract": "",
      "year": "2023",
      "venue": "ACM SIGCOMM 2023 Conference",
      "authors": "J. Piet, D. Nwoji, and V. Paxson"
    },
    {
      "index": 40,
      "title": "AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2003.06505",
      "authors": "N. Erickson, J. Mueller, A. Shirkov, H. Zhang, P. Larroy, M. Li, and A. Smola",
      "orig_title": "Autogluon-tabular: Robust and accurate automl for structured data",
      "paper_id": "2003.06505v1"
    },
    {
      "index": 41,
      "title": "Mljar: State-of-the-art automated machine learning framework for tabular data. version 0.10.3",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "A. Płońska and P. Płoński"
    },
    {
      "index": 42,
      "title": "Analyzing learning-based encrypted malware traffic classification with automl",
      "abstract": "",
      "year": "2021",
      "venue": "IEEE International Conference on Communication Technology (ICCT)",
      "authors": "D. F. Isingizwe, M. Wang, W. Liu, D. Wang, T. Wu, and J. Li"
    },
    {
      "index": 43,
      "title": "End-to-end encrypted traffic classification with one-dimensional convolution neural networks",
      "abstract": "",
      "year": "2017",
      "venue": "2017 IEEE International Conference on Intelligence and Security Informatics (ISI)",
      "authors": "W. Wang, M. Zhu, J. Wang, X. Zeng, and Z. Yang"
    },
    {
      "index": 44,
      "title": "TensorFlow: Large-scale machine learning on heterogeneous systems",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": ""
    },
    {
      "index": 45,
      "title": "Keras",
      "abstract": "",
      "year": "2015",
      "venue": "",
      "authors": "F. Chollet et al."
    },
    {
      "index": 46,
      "title": "Apache spark: A unified engine for big data processing",
      "abstract": "",
      "year": "2016",
      "venue": "Commun. ACM",
      "authors": "M. Zaharia, R. S. Xin, P. Wendell, T. Das, M. Armbrust, A. Dave, X. Meng, J. Rosen, S. Venkataraman, M. J. Franklin, A. Ghodsi, J. Gonzalez, S. Shenker, and I. Stoica"
    },
    {
      "index": 47,
      "title": "Hypernets",
      "abstract": "",
      "year": "2021",
      "venue": "",
      "authors": "D. IO"
    },
    {
      "index": 48,
      "title": "TLS Encrypted Client Hello",
      "abstract": "",
      "year": "2022",
      "venue": "Internet Engineering Task Force",
      "authors": "E. Rescorla, K. Oku, N. Sullivan, and C. A. Wood"
    },
    {
      "index": 49,
      "title": "Characterization of encrypted and vpn traffic using time-related features",
      "abstract": "",
      "year": "2016",
      "venue": "International Conf. on Information Systems Security and Privacy",
      "authors": "G. Draper-Gil, A. H. Lashkari et al."
    },
    {
      "index": 50,
      "title": "Finite-time analysis of the multiarmed bandit problem",
      "abstract": "",
      "year": "2002",
      "venue": "Machine learning",
      "authors": "P. Auer, N. Cesa-Bianchi, and P. Fischer"
    },
    {
      "index": 51,
      "title": "Lightgbm: A highly efficient gradient boosting decision tree",
      "abstract": "",
      "year": "2017",
      "venue": "NIPS",
      "authors": "G. Ke, Q. Meng, T. Finley, T. Wang, W. Chen, W. Ma, Q. Ye, and T.-Y. Liu"
    },
    {
      "index": 52,
      "title": "Attention Is All You Need",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in neural information processing systems",
      "authors": "A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin",
      "orig_title": "Attention is all you need",
      "paper_id": "1706.03762v7"
    },
    {
      "index": 53,
      "title": "Mt-flowformer: A semi-supervised flow transformer for encrypted traffic classification",
      "abstract": "",
      "year": "2022",
      "venue": "ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD ’22",
      "authors": "R. Zhao, X. Deng, Z. Yan, J. Ma, Z. Xue, and Y. Wang"
    },
    {
      "index": 54,
      "title": "Understanding and simplifying one-shot architecture search",
      "abstract": "",
      "year": "2018",
      "venue": "ICML",
      "authors": "G. Bender, P.-J. Kindermans, B. Zoph, V. Vasudevan, and Q. V. Le"
    }
  ]
}