{
  "paper_id": "2002.08394v1",
  "title": "MonoLayout: Amodal scene layout from a single image",
  "sections": {
    "appendix c comparision with pseudo-lidar": "There is another recent set of approaches to object detection in bird’s eye view—pseudo-lidar approaches . At the core of these approaches lies the idea that, since lidar object detection works exceedingly well, monocular images can be mapped to (pseudo) lidar-like maps in bird’s eye view, and object detecion networks tailored to lidar bird’s eye view maps can readily be applied to this setting. Such approaches are primarily geared towards detecting objects in lidar-like maps. MonoLayout, on the other hand, intends to estimate an amodal scene layout, and to do so, it must reason not only about vehicles, but also about the static scene layout. Table 5 compares MonoLayout with a set of pseudo-lidar approaches, in terms of vehicle occupancy estimation and road layout estimation. Specifically, we evaluate the following pesudo-lidar based methods. ENet + Pseudo-lidar input (Monodepth2): Uses an ENet [ref]27-style encoder-decoder architecture that uses Monodepth2  to get monocular depth estimates. PointRCNN + Pseudo-lidar input (Monodepth2): Uses a PointRCNN [ref]35 architecture (a two-stage object detector comprising a region proposal network, and a classification network) to detect vehicles in bird’s eye view. AVOD + Pseudo-lidar input (PSMNet): A stereo, supervised method. Uses the aggregated view object detector AVOD [avod] and pseudo-lidar input computed from a disparity estimation network (PSMNet [ref]4). The comparision is shown in Table 5. The PointRCNN [ref]35 and AVOD  are tailored specifically for object detection, and hence cannot be repurposed to estimate road layouts. However, the ENet [ref]27 architecture can, and we trained it for the task of road layout estimation. We observe that, among all approaches, MonoLayout is the fastest (about an order of magnitude speedup over pseudo-lidar methods). Furthermore, the accuracy is competitive, if not greater, compared to pseudo-lidar based approaches. We also evaluate against a stereo pseudo-lidar baseline (AVOD + pseudolidar PSMNet [ref]4). By virtue of using stereo images, and being supervised on the KITTI Object dataset 777Monodepth2  is unsupervised, and has not been finetuned on the KITTI Object dataset, achieves superior performance. However, the comparision is unfair, and is provided only for a reference, to enable progress in amodal layout estimation from a monocular camera. Another shortcoming of pseudolidar-style approaches is that, it is not possible to learn visual (i.e., image intensity based) features that are extremely useful in road layout estimation)."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "SemanticKITTI: A Dataset for Semantic Scene Understanding of LiDAR Sequences",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "J. Behley, M. Garbade, A. Milioto, J. Quenzel, S. Behnke, C. Stachniss, and J. Gall",
      "orig_title": "Semantickitti: A dataset for semantic scene understanding of lidar sequences",
      "paper_id": "1904.01416v3"
    },
    {
      "index": 1,
      "title": "BirdNet: a 3D Object Detection Framework from LiDAR information",
      "abstract": "",
      "year": "2018",
      "venue": "ITSC",
      "authors": "J. Beltrán, C. Guindel, F. M. Moreno, D. Cruzado, F. Garcia, and A. De La Escalera",
      "orig_title": "Birdnet: a 3d object detection framework from lidar information",
      "paper_id": "1805.01195v1"
    },
    {
      "index": 2,
      "title": "High-speed tracking-by-detection without using image information",
      "abstract": "",
      "year": "2017",
      "venue": "International Workshop on Traffic and Street Surveillance for Safety and Security at IEEE AVSS 2017",
      "authors": "E. Bochinski, V. Eiselein, and T. Sikora"
    },
    {
      "index": 3,
      "title": "Pyramid Stereo Matching Network",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "J.-R. Chang and Y.-S. Chen",
      "orig_title": "Pyramid stereo matching network",
      "paper_id": "1803.08669v1"
    },
    {
      "index": 4,
      "title": "Argoverse: 3D Tracking and Forecasting with Rich Maps",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "M.-F. Chang, J. Lambert, P. Sangkloy, J. Singh, S. Bak, A. Hartnett, D. Wang, P. Carr, S. Lucey, D. Ramanan, et al.",
      "orig_title": "Argoverse: 3d tracking and forecasting with rich maps",
      "paper_id": "1911.02620v1"
    },
    {
      "index": 5,
      "title": "Monocular 3d object detection for autonomous driving",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "X. Chen, K. Kundu, Z. Zhang, H. Ma, S. Fidler, and R. Urtasun"
    },
    {
      "index": 6,
      "title": "Multi-View 3D Object Detection Network for Autonomous Driving",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "X. Chen, H. Ma, J. Wan, B. Li, and T. Xia",
      "orig_title": "Multi-view 3d object detection network for autonomous driving",
      "paper_id": "1611.07759v3"
    },
    {
      "index": 7,
      "title": "Multi-column deep neural networks for image classification",
      "abstract": "",
      "year": "2012",
      "venue": "arXiv preprint",
      "authors": "D. Cireşan, U. Meier, and J. Schmidhuber"
    },
    {
      "index": 8,
      "title": "Imagenet: A large-scale hierarchical image database",
      "abstract": "",
      "year": "2009",
      "venue": "CVPR",
      "authors": "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei"
    },
    {
      "index": 9,
      "title": "Are we ready for autonomous driving? the kitti vision benchmark suite",
      "abstract": "",
      "year": "2012",
      "venue": "CVPR",
      "authors": "A. Geiger, P. Lenz, and R. Urtasun"
    },
    {
      "index": 10,
      "title": "Fast R-CNN",
      "abstract": "",
      "year": "2015",
      "venue": "IEEE international conference on computer vision",
      "authors": "R. Girshick",
      "orig_title": "Fast r-cnn",
      "paper_id": "1504.08083v2"
    },
    {
      "index": 11,
      "title": "Digging Into Self-Supervised Monocular Depth Estimation",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint",
      "authors": "C. Godard, O. Mac Aodha, M. Firman, and G. Brostow",
      "orig_title": "Digging into self-supervised monocular depth estimation",
      "paper_id": "1806.01260v4"
    },
    {
      "index": 12,
      "title": "Generative adversarial nets",
      "abstract": "",
      "year": "2014",
      "venue": "Advances in Neural Information Processing Systems 27",
      "authors": "I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio"
    },
    {
      "index": 13,
      "title": "Probabilistic Object Detection: Definition and Evaluation",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1811.10800",
      "authors": "D. Hall, F. Dayoub, J. Skinner, H. Zhang, D. Miller, P. Corke, G. Carneiro, A. Angelova, and N. Sünderhauf",
      "orig_title": "Probabilistic object detection: Definition and evaluation",
      "paper_id": "1811.10800v4"
    },
    {
      "index": 14,
      "title": "Mask R-CNN",
      "abstract": "",
      "year": "2017",
      "venue": "IEEE international conference on computer vision",
      "authors": "K. He, G. Gkioxari, P. Dollár, and R. Girshick",
      "orig_title": "Mask r-cnn",
      "paper_id": "1703.06870v3"
    },
    {
      "index": 15,
      "title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification",
      "abstract": "",
      "year": "2015",
      "venue": "ICCV",
      "authors": "K. He, X. Zhang, S. Ren, and J. Sun"
    },
    {
      "index": 16,
      "title": "Image-to-Image Translation with Conditional Adversarial Networks",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros",
      "orig_title": "Image-to-image translation with conditional adversarial networks",
      "paper_id": "1611.07004v3"
    },
    {
      "index": 17,
      "title": "Image-to-Image Translation with Conditional Adversarial Networks",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros",
      "orig_title": "Image-to-image translation with conditional adversarial networks",
      "paper_id": "1611.07004v3"
    },
    {
      "index": 18,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Learning Representatiosn (ICLR)",
      "authors": "D. P. Kingma and J. Ba"
    },
    {
      "index": 19,
      "title": "Joint 3D Proposal Generation and Object Detection from View Aggregation",
      "abstract": "",
      "year": "2018",
      "venue": "IROS",
      "authors": "J. Ku, M. Mozifian, J. Lee, A. Harakeh, and S. L. Waslander",
      "orig_title": "Joint 3d proposal generation and object detection from view aggregation",
      "paper_id": "1712.02294v4"
    },
    {
      "index": 20,
      "title": "GS3D: An Efficient 3D Object Detection Framework for Autonomous Driving",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "B. Li, W. Ouyang, L. Sheng, X. Zeng, and X. Wang",
      "orig_title": "Gs3d: An efficient 3d object detection framework for autonomous driving",
      "paper_id": "1903.10955v2"
    },
    {
      "index": 21,
      "title": "Deep Continuous Fusion for Multi-Sensor 3D Object Detection",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "M. Liang, B. Yang, S. Wang, and R. Urtasun",
      "orig_title": "Deep continuous fusion for multi-sensor 3d object detection",
      "paper_id": "2012.10992v1"
    },
    {
      "index": 22,
      "title": "Wise-ale: Wide sample estimator for aggregate latent embedding",
      "abstract": "",
      "year": "2019",
      "venue": "",
      "authors": "S. Lin, R. Clark, R. Birke, N. Trigoni, and S. Roberts"
    },
    {
      "index": 23,
      "title": "Monocular Semantic Occupancy Grid Mapping with Convolutional Variational Encoder-Decoder Networks",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Robotics and Automation Letters",
      "authors": "C. Lu, M. J. G. van de Molengraft, and G. Dubbelman",
      "orig_title": "Monocular semantic occupancy grid mapping with convolutional variational encoder–decoder networks",
      "paper_id": "1804.02176v3"
    },
    {
      "index": 24,
      "title": "3d bounding box estimation using deep learning and geometry",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "A. Mousavian, D. Anguelov, J. Flynn, and J. Kosecka"
    },
    {
      "index": 25,
      "title": "Planet dump retrieved from https://planet.osm.org",
      "abstract": "",
      "year": "2017",
      "venue": "https://www.openstreetmap.org",
      "authors": "OpenStreetMap contributors"
    },
    {
      "index": 26,
      "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1606.02147",
      "authors": "A. Paszke, A. Chaurasia, S. Kim, and E. Culurciello",
      "orig_title": "Enet: A deep neural network architecture for real-time semantic segmentation",
      "paper_id": "1606.02147v1"
    },
    {
      "index": 27,
      "title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
      "abstract": "",
      "year": "2015",
      "venue": "arXiv preprint arXiv:1511.06434",
      "authors": "A. Radford, L. Metz, and S. Chintala",
      "orig_title": "Unsupervised representation learning with deep convolutional generative adversarial networks",
      "paper_id": "1511.06434v2"
    },
    {
      "index": 28,
      "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in neural information processing systems",
      "authors": "S. Ren, K. He, R. Girshick, and J. Sun",
      "orig_title": "Faster r-cnn: Towards real-time object detection with region proposal networks",
      "paper_id": "1506.01497v3"
    },
    {
      "index": 29,
      "title": "Orthographic Feature Transform for Monocular 3D Object Detection",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint",
      "authors": "T. Roddick, A. Kendall, and R. Cipolla",
      "orig_title": "Orthographic feature transform for monocular 3d object detection",
      "paper_id": "1811.08188v1"
    },
    {
      "index": 30,
      "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Medical image computing and computer-assisted intervention",
      "authors": "O. Ronneberger, P. Fischer, and T. Brox",
      "orig_title": "U-net: Convolutional networks for biomedical image segmentation",
      "paper_id": "1505.04597v1"
    },
    {
      "index": 31,
      "title": "In-Place Activated BatchNorm for Memory-Optimized Training of DNNs",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "S. Rota Bulò, L. Porzi, and P. Kontschieder",
      "orig_title": "In-place activated batchnorm for memory-optimized training of dnns",
      "paper_id": "1712.02616v3"
    },
    {
      "index": 32,
      "title": "Improved Techniques for Training GANs",
      "abstract": "",
      "year": "2016",
      "venue": "Advances in neural information processing systems",
      "authors": "T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen",
      "orig_title": "Improved techniques for training gans",
      "paper_id": "1606.03498v1"
    },
    {
      "index": 33,
      "title": "Learning to Look around Objects for Top-View Representations of Outdoor Scenes",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "S. Schulter, M. Zhai, N. Jacobs, and M. Chandraker",
      "orig_title": "Learning to look around objects for top-view representations of outdoor scenes",
      "paper_id": "1803.10870v1"
    },
    {
      "index": 34,
      "title": "PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "S. Shi, X. Wang, and H. Li",
      "orig_title": "Pointrcnn: 3d object proposal generation and detection from point cloud",
      "paper_id": "1812.04244v2"
    },
    {
      "index": 35,
      "title": "Learning 2D to 3D Lifting for Object Detection in 3D for Autonomous Vehicles",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint",
      "authors": "S. Srivastava, F. Jurie, and G. Sharma",
      "orig_title": "Learning 2d to 3d lifting for object detection in 3d for autonomous vehicles",
      "paper_id": "1904.08494v2"
    },
    {
      "index": 36,
      "title": "Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Y. Wang, W.-L. Chao, D. Garg, B. Hariharan, M. Campbell, and K. Q. Weinberger",
      "orig_title": "Pseudo-lidar from visual depth estimation: Bridging the gap in 3d object detection for autonomous driving",
      "paper_id": "1812.07179v6"
    },
    {
      "index": 37,
      "title": "A Parametric Top-View Representation of Complex Road Scenes",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Z. Wang, B. Liu, S. Schulter, and M. Chandraker",
      "orig_title": "A parametric top-view representation of complex road scenes",
      "paper_id": "1812.06152v2"
    },
    {
      "index": 38,
      "title": "PIXOR: Real-time 3D Object Detection from Point Clouds",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "B. Yang, W. Luo, and R. Urtasun",
      "orig_title": "Pixor: Real-time 3d object detection from point clouds",
      "paper_id": "1902.06326v3"
    },
    {
      "index": 39,
      "title": "Pseudo-LiDAR++: Accurate Depth for 3D Object Detection in Autonomous Driving",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint",
      "authors": "Y. You, Y. Wang, W.-L. Chao, D. Garg, G. Pleiss, B. Hariharan, M. Campbell, and K. Q. Weinberger",
      "orig_title": "Pseudo-lidar++: Accurate depth for 3d object detection in autonomous driving",
      "paper_id": "1906.06310v3"
    },
    {
      "index": 40,
      "title": "Sketch-a-net: A deep neural network that beats humans",
      "abstract": "",
      "year": "2017",
      "venue": "International journal of computer vision",
      "authors": "Q. Yu, Y. Yang, F. Liu, Y.-Z. Song, T. Xiang, and T. M. Hospedales"
    }
  ]
}