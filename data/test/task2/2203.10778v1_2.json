{
  "paper_id": "2203.10778v1",
  "title": "Delving into the Estimation Shift of Batch Normalization in a Network",
  "sections": {
    "introduction": "Input normalization is extensively used in training neural networks for decades  and shows good theoretical properties in optimization for linear models  .\nIt uses population statistics for normalization that can be calculated directly from the available training data. A natural idea is to extend normalization for the activation in a network. However, normalizing activation is more challenging since the distribution of internal activation varies, which leads to the estimation of population statistics for normalization inaccurate  . A network with activation normalized by the population statistics shows the training instability 2. Batch normalization (BN)  addresses itself to normalize the activation using mini-batch statistics during training, but the estimated population statistics during inference/test.\nBN ensures the normalized mini-batch output standardized over each iteration, enabling stable training, efficient optimization     3 and potential generalization 3  . It has been extensively used in varieties of architectures [ref]9    1 [ref]53, and successfully proliferated throughout various areas 7  2. Despite the common success of BN, it still suffers from problems when applied in certain scenarios 2 . One notorious limitation of BN is its small-batch-size problem — BN’s error increases rapidly as the batch size becomes smaller  4. Besides, a network with a naive BN gets significantly degenerated performance, if there exists covariate shift between the training and test data  0 1 .\nWhile these problems raise across different scenarios and contexts, the estimated population statistics of BN used for inference seems to be the link between them: 1) the small-batch-size problem of BN can be relieved if its estimated populations statistics are corrected during test 4 6; 2) and a model is more robust for unseen domain data (corrupted images) if the estimated population statistics of BN are adapted based on the available test data  0 . This paper investigates the estimation of population statistics in a systematic way. We introduce expected population statistics of BN, considering the ill-defined population statistics of the activation with a varying distribution during training (see Section 4.2 for details). We refer to as estimation shift of BN if its estimated population statistics do not equal to its expected ones, and design experiments to quantitatively investigate how the estimation shift affects a batch normalized network. Our primary observation is that the estimation shift of BN can be accumulated in a network (Figure 1 (a)). This observation provides clues to explain why a network with BN has significantly degenerated performance under small-batch-size training, and why the population statistics of BN need to be adapted if there exists distribution shift for input data during test.\nWe further find that a batch-free normalization (BFN)—normalizing each sample independently without across batch dimension—can block the accumulation of the estimation shift of BN. This relieves the performance degeneration of a network if a distribution shift occurs. These observations motivate our design of XBNBlock that replaces one BN with BFN in the bottleneck of residual-style networks [ref]9 [ref]53. We apply the proposed XBNBlock to ResNet [ref]9 and ResNeXt [ref]53 architectures and conduct experiments on the ImageNet 7 and COCO  benchmarks.\nXBNBlock consistently improves the performance for both architectures, with absolute gains of 0.6%∼1.1%similar-topercent0.6percent1.10.6\\%\\sim 1.1\\% in top-1 accuracy for ImageNet, 0.86%∼1.62%similar-topercent0.86percent1.620.86\\%\\sim 1.62\\% in bounding box AP for COCO using Faster R-CNN 6, and 0.56%∼2.06%similar-topercent0.56percent2.060.56\\%\\sim 2.06\\% ( 0.22%∼1.18%similar-topercent0.22percent1.180.22\\%\\sim 1.18\\%) in bounding box AP (mask AP) for COCO using Mask R-CNN . Besides, XBNBlock seems to be more robust to the distribution shift."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Layer normalization",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1607.06450",
      "authors": "Lei Jimmy Ba, Ryan Kiros, and Geoffrey E. Hinton"
    },
    {
      "index": 1,
      "title": "Revisiting Batch Normalization for Improving Corruption Robustness",
      "abstract": "",
      "year": "2021",
      "venue": "WACV",
      "authors": "Philipp Benz, Chaoning Zhang, Adil Karjauv, and In So Kweon",
      "orig_title": "Revisiting batch normalization for improving corruption robustness",
      "paper_id": "2010.03630v4"
    },
    {
      "index": 2,
      "title": "Understanding Batch Normalization",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Johan Bjorck, Carla Gomes, and Bart Selman",
      "orig_title": "Understanding batch normalization",
      "paper_id": "1806.02375v4"
    },
    {
      "index": 3,
      "title": "High-performance large-scale image recognition without normalization",
      "abstract": "",
      "year": "2021",
      "venue": "ICML",
      "authors": "Andy Brock, Soham De, Samuel L Smith, and Karen Simonyan"
    },
    {
      "index": 4,
      "title": "TaskNorm: Rethinking Batch Normalization for Meta-Learning",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "John Bronskill, Jonathan Gordon, James Requeima, Sebastian Nowozin, and Richard E Turner",
      "orig_title": "Tasknorm: Rethinking batch normalization for meta-learning",
      "paper_id": "2003.03284v2"
    },
    {
      "index": 5,
      "title": "Online Normalization for Training Neural Networks",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Vitaliy Chiley, Ilya Sharapov, Atli Kosson, Urs Koster, Ryan Reece, Sofia Samaniego de la Fuente, Vishal Subbiah, and Michael James",
      "orig_title": "Online normalization for training neural networks",
      "paper_id": "1905.05894v3"
    },
    {
      "index": 6,
      "title": "Natural neural networks",
      "abstract": "",
      "year": "2015",
      "venue": "NeurIPS",
      "authors": "Guillaume Desjardins, Karen Simonyan, Razvan Pascanu, and koray kavukcuoglu"
    },
    {
      "index": 7,
      "title": "Mask R-CNN",
      "abstract": "",
      "year": "2017",
      "venue": "ICCV",
      "authors": "Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross B. Girshick",
      "orig_title": "Mask R-CNN",
      "paper_id": "1703.06870v3"
    },
    {
      "index": 8,
      "title": "Deep Residual Learning for Image Recognition",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun",
      "orig_title": "Deep residual learning for image recognition",
      "paper_id": "1512.03385v1"
    },
    {
      "index": 9,
      "title": "Bag of Tricks for Image Classification with Convolutional Neural Networks",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Tong He, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Junyuan Xie, and Mu Li",
      "orig_title": "Bag of tricks for image classification with convolutional neural networks",
      "paper_id": "1812.01187v2"
    },
    {
      "index": 10,
      "title": "Densely connected convolutional networks",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Gao Huang, Zhuang Liu, and Kilian Q. Weinberger"
    },
    {
      "index": 11,
      "title": "Normalization Techniques in Training DNNs: Methodology, Analysis and Application",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2009.12836",
      "authors": "Lei Huang, Jie Qin, Yi Zhou, Fan Zhu, Li Liu, and Ling Shao",
      "orig_title": "Normalization techniques in training dnns: Methodology, analysis and application",
      "paper_id": "2009.12836v1"
    },
    {
      "index": 12,
      "title": "Decorrelated Batch Normalization",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Lei Huang, Dawei Yang, Bo Lang, and Jia Deng",
      "orig_title": "Decorrelated batch normalization",
      "paper_id": "1804.08450v1"
    },
    {
      "index": 13,
      "title": "An Investigation into the Stochasticity of Batch Whitening",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Lei Huang, Lei Zhao, Yi Zhou, Fan Zhu, Li Liu, and Ling Shao",
      "orig_title": "An investigation into the stochasticity of batch whitening",
      "paper_id": "2003.12327v1"
    },
    {
      "index": 14,
      "title": "Group Whitening: Balancing Learning Efficiency and Representational Capacity",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Lei Huang, Yi Zhou, Li Liu, Fan Zhu, and Ling Shao",
      "orig_title": "Group whitening: Balancing learning efficiency and representational capacity",
      "paper_id": "2009.13333v4"
    },
    {
      "index": 15,
      "title": "Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS",
      "authors": "Sergey Ioffe",
      "orig_title": "Batch renormalization: Towards reducing minibatch dependence in batch-normalized models",
      "paper_id": "1702.03275v2"
    },
    {
      "index": 16,
      "title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "abstract": "",
      "year": "2015",
      "venue": "ICML",
      "authors": "Sergey Ioffe and Christian Szegedy"
    },
    {
      "index": 17,
      "title": "Averaging Weights Leads to Wider Optima and Better Generalization",
      "abstract": "",
      "year": "2018",
      "venue": "arXiv preprint arXiv:1803.05407",
      "authors": "Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson",
      "orig_title": "Averaging weights leads to wider optima and better generalization",
      "paper_id": "1803.05407v3"
    },
    {
      "index": 18,
      "title": "U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation",
      "abstract": "",
      "year": "2020",
      "venue": "ICLR",
      "authors": "Junho Kim, Minjae Kim, Hyeonwoo Kang, and Kwang Hee Lee",
      "orig_title": "U-gat-it: Unsupervised generative attentional networks with adaptive layer-instance normalization for image-to-image translation",
      "paper_id": "1907.10830v4"
    },
    {
      "index": 19,
      "title": "Efficient backprop",
      "abstract": "",
      "year": "1998",
      "venue": "Neural Networks: Tricks of the Trade",
      "authors": "Yann LeCun, Leon Bottou, Genevieve B. Orr, and Klaus-Robert Muller"
    },
    {
      "index": 20,
      "title": "Second order properties of error surfaces",
      "abstract": "",
      "year": "1990",
      "venue": "NeurIPS",
      "authors": "Yann LeCun, Ido Kanter, and Sara A. Solla"
    },
    {
      "index": 21,
      "title": "Positional Normalization",
      "abstract": "",
      "year": "2019",
      "venue": "NeurIPS",
      "authors": "Boyi Li, Felix Wu, Kilian Q Weinberger, and Serge Belongie",
      "orig_title": "Positional normalization",
      "paper_id": "1907.04312v2"
    },
    {
      "index": 22,
      "title": "Revisiting Batch Normalization For Practical Domain Adaptation",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1603.04779",
      "authors": "Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou",
      "orig_title": "Revisiting batch normalization for practical domain adaptation",
      "paper_id": "1603.04779v4"
    },
    {
      "index": 23,
      "title": "Feature Pyramid Networks for Object Detection",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Tsung-Yi Lin, Piotr Dollár, Ross B. Girshick, Kaiming He, Bharath Hariharan, and Serge J. Belongie",
      "orig_title": "Feature pyramid networks for object detection",
      "paper_id": "1612.03144v2"
    },
    {
      "index": 24,
      "title": "Microsoft COCO: Common Objects in Context",
      "abstract": "",
      "year": "2014",
      "venue": "ECCV",
      "authors": "Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C. Lawrence Zitnick",
      "orig_title": "Microsoft coco: Common objects in context",
      "paper_id": "1405.0312v3"
    },
    {
      "index": 25,
      "title": "SGDR: stochastic gradient descent with restarts",
      "abstract": "",
      "year": "2017",
      "venue": "ICLR",
      "authors": "Ilya Loshchilov and Frank Hutter"
    },
    {
      "index": 26,
      "title": "Differentiable Learning-to-Normalize via Switchable Normalization",
      "abstract": "",
      "year": "2019",
      "venue": "ICLR",
      "authors": "Ping Luo, Jiamin Ren, Zhanglin Peng, Ruimao Zhang, and Jingyu Li",
      "orig_title": "Differentiable learning-to-normalize via switchable normalization",
      "paper_id": "1806.10779v5"
    },
    {
      "index": 27,
      "title": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun",
      "orig_title": "Shufflenet v2: Practical guidelines for efficient cnn architecture design",
      "paper_id": "1807.11164v1"
    },
    {
      "index": 28,
      "title": "maskrcnn-benchmark: Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch",
      "abstract": "",
      "year": "2018",
      "venue": "https://github.com/facebookresearch/maskrcnn-benchmark",
      "authors": "Francisco Massa and Ross Girshick"
    },
    {
      "index": 29,
      "title": "Deep Boltzmann Machines and the Centering Trick, volume 7700 of LNCS",
      "abstract": "",
      "year": "2012",
      "venue": "Springer",
      "authors": "Grégoire Montavon and Klaus-Robert Müller"
    },
    {
      "index": 30,
      "title": "Evaluating Prediction-Time Batch Normalization for Robustness under Covariate Shift",
      "abstract": "",
      "year": "2020",
      "venue": "arXiv preprint arXiv:2006.10963",
      "authors": "Zachary Nado, Shreyas Padhy, D Sculley, Alexander D’Amour, Balaji Lakshminarayanan, and Jasper Snoek",
      "orig_title": "Evaluating prediction-time batch normalization for robustness under covariate shift",
      "paper_id": "2006.10963v3"
    },
    {
      "index": 31,
      "title": "Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Hyeonseob Nam and Hyo-Eun Kim",
      "orig_title": "Batch-instance normalization for adaptively style-invariant neural networks",
      "paper_id": "1805.07925v3"
    },
    {
      "index": 32,
      "title": "Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Xingang Pan, Ping Luo, Jianping Shi, and Xiaoou Tang",
      "orig_title": "Two at once: Enhancing learning and generalization capacities via ibn-net",
      "paper_id": "1807.09441v3"
    },
    {
      "index": 33,
      "title": "Switchable whitening for deep representation learning",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Xingang Pan, Xiaohang Zhan, Jianping Shi, Xiaoou Tang, and Ping Luo"
    },
    {
      "index": 34,
      "title": "Automatic differentiation in PyTorch",
      "abstract": "",
      "year": "2017",
      "venue": "NeurIPS Autodiff Workshop",
      "authors": "Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer"
    },
    {
      "index": 35,
      "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
      "abstract": "",
      "year": "2015",
      "venue": "NeurIPS",
      "authors": "Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun",
      "orig_title": "Faster R-CNN: Towards real-time object detection with region proposal networks",
      "paper_id": "1506.01497v3"
    },
    {
      "index": 36,
      "title": "ImageNet Large Scale Visual Recognition Challenge",
      "abstract": "",
      "year": "2015",
      "venue": "International Journal of Computer Vision (IJCV)",
      "authors": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei",
      "orig_title": "ImageNet Large Scale Visual Recognition Challenge",
      "paper_id": "1409.0575v3"
    },
    {
      "index": 37,
      "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks",
      "abstract": "",
      "year": "2018",
      "venue": "CVPR",
      "authors": "Mark Sandler, Andrew G. Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen",
      "orig_title": "Mobilenetv2: Inverted residuals and linear bottlenecks",
      "paper_id": "1801.04381v4"
    },
    {
      "index": 38,
      "title": "How Does Batch Normalization Help Optimization?",
      "abstract": "",
      "year": "2018",
      "venue": "NeurIPS",
      "authors": "Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry",
      "orig_title": "How does batch normalization help optimization?",
      "paper_id": "1805.11604v5"
    },
    {
      "index": 39,
      "title": "Improving robustness against common corruptions by covariate shift adaptation",
      "abstract": "",
      "year": "2020",
      "venue": "NeurIPS",
      "authors": "Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge"
    },
    {
      "index": 40,
      "title": "Learning to Optimize Domain Specific Normalization for Domain Generalization",
      "abstract": "",
      "year": "2020",
      "venue": "ECCV",
      "authors": "Seonguk Seo, Yumin Suh, Dongwan Kim, Jongwoo Han, and Bohyung Han",
      "orig_title": "Learning to optimize domain specific normalization for domain generalization",
      "paper_id": "1907.04275v3"
    },
    {
      "index": 41,
      "title": "SSN: Learning Sparse Switchable Normalization via SparsestMax",
      "abstract": "",
      "year": "2019",
      "venue": "CVPR",
      "authors": "Wenqi Shao, Tianjian Meng, Jingyu Li, Ruimao Zhang, Yudian Li, Xiaogang Wang, and Ping Luo",
      "orig_title": "Ssn: Learning sparse switchable normalization via sparsestmax",
      "paper_id": "1903.03793v1"
    },
    {
      "index": 42,
      "title": "Powernorm: Rethinking batch normalization in transformers",
      "abstract": "",
      "year": "2020",
      "venue": "ICML",
      "authors": "Sheng Shen, Zhewei Yao, Amir Gholami, Michael W Mahoney, and Kurt Keutzer"
    },
    {
      "index": 43,
      "title": "EvalNorm: Estimating Batch Normalization Statistics for Evaluation",
      "abstract": "",
      "year": "2019",
      "venue": "ICCV",
      "authors": "Saurabh Singh and Abhinav Shrivastava",
      "orig_title": "Evalnorm: Estimating batch normalization statistics for evaluation",
      "paper_id": "1904.06031v2"
    },
    {
      "index": 44,
      "title": "Unsupervised out-of-distribution detection with batch normalization",
      "abstract": "",
      "year": "2019",
      "venue": "arXiv preprint arXiv:1910.09115",
      "authors": "Jiaming Song, Yang Song, and Stefano Ermon"
    },
    {
      "index": 45,
      "title": "Four Things Everyone Should Know to Improve Batch Normalization",
      "abstract": "",
      "year": "2020",
      "venue": "ICLR",
      "authors": "Cecilia Summers and Michael J. Dinneen",
      "orig_title": "Four things everyone should know to improve batch normalization",
      "paper_id": "1906.03548v2"
    },
    {
      "index": 46,
      "title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",
      "abstract": "",
      "year": "2017",
      "venue": "AAAI",
      "authors": "Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke",
      "orig_title": "Inception-v4, inception-resnet and the impact of residual connections on learning",
      "paper_id": "1602.07261v2"
    },
    {
      "index": 47,
      "title": "Rethinking the inception architecture for computer vision",
      "abstract": "",
      "year": "2016",
      "venue": "CVPR",
      "authors": "Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna"
    },
    {
      "index": 48,
      "title": "Instance Normalization: The Missing Ingredient for Fast Stylization",
      "abstract": "",
      "year": "2016",
      "venue": "arXiv preprint arXiv:1607.08022",
      "authors": "Dmitry Ulyanov, Andrea Vedaldi, and Victor S. Lempitsky",
      "orig_title": "Instance normalization: The missing ingredient for fast stylization",
      "paper_id": "1607.08022v3"
    },
    {
      "index": 49,
      "title": "A convergence analysis of log-linear training",
      "abstract": "",
      "year": "2011",
      "venue": "NeurIPS",
      "authors": "Simon Wiesler and Hermann Ney"
    },
    {
      "index": 50,
      "title": "Group Normalization",
      "abstract": "",
      "year": "2018",
      "venue": "ECCV",
      "authors": "Yuxin Wu and Kaiming He",
      "orig_title": "Group normalization",
      "paper_id": "1803.08494v3"
    },
    {
      "index": 51,
      "title": "Rethinking “Batch” in BatchNorm",
      "abstract": "",
      "year": "2021",
      "venue": "arXiv preprint arXiv:2105.07576",
      "authors": "Yuxin Wu and Justin Johnson",
      "orig_title": "Rethinking ”batch” in batchnorm",
      "paper_id": "2105.07576v1"
    },
    {
      "index": 52,
      "title": "Aggregated Residual Transformations for Deep Neural Networks",
      "abstract": "",
      "year": "2017",
      "venue": "CVPR",
      "authors": "Saining Xie, Ross B. Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He",
      "orig_title": "Aggregated residual transformations for deep neural networks",
      "paper_id": "1611.05431v2"
    },
    {
      "index": 53,
      "title": "Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization",
      "abstract": "",
      "year": "2020",
      "venue": "ICLR",
      "authors": "Junjie Yan, Ruosi Wan, Xiangyu Zhang, Wei Zhang, Yichen Wei, and Jian Sun",
      "orig_title": "Towards stabilizing batch statistics in backward propagation of batch normalization",
      "paper_id": "2001.06838v2"
    },
    {
      "index": 54,
      "title": "Cross-Iteration Batch Normalization",
      "abstract": "",
      "year": "2021",
      "venue": "CVPR",
      "authors": "Zhuliang Yao, Yue Cao, Shuxin Zheng, Gao Huang, and Stephen Lin",
      "orig_title": "Cross-iteration batch normalization",
      "paper_id": "2002.05712v3"
    },
    {
      "index": 55,
      "title": "Gradient Centralization: A New Optimization Technique for Deep Neural Networks",
      "abstract": "",
      "year": "2020",
      "venue": "ECCV",
      "authors": "Hongwei Yong, Jianqiang Huang, Xiansheng Hua, and Lei Zhang",
      "orig_title": "Gradient centralization: A new optimization technique for deep neural networks",
      "paper_id": "2004.01461v2"
    },
    {
      "index": 56,
      "title": "Wide Residual Networks",
      "abstract": "",
      "year": "2016",
      "venue": "BMVC",
      "authors": "Sergey Zagoruyko and Nikos Komodakis",
      "orig_title": "Wide residual networks",
      "paper_id": "1605.07146v4"
    },
    {
      "index": 57,
      "title": "mixup: Beyond Empirical Risk Minimization",
      "abstract": "",
      "year": "2018",
      "venue": "ICLR",
      "authors": "Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz",
      "orig_title": "mixup: Beyond empirical risk minimization",
      "paper_id": "1710.09412v2"
    },
    {
      "index": 58,
      "title": "Exemplar Normalization for Learning Deep Representation",
      "abstract": "",
      "year": "2020",
      "venue": "CVPR",
      "authors": "Ruimao Zhang, Zhanglin Peng, Lingyun Wu, Zhen Li, and Ping Luo",
      "orig_title": "Exemplar normalization for learning deep representation",
      "paper_id": "2003.08761v2"
    }
  ]
}