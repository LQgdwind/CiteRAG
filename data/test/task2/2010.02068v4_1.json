{
  "paper_id": "2010.02068v4",
  "title": "Deep Reinforcement Learning for the Electric Vehicle Routing Problem with Time Windows",
  "sections": {
    "ii related work": "We first review the literature on utilizing ML to solve CO, focusing on developing primal heuristics. Readers are referred to  for a more comprehensive modern survey. The application of neural network (NN) to solving CO dates back to the paper by Hopfield and Tank .\nThey define an array representation for TSP solutions.\nIn an nùëõn-city TSP instance, each city iùëñi is associated with an nùëõn-dimensional array VisubscriptùëâùëñV_{i} whose jt‚Äãhsuperscriptùëóùë°‚Ñéj^{th} entry vi,jsubscriptùë£ùëñùëóv_{i,j} takes a value of 111 if city iùëñi is the jt‚Äãhsuperscriptùëóùë°‚Ñéj^{th} city along the route and takes 00 otherwise.\nAll the city arrays form an n√ónùëõùëõn\\times n array modeled by n2superscriptùëõ2n^{2} neurons.\nSome motion equations were constructed to describe the time evolution of the circuit in the analogy network comprised of the neurons.\nThe circuit finally converge to a ‚Äúlow-energy‚Äù state favoring high quality feasible solutions to the TSP.\nAlthough the NN proposed in  does not have a learning process, and its performance heavily relies on the choice of model parameters which hinders its scalability and the generalization capability , it stimulated subsequent research efforts on applying NN to solve CO. One promising direction is to solve CO by learning a value function to evaluate each possible adjustment in the current solution or action for constructing solutions.\nThe value function can then be utilized by search algorithms to find good solutions to the target problem.\nFor example, for a job-scheduling problem of NASA, Zhang et al.  parameterize such a value function as an NN that intakes some hand-designed features of the current schedule and outputs the ‚Äúvalue‚Äù of the possible adjustments.\nFor CO that is defined on a graph, hand designed features could be replaced by graph embedding networks that synthesize the structure as well as local and global information of the graph.\nKhalil et al. [ref]6 use fitted-Q learning to train a graph embedding network (DQN) for action evaluation based on which they greedily decode solutions to target problems including TSP, MVC and MAXCUT.\nOther graph embedding examples could be seen in  [ref]12 [ref]13, though the embedded graph vectors in [ref]12 and [ref]13 are fed to NN to predict problem-specific values instead of evaluating actions. While  [ref]6 mainly focus on how to construct NN to estimate values of actions, there are some other research concentrating on the decoding process based on the value function.\nFor the maximum independent set problem, Li et al.  argue that the naive decoding method, i.e. to greedily select the vertex with the highest value, might lead to poor results because there might exist many optimal solutions and each vertex could participate in some of them.\nTo address the issue, they propose a tree search paradigm supported by the value function enabling the algorithm to explore a diverse set of solutions.\nA graph reduction and a local search component were incorporated to enhance solution efficiency and quality.\nTo further accelerate the search process, Mittal et al.  propose a graph convolution network to prune poor vertices and learn the embeddings of good vertices which are then fed to the model of Li et al.  to produce solution set.\nMoreover, Barrett et al.  proposed the exploratory DQN allowing the algorithm to revise the actions it previously made so as to more comprehensively explore the solution space. There is another group of research on applying policy-based approaches, which learn policies to directly determine the next action given a system state, to solve CO.\nOne good example is the pointer network (PN) developed by Vinyals et al.  for CO, such as TSP and VRP, whose solutions are permutations of the given vertices.\nInspired by the sequence-to-sequence learning  originally proposed for machine translation, the PN intakes the given vertices and predict a permutation of them.\nThe PN is trained in a supervised manner with instance-solution pairs generated by an approximate solver.\nTo generalize the PN to CO for which instance-solution pairs are difficult to obtain, Bello et al.  used a policy gradient method to train the PN.\nThe PN is able to efficietly find close-to-optimal solutions to TSP instances with up to 100100100 vertices.\nNazari et al.  further generalized this method to the VRP whose vertex states change during the decoding process.\nConsidering that the order of the vertices does not provide any additional information for a VRP solver, they replace the RNN encoder in the PN with element-wise projections of vertex information which accelerates the model implementation.\nOn the other hand, Kool et al.  propose a multi-head attention model for the TSP and VRP.\nThe model is trained using policy gradient with roll-out baseline which is easier to implement in practice than the A3C method utilized by . Although value-based methods perform well on various CO problems, they do not directly apply to EVRPTW since some vertices (stations and the depot) could appear more than once in a solution.\nGiven the similarity between the VRP and the EVRPTW, the policy-based framework proposed by Nazari et al.  is a better fit to the EVRPTW, yet global information of the system, which is very important for solving EVRPTW, should also be taken into consideration.\nHence, our proposed model is based on the framework of  and\nincorporates a graph embedding component proposed by [ref]6 to synthesize the local and global information of the network. This research is also related to the stream of literature on applying reinforcement learning in intelligent transportation system.\nWith a very similar idea, Yu et al.  incorporate the Structure2Vec tool  with PN  to develop a distributed system for solving an online autonomous vehicle routing problem.\nZhao et al.  extend the work of  to VRPTW by revising the masking scheme and adding a local search phase to further improve the solution provided by the attention model.\nIn , Shi et al. propose an RL framework for ride-hailing service provision in a local community, while in , Gao et al. employ the idea of RL to build a data-driven cruise control algorithm for the bus transit line connecting New Jersey and Manhattan, New York.\nOur proposed approach differs from them in terms of model architecture, training method as well as problem settings."
  },
  "reference_labels": [
    {
      "index": 0,
      "title": "Vehicle electrification: Status and issues",
      "abstract": "",
      "year": "2011",
      "venue": "IEEE",
      "authors": "A. G. Boulanger, A. C. Chu, S. Maxx, and D. L. Waltz"
    },
    {
      "index": 1,
      "title": "Plug-in hybrid electric vehicles and smart grids: Investigations based on a microsimulation",
      "abstract": "",
      "year": "2013",
      "venue": "Transportation Research Part C: Emerging Technologies",
      "authors": "R. A. Waraich, M. D. Galus, C. Dobler, M. Balmer, G. Andersson, and K. W. Axhausen"
    },
    {
      "index": 2,
      "title": "The electric vehicle-routing problem with time windows and recharging stations",
      "abstract": "",
      "year": "2014",
      "venue": "Transportation Science",
      "authors": "M. Schneider, A. Stenger, and D. Goeke"
    },
    {
      "index": 3,
      "title": "Exact algorithms for electric vehicle-routing problems with time windows",
      "abstract": "",
      "year": "2016",
      "venue": "Operations Research",
      "authors": "G. Desaulniers, F. Errico, S. Irnich, and M. Schneider"
    },
    {
      "index": 4,
      "title": "Electric vehicle routing with charging/discharging under time-variant electricity prices",
      "abstract": "",
      "year": "2021",
      "venue": "Transportation Research Part C: Emerging Technologies",
      "authors": "B. Lin, B. Ghaddar, and J. Nathwani"
    },
    {
      "index": 5,
      "title": "Learning Combinatorial Optimization Algorithms over Graphs",
      "abstract": "",
      "year": "2017",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "E. Khalil, H. Dai, Y. Zhang, B. Dilkina, and L. Song",
      "orig_title": "Learning combinatorial optimization algorithms over graphs",
      "paper_id": "1704.01665v4"
    },
    {
      "index": 6,
      "title": "Reinforcement Learning for Solving the Vehicle Routing Problem",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "M. Nazari, A. Oroojlooy, L. Snyder, and M. Tak√°c",
      "orig_title": "Reinforcement learning for solving the vehicle routing problem",
      "paper_id": "1802.04240v2"
    },
    {
      "index": 7,
      "title": "Learning to branch in mixed integer programming",
      "abstract": "",
      "year": "2016",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "E. Khalil, P. Le Bodic, L. Song, G. Nemhauser, and B. Dilkina"
    },
    {
      "index": 8,
      "title": "Reinforcement Learning for Integer Programming: Learning to Cut",
      "abstract": "",
      "year": "2020",
      "venue": "International Conference on Machine Learning",
      "authors": "Y. Tang, S. Agrawal, and Y. Faenza",
      "orig_title": "Reinforcement learning for integer programming: Learning to cut",
      "paper_id": "1906.04859v3"
    },
    {
      "index": 9,
      "title": "Pointer networks",
      "abstract": "",
      "year": "2015",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "O. Vinyals, M. Fortunato, and N. Jaitly"
    },
    {
      "index": 10,
      "title": "Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search",
      "abstract": "",
      "year": "2018",
      "venue": "Advances in Neural Information Processing Systems",
      "authors": "Z. Li, Q. Chen, and V. Koltun",
      "orig_title": "Combinatorial optimization with graph convolutional networks and guided tree search",
      "paper_id": "1810.10659v1"
    },
    {
      "index": 11,
      "title": "Learning a SAT solver from single-bit supervision",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "D. Selsam, M. Lamm, B. B√ºnz, P. Liang, L. de Moura, and D. L. Dill"
    },
    {
      "index": 12,
      "title": "Learning to Solve NP-Complete Problems: A Graph Neural Network for Decision TSP",
      "abstract": "",
      "year": "2019",
      "venue": "AAAI Conference on Artificial Intelligence",
      "authors": "M. Prates, P. H. Avelar, H. Lemos, L. C. Lamb, and M. Y. Vardi",
      "orig_title": "Learning to solve np-complete problems: A graph neural network for decision tsp",
      "paper_id": "1809.02721v3"
    },
    {
      "index": 13,
      "title": "Neural Combinatorial Optimization with Reinforcement Learning",
      "abstract": "",
      "year": "2017",
      "venue": "International Conference on Learning Representations Workshop",
      "authors": "I. Bello, H. Pham, Q. V. Le, M. Norouzi, and S. Bengio",
      "orig_title": "Neural combinatorial optimization with reinforcement learning",
      "paper_id": "1611.09940v3"
    },
    {
      "index": 14,
      "title": "A reinforcement learning approach to job-shop scheduling",
      "abstract": "",
      "year": "1995",
      "venue": "IJCAI",
      "authors": "W. Zhang and T. G. Dietterich"
    },
    {
      "index": 15,
      "title": "Learning heuristics over large graphs via deep reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "CoRR",
      "authors": "S. Manchanda, A. Mittal, A. Dhawan, S. Medya, S. Ranu, and A. K. Singh"
    },
    {
      "index": 16,
      "title": "Exploratory combinatorial optimization with reinforcement learning",
      "abstract": "",
      "year": "2020",
      "venue": "AAAI conference",
      "authors": "T. D. Barrett, W. R. Clements, J. N. Foerster, and A. I. Lvovsky"
    },
    {
      "index": 17,
      "title": "Attention, Learn to Solve Routing Problems!",
      "abstract": "",
      "year": "2019",
      "venue": "International Conference on Learning Representations",
      "authors": "W. Kool, H. van Hoof, and M. Welling",
      "orig_title": "Attention, learn to solve routing problems!",
      "paper_id": "1803.08475v3"
    },
    {
      "index": 18,
      "title": "Discriminative embeddings of latent variable models for structured data",
      "abstract": "",
      "year": "2016",
      "venue": "International conference on machine learning",
      "authors": "H. Dai, B. Dai, and L. Song"
    },
    {
      "index": 19,
      "title": "Machine learning for combinatorial optimization: a methodological tour d‚Äôhorizon",
      "abstract": "",
      "year": "2020",
      "venue": "European Journal of Operational Research",
      "authors": "Y. Bengio, A. Lodi, and A. Prouvost"
    },
    {
      "index": 20,
      "title": "‚Äúneural‚Äù computation of decisions in optimization problems",
      "abstract": "",
      "year": "1985",
      "venue": "Biological cybernetics",
      "authors": "J. J. Hopfield and D. W. Tank"
    },
    {
      "index": 21,
      "title": "On the stability of the travelling salesman problem algorithm of hopfield and tank",
      "abstract": "",
      "year": "1988",
      "venue": "Biological Cybernetics",
      "authors": "G. Wilson and G. Pawley"
    },
    {
      "index": 22,
      "title": "Sequence to sequence learning with neural networks",
      "abstract": "",
      "year": "2014",
      "venue": "Advances in neural information processing systems",
      "authors": "I. Sutskever, O. Vinyals, and Q. V. Le"
    },
    {
      "index": 23,
      "title": "Online vehicle routing with neural combinatorial optimization and deep reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "J. James, W. Yu, and J. Gu"
    },
    {
      "index": 24,
      "title": "A hybrid of deep reinforcement learning and local search for the vehicle routing problems",
      "abstract": "",
      "year": "2020",
      "venue": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "J. Zhao, M. Mao, X. Zhao, and J. Zou"
    },
    {
      "index": 25,
      "title": "Operating electric vehicle fleet for ride-hailing services with reinforcement learning",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "J. Shi, Y. Gao, W. Wang, N. Yu, and P. A. Ioannou"
    },
    {
      "index": 26,
      "title": "Reinforcement-learning-based cooperative adaptive cruise control of buses in the lincoln tunnel corridor with time-varying topology",
      "abstract": "",
      "year": "2019",
      "venue": "IEEE Transactions on Intelligent Transportation Systems",
      "authors": "W. Gao, J. Gao, K. Ozbay, and Z.-P. Jiang"
    },
    {
      "index": 27,
      "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Learning Representations",
      "authors": "D. Bahdanau, K. Cho, and Y. Bengio",
      "orig_title": "Neural machine translation by jointly learning to align and translate",
      "paper_id": "1409.0473v7"
    },
    {
      "index": 28,
      "title": "Neural machine translation and sequence-to-sequence models: A tutorial",
      "abstract": "",
      "year": "2017",
      "venue": "arXiv preprint arXiv:1703.01619",
      "authors": "G. Neubig"
    },
    {
      "index": 29,
      "title": "Adam: A method for stochastic optimization",
      "abstract": "",
      "year": "2015",
      "venue": "International Conference on Learning Representations",
      "authors": "D. P. Kingma and J. Ba"
    },
    {
      "index": 30,
      "title": "Algorithms for the vehicle routing and scheduling problems with time window constraints",
      "abstract": "",
      "year": "1987",
      "venue": "Operations research",
      "authors": "M. M. Solomon"
    },
    {
      "index": 31,
      "title": "Understanding the difficulty of training deep feedforward neural networks",
      "abstract": "",
      "year": "2010",
      "venue": "International conference on artificial intelligence and statistics",
      "authors": "X. Glorot and Y. Bengio"
    }
  ]
}