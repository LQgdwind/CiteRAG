{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Operational Collective Intelligence of Humans and Machines\n\nPaper Abstract: \n\nPaper Section Text:\nThe machine intelligence (i.e., algorithmic) factors of a successful OCI are subject to the same limitations as machine learning more generally: they perform best on well-defined tasks , when the environment is simple and stable [ref]4, and when high-quality training data are available . Operational scenarios are driven by the need for predictable, defined protocols for common occurrences, meaning that the task is generally well-defined for the machine intelligence that underpins ACF systems. However, one factor that could undermine them could also make OCI invaluable: the ability to handle exceptional task cases. Thus, a critical stage in developing OCI is engineering pathways into the ACF system for handling exceptions. One solution is to empower the ACF model with a classification tool for detecting exceptions  and passing exceptional cases off to human staff, who are typically better at handling them . Using operational scenarios is most common in stable, i.e., predictable, environments. However, stable and predictable does not necessarily mean an operational scenario is simple. Many operational scenarios exist as responses to complicated environments in which simplification can improve a given operation. Machine intelligence, at least historically, is not considered an applicable solution for tasks in complex settings, although given sufficient data and training resources, models are able to generalize their learning (e.g., ). Innovative modeling approaches in the space of neural-symbolic reasoning, however, may prove a solution for ACF in complex environments [ref]16. Access to high-quality, operation-relevant data is critical for training an ACF model. Data quality is simply the degree to which archived training data reflects the real world 2. Moreover, a training data set’s relevance is contingent on a given organization and the operational setting. For example, network intrusion detection is complicated by the fact that operational data from one network setting is rarely relevant to another, which creates a lack of training data . Although network data from other operational settings could be used to train a model, it likely will not reflect “the real world” in new network security settings, meaning it is poor-quality data. The impact of poor data quality on a given model is contingent on the type of model and the task at hand —if the cost of errors is low, then poor quality data may be a reasonable tool for getting a model established to facilitate collection of more relevant data . In the case of ACF, data quality may be the result of how the crowd was selected  . This suggests that an OCI may benefit from tools that allow it to select which training data are used for a given operational scenario. ACF models are subject to the same generalization challenges as other machine learning models. The models underpinning ACF typically adopt the classic statistical assumption of independent and identically distributed data (i.i.d.)—a very strong assumption that is made necessary by the intractable complexity of its absence. Out-of-Distribution (OOD) data, i.e., real-world data, can prove a significant challenge for these models. ML models for OOD data are still in their nascent phase, but improving , including in forecasting applications 0. Models that are able to handle OOD data that do not abide by the i.i.d. assumption will also prove a key MI factor of successful OCI.\n\nReference markers found: [4]\n\nContext windows for each [ref]:\n[ref]4: algorithmic) factors of a successful OCI are subject to the same limitations as machine learning more generally: they perform best on well-defined tasks , when the environment is simple and stable [ref]4, and when high-quality training data are available . Operational scenarios are driven by the need for predictable, defined protocols for common occurrences, meaning that the task is generally\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 4,\n            \"titles\": [\n                \"The Effects of Data Quality on Machine Learning Performance\",\n                \"Distilling the wisdom of crowds: Prediction markets vs. prediction polls\",\n                \"Hybrid forecasting of geopolitical events\",\n                \"The promise and peril of big data\",\n                \"What can machine learning do? workforce implications\",\n                \"Identifying expertise to extract the wisdom of crowds\",\n                \"Confidence in aggregation of opinions from multiple sources\",\n                \"Deep Reinforcement Learning from Human Preferences\",\n                \"Harnessing the wisdom of crowds\",\n                \"Clinical versus actuarial judgment\",\n                \"Hybrid intelligence\",\n                \"Algorithm aversion: people erroneously avoid algorithms after seeing them err\",\n                \"Human-machine hybrid prediction market: A promising sales forecasting solution for e-commerce enterprises\",\n                \"Military applications of machine learning: a bibliometric perspective\",\n                \"Vox populi\",\n                \"Neural-Symbolic Learning and Reasoning: A Survey and Interpretation\",\n                \"인공지능 기반 공격 그래프 생성\",\n                \"Measuring and predicting human trust in recommendations from an ai teammate\",\n                \"Comparing psychometric and behavioral predictors of compliance during human-ai interactions\",\n                \"Learning from class-imbalanced data: Review of methods and applications\",\n                \"Forecasting with big data: A review\",\n                \"Requirements for data quality metrics\",\n                \"Matrics: A system for human-machine hybrid forecasting of geopolitical events\",\n                \"Enabling on-line deliberation and collective decision-making through large-scale argumentation: a new approach to the design of an internet-based mass collaboration platform\",\n                \"Machine learning: Trends, perspectives, and prospects\",\n                \"Combining human and machine intelligence in large-scale crowdsourcing\",\n                \"Information aggregation and collective intelligence beyond the wisdom of crowds\",\n                \"Toward a research agenda in adversarial reasoning: Computational approaches to anticipating the opponent’s intent and actions\",\n                \"Automating hybrid collective intelligence in open-ended medical diagnostics\",\n                \"Collective wisdom: Old and new\",\n                \"Competing approaches to forecasting elections: Economic models, opinion polling and prediction markets\",\n                \"Collective Intelligence: Mankind’s Emerging World in Cyberspace\",\n                \"Cheaper and Better: Selecting Good Workers for Crowdsourcing\",\n                \"The wisdom of minority: Discovering and targeting the right group of workers for crowdsourcing\",\n                \"Towards out-of-distribution generalization: A survey\",\n                \"Algorithm appreciation: People prefer algorithmic to human judgment\",\n                \"How social influence can undermine the wisdom of crowd effect\",\n                \"The collective intelligence genome\",\n                \"The wisdom of select crowds\",\n                \"Psychological strategies for winning a geopolitical forecasting tournament\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]4 based on the context and research area of Operational Collective Intelligence of Humans and Machines. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}