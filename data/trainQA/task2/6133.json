{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Exploring the Landscape of Machine Unlearning: A Comprehensive Survey and Taxonomy\n\nPaper Abstract: \n\nPaper Section Text:\nThe concept of the “right to be forgotten” refers to the ability to have personal information removed from online search results and directories in certain situations . However, there is no consensus on its definition, or whether it should be classified as a human right. Nevertheless, various institutions and governments, such as those in Argentina, the European Union (EU), and the Philippines, are beginning to propose regulations around this issue 111https://link.library.eui.eu/portal/The-Right-To-Be-Forgotten–A-Comparative-Study/tw0VHCyGcDc/. Information and events from an individual’s past can continue to carry a stigma and lead to negative consequences, even after a considerable amount of time has passed. For example, in July 2018, Disney fired writer and director James Gunn, who was credited for much of the studio’s success with films such as “Guardians of the Galaxy”, after old tweets resurfaced containing dark humor about pedophilia and rape. Fans and actors rallied to Gunn’s defense, with an open letter calling for his reinstatement and petitions to rehire him . However, deleting what a person has posted on social media platforms such as Facebook and Instagram may not entirely remove the data from the Internet. Although Facebook launched a tool called “Off-Facebook Activity” to help users delete data that third-party apps and websites share with Facebook, it only de-links the data from the user. In 2014, a Spanish court ruled in favor of a man who requested that Google remove certain information about him from its search results . The court found that the information was no longer relevant or adequate, as the debt had been paid a long time before. The EU court also ruled that Google needed to remove the search results. The “right to be forgotten” is used to describe an individual’s right to request that their personal information be removed from the Internet, particularly search engine results, in certain cases . Supporters of this right argue that it is necessary to protect individuals from having past mistakes or personal information used against them, such as in cases of revenge porn, petty crimes, or unpaid debts. However, critics of this right claim that it infringes upon freedom of expression and the right to criticize. The EU has tried to address these concerns by striking a balance between the right to privacy and freedom of expression . The issue is further complicated by the use of ML, which can collect and analyze vast amounts of data indefinitely. This data can then be used in applications such as insurance, medical, and loan evaluations, leading to potential harm and amplifying existing biases. As such, it is important to consider the ethical implications of ML models and data collection in these contexts.\nWe generate a definition of MU based on a comprehensive review of existing research literature, including the studies in [ref]6  [ref]19  [ref]20  : General Definition: Machine unlearning is a concept that refers to the process of removing or “forgetting” previously learned information from a machine learning model. In essence, it is the opposite of machine learning; while machine learning is all about training models to recognize patterns and make predictions based on that data, machine unlearning aims to undo or reverse that process, by removing previously learned patterns or predictions that are no longer relevant or accurate. MU is an emerging field within the realm of artificial intelligence (AI) that seeks to remove specific data points from a model without compromising its performance. This technique, also known as selective amnesia , has a variety of potential applications, including enabling individuals to exercise their “right to be forgotten” and preventing AI models from inadvertently leaking sensitive information. MU can also help combat data poisoning and adversarial attacks. Through its application, MU has the following objectives: To address privacy concerns in ML by eliminating sensitive or personal data from the model without significantly reducing its performance. It is different from ML, which focuses on training models to predict outcomes based on input data. The works cited in this context include research on novel techniques for privacy-preserving ML, statistical methods for data protection, and adaptive algorithms that adjust to changing data privacy requirements           . To improve the accuracy and fairness of ML models by removing biases or correcting errors that may have been introduced during the learning process. This is typically done by analyzing the model’s performance on various metrics and identifying areas where improvement is needed. These works cover research on mitigating bias in machine learning models and techniques for improving fairness in algorithmic decision-making           . To improve the performance of ML models over time by allowing them to adapt to changing data and circumstances. By unlearning outdated or irrelevant information, ML models can become more accurate, efficient, and adaptable to new situations. The references cited in this context include studies on transfer learning, which involves applying knowledge from previously learned tasks to new problems        . Despite the significant investment that companies make in training and deploying large AI models, regulators in both the EU and the United States are cautioning that models trained on sensitive data may need to be removed. In a report focused on AI frameworks, the UK government explained that ML models may be subject to data deletion under the General Data Protection Regulation (GDPR). For instance, Paravision was recently found to have collected millions of facial photos inappropriately and was required by the US Federal Trade Commission to delete both the data and any trained models that relied on it 222https://www.wired.com/story/startup-nix-algorithms-ill-gotten-facial-data/. The most straightforward strategy for removing a data point from training data and updating the model is to conduct retraining . Unfortunately, this procedure incurs considerable costs, as exemplified by OpenAI’s reported expenses of up to 20 million dollars to train GPT-3 . Hence, there is a need for more cost-effective and efficient methods to address data point removal in ML models. The challenge is to balance privacy and the right to expression to prevent the right to be forgotten from becoming a form of censorship . Balancing privacy and the right to expression is crucial in implementing the right to be forgotten without this process being misused. The emergence of new technologies, such as blockchain, presents new challenges in maintaining this balance. Furthermore, the increasing public sensitivity toward data privacy has prompted many companies to prioritize user privacy. For example, Google recently announced an expanded policy for US citizens to remove personal data from search results333https://techcrunch.com/2022/09/28/google-rolls-out-tool-to-request-removal-of-personal-info-from-search-results-will-later-add-proactive-alerts/. However, when data points are eliminated, the AI models trained on them need to be appropriately cleaned up to avoid perpetuating biased or sensitive information. While MU is a complex challenge, various approaches are being tested and developed to address this issue. As regulations on data privacy increase, MU is expected to play a critical role in ensuring that AI models are transparent and ethical.\n\nReference markers found: [6]\n\nContext windows for each [ref]:\n[ref]6: the ethical implications of ML models and data collection in these contexts.\nWe generate a definition of MU based on a comprehensive review of existing research literature, including the studies in [ref]6  [ref]19  [ref]20  : General Definition: Machine unlearning is a concept that refers to the process of removing or “forgetting” previously learned information from a machine learning model. In\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 6,\n            \"titles\": [\n                \"Verifiable and Provably Secure Machine Unlearning\",\n                \"Machine learning: Algorithms, real-world applications and research directions\",\n                \"The potential for artificial intelligence in healthcare\",\n                \"Machine learning and deep learning\",\n                \"Approximate data deletion from machine learning models\",\n                \"A Review on Machine Unlearning\",\n                \"Towards making systems forget with machine unlearning\",\n                \"A Survey of Machine Unlearning\",\n                \"Remember what you want to forget: Algorithms for machine unlearning\",\n                \"Deep unlearning via randomized conditionally independent hessians\",\n                \"Medroberta. nl: a language model for dutch electronic health records\",\n                \"Markov Chain Monte Carlo-Based Machine Unlearning: Unlearning What Needs to be Forgotten\",\n                \"Preserving personal dignity: the vital role of the right to be forgotten\",\n                \"Decision making within a cancel culture environment\",\n                \"The right to be forgotten is taking shape: Cjeu judgments in gc and others (c-136/17) and google v cnil (c-507/17)\",\n                \"Humans forget, machines remember: Artificial intelligence and the right to be forgotten\",\n                \"The european union general data protection regulation: what it is and what it means\",\n                \"Machine unlearning\",\n                \"Coded machine unlearning\",\n                \"Machine Unlearning for Random Forests\",\n                \"Adaptive Machine Unlearning\",\n                \"Fast Yet Effective Machine Unlearning\",\n                \"Can ai learn to forget?\",\n                \"Novel neural network repair methods for data privacy and individual fairness\",\n                \"A statistical framework for differential privacy\",\n                \"Adaptive laplace mechanism: Differential privacy preservation in deep learning\",\n                \"Proactively control privacy in recommender systems\",\n                \"Understanding and Measuring Privacy Risks in Machine Learning\",\n                \"Towards improving privacy of synthetic datasets\",\n                \"Consent management platforms under the gdpr: processors and/or controllers?\",\n                \"Personal data vulnerability: Constitutional issues with the california consumer privacy act\",\n                \"“it wouldn’t happen to me”: Privacy concerns and perspectives following the cambridge analytica scandal\",\n                \"Privacy laws and privacy by design schemes for the internet of things\",\n                \"Analyzing privacy and end user information exposure in digital communication environments\",\n                \"Discover and Mitigate Unknown Biases with Debiasing Alternate Networks\",\n                \"A high-bias, low-variance introduction to Machine Learning for physicists\",\n                \"Biased against debiasing: On the role of (institutionally sponsored) self-transformation in the struggle against prejudice\",\n                \"FedHarmony: Unlearning Scanner Bias with Distributed Data\",\n                \"TRAPDOOR: Repurposing backdoors to detect dataset bias in machine learning-based genomic analysis\",\n                \"Learning to Unlearn: Building Immunity to Dataset Bias in Medical Imaging Studies\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]6 based on the context and research area of Exploring the Landscape of Machine Unlearning: A Comprehensive Survey and Taxonomy. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}