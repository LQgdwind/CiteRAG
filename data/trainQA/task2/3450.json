{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Towards Continuous Consistency Axiom\n\nPaper Abstract: \n\nPaper Section Text:\nThe attempts to axiomatize the domain of clustering have a rich history.\nVan Laarhoven and Marchiori\n and Ben-David and Ackerman \nthe clustering axiomatic frameworks address either:\n(1) required properties of clustering functions, or\n(2) required properties of the values of a clustering quality function,\nor\n(3) required properties of the relation between qualities of different partitions.\n The work of Kleinberg[ref]18, which we discussed extensively, fits into the first category. Van Laarhoven and Marchiori \ndeveloped an axiomatic system for graphs, fitting the same category. Though it is possible to view the datapoints in ‚Ñùmsuperscript‚Ñùùëö\\mathbb{R}^{m} as nodes of a graph connected by edges with appropriate weights, their axioms essentially reflect the axioms of Kleinberg with all the problems for kùëòk-means like algorithms. To overcome the problems with the consistency property,\nAckerman et al. \npropose\nsplitting of it into\nthe concept of outer-consistency and of inner-consistency.\nHowever,\nthe kùëòk-means algorithm is not inner-consistent, see [3, Section 3.1].\nWe show that the problem with inner-consistency is much deeper, as\nit may be not applicable at all Theorem 16 and Theorem 17). The kùëòk-means algorithm is said to be in this sense outer-consistent [3, Section 5.2].\nBut we have demonstrated in this paper that outer-consistency constitutes a problem in the Euclidean space, if continuous transformations are required, see Theorem 20. They claim also that\nkùëòk\n-means-ideal has the properties of outer-consistency and locality555\nA clustering function clustering into kùëòk clusters has the locality property,\nif whenever a set SùëÜS for a given kùëòk is clustered by it into the partition ŒìŒì\\Gamma,\nand we take a subset Œì‚Ä≤‚äÇŒìsuperscriptŒì‚Ä≤Œì\\Gamma^{\\prime}\\subset\\Gamma with |Œì‚Ä≤|=k‚Ä≤<ksuperscriptŒì‚Ä≤superscriptùëò‚Ä≤ùëò|\\Gamma^{\\prime}|=k^{\\prime}<k,\nthen clustering of ‚à™C‚ààŒì‚Ä≤subscriptùê∂superscriptŒì‚Ä≤\\cup_{C\\in\\Gamma^{\\prime}} into k‚Ä≤superscriptùëò‚Ä≤k^{\\prime} clusters will yield exactly Œì‚Ä≤superscriptŒì‚Ä≤\\Gamma^{\\prime}.\n.\nThe property of locality would be useful for generation of testing sets for clustering function implementation.\nAckerman at el  show that these properties are satisfied neither by\nkùëòk-means-random nor by a kùëòk-means with furthest element initialization. The mentioned properties cannot be fulfilled by any algorithm under fixed-dimensional settings.\nSo they do so for kùëòk-means-ideal. Zadeh Ben-David 7 propose instead the\norder-consistency, satisfied by some versions of single-linkage algorithm, providing with an elegant way of creating multitude of derived test sets.\nkùëòk-means is not order-consistent so that the property is not useful for continuous test data transformations for kùëòk-means. Ackerman and Ben-David\n pursue the second category of approaches to axiomatization.\nInstead of axiomatizaing the clustering function, they create axioms for cluster quality function. Let ‚Ñ≠‚Äã(ùêó)‚Ñ≠ùêó\\mathfrak{C}(\\mathbf{X}) be the set of all possible partitions\nover the set of objects ùêóùêó\\mathbf{X},\nand let ùîá‚Äã(ùêó)ùîáùêó\\mathfrak{D}(\\mathbf{X}) be the set of all possible distance functions\nover the set of objects ùêóùêó\\mathbf{X}.\nA clustering-quality measure (CQM) J:ùêó√ó‚Ñ≠‚Äã(ùêó)√óùîá‚Äã(ùêó)‚Üí‚Ñù+‚à™{0}:ùêΩ‚Üíùêó‚Ñ≠ùêóùîáùêósuperscript‚Ñù0J:\\mathbf{X}\\times\\mathfrak{C}(\\mathbf{X})\\times\\mathfrak{D}(\\mathbf{X})\\rightarrow\\mathbb{R}^{+}\\cup\\{0\\}\nis a function that, given a data set (with a distance function) and its partition\ninto clusters, returns a non-negative real number representing how strong or\nconclusive the clustering is. Ackerman and Ben-David propose among others the following axioms: (CQM-scale-invariance) A quality measure JùêΩJ satisfies scale invariance if for every clustering\nŒìŒì\\Gamma of (X,d)ùëãùëë(X,d) and every positive Œ≤ùõΩ\\beta, J‚Äã(X,Œì,d)=J‚Äã(X,Œì,Œ≤‚Äãd)ùêΩùëãŒìùëëùêΩùëãŒìùõΩùëëJ(X,\\Gamma,d)=J(X,\\Gamma,\\beta d). (CQM-consistency) A quality measure JùêΩJ satisfies consistency if for every clustering ùíûùíû\\mathcal{C} over\n(X,d)ùëãùëë(X,d), whenever d‚Ä≤superscriptùëë‚Ä≤d^{\\prime} is consistency-transformation of dùëëd, then J‚Äã(X,Œì,d‚Ä≤)‚â•J‚Äã(X,Œì,d)ùêΩùëãŒìsuperscriptùëë‚Ä≤ùêΩùëãŒìùëëJ(X,\\Gamma,d^{\\prime})\\geq J(X,\\Gamma,d). If we define a clustering function fùëìf to maximize the quality function, then\nthe clustering function is (scale)-invariant, but\nthe clustering function does not need to be consistent in Kleinberg‚Äôs sense.\nE.g. kùëòk-means is CQM-consistent, not being consistent in Kleinberg‚Äôs sense. . The basic problem with this axiomatic set is that the CQM-consistency does not tell anything about the (optimal) partition being the result of the consistency-transform, while Kleinberg‚Äôs axioms make a definitive statement: the partition before and after consistency-transform has to be the same.\nSo kùëòk-means could be in particular rendered to become\nCQM-consistent, CQM-scale-invariant, and CQM-rich, if one applies\na bi-sectional version\n(bisectional-a‚Äãu‚Äãt‚Äãoùëéùë¢ùë°ùëúauto-means). A number of further characterizations of clustering functions has been proposed\ne.g. Ackerman‚Äôs at al.  for linkage algorithms,\nCarlsson‚Äôs  for multiscale clustering.\nNone of the transforms proposed there seems however to fit the purpose of test set derivation for kùëòk-means testing by a continuous derivation. An interesting axiomatic system for hierarchical clustering was developed in 3. It is defined not for datapoints but for probability distributions over some support(s). It includes a scale invariance property, but provides nothing that can be considered as corresponding to Kleinberg‚Äôs consistency. This clearly limits the usability for test set generation for (hierarchical) clustering algorithms. Nonetheless this approach is worth noting and worth pursuing for non-hierarchical clustering functions like kùëòk-means for two reasons: (1) kùëòk-means not only splits the data themselves but also the Euclidean spce as such, (2) kùëòk-means is probabilistic in nature and rather than exact re-clustering of data one should pay attention to recovery of appropriately defined probability distributions over the space (3) the concepts of centric consistency and that of motion consistency are applicable to probability distributions over finite support. So it may constitute a research path worthy further exploration. Puzicha et al. 9 propose an axiomatic system in which the data can be transformed by shifting the entire data set (and not the individual clusters). In our approach, individual clusters may be subject to shifts. Strazzeri et al. 2 introduced the axiom of monotonic consistency to replace Kleinberg‚Äôs consistency axiom. He requires that, for an expansion function (monotonically increasing) ŒΩ::[0;‚àû1)‚Üí[0;‚àû)\\nu::[0;\\infty 1)\\rightarrow[0;\\infty),\neach intercluster distance dùëëd is changed to d‚Ä≤=ŒΩ‚Äã(d)superscriptùëë‚Ä≤ùúàùëëd^{\\prime}=\\nu(d) and each intracluster distance dùëëd is changed to d‚Ä≤=ŒΩ‚àí1‚Äã(d)superscriptùëë‚Ä≤superscriptùúà1ùëëd^{\\prime}=\\nu^{-1}(d).\nThis transform, though it is non-linear on the one hand, is more rigid than our centric consistency and motion consistency transforms, as it has to apply globally, and not locally to a cluster, and on the other hand, it is designed and applicable for graphs, but not for ‚Ñùmsuperscript‚Ñùùëö\\mathbb{R}^{m} except for special cases. Addad  proposed the following modification of the Kleinberg‚Äôs consistency axiom.\nLet O‚ÄãP‚ÄãT‚Äã(k)ùëÇùëÉùëáùëòOPT(k) be the optimal value of a cost function when clustering into kùëòk parts. Let k‚àósuperscriptùëòk^{*} the kùëòk maximizing quotient O‚ÄãP‚ÄãT‚Äã(k)/O‚ÄãP‚ÄãT‚Äã(k‚àí1)ùëÇùëÉùëáùëòùëÇùëÉùëáùëò1OPT(k)/OPT(k-1)\nThen their refined consistency requires that the Kleinberg‚Äôs consistency transform yields the same clustering only if k‚àósuperscriptùëòk^{*} prior and after the transform agree.\nThey prove that single link and kùëòk-means fulfil the refined consistency axiom (the latter under some ‚Äùbalance‚Äù requirements).\nWhile the refined consistency transform (identical to Kleinberg‚Äôs consistency transform) is much more flexible in generating derived test sets, it is in practice hard to test whether or not a given transform produces identically clusterable datasets. Ackerman et al.  consider a different way of deriving new samples from old ones, re-weighting of datapoints. It turns out that some algorithms are sensitive to re-weighting, other are robust. Regrettably, kùëòk-means is sensitive so that the method cannot be applied to derive new clustering test datasets from existent ones. A discussion and critics of various approaches to axiomatic systems for clustering can be found in .\n\nReference markers found: [18]\n\nContext windows for each [ref]:\n[ref]18: functions, or\n(2) required properties of the values of a clustering quality function,\nor\n(3) required properties of the relation between qualities of different partitions.\n The work of Kleinberg[ref]18, which we discussed extensively, fits into the first category. Van Laarhoven and Marchiori \ndeveloped an axiomatic system for graphs, fitting the same category. Though it is possible to view\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 18,\n            \"titles\": [\n                \"On the Consistency of ùëò-means++ algorithm\",\n                \"Towards theoretical foundations of clustering\",\n                \"Characterization of linkage-based clustering\",\n                \"Towards property-based classification of clustering paradigms\",\n                \"Weighted clustering: Towards solving the user‚Äôs dilemma\",\n                \"Center-based clustering under perturbation stability\",\n                \"Clustering under perturbation resilience\",\n                \"Measures of clustering quality: A working set of axioms for clustering\",\n                \"Persistent clustering and a theorem of j. kleinberg\",\n                \"Characterization, stability and convergence of hierarchical clustering methods\",\n                \"Revolt: Collaborative crowdsourcing for labeling machine learning datasets\",\n                \"Combining partitional and hierarchical algorithms for robust and efficient data clustering with cohesion self-merging\",\n                \"Clustering redemption‚Äìbeyond the impossibility of kleinberg‚Äôs axioms\",\n                \"Pattern Classification\",\n                \"Clustering axioms\",\n                \"What are the true clusters?\",\n                \"Computer science theory for the information age\",\n                \"Mdcgen: Multidimensional dataset generator for clustering\",\n                \"An impossibility theorem for clustering\",\n                \"A feasible k-means kernel trick under non-euclidean feature space\",\n                \"In-the-limit clustering axioms\",\n                \"kùëòk-means cluster shape implications\",\n                \"A multi-prototype clustering algorithm\",\n                \"Some methods for classification and analysis of multivariate observations\",\n                \"Foundations of perturbation robust clustering\",\n                \"Kmlocal: A testbed for k-means clustering algorithms\",\n                \"K-multiple-means: A multiple-means clustering method with specified k clusters\",\n                \"Strong consistency of k‚Äìmeans clustering\",\n                \"A theory of proximity based clustering: Structure detection by optimization\",\n                \"A knowledge-based approach to pattern clustering\",\n                \"A comparison of document clustering techniques\",\n                \"Possibility Results for Graph Clustering: A Novel Consistency Axiom\",\n                \"Towards an axiomatic approach to hierarchical clustering of measures\",\n                \"Axioms for graph clustering quality functions\",\n                \"Modern Clustering Algorithms\",\n                \"A formalization of cluster analysis\",\n                \"A uniqueness theorem for clustering\",\n                \"Communities in Preference Networks: Refined Axioms and Beyond\",\n                \"Generated Reference Title 38 for [ref]18\",\n                \"Generated Reference Title 39 for [ref]18\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]18 based on the context and research area of Towards Continuous Consistency Axiom. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}