{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Image-Guided Navigation of a Robotic Ultrasound Probe for Autonomous Spinal Sonography Using a Shadow-aware Dual-Agent Framework\n\nPaper Abstract: \n\nPaper Section Text:\nIn the RL framework, an agent learns the behavior policy by interacting with the environment through a sequence of states, actions and rewards. Here, we formulate the task of the US acquisition robot to observe US images and navigate the probe toward a target standard view as a partially observed sequential decision making problem in the RL framework. States and observations.\nThe full state of the probe-holding agent can be represented as (ğ“PW,ğ“GW,I,Ig)superscriptsubscriptğ“ğ‘ƒğ‘Šsuperscriptsubscriptğ“ğºğ‘Šğ¼subscriptğ¼ğ‘”(\\prescript{W}{P}{\\mathbf{T}},\\prescript{W}{G}{\\mathbf{T}},I,I_{g}), indicating the current and goal probe poses and the corresponding US images, as described in SectionÂ III-A. We assume that the patient anatomy and the relative pose between the robot and the patient are unknown. Therefore, the goal probe pose and image are unobservable to the agent, and the agent can only observe the acquired US image Iğ¼I and make navigation decisions. We use a sequence of 444 consecutive US frames acquired by the agent recently as the observation at time tğ‘¡t: st=[Itâˆ’3,â‹¯,It]subscriptğ‘ ğ‘¡subscriptğ¼ğ‘¡3â‹¯subscriptğ¼ğ‘¡s_{t}=[I_{t-3},\\cdots,I_{t}] to make use of the dynamic information, similar to . Navigation actions.\nThe policy of the RL agent Ï€:stâ†¦at:ğœ‹maps-tosubscriptğ‘ ğ‘¡subscriptğ‘ğ‘¡\\pi\\colon s_{t}\\mapsto a_{t} maps from the current observation stsubscriptğ‘ ğ‘¡s_{t} to a navigation action atsubscriptğ‘ğ‘¡a_{t}. In order to make the learned actions more versatile and independent of the actual patient position and orientation, different from previous methods that represent the actions in the world frame [ref]29[ref]30, we follow a probe-centric parameterization and define the navigation action ağ‘a as a transformation operator ğ“Psuperscriptğ“ğ‘ƒ\\prescript{P}{}{\\mathbf{T}} with respect to the probe frame {P}ğ‘ƒ\\{P\\}, so that the probe is moved by Since ğ“Psuperscriptğ“ğ‘ƒ\\prescript{P}{}{\\mathbf{T}} contains 161616 parameters under constraints to represent a valid transformation, directly learning these parameters will be intractable and the interpretability of the learned policy will be limited. Also, a small change of the parameters may result in an abrupt change of the probe pose, which is not favorable in the US probe navigation task. To address these issues, we discretize the action space into 101010 action primitives associated with 555 DOFs of the probe, as shown in Fig. 2 (b). Four actions represent the translation of the probe along Â±xplus-or-minusğ‘¥\\pm x, Â±yplus-or-minusğ‘¦\\pm y axes of the probe, and six actions represent the rotation around Â±xplus-or-minusğ‘¥\\pm x, Â±yplus-or-minusğ‘¦\\pm y, Â±zplus-or-minusğ‘§\\pm z axes of the probe.\nWe adopt hierarchical action steps to navigate the probe in a coarse-to-fine manner, similar to . Specifically, the action step dsâ€‹tâ€‹eâ€‹psubscriptğ‘‘ğ‘ ğ‘¡ğ‘’ğ‘d_{step} and Î¸sâ€‹tâ€‹eâ€‹psubscriptğœƒğ‘ ğ‘¡ğ‘’ğ‘\\theta_{step} are initialized as 5â€‹mâ€‹m/5âˆ˜5ğ‘šğ‘šsuperscript55mm/5^{\\circ}. 303030 most recent probe poses are stored in a buffer with the format of (ğ’‘t,ğ’’t)subscriptğ’‘ğ‘¡subscriptğ’’ğ‘¡(\\boldsymbol{p}_{t},\\boldsymbol{q}_{t}), where ğ’‘tsubscriptğ’‘ğ‘¡\\boldsymbol{p}_{t} is the position of the probe at time tğ‘¡t and ğ’’tsubscriptğ’’ğ‘¡\\boldsymbol{q}_{t} is the quaternion representation of the probe orientation. If at least 333 pairs among the 303030 most recent probe poses have a pairwise Euclidean distance smaller than 0.010.010.01, the probe pose is assumed to have converged and the action step will be decreased by 1â€‹mâ€‹m/1âˆ˜1ğ‘šğ‘šsuperscript11mm/1^{\\circ}. State transition under constraints.\nDifferent from previous work that directly apply the navigation action selected by the agent [ref]29[ref]30, we take into account some safety-related environment constraints in real-world US scans to update the probe pose, as shown in Fig. 2.\nFirst, we consider the practical requirement that the probe be placed over the skin surface to ensure good acoustic coupling. Since the virtual patient in our simulation is roughly parallel with the horizontal plane (see SectionÂ III-A), we use 111-DOF translational movement of the probe in the Â±zplus-or-minusğ‘§\\pm z direction to follow the patient surface z=fâ€‹(x,y)ğ‘§ğ‘“ğ‘¥ğ‘¦z=f(x,y).\nSecond, to ensure good probe-patient contact and guarantee patient safety, the tilt angle of the probe (angle between the imaging plane and the vertical direction) should be limited. Therefore, after the new probe orientation is calculated, the tilt angle is calculated as where ğ’›^psubscript^ğ’›ğ‘\\hat{\\boldsymbol{z}}_{p} is a unit vector along the zğ‘§z-axis of the probe.\nWe limit the tilt angle to be smaller than 30âˆ˜superscript3030^{\\circ}. If Î±>30âˆ˜ğ›¼superscript30\\alpha>30^{\\circ}, the probe orientation will not be updated. After the new probe pose is determined under the above constraints, a new US image can be acquired from the virtual patient, and the state of the probe will be updated. Reward.\nIn our task, the reward function used for RL training should encourage the agent to minimize the distance to goal, which can be represented by where âˆ¥â‹…âˆ¥2\\left\\|\\cdot\\right\\|_{2} is the L2 norm and âŸ¨â‹…,â‹…âŸ©â‹…â‹…\\langle\\cdot,\\cdot\\rangle is the inner product. By definition, dtsubscriptğ‘‘ğ‘¡d_{t} measures the Euclidean distance between the current probe position and the goal position at time tğ‘¡t, and Î¸tsubscriptğœƒğ‘¡\\theta_{t} is the minimum angle required to rotate from the current probe orientation to the goal orientation. Some methods construct a dense reward function by classifying the actions as â€œgoodâ€ (moving closer to the goal) or â€œbadâ€ (moving away from the goal), and assigning rewards with manually set values [ref]29[ref]30. Similar to , we design the navigation reward at time tğ‘¡t to be proportional to the amount of pose improvement normalized by the action steps Note that rnâ€‹aâ€‹v,tâˆˆ[âˆ’1,1]subscriptğ‘Ÿğ‘›ğ‘ğ‘£ğ‘¡11r_{nav,t}\\in[-1,1] since the action in each step is either translation or rotation.\nIn addition, we assign a high reward (+1010+10) for task accomplishment (dtâ‰¤1â€‹mâ€‹mâ€‹andÂ â€‹Î¸tâ‰¤1âˆ˜subscriptğ‘‘ğ‘¡1ğ‘šğ‘šandÂ subscriptğœƒğ‘¡superscript1d_{t}\\leq 1mm\\ \\text{and }\\theta_{t}\\leq 1^{\\circ}) and add some penalties based on the safety-related constraints. When the tilt angle of the probe Î±ğ›¼\\alpha exceeds 30âˆ˜superscript3030^{\\circ}, the agent will receive a penalty of âˆ’0.50.5-0.5. When the probe moves outside the patient volume (the proportion of pixels with non-zero gray value in Itsubscriptğ¼ğ‘¡I_{t} is less than 30%percent3030\\%), the agent will get a reward of âˆ’11-1. In summary, the reward at time step tğ‘¡t is defined as Termination conditions.\nDuring training, we define four conditions to terminate the navigation: (i) the goal is reached; (ii) the number of steps exceeds the maximum limit (e.g., 120120120); (iii) the action step is decreased to zero; and (iv) the probe moves out of the patient. Only the last three conditions are used during inference, since the true location of the standard plane is assumed unknown to the agent.\n\nReference markers found: [29]\n\nContext windows for each [ref]:\n[ref]29: In order to make the learned actions more versatile and independent of the actual patient position and orientation, different from previous methods that represent the actions in the world frame [ref]29[ref]30, we follow a probe-centric parameterization and define the navigation action ağ‘a as a transformation operator ğ“Psuperscriptğ“ğ‘ƒ\\prescript{P}{}{\\mathbf{T}} with respect to the probe frame\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 29,\n            \"titles\": [\n                \"Ultrasound-Guided Robotic Navigation with Deep Reinforcement Learning\",\n                \"A review of diagnostic ultrasound of the spine and soft tissue.\",\n                \"Sonographically guided lumbar spine procedures\",\n                \"Ultrasound for lumbar spinal procedures.\",\n                \"Intraoperative spine ultrasound: application and benefits\",\n                \"SonoNet: Real-Time Detection and Localisation of Fetal Standard Scan Planes in Freehand Ultrasound\",\n                \"Sonoanatomy of the spine: A comprehensive scanning protocol from cervical to sacral region\",\n                \"Spinal Sonography and Applications of Ultrasound for Central Neuraxial Blocks\",\n                \"Sonoanatomy relevant for ultrasound-guided central neuraxial blocks via the paramedian approach in the lumbar region\",\n                \"Ultrasound-guided lumbar central neuraxial block\",\n                \"The nature, cause, and extent of occupational musculoskeletal injuries among sonographers: recommendations for treatment and prevention\",\n                \"Operator dependence of physician-performed whole-breast us: lesion detection and characterization\",\n                \"Combating covid-19â€”the role of robotics in managing public health and infectious diseases\",\n                \"An overview of systems and techniques for autonomous robotic ultrasound acquisitions\",\n                \"Sarl: Deep reinforcement learning based human-aware navigation for mobile robot in indoor environments\",\n                \"Deep learning in medical ultrasound analysis: a review\",\n                \"Automated 3d ultrasound biometry planes extraction for first trimester fetal assessment\",\n                \"Automated abdominal plane and circumference estimation in 3d us for fetal screening\",\n                \"Standard Plane Detection in 3D Fetal Ultrasound Using an Iterative Transformation Network\",\n                \"Automatic View Planning with Multi-scale Deep Reinforcement Learning Agents\",\n                \"Agent with Warm Start and Active Termination for Plane Localization in 3D Ultrasound\",\n                \"Towards mri-based autonomous robotic us acquisitions: a first feasibility study\",\n                \"Fully automatic three-dimensional ultrasound imaging based on conventional b-scan\",\n                \"Autonomic robotic ultrasound imaging system based on reinforcement learning\",\n                \"Ultrasound is superior to palpation in identifying the cricothyroid membrane in subjects with poorly defined neck landmarks: a randomized clinical trial\",\n                \"Intensity-based visual servoing for instrument and tissue tracking in 3d ultrasound volumes\",\n                \"Implementation of an automatic scanning and detection algorithm for the carotid artery by an assisted-robotic measurement system\",\n                \"Automatic Probe Movement Guidance for Freehand Obstetric Ultrasound\",\n                \"Imitation learning: A survey of learning methods\",\n                \"Straight to the point: reinforcement learning for user guidance in ultrasound\",\n                \"Autonomous Navigation of an Ultrasound Probe Towards Standard Scan Planes with Deep Reinforcement Learning\",\n                \"Plus: Open-source toolkit for ultrasound-guided intervention systems\",\n                \"Development of a portable 3d ultrasound imaging system for musculoskeletal tissues\",\n                \"Human-level control through deep reinforcement learning\",\n                \"Network in network\",\n                \"Adam: A method for stochastic optimization\",\n                \"Ultrasound confidence maps using random walks\",\n                \"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\n                \"Imagenet: A large-scale hierarchical image database\",\n                \"Automatic force-compliant robotic ultrasound screening of abdominal aortic aneurysms\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]29 based on the context and research area of Image-Guided Navigation of a Robotic Ultrasound Probe for Autonomous Spinal Sonography Using a Shadow-aware Dual-Agent Framework. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}