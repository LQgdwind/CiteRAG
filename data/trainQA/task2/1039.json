{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: A Framework to Quantify Approximate Simulation on Graph Data\n\nPaper Abstract: \n\nPaper Section Text:\nIn this subsection, we used three case studies to exhibit the potential of ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} in the applications of pattern matching, node similarity measurement and RDF graph alignment. We will demonstrate the following strengths of our framework. Our ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} framework quantifies the degree of simulation, which remedies the coarse â€œyes-or-noâ€ semantics of simulation, significantly improves the effectiveness, and expand the scope of applying simulation. When multiple simulation variants are suitable for a certain application, the ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} framework provides a flexible way to experiment with all suitable variants, so as to determine the one that performs the best.\n Before simply driving into the case studies, the first question to answer is: which simulation variant should be used for a given application? We discuss the answer intuitively. Subgraph pattern matching is essentially asymmetric (matching the pattern graph to the data graph but not the other way around), and thus ğ–¥ğ–²ğ—‚ğ—†ğ—Œsubscriptğ–¥ğ–²ğ—‚ğ—†ğ—Œ{\\mathsf{FSim}}_{{\\mathsf{s}}} and ğ–¥ğ–²ğ—‚ğ—†ğ–½ğ—‰subscriptğ–¥ğ–²ğ—‚ğ—†ğ–½ğ—‰{\\mathsf{FSim}}_{{\\mathsf{dp}}} are appropriate choices. Node similarity measurement and graph alignment require symmetry, and hence ğ–¥ğ–²ğ—‚ğ—†ğ–»subscriptğ–¥ğ–²ğ—‚ğ—†ğ–»{\\mathsf{FSim}}_{{\\mathsf{b}}} and ğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒsubscriptğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒ{\\mathsf{FSim}}_{{\\mathsf{bj}}} are applied. The codes of all the baselines were provided by the respective authors. â„’â€‹(â‹…)â„’â‹…\\mathcal{L}(\\cdot) was used indicator function since the semantics of node labels in the studied data were clear and without ambiguity. Pattern Matching. In this case study, we first considered strong simulation (exact simulation by nature, ) and ğ–½ğ—‰ğ–½ğ—‰{\\mathsf{dp}}-simulation  as two baselines, and compared them with ğ–¥ğ–²ğ—‚ğ—†ğ—Œsubscriptğ–¥ğ–²ğ—‚ğ—†ğ—Œ{\\mathsf{FSim}}_{{\\mathsf{s}}} and ğ–¥ğ–²ğ—‚ğ—†ğ–½ğ—‰subscriptğ–¥ğ–²ğ—‚ğ—†ğ–½ğ—‰{\\mathsf{FSim}}_{{\\mathsf{dp}}} to illustrate how ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} facilitates pattern matching. FigureÂ 10 shows two example matches on the Amazon graph (see TableÂ 4 for graph statistics). When answering query Q1subscriptğ‘„1Q_{1}, strong simulation (and ğ–½ğ—‰ğ–½ğ—‰{\\mathsf{dp}}-simulation) returns G1subscriptğº1G_{1}, pictured in FigureÂ 10(b), which is also the top-1 result of ğ–¥ğ–²ğ—‚ğ—†ğ—Œsubscriptğ–¥ğ–²ğ—‚ğ—†ğ—Œ{\\mathsf{FSim}}_{\\mathsf{s}} (and ğ–¥ğ–²ğ—‚ğ—†ğ–½ğ—‰subscriptğ–¥ğ–²ğ—‚ğ—†ğ–½ğ—‰{\\mathsf{FSim}}_{{\\mathsf{dp}}}). Clearly, a simulation relation exists between Q1subscriptğ‘„1Q_{1} and G1subscriptğº1G_{1}, and ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} captures G1subscriptğº1G_{1} with the highest score because of simulation definiteness (DefinitionÂ 4). Q2subscriptğ‘„2Q_{2} adds two extra nodes with new labels to Q1subscriptğ‘„1Q_{1} but, with this modification, both strong simulation and ğ–½ğ—‰ğ–½ğ—‰{\\mathsf{dp}}-simulation fail to return a result while ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} returns G2subscriptğº2G_{2} (strength S1), which closely matches Q2subscriptğ‘„2Q_{2} by missing only an edge. For a more complete study, we also compared the results of ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} with some other approximate pattern matching algorithms. The related algorithms can be summarized in two categories: (1) the edit-distance based algorithms, e.g., ğ–²ğ– ğ–¯ğ–¯ğ–¤ğ–±ğ–²ğ– ğ–¯ğ–¯ğ–¤ğ–±\\mathsf{SAPPER}  and ğ–³ğ–²ğ—‰ğ–ºğ—‡ğ–³ğ–²ğ—‰ğ–ºğ—‡\\mathsf{TSpan} , which enumerate all matches with mismatched edges up to a given threshold; and (2) the similarity-based algorithms that compute matches based on (sub)graph similarity or node similarity. To name a few, G-Ray  computes the â€œgoodnessâ€ of a match based on node proximity. ğ–¨ğ—Œğ—ˆğ–±ğ–ºğ—‡ğ—„ğ–¨ğ—Œğ—ˆğ–±ğ–ºğ—‡ğ—„\\mathsf{IsoRank} , ğ–­ğ–¾ğ–¬ğ–ºğ–­ğ–¾ğ–¬ğ–º\\mathsf{NeMa}  and ğ–­ğ– ğ–¦ğ– ğ–­ğ– ğ–¦ğ– \\mathsf{NAGA}  find matches based on node similarity. ğ–¦ğ–¦\\mathsf{G}-ğ–¥ğ—‚ğ—‡ğ–½ğ–¾ğ—‹ğ–¥ğ—‚ğ—‡ğ–½ğ–¾ğ—‹\\mathsf{Finder}  and ğ–²ğ– ğ–¦ğ– ğ–²ğ– ğ–¦ğ– \\mathsf{SAGA}  design cost functions with multiple components to allow node mismatches and graph structural differences. ğ–²ğ–«ğ–°ğ–²ğ–«ğ–°\\mathsf{SLQ}  and S4superscriptğ‘†4S^{4}  find matches in RDF knowledge graphs by considering the semantics of queries. More specifically, S4superscriptğ‘†4S^{4} uses the semantic graph edit distance to integrate structure similarity and semantic similarity. Note that, in the Amazon graph, an edge from uğ‘¢u to vğ‘£v indicates that people are highly likely to buy item vğ‘£v after buying item uğ‘¢u , and hence there is no complex semantics among edges. As a result, we choose ğ–³ğ–²ğ—‰ğ–ºğ—‡ğ–³ğ–²ğ—‰ğ–ºğ—‡\\mathsf{TSpan}, ğ–­ğ– ğ–¦ğ– ğ–­ğ– ğ–¦ğ– \\mathsf{NAGA} and ğ–¦ğ–¦\\mathsf{G}-ğ–¥ğ—‚ğ—‡ğ–½ğ–¾ğ—‹ğ–¥ğ—‚ğ—‡ğ–½ğ–¾ğ—‹\\mathsf{Finder}, the state-of-the-art algorithms in each category, as another three baselines. We followed the state-of-the-art algorithm ğ–­ğ– ğ–¦ğ– ğ–­ğ– ğ–¦ğ– \\mathsf{NAGA}  for match generation and quality evaluation. Briefly, node pairs with high ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} scores are considered to be â€œseedsâ€, and matches are generated by expanding the regions around the â€œseedsâ€ subsequently. The evaluated queries are generated randomly by extracting subgraphs from the data graph and introducing structural noises (randomly insert edges, up to 33%) or label noises (randomly modify node labels, up to 33%). We then evaluated different algorithms across four query scenarios: (1) queries with no noises (ğ–¤ğ—‘ğ–ºğ–¼ğ—ğ–¤ğ—‘ğ–ºğ–¼ğ—\\mathsf{Exact}); (2) queries with structural noises only (ğ–­ğ—ˆğ—‚ğ—Œğ—’ğ–­ğ—ˆğ—‚ğ—Œğ—’\\mathsf{Noisy}-ğ–¤ğ–¤\\mathsf{E}); (3) queries with label noises only (ğ–­ğ—ˆğ—‚ğ—Œğ—’ğ–­ğ—ˆğ—‚ğ—Œğ—’\\mathsf{Noisy}-ğ–«ğ–«\\mathsf{L}); and (4) queries with both kinds of noises (ğ–¢ğ—ˆğ—†ğ–»ğ—‚ğ—‡ğ–¾ğ–½ğ–¢ğ—ˆğ—†ğ–»ğ—‚ğ—‡ğ–¾ğ–½\\mathsf{Combined}). Note that the queries are extracted from the graphs, which naturally serve as the â€œground truthâ€. Given a query Qğ‘„Q and a returned match Ï•italic-Ï•\\phi (we use top-1 match in this case study), the F1subscriptğ¹1F_{1} score is calculated by F1=2â‹…Pâ‹…R(P+R)subscriptğ¹1â‹…2ğ‘ƒğ‘…ğ‘ƒğ‘…F_{1}=\\frac{2\\cdot P\\cdot R}{(P+R)}, where P=|Ï•t||Ï•|ğ‘ƒsubscriptitalic-Ï•ğ‘¡italic-Ï•P=\\frac{|\\phi_{t}|}{|\\phi|}, R=|Ï•t||Q|ğ‘…subscriptitalic-Ï•ğ‘¡ğ‘„R=\\frac{|\\phi_{t}|}{|Q|}, Ï•tsubscriptitalic-Ï•ğ‘¡\\phi_{t} is a subset of Ï•italic-Ï•\\phi that includes the correctly discovered node matches in Ï•italic-Ï•\\phi, and |X|ğ‘‹|X| indicates the number of nodes in the match or graph, âˆ€Xâˆˆ{Ï•t,Ï•,Q}for-allğ‘‹subscriptitalic-Ï•ğ‘¡italic-Ï•ğ‘„\\forall X\\in\\{\\phi_{t},\\phi,Q\\}. TableÂ 6444The results of ğ–­ğ– ğ–¦ğ– ğ–­ğ– ğ–¦ğ– \\mathsf{NAGA} are provided by the authors and we acknowledge the assistance from Dr. Sourav Dutta and Dr. Shubhangi Agarwal. shows the F1 scores of different algorithms. The result is an average from 100 random queries of sizes ranging from 3 to 13. ğ–½ğ—‰ğ–½ğ—‰{\\mathsf{dp}}-simulation was not compared as it is similar to strong simulation. As with the last results, strong simulation performed poorly against noise. In comparison, ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} was more robust and performed much better (strength S1). Additionally, ğ–¥ğ–²ğ—‚ğ—†ğ—Œsubscriptğ–¥ğ–²ğ—‚ğ—†ğ—Œ{\\mathsf{FSim}}_{{\\mathsf{s}}} outperformed ğ–­ğ– ğ–¦ğ– ğ–­ğ– ğ–¦ğ– \\mathsf{NAGA}, ğ–¦ğ–¦\\mathsf{G}-ğ–¥ğ—‚ğ—‡ğ–½ğ–¾ğ—‹ğ–¥ğ—‚ğ—‡ğ–½ğ–¾ğ—‹\\mathsf{Finder} and ğ–³ğ–²ğ—‰ğ–ºğ—‡ğ–³ğ–²ğ—‰ğ–ºğ—‡\\mathsf{TSpan}-1 by a big margin on all query scenarios. ğ–³ğ–²ğ—‰ğ–ºğ—‡ğ–³ğ–²ğ—‰ğ–ºğ—‡\\mathsf{TSpan}-3 performed well in â€œğ–¤ğ—‘ğ–ºğ–¼ğ—ğ–¤ğ—‘ğ–ºğ–¼ğ—\\mathsf{Exact}â€ and â€œğ–­ğ—ˆğ—‚ğ—Œğ—’ğ–­ğ—ˆğ—‚ğ—Œğ—’\\mathsf{Noisy}-ğ–¤ğ–¤\\mathsf{E}â€ with its highest F1 score of 95.8% for â€œğ–­ğ—ˆğ—‚ğ—Œğ—’ğ–­ğ—ˆğ—‚ğ—Œğ—’\\mathsf{Noisy}-ğ–¤ğ–¤\\mathsf{E}â€. This is because ğ–³ğ–²ğ—‰ğ–ºğ—‡ğ–³ğ–²ğ—‰ğ–ºğ—‡\\mathsf{TSpan}-3 finds all matches with up to 3 mismatched edges, which is not less than the number of noisy edges in most queries. However, ğ–³ğ–²ğ—‰ğ–ºğ—‡ğ–³ğ–²ğ—‰ğ–ºğ—‡\\mathsf{TSpan} favors the case with missing edges rather than nodes. Thus, it has no results for â€œğ–­ğ—ˆğ—‚ğ—Œğ—’ğ–­ğ—ˆğ—‚ğ—Œğ—’\\mathsf{Noisy}-ğ–«ğ–«\\mathsf{L}â€ and â€œğ–¢ğ—ˆğ—†ğ–»ğ—‚ğ—‡ğ–¾ğ–½ğ–¢ğ—ˆğ—†ğ–»ğ—‚ğ—‡ğ–¾ğ–½\\mathsf{Combined}â€. In summary, ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} is qualified for approximate pattern matching (strength S1). While both ğ—Œğ—Œ{\\mathsf{s}}- and ğ–½ğ—‰ğ–½ğ—‰{\\mathsf{dp}}-simulation can be configured for the application, ğ–¥ğ–²ğ—‚ğ—†ğ—Œsubscriptğ–¥ğ–²ğ—‚ğ—†ğ—Œ{\\mathsf{FSim}}_{{\\mathsf{s}}} is more robust to noises and performs better than ğ–¥ğ–²ğ—‚ğ—†ğ–½ğ—‰subscriptğ–¥ğ–²ğ—‚ğ—†ğ–½ğ—‰{\\mathsf{FSim}}_{{\\mathsf{dp}}} (strength S2). Node Similarity Measurement. In this case study, we compared ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} to four state-of-the-art similarity measurement algorithms: ğ–¯ğ–¢ğ–±ğ–¶ğ–¯ğ–¢ğ–±ğ–¶\\mathsf{PCRW} 0, ğ–¯ğ–ºğ—ğ—ğ–²ğ—‚ğ—†ğ–¯ğ–ºğ—ğ—ğ–²ğ—‚ğ—†\\mathsf{PathSim} 1, ğ–©ğ—ˆğ—‚ğ—‡ğ–²ğ—‚ğ—†ğ–©ğ—ˆğ—‚ğ—‡ğ–²ğ—‚ğ—†\\mathsf{JoinSim} 2 and ğ—‡ğ–²ğ—‚ğ—†ğ–¦ğ—‹ğ–ºğ—†ğ—‡ğ–²ğ—‚ğ—†ğ–¦ğ—‹ğ–ºğ—†\\mathsf{nSimGram} 3. Following 3 1, we used the DBIS dataset, which contains 60,694 authors, 72,902 papers and 464 venues. In DBIS, the venues and papers are labeled as â€œVâ€ and â€œP\", respectively. The authors are labeled by their names. We first computed the top-5 most similar venues to WWW using all algorithms. The results are shown in TableÂ 7. Note that WWW1, WWW2 and WWW3 all represent the WWW venue but with different node ids in DBIS, and thus they are naturally similar to WWW. Although all algorithms gave reasonable results, ğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒsubscriptğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒ{\\mathsf{FSim}}_{\\mathsf{bj}} was the only one to return WWW1, WWW2 and WWW3 in the top-5 results. In addition, if we applied exact ğ–»ğ–»{\\mathsf{b}}- and ğ–»ğ—ƒğ–»ğ—ƒ{\\mathsf{bj}}-simulation to the task, other than â€œWWWâ€ itself (â€œYesâ€), all the other venues had the same score (â€œNoâ€). This shows that ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} can be applied to the scenarios that require fine-grained evaluation, such as node similarity measurement (strength S1). Following 3 1, we further computed the top-15 most similar venues to 15 subject venues (same as 3) of each algorithm.\nFor each subject venue, we labeled each returned venue with a relevance score: 0 for non-relevant, 1 for some-relevant, and 2 for very-relevant, considering both the research area and venue ranking in 4. For example, the relevance score for ICDE and VLDB is 2 as both are top-tier conferences in the area of database. We then evaluated the ranking quality of the algorithms using nDCG (the larger the score, the better). TableÂ 8 shows the nDCG results. Accordingly, ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} outperforms the state-of-the-art algorithms by a large margin. This indicates that ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} is qualified to measure node similarity on labeled graphs (strength S1). The result that ğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒsubscriptğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒ{\\mathsf{FSim}}_{\\mathsf{bj}} outperforms ğ–¥ğ–²ğ—‚ğ—†ğ–»subscriptğ–¥ğ–²ğ—‚ğ—†ğ–»{\\mathsf{FSim}}_{\\mathsf{b}} in both the â€œWWWâ€ case and the general evaluation suggests ğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒsubscriptğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒ{\\mathsf{FSim}}_{\\mathsf{bj}} is a better candidate for similarity measurement (strength S2). RDF Graph Alignment. We investigate the potential of ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi}\\! in RDF graph alignment and briefly discuss its performance below. We followed Olap  (a bisimulation-based alignment algorithm) to align three different versions of biological graphs from different times, G1subscriptğº1G_{1}, G2subscriptğº2G_{2} and G3subscriptğº3G_{3} [ref]27. G1subscriptğº1G_{1} has 133,195 nodes and 273,512 edges, G2subscriptğº2G_{2} has 138,651 nodes and 285,000 edges, G3subscriptğº3G_{3} includes 144,879 nodes and 298,564 edges, and all of them have 8 node labels and 23 edge labels. Note that the original URI values in these datasets do not change over time. Hence, we can use this information to identify the ground truth alignment. In addition to Olap, we also included another four state-of-the-art algorithms, namely kğ‘˜k-bisimulation 0, gsaNA 5, ğ–¥ğ–¨ğ–­ğ– ğ–«ğ–¥ğ–¨ğ–­ğ– ğ–«\\mathsf{FINAL} 6 and ğ–¤ğ–¶ğ–²ğ–¤ğ–¶ğ–²\\mathsf{EWS} 7. When aligning graphs with ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi}, a node uâˆˆV1ğ‘¢subscriptğ‘‰1u\\in V_{1} will be aligned to a node set Au=argmaxvâˆˆV2ğ–¥ğ–²ğ—‚ğ—†Ï‡â€‹(u,v)subscriptğ´ğ‘¢subscriptargmaxğ‘£subscriptğ‘‰2subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’ğ‘¢ğ‘£A_{u}=\\mathop{\\mathrm{argmax}}_{v\\in V_{2}}{\\mathsf{FSim}}_{\\chi}(u,v), while with kğ‘˜k-bisimulation, uğ‘¢u will be aligned to Au={v|vâˆˆV2âˆ§uâ€‹Â andÂ â€‹vâ€‹Â are bisimilar}subscriptğ´ğ‘¢conditional-setğ‘£ğ‘£subscriptğ‘‰2ğ‘¢Â andÂ ğ‘£Â are bisimilarA_{u}=\\{v|v\\in V_{2}\\wedge u\\text{ and }v\\text{ are bisimilar}\\}. The F1 score of ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} and kğ‘˜k-bisimulation is calculated by Fâ€‹1=âˆ‘uâˆˆV12â‹…Puâ‹…Ru|V1|â€‹(Pu+Ru)ğ¹1subscriptğ‘¢subscriptğ‘‰1â‹…2subscriptğ‘ƒğ‘¢subscriptğ‘…ğ‘¢subscriptğ‘‰1subscriptğ‘ƒğ‘¢subscriptğ‘…ğ‘¢F1=\\sum_{u\\in V_{1}}\\frac{2\\cdot P_{u}\\cdot R_{u}}{|V_{1}|(P_{u}+R_{u})}, where Pusubscriptğ‘ƒğ‘¢P_{u} (resp. Rusubscriptğ‘…ğ‘¢R_{u}) is 1|Au|1subscriptğ´ğ‘¢\\frac{1}{|A_{u}|} (resp. 1) if Ausubscriptğ´ğ‘¢A_{u} contains the ground truth, and 0 otherwise. We follow the settings in the related papers for the other baselines.  TableÂ 9 reports the F1 scores of each algorithm. Note that we also tested the bisimulation, which resulted in 0% F1 scores in both cases since there is no exact bisimulation relation between two graphs. kğ‘˜k-bisimulation performs better than bisimulation as it, to some extent, approximates bisimulation. From TableÂ 9, our ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} had the highest F1 scores and thus outperformed all the other baselines. This shows that we can apply ğ–¥ğ–²ğ—‚ğ—†ğ–»subscriptğ–¥ğ–²ğ—‚ğ—†ğ–»{\\mathsf{FSim}}_{\\mathsf{b}} and ğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒsubscriptğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒ{\\mathsf{FSim}}_{\\mathsf{bj}} with high potential for graph alignment (strength S1). ğ–¥ğ–²ğ—‚ğ—†ğ–»subscriptğ–¥ğ–²ğ—‚ğ—†ğ–»{\\mathsf{FSim}}_{{\\mathsf{b}}} outperforms ğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒsubscriptğ–¥ğ–²ğ—‚ğ—†ğ–»ğ—ƒ{\\mathsf{FSim}}_{{\\mathsf{bj}}} and thus is a better candidate for graph alignment (strength S2). Efficiency Evaluation. Given the superior effectiveness of ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} in the above case studies, one may also be interested in its efficiency. Next, we show the running time of ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} (with 32 threads) and the most effective baseline in each case study. We will also report the running time of exact simulation (or its variant) if it is applied and effective in the case study. For pattern matching, ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} on average took 0.25s for each query. In comparison, exact simulation took around 1.2s, and ğ–³ğ–²ğ—‰ğ–ºğ—‡ğ–³ğ–²ğ—‰ğ–ºğ—‡\\mathsf{TSpan}, the most effective baseline, spent more than 70s. In similarity measurement, ğ—‡ğ–²ğ—‚ğ—†ğ–¦ğ—‹ğ–ºğ—†ğ—‡ğ–²ğ—‚ğ—†ğ–¦ğ—‹ğ–ºğ—†\\mathsf{nSimGram} took 0.03ms to compute a single node pair, while ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi} finished the computation within 6500s for 134060Ã—\\times134060 pairs or roughly 0.0004ms per pair. In graph alignment, kğ‘˜k-bisimulation (k=4ğ‘˜4k=4) spent 0.4s for the computation, and ğ–¤ğ–¶ğ–²ğ–¤ğ–¶ğ–²\\mathsf{EWS} spent 1496s. Our ğ–¥ğ–²ğ—‚ğ—†Ï‡subscriptğ–¥ğ–²ğ—‚ğ—†ğœ’{\\mathsf{FSim}}_{\\chi}\nran a bit slower than ğ–¤ğ–¶ğ–²ğ–¤ğ–¶ğ–²\\mathsf{EWS} and took 3120s, which is tolerable as it is much more effective than the other algorithms. Note that it is not straightforward and potentially unfair to compare with all the baselines as they either focus on per-query computation (e.g., ğ–¯ğ–ºğ—ğ—ğ–²ğ—‚ğ—†ğ–¯ğ–ºğ—ğ—ğ–²ğ—‚ğ—†\\mathsf{PathSim} and ğ–©ğ—ˆğ—‚ğ—‡ğ–²ğ—‚ğ—†ğ–©ğ—ˆğ—‚ğ—‡ğ–²ğ—‚ğ—†\\mathsf{JoinSim}) or have been individually implemented in different languages (e.g., Olap in Python and ğ–¥ğ–¨ğ–­ğ– ğ–«ğ–¥ğ–¨ğ–­ğ– ğ–«\\mathsf{FINAL} in Matlab).\n\nReference markers found: [27]\n\nContext windows for each [ref]:\n[ref]27: followed Olap  (a bisimulation-based alignment algorithm) to align three different versions of biological graphs from different times, G1subscriptğº1G_{1}, G2subscriptğº2G_{2} and G3subscriptğº3G_{3} [ref]27. G1subscriptğº1G_{1} has 133,195 nodes and 273,512 edges, G2subscriptğº2G_{2} has 138,651 nodes and 285,000 edges, G3subscriptğº3G_{3} includes 144,879 nodes and 298,564 edges, and all of them\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 27,\n            \"titles\": [\n                \"ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ ê³µê²© ê·¸ë˜í”„ ìƒì„±\",\n                \"Capturing topology in graph pattern matching\",\n                \"An algebraic definition of simulation between programs\",\n                \"Communication and concurrency\",\n                \"Event pattern matching over graph streams\",\n                \"Graph pattern matc-hing: From intractable to polynomial time\",\n                \"Strong simulation: Capturing topology in graph pattern matching\",\n                \"RDF Graph Alignment with Bisimulation\",\n                \"Efficient external-memory bisimulation on dags\",\n                \"Large-scale bisimulation of RDF graphs\",\n                \"On structure preserving sampling and approximate partitioning of graphs\",\n                \"Covering indexes for XML queries: Bisimulation - simulation = negation\",\n                \"Query preserving graph compression\",\n                \"A methodology for coupling fragments of xpath with structural indexes for XML documents\",\n                \"Covering indexes for branching path queries\",\n                \"Structural indexing for conjunctive path queries\",\n                \"Weisfeiler-lehman graph kernels\",\n                \"Simrank: a measure of structural-context similarity\",\n                \"Axiomatic ranking of network role similarity\",\n                \"The algorithmics of bisimilarity\",\n                \"Bisimulation reduction of big graphs on mapreduce\",\n                \"External memory k-bisimulation reduction of big graphs\",\n                \"A survey of heuristics for the weighted matching problem\",\n                \"Graph isomorphism in quasipolynomial time\",\n                \"SAPPER: subgraph indexing and approximate matching in large graphs\",\n                \"Treespan: efficiently computing similarity all-matching\",\n                \"Fast best-effort pattern matching in large attributed graphs\",\n                \"Global alignment of multiple protein interaction networks with application to functional orthology detection\",\n                \"Nema: Fast graph search with label similarity\",\n                \"Neighbor-aware search for approximate labeled graph matching using the chi-square statistics\",\n                \"G-finder: Approximate attributed subgraph matching\",\n                \"SAGA: a subgraph matching tool for biological graphs\",\n                \"Schemaless and structureless graph querying\",\n                \"Semantic SPARQL similarity search over RDF knowledge graphs\",\n                \"Relational retrieval using a combination of path-constrained random walks\",\n                \"Pathsim: Meta path-based top-k similarity search in heterogeneous information networks\",\n                \"Top-k similarity join in heterogeneous information networks\",\n                \"Node similarity with q-grams for real-world labeled networks\",\n                \"An iterative global structure-assisted labeled network aligner\",\n                \"FINAL: fast attributed network alignment\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]27 based on the context and research area of A Framework to Quantify Approximate Simulation on Graph Data. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}