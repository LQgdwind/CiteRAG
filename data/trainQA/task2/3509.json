{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Towards Effective and Robust Neural Trojan Defenses via Input Filtering\n\nPaper Abstract: \n\nPaper Section Text:\nFollowing previous works 1  [ref]38,\nwe evaluate our proposed defenses on four image datasets namely MNIST,\nCIFAR10 , GTSRB ,\nand CelebA . For CelebA, we follow Salem et al.\n[ref]38 and select the top 3 most balanced binary\nattributes (out of 40) to form an 8-class classification problem.\nThe chosen attributes are â€œHeavy Makeupâ€, â€œMouth\nSlightly Openâ€, and â€œSmilingâ€. Like other works  7,\nwe assume that we have access to the test set of these datasets. We\nuse 70% data of the test set for training our defense methods (ğ’Ÿvalsubscriptğ’Ÿval\\mathcal{D}_{\\text{val}}\nin SectionsÂ 3, 4)\nand 30% for testing (denoted as ğ’Ÿtestsubscriptğ’Ÿtest\\mathcal{D}_{\\text{test}}). For more\ndetails about the datasets, please refer to Appdx.Â 0.B.1.\nSometimes, we do not test our methods on all images in ğ’Ÿtestsubscriptğ’Ÿtest\\mathcal{D}_{\\text{test}}\nbut on those not belonging to the target class. This set is\ndenoted as ğ’Ÿtestâ€²subscriptsuperscriptğ’Ÿâ€²test\\mathcal{D}^{\\prime}_{\\text{test}}. We also provide results with less\ntraining data in Appdx.Â 5.4.2. We use 5 different benchmark Trojan attacks for our defenses, which\nare BadNet+, noise-BI+, image-BI+, InpAwAtk ,\nand WaNet . InpAwAtk and WaNet are recent SOTA\nattacks that were shown to break many strong defenses completely.\nBadNet+ and noise/image-BI+ are variants of BadNet 1\nand Blended Injection (BI)  that use multiple\ntriggers instead of one. They are described in detail in Appdx.Â 0.C.1.\nThe training settings for the 5 attacks are given in Appdx.Â 0.B.2. We also consider 2 attack modes namely single-target and all-target\n . In the first mode, only\none class tğ‘¡t is chosen as target. Every Trojan image x~~ğ‘¥\\tilde{x}\nis classified as tğ‘¡t regardless of the ground-truth label of its\nclean counterpart xğ‘¥x. Without loss of generality, tğ‘¡t is set to\n0. In the second mode, x~~ğ‘¥\\tilde{x} is classified as (k+1)modKmoduloğ‘˜1ğ¾(k+1)\\mod K\nif xğ‘¥x belongs to the class kğ‘˜k. If not clearly stated, attacks\nare assumed to be single-target. We report the test clean and Trojan accuracies of the benchmark attacks\n(in single-target mode) in TableÂ 5.1.\nIt is clear that all attacks achieve very high Trojan accuracies with\nlittle or no decrease in clean accuracy compared to the benign modelâ€™s,\nhence, are qualified for our experimental purpose. For results of\nthe attacks on ğ’Ÿtestsubscriptğ’Ÿtest\\mathcal{D}_{\\text{test}}, please refer to Appdx.Â 0.C. We consider 5 well-known baseline defenses namely Neural Cleanse (NC)\n7, STRIP , Network\nPruning (NP) , Neural Attention Distillation (NAD)\n, and Februus . Neural Cleanse (NC) assumes that attacks (i) choose only one target\nclass tğ‘¡t and (ii) use at least (not exactly) one input-agnostic\ntrigger associated with tğ‘¡t. We refer to (i) as the â€œsingle\ntarget classâ€ assumption and (ii) as the â€œinput-agnostic\ntriggerâ€ assumption. Based on these assumptions, NC finds a trigger\nÏˆk=(mk,pk)subscriptğœ“ğ‘˜subscriptğ‘šğ‘˜subscriptğ‘ğ‘˜\\psi_{k}=(m_{k},p_{k}) for every class kâˆˆğ’´ğ‘˜ğ’´k\\in\\mathcal{Y} via reverse-engineering\n(Eq.Â 2), and uses the L1 norms of the\nsynthetic trigger masks {m1,â€¦,mK}subscriptğ‘š1â€¦subscriptğ‘šğ¾\\{m_{1},...,m_{K}\\} to detect the target\nclass. The intuition is that if tğ‘¡t is the target class, â€–mtâ€–1subscriptnormsubscriptğ‘šğ‘¡1{\\|m_{t}\\|}_{1}\nwill be much smaller than the rest. A zğ‘§z-value of each mask norm\nis calculated via Median Absolute Deviation and the zğ‘§z-value of\nthe smallest mask norm (referred to as the anomaly index) is\ncompared against a threshold Î¶ğœ\\zeta (2.0 by default). If the anomaly\nindex is smaller than Î¶ğœ\\zeta, ğ™²ğ™²\\mathtt{C} is marked as clean.\nOtherwise, ğ™²ğ™²\\mathtt{C} is marked Trojan-infected with the target\nclass corresponding to the smallest mask norm. In this case, the Trojans\nin ğ™²ğ™²\\mathtt{C} can be mitigated via pruning or via checking the\ncleanliness of input images. Both mitigation methods make use of Ïˆtsubscriptğœ“ğ‘¡\\psi_{t}\nand are analyzed in Appdx.Â 0.D. STRIP assumes triggers are input-agnostic and argues that if an input\nimage xğ‘¥x contains triggers then these triggers still have effect\nif xğ‘¥x is superimposed (blended) with other images. Therefore, STRIP\nsuperimposes xğ‘¥x with Nssubscriptğ‘sN_{\\text{s}} random clean images from ğ’Ÿvalsubscriptğ’Ÿval\\mathcal{D}_{\\text{val}}\nand computes the average entropy â„‹â€‹(x)â„‹ğ‘¥\\mathcal{H}(x) of Nssubscriptğ‘sN_{\\text{s}}\npredicted class probabilities corresponding to Nssubscriptğ‘sN_{\\text{s}} superimposed\nversions of xğ‘¥x. If â„‹â€‹(x)â„‹ğ‘¥\\mathcal{H}(x) is smaller than a predefined\nthreshold, xğ‘¥x is considered as trigger-embedded, otherwise, clean.\nThe threshold is set according to the false positive rate (FPR) over\nthe average entropies of all images in ğ’Ÿvalsubscriptğ’Ÿval\\mathcal{D}_{\\text{val}},\nusually at FPR equal to 1/5/10%. We evaluate the performance of STRIP\nagainst an attack using Mssubscriptğ‘€sM_{\\text{s}} random clean images from ğ’Ÿtestsubscriptğ’Ÿtest\\mathcal{D}_{\\text{test}}\nand Mssubscriptğ‘€sM_{\\text{s}} corresponding Trojan images generated by that\nattack. Following , we set Ns=100subscriptğ‘s100N_{\\text{s}}=100\nand Ms=2000subscriptğ‘€s2000M_{\\text{s}}=2000. Network Pruning (NP) hypothesizes that idle neurons are more likely\nto store Trojan-related information. Thus, it ranks neurons in the\nsecond top layer of ğ™²ğ™²\\mathtt{C} according to their average activation\nover all data in ğ’Ÿvalsubscriptğ’Ÿval\\mathcal{D}_{\\text{val}} and gradually prunes them until\na certain decrease in clean accuracy is reached, usually at 1/5/10%\ndecrease in clean accuracy. Neural Attention Distillation (NAD)  is a distillation-based\nTrojan defense. It first fine-tunes the pretrained classifier ğ™²ğ™²\\mathtt{C}\non clean images in ğ’Ÿvalsubscriptğ’Ÿval\\mathcal{D}_{\\text{val}} to obtain a fine-tune classifier\nğšƒğšƒ\\mathtt{T}. Then, it treats ğšƒğšƒ\\mathtt{T} and ğ™²ğ™²\\mathtt{C} as\nthe teacher and student respectively, and performs attention-based\nfeature distillation 2 between ğšƒğšƒ\\mathtt{T}\nand ğ™²ğ™²\\mathtt{C} on ğ’Ÿvalsubscriptğ’Ÿval\\mathcal{D}_{\\text{val}} again. Since ğšƒğšƒ\\mathtt{T}\nis ğ™²ğ™²\\mathtt{C} fine-tuned on clean data, ğšƒğšƒ\\mathtt{T} is expected\nto have most of the Trojan in ğ™²ğ™²\\mathtt{C} removed. Via distillation,\nsuch Trojan-free knowledge is transferred from ğšƒğšƒ\\mathtt{T} to ğ™²ğ™²\\mathtt{C}\nwhile performance of ğ™²ğ™²\\mathtt{C} on clean data is still preserved. Among the baselines, Februus is the most related to our filtering\ndefenses since it mitigates Trojan attacks via input purification.\nIt uses GradCAM 0 to detect regions in an\ninput image xğ‘¥x that may contain triggers. Then, it removes all pixels\nin the suspected regions and generates new ones via inpainiting. The\ninpainted image is expected to contain no trigger and is fed to ğ™²ğ™²\\mathtt{C}\ninstead of xğ‘¥x. Please refer to Appdx.Â 0.B.3. We evaluate VIF/AIF using 3 metrics namely decrease in clean\naccuracy (â†“â†“\\downarrowC), Trojan accuracy (T), and decrease\nin recovery accuracy (â†“â†“\\downarrowR). The first is the difference\nbetween the classification accuracies of clean images before and after\nfiltering. The second is the attack success rate of Trojan images\nafter filtering. The last is the difference between the classification\naccuracy of clean images before filtering and that of the corresponding\nTrojan images after filtering. Smaller values of the metrics indicate\nbetter results. â†“â†“\\downarrowC and â†“â†“\\downarrowR are computed on\nğ’Ÿtestsubscriptğ’Ÿtest\\mathcal{D}_{\\text{test}}. T is computed on ğ’Ÿtestâ€²subscriptsuperscriptğ’Ÿâ€²test\\mathcal{D}^{\\prime}_{\\text{test}} under\nsingle-target attacks and ğ’Ÿtestsubscriptğ’Ÿtest\\mathcal{D}_{\\text{test}} under all-target\nattacks. This ensures that T can be 00 in the best case. Otherwise,\nT will be around 1/K1ğ¾1/K where Kğ¾K is the total number of classes.\nâ†“â†“\\downarrowC and â†“â†“\\downarrowR are upper-bounded by 1 and can be\nnegative. We evaluate VIFtC/AIFtC using FPR and FNR. FPR/FNR is defined as the\nproportion of clean/Trojan images having different/similar class predictions\nwhen the filter ğ™µğ™µ\\mathtt{F} is applied and not applied. FPR is computed\non ğ’Ÿtestsubscriptğ’Ÿtest\\mathcal{D}_{\\text{test}}. FNR is computed on ğ’Ÿtestâ€²subscriptsuperscriptğ’Ÿâ€²test\\mathcal{D}^{\\prime}_{\\text{test}}\nunder single-target attacks and ğ’Ÿtestsubscriptğ’Ÿtest\\mathcal{D}_{\\text{test}} under all-target\nattacks. Both metrics are in   and smaller values of them\nare better. Interestingly, FPR and FNR are strongly correlated to\nâ†“â†“\\downarrowC and T, respectively. FPR/FNR is exactly equal to â†“â†“\\downarrowC/T\nif ğ™²ğ™²\\mathtt{C} achieves perfect clean/Trojan accuracy.\n\nReference markers found: [38]\n\nContext windows for each [ref]:\n[ref]38: Following previous works 1  [ref]38,\nwe evaluate our proposed defenses on four image datasets namely MNIST,\nCIFAR10 , GTSRB ,\nand CelebA . For CelebA, we follow Salem et al.\n[ref]38 and select the top 3 most balanced\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"FaceNet: A Unified Embedding for Face Recognition and Clustering\",\n                \"Bayesian Bits: Unifying Quantization and Pruning\",\n                \"Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering\",\n                \"DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks\",\n                \"Targeted backdoor attacks on deep learning systems using data poisoning\",\n                \"Februus: Input Purification Defense Against Trojan Attacks on Deep Neural Network Systems\",\n                \"Black-box Detection of Backdoor Attacks with Limited Information and Data\",\n                \"Adversarial vulnerability for any classifier\",\n                \"Strip: A Defence Against Trojan Attacks on Deep Neural Networks\",\n                \"Generative adversarial nets\",\n                \"Explaining and Harnessing Adversarial Examples\",\n                \"Badnets: Identifying vulnerabilities in the machine learning model supply chain\",\n                \"TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems\",\n                \"Scalable Backdoor Detection in Neural Networks\",\n                \"Deep Residual Learning for Image Recognition\",\n                \"Identity Mappings in Deep Residual Networks\",\n                \"Backdoor attacks against learning systems\",\n                \"Adam: A Method for Stochastic Optimization\",\n                \"Auto-encoding variational bayes\",\n                \"Learning Multiple Layers of Features from Tiny Images\",\n                \"Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks\",\n                \"Backdoor attack with sample-specific triggers\",\n                \"Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks\",\n                \"ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation\",\n                \"Reflection Backdoor: A Natural Backdoor Attack on Deep Neural Networks\",\n                \"Neural Trojans\",\n                \"Deep learning face attributes in the wild\",\n                \"Bayesian Compression for Deep Learning\",\n                \"Towards Deep Learning Models Resistant to Adversarial Attacks\",\n                \"Adversarial training and dilated convolutions for brain MRI segmentation\",\n                \"Variational Dropout Sparsifies Deep Neural Networks\",\n                \"Poisoning Attacks with Generative Adversarial Nets\",\n                \"Input-aware dynamic backdoor attack\",\n                \"Wanetâ€“imperceptible warping-based backdoor attack\",\n                \"Deep face recognition\",\n                \"Defending Neural Backdoors via Generative Distribution Modeling\",\n                \"You Only Look Once: Unified, Real-Time Object Detection\",\n                \"Hidden trigger backdoor attacks\",\n                \"Dynamic Backdoor Attacks Against Machine Learning Models\",\n                \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]38 based on the context and research area of Towards Effective and Robust Neural Trojan Defenses via Input Filtering. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}