{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Parameterized Complexity of Streaming Diameter and Connectivity Problems\n\nPaper Abstract: \n\nPaper Section Text:\nWe now show how our insights into parameterized, streaming graph exploration can aid in producing a new kernelization algorithm for Vertex Cover [kğ‘˜k].\nThe basis for our result is a well-known kernel for the Vertex Cover [kğ‘˜k] problem of Buss and GoldsmithÂ , consisting of ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) edges. Constructing this kernel is simple: find all vertices with degree bigger than kğ‘˜k, and remove them from the graph, and decrease the parameter with the number of vertices removed, say to kâ€²superscriptğ‘˜â€²k^{\\prime}. Then, there is no solution if there are more than kâ‹…kâ€²â‹…ğ‘˜superscriptğ‘˜â€²k\\cdot k^{\\prime} edges. Therefore, we have a kernel consisting of ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) edges. We are able to achieve this same kernel in the AL model, as counting the degree of a vertex is possible in this model. Interestingly, we do not require ğ’ª~â€‹(k2)~ğ’ªsuperscriptğ‘˜2\\tilde{\\mathcal{O}}(k^{2}) bits of memory to produce a stream corresponding to the kernel of ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) edges. This result is also possible in the EA model, by allowing vertices up to degree 2â€‹k2ğ‘˜2k. Given a graph GğºG as an AL stream, we can make an AL stream corresponding to an ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2})-edge kernel for the Vertex Cover [kğ‘˜k] problem using two passes and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. When we work with an EA stream, we can make an EA stream corresponding to an ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2})-edge kernel using four passes and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. Let GğºG be a graph, with nğ‘›n vertices and mğ‘šm edges, given as an AL stream, and let kğ‘˜k be the solution size parameter for the Vertex Cover [kğ‘˜k] problem. Note that we can count the degree of every vertex when it appears in the stream, as we are given all adjacencies of a vertex consecutively. Therefore, in one pass over the stream we can count the degree of every vertex, and save each vertex with a degree bigger than kğ‘˜k in a set Sğ‘†S, as long as |S|â‰¤kğ‘†ğ‘˜|S|\\leq k. In this same pass, we keep track of two more counters: the total number of edges in the stream mâ€²superscriptğ‘šâ€²m^{\\prime} (which is 2â€‹m2ğ‘š2m), and the number of unique edges we remove rğ‘Ÿr. The second can be done by keeping a local counter which we reset at every vertex and only increment for edges towards vertices not in Sğ‘†S, and adding this local counter to the number of edges removed when we decide to add the vertex to Sğ‘†S. If mâ€²2âˆ’r>kâ‹…(kâˆ’|S|)superscriptğ‘šâ€²2ğ‘Ÿâ‹…ğ‘˜ğ‘˜ğ‘†\\frac{m^{\\prime}}{2}-r>k\\cdot(k-|S|), return NO. Otherwise, make a pass over the stream, and output only those edges between vertices not in Sğ‘†S. The output must be an AL stream, as we only remove edges from an AL stream to produce it. Let is also be clear that we use two passes over the stream. The set Sğ‘†S takes ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory, as finding more than kğ‘˜k vertices will result in returning NO. Counting the total number of edges takes ğ’ªâ€‹(logâ¡m)=ğ’ªâ€‹(logâ¡n)ğ’ªğ‘šğ’ªğ‘›\\mathcal{O}(\\log m)=\\mathcal{O}(\\log n) bits of space, and other counters are the same size or smaller, of which there are a constant amount. Therefore, the memory usage of this procedure is ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits. The behaviour of this procedure is equivalent of the kernelization algorithm of Buss and GoldsmithÂ , as it finds exactly those vertices with degree higher than kğ‘˜k, and â€˜removesâ€™ them by adding them to Sğ‘†S and ignoring edges incident to them in the output. Checking the instance size is done correctly, as the new parameter kâ€²superscriptğ‘˜â€²k^{\\prime} is equivalent to kâˆ’|S|ğ‘˜ğ‘†k-|S|, and the number of remaining edges is equal to mâˆ’rğ‘šğ‘Ÿm-r, which is mâ€²2âˆ’rsuperscriptğ‘šâ€²2ğ‘Ÿ\\frac{m^{\\prime}}{2}-r. rğ‘Ÿr is counted correctly because we only count unique edges by ignoring those towards vertices already in Sğ‘†S. Therefore, this kernelization procedure is correct. For the case of the EA stream, we essentially do the same as in the AL model, but in this model we end up with a slightly larger kernel. In our first pass, we greedily construct a vertex cover Xğ‘‹X of size 2â€‹k2ğ‘˜2k or conclude that there is no solution to Vertex Cover [kğ‘˜k]. Now, we know that all vertices not in Xğ‘‹X must have degree at most 2â€‹k2ğ‘˜2k. So, in the second pass we count the degree of all vertices in Xğ‘‹X, and if a degree exceeds 2â€‹k2ğ‘˜2k we the add vertex to Sğ‘†S. This takes only ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. If at some point |S|>kğ‘†ğ‘˜|S|>k we also stop and conclude there is no solution to Vertex Cover [kğ‘˜k], as all vertices of degree at least 2â€‹k2ğ‘˜2k must be in any solution. In a third pass, we count the total number mğ‘šm of edges in the stream, and the number of unique edges we remove rğ‘Ÿr (this is not possible during the second pass because we might count edges double when it has both endpoints in Sğ‘†S). Now if mâˆ’r>2â€‹kâ‹…(kâˆ’|S|)ğ‘šğ‘Ÿâ‹…2ğ‘˜ğ‘˜ğ‘†m-r>2k\\cdot(k-|S|), we can conclude there is no solution to Vertex Cover [kğ‘˜k], as each vertex has maximum degree 2â€‹k2ğ‘˜2k. Now to output the kernel as an EA stream, we make a fourth pass and only output those edges not incident to vertices in Sğ‘†S. In this procedure we only use ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory for counting and Xğ‘‹X. The resulting kernel has at most 2â€‹kâ‹…(kâˆ’|S|)=ğ’ªâ€‹(k2)â‹…2ğ‘˜ğ‘˜ğ‘†ğ’ªsuperscriptğ‘˜22k\\cdot(k-|S|)=\\mathcal{O}(k^{2}) edges. Next, we show how to use TheoremÂ 6.1 to produce a kernel of even smaller size, using only ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. This requires TheoremÂ 6.1 to convert the original graph stream into the kernel input for the next theorem, which only increases the number of passes by a factor 2 or 4 (we have to apply TheoremÂ 6.1 every time the other procedure uses a pass). Interestingly, Chen et al.Â  show a way to convert the kernel of Buss and Goldsmith into a 2â€‹k2ğ‘˜2k-vertex kernel for Vertex Cover [kğ‘˜k], using a theorem by Nemhauser and TrotterÂ . We will adapt this method in the streaming setting. The kernel conversion is done by converting the ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) edges kernel into a bipartite graph (two copies of all vertices V,Vâ€²ğ‘‰superscriptğ‘‰â€²V,V^{\\prime}, and an edge (x,y)ğ‘¥ğ‘¦(x,y) translates to the edges (x,yâ€²)ğ‘¥superscriptğ‘¦â€²(x,y^{\\prime}), (xâ€²,y)superscriptğ‘¥â€²ğ‘¦(x^{\\prime},y)), in which we find a minimum vertex cover using a maximum matching (see for example [13, PageÂ 74, TheoremÂ 5.3]). The minimum vertex cover we find gives us the sets stated in the theorem by Nemhauser and TrotterÂ , as indicated by the constructive proof of the same theorem by Bar-Yehuda and EvenÂ . Lastly, we use these sets to give the 2â€‹k2ğ‘˜2k kernel in the streaming setting as indicated by Chen et al.Â . This also works for the EA model, because we only require the input kernel to consist of ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) edges, not that it specifically is the kernel by Buss and Goldsmith. Given a graph GğºG as a stream in model AL or EA, we can produce a stream in the same model corresponding to the Phase 1 bipartite graph of [8, Algorithm NT] using two passes and ğ’ª~~ğ’ª\\tilde{\\mathcal{O}}(1) bits of memory. Given a graph G=(V,E)ğºğ‘‰ğ¸G=(V,E), Phase 1 of [8, Algorithm NT] asks for the bipartite graph BğµB with vertex sets V,Vâ€²ğ‘‰superscriptğ‘‰â€²V,V^{\\prime} and edges EBsubscriptğ¸ğµE_{B} such that Vâ€²={vâ€²âˆ£vâˆˆV}superscriptğ‘‰â€²conditional-setsuperscriptğ‘£â€²ğ‘£ğ‘‰V^{\\prime}=\\{v^{\\prime}\\mid v\\in V\\} and EB={(x,yâ€²)âˆ£(x,y)âˆˆE}subscriptğ¸ğµconditional-setğ‘¥superscriptğ‘¦â€²ğ‘¥ğ‘¦ğ¸E_{B}=\\{(x,y^{\\prime})\\mid(x,y)\\in E\\}. This is essentially two copies of all vertices and each edge in the original graph makes two edges, between the corresponding (original,copy)-pairs. The process of creating a stream corresponding to BğµB is quite simple: first we use a pass and, for every edge (x,y)ğ‘¥ğ‘¦(x,y), we output (x,yâ€²)ğ‘¥superscriptğ‘¦â€²(x,y^{\\prime}), and then we use another pass and, for every edge (x,y)ğ‘¥ğ‘¦(x,y), we output (xâ€²,y)superscriptğ‘¥â€²ğ‘¦(x^{\\prime},y). If the input is an EA stream, then the output must be as well, as there are no requirements. If the input stream is an AL stream, the output must be an AL stream too, as we are consistent in which copy we address. That is, the output AL stream first reveals all vertices in Vğ‘‰V and then all those in Vâ€²superscriptğ‘‰â€²V^{\\prime}. All adjacencies of these vertices are present in the stream, as all the adjacencies were present in the input stream. We can see that this uses two passes and ğ’ª~~ğ’ª\\tilde{\\mathcal{O}}(1) bits of memory (to remember what pass we are in, and to read an edge). It is trivial that the bipartite graph BğµB is constructed correctly, as for every edge (x,y)ğ‘¥ğ‘¦(x,y) we output the edges (x,yâ€²)ğ‘¥superscriptğ‘¦â€²(x,y^{\\prime}) and (xâ€²,y)superscriptğ‘¥â€²ğ‘¦(x^{\\prime},y). Before we continue to find the maximum matching in such a graph BğµB produced by LemmaÂ 6.3, we need a few observations to restrict the size of the matching we want to find. The output sets C0subscriptğ¶0C_{0} and V0subscriptğ‘‰0V_{0} of [8, Algorithm NT] are used by Chen et al.Â  to produce a 2â€‹k2ğ‘˜2k kernel. The sets C0subscriptğ¶0C_{0} and V0subscriptğ‘‰0V_{0} output by [8, Algorithm NT] are such that C0subscriptğ¶0C_{0} together with a minimum vertex cover on Gâ€‹[V0]ğºdelimited-[]subscriptğ‘‰0G[V_{0}] forms a minimum vertex cover for GğºG, and any minimum vertex cover for Gâ€‹[V0]ğºdelimited-[]subscriptğ‘‰0G[V_{0}] includes at least |V0|/2subscriptğ‘‰02|V_{0}|/2 vertices. From the conversion of these sets to a 2â€‹k2ğ‘˜2k kernel by Chen et al.Â , we can conclude that it must be that |V0|â‰¤2â€‹kâˆ’2â€‹|C0|subscriptğ‘‰02ğ‘˜2subscriptğ¶0|V_{0}|\\leq 2k-2|C_{0}| (as this shows the kernel size). But then it must also be that |V0|+|C0|â‰¤2â€‹ksubscriptğ‘‰0subscriptğ¶02ğ‘˜|V_{0}|+|C_{0}|\\leq 2k, and, as V0subscriptğ‘‰0V_{0} and C0subscriptğ¶0C_{0} together include all vertices in the found minimum vertex cover in BğµB (which has the same size as the maximum matching in BğµB, see [13, PageÂ 74, TheoremÂ 5.3]). To find the maximum matching we execute a DFS procedure, which can be done with surprising efficiency in this restricted bipartite setting. Given a bipartite graph BğµB as an AL stream with ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) vertices, we can find a maximum matching of size at most ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) using ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) passes and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. For the EA model this can be done in ğ’ªâ€‹(k3)ğ’ªsuperscriptğ‘˜3\\mathcal{O}(k^{3}) passes. We first use a pass to find a maximal matching Mğ‘€M in the graph. This can be done in a single pass because we can construct a maximal matching in a greedy manner, picking every edge that appears in the stream for which both vertices are unmatched. Then, we iteratively find an Mğ‘€M-augmenting path Pğ‘ƒP (a path starting and ending in a unmatched vertices, alternating between edges in and not in Mğ‘€M), and improve the matching by switching all edges on Pğ‘ƒP (i.e., remove from Mğ‘€M the edges on Pğ‘ƒP in Mğ‘€M, and add to Mğ‘€M the edges on Pğ‘ƒP not in Mğ‘€M). Note that any such Pğ‘ƒP has length ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k), as otherwise Mğ‘€M would exceed size ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k). It is known that a matching Mğ‘€M in a bipartite graph is maximum when there is no Mğ‘€M-augmenting path [ref]41. We can also find an Mğ‘€M-augmenting path only ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) times, as the size of the matching increases by at least 1 for each Mğ‘€M-augmenting path. Let us now describe how we find an Mğ‘€M-augmenting path, given some matching Mğ‘€M of size ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k). We find Mğ‘€M-augmenting paths by executing a Depth First Search (DFS) from each unmatched vertex. Note that we alternate between traversing edges in Mğ‘€M and not in Mğ‘€M in this search. In contrary to a normal DFS, we do not save which vertices we visited, as this would cost too much memory. Instead, we mark edges in Mğ‘€M as visited, together with the vertex from which we started the search. If an edge eâˆˆMğ‘’ğ‘€e\\in M has been visited once in the search tree, there is no need to visit it again, as the search that visited eğ‘’e would have found an Mğ‘€M-augmenting path containing eğ‘’e if it exists. Let us discuss the exact details on the size of the search tree and recursion. As any Mğ‘€M-augmenting path has length at most ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k), the depth of the search tree is also ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k). Looking at any vertex, it might have ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) neighbours in the given bipartite graph. However, only ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) of its neighbours can be in Mğ‘€M. As visiting an unmatched vertex must end the Mğ‘€M-augmenting path, the search tree size is only increased by visiting matched vertices. Therefore, the search comes down to the following process. From the initial unmatched vertex, we can explore to at most ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) vertices (those in the matching) or any unmatched vertex which would end the search. If we explore to a matched vertex, the next step must traverse the edge in the matching to make an Mğ‘€M-augmenting path, which is deterministic. Then we again can explore to ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) matched vertices, or any unmatched vertex which would end the search. This process continues. As we only visit each matched vertex at most once, we can see that the number of vertices the search visits is bounded by ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k). In each node along the currently active path of the search tree, we can keep a counter with value â‰¤ğ’ªâ€‹(k2)absentğ’ªsuperscriptğ‘˜2\\leq\\mathcal{O}(k^{2}) (using ğ’ªâ€‹(logâ¡(k2))=ğ’ªâ€‹(logâ¡k)ğ’ªsuperscriptğ‘˜2ğ’ªğ‘˜\\mathcal{O}(\\log(k^{2}))=\\mathcal{O}(\\log k) bits) to keep track of what edge we consider next. These counters take up ğ’ªâ€‹(kâ‹…logâ¡k)=ğ’ª~â€‹(k)ğ’ªâ‹…ğ‘˜ğ‘˜~ğ’ªğ‘˜\\mathcal{O}(k\\cdot\\log k)=\\tilde{\\mathcal{O}}(k) space. In any node, if we wish to consider the next edge incident to a vertex vğ‘£v with a counter value xğ‘¥x, we inspect the xğ‘¥x-th edge incident to vğ‘£v in the stream. If it turns out we cannot visit that vertex (have already visited it), we can increment the counter and find the next edge to consider in the same pass (as the (x+1)ğ‘¥1(x+1)-th edge incident to vğ‘£v must be later in the stream than the xğ‘¥x-th edge incident to vğ‘£v). Therefore, finding the next edge to visit in the search only takes a single pass. Notice that we return to nodes in the search tree at most ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) times in total, because only visiting matched vertices can result in a â€˜failedâ€™ search recursion. So, a search that visits all matched vertices uses ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) passes, and this is the maximum number of passes for a single search. We start our search at most once from each unmatched vertex that has at least one edge (for which we can keep another counter to keep track), which means we do at most ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) searches. However, for each of these searches we start from different vertices, we still keep saved the set of visited matched vertices. If a search from a vertex visits a matched vertex and does not find an Mğ‘€M-augmenting path, then neither will a search from a different vertex by visiting that matched vertex again. In particular, this is because the graph is bipartite, because, when we start from an unmatched vertex on e.g. the â€˜rightâ€™ side, we have to end on an unmatched vertex on the â€˜leftâ€™ side, while all vertices we visit on the path are matched vertices. So, the current path does not interfere with the ability to successfully find an endpoint, which makes another search visiting the same matched edge have exactly the same result. Having to do ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) searches would indicate that we need to use ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) passes, at least one for every search. However, in the AL model, if we consider the xğ‘¥x-th vertex, and in the pass we use for it, we do no successful visit to a vertex (all adjacencies are matched and already visited), then in the same pass we can consider the (x+1)ğ‘¥1(x+1)-th vertex, because all edges incident to the (x+1)ğ‘¥1(x+1)-th vertex in the stream appear later than the edges incident to the xğ‘¥x-th vertex in the stream. Hence, in the AL model, over all ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) starting vertices, we only use ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) passes, because only (partially) successful searches increase the number of passes, and we can only visit ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) vertices in total. In the EA model, we require at least one pass for each vertex we want to start searching from, and so the total number of passes is ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}). We conclude that with ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) passes in the AL model, and ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) passes in the EA model, and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory we can execute a DFS to find an Mğ‘€M-augmenting path (if it exists). As mentioned, we can search for an Mğ‘€M-augmenting path only ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) times, as the existence of more Mğ‘€M-augmenting paths would result in returning NO. Therefore, we can find a maximum matching in BğµB using ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) passes and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory in the AL model. In the EA model, we require ğ’ªâ€‹(k3)ğ’ªsuperscriptğ‘˜3\\mathcal{O}(k^{3}) passes to accomplish this. Next, we show how to convert such a maximum matching as found by TheoremÂ 6.5 into a minimum vertex cover for BğµB, as asked by [8, Algorithm NT], for which we can use a DFS procedure as in TheoremÂ 6.5 as a subroutine. Given a bipartite graph BğµB as an AL stream and a maximum matching Mğ‘€M of size ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k), we can find a minimum vertex cover Xğ‘‹X for BğµB with |X|=|M|ğ‘‹ğ‘€|X|=|M|, using ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) passes and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. For the EA model, this takes ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) passes. We adapt a theorem by Bondy and MurtyÂ [13, PageÂ 74, TheoremÂ 5.3] to the streaming setting to achieve this lemma. Let us shortly go over what it entails. If our bipartite graph has vertex sets V,Vâ€²ğ‘‰superscriptğ‘‰â€²V,V^{\\prime} and a maximum matching Mğ‘€M, then we can find a minimum vertex cover Xğ‘‹X with |X|=|M|ğ‘‹ğ‘€|X|=|M| in the following manner. Denote all unmatched vertices in Vğ‘‰V with Uğ‘ˆU, and let ZâŠ†VâˆªVâ€²ğ‘ğ‘‰superscriptğ‘‰â€²Z\\subseteq V\\cup V^{\\prime} be the set of vertices connected to Uğ‘ˆU with an Mğ‘€M-alternating path (a path such that edges in Mğ‘€M and not in Mğ‘€M alternate). If S=Zâˆ©Vğ‘†ğ‘ğ‘‰S=Z\\cap V and T=Zâˆ©Vâ€²ğ‘‡ğ‘superscriptğ‘‰â€²T=Z\\cap V^{\\prime}, then Xğ‘‹X is given by X=(Vâˆ–S)âˆªTğ‘‹ğ‘‰ğ‘†ğ‘‡X=(V\\setminus S)\\cup T. As TâŠ†Xğ‘‡ğ‘‹T\\subseteq X and |X|=|M|ğ‘‹ğ‘€|X|=|M|, we can find and save Tğ‘‡T by executing a DFS procedure just like in TheoremÂ 6.5, without exceeding ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. This takes ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) passes in the AL model and ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) passes in the EA model, and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. Also, Vâˆ–Sğ‘‰ğ‘†V\\setminus S must only contain matched vertices, as UâŠ†Sğ‘ˆğ‘†U\\subseteq S. Therefore, in the same DFS procedure to find Tğ‘‡T, we can also save for every matched vertex in Vğ‘‰V if it is reachable through an Mğ‘€M-alternating path. Then Vâˆ–Sğ‘‰ğ‘†V\\setminus S is simply given by all matched vertices in Mğ‘€M for which we did not save that they were reachable. We conclude that we can find Xğ‘‹X, the minimum vertex cover such that |X|=|M|ğ‘‹ğ‘€|X|=|M|, in ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) passes (AL model) or ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) passes (EA model) and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. The final result is as follows, which consists of putting the original stream through each step for every time we require a pass, i.e. the number of passes of each of the parts of this theorem combine in a multiplicative fashion. Given a graph GğºG as an AL stream, we can produce a kernel of size 2â€‹k2ğ‘˜2k for the Vertex Cover [kğ‘˜k] problem using ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) passes and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory. In the EA model, this procedure takes ğ’ªâ€‹(k3)ğ’ªsuperscriptğ‘˜3\\mathcal{O}(k^{3}) passes. We execute TheoremÂ 6.5 on the stream produced by applying TheoremÂ 6.1 and then LemmaÂ 6.3 on the input stream (we have to apply these transformations every time that we require a pass). Notice that these applications increase the number of passes by a constant factor. On the result of TheoremÂ 6.5 we apply LemmaÂ 6.7 to obtain a minimum vertex cover for the specific bipartite graph BğµB. As described by Bar-Yehuda and EvenÂ [8, Algorithm NT], the sets C0subscriptğ¶0C_{0} and V0subscriptğ‘‰0V_{0} can be computed from this minimum vertex cover. This computation is a simple process, where C0subscriptğ¶0C_{0} contains the vertices vğ‘£v for which both v,vâ€²âˆˆBğ‘£superscriptğ‘£â€²ğµv,v^{\\prime}\\in B are contained in the minimum vertex cover of BğµB, and V0subscriptğ‘‰0V_{0} contains the vertices vğ‘£v where either v,vâ€²âˆˆBğ‘£superscriptğ‘£â€²ğµv,v^{\\prime}\\in B is contained in the minimum vertex cover of BğµB, but not both. Finding C0subscriptğ¶0C_{0} and V0subscriptğ‘‰0V_{0} from BğµB and its minimum vertex cover requires no passes over the stream, as they are simply given by analysing the minimum vertex cover of BğµB. These sets C0subscriptğ¶0C_{0} and V0subscriptğ‘‰0V_{0} are exactly the sets in the theorem by Nemhauser and TrotterÂ , and, as described by Chen et al.Â , we can use them to obtain a 2â€‹k2ğ‘˜2k kernel for vertex cover. The kernel is given by Gâ€²=Gâ€‹[V0]superscriptğºâ€²ğºdelimited-[]subscriptğ‘‰0G^{\\prime}=G[V_{0}], which we can find with a pass (we can output the kernel as a stream), and parameter kâ€²=k1âˆ’|C0|superscriptğ‘˜â€²subscriptğ‘˜1subscriptğ¶0k^{\\prime}=k_{1}-|C_{0}|, where k1subscriptğ‘˜1k_{1} is the parameter after application of TheoremÂ 6.1. All in all, this process takes ğ’ªâ€‹(k2)ğ’ªsuperscriptğ‘˜2\\mathcal{O}(k^{2}) (AL) or ğ’ªâ€‹(k3)ğ’ªsuperscriptğ‘˜3\\mathcal{O}(k^{3}) (EA) passes and ğ’ª~â€‹(k)~ğ’ªğ‘˜\\tilde{\\mathcal{O}}(k) bits of memory.\n\nReference markers found: [41]\n\nContext windows for each [ref]:\n[ref]41: Pğ‘ƒP has length ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k), as otherwise Mğ‘€M would exceed size ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k). It is known that a matching Mğ‘€M in a bipartite graph is maximum when there is no Mğ‘€M-augmenting path [ref]41. We can also find an Mğ‘€M-augmenting path only ğ’ªâ€‹(k)ğ’ªğ‘˜\\mathcal{O}(k) times, as the size of the matching increases by at least 1 for each Mğ‘€M-augmenting path. Let us now describe how we find an\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 41,\n            \"titles\": [\n                \"Dynamic Graph Stream Algorithms in ğ‘œâ¢(ğ‘›) Space\",\n                \"Approximation and fixed parameter subquadratic algorithms for radius and diameter in sparse graphs\",\n                \"Spatial scan statistics: approximations and performance study\",\n                \"Polynomial pass lower bounds for graph streaming algorithms\",\n                \"Multi-Pass Graph Streaming Lower Bounds for Cycle Counting, MAX-CUT, Matching Size, and Other Problems\",\n                \"Graph streaming lower bounds for parameter estimation and property testing via a streaming XOR lemma\",\n                \"Near-Quadratic Lower Bounds for Two-Pass Graph Streaming Algorithms\",\n                \"A local-ratio theorem for approximating the weighted vertex cover problem\",\n                \"Parameterized complexity of diameter\",\n                \"Fixed-parameter tractability of graph deletion problems over data streams\",\n                \"Fixed parameter tractability of graph deletion problems over data streams\",\n                \"On the streaming complexity of fundamental geometric problems\",\n                \"Graph Theory with Applications\",\n                \"Multivariate analysis of orthogonal range searching and graph distances\",\n                \"Nondeterminism within P\",\n                \"Subquadratic algorithms for the diameter and the sum of pairwise distances in planar graphs\",\n                \"Near-optimal lower bounds on the multi-party communication complexity of set disjointness\",\n                \"Vertex cover: Further observations and further improvements\",\n                \"Almost optimal super-constant-pass streaming lower bounds for reachability\",\n                \"Towards a theory of parameterized streaming algorithms\",\n                \"Kernelization via sampling with applications to finding matchings and related problems in dynamic graph streams\",\n                \"Brief announcement: New streaming algorithms for parameterized maximal matching & beyond\",\n                \"Parameterized streaming: Maximal matching and vertex cover\",\n                \"Diameter determination on restricted graph families\",\n                \"Fully polynomial FPT algorithms for some classes of bounded clique-width graphs\",\n                \"Satisfiability allows no nontrivial sparsification unless the polynomial-time hierarchy collapses\",\n                \"Parameterized Complexity\",\n                \"Beyond Helly graphs: the diameter problem on absolute retracts\",\n                \"A story of diameter, radius, and (almost) helly property\",\n                \"Fast Diameter Computation within Split Graphs\",\n                \"Diameter computation on ğ»-minor free graphs and graphs of bounded (distance) VC-dimension\",\n                \"Distributed Exact Shortest Paths in Sublinear Time\",\n                \"(1+Ïµ)1italic-Ïµ(1+\\\\epsilon)-approximate shortest paths in dynamic streams\",\n                \"Streaming kernelization\",\n                \"On graph problems in a semi-streaming model\",\n                \"Graph distances in the data-stream model\",\n                \"Voronoi diagrams on planar graphs, and computing the diameter in deterministic Ãµ(n5/35/3{}^{\\\\mbox{5/3}}) time\",\n                \"On the communication and streaming complexity of maximum bipartite matching\",\n                \"Superlinear lower bounds for multipass graph processing\",\n                \"Computing on data streams\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]41 based on the context and research area of Parameterized Complexity of Streaming Diameter and Connectivity Problems. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}