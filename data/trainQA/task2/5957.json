{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Beyond Submodularity: A Unified Framework of Randomized Set Selection with Group Fairness Constraints\n\nPaper Abstract: \n\nPaper Section Text:\nThe increasing use of machine learning algorithms in decision-making has raised concerns about the possibility of biases and discrimination. However, various efforts are being made to develop fair algorithms that ensure equitable outcomes for individuals or groups, even in sensitive domains. These efforts involve creating techniques for classification , ranking , clustering , bandit learning 8, voting , college admission , matching 4, influence maximization [ref]30, and diverse data summarization 6. Various concepts of fairness have been proposed in the literature, including individual fairness, group fairness, and subgroup fairness. These concepts intend to tackle discrimination and bias in algorithmic decision-making, particularly in sensitive domains like employment, housing, and criminal justice. However, there is no universal measure of fairness since it often depends on the context and can be affected by various factors such as the decision-making processâ€™s objectives and the sensitive attribute in question. In this paper, we propose a general group fairness notation that unifies many notations from previous works. We assume there are mğ‘šm groups defined by a set of shared attributes like race, gender, or age. To assess the appropriateness of a particular solution set Sğ‘†S for a specific group tâˆˆ[m]ğ‘¡delimited-[]ğ‘št\\in[m], we introduce mğ‘šm group utility functions g1,g2,â‹¯,gm:2Vâ†’â„â‰¥0:subscriptğ‘”1subscriptğ‘”2â‹¯subscriptğ‘”ğ‘šâ†’superscript2ğ‘‰â„0g_{1},g_{2},\\cdots,g_{m}:2^{V}\\rightarrow\\mathbb{R}{\\geq 0}. Each group utility function gtâ€‹(S)subscriptğ‘”ğ‘¡ğ‘†g_{t}(S) evaluates the utility that group tğ‘¡t derives from the solution set Sğ‘†S. For instance, in committee selection , gtâ€‹(S)subscriptğ‘”ğ‘¡ğ‘†g_{t}(S) corresponds to the number of candidates chosen from group tğ‘¡t in the solution set Sğ‘†S. Given a set of feasible subsets â„±â„±\\mathcal{F}, let xâˆˆ â„±ğ‘¥superscript01â„±x\\in ^{\\mathcal{F}} represent a distribution over solution sets in â„±â„±\\mathcal{F}, where xSsubscriptğ‘¥ğ‘†x_{S} is the probability of choosing Sâˆˆâ„±ğ‘†â„±S\\in\\mathcal{F}. A distribution xğ‘¥x is deemed fair if âˆ‘Sâˆˆâ„±â€‹xSâ€‹gtâ€‹(S)â‰¥Î±t,âˆ€tâˆˆ[m]formulae-sequenceğ‘†â„±subscriptğ‘¥ğ‘†subscriptğ‘”ğ‘¡ğ‘†subscriptğ›¼ğ‘¡for-allğ‘¡delimited-[]ğ‘š\\sum{S\\in\\mathcal{F}}x_{S}g_{t}(S)\\geq\\alpha_{t},\\forall t\\in[m], meaning the expected utility from each group tâˆˆ[m]ğ‘¡delimited-[]ğ‘št\\in[m] is lower bounded by Î±tsubscriptğ›¼ğ‘¡\\alpha_{t}. This enables the consideration of each groupâ€™s representation in the final outcome, promoting diversity and preventing under-representation of any particular group. In addition, there is a global utility function f:2Vâ†’â„â‰¥0:ğ‘“â†’superscript2ğ‘‰subscriptâ„absent0f:2^{V}\\rightarrow\\mathbb{R}_{\\geq 0}. The expected (global) utility of a distribution xğ‘¥x can be computed as âˆ‘Sâˆˆâ„±xSâ€‹fâ€‹(S)subscriptğ‘†â„±subscriptğ‘¥ğ‘†ğ‘“ğ‘†\\sum_{S\\in\\mathcal{F}}x_{S}f(S). Our goal is to find a distribution xğ‘¥x that maximizes âˆ‘Sâˆˆâ„±xSâ€‹fâ€‹(S)subscriptğ‘†â„±subscriptğ‘¥ğ‘†ğ‘“ğ‘†\\sum_{S\\in\\mathcal{F}}x_{S}f(S) while ensuring that âˆ‘Sâˆˆâ„±xSâ€‹gtâ€‹(S)â‰¥Î±t,âˆ€tâˆˆ[m]formulae-sequencesubscriptğ‘†â„±subscriptğ‘¥ğ‘†subscriptğ‘”ğ‘¡ğ‘†subscriptğ›¼ğ‘¡for-allğ‘¡delimited-[]ğ‘š\\sum_{S\\in\\mathcal{F}}x_{S}g_{t}(S)\\geq\\alpha_{t},\\forall t\\in[m]. A formal definition of this problem is listed in P.0. We show that this formulation brings together and extends numerous noteworthy applications in both machine learning and operations research. We next summarize the main contributions of this paper. We develop a polynomial-time algorithmic framework for P.0 based on ellipsoid method. One main algorithmic finding (as formally presented in Theorem 3.1) is that suppose that for all zâˆˆâ„â‰¥0mğ‘§superscriptsubscriptâ„absent0ğ‘šz\\in\\mathbb{R}_{\\geq 0}^{m}, there exists a polynomial-time algorithm that returns a set Aâˆˆâ„±ğ´â„±A\\in\\mathcal{F} such that for some Ï,Î¼âˆˆ ğœŒğœ‡01\\rho,\\mu\\in . Then there is a polynomial-time (Ï,Î¼)ğœŒğœ‡(\\rho,\\mu)-approximation algorithm for P.0. Here, the ÏğœŒ\\rho represents the approximation ratio, while the Î¼ğœ‡\\mu indicates that the solution may violate the fairness constraint by at most a factor of Î¼ğœ‡\\mu. Hence, solving P.0 is reduced to finding an approximation algorithm for a combinatorial subset selection problem. We utilize this result to tackle various applications such as fairness-aware submodular maximization, sequential submodular maximization with group constraints, and assortment planning with market share constraints. Our approach outperforms existing methods for some of these applications, while for others, we introduce novel applications and develop the first approximation algorithms. Notably, when fğ‘“f is non-negative monotone and submodular, and gtsubscriptğ‘”ğ‘¡g_{t} is a modular function, our approach gives a feasible and optimal (1âˆ’1/e,1)11ğ‘’1(1-1/e,1)-approximation solution. We explore extensions to other commonly used fairness metrics and propose effective algorithms for solving them. In the first extension, we introduce additional upper bounds Î²tsubscriptğ›½ğ‘¡\\beta_{t} on the expected utility of each group tâˆˆ[m]ğ‘¡delimited-[]ğ‘št\\in[m]. Specifically, we require that Î±tâ‰¤âˆ‘Sâˆˆâ„±xSâ‹…gtâ€‹(S)â‰¤Î²t,âˆ€tâˆˆ[m]formulae-sequencesubscriptğ›¼ğ‘¡subscriptğ‘†â„±â‹…subscriptğ‘¥ğ‘†subscriptğ‘”ğ‘¡ğ‘†subscriptğ›½ğ‘¡for-allğ‘¡delimited-[]ğ‘š\\alpha_{t}\\leq\\sum_{S\\in\\mathcal{F}}x_{S}\\cdot g_{t}(S)\\leq\\beta_{t},\\forall t\\in[m]. In the second extension, we explore another frequently used measure of fairness that aims to achieve parity in pairwise utility between groups. The degree of fairness is defined by a parameter Î³ğ›¾\\gamma. Specifically, we require that for any two groups t,tâ€²âˆˆ[m]ğ‘¡superscriptğ‘¡â€²delimited-[]ğ‘št,t^{\\prime}\\in[m], the difference between their expected utilities does not exceed Î³ğ›¾\\gamma, i.e., âˆ‘Sâˆˆâ„±xSâ‹…gtâ€‹(S)âˆ’âˆ‘Sâˆˆâ„±xSâ‹…gtâ€²â€‹(S)â‰¤Î³,âˆ€t,tâ€²âˆˆ[m]formulae-sequencesubscriptğ‘†â„±â‹…subscriptğ‘¥ğ‘†subscriptğ‘”ğ‘¡ğ‘†subscriptğ‘†â„±â‹…subscriptğ‘¥ğ‘†subscriptğ‘”superscriptğ‘¡â€²ğ‘†ğ›¾for-allğ‘¡superscriptğ‘¡â€²delimited-[]ğ‘š\\sum_{S\\in\\mathcal{F}}x_{S}\\cdot g_{t}(S)-\\sum_{S\\in\\mathcal{F}}x_{S}\\cdot g_{t^{\\prime}}(S)\\leq\\gamma,\\forall t,t^{\\prime}\\in[m]. Over the years, there has been a significant effort to develop fair algorithms across various fields to address the issue of biased decision-making. In the domain of influence maximization and classification, researchers have been actively developing fair algorithms [ref]30 . Similarly, in voting systems, the focus has been on ensuring that election outcomes are a fair representation of the preferences of voters, leading to the development of fair algorithms . The field of bandit learning, which involves making sequential decisions based on uncertain information, has also seen a growing interest in the development of fair algorithms to address the issue of bias 8. Additionally, the field of data summarization has seen an increasing focus on the development of fair algorithms [ref]9 to provide a balanced representation of data and avoid biased decision-making. The choice of fairness metric in previous studies depends on the context and type of bias being addressed, resulting in a range of optimization problems and fair algorithms customized to the particular demands of each application. We adopt a general group utility function to assess the solutionâ€™s utility from each groupâ€™s perspective. Our framework is general enough to encompass numerous existing fairness notations, including the 80%percent8080\\%-rule , statistical parity 5, and proportional representation . While most previous research on fairness-aware algorithm design (such as [ref]9   ) aims to find a deterministic solution set, our goal is to compute a randomized solution that can meet the group fairness constraints on average. This approach offers more flexibility in attaining group fairness. Our framework is general enough to encompass various existing studies on achieving group fairness through randomization, such as those examined in  2 9.\n\nReference markers found: [30]\n\nContext windows for each [ref]:\n[ref]30: even in sensitive domains. These efforts involve creating techniques for classification , ranking , clustering , bandit learning 8, voting , college admission , matching 4, influence maximization [ref]30, and diverse data summarization 6. Various concepts of fairness have been proposed in the literature, including individual fairness, group fairness, and subgroup fairness. These concepts\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 30,\n            \"titles\": [\n                \"Fair and Representative Subset Selection from Data Streams\",\n                \"College admissions with affirmative action\",\n                \"Sequential submodular maximization and applications to ranking an assortment of products\",\n                \"Fairness in recommendation ranking through pairwise comparisons\",\n                \"Adverse impact and test validation: A practitionerâ€™s guide to valid and defensible employment testing\",\n                \"Convex Optimization: Algorithms and Complexity\",\n                \"Constrained submodular maximization via a nonsymmetric technique\",\n                \"Submodular maximization with cardinality constraints\",\n                \"Maximizing a submodular set function subject to a matroid constraint\",\n                \"Fair and diverse dpp-based data summarization\",\n                \"Multiwinner Voting with Fairness Constraints\",\n                \"Ranking with fairness constraints\",\n                \"Fair assortment planning\",\n                \"Fair Clustering Through Fairlets\",\n                \"Matroids, matchings, and fairness\",\n                \"Fairness through awareness\",\n                \"Fairness in Streaming Submodular Maximization: Algorithms and Hardness\",\n                \"The ellipsoid method and its consequences in combinatorial optimization\",\n                \"Fairness in learning: Classic and contextual bandits\",\n                \"The Fairness of Risk Scores Beyond Classification: Bipartite Ranking and the xAUC Metric\",\n                \"A cascade model for externalities in sponsored search\",\n                \"Mitigating bias in set selection with noisy protected attributes\",\n                \"Fully proportional representation\",\n                \"Pairwise Fairness for Ranking and Regression\",\n                \"An analysis of approximations for maximizing submodular set functions-i\",\n                \"Approximation algorithm for submodular maximization under submodular cover\",\n                \"On maximizing sums of non-monotone submodular and linear functions\",\n                \"Optimal approximation for submodular and supermodular optimization with bounded curvature\",\n                \"Revenue management under a general discrete choice model of consumer behavior\",\n                \"Achieving Long-term Fairness in Submodular Maximization through Randomization\",\n                \"Group-Fairness in Influence Maximization\",\n                \"Group Fairness in Non-monotone Submodular Maximization\",\n                \"Linear submodular bandits and their application to diversified retrieval\",\n                \"Fairness constraints: Mechanisms for fair classification\",\n                \"Generated Reference Title 34 for [ref]30\",\n                \"Generated Reference Title 35 for [ref]30\",\n                \"Generated Reference Title 36 for [ref]30\",\n                \"Generated Reference Title 37 for [ref]30\",\n                \"Generated Reference Title 38 for [ref]30\",\n                \"Generated Reference Title 39 for [ref]30\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]30 based on the context and research area of Beyond Submodularity: A Unified Framework of Randomized Set Selection with Group Fairness Constraints. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}