{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: A Novel Nuanced Conversation Evaluation Framework for Large Language Models in Mental Health\n\nPaper Abstract: \n\nPaper Section Text:\nIn this section, we identify and analyse notable papers combining mental health and LLMs. It is important to note that the number of relevant works is limited, which may be due to several complicated factors ranging from medical data privacy to the popularity of other domains being more appealing. Arguably, the original paper that spurred interest in this domain proposed two of the first pre-trained models specialised for mental health use, MentalBERT and MentalRoBERTa . However, an issue that is present in the paper is the use of unverified Reddit data to train the model. When evaluating the model, which is the topic we are most interested in, we see the paper focus on benchmarking the mental health detection abilities of the models. Having a chatbot that could have a conversation with an individual and then potentially diagnose them could be incredibly beneficial for early detection and treatment.\n While some relevant papers also provide attention to evaluating for demographic or racial bias, the focus tends to remain on detection performance [ref]30. This paper leverages a more popular and commonly used frontier model, GPT3, to conduct its analysis, making results more applicable than analyses done with MentalBERT or MentalRoBERTa. This is due to the widespread use and popularity of GPT3. However, a lack of depth is present by not comparing results across models. On top of this, by not providing any analysis of user interaction, detection performance is effectively done in isolation. The reality is that this separation from user interaction makes the results less meaningful, as any real applications that leverage the results will not be done in isolation from users. We see another relevant paper, [ref]31, which focuses entirely on depression detection and investigates and attempts to improve the domain generalisability of models. The paper has promising results in identifying that grounding the model on a specific set of depression symptoms improves generalisability. Intuitively, we are also improving model interpretability by anchoring the model to a set of symptoms. However, this paper does use unverified Reddit data, which raises questions about how it will perform when applied in the real world. Due to the topic, it also focuses its evaluation solely on detection performance. Which, as aforementioned, needs more nuance and reveals little about user interaction. While the papers listed above tend to focus on a singular model and are focused on investigating one specific thing, we do see documents that are much larger in scale . This work evaluates a comprehensive amount of models, ranging from Alpaca to GPT4, across different categories, from zero-shot prompting to instructional fine-tuning. However, even this paper uses public data from social media sites to train the models. This opens the door to conversations about extrapolating these results when dealing with genuine data. Additionally, as mentioned in the paper and similarly to the documents listed above, the evaluation is focused solely on detection performance. When we diverge from the papers where the evaluation centres around mental health detection or classification , the literature becomes increasingly limited and relevant to our topic. We see papers put forward measures like word count per therapy session, sentiment analysis of the user, and emotion analysis of the user to measure LLM performance . While this paper provides a practical summary of several related topics, its analysis focuses on the user instead of the LLM. To emphasise that, all of the metrics mentioned are focused on analysing the content produced by the user rather than that of the LLM. When looking for papers that specifically focus on evaluating the characteristics of the responses made by the LLM, the work gets even more limited. Metrics such as the LLM’s ability to interpret, explore, and demonstrate emotional reactions have been evaluated [ref]3. An issue with this paper is that the data used is not verified genuine mental health data. However, something they do incredibly well is leaning into the mental health domain and borrowing from the field of mental health counselling to use metrics like interpretations and explorations. Several works establish a need for additional work in developing mental health LLMs for purposes other than standard diagnosis or record keeping. “Chatbots for psychiatric diagnosis can not achieve satisfying performance by simply collecting symptoms like questionnaires. Instead, they should be equipped with various professional skills, such as emotional support, to complete the diagnosis task effectively” . While this paper brings to light what a number of the previous ones are lacking in terms of what should be considered, it has places where it could be improved. Firstly, it focuses just on depression detection and doesn’t include other conditions or topics. Secondly, while it discusses and evaluates several more interesting conversational characteristics like fluency, expertise, and engagement, these are reviewed by humans. This makes the evaluation less scalable and more open to bias. However, understandably, the nuance of the metrics lends to the difficulty in making them automatic. While we traditionally relied upon human evaluation to help judge hard-to-quantify nuanced qualities, we now see LLMs being leveraged for this task. For example, we have specifically seen papers leverage an LLM, RoBERTa, to help measure empathy . While this is a significant step forward, this paper would benefit from tuning the model’s temperature to make it increasingly deterministic among responses. It would also benefit from using frontier high-performance models for detection rather than just RoBERTa. Additionally, comparing performance across the chosen models would add an exciting facet of analysis. Considering this grouping of literature, we can identify some things that are missing or could be improved in future work. Papers would benefit from an increased focus on evaluating the linguistic qualities of the responses provided by the LLM instead of assessing the LLM’s ability to diagnose and classify the user. This is an avenue that has yet to be thoroughly studied. While difficult due to the nature of medical data, the quality of derived results would benefit highly from using verified mental health data. Most papers mentioned here use public open-source and unverified data from Reddit [ref]3, . Additionally, it would be interesting to see a study across topics and different frontier LLMs to investigate how mental health topics impact LLM conversation ability. This is because some of the most relevant literature focuses on singular topics like depression  and uses just one LLM in the analysis. Additionally, leveraging LLMs over human evaluations to measure nuanced metrics could provide a scalable and more objective alternative. Finally, leaning into the counselling world to derive more applied metrics, similarly to as started by [ref]3, could make generated results much more effective.\n\nReference markers found: [30]\n\nContext windows for each [ref]:\n[ref]30: beneficial for early detection and treatment.\n While some relevant papers also provide attention to evaluating for demographic or racial bias, the focus tends to remain on detection performance [ref]30. This paper leverages a more popular and commonly used frontier model, GPT3, to conduct its analysis, making results more applicable than analyses done with MentalBERT or MentalRoBERTa. This\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 30,\n            \"titles\": [\n                \"Improving the Generalizability of Depression Detection by Leveraging Clinical Questionnaires\",\n                \"Evaluating large language models for use in healthcare: A framework for translational value assessment\",\n                \"EMP-EVAL: A Framework for Measuring Empathy in Open Domain Dialogues\",\n                \"A computational approach to understanding empathy expressed in text-based mental health support\",\n                \"Attention Is All You Need\",\n                \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n                \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\",\n                \"MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare\",\n                \"roberta-base-go_emotions llm model\",\n                \"Language Models are Few-Shot Learners\",\n                \"Llama 2: Open Foundation and Fine-Tuned Chat Models\",\n                \"6 main differences between llama 2, gpt3.5 & gpt4\",\n                \"Mistral ai, a paris-based openai rival, closed its $415 million funding round\",\n                \"Mistral 7B\",\n                \"Lifetime prevalence and age-of-onset distributions of dsm-iv disorders in the national comorbidity survey replication\",\n                \"The effectiveness of psychotherapy\",\n                \"The state of mental health in america, 2019\",\n                \"Rapid assessment of psychological and epidemiological correlates of covid-19 concern, financial strain, and health-related behavior change in a large online sample\",\n                \"Upwork study finds 22% of american workforce will be remote by 2025\",\n                \"Fulfilling the promise of mental health technology to reduce public health disparities: Review and research agenda\",\n                \"A comparative conversation analytic study of formulations in psychoanalysis and cognitive psychotherapy\",\n                \"A review of conversational practices in psychotherapy\",\n                \"Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4\",\n                \"DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models\",\n                \"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity\",\n                \"Rouge: A package for automatic evaluation of summaries\",\n                \"LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models\",\n                \"LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset\",\n                \"A Survey on Evaluation of Large Language Models\",\n                \"Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench\",\n                \"Testing domain knowledge and risk of bias of a large-scale general artificial intelligence model in mental health\",\n                \"Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data\",\n                \"A systematic survey on computational agents for mental health aid\",\n                \"LLM-empowered Chatbots for Psychiatrist and Patient Simulation: Application and Evaluation\",\n                \"Bleu: a method for automatic evaluation of machine translation\",\n                \"Evaluation framework to guide implementation of ai systems into healthcare settings\",\n                \"Relational Integrative Psychotherapy, volume Website Edition\",\n                \"Practical counselling and helping skills: Text and activities for the lifeskills counselling model\",\n                \"Rbo v/s kendall tau to compare ranked lists of items\",\n                \"textblob documentation\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]30 based on the context and research area of A Novel Nuanced Conversation Evaluation Framework for Large Language Models in Mental Health. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}