{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Joint Detection and Localization of Stealth False Data Injection Attacks in Smart Grids using Graph Neural Networks\n\nPaper Abstract: \n\nPaper Section Text:\nAs indicated earlier, two main approaches have been proposed for detecting and localizing the FDIAs: model-based and data driven approaches [ref]8.\nModel-based approaches such as those in      do not require any historical datasets. Nevertheless, scalability, manual threshold optimization process, detection lags, model complexity, and localization resolution could hinder the usability of them for real applications. For instance, results are not published in  and localization could only be done at the cluster level in .\nDetection times are larger than a second in  and  for small test systems having 12 and 36 buses, respectively. In their model-based detectors, authors of  utilize GSP techniques such as Local Smoothness (LS) and Vertex-Frequency Energy Distribution (VFED). Nonetheless, they evaluate their method with an easily detectable attack by the classical LNRT based BDD methods which can conceal the actual performance of the the model.\nSpecifically, they simulate the FDIAs using zai​(t)=zoi​(t)+(−1)d.a.u.r​a​n​g​eformulae-sequencesuperscriptsubscript𝑧𝑎𝑖𝑡superscriptsubscript𝑧𝑜𝑖𝑡superscript1𝑑𝑎𝑢𝑟𝑎𝑛𝑔𝑒z_{a}^{i}(t)=z_{o}^{i}(t)+(-1)^{d}.a.u.range where d∼{0,1}similar-to𝑑01d\\sim\\{0,1\\} is a binary random variable (r.v.), u∼𝒰​ similar-to𝑢𝒰01u\\sim\\mathcal{U}  is an uniform r.v., r​a​n​g​e=max⁡(zoi)−min⁡(zoi)𝑟𝑎𝑛𝑔𝑒superscriptsubscript𝑧𝑜𝑖superscriptsubscript𝑧𝑜𝑖range=\\max(z_{o}^{i})-\\min(z_{o}^{i}) and a𝑎a is scaler for the attack.\nFor instance, if zoi∼𝒩​(μo,σo2)similar-tosuperscriptsubscript𝑧𝑜𝑖𝒩subscript𝜇𝑜superscriptsubscript𝜎𝑜2z_{o}^{i}\\sim\\mathcal{N}(\\mu_{o},\\sigma_{o}^{2}), expected values of the attacked data distribution become 𝔼⁡[μa]=μo𝔼subscript𝜇𝑎subscript𝜇𝑜\\operatorname{\\mathbb{E}}[\\mu_{a}]=\\mu_{o}, and 𝔼⁡[σa]=6​a​σo𝔼subscript𝜎𝑎6𝑎subscript𝜎𝑜\\operatorname{\\mathbb{E}}[\\sigma_{a}]=6a\\sigma_{o} due to the product properties of uniform and normal distributions, where μo,σosubscript𝜇𝑜subscript𝜎𝑜\\mu_{o},\\sigma_{o} and μa,σasubscript𝜇𝑎subscript𝜎𝑎\\mu_{a},\\sigma_{a} tuples represent the mean and standard deviation of original and attacked data, respectively.\nThe accuracy of localization for IEEE 118-bus test system when a=4𝑎4a=4, which makes 𝔼⁡[σa]=24​σo𝔼subscript𝜎𝑎24subscript𝜎𝑜\\operatorname{\\mathbb{E}}[\\sigma_{a}]=24\\sigma_{o}, are 85%percent8585\\% and 91%percent9191\\% for the LS and VFED techniques, respectively.\nThese high accuries are not realistic since the scaler a𝑎a plays a significant role in simulation process. The data-driven methods, in contrast, present a better performance since historical datasets are growing and the modeling capability of these algorithms is being increased [ref]8 .\nFor example, in their data-driven method in 5 researchers employ an LSTM model for each measurement in a 5-bus test system in which only one bus is under attack at a time to detect and localize the point-wise FDIAs.\nThey report greater than 90%percent9090\\% accuracy for detection and localization of random, ramp, and scale attacks for low, medium, and high attack levels.\nHowever, the capability of this method for detection and localization of different FDIAs in large test cases has not been investigated.\nBesides, assigning an independent model to each measurement has two major drawbacks: (i) overall model complexity increases severely, and (ii) spatial correlations of the measurements are ignored totally. In data-driven approaches, compatibility between the structure of collected data and architecture of the data-driven model is the primary factor on the performance of the model.\nFor instance, DT, KNN, or MLP architectures could be better suited for a dataset having uncorrelated features from different spaces.\nSimilarly, an RNN architecture might be more applicable to model the recurrent relations in a natural language data.\nA CNN architecture, in contrast, could be more favorable than GNN for an image data where pixel locality is well modeled in 2D Euclidean space.\nHowever, as demonstrated with Fig. 1a, spatial correlations in power measurements data can only be captured in a non-Euclidean space dictated by the topology of the grid.\nFor instance, if we had a hypothetical power grid like in Fig. 1a, a CNN architecture could have comparable performances with ARMA.\nNonetheless, for a power grid data collected from graph type structure, a GNN is more advantageous than other architectures as can be seen from the detection results in Table IV and the localization distributions in Figs. 6 and 7.\nAs for the GNN family, ARMA outperforms CHEB due to the fact that rational GFs implemented using the ARMA architecture provide more flexible frequency responses compared to the polynomial filters such as CHEB . It is observed from our extensive experiments that the proposed ARMA based model performs better compared to other models for larger test cases.\nAs an illustration, for the 95%percent9595\\% F​1𝐹1F1 threshold level, it outperforms the second best model CHEB by 5.64%percent5.645.64\\%, 8.56%percent8.568.56\\%, and 10.07%percent10.0710.07\\% in SW localization and by 8.78%percent8.788.78\\%, 11.87%percent11.8711.87\\%, and 14.67%percent14.6714.67\\% in NW localization for IEEE 57-, 118-, and 300-bus systems, respectively.\nThis difference is due to the fact that in larger and denser graphs,\n(i) the spatial correlation between adjacent measurements becomes more dominant compared to the global correlations and\n(ii) ARMA GFs better adapt to abrupt changes in the spectral domain compared to the polynomial ones. As stated before, the output of each vertex v𝑣v only depends on its K𝐾K-hop neighbors for a K𝐾K-order polynomial GF.\nIn other words, the output of v𝑣v is independent of the vertices beyond the K𝐾K-hop neighbors for a K𝐾K-order FIR GF [ref]22.\nThus, to capture the global characteristics of the graph, an FIR GF requires “high” order spectral response as can be seen from Fig. 4.\nNevertheless, due to the poor interpolation and extrapolation capabilities of the high order polynomials, it becomes sensitive to variations and may overfit to the training data .\nTo verify this characteristic, we fix the other parameters of CHEB GF at their optimal values tabulated in Table III and train a CHEB model for the IEEE 300-bus test system for each K∈{5,7,9,11}𝐾57911K\\in\\{5,7,9,11\\}.\nFDIA detection results in terms of F​1%𝐹percent1F1\\% are depicted in Fig. 10. Clearly, increasing K𝐾K beyond a certain point makes the model susceptible to variations such as noise, and thus, it can degrade the test set performance. Note that similar conclusion can also be corroborated for the localization results. Bus level localization is a multi-label classification task and should be evaluated accordingly.\nBesides, performance metrics can cause inaccurate or misleading outcomes when they are not interpreted correctly.\nNamely, missing an attack (FN) could be much more severe than a false alarm (FP) when dealing with FDIAs due to their consequences.\nAn example of localization results for a hypothetical model is given in Table VI with 4 samples in rows and 5 buses in columns where TP, FP, FN, and TN samples are highlighted with green, blue, red, and black colors, respectively.\nIn addition, SW and NW localization results are given at the end of each row and columns in terms of accuracy A​C​C=T​P+T​NT​P+T​N+F​P+F​N𝐴𝐶𝐶𝑇𝑃𝑇𝑁𝑇𝑃𝑇𝑁𝐹𝑃𝐹𝑁ACC=\\frac{TP+TN}{TP+TN+FP+FN} and F​1𝐹1F1 percentages. The A​C​Cs​w𝐴𝐶subscript𝐶𝑠𝑤ACC_{sw} is not a reliable metric since it can not properly take into account the distribution of errors. For instance, although A​C​Cs​w𝐴𝐶subscript𝐶𝑠𝑤ACC_{sw} shows high accuracy for all the samples, it does not have any mechanism to mirror the faults at n2subscript𝑛2n_{2} which can have\nserious consequences for the power system.\nComparing F​1𝐹1F1 with A​C​C𝐴𝐶𝐶ACC reveals that F​1𝐹1F1 has a better mechanism to evaluate the accuracy of the model.\nFor instance, the A​C​Cs​w=60%𝐴𝐶subscript𝐶𝑠𝑤percent60ACC_{sw}=60\\% for s3subscript𝑠3s_{3} and s4subscript𝑠4s_{4} since they have the same number of falsely predicted samples.\nF​1s​w𝐹subscript1𝑠𝑤F1_{sw} metric, in contrast, yields 50%percent5050\\% for s3subscript𝑠3s_{3} and 75%percent7575\\% for s4subscript𝑠4s_{4} since s4subscript𝑠4s_{4} includes 1 more TP compared to the s3subscript𝑠3s_{3}.\nSince our focus is to determine the localization of FDIAs, then F​1𝐹1F1 is the proper candidate to evaluate the accuracy of the model. The result and discussion reveals the supremacy of our model compared to DT, MLP, RNN, CNN, and CHEB models in terms of detection and localization of FDIAs.\n\nReference markers found: [8]\n\nContext windows for each [ref]:\n[ref]8: As indicated earlier, two main approaches have been proposed for detecting and localizing the FDIAs: model-based and data driven approaches [ref]8.\nModel-based approaches such as those in      do not require any historical datasets. Nevertheless, scalability, manual threshold optimization process, detection lags, model complexity, and\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 8,\n            \"titles\": [\n                \"A Survey of Machine Learning Methods for Detecting False Data Injection Attacks in Power Systems\",\n                \"Smart grids: A cyber–physical systems perspective\",\n                \"Power flow cyber attacks and perturbation-based defense\",\n                \"Cyber–physical system security for the electric power grid\",\n                \"Power System State Estimation: Theory and Implementation\",\n                \"Monitoring and optimization for power grids: A signal processing perspective\",\n                \"A review of false data injection attacks against modern power systems\",\n                \"False data injection attacks against state estimation in electric power grids\",\n                \"A survey on the detection algorithms for false data injection attacks in smart grids\",\n                \"A real-time attack localization algorithm for large power system networks using graph-theoretic techniques\",\n                \"Joint detection and mitigation of false data injection attacks in agc systems\",\n                \"Cyber attack localization in smart grids by graph modulation (brief announcement)\",\n                \"Interval observer-based detection and localization against false data injection attack in smart grids\",\n                \"Detection and locating cyber and physical stresses in smart grids using graph signal processing\",\n                \"Physics-and learning-based detection and localization of false data injections in automatic generation control\",\n                \"Pattern Recognition and Machine Learning (Information Science and Statistics)\",\n                \"A Comprehensive Survey on Graph Neural Networks\",\n                \"Graph signal processing: Overview, challenges, and applications\",\n                \"The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains\",\n                \"Convolutional neural networks on graphs with fast localized spectral filtering\",\n                \"Graph Neural Networks with Convolutional ARMA Filters\",\n                \"Infinite impulse response graph filters in wireless sensor networks\",\n                \"Design of graph filters and filterbanks\",\n                \"Graph Neural Networks Based Detection of Stealth False Data Injection Attacks in Smart Grids\",\n                \"Visualizing Data using GTSNE\",\n                \"Chebyshev polynomials\",\n                \"The scientist and engineer’s guide to digital signal processing\",\n                \"Richard von mises\",\n                \"Distributed Autoregressive Moving Average Graph Filters\",\n                \"Think globally, act locally: On the reshaping of information landscapes\",\n                \"Autoregressive moving average graph filtering\",\n                \"Detection and control against replay attacks in smart grid\",\n                \"Detecting false data injection attacks in ac state estimation\",\n                \"Online data integrity attacks against real-time electrical market in smart grid\",\n                \"Integrity attacks on real-time pricing in smart grids: impact and countermeasures\",\n                \"Actual - historical\",\n                \"Machine Learning Methods for Attack Detection in the Smart Grid\",\n                \"Detection of false data attacks in smart grid with supervised learning\",\n                \"pandapower - an Open Source Python Tool for Convenient Modeling, Analysis and Optimization of Electric Power Systems\",\n                \"Scikit-learn: Machine learning in python\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]8 based on the context and research area of Joint Detection and Localization of Stealth False Data Injection Attacks in Smart Grids using Graph Neural Networks. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}