{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Deep Reinforcement Learning for Uplink Scheduling in NOMA-URLLC Networks\n\nPaper Abstract: \n\nPaper Section Text:\n[\ncap = Simulation Settings.,\ncaption = Network Simulation Settings.,\nlabel = tab:simparam,\npos = ht\n]â€”câ€”câ€”câ€”\n\\tnote[a]For a channel bandwidth of 40Â MHz, the signal occupies 38.16Â MHz after having excluded guard bandsÂ .\n\\tnote[b]Typical delay spread for an indoor hot-spot scenario with carrier frequency 4 GHzÂ .\n\\tnote[c]Normal cyclic prefix duration for symbols not at the start or in the middle of the subframeÂ .\n\\tnote[e]Size of an array of size 565656 corresponding to a maximum deadline of 565656 frames, i.e., 101010Â ms, with 333Â bits entries giving the number of packets for every deadline.\n\\tnote[d]Headers include 2Â bytes of CRCÂ , 1Â byte for MACÂ , 0Â byte for RLCÂ 5, 2Â bytes for PDCPÂ 6, 0Â byte for SDAPÂ 7 and 40Â bytes for IPv6Â 8.\n\nParameter  Notation  Value \nCarrier frequency  fcsubscriptğ‘“ğ‘f_{c} 444Â GHz \nBandwidth\\tmark[a]  Wğ‘ŠW 38.1638.1638.16 MHz \nSubcarrier spacing  Î”â€‹fÎ”ğ‘“\\Delta f 303030 kHz \nDelay spread\\tmark[b]  Tdsubscriptğ‘‡ğ‘‘T_{d} 100100100Â ns \nOFDM symbol information part  Tisubscriptğ‘‡ğ‘–T_{i} 33.3333.3333.33Â Î¼ğœ‡\\mus \nOFDM symbol cyclic prefix\\tmark[c]  Tcâ€‹psubscriptğ‘‡ğ‘ğ‘T_{cp} 2.342.342.34Â Î¼ğœ‡\\mus \nSIC limitation  BğµB 333\nInformation length  Lisubscriptğ¿ğ‘–L_{i} 323232Â bytes \nHeaders\\tmark[d] length  Lhsubscriptğ¿â„L_{h} 464646Â bytes \nBuffer information\\tmark[e]  Lbsubscriptğ¿ğ‘L_{b} 141414Â bytes \nAverage inter-arrival rate  1/Î»1ğœ†1/\\lambda  2 ms\nDeadline  Î´ğ›¿\\delta 111Â ms \nNetwork layout  â„“Ã—â„“â€²â„“superscriptâ„“â€²\\ell\\times\\ell^{\\prime} 50Ã—1205012050\\times 120Â m2\nNoise Power Spectral Density  N0subscriptğ‘0N_{0} âˆ’174174-174Â dBm/Hz\nBS noise figure  NFsubscriptğ‘ğ¹N_{F} 555Â dB \nBS antenna height  h~bsubscript~â„ğ‘\\tilde{h}_{b} 333Â m \nBS antenna gain  Gbsubscriptğºğ‘G_{b} 555Â dBi \nBS number of antennas  nasubscriptğ‘›ğ‘n_{a}  4 \nDevice transmit power  pğ‘p 232323Â dBm \nDevice antenna height  h~dsubscript~â„ğ‘‘\\tilde{h}_{d} 1.51.51.5Â m \nDevice antenna gain  Gdsubscriptğºğ‘‘G_{d} 00Â dBi \nDevice speed  vğ‘£v 333Â km/h \n Our simulation settings (see TableÂ LABEL:tab:simparam) adopt the parameters of the factory automation use case of the 3GPP 5G NR specifications on URLLCÂ  and industrial IoTÂ 9. Our radio frame is made of five time-slots (Tf=5â€‹Tssubscriptğ‘‡ğ‘“5subscriptğ‘‡ğ‘ T_{f}=5T_{s}), whose duration Tssubscriptğ‘‡ğ‘ T_{s} is equivalent to an OFDM symbol in NR. It can be decomposed into an information part of duration Tisubscriptğ‘‡ğ‘–T_{i} and a cyclic prefix of duration Tcâ€‹psubscriptğ‘‡ğ‘ğ‘T_{cp}, which both depend on the subcarrier spacing Î”â€‹fÎ”ğ‘“\\Delta f: Ts=Ti+Tcâ€‹psubscriptğ‘‡ğ‘ subscriptğ‘‡ğ‘–subscriptğ‘‡ğ‘ğ‘T_{s}=T_{i}+T_{cp} with Ti=1/Î”â€‹fsubscriptğ‘‡ğ‘–1Î”ğ‘“T_{i}=1/\\Delta f. From the signal bandwidth we substract the subcarriers dedicated to uplink pilots, so that, when there are Uğ‘ˆU polled devices and npsubscriptğ‘›ğ‘n_{p} pilots per device, the number of complex channel uses is n=(Wâˆ’npâ€‹Uâ€‹Î”â€‹f)â€‹Tiğ‘›ğ‘Šsubscriptğ‘›ğ‘ğ‘ˆÎ”ğ‘“subscriptğ‘‡ğ‘–n=(W-n_{p}U\\Delta f)T_{i}Â [37, Chapter 5]. The number of pilots per device can be obtained as follows: np=âŒˆW/WcâŒ‰subscriptğ‘›ğ‘ğ‘Šsubscriptğ‘Šğ‘n_{p}=\\lceil W/W_{c}\\rceil, where Wc=1/(2â€‹Td)subscriptğ‘Šğ‘12subscriptğ‘‡ğ‘‘W_{c}=1/(2T_{d})Â [37, Chapter 2] is the coherence bandwidth and Tdsubscriptğ‘‡ğ‘‘T_{d} is the delay spread. Regarding the traffic model, we consider either a deterministic periodic traffic with period 1/Î»1ğœ†1/\\lambda or a probabilistic aperiodic traffic with average inter-arrival time 1/Î»1ğœ†1/\\lambda. A packet can be decomposed into an information part of length Lisubscriptğ¿ğ‘–L_{i}, a header part of length Lhsubscriptğ¿â„L_{h}, and a buffer description of length Lbsubscriptğ¿ğ‘L_{b}, so that L=Li+Lh+Lbğ¿subscriptğ¿ğ‘–subscriptğ¿â„subscriptğ¿ğ‘L=L_{i}+L_{h}+L_{b}. In URLLC, headers cannot indeed be neglected with respect to the message length. We assume that the information part, the header and the buffer information are jointly encodedÂ . The traffic parameters of TableÂ LABEL:tab:simparam are taken from the factory automation use case of Release 16Â . For realistic numerical experiments, we partly adopt the scenario proposed inÂ [40, Table A.2.2-1] for the factory automation use case, with a single BS. The network layout is a rectangle of size â„“Ã—â„“â€²â„“superscriptâ„“â€²\\ell\\times\\ell^{\\prime}; the BS is positioned at its center at a height h~bsubscript~â„ğ‘\\tilde{h}_{b} and serves devices, each at height h~dsubscript~â„ğ‘‘\\tilde{h}_{d} and moving with velocity vğ‘£v. Devices are uniformly distributed within the network area. Devices and BS benefit from antenna gains Gbsubscriptğºğ‘G_{b} and Gdsubscriptğºğ‘‘G_{d} respectively. For a speed of v=3ğ‘£3v=3Â km/h, we obtain a coherence time of Tc=c/(8â€‹fcâ€‹v)=11.2subscriptğ‘‡ğ‘ğ‘8subscriptğ‘“ğ‘ğ‘£11.2T_{c}=c/(8f_{c}v)=11.2Â ms, which corresponds to 636363 radio frames. We choose an episode length of 200200200 frames that allows us to consider speeds below 111Â km/h. The path-loss model is the ITU InH NLOSÂ [ref]61. The BS has a noise figure NFsubscriptğ‘ğ¹N_{F}, so that the noise power is Ïƒn2=N0â€‹Wâ€‹NFsuperscriptsubscriptğœğ‘›2subscriptğ‘0ğ‘Šsubscriptğ‘ğ¹\\sigma_{n}^{2}=N_{0}WN_{F}, where N0subscriptğ‘0N_{0} is the noise power spectral density. Typical values for the channel parameters are given in TableÂ LABEL:tab:simparam. We express the deadlines and inter-arrival time in term of frames. Indeed, given the frame duration Tfsubscriptğ‘‡ğ‘“T_{f}, we can deduce that the average inter-arrival time of 2 ms corresponds to 11.211.211.2 frames and that the deadline of 111 ms to 5.65.65.6 frames. The parameters of the DRL algorithms are given in TableÂ I. We preprocess the agent state as follows. In order to reduce the dimension of the buffer information, the matrix ğ‘©Aâ€‹(t)superscriptğ‘©ğ´ğ‘¡\\bm{B}^{A}(t) is transformed into a vector of size Kğ¾K of head-of-line delays for each agent. In order to improve stability of speed up training, we normalize ğ‰p,ğ‰a,ğ‰ssuperscriptğ‰ğ‘superscriptğ‰ğ‘superscriptğ‰ğ‘ \\bm{\\tau}^{p},\\bm{\\tau}^{a},\\bm{\\tau}^{s} between 0 and 1 by taking 1/ğ‰p,1/ğ‰a,1/ğ‰s1superscriptğ‰ğ‘1superscriptğ‰ğ‘1superscriptğ‰ğ‘ 1/\\bm{\\tau}^{p},1/\\bm{\\tau}^{a},1/\\bm{\\tau}^{s}. Finally, the channel threshold Î·âˆ—superscriptğœ‚\\eta^{*} is calculated using (8) such that the error probability in absence of interference corresponding to Î·âˆ—superscriptğœ‚\\eta^{*} is equal to 10âˆ’5superscript10510^{-5}.\n\nReference markers found: [61]\n\nContext windows for each [ref]:\n[ref]61: which corresponds to 636363 radio frames. We choose an episode length of 200200200 frames that allows us to consider speeds below 111Â km/h. The path-loss model is the ITU InH NLOSÂ [ref]61. The BS has a noise figure NFsubscriptğ‘ğ¹N_{F}, so that the noise power is Ïƒn2=N0â€‹Wâ€‹NFsuperscriptsubscriptğœğ‘›2subscriptğ‘0ğ‘Šsubscriptğ‘ğ¹\\sigma_{n}^{2}=N_{0}WN_{F}, where N0subscriptğ‘0N_{0} is the\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 61,\n            \"titles\": [\n                \"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\",\n                \"Study on scenarios and requirements for next generation access technologies\",\n                \"Non-orthogonal multiple access (noma) for cellular future radio access\",\n                \"Enabling urllc in 5g nr iiot networks: A full-stack end-to-end analysis\",\n                \"Uplink scheduling for mixed grant-based embb and grant-free urllc traffic in 5g networks\",\n                \"NR; Medium Access Control (MAC) protocol specification\",\n                \"A predictive semi-persistent scheduling scheme for low-latency applications in lte and nr networks\",\n                \"Radio resource allocation and retransmission schemes for urllc over 5g networks\",\n                \"Uplink grant-free access solutions for urllc services in 5g new radio\",\n                \"Slotted aloha with noma for the next generation iot\",\n                \"Grant-free non-orthogonal multiple access for iot: A survey\",\n                \"Analyzing grant-free access for urllc service\",\n                \"Human-level control through deep reinforcement learning\",\n                \"Deep reinforcement learning for internet of things: A comprehensive survey\",\n                \"Distributive dynamic spectrum access through deep reinforcement learning: A reservoir computing-based approach\",\n                \"The application of deep reinforcement learning to distributed spectrum access in dynamic heterogeneous environments with partial observations\",\n                \"Cooperative multi-agent reinforcement learning based distributed dynamic spectrum access in cognitive radio networks\",\n                \"Deep reinforcement learning based massive access management for ultra-reliable low-latency communications\",\n                \"A reliable reinforcement learning for resource allocation in uplink noma-urllc networks\",\n                \"A general deep reinforcement learning framework for grant-free noma optimization in murllc\",\n                \"Deep reinforcement learning for scheduling uplink iot traffic with strict deadlines\",\n                \"Deep Reinforcement Learning in Large Discrete Action Spaces\",\n                \"Continuous control with deep reinforcement learning\",\n                \"Discrete Sequential Prediction of Continuous Actions for Deep RL\",\n                \"Action Branching Architectures for Deep Reinforcement Learning\",\n                \"The optimal control of partially observable Markov processes\",\n                \"Planning and acting in partially observable stochastic domains\",\n                \"Deep Recurrent Q-Learning for Partially Observable MDPs\",\n                \"Deep Variational Reinforcement Learning for POMDPs\",\n                \"Approximate information state for approximate planning and reinforcement learning in partially observed systems\",\n                \"Reinforcement Learning\",\n                \"Proximal policy optimization algorithms\",\n                \"Bayesian transfer reinforcement learning with prior knowledge rules\",\n                \"Joint subcarrier and power allocation in noma: Optimal and approximate algorithms\",\n                \"Joint Power and Blocklength Optimization for URLLC in a Factory Automation Scenario\",\n                \"Joint beamforming and scheduling for a multi-antenna downlink with imperfect transmitter channel knowledge\",\n                \"Microwave mobile communications\",\n                \"Fundamentals of wireless communication\",\n                \"Wireless communications\",\n                \"The effect of imperfect channel estimation on the performance of maximum ratio combining in the presence of cochannel interference\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]61 based on the context and research area of Deep Reinforcement Learning for Uplink Scheduling in NOMA-URLLC Networks. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}