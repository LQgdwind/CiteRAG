{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Arbitrariness and Prediction: The Confounding Role of Variance in Fair Classification\n\nPaper Abstract: \n\nPaper Section Text:\nModels.  According to a comprehensive recent survey study , as well as related work like Chen et al. [ref]11, we conclude that some of the most common models used in fair classification are logistic regression, decision tree classifiers, random forest classifiers, SVMs, and MLPs. We opted to include comprehensive results for the first three, since they capture different complexities, and therefore encode different degrees of statistical bias, that we expected to have an impact on the underlying sources of error. We provide some results for SVMs and MLPs, which we include in this Appendix. Since we choose not to use stochastic optimizers to reduce the sources of randomness, for our results, training MLPs is slower than it could be. We consistently use a decision threshold of 0.5 (i.e., 0-1 loss) for our experiments, though our results can easily be extended to other thresholds, as discussed in Section 3. Depending on the dataset, we reserve between 20% and 30% of the available data for the test set. This is consistent with standard fair classification training settings, which we validated during our initial experiments to explore the space (for which we also did preliminary hyperparameter optimization, before fixing the hyperparameters for our presented results).161616Please refer to https://github.com/pasta41/variance for more details. Datasets.  Also according to Fabris et al. , the most common tasks in fair classification are Old Adult , COMPAS , and South German Credit [ref]32.171717Technically, Grömping [ref]32 is an updated and corrected version of the dataset from 2019. These three datasets arguably serve as a de facto benchmark in the community, so we felt the need to include them in the present work. In recognition of the fact that these three datasets, however standard, have problems, we also run experiments on 333 tasks in the New Adult dataset, introduced by Ding et al.  to replace Old Adult. We subset to the CA (California) subset of the dataset, and run on Income, Employment, and Public Coverage, and consider sex and race as protected attributes, which we binarize into {Male, Female} and {White, Non-white}. These are all large-scale tasks, at least in the domain of algorithmic fairness — on the order of hundreds of thousands of example instances. However, the 333 tasks do share example instances and some features. In summary, concerning common tasks in fair classification: COMPAS . We run on the commonly-used version of this dataset from Friedler et al. , which has 6167 example instances with 404 features. The target is to predict recidivism within 2 years (111 corresponding to Yes, and 00 to No). The protected attribute is race, binarized into “Non-white” (00) and “White” (111) subgroups. Old Adult . We run on the commonly-used version of this dataset from Friedler et al. , which has 30,162 examples with 97 features. This version of the dataset removes instances with missing values from the original dataset, and changes the encoding of some of the features (Kohavi  has 48842 example instnaces with 88 features). The target is to predict <$50,000absentcurrency-dollar50000<\\$50,000 income (00) >=$50,000absentcurrency-dollar50000>=\\$50,000 income (111). The protected attribute is sex, binarized into “Female” (00) and “Male” (111) subgroups. South German Credit [ref]32. We download the dataset from UCI181818See https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29 and process the data ourselves. We use the provided codetable.txt to “translate” the features from German to English. We say “translate” because the authors took some liberties, e.g., the column converted to “credit_history” is labeled “moral” in the German, which is not a translation. There are four categories in the protected attribute “personal_status_sex” column, one of which (222) is used for both “Male (single)” and “Female (non-single).” We therefore remove rows with this value, and binarize the remaining three categories into “Female” (00) and “Male” (111). What results is a dataset with 690 example instances (of the original 1000) with 19 features. The target is “good” credit (111) and “bad” credit (00). Taiwan Credit . This task is to predict default on credit card payments (111) or not (00). There are 30,000 example instances and 24 features. The protected attribute is binary sex. We download this dataset from UCI.191919See https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients. New Adult . This dataset contains millions of example instances from US Census data, which can be used for several different targets/tasks. We select three of them (listed below). These tasks share some features, and therefore are not completely independent. Further, given the size of the whole dataset, we subset to CA (California), the most populous state in the US. There are two protected attribute columns that we use: sex, which is binarized “Female” (00) and “Male” (111) subgroups, and race, which we binarize into “Non-white” (00) and “White” (111). In future work, we would like to explore extending our results beyond binary subgroups. Income. This task is designed to be analogous to Old Adult . As a result, the target is to predict <$50,000absentcurrency-dollar50000<\\$50,000 income (00) >=$50,000absentcurrency-dollar50000>=\\$50,000 income (111). In the CA subset, there are 195,665 example instances with 8 features. Employment. This task is to predict whether an individual is employed (111) or not (00). In the CA subset, there are 378,817 example instances with 14 features. Public Coverage. This task is to predict whether an individual is on public health insurance (111) or not (00). In the CA subset, there are 138,554\nexample instances with 17 features.\n\nReference markers found: [11]\n\nContext windows for each [ref]:\n[ref]11: Models.  According to a comprehensive recent survey study , as well as related work like Chen et al. [ref]11, we conclude that some of the most common models used in fair classification are logistic regression, decision tree classifiers, random forest classifiers, SVMs, and MLPs. We opted to include\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 11,\n            \"titles\": [\n                \"Emergent Unfairness in Algorithmic Fairness-Accuracy Trade-Off Research\",\n                \"Consistency Tradeoffs in Modern Distributed Database System Design: CAP is Only Part of the Story\",\n                \"Learning From Data: A Short Course\",\n                \"Accounting for Model Uncertainty in Algorithmic Discrimination\",\n                \"Fairness and Machine Learning: Limitations and Opportunities\",\n                \"Uncertainty as a Form of Transparency: Measuring, Communicating, and Using Uncertainty\",\n                \"Selective Ensembles for Consistent Predictions\",\n                \"Model Multiplicity: Opportunities, Concerns, and Solutions\",\n                \"Bagging Predictors\",\n                \"Arcing classifiers\",\n                \"Statistical Modeling: The Two Cultures\",\n                \"Why Is My Classifier Discriminatory?\",\n                \"Accuracy-Efficiency Trade-Offs and Accountability in Distributed ML Systems\",\n                \"Hyperparameter Optimization Is Deceiving Us, and How to Stop It\",\n                \"Accountability in an Algorithmic Society: Relationality, Responsibility, and Robustness in Machine Learning\",\n                \"Algorithmic decision making and the cost of fairness\",\n                \"The Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision-Making Systems\",\n                \"Retiring Adult: New Datasets for Fair Machine Learning\",\n                \"A Unified Bias-Variance Decomposition and Its Applications\",\n                \"A unified bias-variance decomposition\",\n                \"Bootstrap Methods: Another Look at the Jackknife\",\n                \"Improvements on Cross-Validation: The 632+ Bootstrap Method\",\n                \"An Introduction to the Bootstrap\",\n                \"The Foundations of Cost-Sensitive Learning\",\n                \"Algorithmic Fairness Datasets: the Story so Far\",\n                \"HMDA Data Publication\",\n                \"Model Selection’s Disparate Impact in Real-World Deep Learning Applications\",\n                \"On the (im)possibility of fairness\",\n                \"A Comparative Study of Fairness-Enhancing Interventions in Machine Learning\",\n                \"The Morality of Law\",\n                \"Neural Networks and the Bias/Variance Dilemma\",\n                \"South German Credit Data: Correcting a Widely Used Data Set\",\n                \"Equality of Opportunity in Supervised Learning\",\n                \"The Elements of Statistical Learning: Data Mining, Inference and Prediction\",\n                \"Knowledge and Belief\",\n                \"Wasserstein Fair Classification\",\n                \"On Fairness and Stability: Is Estimator Variance a Friend or a Foe?\",\n                \"Inherent Trade-Offs in the Fair Determination of Risk Scores\",\n                \"FAIR-Ensemble: When Fairness Naturally Emerges From Deep Ensembling\",\n                \"Scaling up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]11 based on the context and research area of Arbitrariness and Prediction: The Confounding Role of Variance in Fair Classification. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}