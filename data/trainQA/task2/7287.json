{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: A Survey of Advances in Optimization Methods for Wireless Communication System Design\n\nPaper Abstract: \n\nPaper Section Text:\nAs discussed in Section IV-A, an efficient pruning rule in the B&B algorithm is of great importance to the algorithm’s computational efficiency and the most common way to prune is to estimate a lower bound on the objective function value of each subproblem. Since convex optimization problems possess favorable theoretical and computational properties    and efficient and mature solvers    , the lower bound on the objective value of each subproblem is often computed via solving a convex relaxation of the corresponding subproblem. The quality of the lower bound depends on the tightness of the convex relaxation. Designing convex relaxations that provide valid lower bounds with satisfactory tightness is an important research topic in global optimization. In this subsection, we review several SDRs for a class of CQPs developed in [ref]38 . For completeness, we consider the following most general CQP as in [ref]38: where 𝐱=[x1,x2,…,xn]𝖳∈ℂn𝐱superscriptsubscript𝑥1subscript𝑥2…subscript𝑥𝑛𝖳superscriptℂ𝑛\\mathbf{x}=[x_{1},x_{2},\\ldots,x_{n}]^{\\mathsf{T}}\\in\\mathbb{C}^{n} is the n𝑛n-dimensional complex (unknown) variable; 𝐐i∈ℂn×nsubscript𝐐𝑖superscriptℂ𝑛𝑛\\mathbf{Q}_{i}\\in\\mathbb{C}^{n\\times n} (i=0,1,…,m𝑖01…𝑚i=0,1,\\ldots,m) are m+1𝑚1m+1 Hermitian matrices, bi∈ℝsubscript𝑏𝑖ℝb_{i}\\in\\mathbb{R} (i=1,2,…,m𝑖12…𝑚i=1,2,\\ldots,m) are m𝑚m real numbers, and ℓisubscriptℓ𝑖\\ell_{i} and uisubscript𝑢𝑖u_{i} (i=1,2,…,n𝑖12…𝑛i=1,2,\\ldots,n), satisfying ui≥ℓi≥0,subscript𝑢𝑖subscriptℓ𝑖0u_{i}\\geq\\ell_{i}\\geq 0, are 2​n2𝑛2n real numbers; 𝒜i​jsubscript𝒜𝑖𝑗\\mathcal{A}_{ij} ({i,j}∈ℰ𝑖𝑗ℰ\\{i,j\\}\\in\\mathcal{E})  is either an interval of the form [θ¯i​j,θ¯i​j]⊆[0,2​π)subscript¯𝜃𝑖𝑗subscript¯𝜃𝑖𝑗02𝜋[\\underline{\\theta}_{ij},\\bar{\\theta}_{ij}]\\subseteq[0,2\\pi), or a set of discrete points of the form {θi​j1,…,θi​jM}⊆[0,2​π)superscriptsubscript𝜃𝑖𝑗1…superscriptsubscript𝜃𝑖𝑗𝑀02𝜋\\{\\theta_{ij}^{1},\\ldots,\\theta_{ij}^{M}\\}\\subseteq[0,2\\pi), where ℰℰ\\mathcal{E} is a subset of {{i,j}| 1≤i<j≤n}conditional-set𝑖𝑗1𝑖𝑗𝑛\\{\\{i,j\\}\\,|\\,1\\leq i<j\\leq n\\}; and arg⁡(⋅)⋅\\arg(\\cdot) denotes the argument of a complex number. The difficulty of developing an SDR  for CQP (67) which can provide a good lower bound lies in its last argument constraint. Indeed, an SDR for CQP (67) with the argument constraint dropped is also an SDR for the problem itself. However, the bound provided by the above naive SDR is generally not tight enough (to be used in the B&B algorithm). The idea of developing an enhanced SDR for CQP (67) in [ref]38  is to represent the complex variable into its polar coordinate form and derive valid inequalities by exploiting the special structure of the argument constraint under the polar coordinate representation. More specifically, introduce the polar coordinate representation of each variable xi=ri​exp⁡(i​θi)subscript𝑥𝑖subscript𝑟𝑖isubscript𝜃𝑖x_{i}=r_{i}\\exp(\\textrm{i}\\theta_{i}) and two lifted matrices where 𝐫=[r1,r2,…,rn]𝖳∈ℝn𝐫superscriptsubscript𝑟1subscript𝑟2…subscript𝑟𝑛𝖳superscriptℝ𝑛\\mathbf{r}=[r_{1},r_{2},\\ldots,r_{n}]^{\\mathsf{T}}\\in\\mathbb{R}^{n}. Then, for each {i,j}∈ℰ𝑖𝑗ℰ\\{i,j\\}\\in\\mathcal{E}, we get We now relax the two types of nonconvex constraints in (68) in order to obtain a convex relaxation of CQP (67). First, for each {i,j}∈ℰ𝑖𝑗ℰ\\{i,j\\}\\in\\mathcal{E}, define the nonconvex set It has been shown in [ref]203 that the convex hull444The convex hull of a set is the smallest convex set that contains the given set. of 𝒮i​jsubscript𝒮𝑖𝑗\\mathcal{S}_{ij} can be represented as in (73) at the top of the next page. Since Ri​j2≤Ri​i​Rj​jsuperscriptsubscript𝑅𝑖𝑗2subscript𝑅𝑖𝑖subscript𝑅𝑗𝑗R_{ij}^{2}\\leq R_{ii}R_{jj} can be rewritten as it follows from (73) that (Ri​i,Rj​j,Ri​j)∈Conv​(𝒮i​j)subscript𝑅𝑖𝑖subscript𝑅𝑗𝑗subscript𝑅𝑖𝑗Convsubscript𝒮𝑖𝑗(R_{ii},R_{jj},R_{ij})\\in\\textsf{Conv}(\\mathcal{S}_{ij}) can be fully characterized by an SOC constraint, two linear constraints, and two box constraints. Second, consider the nonconvex set We have the following results on the convex hull of 𝒯i​jsubscript𝒯𝑖𝑗\\mathcal{T}_{ij} [ref]38 , as shown in Fig. 7 where the light blue regions represent the convex hull of 𝒯i​jsubscript𝒯𝑖𝑗\\mathcal{T}_{ij} in the continuous and discrete cases, respectively. In particular, for the continuous case where 𝒜i​j=[θ¯i​j,θ¯i​j]⊆[0,2​π),subscript𝒜𝑖𝑗subscript¯𝜃𝑖𝑗subscript¯𝜃𝑖𝑗02𝜋\\mathcal{A}_{ij}=[\\underline{\\theta}_{ij},\\bar{\\theta}_{ij}]\\subseteq[0,2\\pi), we have where for the discrete case where 𝒜i​j={θi​j1,θi​j2,…,θi​jM}subscript𝒜𝑖𝑗superscriptsubscript𝜃𝑖𝑗1superscriptsubscript𝜃𝑖𝑗2…superscriptsubscript𝜃𝑖𝑗𝑀\\mathcal{A}_{ij}=\\{\\theta_{ij}^{1},\\theta_{ij}^{2},\\ldots,\\theta_{ij}^{M}\\} with 0≤θi​j1<θi​j2<⋯<θi​jM<2​π,0superscriptsubscript𝜃𝑖𝑗1superscriptsubscript𝜃𝑖𝑗2⋯superscriptsubscript𝜃𝑖𝑗𝑀2𝜋0\\leq\\theta_{ij}^{1}<\\theta_{ij}^{2}<\\cdots<\\theta_{ij}^{M}<2\\pi,\nwe have where θi​jM+1≜θi​j1+2​π≜superscriptsubscript𝜃𝑖𝑗𝑀1superscriptsubscript𝜃𝑖𝑗12𝜋\\theta_{ij}^{M+1}\\triangleq\\theta_{ij}^{1}+2\\pi and The valid cuts shown in (75) and (76) have been named argument cuts in   because they exploit the structure of the argument constraint. The corresponding constraint (Xi​j,Ri​j)∈Conv​(𝒯i​j)subscript𝑋𝑖𝑗subscript𝑅𝑖𝑗Convsubscript𝒯𝑖𝑗(X_{ij},R_{ij})\\in\\textsf{Conv}(\\mathcal{T}_{ij}) can be fully characterized by one linear constraint and one SOC constraint in the continuous case and by M+1𝑀1M+1 linear constraints in the discrete case. Putting all of the above together, we obtain the enhanced SDR for CQP (67) as follows [ref]38: The SDR in (77) are closely related to many SDRs, e.g., those in [ref]203  ; please see [38, Section 3] for a detailed comparison. As an extreme case where CQP (67) reduces to the MIMO detection problem (14) with 𝒮=𝒮L,𝒮subscript𝒮𝐿\\mathcal{S}=\\mathcal{S}_{L}, the corresponding SDR in (77) then reduces to (CSDP2) in . Thanks to the argument cuts in (76), (CSDP2) is shown to be tight555The tightness of the SDR here means that the gap between the SDR and problem (14) is zero and the SDR recovers the true vector of transmitted signals. for the general case where L≥3𝐿3L\\geq 3 if the condition λmin​(𝐇†​𝐇)​sin⁡(π/L)≥‖𝐇†​𝐳‖1subscript𝜆superscript𝐇†𝐇𝜋𝐿subscriptnormsuperscript𝐇†𝐳1\\lambda_{\\min}(\\mathbf{H}^{\\dagger}\\mathbf{H})\\sin(\\pi/L)\\geq\\|\\mathbf{H}^{\\dagger}\\mathbf{z}\\|_{1} holds true. The above sufficient condition for (CSDP2) in  to be tight is intuitive: it basically says that if the channel matrix 𝐇𝐇\\mathbf{H} is well conditioned and if the constellation level L𝐿L and the level of the noise 𝐳𝐳\\mathbf{z} are not too large, then solving the corresponding SDR can find the global solution of problem (14), which is also the true vector of transmitted signals 𝐱∗superscript𝐱∗\\mathbf{x}^{\\ast} in (12). Final remarks to conclude this subsection are on the use of the argument cuts in (75) and (76) and the SDR in (77) to design efficient global optimization algorithms. Great efforts have been made in the literature to globally solve nonconvex CQPs, among which  and  are closely related to wireless communication system design. In particular, the argument cuts (75) have been embedded in the B&B framework in  to globally solve the NP-hard single-group multicast problem ; efficient B&B algorithms based on the argument cuts (75) and (76) have been developed in  to solve a class of nonconvex CQPs with signal processing and wireless communication applications. When applied to solve the MIMO detection problem (14) with 𝒮=𝒮L,𝒮subscript𝒮𝐿\\mathcal{S}=\\mathcal{S}_{L}, the proposed global optimization algorithm in  significantly\noutperforms the state-of-the-art tailored global optimization algorithm called sphere decoder  in the\nhard cases (where the number of inputs and outputs is equal or the SNR is low).\n\nReference markers found: [38]\n\nContext windows for each [ref]:\n[ref]38: that provide valid lower bounds with satisfactory tightness is an important research topic in global optimization. In this subsection, we review several SDRs for a class of CQPs developed in [ref]38 . For completeness, we consider the following most general CQP as in [ref]38: where\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Mixed Monotonic Programming for Fast Global Optimization\",\n                \"What Will 5G Be?\",\n                \"A Vision of 6G Wireless Systems: Applications, Trends, Technologies, and Open Research Problems\",\n                \"What Should 6G Be?\",\n                \"Towards 6G wireless communication networks: Vision, enabling technologies, and new paradigm shifts\",\n                \"The road towards 6G: A comprehensive survey\",\n                \"Framework and overall objectives of the future development of IMT for 2030 and beyond\",\n                \"Massive MIMO networks: Spectral, energy, and hardware efficiency\",\n                \"Prospective multiple antenna technologies for beyond 5G\",\n                \"Twenty-five years of signal processing advances for multiantenna communications: From theory to mainstream technology\",\n                \"Convex optimization-based beamforming\",\n                \"Twenty-Five Years of Advances in Beamforming: From Convex and Nonconvex Optimization to Learning Techniques\",\n                \"Evolution of NOMA Toward Next Generation Multiple Access (NGMA) for 6G\",\n                \"Sparse Signal Processing for Grant-Free Massive Connectivity: A Future Paradigm for Random Access Protocols in the Internet of Things\",\n                \"Massive Access for 5G and Beyond\",\n                \"Cloud Radio Access Network: Virtualizing Wireless Access for Dense Heterogeneous Systems\",\n                \"Cell-Free Massive MIMO versus Small Cells\",\n                \"Integrated sensing and communications: Toward dual-functional wireless networks for 6G and beyond\",\n                \"A Survey on Fundamental Limits of Integrated Sensing and Communication\",\n                \"Towards Smart and Reconfigurable Environment: Intelligent Reflecting Surface Aided Wireless Network\",\n                \"Smart radio environments empowered by reconfigurable intelligent surfaces: How it works, state of research, and the road ahead\",\n                \"“Applications of convex optimization in signal processing and digital communication\",\n                \"“Geometric programming for communication systems\",\n                \"“An introduction to convex optimization for communications and signal processing\",\n                \"Convex Optimization in Signal Processing and Communications. New York\",\n                \"Convex Optimization. New York\",\n                \"Lectures on Modern Convex Optimization\",\n                \"Interior Point Polynomial Methods in Convex Programming: Theory and Algorithms\",\n                \"“Using SeDuMi 1.02\",\n                \"“SDPT3: A MATLAB software package for semidefinite programming\",\n                \"“SDPNAL+: A MATLAB software for semidefinite programming with bound constraints (version 1.0)\",\n                \"“Semidefinite relaxation of quadratic optimization problems\",\n                \"Modern Nonconvex Nondifferentiable Optimization. Philadelphia\",\n                \"“The Łojasiewicz inequality for nonsmooth subanalytic functions with applications to subgradient dynamical systems\",\n                \"“Energy efficiency in wireless networks via fractional programming theory\",\n                \"“Fractional programming for communication systems—Part I: Power control and beamforming\",\n                \"“Fractional programming for communication systems—Part II: Uplink scheduling via matching\",\n                \"Introduction to Global Optimization. Norwell\",\n                \"“New semidefinite relaxations for a class of complex quadratic programming problems\",\n                \"“Mixed-integer semidefinite relaxation of joint admission control and beamforming: An SOC-based outer approximation approach with provable guarantees\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]38 based on the context and research area of A Survey of Advances in Optimization Methods for Wireless Communication System Design. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}