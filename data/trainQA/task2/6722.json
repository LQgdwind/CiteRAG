{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Attribution-Scores in Data Management and Explainable Machine LearningPaper associated to tutorial at ADBIS 2023.\n\nPaper Abstract: \n\nPaper Section Text:\nBefore going into the subject, we recall some notions and notation used in data management. Â  A relational schema â„›â„›\\mathcal{R} contains a domain of constants, ğ’ğ’\\mathcal{C}, and a set of predicates of finite arities, ğ’«ğ’«\\mathcal{P}. Â â„›â„›\\mathcal{R} gives rise to a language ğ”â€‹(â„›)ğ”â„›\\mathfrak{L}(\\mathcal{R}) of first-order (FO) predicate logic with built-in equality, ==. Variables are usually denoted with x,y,z,â€¦ğ‘¥ğ‘¦ğ‘§â€¦x,y,z,...; and finite sequences thereof with xÂ¯,â€¦Â¯ğ‘¥â€¦\\bar{x},...; and constants with a,b,c,â€¦ğ‘ğ‘ğ‘â€¦a,b,c,..., etc. An atom is of the form Pâ€‹(t1,â€¦,tn)ğ‘ƒsubscriptğ‘¡1â€¦subscriptğ‘¡ğ‘›P(t_{1},\\ldots,t_{n}), with nğ‘›n-ary Pâˆˆğ’«ğ‘ƒğ’«P\\in\\mathcal{P} and t1,â€¦,tnsubscriptğ‘¡1â€¦subscriptğ‘¡ğ‘›t_{1},\\ldots,t_{n} terms, i.e. constants, or variables.\nAn atom is ground (a.k.a. a tuple) if it contains no variables. A database (instance), Dğ·D, for â„›â„›\\mathcal{R} is a finite set of ground atoms; and it serves as an  interpretation structure for ğ”â€‹(â„›)ğ”â„›\\mathfrak{L}(\\mathcal{R}). A conjunctive query (CQ) is a FOÂ formula, ğ’¬â€‹(xÂ¯)ğ’¬Â¯ğ‘¥\\mathcal{Q}(\\bar{x}), of the form Â âˆƒyÂ¯â€‹(P1â€‹(xÂ¯1)âˆ§â‹¯âˆ§Pmâ€‹(xÂ¯m))Â¯ğ‘¦subscriptğ‘ƒ1subscriptÂ¯ğ‘¥1â‹¯subscriptğ‘ƒğ‘šsubscriptÂ¯ğ‘¥ğ‘š\\exists\\bar{y}\\;(P_{1}(\\bar{x}_{1})\\wedge\\dots\\wedge P_{m}(\\bar{x}_{m})),\nwith Piâˆˆğ’«subscriptğ‘ƒğ‘–ğ’«P_{i}\\in\\mathcal{P}, and (distinct) free variables xÂ¯:=(â‹ƒxÂ¯i)âˆ–yÂ¯assignÂ¯ğ‘¥subscriptÂ¯ğ‘¥ğ‘–Â¯ğ‘¦\\bar{x}:=(\\bigcup\\bar{x}_{i})\\smallsetminus\\bar{y}. If ğ’¬ğ’¬\\mathcal{Q} has nğ‘›n (free) variables, cÂ¯âˆˆğ’nÂ¯ğ‘superscriptğ’ğ‘›\\bar{c}\\in\\mathcal{C}^{n} Â is an answer to ğ’¬ğ’¬\\mathcal{Q} from Dğ·D if DâŠ§ğ’¬â€‹[cÂ¯]modelsğ·ğ’¬delimited-[]Â¯ğ‘D\\models\\mathcal{Q}[\\bar{c}], i.e. Qâ€‹[cÂ¯]ğ‘„delimited-[]Â¯ğ‘Q[\\bar{c}] is true in Dğ·D when the variables in xÂ¯Â¯ğ‘¥\\bar{x} are componentwise replaced by the values in cÂ¯Â¯ğ‘\\bar{c}. ğ’¬â€‹(D)ğ’¬ğ·\\mathcal{Q}(D) denotes the set of answers to ğ’¬ğ’¬\\mathcal{Q} from Dğ·D. ğ’¬ğ’¬\\mathcal{Q} is a Boolean conjunctive query (BCQ) when xÂ¯Â¯ğ‘¥\\bar{x} is empty; and when true in Dğ·D, ğ’¬â€‹(D):={ğ‘¡ğ‘Ÿğ‘¢ğ‘’}assignğ’¬ğ·ğ‘¡ğ‘Ÿğ‘¢ğ‘’\\mathcal{Q}(D):=\\{{\\it true}\\}. Otherwise, it is false, and ğ’¬â€‹(D):=âˆ…assignğ’¬ğ·\\mathcal{Q}(D):=\\emptyset. We will consider only conjunctive queries, which are the most common the data management. Integrity constraints (ICs) are sentences of ğ”â€‹(â„›)ğ”â„›\\mathfrak{L}(\\mathcal{R}) that a DB is expected to satisfy. Here, we consider mainly denial constraints Â (DCs), i.e. of the form Îº:Â¬âˆƒxÂ¯â€‹(P1â€‹(xÂ¯1)âˆ§â‹¯âˆ§Pmâ€‹(xÂ¯m)):ğœ…Â¯ğ‘¥subscriptğ‘ƒ1subscriptÂ¯ğ‘¥1â‹¯subscriptğ‘ƒğ‘šsubscriptÂ¯ğ‘¥ğ‘š\\kappa\\!:\\neg\\exists\\bar{x}(P_{1}(\\bar{x}_{1})\\wedge\\dots\\wedge P_{m}(\\bar{x}_{m})),\nwhere Piâˆˆğ’«subscriptğ‘ƒğ‘–ğ’«P_{i}\\in\\mathcal{P}, and xÂ¯=â‹ƒxÂ¯iÂ¯ğ‘¥subscriptÂ¯ğ‘¥ğ‘–\\bar{x}=\\bigcup\\bar{x}_{i}.\nÂ  If an instance Dğ·D does not satisfy the set Î£Î£\\Sigma of ICs associated to the schema, we say that Dğ·D is inconsistent, denoted with Â DâŠ§Ì¸Î£not-modelsğ·Î£D\\not\\models\\Sigma. Now we move into the proper subject of this section. Â  In data management we need to understand and compute\nwhy certain results are obtained or not, e.g. query answers, violations of semantic conditions, etc.; and we\nexpect a database system to provide explanations. Â Here, we will consider explanations that are based on actual causality 4 . They were introduced in\n , and will be illustrated by means of an example. Consider the database Dğ·{D}, and the Boolean conjunctive query (BCQ) oo oo ğ’¬:âˆƒxâ€‹âˆƒyâ€‹(Sâ€‹(x)âˆ§Râ€‹(x,y)âˆ§Sâ€‹(y)):ğ’¬ğ‘¥ğ‘¦ğ‘†ğ‘¥ğ‘…ğ‘¥ğ‘¦ğ‘†ğ‘¦\\mathcal{Q}\\!:\\ \\exists x\\exists y(S(x)\\land R(x,y)\\land S(y)),\nfor which Â DâŠ§ğ’¬modelsğ·ğ’¬{D\\models\\mathcal{Q}} holds, i.e. the query is true in Dğ·D. Â We ask about the causes for ğ’¬ğ’¬\\mathcal{Q} to be true. Â A tuple Ï„âˆˆDğœğ·{\\tau\\in D} is\ncounterfactual cause for ğ’¬ğ’¬{\\mathcal{Q}} Â (being true in Dğ·D) Â if Â DâŠ§ğ’¬modelsğ·ğ’¬{D\\models\\mathcal{Q}} oo and Â Dâˆ–{Ï„}âŠ§Ì¸ğ’¬not-modelsğ·ğœğ’¬{D\\smallsetminus\\{\\tau\\}\\not\\models\\mathcal{Q}}.\nÂ In this example, Sâ€‹(b)ğ‘†ğ‘S(b) is a counterfactual cause for ğ’¬ğ’¬\\mathcal{Q}: Â If Sâ€‹(b)ğ‘†ğ‘{S(b)} is removed from Dğ·{D},\nğ’¬ğ’¬{\\mathcal{Q}} is no longer true. Removing a single tuple may not be enough to invalidate the query. Accordingly, a tuple Ï„âˆˆDğœğ·{\\tau\\in D} is an actual cause for ğ’¬ğ’¬{\\mathcal{Q}}\nif there is a contingency set Â Î“âŠ†(Dâˆ–{Ï„})Î“ğ·ğœ{\\Gamma\\subseteq(D\\smallsetminus\\{\\tau\\})}, such that Â Ï„ğœ{\\tau} Â is a counterfactual cause for ğ’¬ğ’¬{\\mathcal{Q}} in Dâˆ–Î“ğ·Î“{D\\smallsetminus\\Gamma}. That is, DâŠ§ğ’¬modelsğ·ğ’¬D\\models\\mathcal{Q}, Â Dâˆ–Î“âŠ§ğ’¬modelsğ·Î“ğ’¬D\\smallsetminus\\Gamma\\models\\mathcal{Q}, but Dâˆ–(Î“âˆª{Ï„})âŠ§Ì¸ğ’¬not-modelsğ·Î“ğœğ’¬D\\smallsetminus(\\Gamma\\cup\\{\\tau\\})\\not\\models\\mathcal{Q}.\nÂ In this example, Râ€‹(a,b)ğ‘…ğ‘ğ‘{R(a,b)} is not a counterfactual cause for ğ’¬ğ’¬{\\mathcal{Q}}, but it is an actual cause with contingency set\n{Râ€‹(b,b)}ğ‘…ğ‘ğ‘{\\{R(b,b)\\}}: Â If Râ€‹(b,b)ğ‘…ğ‘ğ‘{R(b,b)} is removed from Dğ·{D}, ğ’¬ğ’¬{\\mathcal{Q}} is still true, but further removing Râ€‹(a,b)ğ‘…ğ‘ğ‘{R(a,b)} makes ğ’¬ğ’¬{\\mathcal{Q}} false.\n  â–¡â–¡\\Box Notice that every counterfactual cause is also an actual cause, with empty contingent set. Actual causes that are not counterfactual causes need company to invalidate a query result.\nÂ Now, we ask how strong are tuples as actual causes. Â To answer this question, we appeal to the responsibility of an actual cause Ï„ğœ{\\tau} for ğ’¬ğ’¬{\\mathcal{Q}} , defined by: where |Î“|Î“{|\\Gamma|} is the\nsize of a smallest contingency set, Î“Î“\\Gamma, for Ï„ğœ{\\tau}, Â and 00, otherwise. (ex. 1 cont.) Â The responsibility of Râ€‹(a,b)ğ‘…ğ‘ğ‘{R(a,b)} is Â  1212\\frac{1}{2} =11+1absent111{=\\frac{1}{1+1}} Â (its several smallest contingency sets have all size 11{1}). Â Râ€‹(b,b)ğ‘…ğ‘ğ‘{R(b,b)} and Sâ€‹(a)ğ‘†ğ‘{S(a)} are also actual causes with responsibility Â 1212{\\frac{1}{2}}; and\nSâ€‹(b)ğ‘†ğ‘{S(b)} is actual (counterfactual) cause with responsibility Â  111 =11+0absent110{=\\frac{1}{1+0}}.   â–¡â–¡\\Box We can see that causes are, in this database context, tuples that come with their responsibilities as â€œscoresâ€. Â It turns out that there are precise connections between database repairs and tuples as actual causes for queries answers in databases. These connections where exploited to obtain complexity results for responsibility  (among other uses, e.g. to obtain answer-set programs for the specification and computation of actual causes and responsibility [ref]9). The notion of repair of a relational database was introduced in order to formalize the notion of consistent query answering (CQA)  : If a database Dğ·D is inconsistent in the sense that is does not satisfy a given set of integrity constraints, ğ¼ğ¶ğ‘ ğ¼ğ¶ğ‘ {\\it ICs}, and a query ğ’¬ğ’¬\\mathcal{Q} is posed to Dğ·D, what are the meaningful, or consistent, answers to ğ’¬ğ’¬\\mathcal{Q} from Dğ·D? They are sanctioned as those that hold (are returned as answers) from all the repairs of Dğ·D. The repairs of Dğ·D are consistent instances Dâ€²superscriptğ·â€²D^{\\prime} (over the same schema of Dğ·D), i.e. Dâ€²âŠ§ğ¼ğ¶ğ‘ modelssuperscriptğ·â€²ğ¼ğ¶ğ‘ D^{\\prime}\\models{\\it ICs}, and minimally depart from Dğ·D. Let us consider the following set of denial constraints (DCs) and a database Dğ·D, whose relations (tables) are shown right here below. Dğ·D is inconsistent, because it violates the DCs: it satisfies the joins that are prohibited by the DCs. ooo We want to repair the original instance by deleting tuples from relations. Notice that, for DCs, insertions of new tuple will not restore consistency. We could change (update) attribute values though, a possibility that has been investigated in [ref]9. Here we have two subset-repairs, a.k.a. S-repairs. They are subset-maximal consistent subinstances of Dğ·D: Â D1={Pâ€‹(e),Qâ€‹(a,b),Râ€‹(a,c)}subscriptğ·1ğ‘ƒğ‘’ğ‘„ğ‘ğ‘ğ‘…ğ‘ğ‘D_{1}=\\{P(e),Q(a,b),R(a,c)\\} Â and Â D2={P(e),D_{2}=\\{P(e), P(a)}P(a)\\}. They are consistent, subinstances of Dğ·D, and any proper superset of them (still contained in Dğ·D) is inconsistent. (In general, we will represent database relations as set of tuples.) We also have cardinality repairs, a.k.a. C-repairs. They are consistent subinstances of Dğ·D that minimize the number of tuples by which they differ from Dğ·D. That is, they are maximum-cardinality consistent subinstances. In this case, only\nD1subscriptğ·1D_{1} is a C-repair. Â Every C-repair is an S-repair, but not necessarily the other way around.   â–¡â–¡\\Box Let us now consider a BCQ which we assume is true in a database Dğ·D. Â It turns out that we can obtain the causes for ğ’¬ğ’¬\\mathcal{Q} Â to be true Dğ·D, and their contingency sets from database repairs. In order to do this, notice that\nÂ¬ğ’¬ğ’¬\\neg\\mathcal{Q} Â becomes a DC ğ’¬ğ’¬\\mathcal{Q} holds in Dğ·D Â  iff Â  Dğ·D is inconsistent w.r.t. Îºâ€‹(ğ’¬)ğœ…ğ’¬\\kappa(\\mathcal{Q}). S-repairs are associated to causes with minimal contingency sets, while C-repairs are associated to causes for ğ’¬ğ’¬\\mathcal{Q} with minimum contingency sets, and maximum responsibilities . In fact,\nfor a database tuple Â Ï„âˆˆDğœğ·\\tau\\in D: Ï„ğœ\\tau Â is actual cause for ğ’¬ğ’¬\\mathcal{Q} with subset-minimal contingency set Î“Î“\\Gamma Â iff Â Dâˆ–(Î“âˆª{Ï„})ğ·Î“ğœD\\smallsetminus(\\Gamma\\cup\\{\\tau\\}) Â is an S-repair (w.r.t. Îºâ€‹(ğ’¬)ğœ…ğ’¬\\kappa(\\mathcal{Q})),\nin which case, its responsibility is Â 11+|Î“|11Î“\\frac{1}{1+|\\Gamma|}. Ï„ğœ\\tau Â is actual cause with minimum-cardinality contingency set Î“Î“\\Gamma Â iff Â Dâˆ–(Î“âˆª{Ï„})ğ·Î“ğœD\\smallsetminus(\\Gamma\\cup\\{\\tau\\}) Â is C-repair,\nin which case, Ï„ğœ\\tau is a maximum-responsibility actual cause. Conversely, repairs can be obtained from causes and their contingency sets . These results can be extended to unions of BCQs (UBCQs), or equivalently, to sets of denial constraints. One can exploit the connection between causes and repairs to understand the computational complexity of the former by leveraging existing results for the latter. Beyond\nthe fact that computing or deciding actual causes can be done in polynomial time in data for CQs and unions of CQs (UCQs)  , one can show that\nmost computational problems related to responsibility are intractable, because they are also intractable for repairs, in particular, for C-repairs (all this in data complexity)\n3. In particular, one can prove : The responsibility problem, about deciding if a tuple has responsibility above a certain threshold, is Nâ€‹Pğ‘ğ‘ƒ{\\it N\\!P}-complete for UCQs. Â However, on the positive side, this problem is fixed-parameter tractable (equivalently, belongs to the FPT class) , with the parameter being the inverse of the threshold. Computing ğ‘…ğ‘’ğ‘ ğ‘Dğ’¬â€‹(Ï„)superscriptsubscriptğ‘…ğ‘’ğ‘ ğ‘ğ·ğ’¬ğœ{\\it Resp}_{{}_{\\!D\\!}}^{\\!\\mathcal{Q}}(\\tau) Â is Fâ€‹PNâ€‹Pâ€‹(ğ‘™ğ‘œğ‘”â€‹(n))ğ¹superscriptğ‘ƒğ‘ğ‘ƒğ‘™ğ‘œğ‘”ğ‘›{\\it F\\!P}^{{\\it N\\!P(log}(n))}-complete for BCQs. This the functional, non-decision, version of the responsibility problem. The complexity class involved is that of computational problems that use polynomial time with a logarithmic number of calls to an oracle in NP. Deciding if a tuple Ï„ğœ\\tau is a most responsible cause is PNâ€‹Pâ€‹(ğ‘™ğ‘œğ‘”â€‹(n))superscriptğ‘ƒğ‘ğ‘ƒğ‘™ğ‘œğ‘”ğ‘›P^{\\it N\\!P(log(n))}-complete for BCQs. The complexity class is as the previous one, but for decision problems . For further illustration, property (b) right above tells us that there is a database schema and a Boolean conjunctive query ğ’¬ğ’¬\\mathcal{Q}, such that computing the responsibility of tuple in an instance Dğ·D as an actual cause for ğ’¬ğ’¬\\mathcal{Q} being true in Dğ·D is Fâ€‹PNâ€‹Pâ€‹(ğ‘™ğ‘œğ‘”â€‹(n))ğ¹superscriptğ‘ƒğ‘ğ‘ƒğ‘™ğ‘œğ‘”ğ‘›{\\it F\\!P}^{{\\it N\\!P(log}(n))}-hard in |D|ğ·|D|. This is due to the fact that, through the C-repair connection,\ndetermining the responsibility of a tuple becomes the problem on hyper-graphs of determining the size of a minimum vertex cover that contains the tuple as a vertex (among all vertex covers that contain the vertex) [7, sec. 6]. This latter problem was first investigated in the context of C-repairs w.r.t. denial constraints. Those repairs can be characterized in terms of hyper-graphs 3 (see Section 3 for a simple example). Â This hyper-graph connection also allows to obtain the FPT result in (a) above, because we are dealing with hyper-edges that have a fixed upper bound given by the number of atoms in the denial constraint associated to que conjunctive query ğ’¬ğ’¬\\mathcal{Q} (see [7, sec. 6.1] for more details). Notice that a class of database repairs determines a possible-world semantics for database consistency restoration. We could use in principle any reasonable notion of distance between database instances, with each choice defining a particular repair semantics. S-repairs and C-repairs are examples of repair semantics. By choosing alternative repair semantics and an associated notion of counterfactual intervention, we can define also alternative notions of actual causality in databases and associated responsibility measures [ref]9.\nÂ We will show an example in Section 2.1.\n\nReference markers found: [9]\n\nContext windows for each [ref]:\n[ref]9: where exploited to obtain complexity results for responsibility  (among other uses, e.g. to obtain answer-set programs for the specification and computation of actual causes and responsibility [ref]9). The notion of repair of a relational database was introduced in order to formalize the notion of consistent query answering (CQA)  : If a database Dğ·D is inconsistent in the sense that is\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 9,\n            \"titles\": [\n                \"Causality-based Explanation of Classification Outcomes\",\n                \"ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ ê³µê²© ê·¸ë˜í”„ ìƒì„±\",\n                \"Computational Complexity\",\n                \"Consistent Query Answers in Inconsistent Databases\",\n                \"The Tractability of SHAP-scores over Deterministic and Decomposable Boolean Circuits\",\n                \"On the Complexity of SHAP-Score-Based Explanations: Tractability via Knowledge Compilation and Non-Approximability Results\",\n                \"Database Repairing and Consistent Query Answering\",\n                \"From Causes for Database Queries to Repairs and Model-Based Diagnosis and Back\",\n                \"Repair-Based Degrees of Database Inconsistency\",\n                \"Specifying and Computing Causes for Query Answers in Databases via Database Repairs and Repair-Programs\",\n                \"Declarative Approaches to Counterfactual Explanations for Classification\",\n                \"Attribution-Scores and Causal Counterfactuals as Explanations in Artificial Intelligence\",\n                \"Compiling Neural Network Classifiers into Boolean Circuits for Efficient Shap-Score Computation\",\n                \"Efficient Computation of Shap Explanation Scores for Neural Network Classifiers via Knowledge Compilation\",\n                \"The Shapley Value in Database Management\",\n                \"From Database Repairs to Causality in Databases and Beyond\",\n                \"Graph-Based Algorithms for Boolean Function Manipulation\",\n                \"An Interpretable Model with Globally Consistent Explanations for Credit Risk\",\n                \"Responsibility and Blame: A Structural-Model Approach\",\n                \"A Knowledge Compilation Map\",\n                \"On the Tractable Counting of Theory Models and its Application to Truth Maintenance and Belief Revision\",\n                \"Parameterized Complexity Theory\",\n                \"Measuring Inconsistency in Information\",\n                \"Causes and Explanations: A Structural-Model Approach. Part I: Causes\",\n                \"A Modification of the Halpern-Pearl Definition of Causality\",\n                \"Statistics and Causal Inference\",\n                \"On the Measure of Conflicts: Shapley Inconsistency Values\",\n                \"A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations\",\n                \"Approximate Inference of Functional Dependencies from Relations\",\n                \"The Shapley Value of Tuples in Query Answering\",\n                \"Query Games in Databases\",\n                \"The Shapley Value of Inconsistency Measures for Functional Dependencies\",\n                \"Complexity of Consistent Query Answering in Databases under Cardinality-Based and Incremental Repair Semantics\",\n                \"A Unified Approach to Interpreting Model Predictions\",\n                \"From Local Explanations to Global Understanding with Explainable AI for Trees\",\n                \"The Complexity of Causality and Responsibility for Query Answers and Non-Answers\",\n                \"Causality in Databases\",\n                \"Causality: Models, Reasoning and Inference\",\n                \"The Shapley Value: Essays in Honor of Lloyd S. Shapley\",\n                \"Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]9 based on the context and research area of Attribution-Scores in Data Management and Explainable Machine LearningPaper associated to tutorial at ADBIS 2023.. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}