{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Parameterized Local Search for Max ùëê-Cut\n\nPaper Abstract: \n\nPaper Section Text:\nGraph coloring and its generalizations are among the most famous NP-hard optimization problems with numerous practical applications¬†.\nIn one prominent problem variant, we want to color the vertices of an edge-weighted graph with¬†cùëêc colors so that the sum of the weights of all edges that have endpoints with different colors is maximized.\nThis problem is known as\nMax cùëêc-Cut¬†  or Maximum Colorable Subgraph¬†.\nApplications of Max cùëêc-Cut include data clustering¬†[ref]5 0, computation of rankings¬†[ref]5, design of experimental studies¬†, sampling of public opinions in social networks¬†, channel assignment in wireless networks¬†, module detection in genetic interaction data¬†, and scheduling of TV commercials¬†6.\nIn addition, Max cùëêc-Cut is closely related to the energy minimization problem in Hopfield neural networks¬†  .\nAn equivalent formulation of the problem is to ask for a coloring that minimizes the weight sum of the edges whose endpoints receive the same color; this formulation is known as Generalized Graph Coloring¬†.\nThe main difference is that for instances of¬†Generalized Graph Coloring, one usually assumes that all edge weights are non-negative, whereas for Max cùëêc-Cut, one usually also allows negative weights. From an algorithmic viewpoint, even restricted cases of Max¬†cùëêc-Cut\nare hard:\nThe special case¬†c=2ùëê2c=2 is the¬†Max Cut\nproblem which is NP-hard even for positive unit weights¬† 3, even on graphs with maximum degree 3¬†.\nMoreover, for all¬†c‚â•3ùëê3c\\geq 3 the Graph Coloring problem where we\nask for a coloring of the vertices with cùëêc¬†colors such that the endpoints of every edge receive different colors is NP-hard¬†.\nAs a consequence, Max¬†cùëêc-Cut is NP-hard for all¬†c‚â•3ùëê3c\\geq 3, again even when all edges have positive unit weight.\nWhile Max cùëêc-Cut admits polynomial-time constant factor approximation algorithms¬†, there are no polynomial-time approximation schemes unless¬†P=NPPNP\\mathrm{P}=\\mathrm{NP}¬†, even on graphs with bounded maximum degree¬†.\nDue to\nthese hardness results, Max¬†cùëêc-Cut is mostly solved using\nheuristic approaches¬†1  3 . A popular heuristic approach for Max¬†cùëêc-Cut\nis hill-climbing local search¬†1  with the 1-flip neighborhood.\nHere, an\ninitial solution (usually computed by a greedy algorithm) is replaced by a better one in\nthe 1-flip neighborhood as long as such a better solution exists.\nHerein, the 1-flip\nneighborhood of a coloring is the set of all colorings that can be obtained by\nchanging the color of one vertex.\nA coloring that has no improving 1-flip is called\n1-optimal and the problem of computing 1-optimal solutions has also received interest from\na theoretical standpoint: Finding 1-optimal solutions for Max Cut is PLS-complete\non edge-weighted graphs¬†6 and thus presumably not efficiently solvable in\nthe worst case.\nThis PLS-completeness result for the 1-flip neighborhood was later\nextended to Generalized Graph Coloring, and thus to Max cùëêc-Cut, for all¬†cùëêc¬†.\nFor graphs where the absolute values of all edge weights are constant, however, a simple hill climbing algorithm terminates after¬†ùí™‚Äã(m)ùí™ùëö\\mathcal{O}(m)¬†improvements, where¬†mùëöm is the number of edges in the input graph.\nHere, a different question arises: Can we replace the 1-flip neighborhood with a larger efficiently searchable neighborhood, to avoid being stuck in a bad local optimum?\nA natural candidate is the kùëòk-flip neighborhood where we are allowed to change the color of at most¬†kùëòk vertices.\nAs noted by Kleinberg and Tardos¬†, a standard algorithm for searching the kùëòk-flip neighborhood takes Œò‚Äã(nk‚ãÖm)Œò‚ãÖsuperscriptùëõùëòùëö\\Theta(n^{k}\\cdot m)¬†time where¬†nùëõn is the number of vertices.\nThis led Kleinberg and Tardos to conclude that the kùëòk-flip neighborhood is impractical.\nIn this work, we ask whether we can do better than the brute-force Œò‚Äã(nk‚ãÖm)Œò‚ãÖsuperscriptùëõùëòùëö\\Theta(n^{k}\\cdot m)-time algorithm or, in other words, whether the dismissal of kùëòk-flip neighborhood may have been premature. The ideal framework to answer this question is parameterized local search, where the\nmain goal would be to design an algorithm that in¬†f‚Äã(k)‚ãÖnùí™‚Äã(1)‚ãÖùëìùëòsuperscriptùëõùí™1f(k)\\cdot n^{\\mathcal{O}(1)}¬†time either\nfinds a better solution in the¬†kùëòk-flip neighborhood or correctly answers that the current\nsolution is¬†kùëòk-optimal.\nSuch a running time is preferable to¬†ùí™‚Äã(nk‚ãÖm)ùí™‚ãÖsuperscriptùëõùëòùëö\\mathcal{O}(n^{k}\\cdot m) since the degree of the polynomial running time part does not depend on¬†kùëòk and thus the running time scales better with¬†nùëõn.\nThe framework also provides a toolkit for negative results that allows to\nconclude that an algorithm with such a running time is unlikely by showing\nW‚ÄãWdelimited-[]1\\mathrm{W}-hardness.\nIn fact, most parameterized local search problems turn out to be W‚ÄãWdelimited-[]1\\mathrm{W}-hard\nwith respect to the search radius¬†kùëòk¬†   8 9 5  4 9.\nIn contrast to these many, mostly negative, theoretical results, there are so far only few encouraging experimental studies¬†4 7  .\nThe maybe most extensive positive results so far were obtained for LS Vertex Cover where the input is an undirected graph¬†Gùê∫G with a vertex cover¬†SùëÜS and the question is whether the¬†kùëòk-swap neighborhood111The¬†kùëòk-swap neighborhood of a vertex cover¬†SùëÜS of¬†Gùê∫G is the set of all vertex covers of¬†Gùê∫G that have a symmetric difference of at most¬†kùëòk with¬†SùëÜS. of¬†SùëÜS contains a smaller vertex cover.\nThe key to obtain practical parameterized local search algorithms is to consider parameterization by¬†kùëòk and the maximum degree¬†ŒîŒî\\Delta of the input graph.\nAs shown by Katzmann¬†and¬†Komusiewicz¬†, LS Vertex Cover can be solved in¬†(2‚ÄãŒî)k‚ãÖnùí™‚Äã(1)‚ãÖsuperscript2Œîùëòsuperscriptùëõùí™1(2\\Delta)^{k}\\cdot n^{\\mathcal{O}(1)}¬†time.\nAn experimental evaluation of this algorithm showed that it can be tuned to solve the problem for¬†k‚âà20ùëò20k\\approx 20 on large sparse graphs, and that¬†kùëòk-optimal solutions for¬†k‚â•9ùëò9k\\geq 9 turned out to be optimal for almost all graphs considered in the experiments. We study LS¬†Max¬†cùëêc-Cut, where we want to decide whether a given coloring has a better one in its¬†kùëòk-flip neighborhood.\nWe first show that LS¬†Max¬†cùëêc-Cut is presumably not solvable in f‚Äã(k)‚ãÖno‚Äã(k)‚ãÖùëìùëòsuperscriptùëõùëúùëòf(k)\\cdot n^{o(k)}¬†time and transfer this lower-bound also to local search versions of related partition problems like¬†Min Bisection and¬†Max Sat.\nWe then present an algorithm to solve¬†LS¬†Max¬†cùëêc-Cut in time¬†ùí™‚Äã((3‚Äãe‚ÄãŒî)k‚ãÖc‚ãÖk3‚ãÖŒî‚ãÖn)ùí™‚ãÖsuperscript3ùëíŒîùëòùëêsuperscriptùëò3Œîùëõ\\mathcal{O}((3e\\Delta)^{k}\\cdot c\\cdot k^{3}\\cdot\\Delta\\cdot n), where¬†ŒîŒî\\Delta is the maximum degree of the input graph.\nTo put this running time bound into context, two aspects should be discussed:\nFirst, the NP-hardness of the special case of Max¬†cùëêc-Cut with¬†Œî=3Œî3\\Delta=3 implies that a running time of¬†f‚Äã(Œî)‚ãÖnùí™‚Äã(1)‚ãÖùëìŒîsuperscriptùëõùí™1f(\\Delta)\\cdot n^{\\mathcal{O}(1)} is impossible unless¬†P=NPPNP\\mathrm{P}=\\mathrm{NP}.\nSecond, only the parameter¬†kùëòk occurs in the exponent; we say that the running time grows mildly with respect to¬†ŒîŒî\\Delta and strongly with respect to¬†kùëòk.\nThis is desirable as¬†kùëòk is a user-determined parameter whereas¬†ŒîŒî\\Delta depends on the input; a broader discussion of this type of running times is given by Komusiewicz and Morawietz¬†. The algorithm is based on two main observations:\nFirst, we show that minimal improving flips are connected in the input graph.\nThis allows to enumerate candidate flips in¬†ùí™‚Äã((e‚ÄãŒî)k‚ãÖk‚ãÖn)ùí™‚ãÖsuperscriptùëíŒîùëòùëòùëõ\\mathcal{O}((e\\Delta)^{k}\\cdot k\\cdot n)¬†time.\nSecond, we show that, given a set of¬†kùëòk vertices to flip, we can determine an optimal way to flip their colors in ùí™‚Äã(3k‚ãÖc‚ãÖk2+k‚ãÖŒî)ùí™‚ãÖsuperscript3ùëòùëêsuperscriptùëò2‚ãÖùëòŒî\\mathcal{O}(3^{k}\\cdot c\\cdot k^{2}+k\\cdot\\Delta)¬†time.\nWe then discuss several ways to speed up the algorithm, for example by computing upper bounds for the improvement of partial flips.\nWe finally evaluate our algorithm experimentally when it is applied as post-processing for a state-of-the-art Max cùëêc-Cut¬†heuristic¬†3.\nIn this application, we take the solutions computed by the heuristic and improve them by hill-climbing with the¬†kùëòk-flip neighborhood for increasing values of¬†kùëòk.\nWe show that, for a standard benchmark data set, a large fraction of the previously best solutions can be improved by our algorithm, leading to new record solutions for these instances.\nThe post-processing is particularly successful for the instances of the data set with¬†c>2ùëê2c>2 and both positive and negative edge weights.\n\nReference markers found: [5]\n\nContext windows for each [ref]:\n[ref]5: of all edges that have endpoints with different colors is maximized.\nThis problem is known as\nMax cùëêc-Cut¬†  or Maximum Colorable Subgraph¬†.\nApplications of Max cùëêc-Cut include data clustering¬†[ref]5 0, computation of rankings¬†[ref]5, design of experimental studies¬†, sampling of public opinions in social networks¬†, channel assignment in wireless networks¬†, module detection in genetic\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 5,\n            \"titles\": [\n                \"Maximizing Agreements for Ranking, Clustering and Hierarchical Clustering via MAX-CUT\",\n                \"Efficient Balanced Treatment Assignments for Experimentation\",\n                \"Breakout Local Search for the Max-Cut problem\",\n                \"On Some Tighter Inapproximability Results (Extended Abstract)\",\n                \"Fine-Grained Complexity of kùëòk-OPT in Bounded-Degree Graphs for Solving TSP\",\n                \"Parameterized Algorithms\",\n                \"On the parameterized complexity of consensus clustering\",\n                \"Fundamentals of Parameterized Complexity\",\n                \"Local search: Is brute-force avoidable?\",\n                \"Clustering with Semidefinite Programming and Fixed Point Iteration\",\n                \"Randomized heuristics for the Max-Cut problem\",\n                \"Improved Approximation Algorithms for MAX kùëòk-CUT and MAX BISECTION\",\n                \"Computers and Intractability: A Guide to the Theory of NP-Completeness\",\n                \"Turbocharging Treewidth Heuristics\",\n                \"Don't Be Strict in Local Search!\",\n                \"Conflict Resolution in the Scheduling of Television Commercials\",\n                \"Efficient Bayesian Network Structure Learning via Parameterized Local Search on Topological Orderings\",\n                \"The Parameterized Complexity of Local Search for TSP, More Refined\",\n                \"Local search for string problems: Brute-force is essentially optimal\",\n                \"Incremental list coloring of graphs, parameterized by conservation\",\n                \"Partitioned Sampling of Public Opinions Based on Their Social Dynamics\",\n                \"Graph coloring problems, volume¬†39\",\n                \"On the Hardness of Approximating Max kùëòk-Cut and its Dual\",\n                \"Reducibility among combinatorial problems\",\n                \"Systematic Exploration of Larger Local Search Neighborhoods for the Minimum Vertex Cover Problem\",\n                \"Algorithm design\",\n                \"Solving large scale Max Cut problems via tabu search\",\n                \"On the Complexity of Parameterized Local Search for the Maximum Parsimony Problem\",\n                \"Parameterized Local Search for Vertex Cover: When Only the Search Radius Is Crucial\",\n                \"Enumerating connected induced subgraphs: Improved delay and experimental comparison\",\n                \"An algorithmic framework for fixed-cardinality optimization in sparse graphs applied to dense subgraph problems\",\n                \"Inferring Mechanisms of Compensation from E-MAP and SGA Data Using Local Search Algorithms for Max Cut\",\n                \"A Multiple Search Operator Heuristic for the Max-k-cut Problem\",\n                \"Searching the kùëòk-change neighborhood for TSP is W[1]-hard\",\n                \"Optimization, Approximation, and Complexity Classes\",\n                \"Simple Local Search Problems That are Hard to Solve\",\n                \"Teams of global equilibrium search algorithms for solving the weighted maximum cut problem in parallel\",\n                \"Minimum Interference Channel Assignment in Multiradio Wireless Mesh Networks\",\n                \"The parameterized complexity of kùëòk-flip local search for SAT and MAX SAT\",\n                \"Engineering a Local Search Solver for Weighted Vertex Cover\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]5 based on the context and research area of Parameterized Local Search for Max ùëê-Cut. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}