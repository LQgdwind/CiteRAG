{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: FedCorr: Multi-Stage Federated Learning for Label Noise Correction\n\nPaper Abstract: \n\nPaper Section Text:\nHyperparameters\nCIFAR-10\nCIFAR-100\nClothing1M\n\n##\\# of iterations in stage 1, T1subscript𝑇1T_{1}\n5\n10\n2\n\n##\\# of rounds in stage 2, T2subscript𝑇2T_{2}\n500\n450\n50\n\n##\\# of rounds in stage 3, T3subscript𝑇3T_{3}\n450\n450\n50\n\nConfidence threshold, θ𝜃\\theta\n0.5\n0.5\n0.9\n\nRelabel ratio, π𝜋\\pi\n0.5\n0.5\n0.8\n\nLearning rate\n0.03\n0.01\n0.001\n\n All experiments were implemented using Pytorch.\nAmong the baselines, we reimplemented FedAvg [ref]26, FedProx [ref]21, JointOpt [ref]30, DivideMix  and PoC , and we used the official implementations of FedDyn  and ARFL . For RoFL111https://github.com/jangsoohyuk/Robust-Federated-Learning-with-Noisy-Labels and Median222https://github.com/fushuhao6/Attack-Resistant-Federated-Learning, we used their unofficial implementations. For all methods, we use an SGD local optimizer with a momentum of 0.5 and no weight decay, with a batch size of 10 for CIFAR-10/100 and 16 for Clothing1M. Note that at each noise level, we used the same training hyperparameters for both IID and non-IID data partitions. For the implementation of each federated learning (FL) method, we define its total communication cost to be the cumulative number of clients that participate in training. For example, if a client participates in 10 communication rounds, then that client would contribute 10 to the total communication cost. For every method except JointOpt and DivideMix, we always reimplement the method using 5 local epochs per communication round, and the same total communication cost for each dataset, which corresponds to 1000 rounds of FedAvg for CIFAR-10/100 with fraction 0.1, and corresponds to 200 rounds of FedAvg for Clothing1M with fraction 0.02. Settings for JointOpt and DivideMix are discussed below. In the rest of this section, we give full details on all remaining hyperparameters used for each method.\nFor baseline methods, we also provide brief descriptions of their main underlying ideas. FedCorr. We fixed k=20𝑘20k=20 for LID estimation, α=1𝛼1\\alpha=1 for mixup, and β=5𝛽5\\beta=5 for the proximal regularization term in all reported experiments. All remaining hyperparameters can be found in Tab. 7. Note that the total communication cost for FedCorr is the same as for other baselines.\nTake CIFAR-10 for example: In each iteration of the pre-processing stage of FedCorr, every client participates exactly once. In contrast, in each communication round of our other baselines, only a fraction of 0.1 of the clients would participate.\nHence, one iteration in the pre-processing stage of FedCorr has 10 times the total communication cost of one communication round of the other baselines. For the latter two stages of FedCorr, we used the usual 0.1 as our fraction.\nHence the total communication cost of the entire implementation of FedCorr equals 100​T1+10​T2+10​T3=10000100subscript𝑇110subscript𝑇210subscript𝑇310000100T_{1}+10T_{2}+10T_{3}=10000; this is the same total communication cost for implementing FedAvg over 100010001000 communication rounds with fraction 0.1. JointOpt [ref]30 is one of the state-of-the-art centralized methods for tackling label noise, which alternately updates network parameters and corrects labels using the model prediction vectors. It introduced αJ​osubscript𝛼𝐽𝑜\\alpha_{Jo} and βJ​osubscript𝛽𝐽𝑜\\beta_{Jo} as two additional hyperparameters. In the centralized setting, we used the hyperparameters given in Tab. 8. In particular, we considered a total of seven noise settings, which we have divided into two groups: low noise levels (first four settings) and high noise levels (last three settings). Within each group, we used the same hyperparameters. Note that the hyperparameters are not exactly the same as those given in [ref]30, as we used different architectures and different frameworks to generate synthetic label noise. In the federated setting, we used αJ​o=1.2subscript𝛼𝐽𝑜1.2\\alpha_{Jo}=1.2, βJ​o=0.8subscript𝛽𝐽𝑜0.8\\beta_{Jo}=0.8 and a learning rate of 0.010.010.01 for CIFAR-10/100. To boost performance, we used a warm-up process for CIFAR-10/100: We first trained using FedAvg over 20 communication rounds with 5 local epochs per communication round, after which we started using JointOpt for local training over 80 communication rounds with 20 local epochs per communication round. For Clothing1M, we used αJ​o=1.2subscript𝛼𝐽𝑜1.2\\alpha_{Jo}=1.2, βJ​o=0.8subscript𝛽𝐽𝑜0.8\\beta_{Jo}=0.8, and a learning rate of 0.0010.0010.001. As we used a ResNet-50 that is already pretrained on ImageNet, no warm-up process was used for our Clothing1M experiments. We trained using JointOpt over 40 communication rounds with 10 local epochs per round. \n\n\n\n\n(ρ,τ)𝜌𝜏(\\rho,\\tau)\nαJ​osubscript𝛼𝐽𝑜\\alpha_{Jo}\nβJ​osubscript𝛽𝐽𝑜\\beta_{Jo}\nLearning rate\n\nLow noise levels\n1.2\n1.5\n0.1\n\n(0.0,0.0),(0.4,0.0),(0.4,0.5),(0.6,0.0)0.00.00.40.00.40.50.60.0(0.0,0.0),(0.4,0.0),(0.4,0.5),(0.6,0.0)\n\nHigh noise levels\n1.2\n0.8\n0.2\n\n(0.6,0.5),(0.8,0.0),(0.8,0.5)0.60.50.80.00.80.5(0.6,0.5),(0.8,0.0),(0.8,0.5)\n\n DivideMix  is another state-of-the-art centralized method, which dynamically divides the training data into labeled (clean) and unlabeled (noisy) data, and trains the model in a semi-supervised manner. For CIFAR-10/100, we used the same two groups of noise settings, as described in the above configuration for JointOpt. The only hyperparameter we tuned is λD​i​vsubscript𝜆𝐷𝑖𝑣\\lambda_{Div}, which is a hyperparameter specific to DivideMix. For low noise levels, we used λD​i​v=0subscript𝜆𝐷𝑖𝑣0\\lambda_{Div}=0 (resp. λD​i​v=25subscript𝜆𝐷𝑖𝑣25\\lambda_{Div}=25) for CIFAR-10 (resp. CIFAR-100). For high noise levels, we used λD​i​v=25subscript𝜆𝐷𝑖𝑣25\\lambda_{Div}=25 (resp. λD​i​v=150subscript𝜆𝐷𝑖𝑣150\\lambda_{Div}=150) for CIFAR-10 (resp. CIFAR-100). For all other hyperparameters for CIFAR-10/100, we used the values given in . For Clothing1M, we use λD​i​v=25subscript𝜆𝐷𝑖𝑣25\\lambda_{Div}=25 and a learning rate of 0.010.010.01; for all other hyperparameters, we used the values given in . We used the same warm-up process for CIFAR-10/100, and we used the same number of communication rounds and number of local epochs for all datasets, as described above in our configuration for JointOpt. FedAvg [ref]26 is the first algorithm that introduced the idea of federated learning. We used a learning rate of 0.03, 0.01 and 0.003 for CIFAR-10, CIFAR-100 and Clothing1M, respectively. FedProx [ref]21 was proposed to tackle data heterogeneity among clients by adding a fixed proximal term with coefficient μp​r​o​xsubscript𝜇𝑝𝑟𝑜𝑥\\mu_{prox} to every local loss function. We used μp​r​o​x=1subscript𝜇𝑝𝑟𝑜𝑥1\\mu_{prox}=1 for all experiments, and a learning rate of 0.01 and 0.003 for CIFAR-10/100 and Clothing1M, respectively. RoFL  is, to the best of our knowledge, the only method that is designed for label correction in FL. It is based on the idea of exchanging feature centroids between the server and clients, and it introduced Tp​lsubscript𝑇𝑝𝑙T_{pl} as an additional hyperparameter to control label correction. We set Tp​lsubscript𝑇𝑝𝑙T_{pl} to 100, 400 and 10 for CIFAR-10, CIFAR-100 and Clothing1M, respectively. All other hyperparameters are set to the same values as given in . ARFL  is a robust aggregation algorithm that resists abnormal attacks via residual-based reweighting, using two hyperparameters λa​rsubscript𝜆𝑎𝑟\\lambda_{ar} and threshold δa​rsubscript𝛿𝑎𝑟\\delta_{ar}. We used λa​r=2subscript𝜆𝑎𝑟2\\lambda_{ar}=2 and δa​r=0.1subscript𝛿𝑎𝑟0.1\\delta_{ar}=0.1 for all experiments. We used a learning rate of 0.010.010.01 and 0.0030.0030.003 for CIFAR-10/100 and Clothing1M, respectively. FedDyn  proposed a dynamic regularizer, with coefficient αD​y​nsubscript𝛼𝐷𝑦𝑛\\alpha_{Dyn}, for local optimization in each communication round, so as to tackle the inconsistency between the local and global empirical loss. We used αD​y​n=0.01subscript𝛼𝐷𝑦𝑛0.01\\alpha_{Dyn}=0.01, a learning rate of 0.1 with a decay of 0.998 for all the experiments. Median  is an aggregation method for robust distributed learning, whereby the notion of “average” in FedAvg is changed from “mean” to “median”. For all experiments, we used a learning rate of 0.01; all other hyperparameters are the same as given in FedAvg. Poc  is a client selection algorithm that is biased towards clients with higher local losses within a given client pool. We used a learning rate of 0.01 and a client pool size of d=30𝑑30d=30 for all experiments.\n\nReference markers found: [26]\n\nContext windows for each [ref]:\n[ref]26: threshold, θ𝜃\\theta\n0.5\n0.5\n0.9\n\nRelabel ratio, π𝜋\\pi\n0.5\n0.5\n0.8\n\nLearning rate\n0.03\n0.01\n0.001\n\n All experiments were implemented using Pytorch.\nAmong the baselines, we reimplemented FedAvg [ref]26, FedProx [ref]21, JointOpt [ref]30, DivideMix  and PoC , and we used the official implementations of FedDyn  and ARFL . For\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 26,\n            \"titles\": [\n                \"Adaptive Federated Optimization\",\n                \"Federated Learning Based on Dynamic Regularization\",\n                \"Estimating local intrinsic dimensionality\",\n                \"Unsupervised Label Noise Modeling and Loss Correction\",\n                \"FOCUS: Dealing with Label Quality Disparity in Federated Learning\",\n                \"Dynamic attention-based communication-efficient federated learning\",\n                \"Client Selection in Federated Learning: Convergence Analysis and Power-of-Choice Selection Strategies\",\n                \"Attack-Resistant Federated Learning with Residual-based Reweighting\",\n                \"A Survey of Label-noise Representation Learning: Past, Present and Future\",\n                \"Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels\",\n                \"Deep Residual Learning for Image Recognition\",\n                \"Dimensionality, discriminability, density and distance distributions\",\n                \"Local intrinsic dimensionality i: an extreme-value-theoretic foundation for similarity applications\",\n                \"Measuring the Effects of Non-Identical Data Distribution for Federated Visual Classification\",\n                \"Distillation-Based Semi-Supervised Federated Learning for Communication-Efficient Collaborative Training with Non-IID Private Data\",\n                \"Scaffold: Stochastic controlled averaging for federated learning\",\n                \"Learning multiple layers of features from tiny images\",\n                \"Backpropagation applied to handwritten zip code recognition\",\n                \"Dividemix: Learning with noisy labels as semi-supervised learning\",\n                \"Ditto: Fair and robust federated learning through personalization\",\n                \"Federated Learning: Challenges, Methods, and Future Directions\",\n                \"Federated optimization in heterogeneous networks\",\n                \"On the Convergence of FedAvg on Non-IID Data\",\n                \"Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality\",\n                \"Dimensionality-Driven Learning with Noisy Labels\",\n                \"Communication-efficient learning of deep networks from decentralized data\",\n                \"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\n                \"Local SGD Converges Fast and Communicates Little\",\n                \"Joint Optimization Framework for Learning with Noisy Labels\",\n                \"Robust Federated Learning with Attack-Adaptive Aggregation\",\n                \"Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization\",\n                \"Part-dependent Label Noise: Towards Instance-dependent Label Noise\",\n                \"Learning from massive noisy labeled data for image classification\",\n                \"Training classifiers that are universally robust to all label noise levels\",\n                \"A Reputation Mechanism Is All You Need: Collaborative Fairness and Adversarial Robustness in Federated Learning\",\n                \"Federated Machine Learning: Concept and Applications\",\n                \"Robust Federated Learning with Noisy Labels\",\n                \"Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates\",\n                \"How does disagreement help generalization against label corruption?\",\n                \"mixup: Beyond Empirical Risk Minimization\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]26 based on the context and research area of FedCorr: Multi-Stage Federated Learning for Label Noise Correction. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}