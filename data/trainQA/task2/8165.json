{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: FusionANNS: An Efficient CPU/GPU Cooperative Processing Architecture for Billion-scale Approximate Nearest Neighbor Search\n\nPaper Abstract: \n\nPaper Section Text:\nApproximate nearest neighbor search (ANNS) in high-dimensional spaces refers to find top-kùëòk vectors most similar to a given query vector. It has a wide range of applications in many fields, including data mining¬†[ref]1, search engines¬†, and AI-driven recommendation systems¬† . Specifically, fueled by the recent prosperity of Large Language Models (LLMs)¬†   , ANNS systems have become a crucial component of modern AI infrastructure. Figure¬†1 shows a typical framework of Retrieval Augmented Generation (RAG). The domain-specific knowledge is first embedded as high-dimensional vectors and stored in a vector database. When a chatbot receives a query, it uses the ANNS engine to retrieve the most relevant knowledge from the vector database, allowing the LLM to use that knowledge as additional context for more accurate inference. ANNS is a typical memory-hungry and compute-intensive application. Most ANNS systems¬†    [ref]13 exploit inverted file (IVF)¬†   or graph-based¬† [ref]13  indices to facilitate ANNS. For billion-scale datasets, these indices usually require a large amount of memory resource. For example, state-of-the-art IVF-based RUMMY¬† and graph-based Bang¬† require terabyte-scale memory space to accommodate billion-scale vectors and their indices. The substantial memory demand significantly increases the total cost of ownership (TCO), impeding ANNS scaling to extremely large datasets (e.g., hundreds of billions of vectors). Despite the huge memory requirement, ANNS is\nalso computationally intensive because it requires massive distance calculations among vectors, especially for large-scale datasets in high-dimensional spaces. With a rapid growth of the vector database, ANNS has emerged as a new performance bottleneck in RAG scenarios¬†, potentially accounting for about 50% of the total latency for an LLM query¬†. To reduce the cost of memory required by ANNS, there are mainly two kinds of approaches, i.e., Hierarchical Indexing (HI)¬†  and Product Quantization (PQ)¬†0 1. First, the hierarchical indexing approach reduces memory consumption by storing indices¬† 2 on SSDs. Typically, Microsoft‚Äôs commercial ANNS system‚ÄìSPANN¬†  stores all IVF-based indices (i.e., posting lists) on SSDs, and maintains the centroids of these posting lists in memory using a navigation graph. Although SPANN achieves low latency, we find that its throughput for concurrent queries is quite limited, peaking at only four CPU threads on a high-end SSD (Section¬†2.1). The limited scalability hampers its practicality for AI applications requiring high throughput.\nSecond, PQ is another effective way for memory cost saving. This vector compression technology can significantly reduce the memory footprint of high-dimensional vectors by up to 95%, and can also accelerate the ANNS speed by several times¬†0. However, since PQ is a lossy-compression scheme, a higher compression rate often implies a lower query accuracy. It is usually unacceptable for some scenarios that require high accuracy (e.g. recall‚â•90%absentpercent90\\geq 90\\%)¬†3. To address the computing challenge, GPUs have been increasingly leveraged to accelerate extensive distance calculations involved in ANNS. Recent GPU-based ANNS solutions¬†  4 5 6 0 have demonstrated high efficiency for handling small datasets that fit within the GPU‚Äôs high bandwidth memory (HBM). However, for billion-scale datasets, the GPU-based approach may suffer from significant performance degradation. Our experiments show that the performance of ANNS even declines by 10% when SPANN directly adopts GPUs for distance calculations (Section¬†2.3). The root cause is that the limited capacity of HBM causes extensive data movement across GPU‚Äôs HBM, host memory, and SSDs. Although the above approaches can address some of the performance/cost/accuracy issues to some extent, none of them can offer high throughput, low latency, cost efficiency, and high accuracy simultaneously for billion-scale ANNS services. Intuitively, one can adopt hierarchical indexing, product quantization, and GPU acceleration techniques together to achieve an optimal ANNS solution. However, we find that the combination of these techniques causes even worse performance than SPANN which exploits hierarchical indexing solely (Section¬†2.3). Overall, there remains several challenges to collaborate hierarchical indexing with product quantization in a GPU-accelerated ANNS system. Challenge 1: To improve query accuracy and efficiency, most ANNS systems¬†  exploit a replication strategy to build high-quality IVF indices, where boundary vectors are replicated into adjacent posting lists. This can significantly expand the size of indices by 8√ó8\\times larger than that of raw vectors¬† . Even these indices are compressed with PQ, the GPU‚Äôs HBM still cannot accommodate all compressed indices, resulting in extensive data swapping between GPU and CPUs. Challenge 2: Since PQ incurs non-trivial accuracy loss, it is often associated with a vector re-ranking process to improve the query accuracy. However, since the accuracy loss varies significantly among different compressed vectors, it is challenging to determine the minimum number of vectors that requires re-ranking for each query under a given accuracy constrain. Challenge 3: Since a raw vector (128‚àºsimilar-to\\sim384 bytes) is much smaller than the minimum read granularity (4 KB) of modern NVMe SSDs, each request for raw vectors often causes significant read amplification, resulting in low I/O efficiency during re-ranking. In this paper, we present FusionANNS, a ‚ÄúCPU + GPU‚Äù cooperative processing\narchitecture for billion-scale ANNS. FusionANNS achieves high throughput, low latency, cost efficiency and high accuracy simultaneously using only one entry-level GPU. The key idea of FusionANNS is to minimize data swapping across GPU, CPUs, and SSDs via CPU/GPU collaborative filtering and re-ranking. Specifically, we propose three novel designs to tackle the above challenges. First, we propose a novel multi-tiered index structure to enable CPU/GPU collaborative filtering. FusionANNS stores (i) raw vectors on SSDs, and (ii) compressed vectors using PQ in the GPU‚Äôs HBM, while maintaining (iii) only vector-IDs of each posting list and a navigation graph in host memory. Since the HBM only stores highly-compressed PQ-vectors rather than compressed posting lists, it can accommodate all compressed vectors in billion-scale datasets. Upon a query, the host CPU first traverses the in-memory navigation graph to find the top-mùëöm nearest posting lists, and then only transmit their vector-IDs (excluding the vectors‚Äô content) to GPU for distance calculations. In this way, FusionANNS can significantly reduce data transmission between CPUs and GPU. Second, we propose heuristic re-ranking to improve the query accuracy while avoiding unnecessary I/O operations and distance calculations. We split the re-ranking process into multiple mini-batches and execute them sequentially. Once a mini-batch is finished, we exploit a lightweight feedback control model to check whether subsequent mini-batches are beneficial for improving the query accuracy, and terminate the re-ranking process immediately if successive mini-batches have little contribute to the query accuracy. Third, we propose redundancy-aware I/O deduplication to further improve the I/O efficiency during re-ranking. We store vectors with high similarity compactly to improve the spatial locality on SSDs. This optimized storage layout enables two I/O deduplication mechanisms: 1) merging multiple I/Os mapped to the same page of SSDs within a mini-batch to mitigate read amplification, 2) fully exploiting the DRAM buffer to eliminate redundant I/Os in subsequent mini-batches. Overall, we make the following contributions: We design FusionANNS, the first GPU-accelerated SSD-based ANNS system that achieves high throughput, low latency, cost efficiency and high accuracy simultaneously for billion-scale datasets. For Challenge 1, we propose a novel multi-tiered index that enables GPU/CPU collaborative filtering to significantly reduce data transmission between CPUs and GPU. For Challenge 2, we propose heuristic re-ranking to eliminate unnecessary I/Os and computations during re-ranking. For Challenge 3, we propose redundancy-aware I/O deduplication based on the optimized storage layout to further enhance I/O efficiency. We evaluate FusionANNS using a general purpose server equipped with an entry-level GPU. Experimental results show that FusionANNS improves QPS by up to 13.1√ó\\times and 4.9√ó\\times, and enhance cost efficiency by up to 8.8√ó\\times and 6.8√ó\\times, compared with the state-of-the-art SSD-based system‚ÄìSPANN and GPU-accelerated in-memory system‚ÄìRUMMY, respectively, while guaranteeing low latency and high accuracy.\n\nReference markers found: [1]\n\nContext windows for each [ref]:\n[ref]1: neighbor search (ANNS) in high-dimensional spaces refers to find top-kùëòk vectors most similar to a given query vector. It has a wide range of applications in many fields, including data mining¬†[ref]1, search engines¬†, and AI-driven recommendation systems¬† . Specifically, fueled by the recent prosperity of Large Language Models (LLMs)¬†   , ANNS systems have become a crucial component of\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 1,\n            \"titles\": [\n                \"Uni-Retriever: Towards Learning The Unified Embedding Based Retriever in Bing Sponsored Search\",\n                \"AnnexML: Approximate Nearest Neighbor Search for Extreme Multi-Label Classification\",\n                \"Visual Search at Alibaba\",\n                \"Embedding-based Retrieval in Facebook Search\",\n                \"Chatlaw: Open-source legal large language model with integrated external knowledge bases. arxiv preprint arxiv:2306.16092\",\n                \"A study on the implementation of generative ai services using an enterprise data-based llm application architecture. arxiv preprint arxiv:2309.01105\",\n                \"Chathome: Development and evaluation of a domain-specific language model for home renovation. arxiv preprint arxiv:2307.15290\",\n                \"Xuanyuan 2.0: A large chinese financial chat model with hundreds of billions parameters. arxiv preprint arxiv:2305.12002\",\n                \"Fast vector query processing for large datasets beyond GPU memory with reordered pipelining\",\n                \"Bang: Billion-scale approximate nearest neighbor search using a single gpu. arxiv preprint arxiv: 2401.11324\",\n                \"Df-gas: a distributed fpga-as-a-service architecture towards billion-scale graph-based approximate nearest neighbor search\",\n                \"ParlayANN: Scalable and Deterministic Parallel Graph-Based Approximate Nearest Neighbor Search Algorithms\",\n                \"iqan: Fast and accurate vector search with efficient intra-query parallelism on multi-core architectures\",\n                \"SPFresh: Incremental In-Place Update for Billion-Scale Vector Search\",\n                \"SPANN: highly-efficient billion-scale approximate nearest neighborhood search\",\n                \"The inverted multi-index\",\n                \"Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs\",\n                \"RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation\",\n                \"Scalable billion-point approximate nearest neighbor search using SmartSSDs\",\n                \"Billion-scale similarity search with GPUs\",\n                \"Juno: Optimizing High-Dimensional Approximate Nearest Neighbour Search with Sparsity-Aware Algorithm and Ray-Tracing Core Mapping\",\n                \"DiskANN: Fast accurate billion-point nearest neighbor search on a single node\",\n                \"Retrieval-Augmented Generation for Large Language Models: A Survey\",\n                \"GGNN: Graph-based GPU Nearest Neighbor Search\",\n                \"Gpu-accelerated proximity graph approximate nearest neighbor search and construction\",\n                \"SONG: approximate nearest neighbor search on GPU\",\n                \"Approximate nearest neighbors: Towards removing the curse of dimensionality\",\n                \"idec: Indexable distance estimating codes for approximate nearest neighbor search\",\n                \"Query-aware locality-sensitive hashing for approximate nearest neighbor search\",\n                \"Optimised kd-trees for fast image descriptor matching\",\n                \"Revisiting the Inverted Indices for Billion-Scale Approximate Nearest Neighbors\",\n                \"Product quantization for nearest neighbor search\",\n                \"Fast approximate nearest neighbor search with the navigating spreading-out graph\",\n                \"Algorithm as 136: A k-means clustering algorithm\",\n                \"Characterizing the Dilemma of Performance and Index Size in Billion-Scale Vector Search and Breaking It with Second-Tier Memory\",\n                \"SPTAG: A library for fast approximate nearest neighbor search\",\n                \"Faiss: A library for efficient similarity search\",\n                \"rkt-io: a direct i/o stack for shielded execution\",\n                \"Combining buffered I/O and direct I/O in distributed file systems\",\n                \"Partitioned elias-fano indexes\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]1 based on the context and research area of FusionANNS: An Efficient CPU/GPU Cooperative Processing Architecture for Billion-scale Approximate Nearest Neighbor Search. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}