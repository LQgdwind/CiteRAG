{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Parallel Clique Counting and Peeling Algorithms\n\nPaper Abstract: \n\nPaper Section Text:\nFinding k𝑘k-cliques in a graph is a fundamental\ngraph-theoretic problem with a long history of study both in theory\nand practice. In recent years, k𝑘k-clique counting and listing have\nbeen widely applied in practice due to their many applications,\nincluding in learning network embeddings ,\nunderstanding the structure and formation of\nnetworks  , identifying dense subgraphs for\ncommunity detection  8  , and\ngraph partitioning and compression . For sparse graphs, the best known sequential algorithm is by Chiba and\nNishizeki , and requires O​(m​αk−2)𝑂𝑚superscript𝛼𝑘2O(m\\alpha^{k-2}) work\n(number of operations), where α𝛼\\alpha is the arboricity of the\ngraph.111A graph has arboricity α𝛼\\alpha if the minimum number of spanning forests needed to cover the graph is α𝛼\\alpha. The state-of-the-art clique parallel k𝑘k-clique counting algorithm is\nkClist , which achieves the same work bound,\nbut does not have a strong theoretical bound on the\nspan (parallel time). Furthermore, kClist as well as existing parallel k𝑘k-clique counting\nalgorithms have limited scalability for graphs with more than a few\nhundred million edges, but real-world graphs today frequently contain\nbillions to hundreds of billions of edges [ref]34. k𝑘k-clique Counting.\nIn this paper, we design a new parallel k𝑘k-clique counting algorithm,\narb-count that matches the work of Chiba-Nishezeki, has\npolylogarithmic span, and has improved space complexity compared to\nkClist. Our algorithm is able to significantly outperform kClist and\nother competitors, and scale to larger graphs than prior work.\narb-count is based on using low out-degree orientations of the graph\nto reduce the total work.\nAssuming that we have a low out-degree ranking of the graph, we show\nthat for a constant k𝑘k we can count or list all k𝑘k-cliques in\nO​(m​αk−2)𝑂𝑚superscript𝛼𝑘2O(m\\alpha^{k-2}) work, and O​(k​log⁡n+log2⁡n)𝑂𝑘𝑛superscript2𝑛O(k\\log n+\\log^{2}n) span with high probability (whp),222We say O​(f​(n))𝑂𝑓𝑛O(f(n)) with\nhigh probability (whp) to indicate O​(c​f​(n))𝑂𝑐𝑓𝑛O(cf(n)) with probability\nat least 1−n−c1superscript𝑛𝑐1-n^{-c} for c≥1𝑐1c\\geq 1, where n𝑛n is the input size.\nwhere m𝑚m is the number of edges in the graph and α𝛼\\alpha is the\narboricity of the graph. Having work bounds parameterized by α𝛼\\alpha is\ndesirable since most real-world graphs have low\narboricity [ref]17. Theoretically, arb-count requires\nO​(α)𝑂𝛼O(\\alpha) extra space per processor; in contrast, the kClist algorithm requires O​(α2)𝑂superscript𝛼2O(\\alpha^{2}) extra space per processor. Furthermore, kClist does not achieve polylogarithmic span. We also design an approximate k𝑘k-clique counting algorithm\nbased on counting on a sparsified graph. We show in the appendix that our approximate algorithm\nproduces unbiased estimates and runs in O​(p​m​αk−2+m)𝑂𝑝𝑚superscript𝛼𝑘2𝑚O(pm\\alpha^{k-2}+m)\nwork and O​(k​log⁡n+log2⁡n)𝑂𝑘𝑛superscript2𝑛O(k\\log n+\\log^{2}n) span whp for a sampling\nprobability of p𝑝p. Parallel Ranking Algorithms.\nWe present two new parallel algorithms\nfor efficiently ranking the vertices, which we use for k𝑘k-clique counting. We show that a distributed\nalgorithm by Barenboim and Elkin  can be implemented\nin linear work and polylogarithmic span. We also parallelize an\nexternal-memory algorithm by Goodrich and Pszona  and\nobtain the same complexity bounds.\nWe believe that our parallel ranking algorithms may be of\nindependent interest, as many other subgraph finding algorithms use\nlow out-degree orderings\n(e.g.,   ). Peeling and k𝑘k-Clique Densest Subgraph.\nWe also present new parallel algorithms for the\nk𝑘k-clique densest subgraph problem, a generalization of the densest subgraph problem\nthat was first introduced by Tsourakakis . This\nproblem admits a natural 1/k1𝑘1/k-approximation by peeling vertices in\norder of their incident k𝑘k-clique counts. We present a parallel peeling\nalgorithm, arb-peel, that peels all vertices with the\nlowest k𝑘k-clique count on each round and uses arb-count as a subroutine.\nThe expected amortized work of arb-peel is O​(m​αk−2+ρk​(G)​log⁡n)𝑂𝑚superscript𝛼𝑘2subscript𝜌𝑘𝐺𝑛O(m\\alpha^{k-2}+\\rho_{k}(G)\\log n) and\nthe span is O​(ρk​(G)​k​log⁡n+log2⁡n)𝑂subscript𝜌𝑘𝐺𝑘𝑛superscript2𝑛O(\\rho_{k}(G)k\\log n+\\log^{2}n) whp, where ρk​(G)subscript𝜌𝑘𝐺\\rho_{k}(G) is the\nnumber of rounds needed to completely peel the graph.\nWe also prove in the appendix that the problem of obtaining the hierarchy given by\nthis process is 𝖯𝖯\\mathsf{P}-complete for k>2𝑘2k>2, indicating that a polylogarithmic-span\nsolution is unlikely. Tsourakakis also shows that naturally extending the Bahmani et\nal.  algorithm for approximate densest subgraph gives\nan 1/(k​(1+ϵ))1𝑘1italic-ϵ1/(k(1+\\epsilon))-approximation in O​(log⁡n)𝑂𝑛O(\\log n) parallel\nrounds, although they were not concerned about work.\nWe present\nan O​(m​αk−2)𝑂𝑚superscript𝛼𝑘2O(m\\alpha^{k-2}) work and polylogarithmic-span algorithm,\narb-approx-peel, for obtaining a 1/(k​(1+ϵ))1𝑘1italic-ϵ1/(k(1+\\epsilon))-approximation to\nthe k𝑘k-clique densest subgraph problem. We obtain this work bound using our k𝑘k-clique algorithm as a subroutine.\nDanisch et al.  use their k𝑘k-clique counting\nalgorithm as a subroutine to implement these two approximation\nalgorithms for k𝑘k-clique densest subgraph, but their implementations do not have\nprovably-efficient bounds. Experimental Evaluation.\nWe present implementations of our algorithms that use various\noptimizations to achieve good practical performance. We\nperform a thorough experimental study on a 30-core\nmachine with two-way hyper-threading and compare to prior work.\nWe show that on a variety of real-world graphs and different\nk𝑘k, our k𝑘k-clique counting algorithm achieves 1.31–9.88x speedup over the\nstate-of-the-art parallel kClist algorithm  and\nself-relative speedups of 13.23–38.99x.\nWe also compared our k𝑘k-clique counting algorithm to other\nparallel k𝑘k-clique counting implementations including Jain and Seshadhri’s\nPivoter , Mhedhbi and Salihoglu’s worst-case optimal\njoin algorithm (WCO) , Lai et al.’s\nimplementation of a binary join algorithm (BinaryJoin)\n, and Pinar et al.’s ESCAPE\n, and demonstrate speedups of up to several orders of\nmagnitude. Furthermore, by integrating state-of-the-art parallel graph\ncompression techniques, we can process graphs\nwith tens to hundreds of billions of edges, significantly\nimproving on the capabilities of existing implementations. As\nfar as we know, we are the first to report 444-clique counts for\nHyperlink2012, the largest publicly-available graph, with over\ntwo hundred billion undirected edges. We study the accuracy-time tradeoff of our sampling algorithm, and\nshow that is able to approximate the clique counts with 5.05% error\n5.32–6573.63 times more quickly than running our exact counting\nalgorithm on the same graph. We compare our sampling algorithm to\nBressan et al.’s serial MOTIVO ,\nand demonstrate 92.71–177.29x speedups. Finally, we study our two\nparallel approximation algorithms for k𝑘k-clique densest subgraph and show that our we are\nable to outperform kClist by up to 29.59x and achieve 1.19–13.76x\nself-relative speedup. We demonstrate up to 53.53x speedup over Fang\net al.’s serial CoreApp  as well. The contributions of this paper are as follows: A parallel algorithm with O​(m​αk−2)𝑂𝑚superscript𝛼𝑘2O(m\\alpha^{k-2}) and polylogarithmic\nspan whp for k𝑘k-clique counting. Parallel algorithms for low out-degree\norientations with O​(m)𝑂𝑚O(m) work and O​(log2⁡n)𝑂superscript2𝑛O(\\log^{2}n) span whp. An O​(m​αk−2)𝑂𝑚superscript𝛼𝑘2O(m\\alpha^{k-2}) amortized expected work parallel algorithm for\ncomputing a 1/k1𝑘1/k-approximation to the k𝑘k-clique densest subgraph problem, and an O​(m​αk−2)𝑂𝑚superscript𝛼𝑘2O(m\\alpha^{k-2}) work and polylogarithmic-span whp\nalgorithm for computing a 1/(k​(1+ϵ))1𝑘1italic-ϵ1/(k(1+\\epsilon))-approximation. Optimized implementations of our algorithms that achieve\nsignificant speedups over existing state-of-the-art methods, and\nscale to the largest publicly-available graphs. Our code is publicly available at: https://github.com/ParAlg/gbbs/tree/master/benchmarks/CliqueCounting.\n\nReference markers found: [34]\n\nContext windows for each [ref]:\n[ref]34: counting\nalgorithms have limited scalability for graphs with more than a few\nhundred million edges, but real-world graphs today frequently contain\nbillions to hundreds of billions of edges [ref]34. k𝑘k-clique Counting.\nIn this paper, we design a new parallel k𝑘k-clique counting algorithm,\narb-count that matches the work of Chiba-Nishezeki, has\npolylogarithmic span, and has improved\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 34,\n            \"titles\": [\n                \"Optimizing Subgraph Queries by Combining Binary and Worst-Case Optimal Joins\",\n                \"EmptyHeaded: A Relational Engine for Graph Processing\",\n                \"Graphlet Decomposition: Framework, Algorithms, and Applications\",\n                \"A 𝖯𝖯\\\\mathsf{P}-complete problem and approximations to it\",\n                \"Densest subgraph in streaming and MapReduce\",\n                \"Sublogarithmic distributed MIS algorithm for sparse graphs using Nash-Williams decomposition\",\n                \"High-performance parallel graph coloring with strong guarantees on work, depth, and quality\",\n                \"Brief announcement: ParlayLib – a toolkit for parallel algorithms on shared-memory multicore machines\",\n                \"Space-efficient scheduling of multithreaded computations\",\n                \"The parallel evaluation of general arithmetic expressions\",\n                \"Motif counting beyond five nodes\",\n                \"Motivo: fast motif counting via succinct color coding and adaptive sampling\",\n                \"Arboricity and subgraph listing algorithms\",\n                \"Introduction to Algorithms (3. ed.)\",\n                \"The Lemur project\",\n                \"Listing k𝑘k-cliques in sparse real-world graphs*\",\n                \"Julienne: A framework for parallel graph algorithms using work-efficient bucketing\",\n                \"Theoretically Efficient Parallel Graph Algorithms Can Be Fast and Scalable\",\n                \"Parallel Batch-Dynamic 𝑘-Clique Counting\",\n                \"Fixed-parameter tractability and completeness I: Basic results\",\n                \"Listing all maximal cliques in sparse graphs in near-optimal time\",\n                \"Efficient Algorithms for Densest Subgraph Discovery\",\n                \"Clique partitions, graph compression and speeding-up algorithms\",\n                \"Clique counting in MapReduce: Algorithms and experiments\",\n                \"Towards a theory of nearly constant time parallel algorithms\",\n                \"External-memory network analysis algorithms for naturally sparse graphs\",\n                \"Parallel k𝑘k-clique community detection on large-scale networks\",\n                \"A fast and provable method for estimating clique counts using Turán’s theorem\",\n                \"The Power of Pivoting for Exact Clique Counting\",\n                \"Introduction to Parallel Algorithms\",\n                \"Distributed subgraph matching on timely dataflow\",\n                \"SNAP Datasets: Stanford large network dataset collection\",\n                \"Ordering heuristics for k𝑘k-clique listing\",\n                \"Smallest-last ordering and clustering and graph coloring algorithms\",\n                \"The graph structure in the web–analyzed on different aggregation levels\",\n                \"Edge-disjoint spanning trees of finite graphs\",\n                \"On the complexity of the subgraph problem\",\n                \"Worst-case optimal join algorithms\",\n                \"Colorful triangle counting and a MapReduce implementation\",\n                \"Enumerating trillion subgraphs on distributed systems\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]34 based on the context and research area of Parallel Clique Counting and Peeling Algorithms. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}