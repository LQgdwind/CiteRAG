{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Improving Schroeppel and Shamir’s Algorithm for Subset Sum via Orthogonal Vectors\n\nPaper Abstract: \n\nPaper Section Text:\nIn this section we present and discuss our algorithm for Orthogonal Vectors.\nAs discussed in the introduction it should be noted that the proof strategy is\nsimilar to the one from  (which is heavily inspired on\nBollobás’s Theorem [ref]14), but we obtain improvements\nthat are crucial for the main result of this paper. We compare our methods with\nexisting literature at the end of this section. For any λ∈[0.4,0.5]𝜆0.40.5\\lambda\\in[0.4,0.5] and σ∈[0.4,0.6]𝜎0.40.6\\sigma\\in[0.4,0.6], there is a Monte-Carlo algorithm that is\ngiven 𝒜⊆(dσ​λ​d)𝒜binomial𝑑𝜎𝜆𝑑\\mathcal{A}\\subseteq\\binom{d}{\\sigma\\lambda d} and ℬ⊆(d(1−σ)​λ​d)ℬbinomial𝑑1𝜎𝜆𝑑\\mathcal{B}\\subseteq\\binom{d}{(1-\\sigma)\\lambda d}, detects if there exist A∈𝒜𝐴𝒜A\\in\\mathcal{A} and B∈ℬ𝐵ℬB\\in\\mathcal{B} with A∩B=∅𝐴𝐵A\\cap B=\\emptyset in time and space 𝒪~​(|𝒜|+|ℬ|+2d)~𝒪𝒜ℬsuperscript2𝑑\\widetilde{\\mathcal{O}}(|\\mathcal{A}|+|\\mathcal{B}|+2^{d}). We can assume that\nλ≤0.5𝜆0.5\\lambda\\leq 0.5 by a subset complementation trick. The bound\nσ∈[0.4,0.6]𝜎0.40.6\\sigma\\in[0.4,0.6] is an artifact of technical methods we used in the proof\nof Lemma B.1.\nIn the proof of this lemma the parameters λ𝜆\\lambda and σ𝜎\\sigma lost their meaning from Section 4. Hence, to simplify, we let p:=σ​λ​nassign𝑝𝜎𝜆𝑛p:=\\sigma\\lambda n and q:=(1−σ)​λ​nassign𝑞1𝜎𝜆𝑛q:=(1-\\sigma)\\lambda n, and let 𝒜⊆([d]p)𝒜binomialdelimited-[]𝑑𝑝\\mathcal{A}\\subseteq\\binom{[d]}{p} and ℬ⊆([d]q)ℬbinomialdelimited-[]𝑑𝑞\\mathcal{B}\\subseteq\\binom{[d]}{q}.\nWe use the following standard definitions from communication complexity (see for example ): For integers p,q,d𝑝𝑞𝑑p,q,d the Disjointness matrix 𝙳𝚒𝚜𝚓p,q,dsubscript𝙳𝚒𝚜𝚓𝑝𝑞𝑑\\mathtt{Disj}_{p,q,d} has its rows indexed by ([d]p)binomialdelimited-[]𝑑𝑝\\binom{[d]}{p} and its columns indexed by ([d]q)binomialdelimited-[]𝑑𝑞\\binom{[d]}{q}. For A∈([d]p)𝐴binomialdelimited-[]𝑑𝑝A\\in\\binom{[d]}{p} and B∈([d]q)𝐵binomialdelimited-[]𝑑𝑞B\\in\\binom{[d]}{q} we define A monochromatic rectangle of a matrix M𝑀M is subset X𝑋X of rows and\nsubset Y𝑌Y of the columns such that M​[i,j]=M​[i′,j′]𝑀𝑖𝑗𝑀superscript𝑖′superscript𝑗′M[i,j]=M[i^{\\prime},j^{\\prime}] for every i,i′∈X𝑖superscript𝑖′𝑋i,i^{\\prime}\\in X\nand j,j′∈Y𝑗superscript𝑗′𝑌j,j^{\\prime}\\in Y. A family of monochromatic rectangles\nℳ=(X1,Y1),…,(Xz,Yz)ℳsubscript𝑋1subscript𝑌1…subscript𝑋𝑧subscript𝑌𝑧\\mathcal{M}=(X_{1},Y_{1}),\\ldots,(X_{z},Y_{z}) is called a 111-cover if for every i,j𝑖𝑗i,j\nsuch that M​[i,j]=1𝑀𝑖𝑗1M[i,j]=1, there exists k∈[z]𝑘delimited-[]𝑧k\\in[z], such that i∈Xk𝑖subscript𝑋𝑘i\\in X_{k} and j∈Yk𝑗subscript𝑌𝑘j\\in Y_{k}. A natural goal in the field of communication complexity is to find ‘good’\n111-covers. The natural parameter that quantifies such ‘goodness’ is z𝑧z (intuitively the smaller z𝑧z the\nbetter a 111-cover we have). The parameter z𝑧z is sometimes called the Boolean rank121212The name ‘Boolean rank’ is used because a 111-cover of M𝑀M with z𝑧z rectangles is equivalent to a factorization M=L⋅R𝑀⋅𝐿𝑅M=L\\cdot R over the Boolean semi-ring of rank z𝑧z. and it is known to be equal to\n2𝚗𝚌​(M)superscript2𝚗𝚌𝑀2^{\\mathtt{nc}(M)} where 𝚗𝚌​(M)𝚗𝚌𝑀\\mathtt{nc}(M) is the ‘non-deterministic\ncommunication complexity’ of M𝑀M (see e.g. ). Such 111-covers of the Disjointness matrix can be used in algorithms for the Orthogonal Vectors problem: An orthogonal pair is a 111 in the submatrix of the Disjointness induced by the rows and columns from the families 𝒜𝒜\\mathcal{A} and ℬℬ\\mathcal{B}, and we can search for such a 111 via searching for the associated monochromatic rectangle that covers it (see Lemma 6.5 for a related approach).\nFor the case that p=q𝑝𝑞p=q, it is well known that 𝙳𝚒𝚜𝚓p,q,dsubscript𝙳𝚒𝚜𝚓𝑝𝑞𝑑\\mathtt{Disj}_{p,q,d} admits a\n111-cover with 𝒪​(22​p​p​ln⁡d)𝒪superscript22𝑝𝑝𝑑\\mathcal{O}(2^{2p}p\\ln d) rectangles [36, Claim 1.37].\nWhen applied naïvely, this 111-cover would imply an 𝒪~​((|𝒜|+|ℬ|)​2d/2)~𝒪𝒜ℬsuperscript2𝑑2\\widetilde{\\mathcal{O}}((|\\mathcal{A}|+|\\mathcal{B}|)2^{d/2})\ntime algorithm for the setting of Theorem 1.2 with p=q=d/4𝑝𝑞𝑑4p=q=d/4. In order to get a faster algorithm we introduce the following new parameter of a 111-cover: The sparsity of a 111-cover ℳ=(X1,Y1),…,(Xz,Yz)ℳsubscript𝑋1subscript𝑌1…subscript𝑋𝑧subscript𝑌𝑧\\mathcal{M}=(X_{1},Y_{1}),\\ldots,(X_{z},Y_{z}) of an n×m𝑛𝑚n\\times m matrix is defined as ∑i|Xi|/n+∑i|Yi|/msubscript𝑖subscript𝑋𝑖𝑛subscript𝑖subscript𝑌𝑖𝑚\\sum_{i}|X_{i}|/n+\\sum_{i}|Y_{i}|/m. A 111-cover of sparsity ΨΨ\\Psi of a matrix can be understood as a factorization\nof M=L⋅R𝑀⋅𝐿𝑅M=L\\cdot R over the Boolean semi-ring such that the average number of 111’s in a\nrow L𝐿L plus the average number of 111’s in a column of R𝑅R is at most ΨΨ\\Psi.\nOur notion of sparsity is related to the degree of the data structure called\nn𝑛n-p𝑝p-q𝑞q-separating collection .\nFor a further discussion about sparse factorizations see [33, Section 5.1]) We present the algorithmic usefulness of the notion of the sparsity of 111-cover with the following\nstatement. For any constant integer c𝑐c and integers p,q,d𝑝𝑞𝑑p,q,d\nsuch that c𝑐c divides p,q,d𝑝𝑞𝑑p,q,d, there is an algorithm that takes as an input\na 111-cover ℳℳ\\mathcal{M} of 𝙳𝚒𝚜𝚓p/c,q/c,d/csubscript𝙳𝚒𝚜𝚓𝑝𝑐𝑞𝑐𝑑𝑐\\mathtt{Disj}_{p/c,q/c,d/c} of sparsity\nΨΨ\\Psi and two set families 𝒜⊆([d]p)𝒜binomialdelimited-[]𝑑𝑝\\mathcal{A}\\subseteq\\binom{[d]}{p}, ℬ⊆([d]q)ℬbinomialdelimited-[]𝑑𝑞\\mathcal{B}\\subseteq\\binom{[d]}{q} with the following properties:\nIt outputs a pair A∈𝒜𝐴𝒜A\\in\\mathcal{A} and B∈ℬ𝐵ℬB\\in\\mathcal{B} such\nthat A∩B=∅𝐴𝐵A\\cap B=\\emptyset with constant non-zero probability if such a\npair exists. Moreover, it uses 𝒪~​((|𝒜|+|ℬ|)​Ψc+22​d/c)~𝒪𝒜ℬsuperscriptΨ𝑐superscript22𝑑𝑐\\widetilde{\\mathcal{O}}((|\\mathcal{A}|+|\\mathcal{B}|)\\Psi^{c}+2^{2d/c}) time and\n𝒪~​(22​d/c+zc)~𝒪superscript22𝑑𝑐superscript𝑧𝑐\\widetilde{\\mathcal{O}}(2^{2d/c}+z^{c}) space, where z𝑧z is the number of rectangles of ℳℳ\\mathcal{M}. Denote the 111-cover to be ℳ=(X1,Y1),…,(Xz,Yz)ℳsubscript𝑋1subscript𝑌1…subscript𝑋𝑧subscript𝑌𝑧\\mathcal{M}=(X_{1},Y_{1}),\\ldots,(X_{z},Y_{z}).\nObserve, that if A∩B=∅𝐴𝐵A\\cap B=\\emptyset then it suffices to find ℓ∈[z]ℓdelimited-[]𝑧\\ell\\in[z] such that A∈Xℓ𝐴subscript𝑋ℓA\\in X_{\\ell} and B∈Yℓ𝐵subscript𝑌ℓB\\in Y_{\\ell} since ℳℳ\\mathcal{M} forms a\n111-cover. In the bird’s eye view, the algorithm will find such an ℓℓ\\ell.\nWe need to make sure that the space usage of our algorithm is low. We\nwill use parameter c𝑐c to achieve that (it is instructive for a reader to\nassume c=1𝑐1c=1). Algorithm 4 presents an\noverview of the proof. First, randomly partition [d]delimited-[]𝑑[d] into blocks U1,…,Ucsubscript𝑈1…subscript𝑈𝑐U_{1},\\ldots,U_{c} with |Ud|=d/csubscript𝑈𝑑𝑑𝑐|U_{d}|=d/c.\nBy Lemma 3.4, if we repeat the algorithm d𝒪​(c)superscript𝑑𝒪𝑐d^{\\mathcal{O}(c)} times with probably\nat least 1/dO​(c)1superscript𝑑𝑂𝑐1/d^{O(c)} this partition is good, i.e., for some orthogonal pair\nA,B𝐴𝐵A,B it holds that |A∩Ui|=p/c𝐴subscript𝑈𝑖𝑝𝑐|A\\cap U_{i}|=p/c and |B∩Ui|=q/c𝐵subscript𝑈𝑖𝑞𝑐|B\\cap U_{i}|=q/c. Next, we map the given factorization X1,…,Xz,Y1,…,Yzsubscript𝑋1…subscript𝑋𝑧subscript𝑌1…subscript𝑌𝑧X_{1},\\ldots,X_{z},Y_{1},\\ldots,Y_{z} of\n𝙳𝚒𝚜𝚓p/c,q/c,d/csubscript𝙳𝚒𝚜𝚓𝑝𝑐𝑞𝑐𝑑𝑐\\mathtt{Disj}_{p/c,q/c,d/c}, to the set Uisubscript𝑈𝑖U_{i} by unifying Uisubscript𝑈𝑖U_{i} with [d]delimited-[]𝑑[d] a uniformly\nrandom permutation. Now we present a processing step of the algorithm. For every i∈[c]𝑖delimited-[]𝑐i\\in[c]\nwe create and store two lists L𝐿L and R𝑅R. The purpose of these lists is\nto give every element in A𝐴A and B𝐵B fast access to corresponding rectangles\nfrom the 111-cover that contain it (i.e., given A𝐴A we need to find all Xisubscript𝑋𝑖X_{i}, such that A∈Xi𝐴subscript𝑋𝑖A\\in X_{i} in 𝒪~​(z)~𝒪𝑧\\widetilde{\\mathcal{O}}(z) time). Specifically, for every i∈[c]𝑖delimited-[]𝑐i\\in[c] construct: And similarly for all i∈[c]𝑖delimited-[]𝑐i\\in[c]: Because (d/cp/c)≤2d/cbinomial𝑑𝑐𝑝𝑐superscript2𝑑𝑐\\binom{d/c}{p/c}\\leq 2^{d/c}\nwe can construct and store all Li​(Q)subscript𝐿𝑖𝑄L_{i}(Q) and Ri​(Q)subscript𝑅𝑖𝑄R_{i}(Q) in\n𝒪~​(22​d/c+2d/c​z)~𝒪superscript22𝑑𝑐superscript2𝑑𝑐𝑧\\widetilde{\\mathcal{O}}(2^{2d/c}+2^{d/c}z) time and space. Additionally, initialize a table T​[i1,…,ic]:=𝙵𝚊𝚕𝚜𝚎assign𝑇subscript𝑖1…subscript𝑖𝑐𝙵𝚊𝚕𝚜𝚎T[i_{1},\\ldots,i_{c}]:=\\mathtt{False} for every\ni1,…,ic∈[c]subscript𝑖1…subscript𝑖𝑐delimited-[]𝑐i_{1},\\ldots,i_{c}\\in[c]. This table will store which sets Xi,Yisubscript𝑋𝑖subscript𝑌𝑖X_{i},Y_{i} have\nbeen seen by elements in 𝒜𝒜\\mathcal{A}.\nObserve that so far we did not look at the\ninput 𝒜𝒜\\mathcal{A} and ℬℬ\\mathcal{B}; we just preprocessed the 111-cover, so\nthe next steps can be computed efficiently. Now iterate over every element A∈𝒜𝐴𝒜A\\in\\mathcal{A} and check if we\ncan afford to process it, i.e., if\n|L1​(A∩U1)|​⋯​|Lc​(A∩Uc)|>(4​c​Ψ)csubscript𝐿1𝐴subscript𝑈1⋯subscript𝐿𝑐𝐴subscript𝑈𝑐superscript4𝑐Ψ𝑐|L_{1}(A\\cap U_{1})|\\cdots|L_{c}(A\\cap U_{c})|>(4c\\Psi)^{c} we simply ignore it\n(later we will prove that for a disjoint pair A𝐴A and B𝐵B this situation\nhappens with low probability). If indeed we can afford it, then we mark it in\ntable T𝑇T: For every (i1,…,ic)∈L1​(A∩U1)×…×Lc​(A∩Uc)subscript𝑖1…subscript𝑖𝑐subscript𝐿1𝐴subscript𝑈1…subscript𝐿𝑐𝐴subscript𝑈𝑐(i_{1},\\ldots,i_{c})\\in L_{1}(A\\cap U_{1})\\times\\ldots\\times L_{c}(A\\cap U_{c}) we mark T​(i1,…,ic)𝑇subscript𝑖1…subscript𝑖𝑐T(i_{1},\\ldots,i_{c}) to be 𝚃𝚛𝚞𝚎𝚃𝚛𝚞𝚎\\mathtt{True}. Clearly\nthis step takes 𝒪~​(|𝒜|​Ψc)~𝒪𝒜superscriptΨ𝑐\\widetilde{\\mathcal{O}}(|\\mathcal{A}|\\Psi^{c}) time. Next, we treat ℬℬ\\mathcal{B} in a similar way: We iterate over every element B∈ℬ𝐵ℬB\\in\\mathcal{B} and check if\n|R1​(B∩U1)|​⋯​|Rc​(B∩Uc)|≤(4​c​Ψ)csubscript𝑅1𝐵subscript𝑈1⋯subscript𝑅𝑐𝐵subscript𝑈𝑐superscript4𝑐Ψ𝑐|R_{1}(B\\cap U_{1})|\\cdots|R_{c}(B\\cap U_{c})|\\leq(4c\\Psi)^{c}. If so, we iterate over every (i1,…,ic)∈R1​(B∩U1)×…×Rc​(B∩Uc)subscript𝑖1…subscript𝑖𝑐subscript𝑅1𝐵subscript𝑈1…subscript𝑅𝑐𝐵subscript𝑈𝑐(i_{1},\\ldots,i_{c})\\in R_{1}(B\\cap U_{1})\\times\\ldots\\times R_{c}(B\\cap U_{c}) and check if T​(i1,…,ic)=𝚃𝚛𝚞𝚎𝑇subscript𝑖1…subscript𝑖𝑐𝚃𝚛𝚞𝚎T(i_{1},\\ldots,i_{c})=\\mathtt{True}. If this\nhappens, then it means there exists A∈𝒜𝐴𝒜A\\in\\mathcal{A} that is\northogonal to the current B𝐵B and we can return 𝚃𝚛𝚞𝚎𝚃𝚛𝚞𝚎\\mathtt{True}. If this never\nhappens, we return 𝙵𝚊𝚕𝚜𝚎𝙵𝚊𝚕𝚜𝚎\\mathtt{False}. Clearly, the total running time of the algorithm is\n𝒪~​((|𝒜|+|ℬ|)​Ψc)~𝒪𝒜ℬsuperscriptΨ𝑐\\widetilde{\\mathcal{O}}\\left((|\\mathcal{A}|+|\\mathcal{B}|)\\Psi^{c}\\right) and extra amount of working memory is\n𝒪~​(22​d/c+zc)~𝒪superscript22𝑑𝑐superscript𝑧𝑐\\widetilde{\\mathcal{O}}(2^{2d/c}+z^{c}). Hence we focus on correctness. Note that if 𝚃𝚛𝚞𝚎𝚃𝚛𝚞𝚎\\mathtt{True} is returned, indeed there must exist\ndisjoint A∈𝒜𝐴𝒜A\\in\\mathcal{A} and B∈ℬ𝐵ℬB\\in\\mathcal{B} because ℳℳ\\mathcal{M} is 111-cover.\nFor the other direction, suppose that there exist orthogonal A∈𝒜𝐴𝒜A\\in\\mathcal{A} and B∈ℬ𝐵ℬB\\in\\mathcal{B}.\nAs mentioned this implies by Lemma 3.4 that with 1/dc1superscript𝑑𝑐1/d^{c} we have that for each i𝑖i it holds that |A∩Ui|=p/c𝐴subscript𝑈𝑖𝑝𝑐|A\\cap U_{i}|=p/c and |B∩Ui|=p/c𝐵subscript𝑈𝑖𝑝𝑐|B\\cap U_{i}|=p/c. Because we unified [d]delimited-[]𝑑[d] with Uisubscript𝑈𝑖U_{i} with a random permutation,\n𝔼​[|Li​(A∩Ui)|],𝔼​[|Ri​(A∩Ui)|]=Ψ𝔼delimited-[]subscript𝐿𝑖𝐴subscript𝑈𝑖𝔼delimited-[]subscript𝑅𝑖𝐴subscript𝑈𝑖Ψ\\mathbb{E}[|L_{i}(A\\cap U_{i})|],\\mathbb{E}[|R_{i}(A\\cap U_{i})|]=\\Psi, and\nby Markov’s inequality and a union bound there will be no i𝑖i with |Li​(A∩Ui)|+|Ri​(B∩Ui)|≥4​c​Ψsubscript𝐿𝑖𝐴subscript𝑈𝑖subscript𝑅𝑖𝐵subscript𝑈𝑖4𝑐Ψ|L_{i}(A\\cap U_{i})|+|R_{i}(B\\cap U_{i})|\\geq 4c\\Psi, and therefore |L1​(A∩U1)|​⋯​|Lc​(A∩Uc)|≤(4​c​Ψ)csubscript𝐿1𝐴subscript𝑈1⋯subscript𝐿𝑐𝐴subscript𝑈𝑐superscript4𝑐Ψ𝑐|L_{1}(A\\cap U_{1})|\\cdots|L_{c}(A\\cap U_{c})|\\leq(4c\\Psi)^{c} and |R1​(B∩U1)|​⋯​|Rc​(B∩Uc)|≤(4​c​Ψ)csubscript𝑅1𝐵subscript𝑈1⋯subscript𝑅𝑐𝐵subscript𝑈𝑐superscript4𝑐Ψ𝑐|R_{1}(B\\cap U_{1})|\\cdots|R_{c}(B\\cap U_{c})|\\leq(4c\\Psi)^{c}. If this happens,\nthe orthogonal pair will be detected since (X1,Y1),…,(Xz,Yz)subscript𝑋1subscript𝑌1…subscript𝑋𝑧subscript𝑌𝑧(X_{1},Y_{1}),\\ldots,(X_{z},Y_{z}) is a\n111-cover.\n∎ Let p,q𝑝𝑞p,q and d𝑑d be integers such that p≤q𝑝𝑞p\\leq q and p+q≤d/2𝑝𝑞𝑑2p+q\\leq d/2. There is a randomized\nalgorithm that in 𝒪​(2d)𝒪superscript2𝑑\\mathcal{O}(2^{d}) time and space, constructs X1,…,Xz⊆([d]p)subscript𝑋1…subscript𝑋𝑧binomialdelimited-[]𝑑𝑝X_{1},\\ldots,X_{z}\\subseteq\\binom{[d]}{p} and Y1,…,Yz⊆([d]p)subscript𝑌1…subscript𝑌𝑧binomialdelimited-[]𝑑𝑝Y_{1},\\ldots,Y_{z}\\subseteq\\binom{[d]}{p},\nwhere z𝑧z is at most 2dsuperscript2𝑑2^{d}. All pairs of sets (X1,Y1),…,(Xz,Yz)subscript𝑋1subscript𝑌1…subscript𝑋𝑧subscript𝑌𝑧(X_{1},Y_{1}),\\ldots,(X_{z},Y_{z}) form monochromatic rectangles in 𝙳𝚒𝚜𝚓p,q,dsubscript𝙳𝚒𝚜𝚓𝑝𝑞𝑑\\mathtt{Disj}_{p,q,d}\nand with probability at least 3/4343/4, it holds that (X1,Y1)​…,(Xz,Yz)subscript𝑋1subscript𝑌1…subscript𝑋𝑧subscript𝑌𝑧(X_{1},Y_{1})\\ldots,(X_{z},Y_{z}) is a 111-cover of 𝙳𝚒𝚜𝚓p,q,dsubscript𝙳𝚒𝚜𝚓𝑝𝑞𝑑\\mathtt{Disj}_{p,q,d} with sparsity Let l=p+q𝑙𝑝𝑞l=p+q and let A∈𝒜,B∈ℬformulae-sequence𝐴𝒜𝐵ℬA\\in\\mathcal{A},B\\in\\mathcal{B} be an orthogonal\npair. Let x𝑥x be some parameter that we will determine later (think about x≈d/2𝑥𝑑2x\\approx d/2). Note that Let 𝒮:={S1,…,Sz}⊆([d]x)assign𝒮subscript𝑆1…subscript𝑆𝑧binomialdelimited-[]𝑑𝑥\\mathcal{S}:=\\{S_{1},\\ldots,S_{z}\\}\\subseteq\\binom{[d]}{x} be obtained by\nincluding each set from ([d]x)binomialdelimited-[]𝑑𝑥\\binom{[d]}{x} with probability\n2​d​(d−lx−p)−12𝑑superscriptbinomial𝑑𝑙𝑥𝑝12d\\binom{d-l}{x-p}^{-1} (assuming x>p+Ω​(1)𝑥𝑝Ω1x>p+\\Omega(1), this probability is indeed in the interval   [ref]1). Thus, if A𝐴A and B𝐵B are disjoint sets, with good\nprobability there is a certificate set S∈𝒮𝑆𝒮S\\in\\mathcal{S}, such that A⊆S𝐴𝑆A\\subseteq S and S∩B=∅𝑆𝐵S\\cap B=\\emptyset. More formally: (where the last inequality is due to the standard inequality 1+α≤exp⁡(α)1𝛼𝛼1+\\alpha\\leq\\exp(\\alpha)).\nNow we define a 111-cover based on the family 𝒮𝒮\\mathcal{S}: First let us prove that with good probability X1,Y1​…,Xz,Yzsubscript𝑋1subscript𝑌1…subscript𝑋𝑧subscript𝑌𝑧X_{1},Y_{1}\\ldots,X_{z},Y_{z} is\n111-cover. There are at most 3dsuperscript3𝑑3^{d} disjoint pairs A,B𝐴𝐵A,B. Hence by\nEquation 15 and the union bound on all disjoint pairs A,B𝐴𝐵A,B, we have that\n(X1,Y1),…,(Xz,Yz)subscript𝑋1subscript𝑌1…subscript𝑋𝑧subscript𝑌𝑧(X_{1},Y_{1}),\\ldots,(X_{z},Y_{z}) is a 111-cover with probability at least\n3/4343/4. Next, we bound the sparsity of (X1,Y1),…,(Xz,Yz)subscript𝑋1subscript𝑌1…subscript𝑋𝑧subscript𝑌𝑧(X_{1},Y_{1}),\\ldots,(X_{z},Y_{z}). By Markov’s\ninequality, z≤4​d​(dx)​(d−lx−p)−1𝑧4𝑑binomial𝑑𝑥superscriptbinomial𝑑𝑙𝑥𝑝1z\\leq 4d\\binom{d}{x}\\binom{d-l}{x-p}^{-1} with probability\nat least 1/2121/2. Hence with probability at least 1/2121/2 our 111-cover\nhas sparsity at most: where the second equality follows from using (ab+c)​(b+cc)=(ab,c)=(ac)​(a−cb)binomial𝑎𝑏𝑐binomial𝑏𝑐𝑐binomial𝑎𝑏𝑐binomial𝑎𝑐binomial𝑎𝑐𝑏\\binom{a}{b+c}\\binom{b+c}{c}=\\binom{a}{b,c}=\\binom{a}{c}\\binom{a-c}{b} twice. Next, we use Lemma B.1 (see\nAppendix B) with: d=n𝑑𝑛d=n, p=σ​λ​n𝑝𝜎𝜆𝑛p=\\sigma\\lambda n,\nq=(1−σ)​λ​n𝑞1𝜎𝜆𝑛q=(1-\\sigma)\\lambda n and p+q=λ​n𝑝𝑞𝜆𝑛p+q=\\lambda n. Note that we assumed that σ∈[0.4,0.6]𝜎0.40.6\\sigma\\in[0.4,0.6] and λ∈[0.4,0.5]𝜆0.40.5\\lambda\\in[0.4,0.5] hence conditions for\nLemma B.1 are satisfied. We obtain that for the choice\nof x:=d​(1/2+(σ−1/2)​(log2⁡(3)/2)+(1/2−σ)​(1/2−λ))assign𝑥𝑑12𝜎12subscript23212𝜎12𝜆x:=d(1/2+(\\sigma-1/2)(\\log_{2}(3)/2)+(1/2-\\sigma)(1/2-\\lambda))\nexpression (16) is bounded from above with as required.\n∎ Now the main statement of this section follows by a straightforward combination of the previous lemmas: Let p:=σ​λ​dassign𝑝𝜎𝜆𝑑p:=\\sigma\\lambda d and q:=(1−σ)​λ​dassign𝑞1𝜎𝜆𝑑q:=(1-\\sigma)\\lambda d. Set c=20𝑐20c=20 and assume that integers p,q,d𝑝𝑞𝑑p,q,d are multiples of c𝑐c (by padding the\ninstance if needed). Next, use Lemma 6.6 with d/c𝑑𝑐d/c, p/c𝑝𝑐p/c and q/c𝑞𝑐q/c to\nconstruct a 111-cover ℳℳ\\mathcal{M} of sparsity with good probability. Subsequently, apply Lemma 6.5 with this\n111-cover ℳℳ\\mathcal{M} to detect a disjoint pair A∈𝒜𝐴𝒜A\\in\\mathcal{A} and B∈ℬ𝐵ℬB\\in\\mathcal{B} with\nconstant probability. Note that the runtime is: Hence, the running time is 𝒪~​((|𝒜|+|ℬ|)​2d​(1/2+λ−h​(λ/2)))~𝒪𝒜ℬsuperscript2𝑑12𝜆ℎ𝜆2\\widetilde{\\mathcal{O}}\\left(\\left(|\\mathcal{A}|+|\\mathcal{B}|\\right)2^{d(1/2+\\lambda-h(\\lambda/2))}\\right). The main bottleneck in the space usage comes from the zcsuperscript𝑧𝑐z^{c} factor in Lemma 6.5 which gives the 2dsuperscript2𝑑2^{d} factor.\n∎\n\nReference markers found: [14]\n\nContext windows for each [ref]:\n[ref]14: discuss our algorithm for Orthogonal Vectors.\nAs discussed in the introduction it should be noted that the proof strategy is\nsimilar to the one from  (which is heavily inspired on\nBollobás’s Theorem [ref]14), but we obtain improvements\nthat are crucial for the main result of this paper. We compare our methods with\nexisting literature at the end of this section. For any\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 14,\n            \"titles\": [\n                \"A Near-Linear Pseudopolynomial Time Algorithm for Subset Sum\",\n                \"personal communication\",\n                \"SETH-Based Lower Bounds for Subset Sum and Bicriteria Path\",\n                \"Space-Time Tradeoffs for Subset Sum: An Improved Worst Case Algorithm\",\n                \"Subset Sum in the Absence of Concentration\",\n                \"Dense Subset Sum may be the hardest\",\n                \"Exact Weight Subgraphs and the k-Sum Conjecture\",\n                \"More Applications of the Polynomial Method to Algorithm Design\",\n                \"Color-coding\",\n                \"Improved Generic Algorithms for Hard Knapsacks\",\n                \"Faster Space-Efficient Algorithms for Subset Sum, k-Sum, and Related Problems\",\n                \"Set Partitioning via Inclusion-Exclusion\",\n                \"Counting Paths and Packings in Halves\",\n                \"Determinant Sums for Undirected Hamiltonicity\",\n                \"On generalized graphs\",\n                \"On Problems as Hard as CNF-SAT\",\n                \"Deterministic APSP, Orthogonal Vectors, and More: Quickly Derandomizing Razborov-Smolensky\",\n                \"An Equivalence Class for Orthogonal Vectors\",\n                \"Efficient Dissection of Composite Problems, with Applications to Cryptanalysis, Knapsacks, and Combinatorial Search Problems\",\n                \"Efficient Computation of Representative Families with Applications in Parameterized and Exact Algorithms\",\n                \"Completeness for First-order Properties on Sparse Structures with Algorithmic Applications\",\n                \"New Generic Algorithms for Hard Knapsacks\",\n                \"Computing Partitions with Applications to the Knapsack Problem\",\n                \"A Simple Near-Linear Pseudopolynomial Time Randomized Algorithm for Subset Sum\",\n                \"A Faster Pseudopolynomial Time Algorithm for Subset Sum\",\n                \"Subset Sum Made Simple\",\n                \"Lower bounds based on the exponential time hypothesis\",\n                \"Saving Space by Algebraization\",\n                \"Equal-Subset-Sum Faster Than the Meet-in-the-Middle\",\n                \"The Complexity of Determining Paths of Length k\",\n                \"Finding Large Set Covers Faster via the Representation Method\",\n                \"Algorithms for NP-hard problems via Rank-related Parameters of Matrices\",\n                \"A Faster Exponential Time Algorithm for Bin Packing With a Constant Number of Bins via Additive Combinatorics\",\n                \"Reducing a Target Interval to a Few Exact Queries\",\n                \"Communication Complexity: and Applications\",\n                \"A T=O​(2n/2)𝑂superscript2𝑛2O(2^{n/2}), S=O​(2n/4)𝑂superscript2𝑛4O(2^{n/4}) Algorithm for Certain NP-Complete Problems\",\n                \"On Some Fine-Grained Questions in Algorithms and Complexity\",\n                \"A new algorithm for optimal 2-constraint satisfaction and its implications\",\n                \"Generated Reference Title 38 for [ref]14\",\n                \"Generated Reference Title 39 for [ref]14\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]14 based on the context and research area of Improving Schroeppel and Shamir’s Algorithm for Subset Sum via Orthogonal Vectors. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}