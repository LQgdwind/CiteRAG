{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Efficient Computation Using Spatial-Photonic Ising Machines: Utilizing Low-Rank and Circulant Matrix Constraints\n\nPaper Abstract: \n\nPaper Section Text:\nThe authors of [ref]25 proposed a mapping from the knapsack problem with integer weights to an Ising problem with a coupling matrix \\matr​J\\matr𝐽\\matr{J} that can be represented by Eq. (4) with rank⁡(\\matr​J)=2rank\\matr𝐽2\\operatorname{rank}(\\matr{J})=2, which does not grow with the size of the problem.\nThe problem is defined as follows:\nGiven a set of items, each having value visubscript𝑣𝑖v_{i} and integer weight wi>0subscript𝑤𝑖0w_{i}>0, we would like to find a subset of the items that maximize the total value of items in the subset while satisfying a constraint where the total weight of items in the subset is not greater than a given limit W𝑊W.\nThe optimization version of the knapsack problem with integer weights is known to be NP-hard [ref]26. Hence, it was argued that the linear combination method can efficiently implement the Ising formulation of NP-hard problems on SPIM. Following a similar mapping strategy, we note that it is possible to use a single rank-1 Mattis-type matrix to represent the NP-complete number partitioning problem (NPP), which can be stated as follows: given a set of N𝑁N positive numbers, is there a partition of this set of numbers into two disjoint sets such that the sums of elements in each subset are equal? This can be easily mapped to the minimization problem of the Ising Hamiltonian HNPP​(\\vect​s)=(∑iNni​si)2subscript𝐻NPP\\vect𝑠superscriptsuperscriptsubscript𝑖𝑁subscript𝑛𝑖subscript𝑠𝑖2H_{\\rm NPP}(\\vect{s})=\\left(\\sum_{i}^{N}n_{i}s_{i}\\right)^{2}, where nisubscript𝑛𝑖n_{i} are numbers given in the set, and si∈{−1,+1}subscript𝑠𝑖11s_{i}\\in\\{-1,+1\\} are Ising spins, which denote which subset nisubscript𝑛𝑖n_{i} is assigned to. This Ising Hamiltonian has a coupling matrix Ji​j=−ni​njsubscript𝐽𝑖𝑗subscript𝑛𝑖subscript𝑛𝑗J_{ij}=-n_{i}n_{j}, which is of the Mattis-type, so one would expect that SPIM can readily implement any number partitioning problem without using any special rank-increasing methods mentioned in the introduction. However, these two examples do not demonstrate that SPIM can efficiently implement computationally intractable NP-hard problems. For a number partitioning problem with N𝑁N integers in the range [1,S]1𝑆[1,S], there exists an algorithm that solves the problem in time scaling like 𝒪​(N​S)𝒪𝑁𝑆\\mathcal{O}(NS) [ref]35. This is known as a pseudo-polynomial time algorithm because if we consider the number of binary digits L𝐿L required to represent the largest integer S𝑆S in the problem, then it is given by L=⌈log2⁡S⌉𝐿subscript2𝑆L=\\lceil\\log_{2}{S}\\rceil. The algorithm has running time scaling like 𝒪​(N​2L)𝒪𝑁superscript2𝐿\\mathcal{O}(N2^{L}), which still grows exponentially as L𝐿L increases. Problems with such pseudo-polynomial time algorithms belong to the weakly NP-complete class, for which increasing problem size alone (in terms of N𝑁N for the number partitioning problem) is insufficient to make it computationally hard. These problems are only computationally intractable (i.e., having only an algorithm whose run time grows exponentially) if the number of digits used to represent the maximum input L𝐿L grows. If the number of digits representing the maximum input is allowed to grow, in both of the above mappings to the Ising Hamiltonian, the number of digits in the coupling matrix elements Ji​jsubscript𝐽𝑖𝑗J_{ij} will also have to grow. Hence, to simulate a weakly NP-complete problem whose solution requires exponentially growing resources on a classical computer, the precision of SPIM optical hardware will need to grow to encode larger integers represented by more binary digits L𝐿L involved in these problems. This is unlikely to be realized in experiments because the precision with which coupling matrices can be implemented in SPIM is a fixed number of significant digits, likely much smaller than problem input sizes of practical interest. Given that NPP with limited binary precision is not NP-hard, studying the statistical properties of random NPP instances is still interesting because it may inform potential modifications or constraints to the problem that can increase its complexity. Historically, NPP was analyzed in , with subsequent extensive rigorous study in . It was found that the average hardness of a randomly generated NPP instance, where N𝑁N integers are uniformly randomly selected from the range [1,2L]1superscript2𝐿[1,2^{L}], is controlled by a parameter κ=LN𝜅𝐿𝑁\\kappa=\\frac{L}{N}. When κ>κc𝜅subscript𝜅𝑐\\kappa>\\kappa_{c}, they require 𝒪​(2N)𝒪superscript2𝑁\\mathcal{O}(2^{N}) operations to solve, but when κ<κc𝜅subscript𝜅𝑐\\kappa<\\kappa_{c}, average problem instances require 𝒪​(N)𝒪𝑁\\mathcal{O}(N) operations to solve. We demonstrate a short basic derivation of the critical parameter κc=1subscript𝜅𝑐1\\kappa_{c}=1 in the limit of N→∞→𝑁N\\rightarrow\\infty below, which is the only parameter responsible for characterizing the phase of the problem, whether it is a “hard” phase (κ>κc𝜅subscript𝜅𝑐\\kappa>\\kappa_{c}) or “easy” phase (κ<κc𝜅subscript𝜅𝑐\\kappa<\\kappa_{c}). One can introduce the signed discrepancy D𝐷D of the numbers, given the binary variables sisubscript𝑠𝑖s_{i}  as D𝐷D can be interpreted as the final distance to the origin of a random walker in one dimension who takes steps to the left (si=−1)subscript𝑠𝑖1\\left(s_{i}=-1\\right) or to the right (si=+1)subscript𝑠𝑖1\\left(s_{i}=+1\\right) with random stepsizes (ni)subscript𝑛𝑖\\left(n_{i}\\right). One can calculate the average number of walks that ends at D𝐷D as where ⟨⋅⟩delimited-⟨⟩⋅\\langle\\cdot\\rangle denotes averaging over the random numbers n𝑛n and δ𝛿\\delta is the Kronecker-delta function.\nFor fixed {si}subscript𝑠𝑖\\left\\{s_{i}\\right\\} and large N𝑁N, the distribution of D𝐷D can be treated as Gaussian with mean and variance Hence, to the leading order in L𝐿L, one can express the probability of the walk ending at a distance D𝐷D as To derive the explicit expression for the average number of walks that ends at a distance D𝐷D from the origin, Ω​(D)Ω𝐷\\Omega(D), we must consider that our random walk takes place on a 1-D lattice with lattice spacing 222. In this setup, the walker’s movements are restricted to even or odd numbers, depending on whether the sum ∑njsubscript𝑛𝑗\\sum n_{j} is even or odd. As a result, we obtain One can get with the final expression This value, denoted as κcsubscript𝜅𝑐\\kappa_{c}, is crucial for indicating the phase transition.\nWhen κ<κc𝜅subscript𝜅𝑐\\kappa<\\kappa_{c}, on average, there exists an exponential number of perfect partitions where the discrepancy D=0𝐷0D=0; however, when κ>κc𝜅subscript𝜅𝑐\\kappa>\\kappa_{c}, none exists. Another essential aspect of such a simple random walk model is the possibility of tracing the effects of finite size. For instance, even with a relatively small system size of around N≈17𝑁17N\\approx 17 units, the critical value of κc≈0.9subscript𝜅𝑐0.9\\kappa_{c}\\approx 0.9 is due to the finite-size scaling window of the transition. These effects become more pronounced in hardware systems that operate with limited variables. This statistical analysis aligns with our previous discussion, which suggested that to generate computationally hard NPP instances, the number of integers N𝑁N and binary digits L𝐿L must increase, which can be challenging in practice. Nevertheless, despite its limitations, NPP is a suitable platform for integrating additional modifications or constraints, making it adaptable for deployment on hardware with limited physical resources. The multiprocessor scheduling problem  stands out among the conventional NPP modifications. It involves distributing the workload across parallel computers to minimize overall runtime. The transition can be detailed by mapping it onto a mean-field anti-ferromagnetic Potts model. In the multiprocessor scheduling problem, we are given q𝑞q identical processors and N𝑁N independent tasks with running times aisubscript𝑎𝑖a_{i} (instead of numbers nisubscript𝑛𝑖n_{i}). The objective is to create a schedule to assign the N𝑁N tasks to the q𝑞q processors to minimize the longest task finishing time where s​(i)𝑠𝑖s(i) denotes which processor task i𝑖i is assigned to, and Aαsubscript𝐴𝛼A_{\\alpha} represents the total workload of processor α𝛼\\alpha. The critical factor is whether two tasks are on the same processor. It is convenient to encode the schedules using Potts vectors  since this reflects the symmetry of the problem.\nIt was shown that this results in a different critical value for the easy-hard phase transition (that is less than 111 for q>1𝑞1q>1): Such a shift is beneficial in our context because one requires smaller precision to achieve the same complexity on the hardware. A more straightforward approach is to consider the so-called constrained number partitioning problem (CNP), which will be discussed in more detail in Section V. It is a variation of the original NPP where, apart from splitting integers into groups with equal sums, we also aim to meet an additional requirement known as a cardinality constraint. This constraint ensures that the difference between the numbers of integers in one group and another equals a specific value. The NPP is a good platform for various modifications, even though it is unsuitable for implementation on SPIM in its original form. Modifications can increase complexity within constrained resources and even combine them. For example, one could tackle the multiprocessor scheduling problem while adhering to cardinality constraints. This versatility allows for fine-tuning parameters to obtain tasks with specific complexity.\n\nReference markers found: [25]\n\nContext windows for each [ref]:\n[ref]25: The authors of [ref]25 proposed a mapping from the knapsack problem with integer weights to an Ising problem with a coupling matrix \\matr​J\\matr𝐽\\matr{J} that can be represented by Eq. (4) with\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 25,\n            \"titles\": [\n                \"인공지능 기반 공격 그래프 생성\",\n                \"Bayesian Optimization in Materials Science: A Survey\",\n                \"Applications of Combinatorial Optimization, 2nd Edition Paschos, Vangelis.\",\n                \"From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference\",\n                \"Computational power consumption and speedup\",\n                \"Computers and Intractability; A Guide to the Theory of NP-Completeness\",\n                \"The easiest hard problem: Number partitioning\",\n                \"Foundations of Data Science\",\n                \"Numerical Methods and Optimization in Finance\",\n                \"Inside the Black Box: A Simple Guide to Quantitative and High Frequency Trading\",\n                \"Phase diagram for the constrained integer partitioning problem\",\n                \"A complete anytime algorithm for balanced number partitioning\",\n                \"Spin Glasses and Complexity\",\n                \"Generated Reference Title 13 for [ref]25\",\n                \"Generated Reference Title 14 for [ref]25\",\n                \"Generated Reference Title 15 for [ref]25\",\n                \"Generated Reference Title 16 for [ref]25\",\n                \"Generated Reference Title 17 for [ref]25\",\n                \"Generated Reference Title 18 for [ref]25\",\n                \"Generated Reference Title 19 for [ref]25\",\n                \"Generated Reference Title 20 for [ref]25\",\n                \"Generated Reference Title 21 for [ref]25\",\n                \"Generated Reference Title 22 for [ref]25\",\n                \"Generated Reference Title 23 for [ref]25\",\n                \"Generated Reference Title 24 for [ref]25\",\n                \"Generated Reference Title 25 for [ref]25\",\n                \"Generated Reference Title 26 for [ref]25\",\n                \"Generated Reference Title 27 for [ref]25\",\n                \"Generated Reference Title 28 for [ref]25\",\n                \"Generated Reference Title 29 for [ref]25\",\n                \"Generated Reference Title 30 for [ref]25\",\n                \"Generated Reference Title 31 for [ref]25\",\n                \"Generated Reference Title 32 for [ref]25\",\n                \"Generated Reference Title 33 for [ref]25\",\n                \"Generated Reference Title 34 for [ref]25\",\n                \"Generated Reference Title 35 for [ref]25\",\n                \"Generated Reference Title 36 for [ref]25\",\n                \"Generated Reference Title 37 for [ref]25\",\n                \"Generated Reference Title 38 for [ref]25\",\n                \"Generated Reference Title 39 for [ref]25\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]25 based on the context and research area of Efficient Computation Using Spatial-Photonic Ising Machines: Utilizing Low-Rank and Circulant Matrix Constraints. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}