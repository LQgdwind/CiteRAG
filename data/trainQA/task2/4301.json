{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: ğ¿â‚‚BN: Enhancing Batch Normalization by Equalizing the ğ¿â‚‚ Norms of Features\n\nPaper Abstract: \n\nPaper Section Text:\nExperimental Settings.\nWe verify the advantages of L2subscriptğ¿2L_{2}BN over BN by conducting image classification experiments using convolutional networks.\nWe experiment on the CIFAR100 datasetÂ  and the ImageNet-1K datasetÂ .\nOn CIFAR100, we employ various classic networks as the backbone models,\nincluding ResNet-20\\\\\\backslash32\\\\\\backslash44\\\\\\backslash56\\\\\\backslash110Â ,\nDenseNetÂ [ref]13 with 40 layers and a growth rate of 12 denoted by DenseNet-40-12,\nDenseNet-BCÂ [ref]13 with 100 layers and a growth rate of 12 denoted by DenseNet-BC-100-12,\nVGG-19Â [ref]39 with BN,\nand RegNet-YÂ .\nOn ImageNet-1K, we evaluate our method with ResNet-50, ResNet-101, ResNeXt-50Â (32Ã—4â€‹d324ğ‘‘32\\times 4d), and ResNeXt-101Â (32Ã—4â€‹d324ğ‘‘32\\times 4d). For CIFAR100, we report the mean and standard deviation of the best accuracy over 5 runs with random seeds ranging from 121 to 125, reducing the impacts of random variations.\nFor ImageNet-1K, we fix the random seed to 1.\nFor a fair comparison, not only the L2subscriptğ¿2L_{2}BN models but also their BN counterparts are trained from scratch, so our results may be slightly different from the ones presented in the original papers due to different random seeds, software, and hardware settings.\nOther training settings and hyper-parameters are detailed in the supplementary materials. Main Results and Analysis.\nTableÂ 1 and TableÂ 2 show the comparison results of the models and their L2subscriptğ¿2L_{2}BN versions on CIFAR100 and ImageNet-1K, respectively. In terms of accuracy, the L2subscriptğ¿2L_{2}BN can improve all the backbone models to varying degrees, regardless of the CIFAR100 or the ImageNet-1K dataset.\nFor example, the L2subscriptğ¿2L_{2}BN can boost the accuracy of ResNet-56 by about 1% on CIFAR100 and ResNet-50 by about 0.6% on ImageNet-1K.\nIt is worth emphasizing that the L2subscriptğ¿2L_{2}BN achieves the improvements without any additional parameters or hyper-parameters.\nDue to the pre-attached l2subscriptğ‘™2l_{2} normalization, the accuracy improvement benefits from the elimination of the difference in l2subscriptğ‘™2l_{2} norms of sample features.\nTo intuitively illustrate the effectiveness of L2subscriptğ¿2L_{2}BN, we plot the training curves of ResNet-56 on CIFAR100 and ResNet-50 on ImageNet-1K in FigureÂ 6.\nThe L2subscriptğ¿2L_{2}BN can get persistently higher classification accuracy and slightly smaller training loss than the BN baseline. In SectionÂ 3.2, we analyze that the improvement in accuracy is due to the ability of L2subscriptğ¿2L_{2}BN to enhance intra-class compactness and inter-class discrepancy.\nIn this part, we demonstrate this claim through extensive experiments.\nTo measure the intra-class compactness and inter-class discrepancy quantitatively, we adopt the measures used in ArcFaceÂ .\nThe intra-class compactness is measured by the mean of angles across features with respect to their respective class feature centers, denoted as intra-angle.\nThe inter-class discrepancy is measured by the mean of minimum angles between each class feature center and the other class feature centers, denoted as inter-angle.\nTo be more clear, we give the formulations of intra-angle and inter-angle: where ğ±iâ€‹jâˆˆR1Ã—dsubscriptğ±ğ‘–ğ‘—superscriptğ‘…1ğ‘‘\\mathbf{x}_{ij}\\in R^{1\\times d} denotes the jğ‘—j-th sample feature vector of the iğ‘–i-th class,\nNisubscriptğ‘ğ‘–N_{i} denotes the number of samples belonging to the iğ‘–i-th class,\nğœiâˆˆR1Ã—dsubscriptğœğ‘–superscriptğ‘…1ğ‘‘\\mathbf{c}_{i}\\in R^{1\\times d} denotes the feature center vector of the iğ‘–i-th class, and Cğ¶C denotes the number of classes. We calculate the intra-angle of training data, the intra-angle of test data, and the inter-angle.\nThe inter-angle refers to the one of training data, and we donâ€™t calculate the inter-angle of test data.\nWe argue that the inter-angle of test data is meaningless because the image classification is a closed-set task.\nFor the same reason, we use the class feature centers computed on the training set for the calculation of intra-angle, whether the intra-angle is of training data or test data.\nNote that the intra-angle and inter-angle are only meaningful for the classification layer.\nThe results in TableÂ 1 show that the intra-angle is reduced after using the L2subscriptğ¿2L_{2}BN either on training data or on test data, for most of the models except the DenseNet.\nBut for all models, the inter-angle gets enlarged.\nThis demonstrates that the L2subscriptğ¿2L_{2}BN can make the intra-class features more compact and the inter-class features more separable.\nTherefore, the L2subscriptğ¿2L_{2}BN can enhance the discriminative ability of neural networks, which is the reason for the accuracy improvement. Given the relative relationship between intra-class compactness and inter-class discrepancy, using either intra-angle or inter-angle alone is not sufficient to evaluate the discriminability of a model.\nFor that reason, we define the Intra-angle and Inter-angle Ratio, abbreviated as Iâ€‹Iâ€‹Rğ¼ğ¼ğ‘…IIR, as follows: The Iâ€‹Iâ€‹Rğ¼ğ¼ğ‘…IIR is a unified metric to evaluate the intra-class compactness and the inter-class discrepancy, the smaller the better.\nWe use the unified Iâ€‹Iâ€‹Rğ¼ğ¼ğ‘…IIR to verify the effect of L2subscriptğ¿2L_{2}BN.\nFor all the backbones, the L2subscriptğ¿2L_{2}BN can always achieve significantly smaller Iâ€‹Iâ€‹Rğ¼ğ¼ğ‘…IIR on both training data and test data, as shown in TableÂ 1.\nTo be more rigorous, we compare the Iâ€‹Iâ€‹Rğ¼ğ¼ğ‘…IIR of BN and L2subscriptğ¿2L_{2}BN throughout the training process in FigureÂ 7.\nWe can see that the L2subscriptğ¿2L_{2}BN can continuously get smaller Iâ€‹Iâ€‹Rğ¼ğ¼ğ‘…IIR, demonstrating the advantages of L2subscriptğ¿2L_{2}BN. It is worth mentioning that the types of backbones used here are diverse, including models with skip connection like ResNetÂ  and DenseNetÂ [ref]13, models without skip connection like VGGÂ [ref]39, and models searched by Neural Architecture Search like RegNetÂ .\nThis indicates that, as a simple plug-and-play module, the L2subscriptğ¿2L_{2}BN is shown to be\narchitecture-agnostic and produce persistent performance improvement.\nTherefore, the key advantage of L2subscriptğ¿2L_{2}BN highlighted in this paper is not the significance but\nthe robustness and generalizability. Choice of Feature Normalization.\nIn the Method SectionÂ 3, we employ the l2subscriptğ‘™2l_{2} normalization on the whole feature map of each sample by default.\nTo justify our choice, we also evaluate in TableÂ 3 other possible alternatives to l2subscriptğ‘™2l_{2} normalization such as Layer NormalizationÂ [ref]2, Instance NormalizationÂ , and Position NormalizationÂ , denoted by LNBN, INBN, and PNBN, respectively. We observe that the INBN and PNBN get much poorer performance than L2subscriptğ¿2L_{2}BN, in terms of both accuracy and Iâ€‹Iâ€‹Rğ¼ğ¼ğ‘…IIR.\nWe argue that it is the entire feature map that represents the sample feature, whether the Instance Normalization or the Position Normalization destroys the sample-level feature information.\nThe Layer Normalization is also performed on the whole feature map.\nCompared with the l2subscriptğ‘™2l_{2} normalization, the main difference is that Layer Normalization has a centering operation.\nFrom the analysis in FigureÂ 4 and FigureÂ 5, the centering operation is unnecessary for the intra-class compactness and inter-class discrepancy.\nMoreover, the centering operation changes the orientation of feature vector and thus may change what the feature vector can representÂ .\nTo address this, Layer Normalization in the original paperÂ [ref]2 employs a learned affine transformation to adaptively compensate for the possible information loss.\nHowever, the subsequent Batch Normalization makes the learned affine transformation of Layer Normalization ineffective in LNBN.\nTherefore, the information loss caused by Layer Normalization can not be effectively compensated.\nThe l2subscriptğ‘™2l_{2} normalization does not change the orientation of feature vector and therefore does not related to the semantic information lossÂ  .\nThe results in TableÂ 3 also prove that both the accuracy and the Iâ€‹Iâ€‹Rğ¼ğ¼ğ‘…IIR of LNBN are inferior to those of L2subscriptğ¿2L_{2}BN.\nIn summary, compared with these possible alternatives, l2subscriptğ‘™2l_{2} normalization is the best choice. Applying L2subscriptğ¿2L_{2}BN to Different Layers.\nAs described in SectionÂ 3.3, the L2subscriptğ¿2L_{2}BN is applicable to all layers.\nTo confirm this point, we study the effect of L2subscriptğ¿2L_{2}BN applied to different parts of neural networks, as shown in TableÂ 4.\nEven if the L2subscriptğ¿2L_{2}BN is only used for part of the neural network, the accuracy can be improved to varying degrees.\nHowever, the accuracy is enhanced to the greatest extent when applying L2subscriptğ¿2L_{2}BN to all layers.\nThis indicates that the L2subscriptğ¿2L_{2}BN is effective for both\nthe output layer and the hidden layers, and the effects can be\naccumulated. Comparison with Other Normalization Methods.\nThis section compares L2subscriptğ¿2L_{2}BN with several existing variants of Batch Normalization, including Layer Normalization (LN)Â [ref]2, Instance Normalization (IN)Â , Group Normalization (GN)Â , Switchable Normalization (SN)Â , Batch-Channel Normalization (BCN)Â , and Batch-Instance Normalization (BIN)Â .\nFor GN, we test settings with the channel-per-group (cpg) values of 4 and 8.\nFor BCN, we set the number of groups to min{32, (the number of channels)/4}, as in the original paperÂ .\nThe results are shown in TableÂ 5.\nFor LN, IN, and GN, they abandon the batch statistics and thus perform worse than BN in popular training settingsÂ .\nSN, BCN, and BIN can be used to address the problem of poor performance of BN when the mini-batch size is very small.\nHowever, their performance in popular training settings is on par with or worse than BN.\nIn contrast, the L2subscriptğ¿2L_{2}BN can still enhance BN when the mini-batch size is not small.\nOverall, the L2subscriptğ¿2L_{2}BN performs better than these normalization methods without any hyper-parameters.\n\nReference markers found: [13]\n\nContext windows for each [ref]:\n[ref]13: datasetÂ  and the ImageNet-1K datasetÂ .\nOn CIFAR100, we employ various classic networks as the backbone models,\nincluding ResNet-20\\\\\\backslash32\\\\\\backslash44\\\\\\backslash56\\\\\\backslash110Â ,\nDenseNetÂ [ref]13 with 40 layers and a growth rate of 12 denoted by DenseNet-40-12,\nDenseNet-BCÂ [ref]13 with 100 layers and a growth rate of 12 denoted by DenseNet-BC-100-12,\nVGG-19Â [ref]39 with BN,\nand\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 13,\n            \"titles\": [\n                \"Delving into the Estimation Shift of Batch Normalization in a Network\",\n                \"Challenge on detection and classification of acoustic scenes and events\",\n                \"Layer normalization\",\n                \"Batch Normalization Increases Adversarial Vulnerability and Decreases Adversarial Transferability: A Non-Robust Feature Perspective\",\n                \"On the properties of neural machine translation: Encoder-decoder approaches\",\n                \"Recurrent Batch Normalization\",\n                \"ArcFace: Additive Angular Margin Loss for Deep Face Recognition\",\n                \"Momentum Contrast for Unsupervised Visual Representation Learning\",\n                \"Mask R-CNN\",\n                \"Deep Residual Learning for Image Recognition\",\n                \"Long short-term memory\",\n                \"Norm matters: efficient and accurate normalization schemes in deep networks\",\n                \"Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization And Data Augmentation\",\n                \"Densely connected convolutional networks\",\n                \"Arbitrary style transfer in real-time with adaptive instance normalization\",\n                \"Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models\",\n                \"Batch normalization: Accelerating deep network training by reducing internal covariate shift\",\n                \"Serial order: A parallel distributed processing approach\",\n                \"Learning multiple layers of features from tiny images\",\n                \"Positional Normalization\",\n                \"Decoupled networks\",\n                \"Deep Hyperspherical Learning\",\n                \"Differentiable Learning-to-Normalize via Switchable Normalization\",\n                \"Acoustic scene classification using deep residual networks with late fusion of separated high and low frequency paths\",\n                \"Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks\",\n                \"Transformers without tears: Improving the normalization of self-attention\",\n                \"Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net\",\n                \"Face Recognition via Centralized Coordinate Learning\",\n                \"Micro-batch training with batch-channel normalization and weight standardization\",\n                \"Weight standardization\",\n                \"Designing Network Design Spaces\",\n                \"Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes\",\n                \"Learning representations by back-propagating errors\",\n                \"ImageNet Large Scale Visual Recognition Challenge\",\n                \"Weight normalization: A simple reparameterization to accelerate training of deep neural networks\",\n                \"How Does Batch Normalization Help Optimization?\",\n                \"SSN: Learning Sparse Switchable Normalization via SparsestMax\",\n                \"Powernorm: Rethinking batch normalization in transformers\",\n                \"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\n                \"Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]13 based on the context and research area of ğ¿â‚‚BN: Enhancing Batch Normalization by Equalizing the ğ¿â‚‚ Norms of Features. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}