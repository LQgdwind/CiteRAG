{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: 𝐿₂BN: Enhancing Batch Normalization by Equalizing the 𝐿₂ Norms of Features\n\nPaper Abstract: \n\nPaper Section Text:\nExperimental Settings.\nWe verify the advantages of L2subscript𝐿2L_{2}BN over BN by conducting image classification experiments using convolutional networks.\nWe experiment on the CIFAR100 dataset  and the ImageNet-1K dataset .\nOn CIFAR100, we employ various classic networks as the backbone models,\nincluding ResNet-20\\\\\\backslash32\\\\\\backslash44\\\\\\backslash56\\\\\\backslash110 ,\nDenseNet [ref]13 with 40 layers and a growth rate of 12 denoted by DenseNet-40-12,\nDenseNet-BC [ref]13 with 100 layers and a growth rate of 12 denoted by DenseNet-BC-100-12,\nVGG-19 [ref]39 with BN,\nand RegNet-Y .\nOn ImageNet-1K, we evaluate our method with ResNet-50, ResNet-101, ResNeXt-50 (32×4​d324𝑑32\\times 4d), and ResNeXt-101 (32×4​d324𝑑32\\times 4d). For CIFAR100, we report the mean and standard deviation of the best accuracy over 5 runs with random seeds ranging from 121 to 125, reducing the impacts of random variations.\nFor ImageNet-1K, we fix the random seed to 1.\nFor a fair comparison, not only the L2subscript𝐿2L_{2}BN models but also their BN counterparts are trained from scratch, so our results may be slightly different from the ones presented in the original papers due to different random seeds, software, and hardware settings.\nOther training settings and hyper-parameters are detailed in the supplementary materials. Main Results and Analysis.\nTable 1 and Table 2 show the comparison results of the models and their L2subscript𝐿2L_{2}BN versions on CIFAR100 and ImageNet-1K, respectively. In terms of accuracy, the L2subscript𝐿2L_{2}BN can improve all the backbone models to varying degrees, regardless of the CIFAR100 or the ImageNet-1K dataset.\nFor example, the L2subscript𝐿2L_{2}BN can boost the accuracy of ResNet-56 by about 1% on CIFAR100 and ResNet-50 by about 0.6% on ImageNet-1K.\nIt is worth emphasizing that the L2subscript𝐿2L_{2}BN achieves the improvements without any additional parameters or hyper-parameters.\nDue to the pre-attached l2subscript𝑙2l_{2} normalization, the accuracy improvement benefits from the elimination of the difference in l2subscript𝑙2l_{2} norms of sample features.\nTo intuitively illustrate the effectiveness of L2subscript𝐿2L_{2}BN, we plot the training curves of ResNet-56 on CIFAR100 and ResNet-50 on ImageNet-1K in Figure 6.\nThe L2subscript𝐿2L_{2}BN can get persistently higher classification accuracy and slightly smaller training loss than the BN baseline. In Section 3.2, we analyze that the improvement in accuracy is due to the ability of L2subscript𝐿2L_{2}BN to enhance intra-class compactness and inter-class discrepancy.\nIn this part, we demonstrate this claim through extensive experiments.\nTo measure the intra-class compactness and inter-class discrepancy quantitatively, we adopt the measures used in ArcFace .\nThe intra-class compactness is measured by the mean of angles across features with respect to their respective class feature centers, denoted as intra-angle.\nThe inter-class discrepancy is measured by the mean of minimum angles between each class feature center and the other class feature centers, denoted as inter-angle.\nTo be more clear, we give the formulations of intra-angle and inter-angle: where 𝐱i​j∈R1×dsubscript𝐱𝑖𝑗superscript𝑅1𝑑\\mathbf{x}_{ij}\\in R^{1\\times d} denotes the j𝑗j-th sample feature vector of the i𝑖i-th class,\nNisubscript𝑁𝑖N_{i} denotes the number of samples belonging to the i𝑖i-th class,\n𝐜i∈R1×dsubscript𝐜𝑖superscript𝑅1𝑑\\mathbf{c}_{i}\\in R^{1\\times d} denotes the feature center vector of the i𝑖i-th class, and C𝐶C denotes the number of classes. We calculate the intra-angle of training data, the intra-angle of test data, and the inter-angle.\nThe inter-angle refers to the one of training data, and we don’t calculate the inter-angle of test data.\nWe argue that the inter-angle of test data is meaningless because the image classification is a closed-set task.\nFor the same reason, we use the class feature centers computed on the training set for the calculation of intra-angle, whether the intra-angle is of training data or test data.\nNote that the intra-angle and inter-angle are only meaningful for the classification layer.\nThe results in Table 1 show that the intra-angle is reduced after using the L2subscript𝐿2L_{2}BN either on training data or on test data, for most of the models except the DenseNet.\nBut for all models, the inter-angle gets enlarged.\nThis demonstrates that the L2subscript𝐿2L_{2}BN can make the intra-class features more compact and the inter-class features more separable.\nTherefore, the L2subscript𝐿2L_{2}BN can enhance the discriminative ability of neural networks, which is the reason for the accuracy improvement. Given the relative relationship between intra-class compactness and inter-class discrepancy, using either intra-angle or inter-angle alone is not sufficient to evaluate the discriminability of a model.\nFor that reason, we define the Intra-angle and Inter-angle Ratio, abbreviated as I​I​R𝐼𝐼𝑅IIR, as follows: The I​I​R𝐼𝐼𝑅IIR is a unified metric to evaluate the intra-class compactness and the inter-class discrepancy, the smaller the better.\nWe use the unified I​I​R𝐼𝐼𝑅IIR to verify the effect of L2subscript𝐿2L_{2}BN.\nFor all the backbones, the L2subscript𝐿2L_{2}BN can always achieve significantly smaller I​I​R𝐼𝐼𝑅IIR on both training data and test data, as shown in Table 1.\nTo be more rigorous, we compare the I​I​R𝐼𝐼𝑅IIR of BN and L2subscript𝐿2L_{2}BN throughout the training process in Figure 7.\nWe can see that the L2subscript𝐿2L_{2}BN can continuously get smaller I​I​R𝐼𝐼𝑅IIR, demonstrating the advantages of L2subscript𝐿2L_{2}BN. It is worth mentioning that the types of backbones used here are diverse, including models with skip connection like ResNet  and DenseNet [ref]13, models without skip connection like VGG [ref]39, and models searched by Neural Architecture Search like RegNet .\nThis indicates that, as a simple plug-and-play module, the L2subscript𝐿2L_{2}BN is shown to be\narchitecture-agnostic and produce persistent performance improvement.\nTherefore, the key advantage of L2subscript𝐿2L_{2}BN highlighted in this paper is not the significance but\nthe robustness and generalizability. Choice of Feature Normalization.\nIn the Method Section 3, we employ the l2subscript𝑙2l_{2} normalization on the whole feature map of each sample by default.\nTo justify our choice, we also evaluate in Table 3 other possible alternatives to l2subscript𝑙2l_{2} normalization such as Layer Normalization [ref]2, Instance Normalization , and Position Normalization , denoted by LNBN, INBN, and PNBN, respectively. We observe that the INBN and PNBN get much poorer performance than L2subscript𝐿2L_{2}BN, in terms of both accuracy and I​I​R𝐼𝐼𝑅IIR.\nWe argue that it is the entire feature map that represents the sample feature, whether the Instance Normalization or the Position Normalization destroys the sample-level feature information.\nThe Layer Normalization is also performed on the whole feature map.\nCompared with the l2subscript𝑙2l_{2} normalization, the main difference is that Layer Normalization has a centering operation.\nFrom the analysis in Figure 4 and Figure 5, the centering operation is unnecessary for the intra-class compactness and inter-class discrepancy.\nMoreover, the centering operation changes the orientation of feature vector and thus may change what the feature vector can represent .\nTo address this, Layer Normalization in the original paper [ref]2 employs a learned affine transformation to adaptively compensate for the possible information loss.\nHowever, the subsequent Batch Normalization makes the learned affine transformation of Layer Normalization ineffective in LNBN.\nTherefore, the information loss caused by Layer Normalization can not be effectively compensated.\nThe l2subscript𝑙2l_{2} normalization does not change the orientation of feature vector and therefore does not related to the semantic information loss  .\nThe results in Table 3 also prove that both the accuracy and the I​I​R𝐼𝐼𝑅IIR of LNBN are inferior to those of L2subscript𝐿2L_{2}BN.\nIn summary, compared with these possible alternatives, l2subscript𝑙2l_{2} normalization is the best choice. Applying L2subscript𝐿2L_{2}BN to Different Layers.\nAs described in Section 3.3, the L2subscript𝐿2L_{2}BN is applicable to all layers.\nTo confirm this point, we study the effect of L2subscript𝐿2L_{2}BN applied to different parts of neural networks, as shown in Table 4.\nEven if the L2subscript𝐿2L_{2}BN is only used for part of the neural network, the accuracy can be improved to varying degrees.\nHowever, the accuracy is enhanced to the greatest extent when applying L2subscript𝐿2L_{2}BN to all layers.\nThis indicates that the L2subscript𝐿2L_{2}BN is effective for both\nthe output layer and the hidden layers, and the effects can be\naccumulated. Comparison with Other Normalization Methods.\nThis section compares L2subscript𝐿2L_{2}BN with several existing variants of Batch Normalization, including Layer Normalization (LN) [ref]2, Instance Normalization (IN) , Group Normalization (GN) , Switchable Normalization (SN) , Batch-Channel Normalization (BCN) , and Batch-Instance Normalization (BIN) .\nFor GN, we test settings with the channel-per-group (cpg) values of 4 and 8.\nFor BCN, we set the number of groups to min{32, (the number of channels)/4}, as in the original paper .\nThe results are shown in Table 5.\nFor LN, IN, and GN, they abandon the batch statistics and thus perform worse than BN in popular training settings .\nSN, BCN, and BIN can be used to address the problem of poor performance of BN when the mini-batch size is very small.\nHowever, their performance in popular training settings is on par with or worse than BN.\nIn contrast, the L2subscript𝐿2L_{2}BN can still enhance BN when the mini-batch size is not small.\nOverall, the L2subscript𝐿2L_{2}BN performs better than these normalization methods without any hyper-parameters.\n\nReference markers found: [13]\n\nContext windows for each [ref]:\n[ref]13: dataset  and the ImageNet-1K dataset .\nOn CIFAR100, we employ various classic networks as the backbone models,\nincluding ResNet-20\\\\\\backslash32\\\\\\backslash44\\\\\\backslash56\\\\\\backslash110 ,\nDenseNet [ref]13 with 40 layers and a growth rate of 12 denoted by DenseNet-40-12,\nDenseNet-BC [ref]13 with 100 layers and a growth rate of 12 denoted by DenseNet-BC-100-12,\nVGG-19 [ref]39 with BN,\nand\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 13,\n            \"titles\": [\n                \"Delving into the Estimation Shift of Batch Normalization in a Network\",\n                \"Challenge on detection and classification of acoustic scenes and events\",\n                \"Layer normalization\",\n                \"Batch Normalization Increases Adversarial Vulnerability and Decreases Adversarial Transferability: A Non-Robust Feature Perspective\",\n                \"On the properties of neural machine translation: Encoder-decoder approaches\",\n                \"Recurrent Batch Normalization\",\n                \"ArcFace: Additive Angular Margin Loss for Deep Face Recognition\",\n                \"Momentum Contrast for Unsupervised Visual Representation Learning\",\n                \"Mask R-CNN\",\n                \"Deep Residual Learning for Image Recognition\",\n                \"Long short-term memory\",\n                \"Norm matters: efficient and accurate normalization schemes in deep networks\",\n                \"Device-Robust Acoustic Scene Classification Based on Two-Stage Categorization And Data Augmentation\",\n                \"Densely connected convolutional networks\",\n                \"Arbitrary style transfer in real-time with adaptive instance normalization\",\n                \"Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models\",\n                \"Batch normalization: Accelerating deep network training by reducing internal covariate shift\",\n                \"Serial order: A parallel distributed processing approach\",\n                \"Learning multiple layers of features from tiny images\",\n                \"Positional Normalization\",\n                \"Decoupled networks\",\n                \"Deep Hyperspherical Learning\",\n                \"Differentiable Learning-to-Normalize via Switchable Normalization\",\n                \"Acoustic scene classification using deep residual networks with late fusion of separated high and low frequency paths\",\n                \"Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks\",\n                \"Transformers without tears: Improving the normalization of self-attention\",\n                \"Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net\",\n                \"Face Recognition via Centralized Coordinate Learning\",\n                \"Micro-batch training with batch-channel normalization and weight standardization\",\n                \"Weight standardization\",\n                \"Designing Network Design Spaces\",\n                \"Normalizing the Normalizers: Comparing and Extending Network Normalization Schemes\",\n                \"Learning representations by back-propagating errors\",\n                \"ImageNet Large Scale Visual Recognition Challenge\",\n                \"Weight normalization: A simple reparameterization to accelerate training of deep neural networks\",\n                \"How Does Batch Normalization Help Optimization?\",\n                \"SSN: Learning Sparse Switchable Normalization via SparsestMax\",\n                \"Powernorm: Rethinking batch normalization in transformers\",\n                \"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\n                \"Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]13 based on the context and research area of 𝐿₂BN: Enhancing Batch Normalization by Equalizing the 𝐿₂ Norms of Features. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}