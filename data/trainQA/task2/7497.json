{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Democratizing Uncertainty Quantification\n\nPaper Abstract: \n\nPaper Section Text:\nThe quantification of uncertainties is crucial for safety-critical applications where an understanding of the associated risks is integral to a broader analysis, such as in engineering design, clinical trials, weather and extreme event forecasting, environmental risk assessment, and infectious disease control, to name but a few. Such risk analyses are typically model-driven since they involve extrapolating complex processes into the future. Accurate quantitative information on uncertainties in predictions underlying decisions can lead to deeper insight into the problem and, consequently, better decisions. The last couple of decades have seen remarkable growth in the use of UQ, including uncertainty propagation and Bayesian inference [ref]1. This is partly due to efficient and robust techniques such as Latin hypercube, quasi-Monte Carlo, ADVI, HMC, and NUTS   [ref]4, and partly due to flexible, open-source implementations of those algorithms, e.g. SciPy stats , Stan , PyMC [ref]7, and Pyro . The success of these software packages can be attributed to the high level of abstraction with which they allow a user to define their statistical model. The subtle details of the underlying algorithms are not exposed to the user, who can simply specify their statistical model using high-level representations of the relevant components (prior, likelihood, observation model, etc.) and solve it using existing general-purpose algorithms.\nThis arrangement is a form of separation of concerns: The algorithm developer does not require detailed knowledge of the domain expert‚Äôs application and vice versa. These successes notwithstanding, advanced statistical inference tools\nare not yet employed extensively in conjunction with computationally demanding models. Such models appear, for example, in engineering design, in geophysics, or in medical imaging. We believe that this is in part due to a chicken-and-egg problem: UQ has not been demonstrated to be useful in those areas, but demonstration requires advanced knowledge of both application and UQ techniques that few research groups have. Our work addresses both of those issues by reducing the required level of knowledge via generic interfaces. We rely on an existing and largely universal theoretical vocabulary for the interaction between models and UQ: The application model (or data-generating process) is represented as a forward operator F‚Äã(Œ∏)ùêπùúÉF(\\theta), which is a map from parameter space to data space. In forward UQ, the parameter Œ∏ùúÉ\\theta is uncertain, and we want to infer the probability distribution of the outputs F‚Äã(Œ∏)ùêπùúÉF(\\theta); in inverse problems, we specify a likelihood model for the observed data based on F‚Äã(Œ∏)ùêπùúÉF(\\theta) and aim to infer the probability distribution of Œ∏ùúÉ\\theta. Many UQ algorithms exploit knowledge of derivatives of the forward map to increase computational efficiency; as a consequence, application models needs to be able to expose the computation of gradients (Jacobians) or Hessians of FùêπF, provided they are available within a particular application. This short list of shared components ‚Äì evaluating F‚Äã(Œ∏)ùêπùúÉF(\\theta) and, perhaps, derivatives ‚Äì can be understood as a form of weak coupling between the statistical and the application model: Only a small part of the machinery inside the application model needs to be exposed to the statistical model, while the application model does not need to see the statistical model at all. This simple fact implies that it is ‚Äì in theory ‚Äì relatively straightforward to apply a wide variety of UQ methods to arbitrary application models. Despite that, in practice, the software packages mentioned above are typically only used to solve problems with relatively simple data-generating processes, such as basic numerical integration or hierarchical Bayesian regression.\nThis dichotomy can at least in part be attributed to the high technical complexity of combining advanced software packages for statistical inference with state-of-the-art implementations of sophisticated application models. The technical complexity arises since there is no equally universal counterpart to the mathematical interface in software, and becomes particularly challenging in HPC applications. To address these issues, we introduce UM-Bridge: A universal link between any UQ package and any forward model that breaks down complex software stacks into manageable components. Language-specific integrations make UM-Bridge models appear as native entities (classes, function calls etc.) in the respective programming language or even as native model classes in specific UQ packages. Its unified interface allows linking arbitrary tools and makes it easy to swap out components on either side, thus reducing user lock-in. UM-Bridge further offers portable models through optional containerization, which offers a high degree of separation of concerns between UQ and model experts. In order to strengthen rigorous performance comparisons in UQ, we present what we believe to be the first library of UQ benchmark problems, developed by the authors of this paper and provided as part of an open-source software repository. UM-Bridge support makes the benchmarks available to virtually any UQ software and ensures portability and reproducibility via containerization. We describe these UQ benchmarks in detail in Appendix¬†B. In addition, UM-Bridge offers a universal approach to scale-up UQ applications on parallel compute clusters that is fully model agnostic. In a black-box fashion, UM-Bridge even allows for HPC-scale computations with existing UQ codes that had never been intended for that purpose. In Appendix¬†A, we describe in detail the workflow for three complex UQ applications, each involving the coupling of UQ software with HPC code. Thus, UM-Bridge democratizes UQ and paves the way to its widespread adoption by seperating concerns of UQ, model and HPC experts, providing transparent scalability and facilitating reproducible benchmarking.\n\nReference markers found: [1]\n\nContext windows for each [ref]:\n[ref]1: deeper insight into the problem and, consequently, better decisions. The last couple of decades have seen remarkable growth in the use of UQ, including uncertainty propagation and Bayesian inference [ref]1. This is partly due to efficient and robust techniques such as Latin hypercube, quasi-Monte Carlo, ADVI, HMC, and NUTS   [ref]4, and partly due to flexible, open-source implementations of\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 1,\n            \"titles\": [\n                \"Automatic Differentiation Variational Inference\",\n                \"Inverse problems: A Bayesian perspective\",\n                \"Hybrid Monte Carlo\",\n                \"The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.\",\n                \"SciPy 1.0‚ÄîFundamental Algorithms for Scientific Computing in Python\",\n                \"Stan: A Probabilistic Programming Language\",\n                \"Probabilistic programming in Python using PyMC3\",\n                \"Pyro: Deep Universal Probabilistic Programming\",\n                \"CUQIpy ‚Äì Part II: computational uncertainty quantification for PDE-based inverse problems in Python\",\n                \"CUQIpy ‚Äì Part I: computational uncertainty quantification for inverse problems in Python\",\n                \"emcee: The MCMC Hammer\",\n                \"MUQ: The MIT Uncertainty Quantification Library\",\n                \"PyApprox: A software package for sensitivity analysis, Bayesian inference, optimal experimental design, and multi-fidelity uncertainty quantification and surrogate modeling\",\n                \"QMCPy: A quasi-Monte Carlo Python Library\",\n                \"Algorithm X: The Sparse Grids Matlab Kit - a Matlab Implementation of Sparse Grids for High-Dimensional Function Approximation and Uncertainty Quantification Just Accepted\",\n                \"tinyDA\",\n                \"TT-Toolbox\",\n                \"UQpy v4.1: Uncertainty Quantification with Python\",\n                \"The deal.II finite element library: Design, features, and insights\",\n                \"A Derivative-Free Line-Search Algorithm for Simulation-Driven Design Optimization Using Multi-Fidelity Computations\",\n                \"A benchmark for the Bayesian inversion of coefficients in partial differential equations\",\n                \"hIPPYlib-MUQ: A Bayesian Inference Software Framework for Integration of Data with Complex Predictive Models under Uncertainty\",\n                \"Dakota, a multilevel parallel object-oriented framework for design optimization, parameter estimation, uncertainty quantification and sensitivity analysis: Version 6.12 user‚Äôs Manual\",\n                \"lagun\",\n                \"UQLab: A Framework for Uncertainty Quantification in Matlab\",\n                \"UM-Bridge: Uncertainty quantification and modeling bridge\",\n                \"The Functional Mockup Interface for Tool independent Exchange of Simulation Models\",\n                \"preCICE v2: A sustainable and user-friendly coupling library [version 2; peer review: 2 approved]\",\n                \"The LINPACK Benchmark: An explanation\",\n                \"The SCEC/USGS Dynamic Earthquake Rupture Code Verification Exercise\",\n                \"A Suite of Exercises for Verifying Dynamic Earthquake Rupture Codes\",\n                \"A3mark: A publicly available online web service for seismic attribute benchmarking\",\n                \"Scalability of High-Performance PDE Solvers\",\n                \"MORwiki - Model Order Reduction Wiki\",\n                \"Stochastic Collocation Methods: A Survey\",\n                \"Equation of State Calculations by Fast Computing Machines\",\n                \"Multilevel Monte Carlo Path Simulation\",\n                \"A Hierarchical Multilevel Markov Chain Monte Carlo Algorithm with Applications to Uncertainty Quantification in Subsurface Flow\",\n                \"Multilevel Delayed Acceptance MCMC with an Adaptive Error Model in PyMC3\",\n                \"Complexity Analysis of Accelerated MCMC Methods for Bayesian Inversion\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]1 based on the context and research area of Democratizing Uncertainty Quantification. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}