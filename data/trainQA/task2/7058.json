{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Learning unitaries with quantum statistical queries\n\nPaper Abstract: \n\nPaper Section Text:\nWe propose several algorithms for learning unitary operators from quantum statistical queries (QSQs) with respect to their Choi-Jamiolkowski state.\nQuantum statistical queries capture the capabilities of a learner with limited quantum resources, which receives as input only noisy estimates of expected values of measurements.\nOur methods hinge on a novel technique for estimating the Fourier mass of a unitary on a subset of Pauli strings with a single quantum statistical query, generalizing a previous result for uniform quantum examples.\nExploiting this insight, we show that the quantum Goldreich-Levin algorithm can be implemented with quantum statistical queries, whereas the prior version of the algorithm involves oracle access to the unitary and its inverse.\nMoreover, we prove that ùí™‚Äã(log‚Å°n)ùí™ùëõ\\mathcal{O}(\\log n)-juntas and quantum Boolean functions with constant total influence are efficiently learnable in our model, and constant-depth circuits are learnable sample-efficiently with quantum statistical queries. On the other hand, all previous algorithms for these tasks require direct access to the Choi-Jamiolkowski state or oracle access to the unitary.\nIn addition, our upper bounds imply that the actions of those classes of unitaries on locally scrambled ensembles can be efficiently learned.\nWe also demonstrate that, despite these positive results, quantum statistical queries lead to an exponentially larger sample complexity for certain tasks, compared to separable measurements to the Choi-Jamiolkowski state. In particular, we show an exponential lower bound for learning a class of phase-oracle unitaries and a double exponential lower bound for testing the unitarity of channels, adapting to our setting previous arguments for quantum states.\nFinally, we propose a new definition of average-case surrogate models, showing a potential application of our results to hybrid quantum machine learning. Learning the dynamic properties of quantum systems is a fundamental problem at the intersection of machine learning (ML) and quantum physics. In the most general case, this task can be achieved under the broad framework of quantum process tomography (QPT) . However, QPT can be extremely resource-intensive, as learning the entire classical description of a unitary transformation requires exponentially many queries  in the worst case. This complexity can be significantly reduced if the unitary is not completely arbitrary, but instead it belongs to a specific class. For instance, this approach has been fruitfully adopted for quantum Boolean functions [ref]3, quantum juntas   and quantum circuits with bounded covering numbers .\nOn the other hand, the complexity of quantum process tomography could be drastically reduced if we restrict our attention only on local properties of the output state, as recently demonstrated in .\nAnother scenario of interest is the one of property testing, where the learner is not asked to retrieve the classical description of the target process, but solely to test whether is satisfies some specific property .\nA further figure of merit in quantum process learning is the type of resources that the learner is allowed to use.\nFor the special case of unitary transformations, the learner is usually given oracle access to the target unitary UùëàU and its inverse U‚Ä†superscriptùëà‚Ä†U^{\\dagger}, or, alternatively, to the corresponding Choi-Jamiolkowski state.\nIn this paper we consider this latter approach and we ask the following question: Which classes of unitaries are efficiently learnable with noisy single-copy measurements of the Choi-Jamiolkowski state? This question is motivated by near-term implementations of quantum algorithms, which involve several sources of noise and severely limited entangling capacity . To this end, we adopt the model of quantum statistical queries (QSQs), previously introduced in 0 1 as an extension of the (classical) statistical query model 2. In the QSQ model, we consider a learner without quantum memory that can only access noisy estimates of the expected values of chosen observables on an unknown initial state.\nInterestingly, several concept classes such as parities, juntas function, and DNF formulae are efficiently learnable in the QSQ model, whereas the classical statistical query model necessitates an exponentially larger number of samples. Despite these positive results, resorting to quantum statistical queries can be considerably limiting for some tasks. In particular, the authors of 1 have established an exponential gap between QSQ learning and learning with quantum examples in the presence of classification noise.\nQuantum statistical queries have also found practical applications in classical verification of quantum learning, as detailed in 3. Furthermore, they have been employed in the analysis of quantum error mitigation models 4 1 and quantum neural networks 5. Alternative variations of quantum statistical queries have also been explored in 6 7 8.\nMoreover, the connection between quantum statistical queries and quantum differential privacy was investigated in 0, and an equivalence between quantum statistical query learning and quantum local differential privacy 9 . In this paper we demonstrate that several classes of unitaries are efficiently learnable with quantum statistical queries with respect to their Choi state. In particular, we show our result for a natural distance over unitaries induced by the Choi-Jamiolkowski isomorphism and previously adopted in¬† . We emphasize that this choice of distance allows to predict the action of the target unitary on a random input state sampled from a locally scrambled ensemble¬†0.\nWe now give an informal version of our upper bounds. When not explicitly stated, the tolerance of a quantum statistical query is at least polynomially small. Constant depth circuits are learnable with polynomially many quantum statistical queries (Theorem¬†3.2). Quantum O‚Äã(log‚Å°n)ùëÇùëõO(\\log n)-juntas are efficiently learnable with polynomially many quantum statistical queries (Theorem¬†3.3). Quantum Boolean functions with constant total influence are efficiently learnable with polynomially many quantum statistical queries (Theorem¬†3.5). In order to prove this result, we show that the quantum Goldreich-Levin algorithm can be implemented with quantum statistical queries (Theorem¬†3.4). While these positive results show that a wide class of unitaries can be efficiently learned in our model, we also argue that resorting to quantum statistical queries leads to an exponentially larger sample complexity for certain tasks. In particular, we give the following lower bound. There is a class of phase oracle unitaries that requires exponentially many quantum statistical queries with polynomially small tolerance to be learnt below distance 0.0050.0050.005 with high probability (Theorem¬†4.1); Estimating the unitarity of a quantum channel with error smaller than 0.240.240.24 and polynomially small tolerance requires double-exponentially many quantum statistical queries (Theorem¬†4.2). Moreover, prior results imply that both tasks can be efficiently performed with polynomially many copies of the associated Choi-Jamiolkowski state.\nIn Section¬†3.3.1, we complement our theoretical findings with a numerical simulation the quantum Goldreich-Levin algorithm implemented with quantum statistical queries. Finally, in Section¬†5 we suggest a potential application of our results to hybrid quantum machine learning. Prior work 1 2 showed that certain quantum learning models can be replaced by classical surrogates during the prediction phase. We argue that the learning algorithms provided in the present paper can also serve to this scope. To this end, we extend the definition of classical surrogates from the worst-case to the average-case. Our results generalize prior work in two ways. On the one hand, we show that several classes of unitaries are learnable in the QSQ model, while all previous results involved the access to stronger oracles. The adoption of a weaker oracle is particularly advantageous for near-term implementation, since the definition of QSQs accounts for the measurement noise.\nOn the other hand, we demonstrate that prior QSQ algorithms for learning classical Boolean functions can be generalized to unitary learning.\nIn particular, Chen et¬†al.  showed that kùëòk-junta unitaries are learnable with O‚Äã(4k)ùëÇsuperscript4ùëòO(4^{k}) copies of the Choi state, and Montanaro and Osborne [ref]3 proposed the original version of the quantum Goldreich-Levin algorithm, requiring oracle access to the target unitary and its inverse. Furthermore, Atƒ±cƒ± and Servedio 3 provided an algorithm for learning classical kùëòk-junta functions with O‚Äã(2k)ùëÇsuperscript2ùëòO(2^{k}) uniform quantum examples, and Arunachalam et¬†al. 0 demonstrated that several classes of quantum Boolean functions are learnable with quantum statistical queries with respect to uniform quantum examples. In particular, they showed that classical kùëòk-junta functions are learnable with O‚Äã(2k+n)ùëÇsuperscript2ùëòùëõO(2^{k}+n) quantum statistical queries, and moreover that the (classical) Goldreich-Levin algorithm can be implemented in the QSQ model.\nIn a subsequent work, Arunachalam et¬†al. 1 showed that the output of constant-depth circuits is learnable with poly‚Äã(n)polyùëõ\\mathrm{poly}(n) quantum statistical queries and provided several hardness results for the QSQ model. Specifically, they showed an exponential lower bound for learning a class of classical Boolean functions, and a double exponential lower bound for testing the purity of a target state. We distil several open questions concerning quantum statistical queries and process learning. The main workhorse for QSQ learning classical Boolean functions is Fourier analysis. While Fourier analysis is usually cast under the uniform distribution, the Œºùúá\\mu-biased Fourier analysis can be applied to every product distribution. In particular, Œºùúá\\mu-biased Fourier sampling can be used to learn linear functions¬†4 and DNFs¬†5 under product distributions with quantum examples. Can we extend these results to the QSQ model? Which classes of channels can be learned under quantum statistical queries? What is the power of quantum statistical queries for testing properties of unitaries (and more broadly channels)? While we provided a double exponential lower bound for testing unitarity, quantum statistical queries might suffice for testing other relevant properties. Following 6 8, we can restrict our model to diagonal measurements. Which classes of channels are learnable under this restricted model?\n\nReference markers found: [3]\n\nContext windows for each [ref]:\n[ref]3: be significantly reduced if the unitary is not completely arbitrary, but instead it belongs to a specific class. For instance, this approach has been fruitfully adopted for quantum Boolean functions [ref]3, quantum juntas   and quantum circuits with bounded covering numbers .\nOn the other hand, the complexity of quantum process tomography could be drastically reduced if we restrict our attention\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 3,\n            \"titles\": [\n                \"Testing and Learning Quantum Juntas Nearly Optimally\",\n                \"Prescription for experimental determination of the dynamics of a quantum black box\",\n                \"Process tomography for unitary quantum channels\",\n                \"Quantum boolean functions\",\n                \"Nearly optimal algorithms for testing and learning quantum junta channels\",\n                \"Learning quantum processes without input control\",\n                \"Learning to predict arbitrary quantum processes\",\n                \"A survey of quantum property testing\",\n                \"Quantum computing in the nisq era and beyond\",\n                \"Quantum statistical query learning\",\n                \"On the Role of Entanglement and Statistics in Learning\",\n                \"Efficient noise-tolerant learning from statistical queries\",\n                \"Classical Verification of Quantum Learning\",\n                \"Exponentially tighter bounds on limitations of quantum error mitigation\",\n                \"Quantum noise protects quantum classifiers against adversaries\",\n                \"One t gate makes distribution learning hard\",\n                \"On the Hardness of PAC-learning Stabilizer States with Noise\",\n                \"On the average-case complexity of learning output distributions of quantum circuits\",\n                \"Quantum Local Differential Privacy and Quantum Statistical Query Model\",\n                \"Out-of-distribution generalization for learning quantum dynamics\",\n                \"Classical surrogates for quantum learning models\",\n                \"Shadows of quantum machine learning\",\n                \"Quantum algorithms for learning and testing juntas\",\n                \"Quantum Learning Boolean Linear Functions w.r.t. Product Distributions\",\n                \"Learning DNFs under product distributions via ùúá‚Äìbiased quantum Fourier sampling\",\n                \"Introduction to haar measure tools in quantum information: A beginner‚Äôs tutorial\",\n                \"Completely positive linear maps on complex matrices\",\n                \"Linear transformations which preserve trace and positive semidefiniteness of operators\",\n                \"Learning and testing algorithms for the clifford group\",\n                \"Property testing of unitary operators\",\n                \"Quantum Talagrand, KKL and Friedgut‚Äôs theorems and the learnability of quantum Boolean functions\",\n                \"Analysis of boolean functions\",\n                \"Learning dnf over the uniform distribution using a quantum example oracle\",\n                \"Learning Quantum Processes and Hamiltonians via the Pauli Transfer Matrix\",\n                \"Strong bound between trace distance and hilbert-schmidt distance for low-rank states\",\n                \"Eigenstate extraction with neural-network tomography\",\n                \"Learning marginals suffices!\",\n                \"Estimating the coherence of noise\",\n                \"Bounding the average gate fidelity of composite channels using the unitarity\",\n                \"Quantum machine learning in feature hilbert spaces\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]3 based on the context and research area of Learning unitaries with quantum statistical queries. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}