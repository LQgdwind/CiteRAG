{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Misspecified Gaussian Process Bandit Optimization\n\nPaper Abstract: \n\nPaper Section Text:\nBandit optimization has been successfully used in a great number of machine learning and real-world applications, e.g., in mobile health , environmental monitoring , economics , hyperparameter tuning , to name a few. To scale to large or continuous domains, modern bandit approaches try to model and exploit the problem structure that is often manifested as correlations in rewards of \"similar\" actions. Hence, the key idea of kernelized bandits is to consider only smooth reward functions of a low norm belonging to a chosen Reproducing Kernel Hilbert Space (RKHS) of functions. This permits the application of flexible nonparametric Gaussian process (GP) models and Bayesian optimization methods via a well-studied link between RKHS functions and GPs (see, e.g.,  for a concise review). A vast majority of previous works on nonparametric kernelized bandits have focused on designing algorithms and theoretical bounds on the standard notions of regret (see, e.g.,   ). However, they solely focus on the realizable (i.e., well-specified) case in which one assumes perfect knowledge of the true function class. For example, the analysis of the prominent GP-UCB  algorithm assumes the model to be well-specified and ignores potential misspecification issues. As the realizability assumption may be too restrictive in real applications, we focus on the case where it may only hold approximately. In practice, model misspecifications can arise due to various reasons, such as incorrect choice of kernel, consideration of an overly smooth function class, hyperparameter estimation errors, etc. Hence, an open question is to characterize the impact of model misspecification in the kernelized setting, and to design robust algorithms whose performance degrades optimally with the increasing level of misspecification. In this paper, we study the GP bandit problem with model misspecification in which the true unknown function might be ϵitalic-ϵ\\epsilon-far (as measured in the max norm) from a member of the learner’s assumed hypothesis class. We propose a novel GP bandit algorithm and regret bounds that depend on the misspecification error, time horizon, and underlying kernel. Specifically, we present an algorithm that is based on the classical uncertainty sampling approach that is frequently used in Bayesian optimization and experimental design. Importantly, our main presented algorithm assumes no knowledge of the misspecification error ϵitalic-ϵ\\epsilon and achieves standard regret rates in the realizable case. Related work on GP bandits. GP bandit algorithms have received significant attention in recent years (e.g.,    ). While the most popular approaches in the stochastic setting rely on upper confidence bound (UCB) and Thompson sampling strategies, a number of works also consider uncertainty sampling procedures (e.g.,   ). Beyond the standard setting, numerous works have also considered the contextual bandit setting (e.g.,   ), while the case of unknown kernel hyperparameters and misspecified smoothness has been studied in, e.g., [ref]46  . [ref]46  assume that the reward function is smooth as measured by the known (or partially known) kernel, while in our problem, we allow the unknown function to lie outside a given kernel’s reproducing space. Related corruption-robust GP bandits in which an adversary can additively perturb the observed rewards are recently considered in [ref]4.\nIn Section 2, we also discuss how the misspecified problem can be seen from this perspective, where the corruption function is fixed and the adversarial budget scales with the time horizon. While the focus of [ref]4 is on protecting against an adaptive adversary and thus designing randomized algorithms and regret bounds that depend on the adversarial budget, we propose deterministic algorithms and analyze the impact of misspecification. Apart from corruptions, several works have considered other robust aspects in GP bandits, such as designing robust strategies against the shift in uncontrollable covariates   1 8 . While they report robust regret guarantees, they still assume the realizable case only. Our goal of attaining small regret despite the wrong hypothesis class requires very different techniques from these previous works. Related work on misspecified linear bandits.\nRecently, works on reinforcement learning with misspecified linear features (e.g.,   ) have renewed interest in the related misspecified linear bandits (e.g., , , 0, 5) first introduced in . In , the authors show that standard algorithms must suffer Ω​(ϵ​T)Ωitalic-ϵ𝑇\\Omega(\\epsilon T) regret under an additive ϵitalic-ϵ\\epsilon–perturbation of the linear model. Recently,  propose a robust variant of OFUL  that requires knowing the misspecification parameter ϵitalic-ϵ\\epsilon. In particular, their algorithm obtains a high-probability O~​(d​T+ϵ​d​T)~𝑂𝑑𝑇italic-ϵ𝑑𝑇\\tilde{O}(d\\sqrt{T}+\\epsilon\\sqrt{d}T) regret bound. In , the authors propose another arm-elimination algorithm based on G-experimental design. Unlike the previous works, their algorithm is agnostic to the misspecification level, and its performance matches the lower bounds. As shown in , when the number of actions K𝐾K is large (K≫dmuch-greater-than𝐾𝑑K\\gg d), the “price” of ϵitalic-ϵ\\epsilon-misspecification must grow as Ω​(ϵ​d​T)Ωitalic-ϵ𝑑𝑇\\Omega(\\epsilon\\sqrt{d}T).111A result by 5 further shows that this result can be improved to O​(ϵ​K​T)𝑂italic-ϵ𝐾𝑇O(\\epsilon\\sqrt{K}T) in the small-K𝐾K regime. Our main algorithm is inspired by the proposed technique for the finite-arm misspecified linear bandit setting . It works in the more general kernelized setting, uses a simpler data acquisition rule often used in Bayesian optimization and experimental design, and recovers the same optimal guarantees when instantiated with linear kernel. Several works have recently considered the misspecified contextual linear bandit problem with unknown model misspecification ϵitalic-ϵ\\epsilon. 4 introduce a new family of algorithms that require access to an online oracle for square loss regression and address the case of adversarial contexts. Concurrent work of 3 solves the case when contexts / action sets are stochastic. Both works (4 and 3) leverage CORRAL-type aggregation  of contextual bandit algorithms and achieve the optimal O~​(d​T​ϵ+d​T)~𝑂𝑑𝑇italic-ϵ𝑑𝑇\\tilde{O}(\\sqrt{d}T\\epsilon+d\\sqrt{T}) regret bound. Finally, in 2, the authors present a practical master algorithm that plays base algorithms that come with a candidate regret bound that may not hold during all rounds. The master algorithm plays base algorithms in a balanced way and suitably eliminates algorithms whose regret bound is no longer valid. Similarly to the previous works that rely on the CORRAL-type master algorithms, we use the balancing master algorithm of 3 together with our GP-bandit base algorithm to provide contextual misspecified regret bounds. Around the time of the submission of this work, a related approach that among others also considers misspecified kernel bandits appeared online . [8, Theorem 3] contains the same regret scaling due to misspecification as we obtain in our results. The main difference between the two works is in the proposed algorithms and analysis techniques.\nOur approach does not require robust estimators and simply uses the standard ones (i.e., GP posterior/ kernelized ridge regression mean and variance estimators) that can be computed in the closed-form. It can also handle infinite action sets similarly to the classical Bayesian optimization algorithms; it utilizes a single acquisition function that, in practice, can be maximized via standard off-the-shelf global optimization solvers. We also present a complete treatment of the misspecified problem by showing the failure of standard UCB approaches, algorithms for known and unknown ϵitalic-ϵ\\epsilon, an impossibility result, and extensions to the contextual bandit setting. Finally, our main algorithm (Algorithm 2) demonstrates the use of a different acquisition function in comparison to   that relies on standard and non-robust estimators. Contributions. In this paper, we systematically handle model misspecification in GP bandits. Specifically, this paper makes the following contributions: We introduce a misspecified kernelized bandit problem, and for known misspecification error ϵitalic-ϵ\\epsilon, we present the EC-GP-UCB algorithm\nwith enlarged confidence bounds that achieves cumulative RT=O​(B​γT​T+γT​T+ϵ​T​γT)subscript𝑅𝑇𝑂𝐵subscript𝛾𝑇𝑇subscript𝛾𝑇𝑇italic-ϵ𝑇subscript𝛾𝑇R_{T}=O(B\\sqrt{\\gamma_{T}T}+\\gamma_{T}\\sqrt{T}+\\epsilon T\\sqrt{\\gamma_{T}}) regret. Our simple lower bound argument shows that Ω​(T​ϵ)Ω𝑇italic-ϵ\\Omega(T\\epsilon) regret is unavoidable in the general kernelized setting. For when ϵitalic-ϵ\\epsilon is unknown, we propose another algorithm based on uncertainty sampling and phased exploration that achieves (up to polylogpolylog\\operatorname{polylog} factors) the previous regret rates in the misspecified setting, and standard regret guarantees in the realizable case (when ϵ=0italic-ϵ0\\epsilon=0). Finally, we consider a misspecified contextual kernelized problem, and show that when action sets are stochastic, our EC-GP-UCB algorithm can be effectively combined with the regret bound balancing strategy from 3 to achieve previous regret bounds (up to some additive lower order terms).\n\nReference markers found: [46]\n\nContext windows for each [ref]:\n[ref]46: setting, numerous works have also considered the contextual bandit setting (e.g.,   ), while the case of unknown kernel hyperparameters and misspecified smoothness has been studied in, e.g., [ref]46  . [ref]46  assume that the reward function is smooth as measured by the known (or partially known) kernel, while in our problem, we allow the unknown function to lie outside a given kernel’s\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 46,\n            \"titles\": [\n                \"Convergence Guarantees for Gaussian Process Means With Misspecified Likelihoods and Smoothness\",\n                \"Improved algorithms for linear stochastic bandits\",\n                \"Corralling a band of bandit algorithms\",\n                \"No-Regret Bayesian Optimization with Unknown Hyperparameters\",\n                \"Corruption-tolerant Gaussian process bandit optimization\",\n                \"Adversarially Robust Optimization with Gaussian Processes\",\n                \"Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation\",\n                \"Bayesian optimization of risk measures\",\n                \"High-dimensional experimental design and kernel bandits\",\n                \"On Kernelized Multi-armed Bandits\",\n                \"Parallel Gaussian process optimization with upper confidence bound and pure exploration\",\n                \"Regret bounds for deterministic Gaussian process bandits\",\n                \"Is a good representation sufficient for sample efficient reinforcement learning?\",\n                \"Streaming kernel regression with provably adaptive mean, variance, and regularization\",\n                \"Adapting to misspecification in contextual bandits\",\n                \"Beyond UCB: Optimal and efficient contextual bandits with regression oracles\",\n                \"Misspecified Linear Bandits\",\n                \"Provably Efficient Reinforcement Learning with Linear Function Approximation\",\n                \"Gaussian Processes and Kernel Methods: A Review on Connections and Equivalences\",\n                \"The equivalence of two extremum problems\",\n                \"Distributionally robust Bayesian optimization\",\n                \"Stochastic Bandits with Context Distributions\",\n                \"Contextual Gaussian process bandit optimization\",\n                \"Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies\",\n                \"Learning with good feature representations in bandits and in RL with a generative model\",\n                \"A contextual-bandit approach to personalized news article recommendation\",\n                \"Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization\",\n                \"Competing Bandits in Matching Markets\",\n                \"Universal kernels\",\n                \"Uncertainty quantification using martingales for misspecified Gaussian processes\",\n                \"Efficient and robust algorithms for adversarial linear contextual bandits\",\n                \"Distributionally robust Bayesian quadrature optimization\",\n                \"Regret Bound Balancing and Elimination for Model Selection in Bandits and RL\",\n                \"Model selection in contextual stochastic bandit problems\",\n                \"Gaussian processes for machine learning, volume 1\",\n                \"Tight Regret Bounds for Bayesian Optimization in One Dimension\",\n                \"Lower Bounds on Regret for Noisy Gaussian Process Bandit Optimization\",\n                \"Quantifying mismatch in Bayesian optimization\",\n                \"Mixed strategies for robust optimization of unknown objectives\",\n                \"Gaussian Process Bandits with Adaptive Discretization\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]46 based on the context and research area of Misspecified Gaussian Process Bandit Optimization. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}