{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Quantum Random Access Codes for Boolean Functions\n\nPaper Abstract: \n\nPaper Section Text:\nThis paper focuses on generalizing the classical, quantum and entanglement-assisted random access codes. Instead of recovering a single bit from the initial string xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n}, we are interested in evaluating a Boolean function f:{âˆ’1,1}kâ†’{âˆ’1,1}:ğ‘“â†’superscript11ğ‘˜11f:\\{-1,1\\}^{k}\\to\\{-1,1\\} on any sequence of kğ‘˜k bits from xğ‘¥x. We generically call them fğ‘“f-random access codes. Let ğ’®nk={(Si)i=1kâˆˆ{1,â€¦,n}k|Siâ‰ Sjâ€‹âˆ€i,j}superscriptsubscriptğ’®ğ‘›ğ‘˜conditional-setsuperscriptsubscriptsubscriptğ‘†ğ‘–ğ‘–1ğ‘˜superscript1â€¦ğ‘›ğ‘˜subscriptğ‘†ğ‘–subscriptğ‘†ğ‘—for-allğ‘–ğ‘—\\mathcal{S}_{n}^{k}=\\{(S_{i})_{i=1}^{k}\\in\\{1,\\dots,n\\}^{k}\\leavevmode\\nobreak\\ |\\leavevmode\\nobreak\\ S_{i}\\neq S_{j}\\leavevmode\\nobreak\\ \\forall i,j\\} be the set of sequences of different elements from {1,â€¦,n}1â€¦ğ‘›\\{1,\\dots,n\\} with length kğ‘˜k and let xSâˆˆ{âˆ’1,1}ksubscriptğ‘¥ğ‘†superscript11ğ‘˜x_{S}\\in\\{-1,1\\}^{k} denote the substring of xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n} specified by Sâˆˆğ’®nkğ‘†superscriptsubscriptğ’®ğ‘›ğ‘˜S\\in\\mathcal{S}_{n}^{k}. Alice gets xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n} and she needs to encode her data and send it to Bob, so that he can decode fâ€‹(xS)ğ‘“subscriptğ‘¥ğ‘†f(x_{S}) for any Sâˆˆğ’®nkğ‘†superscriptsubscriptğ’®ğ‘›ğ‘˜S\\in\\mathcal{S}_{n}^{k} with probability p>1/2ğ‘12p>1/2. Such problem was already considered by Sherstov in a two-way communication complexity settingÂ  and later used in his pattern matrix methodÂ  in order to prove other communication complexity lower bounds. Even though our results are expressed in a random access code language, they can also be seen as in a one-way communication complexity setting. If two-way communication is allowed, Bob can send the identity of his sequence to Alice with Oâ€‹(kâ€‹logâ¡n)ğ‘‚ğ‘˜ğ‘›O(k\\log n) bits of communication, whereas (as we will see) significantly more communication may be required in the one-way scenario. In the following, Î Î \\Pi will refer to a sample space with some probability distribution. As before, PR and SR stand for private and shared randomness, respectively. Moreover, since we require the success probability to always be greater than 1/2121/2, given that one can always guess the correct result with probability 1/2121/2, from now on it will be convenient to use the bias Îµğœ€\\varepsilon of the prediction, defined as Îµ=2â€‹pâˆ’1ğœ€2ğ‘1\\varepsilon=2p-1, instead of its success probability pğ‘p. We start with nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-RAC, the fğ‘“f-classical random access code on mğ‘šm bits with bias Îµğœ€\\varepsilon. An nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-RAC with PR is an encoding map E:{âˆ’1,1}nÃ—Î Aâ†’{âˆ’1,1}m:ğ¸â†’superscript11ğ‘›subscriptÎ ğ´superscript11ğ‘šE:\\{-1,1\\}^{n}\\times\\Pi_{A}\\to\\{-1,1\\}^{m} satisfying the following: for every Sâˆˆğ’®nkğ‘†superscriptsubscriptğ’®ğ‘›ğ‘˜S\\in\\mathcal{S}_{n}^{k} there is a decoding map DS:{âˆ’1,1}mÃ—Î Bâ†’{âˆ’1,1}:subscriptğ·ğ‘†â†’superscript11ğ‘šsubscriptÎ ğµ11D_{S}:\\{-1,1\\}^{m}\\times\\Pi_{B}\\to\\{-1,1\\} such that PrrA,rBâ¡[DSâ€‹(Eâ€‹(x,rA),rB)=fâ€‹(xS)]â‰¥12+12â€‹ÎµsubscriptPrsubscriptğ‘Ÿğ´subscriptğ‘Ÿğµsubscriptğ·ğ‘†ğ¸ğ‘¥subscriptğ‘Ÿğ´subscriptğ‘Ÿğµğ‘“subscriptğ‘¥ğ‘†1212ğœ€\\operatorname{Pr}_{r_{A},r_{B}}[D_{S}(E(x,r_{A}),r_{B})=f(x_{S})]\\geq\\frac{1}{2}+\\frac{1}{2}\\varepsilon for all xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n}. An nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-RAC with SR is an encoding map E:{âˆ’1,1}nÃ—Î â†’{âˆ’1,1}m:ğ¸â†’superscript11ğ‘›Î superscript11ğ‘šE:\\{-1,1\\}^{n}\\times\\Pi\\to\\{-1,1\\}^{m} satisfying the following: for every Sâˆˆğ’®nkğ‘†superscriptsubscriptğ’®ğ‘›ğ‘˜S\\in\\mathcal{S}_{n}^{k} there is a decoding map DS:{âˆ’1,1}mÃ—Î â†’{âˆ’1,1}:subscriptğ·ğ‘†â†’superscript11ğ‘šÎ 11D_{S}:\\{-1,1\\}^{m}\\times\\Pi\\to\\{-1,1\\} such that Prrâ¡[DSâ€‹(Eâ€‹(x,r),r)=fâ€‹(xS)]â‰¥12+12â€‹ÎµsubscriptPrğ‘Ÿsubscriptğ·ğ‘†ğ¸ğ‘¥ğ‘Ÿğ‘Ÿğ‘“subscriptğ‘¥ğ‘†1212ğœ€\\operatorname{Pr}_{r}[D_{S}(E(x,r),r)=f(x_{S})]\\geq\\frac{1}{2}+\\frac{1}{2}\\varepsilon for all xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n}. We define nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-QRAC, the fğ‘“f-quantum random access code on mğ‘šm qubits with bias Îµğœ€\\varepsilon. An nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-QRAC with PR is an encoding map E:{âˆ’1,1}nâ†’â„‚2mÃ—2m:ğ¸â†’superscript11ğ‘›superscriptâ„‚superscript2ğ‘šsuperscript2ğ‘šE:\\{-1,1\\}^{n}\\to\\mathbb{C}^{2^{m}\\times 2^{m}} that assigns an mğ‘šm-qubit density matrix to every xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n} and satisfies the following: for every Sâˆˆğ’®nkğ‘†superscriptsubscriptğ’®ğ‘›ğ‘˜S\\in\\mathcal{S}_{n}^{k} there is a POVM MS={Mâˆ’1S,M1S}superscriptğ‘€ğ‘†subscriptsuperscriptğ‘€ğ‘†1subscriptsuperscriptğ‘€ğ‘†1M^{S}=\\{M^{S}_{-1},M^{S}_{1}\\} such that Trâ¡(Mfâ€‹(xS)Sâ‹…Eâ€‹(x))â‰¥12+12â€‹ÎµTrâ‹…subscriptsuperscriptğ‘€ğ‘†ğ‘“subscriptğ‘¥ğ‘†ğ¸ğ‘¥1212ğœ€\\operatorname{Tr}(M^{S}_{f(x_{S})}\\cdot E(x))\\geq\\frac{1}{2}+\\frac{1}{2}\\varepsilon for all xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n}. An nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-QRAC with SR is an encoding map E:{âˆ’1,1}nÃ—Î â†’â„‚2m:ğ¸â†’superscript11ğ‘›Î superscriptâ„‚superscript2ğ‘šE:\\{-1,1\\}^{n}\\times\\Pi\\to\\mathbb{C}^{2^{m}} that assigns an mğ‘šm-qubit pure state to every xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n} and satisfies the following: for every Sâˆˆğ’®nkğ‘†superscriptsubscriptğ’®ğ‘›ğ‘˜S\\in\\mathcal{S}_{n}^{k} there is a set of POVMs {MrS}râˆˆÎ subscriptsubscriptsuperscriptğ‘€ğ‘†ğ‘Ÿğ‘ŸÎ \\{M^{S}_{r}\\}_{r\\in\\Pi}, with MrS={Mâˆ’1,rS,M1,rS}subscriptsuperscriptğ‘€ğ‘†ğ‘Ÿsubscriptsuperscriptğ‘€ğ‘†1ğ‘Ÿsubscriptsuperscriptğ‘€ğ‘†1ğ‘ŸM^{S}_{r}=\\{M^{S}_{-1,r},M^{S}_{1,r}\\}, such that ğ”¼râ€‹[Eâ€‹(x,r)â€ â€‹Mfâ€‹(xS),rSâ€‹Eâ€‹(x,r)]â‰¥12+12â€‹Îµsubscriptğ”¼ğ‘Ÿdelimited-[]ğ¸superscriptğ‘¥ğ‘Ÿâ€ subscriptsuperscriptğ‘€ğ‘†ğ‘“subscriptğ‘¥ğ‘†ğ‘Ÿğ¸ğ‘¥ğ‘Ÿ1212ğœ€\\mathbb{E}_{r}[E(x,r)^{\\dagger}M^{S}_{f(x_{S}),r}E(x,r)]\\geq\\frac{1}{2}+\\frac{1}{2}\\varepsilon for all xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n}. Similarly, we define nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-EARAC, the fğ‘“f-entanglement-assisted random access code on mğ‘šm bits with bias Îµğœ€\\varepsilon. An nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-EARAC is an nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-RAC with SR where the encoding and decoding parties share an unlimited amount of entangled quantum states. Due to shared entanglement being a source of SR, we already include SR in fğ‘“f-EARACs. We note thatÂ  focused on EARACs without SR. Finally, we define nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-PRRAC, the fğ‘“f-Popescu-Rohrlich random access code on mğ‘šm bits with bias Îµğœ€\\varepsilon. A Popescu-Rohrlich boxÂ  is a bipartite system shared by two parties with two inputs x,yâˆˆ{0,1}ğ‘¥ğ‘¦01x,y\\in\\{0,1\\} and two outputs a,bâˆˆ{0,1}ğ‘ğ‘01a,b\\in\\{0,1\\} and is defined by the joint probability distribution An nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-PRRAC is an nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-RAC with SR where the encoding and decoding parties share an unlimited amount of Popescu-Rohrlich boxes. In SectionÂ 3 we devise encoding-decoding strategies for all the fğ‘“f-random access codes just defined, thus deriving lower bounds on their biases given the encoding/decoding parameters n,mğ‘›ğ‘šn,m and kğ‘˜k. These fğ‘“f-random access codes are built based on previous ideas fromÂ [ref]5  . The Boolean function f:{âˆ’1,1}kâ†’{âˆ’1,1}:ğ‘“â†’superscript11ğ‘˜11f:\\{-1,1\\}^{k}\\to\\{-1,1\\} that needs to be evaluated directly influences the final bias and such influence in our results is captured by the single quantity called noise stabilityÂ  5. Informally it is a measure of how resilient to noise a Boolean function is. Given a uniformly random input xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n}, one might imagine a process that flips each bit of xğ‘¥x independently with some probability 12âˆ’12â€‹q1212ğ‘\\frac{1}{2}-\\frac{1}{2}q, where qâˆˆ[âˆ’1,1]ğ‘11q\\in[-1,1], which leads to some final string yâˆˆ{âˆ’1,1}nğ‘¦superscript11ğ‘›y\\in\\{-1,1\\}^{n}. The noise stability Stabqâ¡[f]subscriptStabğ‘ğ‘“\\operatorname{Stab}_{q}[f] of fğ‘“f with parameter qğ‘q is the correlation between fâ€‹(x)ğ‘“ğ‘¥f(x) and fâ€‹(y)ğ‘“ğ‘¦f(y) (see SectionÂ 2 for a formal definition). Our positive results can be summarized by the following theorem. Let f:{âˆ’1,1}kâ†’{âˆ’1,1}:ğ‘“â†’superscript11ğ‘˜11f:\\{-1,1\\}^{k}\\to\\{-1,1\\} be a Boolean function and Stabqâ¡[f]subscriptStabğ‘ğ‘“\\operatorname{Stab}_{q}[f] its noise stability with parameter qğ‘q. Let â„“âˆˆâ„•â„“â„•\\ell\\in\\mathbb{N}. If m=Î©â€‹(â„“â€‹logâ¡n)ğ‘šÎ©â„“ğ‘›m=\\Omega(\\ell\\log{n}) and k=oâ€‹(â„“)ğ‘˜ğ‘œâ„“k=o(\\sqrt{\\ell}), there is an nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-RAC with PR and bias Îµâ‰¥(1âˆ’onâ€‹(1))â€‹Stabqâ¡[f]ğœ€1subscriptğ‘œğ‘›1subscriptStabğ‘ğ‘“\\varepsilon\\geq(1-o_{n}(1))\\operatorname{Stab}_{q}[f] with qâ‰¥mnâˆ’5â€‹log2â¡(n/â„“)n/â„“ğ‘ğ‘šğ‘›5subscript2ğ‘›â„“ğ‘›â„“q\\geq\\sqrt{\\frac{m}{n}-\\frac{5\\log_{2}{(n/\\ell)}}{n/\\ell}}. If k=oâ€‹(m)ğ‘˜ğ‘œğ‘šk=o(\\sqrt{m}), there is an nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-RAC with SR and Îµâ‰¥(1âˆ’onâ€‹(1))â€‹Stabqâ¡[f]ğœ€1subscriptğ‘œğ‘›1subscriptStabğ‘ğ‘“\\varepsilon\\geq(1-o_{n}(1))\\operatorname{Stab}_{q}[f] with qâ‰¥m2â€‹nğ‘ğ‘š2ğ‘›q\\geq\\sqrt{\\frac{m}{2n}}. If k=oâ€‹(m)ğ‘˜ğ‘œğ‘šk=o(\\sqrt{m}), there is an nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-QRAC with SR and Îµâ‰¥(1âˆ’onâ€‹(1))â€‹Stabqâ¡[f]ğœ€1subscriptğ‘œğ‘›1subscriptStabğ‘ğ‘“\\varepsilon\\geq(1-o_{n}(1))\\operatorname{Stab}_{q}[f] with qâ‰¥8â€‹m3â€‹Ï€â€‹nğ‘8ğ‘š3ğœ‹ğ‘›q\\geq\\sqrt{\\frac{8m}{3\\pi n}}. If k=oâ€‹(m)ğ‘˜ğ‘œğ‘šk=o(\\sqrt{m}), there is an nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-EARAC with Îµâ‰¥(1âˆ’onâ€‹(1))â€‹Stabqâ¡[f]ğœ€1subscriptğ‘œğ‘›1subscriptStabğ‘ğ‘“\\varepsilon\\geq(1-o_{n}(1))\\operatorname{Stab}_{q}[f] and q=mnğ‘ğ‘šğ‘›q=\\sqrt{\\frac{m}{n}}. For any nâˆˆâ„•ğ‘›â„•n\\in\\mathbb{N}, there is an nâ€‹â†¦1â€‹1ğ‘›1maps-to1n\\overset{1}{\\mapsto}1 fğ‘“f-PRRAC. Results (a), (b), (c) and (d) use an encoding scheme reminiscent of the concatenation idea from 9   (and suggested to us by Ronald de Wolf). The underlying idea is to randomly break the initial string xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n} into different â€˜blocksâ€™ and encode them via a standard RAC/QRAC/EARAC. Result (a) breaks xğ‘¥x into â„“â„“\\ell blocks and employs the n/â„“â†¦m/â„“maps-toğ‘›â„“ğ‘šâ„“n/\\ell\\mapsto m/\\ell RAC from TheoremÂ 2 on every block, each with n/â„“ğ‘›â„“n/\\ell elements, while in results (b)/(c)/(d) we employ the n/mâ†¦1maps-toğ‘›ğ‘š1n/m\\mapsto 1 RAC/QRAC/EARAC from TheoremsÂ 1/3/5 in order to encode mğ‘šm blocks, each with n/mğ‘›ğ‘šn/m elements, into a single (qu)bit each, resulting in mğ‘šm encoded (qu)bits. With high probability all the bits from the needed string xSâˆˆ{âˆ’1,1}ksubscriptğ‘¥ğ‘†superscript11ğ‘˜x_{S}\\in\\{-1,1\\}^{k} will be encoded into different blocks and therefore can be decoded and fğ‘“f evaluated. The decoded string yâˆˆ{âˆ’1,1}kğ‘¦superscript11ğ‘˜y\\in\\{-1,1\\}^{k} can be viewed as a â€˜noisyâ€™ xSsubscriptğ‘¥ğ‘†x_{S}, to which the noise stability framework can be applied. The bias of the base RAC/QRAC/EARAC thus becomes the parameter qğ‘q in the noise stability of the corresponding fğ‘“f-random access code. As a quick remark, since we opted to lower-bound the parameters qğ‘q in TheoremÂ 12, in resultÂ (b) qğ‘q does not exactly equal the bias from TheoremÂ 1. One could write, though, qâ‰ˆ2â€‹mÏ€â€‹nğ‘2ğ‘šğœ‹ğ‘›q\\approx\\sqrt{\\frac{2m}{\\pi n}}. Result (a) is our strongest bound, since it also applies to all other fğ‘“f-random access codes. Moreover, there is some freedom in setting the number of blocks â„“â„“\\ell, since the number of encoded bits in TheoremÂ 2 is not fixed to a single number (as opposed to TheoremsÂ 1,Â 3 andÂ 5). The result is a trade-off between the number of bits kğ‘˜k of the Boolean function and the number of encoded bits mğ‘šm. However, the number of encoded bits in result (a) is limited to m=Î©â€‹(logâ¡n)ğ‘šÎ©ğ‘›m=\\Omega(\\log{n}), a characteristic inherited from the RAC in TheoremÂ 2. It is possible to go below this limit by using SR, as demonstrated by results (b), (c) and (d). The above results show that quantum resources offer a modest advantage over the classical fğ‘“f-random access code. On the other hand, result (e) demonstrates that stronger-than-quantum resources like Popescu-Rohrlich boxes can lead to extremely powerful fğ‘“f-random access codes. This is a consequence of violating Information CausalityÂ 9, since one bit transfer allows the access to any bit in a database via Popescu-Rohrlich boxes. From xâˆˆ{âˆ’1,1}nğ‘¥superscript11ğ‘›x\\in\\{-1,1\\}^{n} a long bit-string xfâˆˆ{âˆ’1,1}tsubscriptğ‘¥ğ‘“superscript11ğ‘¡x_{f}\\in\\{-1,1\\}^{t}, where t=|ğ’®nk|ğ‘¡superscriptsubscriptğ’®ğ‘›ğ‘˜t=|\\mathcal{S}_{n}^{k}|, can be constructed with the values fâ€‹(xS)ğ‘“subscriptğ‘¥ğ‘†f(x_{S}) for all Sâˆˆğ’®nkğ‘†superscriptsubscriptğ’®ğ‘›ğ‘˜S\\in\\mathcal{S}_{n}^{k}. All bits from xfsubscriptğ‘¥ğ‘“x_{f} are readable with the aid of Popescu-Rohrlich boxes, with non-signaling constraining the readout to just one bit. The protocol for fğ‘“f-PRRACs is taken fromÂ 9 and uses a pyramid of Popescu-Rohrlich boxes and nests a van Damâ€™s protocolÂ . In SectionÂ 4 we prove an upper bound on the bias of any fğ‘“f-QRAC with SR (and fğ‘“f-RAC) using the same method of the hypercontractive inequality for matrix-valued functions fromÂ . Let f:{âˆ’1,1}kâ†’{âˆ’1,1}:ğ‘“â†’superscript11ğ‘˜11f:\\{-1,1\\}^{k}\\to\\{-1,1\\} be a Boolean function. For any nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-QRAC with SR and k=oâ€‹(n)ğ‘˜ğ‘œğ‘›k=o(n) the following holds: for any Î·>2â€‹lnâ¡2ğœ‚22\\eta>2\\ln{2} there is a constant CÎ·subscriptğ¶ğœ‚C_{\\eta} such that where L1,â„“â€‹(f)=âˆ‘TâŠ†[k]|T|=â„“|f^â€‹(T)|subscriptğ¿1â„“ğ‘“subscriptğ‘‡delimited-[]ğ‘˜ğ‘‡â„“^ğ‘“ğ‘‡L_{1,\\ell}(f)=\\sum_{\\begin{subarray}{c}T\\subseteq[k]\\\\\n|T|=\\ell\\end{subarray}}\\big{|}\\widehat{f}(T)\\big{|} is the 111-norm of the â„“â„“\\ell-th level of the Fourier transform of fğ‘“f. One can see that the above result is a generalization of TheoremÂ 4. Indeed, for Parity on kğ‘˜k bits, L1,â„“â€‹(XORk)=1subscriptğ¿1â„“subscriptXORğ‘˜1L_{1,\\ell}(\\operatorname{XOR}_{k})=1 iff â„“=kâ„“ğ‘˜\\ell=k, and so Eq.Â (1) is recovered. The following corollary from TheoremÂ 13 helps to compare the bias upper bound to the bias lower bounds from TheoremÂ 12. Let f:{âˆ’1,1}kâ†’{âˆ’1,1}:ğ‘“â†’superscript11ğ‘˜11f:\\{-1,1\\}^{k}\\to\\{-1,1\\} be a Boolean function. For any nâ€‹â†¦ğœ€â€‹mğ‘›ğœ€maps-toğ‘šn\\overset{\\varepsilon}{\\mapsto}m fğ‘“f-QRAC with SR and k=oâ€‹(n)ğ‘˜ğ‘œğ‘›k=o(n) the following holds: for any Î·>2â€‹lnâ¡2ğœ‚22\\eta>2\\ln{2} there is a constant CÎ·subscriptğ¶ğœ‚C_{\\eta} such that where degâ¡(f)=maxâ¡{|S|:f^â€‹(S)â‰ 0}degğ‘“:ğ‘†^ğ‘“ğ‘†0\\operatorname{deg}(f)=\\max\\{|S|:\\widehat{f}(S)\\neq 0\\} is the degree of fğ‘“f and q=Î·â€‹mnğ‘ğœ‚ğ‘šğ‘›q=\\sqrt{\\frac{\\eta m}{n}}. Taking degâ¡(f)degğ‘“\\operatorname{deg}(f) to be upper-bounded by a constant (for example, if k=Oâ€‹(1)ğ‘˜ğ‘‚1k=O(1)), our bias upper bound matches our bias lower bounds for fğ‘“f-RAC/QRAC with SR up to a global multiplicative constant and a multiplicative constant Î·ğœ‚\\sqrt{\\eta} in the parameterÂ qğ‘q. We conjecture that the parameter qğ‘q can be improved to mnğ‘šğ‘›\\sqrt{\\frac{m}{n}}, which might require a stronger version of the hypercontractive inequality.\nOther corollaries from TheoremÂ 13 are derived in SectionÂ 4 and compared to our bias lower bounds. Upper boundÂ (2) does not apply to fğ‘“f-EARACs. Previously, it was known that for the special case of standard EARACs (m=1ğ‘š1m=1), the bias Îµğœ€\\varepsilon is upper-bounded by 1/n1ğ‘›1/\\sqrt{n} (TheoremÂ 5). This upper bound can generalised to EARACs with m>1ğ‘š1m>1 assuming an independence condition (SectionÂ 3.4). The resulting bound is Îµâ‰¤m/nğœ€ğ‘šğ‘›\\varepsilon\\leq\\sqrt{m/n}. We view this as evidence that the bias lower bound for the general case of fğ‘“f-EARACs given in TheoremÂ 12 should actually be tight. Regarding the quantity Stabqâ¡[f]subscriptStabğ‘ğ‘“\\operatorname{Stab}_{q}[f] itself, it can be nicely related to the Fourier coefficients of fğ‘“f (see TheoremÂ 17 in the next section). We briefly mention the noise stability for a few functions. For Parity (XORksubscriptXORğ‘˜\\operatorname{XOR}_{k}), Stabqâ¡[XORk]=qksubscriptStabğ‘subscriptXORğ‘˜superscriptğ‘ğ‘˜\\operatorname{Stab}_{q}[\\operatorname{XOR}_{k}]=q^{k}, and, more generally, for any function Ï‡Sâ€‹(x)=âˆiâˆˆSxisubscriptğœ’ğ‘†ğ‘¥subscriptproductğ‘–ğ‘†subscriptğ‘¥ğ‘–\\chi_{S}(x)=\\prod_{i\\in S}x_{i}, Stabqâ¡[Ï‡S]=q|S|subscriptStabğ‘subscriptğœ’ğ‘†superscriptğ‘ğ‘†\\operatorname{Stab}_{q}[\\chi_{S}]=q^{|S|}. As for the Majority function (MAJksubscriptMAJğ‘˜\\operatorname{MAJ}_{k}), one can show thatÂ [46, TheoremÂ 5.18] 2Ï€â€‹arcsinâ¡qâ‰¤Stabqâ¡[MAJk]â‰¤2Ï€â€‹arcsinâ¡q+Oâ€‹(11âˆ’q2â€‹k)2ğœ‹ğ‘subscriptStabğ‘subscriptMAJğ‘˜2ğœ‹ğ‘ğ‘‚11superscriptğ‘2ğ‘˜\\frac{2}{\\pi}\\arcsin{q}\\leq\\operatorname{Stab}_{q}[\\operatorname{MAJ}_{k}]\\leq\\frac{2}{\\pi}\\arcsin{q}+O\\left(\\frac{1}{\\sqrt{1-q^{2}}\\sqrt{k}}\\right). Other examples can be found inÂ 1. Moreover, a randomized algorithm for approximating the noise stability of monotone Boolean functions up to relative error was proposed inÂ . In SectionÂ 3 we present protocols for all our fğ‘“f-random access codes, and in SectionÂ 4 we derive an upper bound on the bias of fğ‘“f-QRACs with SR.\n\nReference markers found: [5]\n\nContext windows for each [ref]:\n[ref]5: access codes just defined, thus deriving lower bounds on their biases given the encoding/decoding parameters n,mğ‘›ğ‘šn,m and kğ‘˜k. These fğ‘“f-random access codes are built based on previous ideas fromÂ [ref]5  . The Boolean function f:{âˆ’1,1}kâ†’{âˆ’1,1}:ğ‘“â†’superscript11ğ‘˜11f:\\{-1,1\\}^{k}\\to\\{-1,1\\} that needs to be evaluated directly influences the final bias and such influence in our results is captured\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 5,\n            \"titles\": [\n                \"Optimal Classical Random Access Codes Using Single ğ‘‘-level Systems\",\n                \"The learnability of quantum states\",\n                \"Certifying an irreducible 1024-dimensional photonic state using refined dimension witnesses\",\n                \"Experimental tests of classical and quantum dimensionality\",\n                \"Dense quantum coding and a lower bound for 1-way quantum automata\",\n                \"Quantum random access codes with shared randomness\",\n                \"Parity Oblivious ğ‘‘-Level Random Access Codes and Class of Noncontextuality Inequalities\",\n                \"A hypercontractive inequality for matrix-valued functions with applications to quantum computing and LDCs\",\n                \"Noise sensitivity of Boolean functions and applications to percolation\",\n                \"Communication complexity lower bounds by polynomials\",\n                \"The exponential complexity of satisfiability problems\",\n                \"Extrema of discrete Wigner functions and applications\",\n                \"Optimal bounds for parity-oblivious random access codes\",\n                \"A nonconstructive upper bound on covering radius\",\n                \"On Krawtchouk polynomials\",\n                \"Implausible consequences of superstrong nonlocality\",\n                \"Asymptotic analysis of the Krawtchouk polynomials by the WKB method\",\n                \"Quantum advantage in information retrieval\",\n                \"Self-testing mutually unbiased bases in the prepare-and-measure scenario\",\n                \"Self-testing mutually unbiased bases in higher dimensions with space-division multiplexing optical fiber technology\",\n                \"Experimental demonstration of sequential quantum random access codes\",\n                \"Bounded-error quantum state identification and exponential separations in communication complexity\",\n                \"When are Popescu-Rohrlich boxes and random access codes equivalent?\",\n                \"Nonsignaling quantum random access-code boxes\",\n                \"Complementarity between entanglement-assisted and quantum distributed random access code\",\n                \"(4, 1)-quantum random access coding does not existâ€”one qubit is not enough to recover one of four bits\",\n                \"Quantum network coding\",\n                \"Quantum detection and estimation theory, volume 3\",\n                \"Bounds for the quantity of information transmitted by a quantum communication channel\",\n                \"Random walks and random environments: random walks, volume 1\",\n                \"Constructions of quantum random access codes\",\n                \"Unbounded-error one-way classical and quantum communication complexity\",\n                \"Quantum encodings and applications to locally decodable codes and communication complexity\",\n                \"Exponential lower bound for 2-query locally decodable codes via a quantum argument\",\n                \"On quantum and probabilistic communication: Las Vegas and one-way protocols\",\n                \"One-way communication complexity and the NeÄiporuk lower bound on formula size\",\n                \"Communication Complexity\",\n                \"Semi-device-independent random-number expansion without entanglement\",\n                \"Improved classical and quantum random access codes\",\n                \"The theory of error correcting codes, volume 16\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]5 based on the context and research area of Quantum Random Access Codes for Boolean Functions. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}