{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Point-based Value Iteration for Neuro-Symbolic POMDPs\n\nPaper Abstract: \n\nPaper Section Text:\nAn emerging trend in artificial intelligence is to integrate traditional symbolic techniques with data-driven components in sequential decision making and optimal control. Application domains include mobile robotics , visual reasoning [ref]2, autonomous driving  and aircraft control . In real-world autonomous navigation systems, agents rely on unreliable sensors to perceive the environment, typically represented using continuous-state spaces, and planning and control must deal with environmental uncertainty. Neural networks (NNs) have proven effective in these complex settings at providing fast data-driven perception mechanisms capable of performing tasks such as object detection or localisation, and are increasingly often deployed in conjunction with conventional controllers. Because of the potential applicability in safety-critical domains, there is growing interest in methodologies for automated optimal policy synthesis for such neuro-symbolic systems, which are currently lacking. Partially observable Markov decision processes (POMDPs) provide a convenient mathematical framework to plan under uncertainty. Solving POMDPs in a scalable and efficient manner is already challenging for finite-state models¬† , but significant progress has been made, e.g., through point-based methods¬†, which extend the classic value iteration algorithm for MDPs by applying it to a selected set of belief states of the POMDP.\nTypically, a belief state is a distribution over the states of the model\nrepresenting an agent‚Äôs knowledge about the current state. Since the resulting belief MDP is infinite-state, conventional value iteration cannot be directly applied and instead point-based methods rely on a so-called Œ±ùõº\\alpha-vector parameterisation, a linear function characterised by its values in the vertices of the belief simplex, which is finitely representable since the value function is piecewise linear and convex. Compared to finite-state POMDPs, solving continuous-state POMDPs suffers from additional challenges due to the uncountably infinite underlying state space. The common approach to discretise or approximate the continuous components with a grid and use methods for finite-state POMDPs may compromise accuracy and lead to an exponential growth in the number of states. Refinement of the discretization to improve accuracy further increases computational complexity. Therefore, an important research direction is to instead consider POMDP solution techniques that operate directly in continuous domains. Additionally, belief spaces for continuous-state POMDPs have infinitely many dimensions, which further complicates the problem. Since functions over continuous spaces can have arbitrary forms\nnot amenable to computation, a key challenge is finding an efficient representation of the value function that allows closed-form belief updates and Bellman backups for the underlying (parameterisable) transition and reward functions. This problem was addressed by Porta et al in¬†[ref]8, where it was proved that continuous-state POMDPs with discrete observations and actions have a piecewise linear and convex value function and admit a finite representation in terms of so-called Œ±ùõº\\alpha-functions, which generalise Œ±ùõº\\alpha-vectors by replacing weighted summation with integration. Working with a representation in terms of linear combinations of Gaussian mixtures, they derive point-based value iteration and implement it by randomly sampling belief points to approximate the value function. In this paper, we address the problem of optimal policy synthesis for discounted cumulative rewards on a subclass of continuous-state POMDPs with discrete observations and actions, called neuro-symbolic POMDPs (NS-POMDPs), whose transition and reward functions are symbolic while observation functions are synthesised in a data-driven fashion, e.g., by means of NNs. The strengths of NNs include trainability from data and fast inference for complex scenarios (e.g., object detection and recognition), while symbolic approaches can provide high interpretability, provable correctness guarantees and ease of inserting human expert knowledge into the underlying systems¬†. Our model is expressive enough for realistic perception functions, while being sufficiently tractable to solve. Working directly with continuous state spaces rather than a discretisation, we propose novel finite representations of the value function inspired by the Œ±ùõº\\alpha-functions of¬†[ref]8, prove convergence and continuity of the value function, and present two algorithms for this representation, the classical value iteration (VI), and a variant of the HSVI (Heuristic Search Value Iteration) algorithm 0.\nOur first main contribution is demonstrating that, by exploiting the structure of NS-POMDPs, one can indeed find\nan Œ±ùõº\\alpha-function representation, namely piecewise linear and convex representation under piecewise constant Œ±ùõº\\alpha-functions (P-PWLC), that has a simple parameterisation and is closed with respect to belief updates and the Bellman operator. More specifically, we show that value functions can be represented using pointwise maxima of piecewise constant Œ±ùõº\\alpha-functions (a finite set of polyhedra and a value vector), which can be obtained directly as the preimage of the (NN) perception function, in conjunction with mild assumptions that ensure closure with respect to the transition and reward functions of NS-POMDPs. In contrast to¬†[ref]8, where Gaussian mixtures are used to represent Œ±ùõº\\alpha-, transitions and reward functions, thus possibly requiring approximation of NS-POMDPs, our representation closely matches the structure of NS-POMDPs, even with NN perception functions. Since Œ±ùõº\\alpha-functions for VI increase exponentially in the number of observations, our second main contribution is a continuous-state space variant of HSVI, called NS-HSVI, for scalable computation of approximate value function from below and above.\nStarting with the polyhedral preimage of the model‚Äôs NN perception function, NS-HSVI works by progressively subdividing the continuous state space during value backups to compute lower bounds, and is able to track the evolution of the system without requiring a priori knowledge about how to discretise the state space. We use a lower KùêæK-Lipschitz envelope of a convex hull to approximate an upper bound. We formulate two representations of the belief space, which have closed forms for the quantities of interest: particle-based, which relies on sampling of individual points, and region-based, which places a (uniform) distribution over a region of continuous space. We develop a prototype implementation of the techniques and provide experimental results for strategy (policy) synthesis for particle- and region-based beliefs on two case studies: dynamic car parking and an aircraft collision avoidance system. We find that region-based values are more robust to disturbance than particle-based. We also compare our particle-based NS-HSVI to a finite-state POMDP approximation of an NS-POMDP model using SARSOP, and observe that our method consistently yields tighter lower bound values, at a higher computational cost due to expensive polyhedra computations, because the accuracy of SARSOP‚Äôs lower bound depends on the length of the horizon considered when building the model. Contributions.\nIn summary, this paper makes the following contributions. We propose neuro-symbolic POMDPs (NS-POMDPs), a subclass of continuous-state POMDPs with discrete observations and actions, whose observation functions are synthesised in a data-driven fashion. We propose a novel piecewise constant Œ±ùõº\\alpha-function representation of the value function (as a pointwise maximum function over a set of piecewise constant Œ±ùõº\\alpha-functions defined over the continuous-state space). We show that this representation admits a finite polyhedral representation and is closed with respect to the Bellman operator. We prove continuity and convexity of the value function for discounted cumulative rewards and derive a value iteration (VI) algorithm. We present a new point-based method called NS-HSVI for approximating values of NS-POMDPs, proving that\npiecewise constant Œ±ùõº\\alpha-functions\nare a suitable representation for lower bound approximations of values. We develop two variants of the algorithm, one based on the popular particle-based beliefs and the other on novel region-based beliefs, and show they have closed forms for computing the quantities of interest. We provide experimental results to demonstrate the applicability of NS-HSVI in practice for neural networks whose preimage (or that of their approximation) is in polyhedral form. Related work.\nVarious approaches have been proposed to solve continuous-state POMDPs, including point-based value iteration [ref]8 1 2, simulation-based policy iteration 3, discrete space approximation 4, locally-valid approximation 5 and tree search planning 6. However, these approaches focus on traditional symbolic systems and, while extended to continuous transitions via sampling¬†[ref]8, they are not adapted to data-driven perception functions. HSVI is a point-based value iteration for finite-state POMDPs 0 7, which was recently extended to stochastic games 8 and works in the continuous belief space, but, to the best our knowledge, has not been applied to continuous-state POMDPs. Approaches based on discretisation suffer from loss of accuracy and exponential growth in the number of states and the finite horizon.\nThe point-based methods of¬†[ref]8 1 2 use Œ±ùõº\\alpha-functions, which is similar to our approach, but they represent value functions as Gaussian mixtures or dynamic Bayes nets, which may result in looser approximation for NNs than our polyhedral representation.\nThis is because our P-PWLC representation exploits the underlying piecewise constant structure of the continuous-state model and the neural perception mechanism (for which the value function may not be piecewise constant). While our VI and NS-HSVI algorithms work directly in the continuous state space of the POMDP, most existing approaches rely on constructing a finite-state POMDP to approximate the continuous-state POMDP and then solving the finite-state model. PBVI 9 was the first point-based algorithm to demonstrate good performance on large POMDPs. HSVI 0 7 uses effective heuristics to guide the forward exploration towards beliefs that significantly reduce the gap between the upper and lower bounds on the optimal value function. FSVI , also a point-based value iteration method, explores the belief space by maintaining the true states, using the optimal value function of the underlying MDP to decide which action to take and then sampling the next states and observations. SARSOP , one of the fastest existing point-based algorithms, first approximates the optimally reachable belief space in each iteration by sampling a belief according to its stored lower and upper bound functions, then performs backups at selected nodes in the belief tree and finally prunes the Œ±ùõº\\alpha-vectors that are dominated by others over a neighbourhood of the belief tree. Formal verification approaches for neuro-symbolic systems have been developed for the non-stochastic case¬† and for stochastic multi-agent systems¬†   but under full observability. When the controller is data-driven which is a counterpart to the neural perception, the risk of the closed-loop stochastic systems is verified in . Verified NN-based POMDP policies are synthesised in , though only for the finite-state setting. Our focus in this paper is on optimal policy synthesis for neuro-symbolic systems, motivated by the need for such guarantees in safety-critical domains.\nTo the best of our knowledge, our approach is the first value computation method for partially observable continuous-state neuro-symbolic systems. Structure of the paper.\nThe remainder of the paper is structured as follows. Section¬†2 overviews the preliminaries of the POMDP framework. Section¬†3 proposes our model of neuro-symbolic POMDPs, together with its belief MDP, and gives an illustrative example. Section 4 introduces piecewise constant representations for functions in NS-POMDPs, and shows that they have a finite representation (P-PWLC) that ensures closure under the Bellman operator. A new value iteration (VI) algorithm is also proposed, and we prove the convexity and continuity of the value function. Section 5 presents a new HSVI algorithm for NS-POMDPs, which uses P-PWLC functions and belief-value induced functions to approximate the value function from below and above, and considers two belief representations for the implementation. Section 6 presents a prototype implementation and experimental\nevaluation of our algorithm for solving and optimal strategy synthesis for NS-POMDPs on two case studies. Section 7 concludes the paper. To ease presentation, proofs of the theorems and lemmas have been placed in the Appendix.\n\nReference markers found: [2]\n\nContext windows for each [ref]:\n[ref]2: is to integrate traditional symbolic techniques with data-driven components in sequential decision making and optimal control. Application domains include mobile robotics , visual reasoning [ref]2, autonomous driving  and aircraft control . In real-world autonomous navigation systems, agents rely on unreliable sensors to perceive the environment, typically represented using\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 2,\n            \"titles\": [\n                \"Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving\",\n                \"Cooperative multi-agent control using deep reinforcement learning\",\n                \"Neuro-symbolic visual reasoning: Disentangling\",\n                \"Verifying Strategic Abilities of Neural-symbolic Multi-agent Systems\",\n                \"The complexity of Markov decision processes\",\n                \"Optimal cost almost-sure reachability in POMDPs\",\n                \"A survey of point-based POMDP solvers\",\n                \"Point-based value iteration for continuous POMDPs\",\n                \"Neuro-Symbolic Artificial Intelligence\",\n                \"Heuristic search value iteration for POMDPs\",\n                \"Optimal continuous state POMDP planning with semantic observations: A variational approach\",\n                \"Symbolic dynamic programming for continuous state and observation POMDPs\",\n                \"Observation-based optimization for POMDPs with continuous state, observation, and action spaces\",\n                \"Solving continuous POMDPs: Value iteration with incremental learning of an efficient space representation\",\n                \"Efficient approximate value iteration for continuous gaussian POMDPs\",\n                \"Voronoi Progressive Widening: Efficient Online Solvers for Continuous State, Action, and Observation POMDPs\",\n                \"Point-based POMDP algorithms: Improved analysis and implementation\",\n                \"Solving Zero-Sum One-Sided Partially Observable Stochastic Games\",\n                \"Point-based value iteration: An anytime algorithm for POMDPs\",\n                \"Forward search value iteration for pomdps.\",\n                \"SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces.\",\n                \"Finite-horizon Equilibria for Neuro-symbolic Concurrent Stochastic Games\",\n                \"Strategy Synthesis for Zero-Sum Neuro-Symbolic Concurrent Stochastic Games\",\n                \"Probabilistic Model Checking for Strategic Equilibria-Based Decision Making: Advances and Challenges\",\n                \"Risk verification of stochastic systems with neural network controllers\",\n                \"Verifiable RNN-based policies for POMDPs under temporal logic constraints\",\n                \"Dynamic programming and optimal control: Volume I\",\n                \"Planning and acting in partially observable stochastic domains\",\n                \"A Reachability Method for Verifying Dynamical Systems with Deep Neural Network Controllers\",\n                \"Computing preimages of deep neural networks with applications to safety\",\n                \"The optimal control of partially observable Markov processes over the infinite horizon: Discounted costs\",\n                \"Goal-HSVI: Heuristic search value iteration for goal POMDPs\",\n                \"Probabilistic planning for robotic exploration\",\n                \"A survey of convergence results on particle filtering methods for practitioners\",\n                \"Sequential Monte Carlo methods in practice\",\n                \"Partially Observable Markov Decision Processes in Robotics: A Survey\",\n                \"Particle Filter Recurrent Neural Networks\",\n                \"On sequential Monte Carlo sampling methods for Bayesian filtering\",\n                \"Probability, random variables, and stochastic processes\",\n                \"The Parma Polyhedra Library: Toward a complete set of numerical abstractions for the analysis and verification of hardware and software systems\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]2 based on the context and research area of Point-based Value Iteration for Neuro-Symbolic POMDPs. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}