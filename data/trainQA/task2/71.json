{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Crowdsourcing the Perception of Machine Teaching\n\nPaper Abstract: \n\nPaper Section Text:\nWe explore how variation666A preliminary analysis of this appears in a work-in-progressÂ [ref]30., inconsistency, and other attributes manifest on participantsâ€™ image sets when they are first called to train the object recognizer on objects of their choice. Incorporating diversity in teaching. Diversity plays an important role in machine learningÂ . When incorporated in the teaching set, it ensures that examples can provide more discriminatory information to help the model learn. By looking at participantsâ€™ photos (results in FigureÂ 7) and by reading their responses, we find that the majority of the participants share this intuition, but not all. In detail, 23 participants (age 21â€“60, Î¼ğœ‡\\mu=37.57, Ïƒğœ\\sigma=9.87) did not include any kind of variation in their TR1 teaching set â€“ 3 of them reported never having heard of machine learning, 12 had heard of it but did not know what it does, and 8 had a broad understanding of what it is and what it does. Immediately after training, when asked about what they considered important, 5 participants referred to the need for consistency, which in this context contradicts the way machines and people learn. For instance, P6 said â€œI figured I needed to be consistent when I took the picture so they looked similar.â€ and P30 â€œKeeping the pictures the same.â€ Others, who did not consider this type of consistency, mentioned that it is important to have a good quality photo where the object is well framed (4) with visible labels (8) and images that are clear (6) with ample light (2). Without even having tested their model, P2 said: â€œGetting different angles and perspectives so the trainer could recognize it more easilyâ€ â€“ a contradiction to their initial teaching set that had no variation. We observed that in TR2, P2 reflected on this observation and varied both the object size and viewpoint. Only two other participants from this group did so as well, P5 and P18. They said having the â€œname and color inâ€ is important in TR1 but also varied the camera distance (P5) and angle (P18) in TR2. However, the majority of participants (N=77ğ‘77N=77) diversified examples in their first attempt. They varied either size (N=65ğ‘65N=65) or viewpoint (N=63ğ‘63N=63), with some considering location (N=39ğ‘39N=39) and illumination (N=19ğ‘19N=19). Light exposure was least diverse (N=4ğ‘4N=4). Looking at responses on important considerations for training, many participants (N=52ğ‘52N=52) mentioned these strategies777All questions, instructions, and prompts prior to training were carefully edited not to prime participants towards our coding attributes. and reflected on the need for diversity with concrete terms such as â€œdifferentâ€, â€œvariousâ€, â€œallâ€, â€œmanyâ€, â€œmultipleâ€, â€œeveryâ€, â€œvarietyâ€, and â€œdifferenceâ€ combined with â€œanglesâ€, â€œviewsâ€, â€œsidesâ€, â€œfacetsâ€, â€œbackgroundâ€, â€œlightingâ€, â€œdistanceâ€, and â€œpositioningâ€. These terms correspond to the four dimensions of our coding scheme informed from prior work on visual object understandingÂ , highlighting that humansâ€™ strategies for machine teaching parallel their own abilities. However, only 11 participants (age: Î¼=34,Ïƒ=8.71formulae-sequenceğœ‡34ğœ8.71\\mu=34,\\sigma=8.71) incorporated diversity in their teaching set across all four dimensions â€“ 3 reported having heard of machine learning with no further understanding, and 8 had a broad understanding of what it is and what it does. Being fair and consistent between classes. Model consistency across classes is a desirable trait in machine learning with many social implications for fairness, whose definition is still being debated in the community (e.g.,Â  ). There is anecdotal evidence on non-experts learning to balance class proportions in the training set over multiple iterationsÂ  . By keeping the number of training examples constant, we look into their behavior across other potential disparate treatments.\nGiven that many participants considered diversity important for good performance, we explore how fair888In this work classes are object instances that fall within the same category and consequently share similarities such as shape, size, and material in the context of the decision making task of incorporating variation. Thus, we consider â€œindividual fairnessâ€Â , where â€œsimilar individuals should be treated similarlyâ€, and explore whether object instances within a category are being treated the same by a participant when introducing variation in the training photos. (i.e., consistent) they are in incorporating diversity across their three objects, with results shown in FigureÂ 7. Beyond the 23 participants who did not introduce any variation for any object, we find that there were 30 other participants that were consistent. This is promising, especially since this included participants from all levels of familiarity with machine learning: not familiar at all (N=1ğ‘1N=1), slightly familiar (N=11ğ‘11N=11), somewhat familiar (N=17ğ‘17N=17), and the only participant in our study that reported being extremely familiar (N=1ğ‘1N=1). While none of these participants explicitly mentioned consistency as important, we find that more than half of them (N=16ğ‘16N=16) continued doing so in their second attempt at training, in TR2. For the remaining 47 participants, their inconsistencies were found in variations related to all four dimensions: object size (N=21ğ‘21N=21), viewpoint (N=31ğ‘31N=31), location (N=10ğ‘10N=10), and illumination (N=5ğ‘5N=5). Deciding what to show in the teaching set. We analyze the fine-grained count attributes in teaching and training sets (FigureÂ 8) to uncover common teaching patterns across participants. Khan et al.Â  observed that one of the most prominent teaching strategies for a binary classification task among non-experts, called the extreme strategy, is consistent with the â€œcurriculum learningâ€ principleÂ  , where participants start with the most extreme examples and continue with those closer to the decision boundary999In the Khan et al.Â  study participants did not generate the examples but they ordered them as most representative of the two classes and chose to teach one by one using all of them or a subset.. While our batch teaching task does not allow for a similar sequential analysis, we find that almost all participants (N=98ğ‘98N=98) included the logo (or label) of objects in their teaching sets; on average 84.9% (Sâ€‹D=25.0ğ‘†ğ·25.0SD=25.0) of any participantsâ€™ images included logos. This indicates that participants understand that logos and labels tend to include the most discriminatory features, which serve as the most extreme examples. Then, through variation they add less discriminative viewpoints that are closer to the decision boundary. Indeed, 18 participants explicitly mentioned logos or labels being important in training. For instance, P36 said â€œâ€¦ trying to have a constant label viewâ€ and P46 â€œâ€¦ a clear shot of the front of the package with minimal background interference.â€ When looking deeper at these responses though, we find that many of the participants assumed that the machine would read the text. For example, P28 said â€œIt [the model] recognizing the different cereals by nameâ€ and P44 â€œGetting a clear shot where the writing and the size are clear.â€ In terms of the background, we find that the majority were textured (N=66ğ‘66N=66) or cluttered (N=62ğ‘62N=62), while many used plain (N=48ğ‘48N=48) and a few none at all (N=11ğ‘11N=11) â€“ the latter two are preferred since very few varied the object location. We observe that 26 participants included their hands in the photos. The presence of hands has been leveraged to better distinguish objects by modeling the contextual relationship between grasp types and object attributesÂ  or to estimate the object of interest in a clutter environmentÂ  . However, given this studyâ€™s fine-grained task, the grasp is expected to be similar across object of the same category. Thus, the presence of the hand doesnâ€™t really help, especially if it is not applied consistently across classes. More surprisingly, we observe that 8 participants reshaped their objects, e.g., opened the lid, and 4 decided to train on the content of the object as well, e.g., cinnamon powder. When asked what is important for training, one of these participants, P76, said: â€œGetting lots of different angles and different ways the spice could be portrayed.â€ In general, there were not many photos with quality issues. Participants took clear photos in most cases and many of them mentioned the importance of image quality in their responses, but some (N=36ğ‘36N=36) mistakenly took a few blurry photos. Also, objects sometimes appeared too small (N=17ğ‘17N=17) and occasionally the light was dim (N=9ğ‘9N=9). Debugging and including edge cases in testing. When asked to evaluate their model in TS1, many participants (N=30ğ‘30N=30)\ndid not diversify their images at all â€“ 2 of them reported never having heard of machine learning, 17 had heard of it but didnâ€™t know what it does, and 11 had a broad understanding of what it is and what it does. This means that they did not check whether the recognizer is robust. We also find that compared to training, fewer participants diversify their testing set across object size (N=57ğ‘57N=57), viewpoint (N=49ğ‘49N=49), location (N=21ğ‘21N=21) and illumination (N=6ğ‘6N=6). This could be explained by many factors such as: smaller number of photos in testing (15) compared to training (90); difficulty in conceptualizing robustness; assumptions about machineâ€™s generalizing capabilities; not anticipating future uses of the model under different circumstances; or simply minimizing efforts for this HIT. Logos were still included by the majority of the participants (N=98ğ‘98N=98) and the same number of participants (N=11ğ‘11N=11) took photos that did not include any background, keeping their testing data consistent with their training examples. Similar to what Zimmermann et al.Â  observed, participants â€œenacted [testing] practices wherein their models appeared to have high reliability but questionable validity.â€ We also find that participants took fewer photos with plain background (W=756ğ‘Š756W=756, Z=2.17ğ‘2.17Z=2.17, p=.030ğ‘.030p=.030, r=0.15ğ‘Ÿ0.15r=0.15), and objects that were too small (W=126.5ğ‘Š126.5W=126.5, Z=2.61ğ‘2.61Z=2.61, p=.011ğ‘.011p=.011, r=0.18ğ‘Ÿ0.18r=0.18) using a Wilcoxon signed rank test. None of the interesting object reshaping, or content images present in training, carried over to testing; a similar behavior to Kacorri et al.Â , with â€œexaggeratedâ€ variation in training unobserved in testing.\n\nReference markers found: [30]\n\nContext windows for each [ref]:\n[ref]30: We explore how variation666A preliminary analysis of this appears in a work-in-progressÂ [ref]30., inconsistency, and other attributes manifest on participantsâ€™ image sets when they are first called to train the object recognizer on objects of their choice. Incorporating diversity in\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 30,\n            \"titles\": [\n                \"Becoming the Expert - Interactive Multi-Class Machine Teaching\",\n                \"Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda\",\n                \"A new look at the statistical model identification\",\n                \"Power to the People: The Role of Humans in Interactive Machine Learning\",\n                \"Guidelines for Human-AI Interaction\",\n                \"Machine bias: Thereâ€™s software used across the country to predict future criminals. And itâ€™s biased against blacks\",\n                \"Browsable Web APIs for Flask\",\n                \"Big dataâ€™s disparate impact\",\n                \"Curriculum Learning\",\n                \"Critical Questions for Big Data\",\n                \"A Personalizable Mobile Sound Detector App Design for Deaf and Hard-of-Hearing Users\",\n                \"Using thematic analysis in psychology\",\n                \"Amazonâ€™s mechanical Turk: A new source of inexpensive, yet high-quality, data?\",\n                \"Understanding hand-object manipulation by modeling the contextual relationship between actions, grasp types and object attributes\",\n                \"AI Now 2017 Report\",\n                \"European Union General Data Protection Regulation (GDPR)\",\n                \"S.1108 - Algorithmic Accountability Act of 2019\",\n                \"Imagenet: A large-scale hierarchical image database\",\n                \"Algorithmic accountability reporting: On the investigation of black boxes\",\n                \"Teaching and learning of robot tasks via observation of human performance\",\n                \"Fairness through Awareness\",\n                \"Interactive Machine Learning\",\n                \"Human Model Evaluation in Interactive Supervised Learning\",\n                \"Diversity in Machine Learning\",\n                \"Explainable Artificial Intelligence (XAI)\",\n                \"A Data-Driven Analysis of Workersâ€™ Earnings on Amazon Mechanical Turk\",\n                \"Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design\",\n                \"Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes\",\n                \"Incentivizing High Quality Crowdwork\",\n                \"Exploring Machine Teaching for Object Recognition with the Crowd\",\n                \"Gesture imitation using machine learning techniques\",\n                \"Teachable Machines for Accessibility\",\n                \"Teachable machines for accessibility\",\n                \"People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges\",\n                \"How Do Humans Teach: On Curriculum Learning and Teaching Dimension\",\n                \"Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-User Expectations of AI Systems\",\n                \"Teachable machine\",\n                \"Revisiting Blind Photography in the Context of Teachable Object Recognizers\",\n                \"Hands Holding Clues for Object Recognition in Teachable Machines\",\n                \"Learning the easy things first: Self-paced visual category discovery\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]30 based on the context and research area of Crowdsourcing the Perception of Machine Teaching. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}