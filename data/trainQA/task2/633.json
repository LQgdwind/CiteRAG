{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Graph-Based Social Relation Reasoning\n\nPaper Abstract: \n\nPaper Section Text:\nComparisons with the State-of-the-Art Methods.\nWe compare the proposed approach with several existing state-of-the-art methods. The details of these competing methods are as follows: Finetuned CNN + SVM [ref]41. Double-stream CaffeNet is used to extract features, then the extracted features are utilized to train a linear SVM. All attributes + SVM [ref]41. Many semantic attribute categories including age, gender, location, and activity are used in this method. Then all attribute features are concatenated to train a linear SVM. Pair CNN [ref]20. This model consists of two CNNs (ResNet-101) with shared weights. The input is two cropped image patches for the two individuals and the extracted features are concatenated for social relation recognition. Dual-Glance [ref]20. Two cropped individual patches and the union region of them are sent to CNNs to extract features. The introduced second glance exploits surrounding proposals as contextual information to refine the predictions. SRG-GN . Five CNNs are utilized to extract scene and attribute context information (e.g., age, gender, and activity). Then these features are utilized to update the state of memory cells like GRUs. MGR [ref]49. It employ five CNNs to extract the global, middle, and fine granularity features to comprehensively capture the multi-granularity semantics. GRM . It replaces the second glance in Dual-Glance with a pre-trained Faster-RCNN detector  and a Gated Graph Neural Network  to model the interaction between the contextual objects and the persons of interest. All of the above methods are person pair-based, which means that they consider the social relations on the same image separately. It is worth noting that although the SRG-GN mentions that they can generate a social relationship graph, they actually still process each relationship independently during the training and testing phases. These methods usually crop the image patches for interested individuals and resize them to 224 ×\\times 224 pixels while our approach takes the entire image as input. In order to make a fair comparison, we should choose the appropriate entire input image size to ensure that the personal area of interest is roughly equal to 224 ×\\times 224. In the PIPA and PISC dataset, the area of the bounding boxes is on average 1/4 and 1/5 of the area of the images, respectively, so we resize the original image to 448 ×\\times 448 pixels, which is denoted as GR2N-448.\nAlthough this is still unfavorable to our approach on the PISC datasets, our method can still achieve promising performance.\nBesides, we also report the performance of GR2N-224 to show the effectiveness of our method, which resizes the original image to 224 ×\\times 224 pixels. The experimental results of social domain recognition and social relationship recognition on the PIPA database are shown in Table 1. We first compare our method with a simple baseline Pair CNN, which, like our method, does not use any scene and attribute context cues, so we can see the benefits brought by the paradigm shift. We observe that our method significantly outperforms Pair CNN. Specifically, the GR2N-448 achieves an accuracy of 64.3% for social relation recognition and 72.3% for social domain recognition, improving the Pair CNN by 6.3% and 6.4% respectively. What’s more, even the GR2N-224 with inferior input image size outperforms the Pair CNN by 3.3% and 3.4% for social relation recognition and social domain recognition respectively, which demonstrates that the paradigm shift and GR2N’s superior relational reasoning ability bring significant performance gains. Next, we compare our method with state-of-the-art methods. In terms of social relation recognition, the proposed GR2N-448 improves GRM by 2.0%. What is worth mentioning is that GRM uses three individual CNNs to extract features from four image patches including one 448 ×\\times 448 entire image and three 224 ×\\times 224 person patches to exploit key contextual cues, while the GR2N only uses one input image and one convolutional neural network. Our method also achieves competitive results with MGR whereas MGR uses 5 CNNs and 4 patches. For social domain recognition, our method GR2N-448 achieves an accuracy of 72.3%, which improves the performance of All attributes + SVM by 4.5% without using any semantic attribute categories.\nClearly, these results illustrate the superiority of our method. Table 2 shows the experimental comparison with the recent state-of-the-art methods on the PISC database. We observe that our method achieves an mAP of 83.1% for the coarse-level recognition and 72.7% for the fine-level recognition, improving the simple baseline Pair CNN by a large margin: 18.0% for coarse relationships and 24.5% for fine relationships, which further validates the advantage of the paradigm shift. Our approach outperforms SRG-GN by 1.1% with a much simpler framework (1 neural net vs. 5 neural nets, 1 image patch vs. 3 image patches). Compared with GRM, GR2N-448 achieves competitive performance for coarse relationship recognition and superior performance for fine relationship recognition with only one image patch and one neural net, while the GRM uses four image patches and three neural nets. It is worth noting that the experimental results of our approach on the PISC dataset are achieved with inferior input image size, which further illustrates the effectiveness of our GR2N. Runtime Analysis. In addition to being simpler and more accurate, another advantage of our GR2N is that it is faster. Since our method handles all relationships on an image at the same time, the GR2N is computationally efficient.\nWe conduct experiments under different batch sizes to compare the speed of different methods using a GeForce GTX 1080Ti GPU on the PIPA dataset. To be fair, the version of GR2N used here is GR2N-448.\nThe results of the forward runtime (seconds/image) are reported in Table 4. The * in the table represents memory overflow. Compared with Pair CNN, our method achieves about 2×2\\times speed-ups, which shows the benefits of the paradigm shift. The GR2N-448 is 4×∼7×4\\times\\sim 7\\times faster than the state-of-the-art method GRM, which further demonstrates the efficiency of our approach.\nSince the average number of bounding boxes per image on the PIPA datasets is only 2.5, we expect higher speedup when there are more individuals on an image. Ablation Study.\nTo validate the effectiveness of the proposed GR2N, we compare it with two commonly used GNN variants: GGNN  and GCN . To apply GGNN and GCN, we connect the nodes together into a fully connected graph. Following , we also add a residual connection in every layer of GCN, which observes an improvement in performance in the experiments. For a fair comparison, all three methods use an image of size 224 ×\\times 224 as input. The readout function of GGNN and GCN is a two-layer neural network and the edge embedding is obtained by concatenating the features of the corresponding two nodes. The cross-entropy loss function is used to train GGNN and GCN. The comparisons on the PIPA dataset by accuracy are listed in Table 4. We observe that our proposed GR2N outperforms GCN and GGNN, which demonstrates that the proposed GR2N effectively performs relational reasoning and exploits the strong logical constraints of social relations on the same image. On the other hand, all three methods adopt the image-based paradigm and we see that they all outperform Pair CNN. In fact, these three methods achieve superior or competitive performance compared with some of the state-of-the-art methods which adopt the person pair-based paradigm, such as Dual-Glance and SRG-GN. Note that these GNNs’ methods only use one input patch and one convolutional neural net, which illustrates the superiority of the image-based paradigm over the person pair-based paradigm. Qualitative Evaluation. In this part, we present some examples to illustrate how our GR2N improves performance by performing relational reasoning and exploiting the strong logical constraints of social relations on a graph in Fig. 2. For the first example, Pair CNN independently processes the relations on the image and predicts that the relation between B and C is friends. On the contrary, our method jointly infers all relations for each image. We easily infer that the relation between B and C is classmates when we know that the relation between A and B and the relation between A and C both are teacher-student. This is also the case in the rest of the examples. When the relationships on an image are processed independently, some obviously unreasonable and contradictory relationships may occur simultaneously, and our method is capable of correcting them through relational reasoning with a thorough understanding of the social scene.\nClearly, our method better models the interactions among people on the graph, and generates a reasonable and consistent social relation graph. We also present some failure cases in Fig. 3. We see that our method can not correct the prediction error in the first case since the error does not cause any obvious conflict. Although the ground truth of the relationship between person A and B is friends, predicting it as lovers does not lead to a contradictory social relation graph. Our method may also fail when most predictions are wrong and our model performs relational reasoning based on these false predictions, as shown in the second case.\n\nReference markers found: [41]\n\nContext windows for each [ref]:\n[ref]41: with the State-of-the-Art Methods.\nWe compare the proposed approach with several existing state-of-the-art methods. The details of these competing methods are as follows: Finetuned CNN + SVM [ref]41. Double-stream CaffeNet is used to extract features, then the extracted features are utilized to train a linear SVM. All attributes + SVM [ref]41. Many semantic attribute categories including\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 41,\n            \"titles\": [\n                \"Relational Forward Models for Multi-Agent Learning\",\n                \"Spectral networks and locally connected networks on graphs\",\n                \"Acquisition of the algorithms of social life: A domain-based approach\",\n                \"Relational action forecasting\",\n                \"Graph-Based Global Reasoning Networks\",\n                \"Learning phrase representations using rnn encoder-decoder for statistical machine translation\",\n                \"A circumplex model for interpersonal personality traits\",\n                \"Convolutional neural networks on graphs with fast localized spectral filtering\",\n                \"ArcFace: Additive Angular Margin Loss for Deep Face Recognition\",\n                \"Structure Inference Machines: Recurrent Neural Networks for Analyzing Relations in Group Activity Recognition\",\n                \"The four elementary forms of sociality: framework for a unified theory of social relations\",\n                \"Neural Message Passing for Quantum Chemistry\",\n                \"Fast R-CNN\",\n                \"An End-to-End Network for Generating Social Relationship Graphs\",\n                \"A new model for learning in graph domains\",\n                \"Inductive Representation Learning on Large Graphs\",\n                \"Adam: A method for stochastic optimization\",\n                \"Neural Relational Inference for Interacting Systems\",\n                \"Semi-Supervised Classification with Graph Convolutional Networks\",\n                \"Social roles in hierarchical models for human activity recognition\",\n                \"Dual-Glance Model for Deciphering Social Relationships\",\n                \"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning\",\n                \"BridgeNet: A Continuity-Aware Probabilistic Network for Age Estimation\",\n                \"GRAPH-BASED KINSHIP REASONING NETWORK\",\n                \"Gated Graph Sequence Neural Networks\",\n                \"Discriminative deep metric learning for face and kinship verification\",\n                \"Cost-sensitive subspace analysis and extensions for face recognition\",\n                \"Reconstruction-based metric learning for unconstrained face verification\",\n                \"Neighborhood repulsed metric learning for kinship verification\",\n                \"Social role discovery in human events\",\n                \"You Only Look Once: Unified, Real-Time Object Detection\",\n                \"YOLO9000: Better, Faster, Stronger\",\n                \"The relationship context of human behavior and development\",\n                \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\n                \"ImageNet Large Scale Visual Recognition Challenge\",\n                \"The graph neural network model\",\n                \"Modeling relational data with graph convolutional networks\",\n                \"What do you do? occupation recognition in a photo via social context\",\n                \"Joint Inference of Groups, Events and Human Roles in Aerial Videos\",\n                \"Predicting occupation via human clothing and contexts\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]41 based on the context and research area of Graph-Based Social Relation Reasoning. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}