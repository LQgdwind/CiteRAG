{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Quantum Motion Segmentation\n\nPaper Abstract: \n\nPaper Section Text:\nIn this section, we report experimental results on synthetic scenarios, a small dataset derived from the Hopkins benchmark [ref]60 and a new real dataset.\nWe evaluate our method on D-Wave’s AQC of the latest generation, i.e., D-Wave Advantage4.1 (Adv4.1), which is an AQC of the Pegasus architecture.\nIt contains ≈5​kabsent5𝑘{\\approx}5k physical qubits organized in cells of 242424 qubits; each qubit is coupled to 151515 other qubits; the total number of couplers is ≈40​kabsent40𝑘{\\approx}40k . Adv4.1 operates at temperatures below 17​m​K17𝑚𝐾17mK and is accessed remotely via Ocean . We run all experiments with 20​μ​s20𝜇𝑠20{\\mu}s annealing time (no pause).\nThe total QPU runtime of our experiments including overheads amounts to over 151515 minutes (over 106superscript10610^{6} obtained samples).\nWe sample 1​k1𝑘1k times and take the lowest-energy sample as the result. Evaluation Methodology.\nSince our method is the first quantum approach to segmentation with two-frame correspondences, we compare it with traditional approaches (i.e., not operating on AQC), namely Mode [ref]5 and Synch [ref]4, whose code is available online . Both our approach and the competitors take the same input, namely a set of pairwise segmentations represented as a d​p×d​p𝑑𝑝𝑑𝑝dp{\\times}dp block-matrix Z𝑍Z – see (10) – and they compute the absolute segmentations either in the form of a p×d𝑝𝑑p{\\times}d matrix X𝑋X or a vector 𝐲=vec⁡(X)𝐲vec𝑋\\mathbf{y}=\\operatorname{vec}(X) of length d​p𝑑𝑝dp.\nIn order to compare a given solution 𝐲∈ℬd​p𝐲superscriptℬ𝑑𝑝\\mathbf{y}\\in\\mathcal{B}^{dp} with the ground-truth solution named 𝐲g​t∈ℬd​psubscript𝐲𝑔𝑡superscriptℬ𝑑𝑝\\mathbf{y}_{gt}\\in\\mathcal{B}^{dp}, we use the accuracy μ𝜇\\mu333Other measures can be considered with similar results, such as the misclassification error, which is widely adopted in motion segmentation., as done also in . It is defined as the number of correct entries over the total amount of entries, namely where ℋℋ\\mathcal{H} denotes the Hamming distance. Experiment with Synthetic Noise.\nWe consider 20 synthetic configurations with 3 or 4 images, 2 motions and 16 points per image, resulting in 96 or 128 qubits. In order to create the ground-truth segmentation X𝑋X, each point is assigned to a motion which is randomly chosen among the two available ones. All the analyzed methods can solve these problems with accuracy μ=1𝜇1\\mu=1. Next, we derive pairwise segmentations from (3) and we systematically inject into them increasing amounts of noise:\nin each pairwise segmentation we switch the motion of a percentage of points ranging from 0%percent00\\% to 50%percent5050\\% (meaning that half of the points are corrupted).\nThe results of this experiment are shown in Fig. 3a, which reports the accuracy (averaged over 20 problem instances) for the analyzed methods.\nQuMoSeg-v1 is certainly on par with the best traditional approach (namely Mode [ref]4).\nConcerning QuMoSeg-v2, it is worth noting that is starts from a similar formulation to Synch [ref]4, but it solves the problem without relaxation: working over binary variables without relaxation in combination with AQC significantly improves the results. There are no significative differences between the two variants of our method on the smallest scenario with 96 qubits. Experiments on Q-MSEG Dataset.\nDue to the lack of small-scale datasets usable for our scenario (i.e., whose size is manageable by current AQC),\nwe generate a new dataset for motion segmentation with ground-truth annotations, which comprises six images depicting three planar objects captured from diverse viewpoints. We focus on planar motions (where the underlying model is the homography) since they can be recovered from a lower amount of points than general motions444At least four points are needed to estimate a homography, whereas at least seven points are required for the fundamental matrix 8.\n(where the corresponding model is the fundamental matrix), hence allowing more flexibility in the experimental setting.\nEach object is manually annotated with respectively 10, 11 and 12 keypoints, selected on highly-textured locations.\nFollowing  , we extract features corresponding to each keypoint using an AlexNet model  pretrained on ImageNet.\nSeveral motion segmentation problems are derived from the dataset: we consider 14 different choices for the number of points/images/motions (see supplementary), and we sample 20 problem instances for each configuration, resulting in 280 problem instances in total.\nFor each problem instance, we perform feature matching on every image pair via nearest neighbor search, where the cosine distance is used as the distance metric. Then, different motions are identified in each image pair by fitting multiple homographies to correspondences . This defines a set of pairwise segmentations which represent the input of Mode [ref]5, Synch [ref]4 and our quantum methods. In order to enrich the evaluation, we evaluate here also the method by Xu et al.  (with public code ), although it makes different assumptions on the input (i.e., it requires multi-frame trajectories, which were computed by us following the same procedure as in [ref]5 [ref]4).\nFor completeness, we also optimize the objective functions of our approach with a simulated annealing (SA) solver  9:\nwhile in general it performs on par with QA for smaller problems, it provides an indication on the QPU’s solution accuracy for the largest problems we test, which future QPU generations can potentially reach and outperform. Results are given in Tab. 1 which reports, for each configuration, the mean accuracy μ𝜇\\mu (over 20 problem instances) for all the analyzed methods.\nResults show that there is no clear winner, since none of the methods outperforms all others in all cases.\nIn particular, QuMoSeg-v1 is better than the state of the art on small-scale problems (i.e., 96-126 qubits) and comparable or better than the best traditional method (i.e., Mode [ref]5) on medium-scale problems (i.e., 136-200 qubits). On the largest cases, instead, either the performances of QuMoSeg-v1 significantly drop (i.e., 216 qubits) or it was unable to find a minor embedding and, hence,\na solution (i.e., 220-243 qubits).\nConcerning QuMoSeg-v2, we can observe that—although working under easier assumptions—it is, in general, worse than QuMoSeg-v1. This might be caused by the difficulty of satisfying the additional (simplified) constraints in practice (as they are treated as soft instead of hard).\nNote that the performances of our approaches are largely affected by the limitation of current QPU. In this respect, the on-par or higher performance of SA (see Tab. 1) suggests that our QUBO approach to motion segmentation is sound and that future QPU generations are expected to reach or surpass that result.\nQualitative results from an example with 969696 qubits are shown in Fig. 1: in this case, QuMoSeg-v1 outperforms existing methods. Fig. 3b visualises how the expected number of physical qubits and the maximum chain length are increasing with the increasing problem size.\nIt also reports the probability of finding a solution in a sampling, which is calculated as the portion of optimal (lowest-energy) solutions among all solutions.\nNote that QuMoSeg-v1 has a non-zero probability to find an optimal solution for all problems except the largest embeddable one with 216216216 qubits, whereas QuMoSeg-v2 has a non-zero probability only on the two smallest cases. Experiments on Hopkins Benchmark.\nStarting from the popular Hopkins155 dataset [ref]60, we created small problems (with 120-240 qubits) by sampling a subset of images/points from the cars2__\\_06__\\_g23 sequence (see our supplement for details). For each configuration, 20 instances were created, resulting in 400 examples in total. We used the fundamental matrix model to produce the pairwise segmentations which are given as input to Mode [ref]5, Synch [ref]4 and our quantum methods. We also consider the method by Xu et al.  and the simulated annealing (SA) solver  9, as done previously. Results are given in Tab. 2, showing that we outperform Xu et al.  (for number of qubits <198absent198{<}198) and obtain comparable performance to classic methods [ref]5 [ref]4 in several cases.\nResults for SA show that the global optima of our QUBOs match expected solutions (and that the obtained energy landscapes are as expected), even though the solutions cannot be recovered by QA in all cases due to hardware limitations. In particular, for small problems, the simulated annealing performs on par with QA (as expected), whereas large problems can be solved with the SA only. Parameters.\nIn the tests with Q-MSEG and Hopkins, we use λ1=10.0subscript𝜆110.0\\lambda_{1}=10.0 (v1) and λ2=10.0subscript𝜆210.0\\lambda_{2}=10.0, λ3=4.0subscript𝜆34.0\\lambda_{3}=4.0 (v2).\nFor the synthetic experiments, we set the parameters as follows: λ1=14.0subscript𝜆114.0\\lambda_{1}=14.0 (v1) and λ2=27.5subscript𝜆227.5\\lambda_{2}=27.5, λ3=3.2subscript𝜆33.2\\lambda_{3}=3.2 (v2).\nThe chain strength required to keep the chains of physical qubits intact, is chosen as a linear function c​(k)=a​k+b𝑐𝑘𝑎𝑘𝑏c(k)=ak+b in the number of the logical qubits.\nWe set a=0.13508𝑎0.13508a=0.13508, b=−1.94207𝑏1.94207b=-1.94207 and a=0.1238𝑎0.1238a=0.1238, b=−1.3180𝑏1.3180b=-1.3180 for v1 and v2, respectively. Discussion.\nIn our experiments, QuMoSeg achieves on-par performance555Note that this reflects the current situation in the field: indeed, other quantum methods   do not outperform classical methods in all scenarios too. with non-quantum state of the art, showing the viability of a quantum approach for segmentation.\nAmong the two proposed variants, QuMoSeg-v1 is the most accurate and QuMoSeg-v2 can solve larger problems.\nMoreover, our approach in a combination with SA shows highly promising results on both Q-MSEG and the data we generated from Hopkins.\nThe characteristics of the current quantum hardware starkly influence the performance of QuMoSeg: Problems with >120absent120{>}120 points cannot be minor-embedded, and the largest mappable problems require maintaining too long qubit chains, which impedes the optimum search. As many other quantum algorithms, QuMoSeg will benefit from improved quantum hardware, both in terms of accuracy and solvable problem sizes.\n\nIndeed, it is expected that the possibility to solve combinatorial problems without approximation will give practical advantages for large-scale problems in the future.\n\nReference markers found: [60]\n\nContext windows for each [ref]:\n[ref]60: In this section, we report experimental results on synthetic scenarios, a small dataset derived from the Hopkins benchmark [ref]60 and a new real dataset.\nWe evaluate our method on D-Wave’s AQC of the latest generation, i.e., D-Wave Advantage4.1 (Adv4.1), which is an AQC of the Pegasus architecture.\nIt contains\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 60,\n            \"titles\": [\n                \"Multi-Image Semantic Matching by Mining Consistent Features\",\n                \"인공지능 기반 공격 그래프 생성\",\n                \"Synchronization problems in computer vision with closed-form solutions\",\n                \"Motion segmentation via synchronization\",\n                \"Robust Motion Segmentation from Pairwise Matches\",\n                \"Multi-Class Model Fitting by Energy Minimization and Mode-Seeking\",\n                \"A Solution for Multi-Alignment by Transformation Synchronisation\",\n                \"HiPPI: Higher-order projected power iterations for scalable multi-matching\",\n                \"Synchronizing probability measures on rotations via optimal transport\",\n                \"Quantum permutation synchronization\",\n                \"Next-Generation Topology of D-Wave Quantum Processors\",\n                \"Beweis des adiabatensatzes\",\n                \"A practical heuristic for finding graph minors\",\n                \"Initialization techniques for 3D SLAM: A survey on rotation estimation and its use in pose graph optimization\",\n                \"Approaching remote sensing image classification with ensembles of support vector machines on the d-wave quantum annealer\",\n                \"Efficient and robust large-scale rotation averaging\",\n                \"Near-optimal joint object matching via convex relaxation\",\n                \"D-wave ocean software documentation\",\n                \"dwave-neal documentation\",\n                \"Pegasus: The second connectivity graph for large-scale quantum annealing hardware\",\n                \"What is the computational value of finite-range tunneling?\",\n                \"What is quantum annealing?\",\n                \"Rotation Averaging and Strong Duality\",\n                \"A quantum adiabatic evolution algorithm applied to random instances of an np-complete problem\",\n                \"A Quantum Computational Approach to Correspondence Problems on Point Sets\",\n                \"On averaging multiview relations for 3D scan registration\",\n                \"Adiabatic quantum computing and quantum annealing\",\n                \"Multiple View Geometry in Computer Vision\",\n                \"Multibodysync: Multi-body segmentation and motion estimation via 3d scan synchronization\",\n                \"Robust motion segmentation with unknown correspondences\",\n                \"Shape interaction matrix revisited and robustified: Efficient subspace clustering with corrupted and incomplete data\",\n                \"Optimization by simulated annealing\",\n                \"Imagenet classification with deep convolutional neural networks\",\n                \"Motion segmentation via a sparsity constraint\",\n                \"Quantum-soft qubo suppression for accurate object detection\",\n                \"Pogo-net: Pose graph optimization with graph neural networks\",\n                \"Perspective motion segmentation via collaborative clustering\",\n                \"Hadamard, Khatri-Rao, Kronecker and other matrix products\",\n                \"T-Linkage: A continuous relaxation of J-Linkage for multi-model fitting\",\n                \"Robust multiple model fitting with preference analysis and low-rank approximation\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]60 based on the context and research area of Quantum Motion Segmentation. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}