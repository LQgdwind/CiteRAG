{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: PCB-Vision: A Multiscene RGB-Hyperspectral Benchmark Dataset of Printed Circuit Boards\n\nPaper Abstract: \n\nPaper Section Text:\nThis subsection outlines the preprocessing steps applied to the RGB data and provides a numerical evaluation of the aforementioned DL models: Train, validation, and test split: the original RGB dataset comprises 53 images of the 53 PCBs. To facilitate effective model training, validation, and testing, we performed a split, allocating 62% of the data for training, 16% for validation, and 20% for testing. This results in 33 images used for training, 9 for validation, and 11 for testing. The split was conducted randomly to ensure representative subsets in each category. We did not use the HSI training set built based on the statistics since the training data in the HSI are much higher than in RGB due to data abundance inherited in hyperspectral imaging consisting of 224 bands. The usage of 62% of PCB-Vision data for training can yield better results. Data augmentation: is a major technique in DL that enhances models’ performance by artificially expanding the training dataset [ref]50. By using the existing samples to create new synthetic data variants, data augmentation addresses the challenges of limited data availability and improves the generalization ability of DL models to unseen data [ref]50. Albumentations [ref]51, a powerful image augmentation Python library, was employed to apply various transformations to both RGB images and their corresponding masks. These transformations fall into two categories: Spatial-level transformations (applied to both image and mask simultaneously): Vertical flip Horizontal flip 40 degrees clockwise rotation 40 degrees anti-clockwise rotation RGB channel color shifting with a 25-shift limit for the red, green, and blue channels Transpose Shift scale rotate Pixel-level transformations (applied to the image without mask changes): Color jittering Channel shuffling Random snow One of: random brightness or random gamma One of: blur or motion blur One of: random contrast or hue saturation value By introducing augmented data during training, the DL model increases its generalization ability, thereby improving performance across unseen data and diverse real-world scenarios. This approach mitigates overfitting risks, ensuring the model’s efficacy in accurately segmenting objects under varying lighting conditions, viewpoints, and occlusion patterns . In the context of semantic segmentation, data augmentation is an indispensable strategy to boost model performance and ensure its practical applicability in various real-world scenarios [ref]50. Class imbalance mitigation: While our dataset comprises three classes (’IC,’ ’Capacitor,’ and ’Connectors’) another class named ’Others’ is introduced for the model to classify everything that is not one of our classes of interest as ’Others’. This includes every other object that appears on the PCB surface, plus the undesired background (conveyor belt) as well. Class imbalance can impact the performance of machine learning models. To mitigate this, class weights were introduced to the loss function in order to highlight the error and updates for the classes of interest since they have fewer training samples than the ’Others’ class.\n The following part contains two types of segmentation experiments, the first is done on the ’General’ ground truth set, and the second is done with the ’Monoseg’ type of ground truth. The five above-mentioned benchmark segmentation models are used for the semantic segmentation of the RGB PCBs. While alternative hyperparameters were explored, the selected set presented in table III empirically demonstrated robust performance across all models, avoiding overfitting issues. A noteworthy observation is that attempting a higher spatial image resolution (1280x1280x3) yielded improved results, despite practical constraints, particularly memory limitations, i.e., lack-of-memory errors that prevented universal application across all five models. Additionally, reducing the batch size below 8 negatively impacted performance, even with higher spatial resolutions. Note: different hyperparameters were tested, resulting in varied outcomes for different models, mostly biased and overfitted performance. The chosen parameters strike a balance, showcasing good performance without encountering overfitting concerns for any of the models. Table IV demonstrates the performance of the five models on the ’General’ ground truths annotations. \n\n\nModel\nMetric \\\\\\backslash Class\nOthers\nIC\nCapacitor\nConnectors\n\nUnet\nPrecision\n0.96\n0.39\n0.74\n0.63\n\n\nRecall\n0.99\n0.04\n0.69\n0.56\n\n\nF1 Score\n0.98\n0.07\n0.71\n0.60\n\n\nIOU\n0.96\n0.03\n0.55\n0.42\n\nAttention Unet\nPrecision\n0.98\n0.73\n0.83\n0.39\n\n\n\nRecall\n0.99\n0.55\n0.73\n0.99\n\n\n\nF1 Score\n0.98\n0.63\n0.78\n0.56\n\n\n\nIOU\n0.97\n0.46\n0.64\n0.39\n\nResUnet\nPrecision\n0.97\n0.25\n0.48\n0.11\n\n\n\nRecall\n0.97\n0.11\n0.86\n0.63\n\n\n\nF1 Score\n0.97\n0.16\n0.62\n0.20\n\n\n\nIOU\n0.94\n0.09\n0.45\n0.11\n\nDeepLabv3+\nPrecision\n0.98\n0.58\n0.84\n0.81\n\n\n\nRecall\n0.98\n0.66\n0.70\n0.68\n\n\n\nF1 Score\n0.98\n0.62\n0.76\n0.74\n\n\n\nIOU\n0.97\n0.45\n0.62\n0.59\n\nLinkNet\nPrecision\n0.98\n0.39\n0.63\n0.72\n\n\n\nRecall\n0.97\n0.61\n0.80\n0.92\n\n\n\nF1 Score\n0.98\n0.48\n0.70\n0.81\n\n\n\nIOU\n0.95\n0.31\n0.54\n0.68\n Based on table IV it can be concluded that the DeepLabv3+ and Attention UNet models stand out as the effective models among those five models exhibiting strong performance across precision, recall, and F1 Score for all classes, indicating a robust overall segmentation capability. Figure 9 presents the prediction performance of the DeepLabv3+ on some of the test images. The quality of the segmentation prediction can be assessed by comparing the predicted masks to the ground truth masks. A good segmentation prediction should have a high overlap with the ground truth mask, and simultaneously be free of noise and artifacts. From figure 9 it can be seen that the DeepLabv3+ model performs well on the three classes, with a high overlap between the predicted and ground truth masks. However, there are some cases where the model fails. Here is more expansion on the overall performance of DeepLabv3+: The model performs very well on the ’IC’ class, with a high overlap between the predicted and ground truth masks. The model also performs well on the ’Capacitor’ class, but there are some cases where the model misses some of the ’Capacitor’ pixels, e.g., the last PCB (bottom right). The model performs worst on the ’Connectors’ class, missing some of the Connector pixels, e.g., the third PCB from the left. The model tends to make more mistakes in images with complex backgrounds. Overall, the DeepLabv3+ model is a promising model for PCB segmentation. However, it is important to note that no model is perfect, and there will always be some cases where the model makes mistakes, especially in imbalanced class scenarios our PCB-Vision contains. Table V demonstrates the performance of the five segmentation models on the ’Monoseg’ ground truth annotations. \n\n\nModel\nMetric \\\\\\backslash Class\nOthers\nIC\nCapacitor\nConnectors\n\nUnet\nPrecision\n0.98\n0.66\n0.58\n0.57\n\n\nRecall\n0.99\n0.38\n0.90\n0.95\n\n\nF1 Score\n0.99\n0.48\n0.71\n0.71\n\n\nIOU\n0.98\n0.32\n0.55\n0.56\n\nAttention Unet\nPrecision\n0.98\n0.57\n0.39\n0.25\n\n\n\nRecall\n0.98\n0.35\n0.96\n0.94\n\n\n\nF1 Score\n0.98\n0.43\n0.56\n0.39\n\n\n\nIOU\n0.97\n0.27\n0.39\n0.24\n\nResUnet\nPrecision\n0.98\n0.26\n0.37\n0.15\n\n\n\nRecall\n0.98\n0.09\n0.84\n0.82\n\n\n\nF1 Score\n0.97\n0.14\n0.53\n0.25\n\n\n\nIOU\n0.96\n0.07\n0.37\n0.14\n\nDeepLabv3+\nPrecision\n0.99\n0.51\n0.49\n0.58\n\n\n\nRecall\n0.98\n0.66\n0.92\n0.96\n\n\n\nF1 Score\n0.99\n0.58\n0.64\n0.72\n\n\n\nIOU\n0.97\n0.40\n0.47\n0.57\n\nLinkNet\nPrecision\n0.99\n0.47\n0.49\n0.86\n\n\n\nRecall\n0.98\n0.61\n0.84\n0.97\n\n\n\nF1 Score\n0.99\n0.53\n0.62\n0.91\n\n\n\nIOU\n0.97\n0.36\n0.44\n0.83\n Based on table V, DeepLabv3+ exhibits strong overall performance, excelling in both precision and recall. This suggests its effectiveness in capturing true positives while minimizing false positives and false negatives. Additionally, LinkNet demonstrates high precision across all classes, indicating accurate positive predictions. It achieves a moderate performance in terms of recall, precision, and F1 Score, making it another robust choice to consider for this particular type of ground truth.\n\nReference markers found: [50]\n\nContext windows for each [ref]:\n[ref]50: usage of 62% of PCB-Vision data for training can yield better results. Data augmentation: is a major technique in DL that enhances models’ performance by artificially expanding the training dataset [ref]50. By using the existing samples to create new synthetic data variants, data augmentation addresses the challenges of limited data availability and improves the generalization ability of DL\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 50,\n            \"titles\": [\n                \"Albumentations: fast and flexible image augmentations\",\n                \"Remanufacturing strategies: A solution for WEEE problem\",\n                \"Towards a national circular economy indicator system in China: an evaluation and critical analysis\",\n                \"Recycling of WEEEs: An economic assessment of present and future e-waste streams\",\n                \"The Global E-waste Monitor 2020: Quantities, flows and the circular economy potential\",\n                \"Towards circular economy implementation: a comprehensive review in context of manufacturing industry\",\n                \"Sustainable Development Goals (SDGs)\",\n                \"Recycling waste circuit board efficiently and environmentally friendly through small-molecule assisted dissolution\",\n                \"Recycling of non-metallic fractions from waste printed circuit boards: a review.\",\n                \"Printed Circuit Board Defect Detection Methods Based on Image Processing, Machine Learning and Deep Learning: A Survey\",\n                \"A review on deep learning in machining and tool monitoring: methods, opportunities, and challenges\",\n                \"Hardware-based image processing for high-speed inspection of grains\",\n                \"A survey and evaluation of promising approaches for automatic image-based defect detection of bridge structures\",\n                \"Segmentation and classification of THCs on PCBAs\",\n                \"SMD segmentation for automated PCB recycling\",\n                \"Text recognition for information retrieval in images of printed circuit boards\",\n                \"Printed circuit board defect detection using deep learning via a skip-connected convolutional autoencoder\",\n                \"TDD-net: a tiny defect detection network for printed circuit boards\",\n                \"Defect detection in printed circuit boards using you-only-look-once convolutional neural networks\",\n                \"You Only Look Once: Unified, Real-Time Object Detection\",\n                \"Fics-pcb: A multi-modal image dataset for automated printed circuit board visual inspection\",\n                \"FICS PCB X-ray: A dataset for automated printed circuit board inter-layers inspection\",\n                \"A PCB Dataset for Defects Detection and Classification\",\n                \"Online PCB Defect Detector On a New PCB Defect Dataset\",\n                \"A dataset for computer-vision-based PCB analysis\",\n                \"PCB-METAL: A PCB Image Dataset for Advanced Computer Vision Machine Learning Component Analysis\",\n                \"Sparsity and Structure in Hyperspectral Imaging : Sensing, Reconstruction, and Target Detection\",\n                \"Use of hyperspectral imaging for the quantification of organic contaminants on copper surfaces for electronic applications\",\n                \"Laser-induced breakdown spectroscopy (LIBS) combined with hyperspectral imaging for the evaluation of printed circuit board composition\",\n                \"Recycling-oriented characterization of plastic frames and printed circuit boards from mobile phones by electronic and chemical imaging\",\n                \"Experimental stand for sorting components dismantled from printed circuit boards\",\n                \"Object detection routine for material streams combining RGB and hyperspectral reflectance data based on guided object localization\",\n                \"Combined use of 3D and HSI for the classification of printed circuit board components\",\n                \"Imagenet classification with deep convolutional neural networks\",\n                \"Rethinking the inception architecture for computer vision\",\n                \"Application of hyperspectral imaging in food safety inspection and control: a review\",\n                \"Hyperspectral imaging in the medical field: Present and future\",\n                \"HybridSN: Exploring 3-D–2-D CNN feature hierarchy for hyperspectral image classification\",\n                \"Small sample hyperspectral image classification based on the random patches network and recursive filtering\",\n                \"Landslide4Sense: Reference Benchmark Data and Deep Learning Models for Landslide Detection\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]50 based on the context and research area of PCB-Vision: A Multiscene RGB-Hyperspectral Benchmark Dataset of Printed Circuit Boards. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}