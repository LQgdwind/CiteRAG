{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Maximally Extendable Sheaf Codes\n\nPaper Abstract: \n\nPaper Section Text:\nIf we equip the cochain complex ğ‚âˆ™=ğ‚âˆ™â€‹(X;â„±)superscriptğ‚âˆ™superscriptğ‚âˆ™ğ‘‹â„±\\mathbf{C}^{\\bullet}=\\mathbf{C}^{\\bullet}(X;\\mathcal{F}) with aÂ norm, we can naturally transfer all the standard notions, such as coboundary expansion and local minimality, from theory of high-dimensional expanders (HDXs)Â  , originally developed for cohomology groups over ğ”½2subscriptğ”½2\\mathbb{F}_{2} to the much more general realm of cohomology groups with local coefficients in theÂ sheafÂ â„±â„±\\mathcal{F}. Here we use the block (Hamming) norm333333This norm is also sometimes called the support normÂ 8. fromÂ [ref]2, naturally generalizing the standard Hamming norm, defined for câˆˆğ‚âˆ™ğ‘superscriptğ‚âˆ™c\\in\\mathbf{C}^{\\bullet} as |c|X=|{ÏƒâˆˆXâˆ£cÏƒâ‰ 0}|subscriptğ‘ğ‘‹conditional-setğœğ‘‹subscriptğ‘ğœ0\\left\\lvert c\\right\\rvert_{X}=\\left\\lvert\\{\\sigma\\in X\\mid c_{\\sigma}\\neq 0\\}\\right\\rvert, and also consider its normalized version343434This normalization is often used for simplicial complexesÂ . as âˆ¥câˆ¥X=âˆ‘cÏƒâ‰ 0wÏƒsubscriptdelimited-âˆ¥âˆ¥ğ‘ğ‘‹subscriptsubscriptğ‘ğœ0subscriptğ‘¤ğœ\\left\\lVert c\\right\\rVert_{X}=\\sum_{c_{\\sigma}\\neq 0}w_{\\sigma}, where wÏƒ=|XÏƒ|/âˆ‘ÏƒâˆˆXâ€‹(i)|XÏƒ|subscriptğ‘¤ğœsubscriptğ‘‹ğœsubscriptğœğ‘‹ğ‘–subscriptğ‘‹ğœw_{\\sigma}=\\left\\lvert X_{\\sigma}\\right\\rvert/\\sum_{\\sigma\\in X(i)}\\left\\lvert X_{\\sigma}\\right\\rvert, dimÏƒ=idimensionğœğ‘–\\dim\\sigma=i. In fact, in all examples we are interested, the poset Xğ‘‹X is sufficiently regular, and wÏƒ=1/|Xâ€‹(i)|subscriptğ‘¤ğœ1ğ‘‹ğ‘–w_{\\sigma}=1/\\left\\lvert X(i)\\right\\rvert for ÏƒâˆˆXâ€‹(i)ğœğ‘‹ğ‘–\\sigma\\in X(i). Both these norms can be naturally extended to subspaces Sâ©½ğ‚âˆ™ğ‘†superscriptğ‚âˆ™S\\leqslant\\mathbf{C}^{\\bullet} as |S|X=minÏƒâˆˆS|Ïƒ|X\\left\\lvert S\\right\\rvert_{X}=\\min_{\\sigma\\in S}\\left\\lvert\\sigma\\right\\rvert_{X} and âˆ¥Sâˆ¥X=minÏƒâˆˆSâˆ¥Ïƒâˆ¥X\\left\\lVert S\\right\\rVert_{X}=\\min_{\\sigma\\in S}\\left\\lVert\\sigma\\right\\rVert_{X}. Now, we are ready to define the iğ‘–i-th coboundary expansion Î·iâ€‹(â„±)=Î·iâ€‹(X;â„±)superscriptğœ‚ğ‘–â„±superscriptğœ‚ğ‘–ğ‘‹â„±\\eta^{i}(\\mathcal{F})=\\eta^{i}(X;\\mathcal{F}) of â„±â„±\\mathcal{F} as and also its normalized version Î·~iâ€‹(â„±)=Î·~iâ€‹(X;â„±)superscript~ğœ‚ğ‘–â„±superscript~ğœ‚ğ‘–ğ‘‹â„±\\tilde{\\eta}^{i}(\\mathcal{F})=\\tilde{\\eta}^{i}(X;\\mathcal{F}), where instead of |â‹…|Xsubscriptâ‹…ğ‘‹\\left\\lvert\\cdot\\right\\rvert_{X} we use âˆ¥â‹…âˆ¥Xsubscriptdelimited-âˆ¥âˆ¥â‹…ğ‘‹\\left\\lVert\\cdot\\right\\rVert_{X}. Here we assume that the minimum over the empty set is equal to âˆ\\infty, and also put Î·â€‹(â„±)=miniâˆˆâ„¤â¡Î·iâ€‹(â„±)ğœ‚â„±subscriptğ‘–â„¤superscriptğœ‚ğ‘–â„±\\eta(\\mathcal{F})=\\min_{i\\in\\mathbb{Z}}\\eta^{i}(\\mathcal{F}) and Î·~â€‹(â„±)=miniâˆˆâ„¤â¡Î·~iâ€‹(â„±)~ğœ‚â„±subscriptğ‘–â„¤superscript~ğœ‚ğ‘–â„±\\tilde{\\eta}(\\mathcal{F})=\\min_{i\\in\\mathbb{Z}}\\tilde{\\eta}^{i}(\\mathcal{F}). Note that it is also possible to define the small set versionsÂ [ref]7 of all these quantities: In the special case when â„±â„±\\mathcal{F} is the constant sheaf ğ”½2Â¯Â¯subscriptğ”½2\\underline{\\mathbb{F}_{2}} on aÂ simplicial complex Xğ‘‹X, we get exactly the coboundary expansion from the theory of HDXs, which in turn generalizes the Cheeger constant hâ€‹(X)â„ğ‘‹h(X) (e.g., seeÂ  8) of aÂ graph Xğ‘‹X since we have hâ€‹(X)=Î·0â€‹(X;ğ”½2Â¯)â„ğ‘‹superscriptğœ‚0ğ‘‹Â¯subscriptğ”½2h(X)=\\eta^{0}(X;\\underline{\\mathbb{F}_{2}}) when we view graphs as simplicial complexes353535This assumption is very important here since simplicial complexes also have the empty face âˆ…\\varnothing with dimâˆ…=âˆ’1dimension1\\dim\\varnothing=-1 (e.g., see ).. At the same time, when â„±â„±\\mathcal{F} is aÂ default sheaf code of length nğ‘›n, then Î·â€‹(â„±)ğœ‚â„±\\eta(\\mathcal{F}) and Î·~â€‹(â„±)~ğœ‚â„±\\tilde{\\eta}(\\mathcal{F}) coincide respectively with the minimum distance dâ€‹(â„±)ğ‘‘â„±d(\\mathcal{F}) and its normalized version 1nâ€‹dâ€‹(â„±)1ğ‘›ğ‘‘â„±\\frac{1}{n}d(\\mathcal{F}). In the case of tensor product code ğ’œâŠ—â„¬tensor-productğ’œâ„¬\\mathcal{A}\\otimes\\mathcal{B}, we have that Î·â€‹(ğ’œâŠ—â„¬)ğœ‚tensor-productğ’œâ„¬\\eta(\\mathcal{A}\\otimes\\mathcal{B}) is, up to normalization factors, the agreement testabilityÂ , which is in turn related with the robust testabilityÂ  of ğ’œâŠ—â„¬tensor-productğ’œâ„¬\\mathcal{A}\\otimes\\mathcal{B} (e.g., seeÂ  ). The quantity Î·â€‹(ğ’œâŠ—â„¬)ğœ‚tensor-productğ’œâ„¬\\eta(\\mathcal{A}\\otimes\\mathcal{B}) was an important ingredient in the first constructions of good LTCs and qLDPC codesÂ  [ref]2, where it played aÂ role similar to the minimal distance in the Sipser-Spielman codes.\nNote, that inÂ [ref]2 it was called product expansion, and also considered in the case when we have some puncturing in the product code ğ’œâŠ—â„¬tensor-productğ’œâ„¬\\mathcal{A}\\otimes\\mathcal{B}. Later Leverrier and ZÃ©mor found anÂ elegant equivalent reformulation of the product expansion, and finally in   it was directly connected to the (co)boundary expansion, and also generalized to D>2ğ·2D>2 dimensions. It is important to note that when D>2ğ·2D>2 it is aÂ strictly stronger property than both the agreement and the robust testabilityÂ 5. Finally, inÂ 8 the authors studied coboundary expansion for arbitrary sheaves of vector spaces on simplicial complexes, and also used it to construct LTCs and qLDPC codes. Let us also say that aÂ sheaf code â„±â„±\\mathcal{F} is anÂ Î·ğœ‚\\eta-expander if Î·â€‹(â„±)â©¾Î·ğœ‚â„±ğœ‚\\eta(\\mathcal{F})\\geqslant\\eta, and aÂ two-way Î·ğœ‚\\eta-expander if both â„±â„±\\mathcal{F} and â„±Tsuperscriptâ„±T\\mathcal{F}^{\\mathrm{T}} are Î·ğœ‚\\eta-expanders, where â„±Tsuperscriptâ„±T\\mathcal{F}^{\\mathrm{T}} is the dual sheaf code. Note that if â„±=â¨‚iâˆˆ[D]ğ’iâ„±subscripttensor-productğ‘–delimited-[]ğ·subscriptğ’ğ‘–\\mathcal{F}=\\bigotimes_{i\\in[D]}\\mathcal{C}_{i}, then two-way Î·ğœ‚\\eta-expansion requires that both â¨‚iâˆˆ[D]ğ’isubscripttensor-productğ‘–delimited-[]ğ·subscriptğ’ğ‘–\\bigotimes_{i\\in[D]}\\mathcal{C}_{i} and â¨‚iâˆˆ[D]ğ’iâŸ‚subscripttensor-productğ‘–delimited-[]ğ·superscriptsubscriptğ’ğ‘–perpendicular-to\\bigotimes_{i\\in[D]}\\mathcal{C}_{i}^{\\perp} are Î·ğœ‚\\eta-expanders, and when D=1ğ·1D=1 it requires that the minimal distance of aÂ code and its dual is at least Î·ğœ‚\\eta. The case D=1ğ·1D=1 was essential for aÂ construction of Sipser-Spielman codes with good bidirectional small-set expansion properties inÂ , 7. At the same time, the case D=2ğ·2D=2 was essential for expander LP codesÂ [ref]2 and their simplification called quantum Tanner codesÂ  to get the linear minimum distance, and also good bidirectional small-set expansionÂ [ref]7, which in turn implies the NLTS theoremÂ 1.\n\nReference markers found: [2]\n\nContext windows for each [ref]:\n[ref]2: much more general realm of cohomology groups with local coefficients in theÂ sheafÂ â„±â„±\\mathcal{F}. Here we use the block (Hamming) norm333333This norm is also sometimes called the support normÂ 8. fromÂ [ref]2, naturally generalizing the standard Hamming norm, defined for câˆˆğ‚âˆ™ğ‘superscriptğ‚âˆ™c\\in\\mathbf{C}^{\\bullet} as |c|X=|{ÏƒâˆˆXâˆ£cÏƒâ‰ 0}|subscriptğ‘ğ‘‹conditional-setğœğ‘‹subscriptğ‘ğœ0\\left\\lvert\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 2,\n            \"titles\": [\n                \"Quantum Tanner codes\",\n                \"Locally Testable Codes with constant rate, distance, and locality\",\n                \"Asymptotically Good Quantum and Locally Testable Classical LDPC Codes\",\n                \"Good Quantum LDPC Codes with Linear Time Decoders\",\n                \"Two-sided Robustly Testable Codes\",\n                \"NLTS Hamiltonians and Strongly-Explicit SoS Lower Bounds from Low-Rate Quantum LDPC Codes\",\n                \"Explicit Lower Bounds Against Î©Î©\\\\Omega(n)-Rounds of Sum-of-Squares\",\n                \"Single-shot decoding of good quantum LDPC codes\",\n                \"An efficient decoder for a linear distance quantum LDPC code\",\n                \"Efficient decoding up to a constant fraction of the code length for asymptotically good quantum codes\",\n                \"NLTS Hamiltonians from good quantum codes\",\n                \"Layer Codes\",\n                \"Local Quantum Codes from Subdivided Manifolds\",\n                \"Geometrically Local Quantum and Classical Codes from Subdivision\",\n                \"High Dimensional Expanders Imply Agreement Expanders\",\n                \"Graph codes and local systems\",\n                \"Balanced product quantum codes\",\n                \"On Good 2-Query Locally Testable Codes from Sheaves on High Dimensional Expanders\",\n                \"New Codes on High Dimensional Expanders\",\n                \"Expansion of higher-dimensional cubical complexes with application to quantum locally testable codes\",\n                \"Topological quantum memory\",\n                \"Quantum LDPC Codes with Almost Linear Minimum Distance\",\n                \"Fiber bundle codes: breaking the N1/2â€‹polylogâ¡(N)superscriptğ‘12polylogğ‘N^{1/2}\\\\operatorname{polylog}(N) barrier for quantum LDPC codes\",\n                \"On expander codes\",\n                \"On the Maximally Recoverable Property for Multi-Protection Group Codes\",\n                \"Explicit Maximally Recoverable Codes With Locality\",\n                \"A Family of Optimal Locally Recoverable Codes\",\n                \"Quantum Locally Recoverable Codes\",\n                \"Maximally extendable product codes are good coboundary expanders\",\n                \"Quantum locally testable codes\",\n                \"Local Hamiltonians Whose Ground States Are Hard to Approximate\",\n                \"Quantum Locally Testable Code with Constant Soundness\",\n                \"Infinite series of quaternionic 1-vertex cube complexes, the doubling construction, and explicit cubical Ramanujan complexes\",\n                \"Good quantum error-correcting codes exist\",\n                \"Error correcting codes in quantum theory\",\n                \"The category of linear codes\",\n                \"Combinatorial problems of elementary Abelian groups\",\n                \"Sheaf codes\",\n                \"A recursive approach to low complexity codes\",\n                \"Expander codes\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]2 based on the context and research area of Maximally Extendable Sheaf Codes. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}