{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Sampling From Autoencoders‚Äô Latent Space via Quantization And Probability Mass Function Concepts\n\nPaper Abstract: \n\nPaper Section Text:\nFollowing the training of various autoencoder-based generative models, notably the Vanilla Autoencoder , Variational Autoencoder [ref]18, Œ≤ùõΩ\\beta-VAE , Wasserstein Autoencoder¬†, and InfoVAE  on the MNIST , CelebA¬†, and MOBIUS  [ref]31   [ref]42 datasets, we computed the Fr√©chet Inception Distance FID metric. The obtained results are presented in Table 1. Furthermore, Figure 2 illustrates the progression of the FID metric in relation to the number of distributions for GMM sampling and the number of partitions for PMFS sampling. It‚Äôs important to note that for calculating the FID metric, we generated a quantity of synthetic images equivalent to the number of images in the respective test set for each dataset. Lastly, Figure 3 displays the distribution of the latent space of the validation set, providing a comparison with samples drawn from GMM and PMFS models. From Table 1 and Figure 2, it becomes evident that, in terms of GMM sampling, the optimal choice for the number of distributions (#dist) is rarely the same as the number of classes in the dataset, even for relatively simple datasets like MNIST. As a result, relying on the heuristic of setting the number of classes as the number of distributions in a GMM, as is commonly done , is likely to yield suboptimal outcomes. Furthermore, a comparison of the lowest FID values achieved by GMM sampling with those obtained through PMFS sampling underscores the enhancements introduced by PMFS sampling across all models and datasets. This improvement can be attributed to the strategy of defining a neighborhood around each latent vector and sampling from within this neighborhood, leading to the acquisition of superior, high-probability samples that can be effectively reconstructed by the decoder network into realistic data points. This contrasts with GMM sampling, which operates on distributions encompassing the entire space and might yield samples lying outside the regions reconstructable by the decoder network. Such a characteristic is crucial in biometric image synthesis, where the goal is to generate synthetic images that closely resemble real-world counterparts. Furthermore, Table 1 reveals substantial gains in terms of the FID metric when applying our proposed PMFS sampling method to deterministic models, particularly the Vanilla Autoencoder  and the Wasserstein Autoencoder¬†. This trend can be attributed to the stochastic learning phase in these models, which capitalizes on the vicinity of each mean latent vector corresponding to an image. Consequently, our method, rooted in the concept of neighborhoods, yields slightly reduced efficacy for this model type. However, it still outperforms the GMM sampling method in terms of FID. Consequently, when employing the PMFS sampling method on biometric data, the outcome is a collection of synthetic images resembling more closely the actual instances. Additionally, a comparison of the model fitting time between PMFS and GMM sampling reveals a substantial improvement, quantifiable in terms of orders of magnitude, thus corroborating the anticipated theoretical disparity in time complexity. Moreover, we conducted an investigation into the distribution of drawn samples via GMM sampling and PMFS, comparing them to the underlying distribution of latent vectors generated by the validation dataset. This investigation was executed quantitatively using the Wasserstein distance  (see the ùí≤ùí≤\\mathcal{W} column in Table 1) and qualitatively (see Figure 3). From the ùí≤ùí≤\\mathcal{W} column in Table 1, it is evident that, particularly for large datasets like MNIST and CelebA, PMFS has the capacity to generate distributions which closely approximate the real ones, demonstrating an improvement over GMM sampling. This holds true, especially when the value of kùëòk is high. Consequently, for smaller datasets like MOBIUS, GMM sampling exhibits superior performance over PMFS due to the low number of partitions kùëòk employed in PMFS, aiming to maximize FID while compensating for the distribution discrepancy between the training and testing sets. These findings are visually supported by Figure¬†3 and Appendix H. Upon analyzing Figure 2, it becomes evident that, for all the datasets, there exists a specific number of partitions kùëòk for PMFS sampling that yields the lowest FID outcome, irrespective of the number of distributions employed in GMM sampling. Particularly on the CelebA dataset, known for face generation, a substantial advantage of PMFS sampling over GMM sampling is apparent. Here, a notable margin separates the images generated using GMM sampling from those produced via PMFS sampling. Additionally, it‚Äôs noticeable that the optimal value for the number of partitions¬†kùëòk in PMFS sampling varies depending on the dataset. Figure 4 showcases samples of synthetic images generated through GMM and PMFS sampling using a Vanilla Autoencoder model (Additional images are provided in Appendix G). From this figure, we notice that the images generated with PMFS sampling possess a heightened realism. Notably, when PMFS sampling is applied to the CelebA dataset. For example, the first image depicts the actor Daniel Radcliffe (Harry Potter) without glasses. This observation underscores how PMFS sampling introduces data augmentation and modifications to images present in the training dataset. This enhancement emphasises the significance of our method in biometric image synthesis and data augmentation on biometric datasets. Furthermore, in Table 2, we present a face image quality assessment on the synthetic images generated using PMFS and GMM sampling via the SDD-FIQA metric . Since the SDD-FIQA metric uses a model which was not trained on the CelebA data set , we start by establishing a baseline by calculating the value of SDD-FIQA metric on the original untouched images of the CelebA data set. Then we generate 10,0001000010,000 synthetic images per sampling strategy, notably GMM sampling and PMFS, and per autoencoder model. The obtained results are presented in Table¬†2. From this table we observe improvements in terms of synthetic face image quality on all models when samples are generated through PMFS which emphasizes the performance gains of PMFS over GMM sampling. In this section, we have presented a quantitative comparison through the FID metric and a qualitative comparison via synthetic images between the GMM sampling method and our proposed method. These comparisons were conducted across five distinct autoencoder-based generative models and three diverse datasets, including two biometric datasets. Throughout these experiments, PMFS sampling consistently outperformed GMM sampling, showcasing the lowest FID values, achieving fitting times several orders of magnitude faster, producing more lifelike synthetic images across all scenarios, and on large datasets with a high number of partitions generating samples with distributions that closely resemble real-world ones.\n\nReference markers found: [18]\n\nContext windows for each [ref]:\n[ref]18: Following the training of various autoencoder-based generative models, notably the Vanilla Autoencoder , Variational Autoencoder [ref]18, Œ≤ùõΩ\\beta-VAE , Wasserstein Autoencoder¬†, and InfoVAE  on the MNIST , CelebA¬†, and MOBIUS  [ref]31   [ref]42 datasets, we computed the Fr√©chet Inception Distance FID metric. The obtained\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 18,\n            \"titles\": [\n                \"Normalizing Flows: An Introduction and Review of Current Methods\",\n                \"On the Best Lattice Quantizers\",\n                \"Hamiltonian Variational Auto-Encoder\",\n                \"A Geometric Perspective on Variational Autoencoders\",\n                \"Data Augmentation in High Dimensional Low Sample Size Setting Using a Geometry-Based Variational Autoencoder\",\n                \"Pythae: Unifying Generative Autoencoders in Python A Benchmarking Use Case\",\n                \"IùêºI-Divergence Geometry of Probability Distributions and Minimization Problems\",\n                \"Sinkhorn distances: Lightspeed computation of optimal transport\",\n                \"Hyperspherical Variational Auto-Encoders\",\n                \"PyTorch Lightning\",\n                \"From variational to deterministic autoencoders\",\n                \"Deep Learning\",\n                \"Generative adversarial nets\",\n                \"Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding\",\n                \"Array Programming with NumPy\",\n                \"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\",\n                \"Beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework\",\n                \"Matplotlib: A 2D Graphics Environment\",\n                \"Auto-Encoding Variational Bayes\",\n                \"Gradient-Based Learning Applied to Document Recognition\",\n                \"Deep Learning Face Attributes in the Wild\",\n                \"Lattice quantization\",\n                \"Iris-GAN: Learning to Generate Realistic Iris Images Using Convolutional GAN\",\n                \"The Expectation-Maximization Algorithm\",\n                \"SDD-FIQA: Unsupervised Face Image Quality Assessment with Similarity Distribution Distance\",\n                \"Normalizing Flows for Probabilistic Modeling and Inference\",\n                \"PyTorch: An Imperative Style, High-Performance Deep Learning Library\",\n                \"Scikit-learn: Machine Learning in Python\",\n                \"Computational Optimal Transport: With Applications to Data Science\",\n                \"Deep multi-class eye segmentation for ocular biometrics\",\n                \"Deep sclera segmentation and recognition\",\n                \"Improved Techniques for Training GANs\",\n                \"Introduction to differential and riemannian geometry\",\n                \"And the bit goes down: Revisiting the quantization of neural networks\",\n                \"Rethinking the inception architecture for computer vision\",\n                \"Haven‚Äôt I Seen You Before? Assessing Identity Leakage in Synthetic Irises\",\n                \"Wasserstein Auto-Encoders\",\n                \"TorchVision: PyTorch‚Äôs Computer Vision library\",\n                \"Neural Discrete Representation Learning\",\n                \"Exploring bias in sclera segmentation models: A group evaluation approach\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]18 based on the context and research area of Sampling From Autoencoders‚Äô Latent Space via Quantization And Probability Mass Function Concepts. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}