{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Binomial Tails for Community Analysis\n\nPaper Abstract: \n\nPaper Section Text:\nThe notion of confidence and in particular statistical confidence has\na range of meanings and approaches in network analysis and community\ndetection. A comprehensive classification and summarization of these\nmethods appears in He et¬†al.¬†[ref]18. In particular\nmuch of the work has been concerned with the significance of the\nentire partitioning discovered, and not on single group (candidate community) at a time\n [ref]3. Those working on significance\nof individual groups, have focused on developing algorithms for group\ndiscovery (community mining) and do not evaluate ranking given groups\n[ref]18, with the exception of the work of Zitnik et¬†al.¬†, based on which we designed much of our\nevaluation protocol and experiments. Their work shows among other\nfindings that there can be significant room for improved ranking over\nrandom or arbitrary rankings, as well as over simple measures, in particular\nModularity and Conductance. Our work shows that a simple statistics\nbased measure can also substantially improve over exiting techniques, and\nmeet our original motivation for a preference towards larger group sizes. Per classification of He et¬†al.¬†[ref]18, our work falls\nunder the analytic approach for computing significance of a single\ncommunity, but differs from others in that we consider a conditional\nevent, that given is a group of dùëëd many incident edges, and our\nnotion or candidate for an extreme event is observing di‚Äãnsubscriptùëëùëñùëõd_{in} or more\ninternal edges. In the existing approaches, a background model such\nas ER (Erdos-Reny) random graph model   or\nthe configuration model [ref]18  is\nassumed, and given a scoring function reflecting a desired community\nproperty, such as density, a formula is derived for probability of\nobserving a subgraph scoring above the observed value. One challenge\nis coming up with a good definition of community property. For\nexample, density (such as di‚Äãndsubscriptùëëùëñùëõùëë\\frac{d_{in}}{d}), ignores the total\ndegree and size of the group. Another challenge is deriving a simple\nbound that is sufficiently tight. The derivation of the binomial formula is simple and short, and the\napproximation provides both a lower and upper bound (thus one can\nbound the approximation error).888There may also exist tighter\nbounds, but possibly limited to special cases. We briefly compare\nwith the upper bound formula of He et¬†al.¬†[ref]18 (in\nSection B), and find that on synthetic datasets we tested,\nnode-based binomial has a wider range, and consistently leads to\nbetter ranking. The authors‚Äô goal is to derive a community mining\nalgorithm with the bound, and they show promising results. Subsequent work\nof the authors derives an exact bound based on the ER random graphs,\nwith improved detection results , but this bound may be\ninefficient as it requires summing factorials up to number of edges.\nTraag et¬†al.¬†use density of all the groups found in the partitioning\n(called Significance)  and later develop\nthe Surprise score for assessing an entire partitioning, which\nis based on the number of edges of all groups in the partitioning\n[ref]38. Further, they use a binomial tail (although not\nreferred to as such) with number of trials being the lesser of the\ntotal number of possible internal edges across all groups and number\nof graph edges, to asymptotically approximate their measure of\nsurprise, and present an efficient variant of Louvain algorithm for\nSurprise [ref]38. The KL divergence for approximations also\narises there. These lines of work show the promise of scoring based\non a statistical significance approach using binomials, for\ndiscovering candidate communities as well. Several approaches attempt to sample from the space of random graphs\n(ER or configuration space), such as , but these\nbecomes prohibitive for large graphs. Other approaches are somewhat\nindirect, and attempt to capture significance in terms of nodes that\nappear to least belong to a candidate group (e.g.¬† ). The work of Yang and Leskovec  introduced a\nnumber of datasets with reference groups and assessed the performance\nof a variety of scoring techniques, based on several goodness\ncriteria, using the reference groups. Later work has cautioned about\ntreating the reference as groundtruth and basing the evaluations\nheavily on comparisons to them . Community analysis\nindeed depends much on the domain and the particular goals of the\ntask. While we used the provided reference groups, we contextualized\nour comparisons to shed more light on the findings. The binomial model naturally finds numerous applications in various\nanalyses of random graphs, in counting and deriving the probability of\nfinding certain structures (e.g.¬†dense subgraphs). However, we are not\naware of this direct use of the binomial tail for scoring significance and ranking\nof candidate communities. It is a way of operationalizing what a\ncommunity means, in particular under the modern view of what\nmakes a good community [ref]3, i.e.¬†based on a comparison\nof estimates of internal (within group) vs external or overall\nprobabilities (e.g.¬†see Equation 2), rather than earlier\ndefinitions based on non-statistical functions of raw counts such as\ngroup degree and conductance.\n\nReference markers found: [18]\n\nContext windows for each [ref]:\n[ref]18: statistical confidence has\na range of meanings and approaches in network analysis and community\ndetection. A comprehensive classification and summarization of these\nmethods appears in He et¬†al.¬†[ref]18. In particular\nmuch of the work has been concerned with the significance of the\nentire partitioning discovered, and not on single group (candidate community) at a time\n [ref]3. Those working\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 18,\n            \"titles\": [\n                \"Detecting Statistically Significant Communities\",\n                \"Community detection in graphs\",\n                \"Networks: An Introduction\",\n                \"Community detection in networks: A user guide\",\n                \"Fast unfolding of communities in large networks\",\n                \"Defining and evaluating network communities based on grough-truth\",\n                \"Tutorial on large deviations for the binomial distribution\",\n                \"Information Theory\",\n                \"Centrality in Modular Networks\",\n                \"Fast algorithm for detecting community structure in networks\",\n                \"Statistics for experimenters\",\n                \"Randomized Algorithms\",\n                \"SNAP: A General Purpose Network Analysis and Graph Mining Library\",\n                \"Empirical comparison of algorithms for network community detection\",\n                \"Normalized cuts and image segmentation\",\n                \"Prioritizing network communities\",\n                \"Communities from seed sets\",\n                \"The ground truth about metadata and community detection in networks\",\n                \"Scikit-learn: Machine learning in Python\",\n                \"√âtude comparative de la distribution florale dans une portion des alpes et des jura\",\n                \"The proof and measurement of association between two things\",\n                \"The collegial phenomenon: The social mechanisms of cooperation among peers in a corporate law partnership\",\n                \"Community structure in social and biological networks\",\n                \"Statistical analysis of the indian railway network: a complex network approach\",\n                \"Network analysis software & services for organizations, communities, and their consultants\",\n                \"The political blogosphere and the 2004 US election: divided they blog\",\n                \"SNAP Datasets: Stanford large network dataset collection\",\n                \"On using nearly-independent feature families for high precision and confidence\",\n                \"Newsweeder: Learning to filter netnews\",\n                \"On the permanence of vertices in network communities\",\n                \"Introduction to Information Retrieval\",\n                \"Metrics for Community Analysis: A Survey\",\n                \"Assessing significance of connectivity and conservation in protein interaction networks\",\n                \"On the statistical significance of protein complex\",\n                \"What is a network community?: A novel quality function and detection algorithms\",\n                \"Computing exact p-values for community detection\",\n                \"Significant scales in community structure\",\n                \"Detecting communities using asymptotical surprise\",\n                \"A generalised significance test for individual communities in networks\",\n                \"Finding statistically significant communities in networks\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]18 based on the context and research area of Binomial Tails for Community Analysis. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}