{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Structure and Independence in Hyperbolic Uniform Disk Graphs\n\nPaper Abstract: \n\nPaper Section Text:\nWe can directly use our clique-based separator to compute independent sets and prove CorollaryÂ 1 via a simple divide-and conquer algorithm as in Corollary 2.4 ofÂ [ref]3. In our case, we use the trivial bound of nğ‘›n on the size of the cliques in TheoremÂ 1, which means that the weight of each clique in the separator is at most logâ¡(n+1)ğ‘›1\\log(n+1). Consequently, the separatorâ€™s weight is at most ğ’ªâ€‹((1+1/r)â€‹log2â¡n)ğ’ª11ğ‘Ÿsuperscript2ğ‘›\\mathcal{O}((1+1/r)\\log^{2}n). The proof of CorollaryÂ 1 now follows that of Corollary 2.4 ofÂ [ref]3, we merely replace the separator weight ğ’ªâ€‹(n1âˆ’1/d)ğ’ªsuperscriptğ‘›11ğ‘‘\\mathcal{O}(n^{1-1/d}) with ğ’ªâ€‹((1+1/r)â€‹log2â¡n)ğ’ª11ğ‘Ÿsuperscript2ğ‘›\\mathcal{O}((1+1/r)\\log^{2}n). We give the proof for completeness. See 1 The algorithm works as follows: First, we find a balanced separator according to TheoremÂ 1 in ğ’ªâ€‹(nâ€‹logâ¡n)ğ’ªğ‘›ğ‘›\\mathcal{O}(n\\log n) time. We can then iterate over all possible intersections Xğ‘‹X between a fixed optimum independent set and the separator. For every clique we can pick one of at most nğ‘›n vertices, or nothing, so there are (n+1)ğ’ªâ€‹(1+1/r)â€‹logâ¡n=2ğ’ªâ€‹(1+1/r)â€‹log2â¡nsuperscriptğ‘›1ğ’ª11ğ‘Ÿğ‘›superscript2ğ’ª11ğ‘Ÿsuperscript2ğ‘›(n+1)^{\\mathcal{O}(1+1/r)\\log n}=2^{\\mathcal{O}(1+1/r)\\log^{2}n} options. For each of these possible intersections, we remove all disks intersecting Xğ‘‹X, and recurse on both sides of the separator. The running time follows the recursion Tâ€‹(n)=2ğ’ªâ€‹(1+1/r)â€‹log2â¡nâ€‹Tâ€‹(23â€‹n)+nğ’ªâ€‹(1)ğ‘‡ğ‘›superscript2ğ’ª11ğ‘Ÿsuperscript2ğ‘›ğ‘‡23ğ‘›superscriptğ‘›ğ’ª1T(n)=2^{\\mathcal{O}(1+1/r)\\log^{2}n}T(\\frac{2}{3}n)+n^{\\mathcal{O}(1)}. Denoting 2xsuperscript2ğ‘¥2^{x} by exp2â¡(x)subscript2ğ‘¥\\exp_{2}(x), we can unroll this as follows: This concludes the proof.\nâˆ We note that the recursion added an extra logarithmic factor, which can be avoided via ğ’«ğ’«\\mathcal{P}-flattened treewidth. We do not optimize this running time as the resulting algorithm would still be slower than that of TheoremÂ 3. However, we do need to bound the ğ’«ğ’«\\mathcal{P}-flattened treewidth for CorollaryÂ 1. Consider a graph GâˆˆHUDGâ€‹(r)ğºHUDGğ‘ŸG\\in\\mathrm{HUDG}(r) where râˆˆğ’ªâ€‹(1)ğ‘Ÿğ’ª1r\\in\\mathcal{O}(1), let Cğ¶C be any clique of GğºG, and let sğ‘ s be the center of some disk of Cğ¶C. Then all other disk centers from Cğ¶C are contained in a disk of radius 2â€‹r2ğ‘Ÿ2r around sğ‘ s. Since râˆˆğ’ªâ€‹(1)ğ‘Ÿğ’ª1r\\in\\mathcal{O}(1), a disk of radius rğ‘Ÿr has area Î˜â€‹(r2)Î˜superscriptğ‘Ÿ2\\Theta(r^{2}), and the above argument shows that the union of the disks in Cğ¶C occupy area Î˜â€‹(r2)Î˜superscriptğ‘Ÿ2\\Theta(r^{2}). We will now decompose â„2superscriptâ„2\\mathbb{H}^{2} into regions of diameter at most 2â€‹r2ğ‘Ÿ2r such that each region has an inscribed disk of radius at least Î©â€‹(r)Î©ğ‘Ÿ\\Omega(r). The following can be derived from Lemma 2.1 (ii) ofÂ [ref]28 and from Theorem 6 ofÂ . [see [ref]28 ]\n\nFor any Î´âˆˆğ’ªâ€‹(1)ğ›¿ğ’ª1\\delta\\in\\mathcal{O}(1) there exists a subdivision of the hyperbolic plane into connected regions with the following properties: Each region has diameter less than Î´ğ›¿\\delta and thus area ğ’ªâ€‹(Î´2)ğ’ªsuperscriptğ›¿2\\mathcal{O}(\\delta^{2}). Each region has an inscribed disk of radius Î©â€‹(Î´)Î©ğ›¿\\Omega(\\delta), and thus area Î©â€‹(Î´2)Î©superscriptğ›¿2\\Omega(\\delta^{2}), Moreover, the regions containing some given set of nğ‘›n points can be computed in ğ’ªâ€‹(n)ğ’ªğ‘›\\mathcal{O}(n) time. We are now ready to prove CorollaryÂ 1. The proof merely needs to establish a clique partition ğ’«ğ’«\\mathcal{P} with a corresponding weighted treewidth bound, and the property that the graph Gğ’«subscriptğºğ’«G_{\\mathcal{P}} has maximum constant degree, that is, each clique of ğ’«ğ’«\\mathcal{P} has at most constantly many neighboring cliques. Then the machinery ofÂ [ref]3 yields the desired algorithms automatically. See 1 Use the subdivision of LemmaÂ 7 with Î´=2â€‹rğ›¿2ğ‘Ÿ\\delta=2r. We can define a clique-partition ğ’«ğ’«\\mathcal{P} of GğºG by putting disks in the same partition class whenever their centers fall in the same region of the subdivision. Clearly each created class induces a clique in GğºG as the disk centers have pairwise distance less or equal to the diameter of the region, which is at most 2â€‹r2ğ‘Ÿ2r. Fix such a clique partition ğ’«ğ’«\\mathcal{P}, and consider now a separator from TheoremÂ 1. If Xğ‘‹X is one of the cliques in the separator, then let pxsubscriptğ‘ğ‘¥p_{x} be the center of some disk of Xğ‘‹X. If Câˆˆğ’«ğ¶ğ’«C\\in\\mathcal{P} and Xğ‘‹X contain disks that intersect each other, then the graph distance of any pair of disks in Cğ¶C and Xğ‘‹X is at most 333. Consequently, all disk centers in CâˆªXğ¶ğ‘‹C\\cup X are covered by a disk Dğ·D of radius 3â‹…2â€‹r=6â€‹râ‹…32ğ‘Ÿ6ğ‘Ÿ3\\cdot 2r=6r around pxsubscriptğ‘ğ‘¥p_{x}. Since each region of ğ’«ğ’«\\mathcal{P} has area Î©â€‹(r2)Î©superscriptğ‘Ÿ2\\Omega(r^{2}), there can be at most ğ’ªâ€‹(1)ğ’ª1\\mathcal{O}(1) regions of the subdivision contained inside Dğ·D. In particular, Xğ‘‹X can intersect at most ğ’ªâ€‹(1)ğ’ª1\\mathcal{O}(1) cliques from ğ’«ğ’«\\mathcal{P}. Consider all cliques from ğ’«ğ’«\\mathcal{P} that are intersected by the separator cliques of TheoremÂ 1: they clearly form a separator, and the above argument shows that there are ğ’ªâ€‹((1+1/r)â€‹logâ¡n)ğ’ª11ğ‘Ÿğ‘›\\mathcal{O}((1+1/r)\\log n) such cliques in ğ’«ğ’«\\mathcal{P}. Since each clique of ğ’«ğ’«\\mathcal{P} has weight at most 1+logâ¡n1ğ‘›1+\\log n, we get a separator of weight ğ’ªâ€‹((1+1/r)â€‹log2â¡n)ğ’ª11ğ‘Ÿsuperscript2ğ‘›\\mathcal{O}((1+1/r)\\log^{2}n) over ğ’«ğ’«\\mathcal{P}. NowÂ [ref]3 (see also [ref]28) implies that the ğ’«ğ’«\\mathcal{P}-flattened treewidth of GğºG is ğ’ªâ€‹((1+1/r)â€‹log2â¡n)ğ’ª11ğ‘Ÿsuperscript2ğ‘›\\mathcal{O}((1+1/r)\\log^{2}n). Since ğ’«ğ’«\\mathcal{P} is a clique-partition with the additional property that each partition class is neighboring to ğ’ªâ€‹(1)ğ’ª1\\mathcal{O}(1) other cliques, we can apply the entire machinery ofÂ [ref]3 and derive the required algorithms.\nâˆ\n\nReference markers found: [3]\n\nContext windows for each [ref]:\n[ref]3: We can directly use our clique-based separator to compute independent sets and prove CorollaryÂ 1 via a simple divide-and conquer algorithm as in Corollary 2.4 ofÂ [ref]3. In our case, we use the trivial bound of nğ‘›n on the size of the cliques in TheoremÂ 1, which means that the weight of each clique in the separator is at most logâ¡(n+1)ğ‘›1\\log(n+1).\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 3,\n            \"titles\": [\n                \"Clique-Based Separators for Geometric Intersection Graphs\",\n                \"Label placement by maximum independent set in rectangles\",\n                \"Approximation Algorithms for NP-Complete Problems on Planar Graphs\",\n                \"A Framework for Exponential-Time-Hypothesis-Tight Algorithms and Lower Bounds in Geometric Intersection Graphs\",\n                \"Recognizing Unit Disk Graphs in Hyperbolic Geometry is âˆƒâ„â„\\\\exists\\\\mathbb{R}-Complete\",\n                \"Solving Vertex Cover in Polynomial Time on Hyperbolic Random Graphs\",\n                \"Efficient Shortest Paths in Scale-Free Networks with Underlying Hyperbolic Geometry\",\n                \"Efficiently Approximating Vertex Cover on Scale-Free Networks with Underlying Hyperbolic Geometry\",\n                \"Strongly Hyperbolic Unit Disk Graphs\",\n                \"Hyperbolic Random Graphs: Separators and Treewidth\",\n                \"A Partial k-Arboretum of Graphs with Bounded Treewidth\",\n                \"Chordal embeddings of planar graphs\",\n                \"On Geometric Set Cover for Orthants\",\n                \"Polynomial-time approximation schemes for packing and piercing fat objects\",\n                \"Parameterized Algorithms\",\n                \"Efficient Exact Algorithms on Planar Graphs: Exploiting Sphere Cut Decompositions\",\n                \"Safe Reduction Rules for Weighted Treewidth\",\n                \"Fast Algorithms for Shortest Paths in Planar Graphs, with Applications\",\n                \"On the diameter of hyperbolic random graphs\",\n                \"Euclidean and Non-Euclidean Geometries: Development and History\",\n                \"Random Hyperbolic Graphs: Degree Sequence and Clustering\",\n                \"Approximately: Independence Implies Vertex Cover\",\n                \"Quasi-Polynomial Time Approximation Scheme for Sparse Subsets of Polygons\",\n                \"Approximation Schemes for Covering and Packing Problems in Image Processing and VLSI\",\n                \"On the complexity of SAT\",\n                \"Computing a Centerpoint of a Finite Planar Set of Points in Linear Time\",\n                \"A quasi-polynomial algorithm for well-spaced hyperbolic TSP\",\n                \"Hyperbolic intersection graphs and (quasi)-polynomial time\",\n                \"A Quadtree, a Steiner Spanner, and Approximate Nearest Neighbours in Hyperbolic Space\",\n                \"Kontaktprobleme der konformen Abbildung\",\n                \"Hyperbolic Geometry of Complex Networks\",\n                \"A separator theorem for planar graphs\",\n                \"Applications of a planar separator theorem\",\n                \"Simple heuristics for unit disk graphs\",\n                \"On the Optimality of Planar and Geometric Approximation Schemes\",\n                \"On Subexponential Parameterized Algorithms for Steiner Tree and Directed Subset TSP on Planar Graphs\",\n                \"Optimal Parameterized Algorithms for Planar Facility Location Problems Using Voronoi Diagrams\",\n                \"Integer realizations of disk and segment graphs\",\n                \"Separators for sphere-packings and nearest neighbor graphs\",\n                \"The Diameter of KPKVB Random Graphs\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]3 based on the context and research area of Structure and Independence in Hyperbolic Uniform Disk Graphs. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}