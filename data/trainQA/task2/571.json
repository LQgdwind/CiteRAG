{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Sparse Approximate Multifrontal Factorization with Butterfly Compression for High Frequency Wave Equations\n\nPaper Abstract: \n\nPaper Section Text:\nDirect solution of large sparse linear systems arsing from e.g., finite-difference, finite-element or finite-volume discretization of partial differential equations (PDE) is crucial for many high-performance scientific and engineering simulation codes. Efficient solution of these sparse systems often requires reordering the matrix to improve numerical stability and fill-in ratios, and performing the computations on smaller but dense submatrices to improve flop performance. Examples include supernodal and multifrontal methods that perform operations on so-called\nsupernodes and frontal matrices, respectivelyÂ  .\nFor multifrontal methodsÂ , the size nğ‘›n of the frontal matrices can grow as\nn=ğ’ªâ€‹(N1/2)ğ‘›ğ’ªsuperscriptğ‘12n=\\mathcal{O}(N^{1/2}) and n=ğ’ªâ€‹(N2/3)ğ‘›ğ’ªsuperscriptğ‘23n=\\mathcal{O}(N^{2/3}) for typical 2D and 3D PDEs with Nğ‘N denoting the system size. Performing dense factorization and solution on the frontal matrices requires ğ’ªâ€‹(n3)ğ’ªsuperscriptğ‘›3\\mathcal{O}(n^{3}) operations, yielding the overall complexities of ğ’ªâ€‹(N3/2)ğ’ªsuperscriptğ‘32\\mathcal{O}(N^{3/2}) in 2D and ğ’ªâ€‹(N2)ğ’ªsuperscriptğ‘2\\mathcal{O}(N^{2}) in 3D. The same complexities also apply to supernodal methods. For many applications arising from wide classes of PDEs, these complexities can be reduced by leveraging algebraic compression tools to exploit rank structures in blocks of the matrix inverse. For example, it can be rigorously shown that, for elliptical PDEs with constant or smooth coefficients, certain off-diagonal blocks in a frontal matrix exhibit low-ranknessÂ . Low-rank based fast direct solvers, including â„‹â„‹\\mathcal{H}Â   and â„‹2superscriptâ„‹2\\mathcal{H}^{2} matricesÂ , hierarchically off-diagonal low-rank (HOD-LR) formatsÂ , sequentially semi-separable formats , hierarchically semi-separable (HSS) formats , and block low-rank (BLR) formats   , represent off-diagonal blocks as low-rank products and leverage fast algebras to perform efficient matrix factorization. These methods were first developed to address dense systems, e.g., arising from boundary element methods, in quasi-linear complexity and have been recently adapted for sparse systems. Examples include solvers coupling â„‹â„‹\\mathcal{H} , HOD-LR [ref]5, HSS   9 or BLR  with multifrontal methods, which we will refer to as rank structured multifrontal methods, and solvers coupling HOD-LR 2 or BLR  with supernodal methods, solvers based on the inverse fast multipole method , and multifrontal-like solvers based on hierarchical interpolative factorization (HIF) 1 5. Available software packages include STRUMPACKÂ 9, MUMPSÂ , and PaStiXÂ 9 . It is worth mentioning that many of these methods rely on fast entry evaluation or randomized matrix vector multiplication (matvec) to compress the frontal matrices, without explicitly forming them. Despite differences in the leading constants, implementation details and applicability of these compression formats, in general they lead to quasi-linear complexity direct solvers and preconditioners when applied to many elliptical PDEs. Unfortunately, when applied to wave equations, such as Helmholtz, Maxwell, or SchrÃ¶dinger equations with constant or non-constant coefficients, the frontal matrices exhibit much higher numerical ranks due to the highly oscillatory nature of the numerical Greenâ€™s functionÂ 8 and consequently no asymptotic complexity reduction compared to the exact sparse solvers can be attained. That said, the low-rank based sparse direct solver packages (e.g., STRUMPACK and MUMPS) oftentimes significantly reduce the costs of exact sparse solvers for practical wave equation systems , and scale quasi-linearly when the 3D computation domain spans less than a few wavelengths. In contrast to low-rank-based algorithms, we consider another algebraic compression tool called butterfly  8 4 3 , for constructing fast multifrontal methods for wave equations. Butterfly is a multilevel matrix decomposition algorithm well-suited for representing highly oscillatory operators such as Fourier transforms and integral operators 1   and special function transforms   . When combined with hierarchical matrix techniques, butterfly can also serve as the building block for accelerating iterative methodsÂ , direct solversÂ 1 2 4 7 and preconditionersÂ 9 for boundary element methods for high-frequency wave equations. These techniques essentially replace low-rank products in the â„‹â„‹\\mathcal{H}Â 2, â„‹2superscriptâ„‹2\\mathcal{H}^{2}Â  0 and HOD-LR formatsÂ 7 with butterflies, and leverage fast and randomized butterfly algebra to compute the matrix inverse (for direct solvers and preconditioners). We particularly focus on the butterfly extension of the HOD-LR formatÂ 7,\ncalled HOD-BF in this paper. The HOD-BF format yields smaller leading constants and better parallel performance compared to other butterfly-enhanced hierarchical matrix formats. Moreover, HOD-BF can attain an ğ’ªâ€‹(nâ€‹log2â¡n)ğ’ªğ‘›superscript2ğ‘›\\mathcal{O}(n\\log^{2}n) compression complexity and an empirical ğ’ªâ€‹(n3/2â€‹logâ¡n)ğ’ªsuperscriptğ‘›32ğ‘›\\mathcal{O}(n^{3/2}\\log n) inversion complexity given an nÃ—nğ‘›ğ‘›n\\times n HOD-BF compressible dense matrix. HOD-BF has been previously applied to both 2DÂ 7 and 3D boundary element methods. In this paper, we leverage the HOD-BF format for compressing the frontal matrices in the multifrontal method. The proposed algorithm is formulated as AlgorithmÂ 5, which combines several butterfly algorithms at multiple phases of the multifrontal method. Specifically, any non-root frontal matrix has a 2Ã—2222\\times 2 blocked partition, and each block represents numerical Greenâ€™s function interactions between unknowns residing on planar or crossing planes (or lines). These blocks are compressed as butterfly or HOD-BF by extracting selected matrix entriesÂ  , from the children frontal matrices and the original sparse matrix. Moreover, the method factorizes the leading diagonal block using the HOD-BF inversion technique 7 and compute its Schur complement with the randomized butterfly construction algorithm 8. Itâ€™s worth mentioning that efficient integration of butterfly algorithms into the multifrontal method requires several algorithmic innovations. First, butterfly construction of frontal blocks requires sub-sampling matrix entries using proxy rows and columns to maintain quasi-linear complexities. These proxies are selected by combining uniform sampling and nearest neighbor sampling, computed using the graph distance (see AlgorithmÂ 2). Second, matrix sub-sampling boils down to extracting entries from the compressed children frontal matrices, implemented as partial matvec in a blocked and parallel fashion (AlgorithmÂ 3). Given a frontal matrix of size nÃ—nğ‘›ğ‘›n\\times n, the construction and factorization can be performed in ğ’ªâ€‹(n3/2â€‹logâ¡n)ğ’ªsuperscriptğ‘›32ğ‘›\\mathcal{O}(n^{3/2}\\log n) complexity. Consequently, for a sparse matrix resulting from 2D and 3D high frequency wave equations, the solver can attain an overall complexity of ğ’ªâ€‹(N)ğ’ªğ‘\\mathcal{O}(N) and ğ’ªâ€‹(Nâ€‹log2â¡N)ğ’ªğ‘superscript2ğ‘\\mathcal{O}(N\\log^{2}N), respectively. It is worth mentioning the same complexities can be attained for 2D and 3D low-frequency or static PDEs such as the Poisson equation. To the best of our knowledge, the proposed solver represents the first-ever quasi-linear complexity multifrontal solver for high-frequency wave equations in 3D. As a related work, the sweeping preconditioner-based domain decomposition solversÂ  represent another quasi-linear complexity technique for wave equations and impressive numerical results have been reported for both 2D and 3D cases. However, sweeping preconditioners only apply to regular grids and domains and do not work well for domains containing resonant cavities. In comparison, the proposed solver does not suffer from these constraints and applies to wider classes of applications. In addition, the proposed solver can be used inside domain decomposition solvers, which often use multifrontal solvers for their local sparse systems. The rest of the paper is organized as follows. The multifrontal method is presented in SectionÂ 2. The butterfly format, construction and entry extraction algorithms are described in SectionÂ 3, followed by their generalization to the HOD-BF format in SectionÂ 4. The proposed rank structured multifrontal method is detailed in SectionÂ 5, including complexity analysis. Numerical results demonstrating the efficiency and applicability of the proposed solver for the 3D Helmholtz, Maxwell, and Poisson equations are presented in SectionÂ 6, followed by conclusions in SectionÂ 7.\n\nReference markers found: [5]\n\nContext windows for each [ref]:\n[ref]5: dense systems, e.g., arising from boundary element methods, in quasi-linear complexity and have been recently adapted for sparse systems. Examples include solvers coupling â„‹â„‹\\mathcal{H} , HOD-LR [ref]5, HSS   9 or BLR  with multifrontal methods, which we will refer to as rank structured multifrontal methods, and solvers coupling HOD-LR 2 or BLR  with supernodal methods, solvers based on the\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 5,\n            \"titles\": [\n                \"MFEM: A Modular Finite Element Methods Library\",\n                \"An ğ’ªâ€‹(Nâ€‹logâ¡N)ğ’ªğ‘ğ‘\\\\mathcal{O}(N\\\\log N) fast direct solver for partial hierarchically semi-separable matrices\",\n                \"Improving multifrontal methods by means of block low-rank representations\",\n                \"Performance and scalability of the block low-rank multifrontal factorization on multicore architectures\",\n                \"Bridging the gap between flat and hierarchical low-rank matrix formats: The multilevel block low-rank format\",\n                \"A Fast Block Low-Rank Dense Solver with Applications to Finite-Element Matrices\",\n                \"A distributed-memory algorithm for computing a heavy-weight perfect matching on bipartite graphs\",\n                \"Rapid Application of the Spherical Harmonic Transform via Interpolative Decomposition Butterfly Factorization\",\n                \"On the spatial bandwidth of scattered fields\",\n                \"Directional â„‹2superscriptâ„‹2\\\\mathcal{H}^{2}-matrix compression for high-frequency problems\",\n                \"A fast butterfly algorithm for the computation of Fourier integral operators\",\n                \"An Efficient Solver for Sparse Linear Systems Based on Rank-Structured Cholesky Factorization\",\n                \"On the numerical rank of the off-diagonal blocks of Schur complements of discretized elliptic PDEs\",\n                \"A survey of direct methods for sparse linear systems\",\n                \"The design and use of algorithms for permuting large entries to the diagonal of sparse matrices\",\n                \"The multifrontal solution of indefinite sparse symmetric linear\",\n                \"Direct Methods for Sparse Matrices, Second Edition\",\n                \"Approximate separability of the Greenâ€™s function of the Helmholtz equation in the high frequency limit\",\n                \"A robust parallel preconditioner for indefinite systems using hierarchical matrices and randomized sampling\",\n                \"Construction and arithmetics of H-matrices\",\n                \"On MLMDA/butterfly compressibility of inverse integral operators\",\n                \"A butterfly-based direct integral-equation solver using hierarchical LU factorization for analyzing scattering from electrically large conducting objects\",\n                \"A butterfly-based direct solver using hierarchical LU factorization for Poggio-Miller-Chang-Harrington-Wu-Tsai equations\",\n                \"A sparse matrix arithmetic based on â„‹â„‹\\\\mathcal{H}-matrices. Part I: Introduction to â„‹â„‹\\\\mathcal{H}-matrices\",\n                \"Data-sparse approximation by adaptive â„‹2superscriptâ„‹2\\\\mathcal{H}^{2}-matrices\",\n                \"Hierarchical matrices based on a weak admissibility criterion\",\n                \"Updating the inverse of a matrix\",\n                \"PaStiX: a High-Performance Parallel Direct Solver for Sparse Symmetric Positive Definite Systems\",\n                \"A fast direct solver for structured linear systems by recursive skeletonization\",\n                \"Hierarchical interpolative factorization for elliptic operators: differential equations\",\n                \"A fast and high quality multilevel scheme for partitioning irregular graphs\",\n                \"Interpolative butterfly factorization\",\n                \"Butterfly factorization\",\n                \"Distributed-memory Hierarchical Interpolative Factorization\",\n                \"The multifrontal method for sparse matrix solution: theory and practice\",\n                \"An HSS matrix-inspired butterfly-based direct solver for analyzing scattering from two-dimensional objects\",\n                \"Butterfly factorization via randomized matrix-vector multiplications\",\n                \"A Hierarchical Butterfly LU Preconditioner for Two-Dimensional Electromagnetic Scattering Problems Involving Open Surfaces\",\n                \"Marmousi2: An elastic upgrade for Marmousi\",\n                \"Multilevel evaluation of electromagnetic fields for the rapid solution of scattering problems\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]5 based on the context and research area of Sparse Approximate Multifrontal Factorization with Butterfly Compression for High Frequency Wave Equations. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}