{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Orientation-Preserving Vectorized Distance Between Curves\n\nPaper Abstract: \n\nPaper Section Text:\nThis paper on the other hand starts with the goal of embedding ordered/oriented curve (and shape) data to a Euclidean vector space, where inner products are natural, fast nearest neighbor search is easily available, and it can directly be dropped into any machine learning or other data analysis frameworks. This builds on recent work with a similar goals for halfspaces, curves, and other shapes [ref]44 . But that work did not encode orientation.\nThis orientation-preserving aspect of these distances is clearly important for some applications; it is needed to say distinguish someone going to work versus returning from work. Why might Fréchet be better for data analysis than discrete Fréchet or DTW or the many other distances? One can potentially point to long segments and no need to discretize, or (quasi-)metric properties. Regardless, an equalizer is in determining how well a distance models data is the prediction error for classification tasks; such tasks demonstrate how well the distances encode what truely matters on real tasks. The previous vectorized representations matched or outperformed a dozen other measures [ref]44. In this paper, we show an oriented distance performs similarly on general tasks, but when orientation is essential, does significantly better than non-orientation preserving measures.\nMoreover, by extending properties from similar, but non-orientable vectorized distances [ref]44 , our proposed distance inherits metric properties, can handle long segments, and also captures curve orientation. More specifically, our approach assumes all objects are in a bounded domain ΩΩ\\Omega a subset of ℝdsuperscriptℝ𝑑\\mathbb{R}^{d} (typically ℝ2superscriptℝ2\\mathbb{R}^{2}). This domain contains a set of landmark points Q𝑄Q, which might constitute a continuous uniform measure over ΩΩ\\Omega, or a finite sample approximation of that distribution. With respect to an object γ𝛾\\gamma, each landmark qi∈Qsubscript𝑞𝑖𝑄q_{i}\\in Q generates a value vqi​(γ)subscript𝑣subscript𝑞𝑖𝛾v_{q_{i}}(\\gamma). Each of these values vqi​(γ)subscript𝑣subscript𝑞𝑖𝛾v_{q_{i}}(\\gamma) can correspond with the i𝑖ith coordinate in a vector vQ​(γ)subscript𝑣𝑄𝛾v_{Q}(\\gamma), which is finite (with |Q|=n𝑄𝑛|Q|=n-dimensions) if Q𝑄Q is finite. Then the distance between two objects γ𝛾\\gamma and γ′superscript𝛾′\\gamma^{\\prime} is the square-root of the average squared distance of these values – or the Euclidean distance of the finite vectors The innovation of this paper is in the definition of the value vqi​(⋅)subscript𝑣subscript𝑞𝑖⋅v_{q_{i}}(\\cdot) and the implications around that choice. In particular in previous works by [ref]44 , in this framework, this had been (mostly) set as the unsigned minDist function: vq𝗆𝖣​(γ)=minp∈γ⁡‖p−q‖subscriptsuperscript𝑣𝗆𝖣𝑞𝛾subscript𝑝𝛾norm𝑝𝑞v^{\\mathsf{mD}}_{q}(\\gamma)=\\min_{p\\in\\gamma}\\|p-q\\|. In this paper we alter this definition to not only capture the distance to the shape γ𝛾\\gamma, but in allowing negative values to also capture the orientation of it. This new definition leads to many interesting structural properties about shapes. These include: We show that 𝚍Fsubscript𝚍𝐹\\mathtt{d}_{F} is stable up to Fréchet perturbations of the curves. In particular, for two curves γ,γ′𝛾superscript𝛾′\\gamma,\\gamma^{\\prime} which are closed, then\n𝚍Q​(γ,γ′)<𝚍F​(γ,γ′)subscript𝚍𝑄𝛾superscript𝛾′subscript𝚍𝐹𝛾superscript𝛾′\\mathtt{d}_{Q}(\\gamma,\\gamma^{\\prime})<\\mathtt{d}_{F}(\\gamma,\\gamma^{\\prime}),\nwhere 𝚍Fsubscript𝚍𝐹\\mathtt{d}_{F} is the Fréchet distance.\nMoreover, for an l∞superscript𝑙l^{\\infty} variant of the distance 𝚍Q∞superscriptsubscript𝚍𝑄\\mathtt{d}_{Q}^{\\infty} (see Definition 1.1),\nand the curves are closed, we obtain 𝚍F​(γ,γ′)=𝚍Q∞​(γ,γ′)subscript𝚍𝐹𝛾superscript𝛾′superscriptsubscript𝚍𝑄𝛾superscript𝛾′\\mathtt{d}_{F}(\\gamma,\\gamma^{\\prime})=\\mathtt{d}_{Q}^{\\infty}(\\gamma,\\gamma^{\\prime}).\nThus 𝚍Qsubscript𝚍𝑄\\mathtt{d}_{Q} captures orientation.\nIn contrast for a class of curves we show 𝚍QmD,∞{\\mathtt{d}^{\\textsf{mD}}_{Q}}^{,\\infty} can equal Hausdorff distance, so this older version explicitly does not capture orientation. We introduce a new stability notion called the signed local feature size for oriented curves and other shapes γ𝛾\\gamma. While it does not rely on the new signed vqi​(γ):ℝd→ℝ:subscript𝑣subscript𝑞𝑖𝛾→superscriptℝ𝑑ℝv_{q_{i}}(\\gamma):\\mathbb{R}^{d}\\to\\mathbb{R} distance function, it captures a scale under which vqi​(γ)subscript𝑣subscript𝑞𝑖𝛾v_{q_{i}}(\\gamma) is stable.\nUnlike its unsigned counterpart (local feature size, which plays a prominent role in shape reconstruction    and computational topology   ), the signed local feature size is infinite for closed simple curves. This in turn implies 𝚍Qsubscript𝚍𝑄\\mathtt{d}_{Q} is stable with respect to Q𝑄Q for all closed simple curves, where as notions which depend on (unsigned) local feature size (e.g., medial axis) are not. For curves with boundary, the signed local feature size requires a more intricate treatment.\nWe show that when the signed local feature size δ𝛿\\delta is positive but finite (0<δ<∞0𝛿0<\\delta<\\infty) then we can set a scale parameter σ𝜎\\sigma in the definition of vqsubscript𝑣𝑞v_{q} (denoted vqσsuperscriptsubscript𝑣𝑞𝜎v_{q}^{\\sigma}) and in 𝚍Qsubscript𝚍𝑄\\mathtt{d}_{Q} (denoted 𝚍Qσsuperscriptsubscript𝚍𝑄𝜎\\mathtt{d}_{Q}^{\\sigma}) so when σ<δ/(4(1+ln⁡(2/ε))\\sigma<\\delta/(4(1+\\sqrt{\\ln(2/\\varepsilon)}), then the signed distance function viσsuperscriptsubscript𝑣𝑖𝜎v_{i}^{\\sigma} is stable up to value ε𝜀\\varepsilon. Altogether, these results build and analyze a new vectorized, and sketchable distance between curves (or other geometric objects) which captures orientation like Fréchet (or dynamic time warping, and other popular measures), but avoids all of the complications when actually used. As we demonstrate, fast nearest neighbor search, machine learning, clustering, etc are all now very easy. By a curve we mean the image of a continuous non-constant mapping γ: →ℝ2:𝛾→01superscriptℝ2\\gamma: \\to\\mathbb{R}^{2}; we simply use γ𝛾\\gamma to refer to these curves. Two curves are equivalent if they can be reparameterized by an increasing monotone function to be identical. Hence there are two equivalence classes corresponding to the same trace of a curve, these two classes correspond to the direction of the curve.\nA curve γ𝛾\\gamma is closed if γ​(0)=γ​(1)𝛾0𝛾1\\gamma(0)=\\gamma(1).\nIt is simple if the mapping does not cross itself, i.e. γ𝛾\\gamma is one-to-one function. Let ΓΓ\\Gamma be the class of all simple curves γ𝛾\\gamma in ℝ2superscriptℝ2\\mathbb{R}^{2} with the property that at almost every point p𝑝p on γ𝛾\\gamma, considering the direction of the curve, there is a unique normal vector npsubscript𝑛𝑝n_{p} at p𝑝p, i.e. there is a tangent line almost everywhere on γ𝛾\\gamma. Such points are called regular points of γ𝛾\\gamma and the set of regular points of γ𝛾\\gamma is denoted by reg(γ)reg𝛾\\mathop{\\rm reg}(\\gamma). Points of γ∖reg(γ)𝛾reg𝛾\\gamma\\setminus\\mathop{\\rm reg}(\\gamma) are called critical points of γ𝛾\\gamma. The terminology “almost every point” means that the Lebesgue measure of those t∈ 𝑡01t\\in  such that γ​(t)𝛾𝑡\\gamma(t) is a critical point is zero. We also assume that at critical points, which are not endpoints of a non-closed curve, γ𝛾\\gamma is left and right differentiable but left and right derivatives are possibly not identical, that is, left and right tangent lines exist. Finally, we assume that non-closed curves in ΓΓ\\Gamma have left/right tangent line at endpoints. These assumptions will guarantee the existence of a unique normal vector at critical points that are defined in Section 1.1.\n\nReference markers found: [44]\n\nContext windows for each [ref]:\n[ref]44: easily available, and it can directly be dropped into any machine learning or other data analysis frameworks. This builds on recent work with a similar goals for halfspaces, curves, and other shapes [ref]44 . But that work did not encode orientation.\nThis orientation-preserving aspect of these distances is clearly important for some applications; it is needed to say distinguish someone going to\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 44,\n            \"titles\": [\n                \"Sketched MinDist\",\n                \"Computing the discrete frechet distance in subquadratic time\",\n                \"Generalized self- approaching curves\",\n                \"Computing the fréchet distance between two polygonal curves\",\n                \"Comparison of distance measures for planar curves\",\n                \"Surface reconstruction by voronoi filtering\",\n                \"The power crust\",\n                \"The power crust, unions of balls, and the medial axis transform\",\n                \"graph\",\n                \"Edit distance cannot be computed in strongly subquadratic time (unless seth is false)\",\n                \"A fast implementation of near neighbors queries for Fréchet distance (GIS Cup)\",\n                \"Why walking the dog takes time: Fréchet distance has no strongly subquadratic algorithms unless SETH fails\",\n                \"Quadratic Conditional Lower Bounds for String Problems and Dynamic Time Warping\",\n                \"Walking the Dog Fast in Practice: Algorithm Engineering of the Fréchet Distance\",\n                \"Four soviets walk the dog: Improved bounds for computing the fréchet distance\",\n                \"Efficient trajectory queries under the fréchet distance (gis cup)\",\n                \"klcluster: Center-based clustering of trajectories\",\n                \"Geometric inference\",\n                \"Geometric inference for probability measures\",\n                \"Robust topolical inference: Distance-to-a-measure and kernel distance\",\n                \"The “λ𝜆\\\\lambda-medial axis”\",\n                \"Robust and fast similarity search for moving object trajectories\",\n                \"Delaunay mesh generation\",\n                \"GPS Trajectories Data Set, February 2016.\",\n                \"Fast frechet queries\",\n                \"Approximating the fréchet distance for realistic curves in near linear time\",\n                \"Clustering time series under the Frechet distance\",\n                \"Sublinear data structures for short Fréchet queries\",\n                \"Locality-sensitive hashing of curves\",\n                \"A filter-and-refinement-algorithm for range queries based on the fréchet distance (gis cup)\",\n                \"Computing discrete Frechet distance\",\n                \"Approximate Nearest Neighbor for Curves: Simple, Efficient, and Deterministic\",\n                \"Fast Fréchet Distance Between Curves with Long Edges\",\n                \"Algebraic topology\",\n                \"On approximate nearest neighbors in non-euclidean spaces\",\n                \"Imagenet classification with deep convolutional neural networks\",\n                \"Medial axis transformation of a planar shape\",\n                \"Faster retrieval with a two-pass dynamic-time-warping lower bound\",\n                \"Marching cubes: A high resolution 3d surface construction algorithm\",\n                \"Objectively identifying landmark use and predicting flight trajectories of the homing pigeon using gaussian processes\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]44 based on the context and research area of Orientation-Preserving Vectorized Distance Between Curves. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}