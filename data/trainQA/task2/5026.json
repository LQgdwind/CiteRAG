{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Outcome-Oriented Prescriptive Process Monitoring Based on Temporal Logic Patterns\n\nPaper Abstract: \n\nPaper Section Text:\nSince the proposed approach leverages a DT trained on â„’tâ€‹râ€‹aâ€‹iâ€‹nsubscriptâ„’ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›\\mathcal{L}_{train} to provide recommendations, we first inspect the performance of the DT in the classification of the outcome of (complete) traces in â„’vâ€‹aâ€‹lsubscriptâ„’ğ‘£ğ‘ğ‘™\\mathcal{L}_{val} and â„’tâ€‹râ€‹aâ€‹iâ€‹nsubscriptâ„’ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›\\mathcal{L}_{train} as positive or negative.\nTable 7 shows the average F-score of the DT on â„’vâ€‹aâ€‹lsubscriptâ„’ğ‘£ğ‘ğ‘™\\mathcal{L}_{val} and â„’tâ€‹râ€‹aâ€‹iâ€‹nsubscriptâ„’ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›\\mathcal{L}_{train}. We notice that the majority of the classifiers have good performance on both the validation and train folds with an absence (or a low degree) of overfitting. However, the hâ€‹oâ€‹sâ€‹pâ€‹iâ€‹tâ€‹aâ€‹lâ€‹_â€‹bâ€‹iâ€‹lâ€‹lâ€‹iâ€‹nâ€‹gâ€‹_â€‹2â„ğ‘œğ‘ ğ‘ğ‘–ğ‘¡ğ‘ğ‘™_ğ‘ğ‘–ğ‘™ğ‘™ğ‘–ğ‘›ğ‘”_2hospital\\_billing\\_2 and the sâ€‹eâ€‹pâ€‹sâ€‹iâ€‹sâ€‹_â€‹câ€‹aâ€‹sâ€‹eâ€‹sâ€‹_â€‹1ğ‘ ğ‘’ğ‘ğ‘ ğ‘–ğ‘ _ğ‘ğ‘ğ‘ ğ‘’ğ‘ _1sepsis\\_cases\\_1 datasets present low performance on both â„’vâ€‹aâ€‹lsubscriptâ„’ğ‘£ğ‘ğ‘™\\mathcal{L}_{val} and â„’tâ€‹râ€‹aâ€‹iâ€‹nsubscriptâ„’ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›\\mathcal{L}_{train}. This underfitting is due to the insufficient information carried by the adopted encoding. We checked this aspect by inspecting the traces of these datasets with the Disco555https://fluxicon.com/disco/ tool. We noticed that both positive and negative labeled traces present a very similar control flow. Therefore, any ML classifier taking as input traces encoded with our declare-based encoding does not have sufficient information for discriminating between positive and negative samples. As future work, we aim at enriching our encoding with information regarding the data payloads attached to events and their execution times to overcome this issue.\nIn general, no significant difference between families of declare constraints used for trace encoding is found in these results. Only the sâ€‹eâ€‹pâ€‹sâ€‹iâ€‹sâ€‹_â€‹câ€‹aâ€‹sâ€‹eâ€‹sâ€‹_â€‹2ğ‘ ğ‘’ğ‘ğ‘ ğ‘–ğ‘ _ğ‘ğ‘ğ‘ ğ‘’ğ‘ _2sepsis\\_cases\\_2 dataset benefits of a higher number of features provided in the ğ’œğ’œ\\mathcal{A} family. We now discuss the results related to the returned recommendations.\nFigures 5 and 6 show the trend of the F-score for different prefix lengths kğ‘˜k computed on each prefix Ïƒksubscriptğœğ‘˜\\sigma_{k} in â„’tâ€‹eâ€‹sâ€‹tâˆ—superscriptsubscriptâ„’ğ‘¡ğ‘’ğ‘ ğ‘¡\\mathcal{L}_{test}^{*}.\nBoth figures show the cumulative results, that is, the Tâ€‹Pğ‘‡ğ‘ƒTP, Tâ€‹Nğ‘‡ğ‘TN, Fâ€‹Pğ¹ğ‘ƒFP and Fâ€‹Nğ¹ğ‘FN at a given prefix length kğ‘˜k are summed to the corresponding ones at prefix jâ‰¤kğ‘—ğ‘˜j\\leq k.\nThis is done to avoid that the results are influenced by the small number of traces that usually characterize long tracesÂ [ref]9.\nThe average over all the prefixes is reported in TableÂ 8. Both the figures and the table show very good results in general, that is, the proposed Prescriptive Process Monitoring system returns recommendations that guarantee a positive outcome in a trace. When the recommendations are not followed, instead, the corresponding traces have, in most of the cases, a negative outcome (RQ1). For some datasets, our system reaches an F-score of 100% along all prefixes. This is due to the encoding with declare patterns that creates a semantically rich feature space that allows a crisp discrimination between regions containing only positive and regions containing only negative samples. In addition, the resulting DTs have a depth of maximum 4 with a consequent lower number of temporal relations to satisfy. Therefore, the fitness and the overall performance of the system increase.\n Although, in most of the cases, the high discriminating power of the temporal constraints on the control flow obtained with the declare encoding guarantees accurate results, for some logs, the declare encoding does not achieve such a good performance. The pâ€‹râ€‹oâ€‹dâ€‹uâ€‹câ€‹tâ€‹iâ€‹oâ€‹nğ‘ğ‘Ÿğ‘œğ‘‘ğ‘¢ğ‘ğ‘¡ğ‘–ğ‘œğ‘›production dataset, for instance, has a DT with depth 8 and contains several paths. In this situation, finding the best path is harder, the fitness score that can be achieved is lower and, as a consequence, the overall performance of the Prescriptive Process Monitoring system decreases. Moreover, our system poorly performs on the sâ€‹eâ€‹pâ€‹sâ€‹iâ€‹sâ€‹_â€‹câ€‹aâ€‹sâ€‹eâ€‹sâ€‹_â€‹1ğ‘ ğ‘’ğ‘ğ‘ ğ‘–ğ‘ _ğ‘ğ‘ğ‘ ğ‘’ğ‘ _1sepsis\\_cases\\_1 dataset due to the poor performance obtained by the DT (see TableÂ 7). We stress the fact that other encodings, like the ones used in [ref]9, are based on a fine-grained vectorization of the log traces that minimizes the loss of information in each trace. For example, the well-known index encodingÂ  assigns at position iğ‘–i of the feature vector the activity name of the event occurring at position iğ‘–i in the trace. Therefore, the inference of high-level relations in the control flow of a trace, such as response (A, B) or existence3 (A), is left to the ML system. In this case, the semantics inference is limited by the expressive capabilities of the ML system being used. The declare encoding, on the other hand, is less fine grained as it abstracts the temporal order of the events with the constraint families. Since these relations are explicitly defined, the ML system only needs to infer the correlation between such the temporal patterns and the trace labeling. For this reason, using the declare encoding, also simple ML models (like DTs) can easily capture those correlations thus improving their performance. Since the use of declare patterns as features in Predictive and Prescriptive Process Monitoring\nis at its early adoptionÂ ,\nwe are interested in studying the effect of the different families of constraints on the quality of the recommendations. We, therefore, performed the Friedmanâ€™s testÂ   on the columns of TableÂ 8 to understand whether there is a statistically significant difference when using different families of constraints for generating the recommendations. We found a p-value of 0.0007 that rejects the null hypothesis and confirms the different impact of different families of constraints. However, we are also interested in which specific constraint family impacts the most. FigureÂ 7 is derived from TableÂ 8 and shows the critical difference diagram of the declare families by using the Nemenyi test with a significance level of 0.05 (as proposed inÂ ). The diagram reports the average ranking of each family according to the F-score results in TableÂ 8. Groups of families that are not significantly different (with p<0.05ğ‘0.05p<0.05) are connected. We can observe that the ğ’«â€‹â„›^^ğ’«â„›\\mathcal{\\widehat{PR}} and ğ’œğ’œ\\mathcal{A} families obtained the best results for the majority of the datasets. The results obtained with these two families are not significantly different. The ğ’^^ğ’\\mathcal{\\widehat{C}} and â„°â„°\\mathcal{E} families have also similar results, while both of them perform worse than ğ’«â€‹â„›^^ğ’«â„›\\mathcal{\\widehat{PR}} (and this difference is statistically significant). The lower performance of these families are due to the limited expressivity of their constraints. The performance of the ğ’©â€‹â„›^^ğ’©â„›\\mathcal{\\widehat{NR}} family is close to the performance of ğ’^^ğ’\\mathcal{\\widehat{C}} and â„°â„°\\mathcal{E} even though ğ’©â€‹â„›^^ğ’©â„›\\mathcal{\\widehat{NR}} contains relation constraints. This is due to the lower discriminating power of the constraints in ğ’©â€‹â„›^^ğ’©â„›\\mathcal{\\widehat{NR}} that negate the occurrence of a target activity (when the activation occurs) rather than explicitly constraining the occurrence of a specific target activity (when the activation occurs) as for ğ’«â€‹â„›^^ğ’«â„›\\mathcal{\\widehat{PR}} constraints. Positive relations (and existential constraints) seem hence to contribute most to the good performance of our Prescriptive Process Monitoring system (RQ2). The time efficiency and scalability performance are crucial for using the proposed system in a real environment that needs real-time performance. As the underlying DT can be learned offline, the time performance becomes relevant for the recommendation generation part (i.e., AlgorithmÂ 2). We therefore measured the time needed for generating the recommendations for prefixes Ïƒksubscriptğœğ‘˜\\sigma_{k} of different lengths. FigureÂ 8 shows the time performance by comparing the case of the event log with the best performance (the sâ€‹eâ€‹pâ€‹sâ€‹iâ€‹sâ€‹_â€‹câ€‹aâ€‹sâ€‹eâ€‹sâ€‹_â€‹3ğ‘ ğ‘’ğ‘ğ‘ ğ‘–ğ‘ _ğ‘ğ‘ğ‘ ğ‘’ğ‘ _3sepsis\\_cases\\_3 in FigureÂ 8(a)) with the one with the worst generation time (the bâ€‹pâ€‹iâ€‹câ€‹2011â€‹_â€‹4ğ‘ğ‘ğ‘–ğ‘2011_4bpic2011\\_4 in FigureÂ 8(b)). From the plot, we can see that our Prescriptive Process Monitoring system generates the recommendations in few milliseconds for both event logs. Such a high efficiency allows the system to be employed by process stakeholders to take decisions in real-time. The second insight we can draw from this experiment is that the generation time increases as the prefix length increases. This was expected since computing the RV satisfaction [ÏƒkâŠ§Ï†]Râ€‹Vsubscriptdelimited-[]modelssubscriptğœğ‘˜ğœ‘ğ‘…ğ‘‰[\\sigma_{k}\\models\\varphi]_{RV} in the fitness function (EquationsÂ 2 and 3) linearly grows with the length of Ïƒksubscriptğœğ‘˜\\sigma_{k}Â . The time performance also depends on the number of paths of the DT and on their lengths (see lines 2 and 4 of AlgorithmÂ 2). In the case of both the considered event logs, the â„°â„°\\mathcal{E} declare family in the log encoding produces larger DTs with respect to the other families and, therefore, requires more time for generating the recommendations.\n\nReference markers found: [9]\n\nContext windows for each [ref]:\n[ref]9: length kğ‘˜k are summed to the corresponding ones at prefix jâ‰¤kğ‘—ğ‘˜j\\leq k.\nThis is done to avoid that the results are influenced by the small number of traces that usually characterize long tracesÂ [ref]9.\nThe average over all the prefixes is reported in TableÂ 8. Both the figures and the table show very good results in general, that is, the proposed Prescriptive Process Monitoring system\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 9,\n            \"titles\": [\n                \"Prescriptive Process Monitoring: Quo Vadis?\",\n                \"Alarm-based prescriptive process monitoring\",\n                \"Fire now, fire later: alarm-based systems for prescriptive process monitoring\",\n                \"Process Mining - Data Science in Action, Second Edition\",\n                \"DECLARE: full support for loosely-structured processes\",\n                \"A next click recommender system for web-based service analytics with context-aware lstms\",\n                \"Design and evaluation of a process-aware recommender system based on prescriptive analytics\",\n                \"Learning to act: a Reinforcement Learning approach to recommend the best next activities\",\n                \"Knowledge-intensive processes: Characteristics, requirements and analysis of contemporary approaches\",\n                \"Outcome-Oriented Predictive Process Monitoring: Review and Benchmark\",\n                \"A meta-model for operational support\",\n                \"Application of process mining for improving adaptivity in case management systems\",\n                \"Applying process mining and semantic reasoning for process model customisation in healthcare\",\n                \"Predictive and prescriptive business process monitoring with reinforcement learning\",\n                \"Learning When to Treat Business Processes: Prescriptive Process Monitoring with Causal Inference and Reinforcement Learning\",\n                \"On-the-fly performance-aware human resource allocation in the business process management systems environment using naÃ¯ve bayes\",\n                \"Context-aware analysis of past process executions to aid resource allocation decisions\",\n                \"Cycle time reduction and runtime rebalancing by reallocating dependent tasks\",\n                \"A resource recommendation approach based on co-working history\",\n                \"Prescriptive process monitoring under resource constraints: A causal inference approach\",\n                \"Next best step and expert recommendation for collaborative processes in IT service management\",\n                \"Supporting the optimized execution of business processes through recommendations\",\n                \"Prescriptive Process Monitoring for Cost-Aware Cycle Time Reduction\",\n                \"A data-driven process recommender framework\",\n                \"Prescriptive process monitoring based on causal effect estimation\",\n                \"Recommending an alternative path of execution using an online decision support system\",\n                \"Proactive process adaptation using deep learning ensembles\",\n                \"Triggering proactive business process adaptations via online reinforcement learning\",\n                \"When to intervene? prescriptive process monitoring under uncertainty and resource constraints\",\n                \"Linear temporal logic and linear dynamic logic on finite traces\",\n                \"Global conformance checking measures using shallow representation and deep learning\",\n                \"Efficient detection of vacuity in temporal model checking\",\n                \"Vacuity detection in temporal model checking\",\n                \"Constraint-based workflow management systems: Shifting control to users\",\n                \"Compliance monitoring of multi-perspective declarative process models\",\n                \"Fast algorithms for mining association rules in large databases\",\n                \"Mutual information between discrete and continuous data sets\",\n                \"The temporal logic of programs\",\n                \"Constructing digital twins for accurate and reliable what-if business process analysis\",\n                \"Declare4py: A python library for declarative process mining\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]9 based on the context and research area of Outcome-Oriented Prescriptive Process Monitoring Based on Temporal Logic Patterns. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}