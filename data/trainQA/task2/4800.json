{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Modeling and Mining Multi-Aspect Graphs With Scalable Streaming Tensor Decomposition\n\nPaper Abstract: \n\nPaper Section Text:\nWe design experiments to answer the following questions: (Q1) How accurately Aptera detect rank as compared to baseline algorithm?\n(Q2) How Aptera used in real-world scenarios?\n(Q3) How does the running time of Aptera increase as tensor data grow (in 3rd mode)? A first step in evaluating our method is to check its performance on simulated data whose rank and factors can be pre-defined. We create synthetic tensors by generating two-factor matrices with RùëÖR columns each, where their elements are drawn as Gaussian with unit variance. Then, factors are column-wise normalized. The set of factor matrices for irregular mode is created in such a way that it retains the property of orthogonality. By considering these matrices as the PARAFAC2 factor matrices, therefore, the rank of the PARAFAC2 tensor will be exactly RùëÖR. We considered a setup with 100010001000 subjects, 500500500 feature variables, and a maximum of 200200200 observations for each subject with rank-555. Also, we deformed the generated tensor data by an additive noise tensor that has the rank higher than 555 but has norm 2√ó2\\times less than actual synthetic data. We evaluate the performance of the proposed method Aptera for the real datasets to assess the practicality in real-world scenarios. For this reason, in our experiments we includes real data sets as shown in Table (1). Chemical Data: We used two chemical data i.e. Wine-GCMS (Gas Chromatography Mass Spectroscopy)  and Amino acids fluorescence data . The wine data consists 444444 samples of red wines, 44 samples, produced from the same grape (Cabernet Sauvignon), harvested in different geographical areas. For each sample a mass spectrum scan is measured at 270027002700 elution time-points was obtained providing a data for 444444 samples have size 2700√ó20027002002700\\times 200. The Amino acid data set consists of 555 simple laboratory-made samples. Each sample has size 333333333. The dimensions are Each sample contains different amounts of tyrosine, tryptophan and phenylalanine dissolved in phosphate buffered water. Through core consistency experiments, it is found that amino acid data has rank-3 222http://www.models.life.ku.dk/Amino_Acid_fluo. Social Network Data: We also analyze EU-Core  data and it consists of emails between members of the research institution during October 2003 to May 2005 (18 months) and messages can be sent to multiple recipients of 42 departments. For this dataset, we created tensor as days-by-researcher-by-researcher. For this data previous research has identified 28 components  so we assume that the true rank is equal or around that number. Healthcare Data: This dataset is synthetically created by Centers for Medicare and Medicaid (CMS)  by using 5% of real medicare data and includes 98‚ÄãK98ùêæ98K subjects. We created PARAFAC2 tensor as visits - by - diagnosis - by - patient. In this experiment, three baselines have been used as to evaluate the performance. Autochrome: an implementation of detecting components for PARAFAC2 model which uses Core Consistency Diagnostic on CP tensor ùêò¬Ø¬Øùêò\\underline{\\mathbf{Y}}. Iteration based [ref]119 : We postulate that this could be a decent baseline because if appropriate number of components are selected, the PARAFAC2 decomposition converges fast within few iteration. Therefore, we consider it as one of our baseline. NSVD based : A Normalized Singular Value Deviation (NSVD) method used to find the rank via CP tensor ùêò¬Ø¬Øùêò\\underline{\\mathbf{Y}}. Tucker ARD based : it is an automatic relevance determination algorithm for Tucker decomposition using the gradient based sparse coding algorithm. We use this method to find the rank via CP tensor ùêò¬Ø¬Øùêò\\underline{\\mathbf{Y}}. BRTF Based : a Bayesian robust tensor factorization\nwhich employs a fully Bayesian generative model for\nautomatic CP-rank estimation All methods except Autochrome require a maximum bound Rm‚Äãa‚ÄãxsubscriptùëÖùëöùëéùë•R_{max} on the rank; for fairness, we set Rm‚Äãa‚Äãx=2‚ÄãRo‚Äãr‚Äãi‚Äãg‚Äãi‚Äãn‚Äãa‚ÄãlsubscriptùëÖùëöùëéùë•2subscriptùëÖùëúùëüùëñùëîùëñùëõùëéùëôR_{max}=2R_{original} for all methods. Note that all comparisons were carried out over 10 iterations (or experiments) for all methods and most repeated rank is reported here. For our synthetic dataset, we observe in Figure (4) that Aptera presents a quite distinct L-curve corner at rank-555 for all given random initilizations which is the correct answer. On the other hand, even though Autochrome and NSVD methods seem to approximate a region around 777 components (tested for 2‚àí102102-10 rank), it struggles to give a definitive answer and leaves open the possibility of up to 888 or more components. Both, Tucker ARD and BRTF based methods not able to provide certain solution for synthetic data. Interestingly, even iteration based baseline seems to be working better than Autochrome and NSVD, showing a subtle indication at 555 components. While our purposed method Aptera performs reasonable on synthetic tensor data, indicating a L-curve corner exactly where the predefined number of component is, but in order to evaluate its practicality in real-world scenarios, it is also important to research its performance and behavior on real-world data. For this reason, we analyze a range of real data sets as shown in Table (1). In Table (2), we can see that Aptera estimates the 444 components of wine-GC data, as opposed to iteration based and BRTF based baseline methods which suggests only 333 components. NSVD and Tucker ARD based baselines also fails to identify the correct answer by vaguely indicating only 666 or 777 components, and on other hand, Autochrome also suggests correct 444 components. It is interesting to observe that for amino acid data, our proposed method Aptera, Iteration based and Tucker-ARD methods are able to estimate the correct rank r=333 where all other baselines fail to discover 333 components in the data, as shown in Table (2). Figure (5), shows the importance of estimating correct rank. Correct rank (Figure 5(b)) can extract all relevant patterns without overlapping them (i.e. under-fitted model) in case low rank estimated than actual rank (Figure 5(a)). Also, more negative values indicated over-fitted model (Figure 5(c)) for such datasets. Our proposed method clearly outperforms most of the baselines. In Table (2), we see that the behavior of NSVD on the EUcore dataset is more complicated, providing multiple estimation at 131313 and 353535 components. On other hand, Tucker ARD and BRTF provides 333333 and 494949 components, respectively and clearly over-fitting the data, while Iteration based and Autochrome detect 252525 and 262626 components. Note that even though it is hard to obtain ground truth for this type of data, Aptera is able to at least suggest potential structure at all the points where other baselines do as well. It is also interesting to observe that the 282828 components or clusters that the authors identify in  make sense considering that not only Aptera, Iteration based and Autochrome also provide an indication near this number of components. Centers for Medicare and Medicaid (CMS) data files were created to allow researchers to gain familiarity using Medicare claims data while protecting beneficiary privacy. The CMS data contains multiple files per year. The file contains synthesized data taken from a 5% random sample of Medicare beneficiaries in 2008 and their claims from 2008 to 2010. We decompose PARAFAC2 tensor with rank between R=2ùëÖ2R=2 to R=50ùëÖ50R=50. Our aim is to estimate appropriate rank to find clinically-meaningful groups of features. For this data, BRTF based and Autochrome baselines unable to proceed due to out of memory after computing PARAFAC2 decompositions. Iteration based baseline and our method Aptera, estimated 111111 and 999 components, respectively. NSVD does not provide any estimation of rank for this data. We observe one of the the component (or cluster) in which most of the patients has respiratory disease. These are the patients with high utilization (>50%absentpercent50>50\\%), multiple clinical visits (avg 67) and high severity (death rate 8-10%). Most of the patients share ICD-9 code 492 (Emphysema), 496 (Chronic airway obstruction) and 511 (Pleurisy). These codes are characterized by obstruction of airflow that interferes with normal breathing. Figure (6a), shows the time taken by each method for synthetic and real dataset. We remark that our proposed method is faster that all baselines, even when compared to iteration based method where only PARAFAC2 decomposition is considered and no further computations are considered to find rank. This is because Aptera only requires to compute decomposition for Rm‚Äãa‚ÄãxsubscriptùëÖùëöùëéùë•R_{max} and other calculations once for each experiment. We also evaluate the scalability of our algorithm on synthetic dataset in terms of time needed for increasing number of subjects (K). A PARAFAC2 tensors ùêó¬Ø‚àà‚Ñù100√ó100√ó¬Øùêósuperscript‚Ñù100100delimited-[]10050000\\underline{\\mathbf{X}}\\in\\mathbb{R}^{100\\times 100\\times[100\\-50000]} are decomposed with fixed target rank R=10ùëÖ10R=10. The time needed by Aptera increases very linearly with increase in nonzero elements. Our proposed method Aptera, successfully estimate the rank of the large PARAFAC2 tensors in reasonable time as shown in Figure (6b) and is up to average 820%percent8208\\-20\\% faster than baseline methods. We remark the favorable scalability properties of Aptera, rendering it is practical to use for large tensors.\n\nReference markers found: [119]\n\nContext windows for each [ref]:\n[ref]119: to evaluate the performance. Autochrome: an implementation of detecting components for PARAFAC2 model which uses Core Consistency Diagnostic on CP tensor ùêò¬Ø¬Øùêò\\underline{\\mathbf{Y}}. Iteration based [ref]119 : We postulate that this could be a decent baseline because if appropriate number of components are selected, the PARAFAC2 decomposition converges fast within few iteration. Therefore, we\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 119,\n            \"titles\": [\n                \"A Flexible and Efficient Algorithmic Framework for Constrained Matrix and Tensor Factorization\",\n                \"Multiway analysis of epilepsy tensors\",\n                \"Data fusion in metabolomics using coupled matrix and tensor factorizations\",\n                \"Modeling and multiway analysis of chatroom tensors\",\n                \"All-at-once optimization for coupled matrix and tensor factorizations\",\n                \"Structure-revealing data fusion\",\n                \"COPA: Constrained PARAFAC2 for Sparse & Large Datasets\",\n                \"TASTE: Temporal and Static Tensor Factorization for Phenotyping Electronic Health Records\",\n                \"A study of distinctiveness in web results of two search engines\",\n                \"Fetal ecg extraction using œÄùúã\\\\pitucker decomposition\",\n                \"t-pine: Tensor-based predictable and interpretable node embeddings\",\n                \"Finding a pareto optimal solution for a multi-objective problem of managing radio resources: A qos aware algorithm\",\n                \"Comprehensive analysis of chromatographic data by using parafac2 and principal components analysis\",\n                \"Practical aspects of parafac modeling of fluorescence excitation-emission data\",\n                \"Strategies for analyzing data from video fluorometric monitoring of liquid chromatographic effluents\",\n                \"Com2: fast automatic discovery of temporal (‚Äòcomet‚Äô) communities\",\n                \"An explainable xgboost-based approach towards assessing the risk of cardiovascular disease in patients with type 2 diabetes mellitus\",\n                \"Isothermal chemical denaturation: Data analysis, error detection, and correction by parafac2\",\n                \"Parallel tensor compression for large-scale scientific data\",\n                \"Discussion tracking in enron email using parafac\",\n                \"Matlab tensor toolbox version 2.6\",\n                \"Matlab tensor toolbox version 2.6, available online, february 2015\",\n                \"Block Model Guided Unsupervised Feature Selection\",\n                \"A generalized maximum entropy approach to bregman co-clustering and matrix approximation\",\n                \"Data analysis and data mining: current issues in biomedical informatics\",\n                \"Finding redundant and complementary communities in multidimensional networks\",\n                \"Distributed optimization and statistical learning via the alternating direction method of multipliers\",\n                \"Kronecker products and matrix calculus in system theory\",\n                \"Parafac. tutorial and applications\",\n                \"Multi-way analysis in the food industry-models, algorithms, and applications\",\n                \"Parafac2‚Äîpart ii. modeling chromatographic data with retention time shifts\",\n                \"A new efficient method for determining the number of components in parafac models\",\n                \"Graph regularized nonnegative matrix factorization for data representation\",\n                \"Tensor-based multi-view feature selection with applications to brain diseases\",\n                \"Semi-supervised tensor factorization for brain network analysis\",\n                \"Toward an architecture for never-ending language learning\",\n                \"Analysis of individual differences in multidimensional scaling via an n-way generalization of ‚Äúeckart-young‚Äù decomposition\",\n                \"An investigation into tournament poker strategy using evolutionary algorithms\",\n                \"The triangle method for finding the corner of the l-curve\",\n                \"‚Äúparallel proportional profiles‚Äù and other principles for determining the choice of factors by rotation\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]119 based on the context and research area of Modeling and Mining Multi-Aspect Graphs With Scalable Streaming Tensor Decomposition. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}