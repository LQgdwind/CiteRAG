{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: RANC: Reconfigurable Architecture for Neuromorphic Computing\n\nPaper Abstract: \n\nPaper Section Text:\nAs the use cases for RANC intersect with a large number of research areas, we break the discussion on related work into two parts.\nFirst, we discuss the large body of work in existing software simulators and discuss how they can be found to be complimentary to the goals of RANC.\nThen, we discuss existing hardware architectures, and we note the differentiating factors that make RANC stand out. Starting with software simulators, there has been a large amount of work in this area ranging from biologically accurate simulators for use in computational neuroscience to simulators inspired by the recent uptick in machine learning research.\nOn the biological front, NEST 2.20.0 ,\nBrian 2 , and NEURON  are among the most widely known simulators.\nWhile the level of detail they provide is surely appreciated among neuroscientists, their bio-realism leads to long runtimes for those only interested in their application to computation.\nTowards enabling enhanced usability across simulators, frameworks like PyNN [ref]35 enable easy porting of models across all of these simulators.\nCARLSim4  is arguably suited for both biological and computational use cases, as while they initially started with a similar focus on GPU-accelerated, biologically plausible SNN simulation, they have begun to similarly apply CARLSim towards general neuromorphic computing applications through advances such as PyCARL [ref]36.\nFinally, on the purely machine learning side, packages like SpykeTorch  are available to enable rapid training and testing of SNNs.\nRANC differentiates itself from these simulation-oriented works by providing an end-to-end ecosystem that tightly couples software simulation and hardware emulation.\nAs such, we are not limited to simulation based experiments.\nInstead we can combine simulation and FPGA based analysis to progressively move from testing new ideas in software to implementing equivalent changes in hardware.\nThis allows rapid validation at the application level impacts through software and enables evaluating further impacts on latency, power, and resource utilization through hardware.\nWhile frameworks like PyCARL [ref]36 claim to have support for simulating commercial platforms such as TrueNorth and Loihi, to the best of our knowledge, no results are presented in this regard.\nAdditionally, the cycle-accurate simulator they use is a general purpose NoC simulator that requires precise SystemC implementations of the NoC tiles tested.\nAs far as we are aware, no SystemC implementations are available for either TrueNorth or Loihi. Moving on to hardware platforms, most existing work in neuromorphic hardware has been the production of prefabricated ASICs in both the commercial sector with chips like Intel’s Loihi , IBM’s TrueNorth , the Akida Neuromorphic SoC , or Qualcomm Zeroth  and the academic environment with chips like SpiNNaker , DYNAPs , NeuronFlow , SpinalFlow , or ODIN .\n\nOf these, ODIN is notable in that it has an open source verilog implementation despite not being targeted towards FPGAs.\nWith that, it is similar to the RANC FPGA emulation environment, and it includes some features that RANC does not such as spike-driven synaptic plasticity (SDSP).\nCompared to RANC, however, ODIN has distinct goals with regards to energy minimization and biological plausibility.\nThe ODIN chip includes only a single crossbar without a broader NoC that connects many parallel neuron crossbars together.\nAs such, with ODIN, the focus is not on providing a scalable architecture for neuromorphic computing but instead maximizing energy savings and enabling large amounts of biologically realistic neuron behaviors.\nWithout a broader NoC, the mapping methodologies required for applications like multilayer SNNs or VMM explored in this paper are quite unclear, and it cannot be used for the same style of architecture exploration as RANC’s focus on general purpose neuromorphic compute.\n\nWhile RANC’s FPGA emulation has a number of disadvantages with regards to power, latency, and resource usage compared to ASICs, the key advantage of RANC against ASIC platforms such as these is that RANC is not a fixed architecture.\nTo the contrary, RANC is built with architectural exploration in mind and as such it prioritizes easy exploration of novel methods of neuromorphic computing at the architectural level rather than only the application level.\nIf the production of improved ASIC architectures is the end goal, RANC positions itself as an environment where such architectural research can be performed.\nIn the vein of FPGA-based architectures, the closest academic platforms to what RANC offers are Minitaur  or DANNA 2 . Minitaur is an FPGA-based SNN accelerator with an event-driven architecture.\nBased on the details provided, the architecture presented takes a fundamentally different approach from the one taken by RANC.\nRather than for general neuromorphic computing, Minitaur is presented purely as an accelerator for spiking neural network inference, and while it is an FPGA-based design, the parameters given are presented as fixed to the design.\nAs such, there are questions as to how flexible the design is in emulating network configurations with widely varied core requirements.\nIn particular, Minitaur appears to be less flexible in enabling general spike-based computation than the NoC approach utilized by RANC, as it is unclear how algorithms like vector matrix multiplication would be mapped.\nAdditionally, the fanin/fanout capabilities are wildly different, with Minitaur utilizing range-based destinations that map connections via start and end address ranges rather than directly mapping between neurons.\nFinally, while the Minitaur design is quite compact, there are concerns with its throughput as, for instance, the MNIST results presented require 1000 spikes per image in order to achieve their maximum of 92% accuracy on MNIST compared to the 1 to 16 spikes used in the studies presented here with 96+% accuracy.\nWhether this due to differences in network architecture, training methodology, or hardware is unclear.\nMeanwhile, DANNA2 is the second iteration of DANNA , an environment for neuromorphic computing that combines software simulation with FPGA and VLSI implementations.\nCompared to RANC, the architecture presented in DANNA2 is quite different.\nEach element in the DANNA2 grid has a fixed set of 24 input synapses that feed a single neuron unit, and this is overall much lower than a single RANC node that supports N​(a)𝑁𝑎N(a) inputs and N​(n)𝑁𝑛N(n) outputs per node.\nOne consequence of this is that DANNA2 nodes inherently give a lower fanout per node than the N​(n)𝑁𝑛N(n) neurons in a single RANC core.\nCoupled with the fact that each node only has a fixed set of 24 inputs compared to N​(a)𝑁𝑎N(a), many of the optimizations explored in VMM and SAR execution involving heterogeneous sizing of cores are infeasible on such an architecture.\nFor DANNA2 in particular, to the best of our knowledge, no published FPGA results are available to directly compare against.\nThis contrasts the published results for the original DANNA , which depicts an even more divergent architecture.\nNegative weights are unsupported and there are only 8 inputs per neuron, and consequently, concerns regarding the fanin/fanout capabilities of DANNA2 apply to DANNA as well. Finally, in the vein of hardware-software ecosystems for neuromorphic computing, two of the most relevant works are Nengo [ref]48 and NAXT .\nThe Nengo ecosystem [ref]48 provides a rich set of APIs to develop large-scale spiking and non-spiking neural networks on a wide range of platforms (e.g. FPGA, Loihi, HPC).\nIn particular, NengoFPGA requires a proprietary bitstream to interact with the Nengo APIs and does not provide a means to exploring novel neuromorphic architectures.\nHowever, similar to NengoLoihi and NengoSpiNNaker, developing NengoRANC APIs in the future would enable co-design and execution of SNNs for user defined neuromorphic architectures in the RANC environment.\nMeanwhile, NAXT  provides an environment where users can generate FPGA-based SNN accelerators with a wide degree of flexibility in parameters of the generated architecture with regards to parallelism versus resource-usage tradeoffs.\nHowever, as NAXT is tailored specifically for SNN execution, the architectures it generates are specifically tailored for the baseline SNN architecture that is being mapped, and they are not suitable for use either by other SNNs with different architectures or non-machine learning applications in general.\nIn this regard, RANC differentiates itself by providing architectures that are independent from the applications they execute and supporting non-machine learning applications that can still be decomposed to parallel spike-based computations like solving sparse coding via the locally competitive algorithm . For the sake of completeness, we end by acknowledging some key limitations to the RANC framework as it currently stands and how the project’s goals align with these limitations.\nFirst, as our intention is neuromorphic computing over biologically realistic modeling, our ecosystem does not support features such as stochastic behavior or emulation of detailed neuronal dynamics, and we focus instead on the synaptic cores and a basic leaky-integrate-and-fire neuron model.\nSecond, while the architecture is amenable to this in the future by customizing the Router component, there is currently no support for NoC topologies other than the current 2D mesh.\nFinally, the core architecture is built around storing a dense-matrix form of synaptic connections, and supporting sparse alternatives will require architectural changes.\n\nHowever, to the best of our knowledge, RANC is a wholly unique environment in its design goals and capabilities.\nWhile it has a software simulation component, it is distinct from existing software simulators through its ability to conduct wider studies impacting both hardware and software usage.\nWhile other hardware designs have been proposed, RANC differs from existing ASICs by its reconfigurable nature and from FPGA implementations with its architectural differences and open source availability.\n\nReference markers found: [35]\n\nContext windows for each [ref]:\n[ref]35: neuroscientists, their bio-realism leads to long runtimes for those only interested in their application to computation.\nTowards enabling enhanced usability across simulators, frameworks like PyNN [ref]35 enable easy porting of models across all of these simulators.\nCARLSim4  is arguably suited for both biological and computational use cases, as while they initially started with a similar\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 35,\n            \"titles\": [\n                \"PyCARL: A PyNN Interface for Hardware-Software Co-Simulation of Spiking Neural Network\",\n                \"A Survey of Neuromorphic Computing and Neural Networks in Hardware\",\n                \"Neuromorphic Hardware In The Loop: Training a Deep Spiking Network on the BrainScaleS Wafer-Scale System\",\n                \"Convolutional Networks for Fast, Energy-Efficient Neuromorphic Computing\",\n                \"Decoding EEG and LFP signals using deep learning: Heading TrueNorth\",\n                \"Unsupervised learning of digit recognition using spike-timing-dependent plasticity\",\n                \"TrueHappiness: Neuromorphic Emotion Recognition on TrueNorth\",\n                \"Binary image classification using a neurosynaptic processor: A trade-off analysis\",\n                \"The TENNLab Suite of LIDAR-Based Control Applications for Recurrent, Spiking, Neuromorphic Systems\",\n                \"Dynamic programming with spiking neural computing\",\n                \"Sparse Coding by Spiking Neural Networks: Convergence Theory and Computational Results\",\n                \"Low-Power Neuromorphic Hardware for Signal Processing Applications: A Review of Architectural and System-Level Design Approaches\",\n                \"IEEE 754 floating-point addition for neuromorphic architecture\",\n                \"TrueNorth: Design and Tool Flow of a 65 mW 1 Million Neuron Programmable Neurosynaptic Chip\",\n                \"Loihi: A Neuromorphic Manycore Processor with On-Chip Learning\",\n                \"The VTR Project: Architecture and CAD for FPGAs from Verilog to Routing\",\n                \"Nest 2.20.0\",\n                \"Brian 2, an intuitive and efficient neural simulator\",\n                \"The NEURON Book\",\n                \"CARLsim 4: An Open Source Library for Large Scale, Biologically Detailed Spiking Neural Network Simulation using Heterogeneous Clusters\",\n                \"Compiling Spiking Neural Networks to Neuromorphic Hardware\",\n                \"FPGA Based Emulation Environment for Neuromorphic Architectures\",\n                \"TensorFlow: Large-scale machine learning on heterogeneous systems\",\n                \"Backpropagation for energy-efficient neuromorphic computing\",\n                \"A digital neurosynaptic core using embedded crossbar memory with 45pJ per spike in 45nm\",\n                \"Improving classification accuracy of feedforward neural networks for spiking neuromorphic chips\",\n                \"Adam: A method for stochastic optimization\",\n                \"Sparse coding using the locally competitive algorithm on the TrueNorth neurosynaptic system\",\n                \"Crowdsourcing the creation of image segmentation algorithms for connectomics\",\n                \"Bridging the Gap Between Neural Networks and Neuromorphic Hardware with A Neural Network Compiler\",\n                \"MSTAR/IU Mixed Targets\",\n                \"An energy-efficient embedded implementation for target recognition in SAR imageries\",\n                \"BinaryConnect: Training Deep Neural Networks with binary weights during propagations\",\n                \"TrueNorth ecosystem for brain-inspired computing: Scalable systems, software, and applications\",\n                \"Understanding the design of IBM neurosynaptic system and its tradeoffs: A user perspective\",\n                \"PyNN: a common interface for neuronal network simulators\",\n                \"SpykeTorch: Efficient Simulation of Convolutional Spiking Neural Networks with at most one Spike per Neuron\",\n                \"Akida Neuromorphic System-On-Chip\",\n                \"Introducing Qualcomm Zeroth Processors: Brain-Inspired Computing\",\n                \"SpiNNaker: A multi-core System-on-Chip for massively-parallel neural net simulation\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]35 based on the context and research area of RANC: Reconfigurable Architecture for Neuromorphic Computing. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}