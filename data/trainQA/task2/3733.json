{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: R2L: Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View Synthesis\n\nPaper Abstract: \n\nPaper Section Text:\nDatasets. We show experiments on the following datasets: NeRF datasets¬†[ref]34.\nWe evaluate our method on two datasets: synthetic dataset (Realistic Synthetic 360‚àòsuperscript360360^{\\circ}) and real-world dataset (Real Forward-Facing). Realistic Synthetic 360‚àò contains path-traced images of 888 objects that exhibit complicated geometry and realistic non-Lambertian materials. 100100100 views of each scene are used for training and 200200200 for testing, with resolution of 800√ó800800800800\\times 800. Real Forward-Facing also contains 888 scenes, captured with a handheld cellphone. There are 202020 to 626262 images for each scene with 1/8181/8 held out for testing. All images have a resolution of 1008√ó75610087561008\\times 756. DONeRF dataset includes their synthetic data. Images are rendered using Blender and their Cycles path tracer to render 300300300 images for each scene, which are split into train/validation/test sets at a 70%percent7070\\%, 10%percent1010\\%, 20%percent2020\\% ratio. Training settings. All images in the synthetic dataset are down-sampled by 2√ó2\\times during training and testing. Due to limited space, we defer the full-resolution (800√ó800800800800\\times 800) results to our supplementary material.\nThe original NeRF model is trained with a batch size of 1,02410241,024 and initial learning rate as 5√ó10‚àí45superscript1045\\times 10^{-4} (decayed during training) for 200‚Äãk200ùëò200k iterations. We synthesize 10‚Äãk10ùëò10k images using the pre-trained NeRF model. Our proposed R2L model is trained for 1,000‚Äãk1000ùëò1,000k iterations with the same learning rate schedule. The rays in a batch (batch size 98,3049830498,304 rays) are randomly sampled from different images so that they do not share the same origin. This is found critical to achieving superior performance. Adam optimizer¬† is employed for all training. We use PyTorch 1.9¬†[ref]39, referring to¬†[ref]58. Experiments are conducted with 888 NVIDIA V100 GPUs. Comparison methods. We compare with with the original NeRF¬†[ref]34 to show that we can achieve significantly better rendering quality while being much faster. Meanwhile, we also compare with DONeRF¬†, NSVF¬†, and NeX¬† since they also target efficient NVS as we do. Other efficient NVS works such as AutoInt¬† and X-Fields¬† have been shown less favorable than RSEN¬†. Therefore, we only compare with RSEN¬†. KiloNeRF¬†3, another closely related work apart from RSEN, will also be compared to. Similar to¬†, we do not compare to baking-based methods¬†  ) as they trade memory footprint for speed while our method aims to maintain the compact representation.\n\nReference markers found: [34]\n\nContext windows for each [ref]:\n[ref]34: Datasets. We show experiments on the following datasets: NeRF datasets¬†[ref]34.\nWe evaluate our method on two datasets: synthetic dataset (Realistic Synthetic 360‚àòsuperscript360360^{\\circ}) and real-world dataset (Real Forward-Facing). Realistic Synthetic 360‚àò contains\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 34,\n            \"titles\": [\n                \"DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks\",\n                \"The plenoptic function and the elements of early vision, vol.¬†2\",\n                \"Single lens stereo with a plenoptic camera\",\n                \"Flip: A difference evaluator for alternating images\",\n                \"Learning neural light fields with ray-space embedding networks\",\n                \"Do deep nets really need to be deep?\",\n                \"‚Äã‚ÄãMip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields‚Äã\",\n                \"X-Fields: Implicit Neural View-, Light- and Time-Image Interpolation\",\n                \"Model compression\",\n                \"Learning efficient object detection models with knowledge distillation\",\n                \"Learning Implicit Fields for Generative Shape Modeling\",\n                \"Neural volume rendering: Nerf and beyond\",\n                \"Fastnerf: High-fidelity neural rendering at 200fps\",\n                \"The lumigraph\",\n                \"Deep Residual Learning for Image Recognition\",\n                \"Baking Neural Radiance Fields for Real-Time View Synthesis\",\n                \"Beyond hard negative mining: Efficient detector learning via block-circulant decomposition\",\n                \"Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons\",\n                \"Distilling the Knowledge in a Neural Network\",\n                \"Batch normalization: Accelerating deep network training by reducing internal covariate shift\",\n                \"Tinybert: Distilling bert for natural language understanding\",\n                \"Ray tracing volume densities\",\n                \"Learning-Based View Synthesis for Light Field Cameras\",\n                \"An introduction to computational learning theory\",\n                \"Adam: A method for stochastic optimization\",\n                \"Imagenet classification with deep convolutional neural networks\",\n                \"Light field rendering\",\n                \"Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes\",\n                \"AutoInt: Automatic Integration for Fast Neural Volume Rendering\",\n                \"NeuLF: Efficient Novel View Synthesis with Neural 4D Light Field\",\n                \"Neural Sparse Voxel Fields\",\n                \"Knowledge distillation via instance relationship graph\",\n                \"Occupancy Networks: Learning 3D Reconstruction in Function Space\",\n                \"Local Light Field Fusion: Practical View Synthesis with Prescriptive Sampling Guidelines\",\n                \"NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis\",\n                \"DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation\",\n                \"Relational Knowledge Distillation\",\n                \"Learning Deep Representations with Probabilistic Knowledge Transfer\",\n                \"PyTorch: An Imperative Style, High-Performance Deep Learning Library\",\n                \"Correlation Congruence for Knowledge Distillation\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]34 based on the context and research area of R2L: Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View Synthesis. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}