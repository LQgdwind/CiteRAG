{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Local consistency as a reduction between constraint satisfaction problems\n\nPaper Abstract: \n\nPaper Section Text:\nIn this subsection we shall explore the role of group CSPs as â€˜obstaclesâ€™ for kğ‘˜k-consistency reductions. A seminal example is the fact that kğ‘˜k-consistency does not solve CSPâ¡(ğ”¾)CSPğ”¾\\operatorname{CSP}(\\mathbb{G}) for any non-trivial finite Abelian group ğ”¾ğ”¾\\mathbb{G} [26, Theorem 30], or equivalently, that CSPâ¡(ğ”¾)â€‹â‰¤Datalogâ€‹CSPâ¡(âŠ¥)CSPğ”¾subscriptDatalogCSPbottom\\operatorname{CSP}(\\mathbb{G})\\not\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\bot). It then follows that, e.g., CSPâ¡(ğŠ3)â€‹â‰¤Datalogâ€‹CSPâ¡(âŠ¥)CSPsubscriptğŠ3subscriptDatalogCSPbottom\\operatorname{CSP}(\\mathbf{K}_{3})\\not\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\bot) since, say, CSPâ¡(â„¤3)CSPsubscriptâ„¤3\\operatorname{CSP}(\\mathbb{Z}_{3}) reduces to CSPâ¡(ğŠ3)CSPsubscriptğŠ3\\operatorname{CSP}(\\mathbf{K}_{3}) by a gadget reduction and Datalogâˆª reductions are transitive by TheoremÂ 3.13.\nThe following proposition allows us to push this approach a bit further. CSPâ¡(â„¤p)â€‹â‰¤Datalogâ€‹CSPâ¡(â„¤q)CSPsubscriptâ„¤ğ‘subscriptDatalogCSPsubscriptâ„¤ğ‘\\operatorname{CSP}(\\mathbb{Z}_{p})\\not\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\mathbb{Z}_{q}) for any distinct primes pğ‘p and qğ‘q. We start with a kğ‘˜k-consistent but unsolvable instance ğ—ğ—\\mathbf{X} of CSPâ¡(â„¤p)CSPsubscriptâ„¤ğ‘\\operatorname{CSP}(\\mathbb{Z}_{p}), i.e., with a system of equations modulo pğ‘p which is not solvable, but is accepted by the kğ‘˜k-consistency test. Such a system is known to exist (see, e.g., [26; 3]). Observe that, after each step in the kğ‘˜k-consistency procedure, the sets â„±Ksubscriptâ„±ğ¾\\mathcal{F}_{K} are always affine subspaces of â„¤pKsuperscriptsubscriptâ„¤ğ‘ğ¾\\mathbb{Z}_{p}^{K} â€” since to begin with they are defined by linear equations, and in each step, we intersect with a projection of another affine subspace. Since the system is consistent, the subspaces are non-empty. Further observe that the maps Ï€:â„±Kâ†’â„±L:ğœ‹â†’subscriptâ„±ğ¾subscriptâ„±ğ¿\\pi\\colon\\mathcal{F}_{K}\\to\\mathcal{F}_{L} defined by restriction to Lğ¿L are affine, and hence the size of the preimage of an element fâˆˆâ„±Lğ‘“subscriptâ„±ğ¿f\\in\\mathcal{F}_{L} under Ï€ğœ‹\\pi does not depend on fğ‘“f â€” it only depends on the dimension of the kernel of Ï€ğœ‹\\pi. Hence the uniform probability on â„±Ksubscriptâ„±ğ¾\\mathcal{F}_{K}, i.e., Î»:â„±Kâ†’â„š:ğœ†â†’subscriptâ„±ğ¾â„š\\lambda\\colon\\mathcal{F}_{K}\\to\\mathbb{Q} defined as Î»â€‹(f)=1/pdğœ†ğ‘“1superscriptğ‘ğ‘‘\\lambda(f)=1/p^{d} where dğ‘‘d is the dimension of â„±Ksubscriptâ„±ğ¾\\mathcal{F}_{K}, solves the corresponding Sherali-Adams linear program. Since pğ‘p and qğ‘q are coprime, we can interpret the expression 1/pd1superscriptğ‘ğ‘‘1/p^{d} as an element of â„¤qsubscriptâ„¤ğ‘\\mathbb{Z}_{q}. Consequently, this assignment is a feasible solution of the â„¤qsubscriptâ„¤ğ‘\\mathbb{Z}_{q}-affine kğ‘˜k-consistency relaxation with input ğ—ğ—\\mathbf{X}. We note that the above proposition could be also proved by using the fact that CSPâ¡(â„¤p)CSPsubscriptâ„¤ğ‘\\operatorname{CSP}(\\mathbb{Z}_{p}) is not expressible in fixed-point logic with modulo qğ‘q rank operators (see, e.g., ) â€” though this proof requires either a refinement of [3, TheoremÂ 3], or our TheoremÂ 3.12. This alternative approach has been communicated to us by Anuj Dawar  and precedes the proof given here. It follows from the previous proposition that CSPâ¡(ğŠ3)â€‹â‰¤Datalogâ€‹CSPâ¡(â„¤2)CSPsubscriptğŠ3subscriptDatalogCSPsubscriptâ„¤2\\operatorname{CSP}(\\mathbf{K}_{3})\\not\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\mathbb{Z}_{2}). More generally, it was shown by Ciardo and Å½ivnÃ½  that\nCSPâ¡(ğŠ3)â€‹â‰¤Datalogâ€‹CSPâ¡(â„¤)CSPsubscriptğŠ3subscriptDatalogCSPâ„¤\\operatorname{CSP}(\\mathbf{K}_{3})\\not\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\mathbb{Z}).777In fact, Ciardo and Å½ivnÃ½  proved that PCSPâ¡(ğŠ3,ğŠc)PCSPsubscriptğŠ3subscriptğŠğ‘\\operatorname{PCSP}(\\mathbf{K}_{3},\\mathbf{K}_{c}) is not solved by the kğ‘˜k-th level of LP and AIP hierarchy, for any câ‰¥3ğ‘3c\\geq 3 and kâ‰¥2ğ‘˜2k\\geq 2, which is a stronger statement.\nSince CSPâ¡(ğŠ3)CSPsubscriptğŠ3\\operatorname{CSP}(\\mathbf{K}_{3}) allows a gadget reduction from any CSP with a finite template, we can view this lack of a reduction as witnessed by CSPâ¡(ğ”¾)CSPğ”¾\\operatorname{CSP}(\\mathbb{G}) where ğ”¾ğ”¾\\mathbb{G} is a non-Abelian finite group. This suggests the following intriguing question: Could it be that group CSPs constitute a complete set of obstructions for consistency reductions between finite-template CSPs? More concretely, is it true that for every finite structures ğ€ğ€\\mathbf{A} and ğğ\\mathbf{B}, CSPâ¡(ğ€)â‰¤DatalogCSPâ¡(ğ)subscriptDatalogCSPğ€CSPğ\\operatorname{CSP}(\\mathbf{A})\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\mathbf{B}) if and only if, for every finite group ğ”¾ğ”¾\\mathbb{G}, CSPâ¡(ğ”¾)â‰¤DatalogCSPâ¡(ğ€)subscriptDatalogCSPğ”¾CSPğ€\\operatorname{CSP}(\\mathbb{G})\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\mathbf{A}) implies CSPâ¡(ğ”¾)â‰¤DatalogCSPâ¡(ğ)subscriptDatalogCSPğ”¾CSPğ\\operatorname{CSP}(\\mathbb{G})\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\mathbf{B}) or, alternatively,\ndoes every equivalence class of finite-template CSPs up to consistency reductions contain a group CSP?\nThe positive verification in the particular case ğ=âŠ¥ğbottom\\mathbf{B}=\\bot is essentially the notorious bounded width conjecture of Larose and ZÃ¡dori  confirmed by Barto and Kozik [ref]8.\nAlthough extending this proof to all ğğ\\mathbf{B} is currently out of reach, we believe that the answer will be affirmative. In particular, we conjecture the following. For every finite structure ğ€ğ€\\mathbf{A}, either CSPâ¡(ğ•Š3)â‰¤DatalogCSPâ¡(ğ€)subscriptDatalogCSPsubscriptğ•Š3CSPğ€\\operatorname{CSP}(\\mathbb{S}_{3})\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\mathbf{A}), where ğ•Š3subscriptğ•Š3\\mathbb{S}_{3} denotes the symmetric group on 3 elements, or CSPâ¡(ğ€)â‰¤DatalogCSPâ¡(â„¤)subscriptDatalogCSPğ€CSPâ„¤\\operatorname{CSP}(\\mathbf{A})\\mathrel{\\leq_{\\text{Datalog}}}\\operatorname{CSP}(\\mathbb{Z}). The conjecture has an important consequence. If true, it would show that all CSPs tractable by the algorithms of Bulatov ; Zhuk  are solved by the â„¤â„¤\\mathbb{Z}-affine kğ‘˜k-consistency relaxation for some kâ‰¥1ğ‘˜1k\\geq 1.\nCombining results of SectionÂ 3 and known results it follows that this algorithm solves correctly all CSPs solvable by the kğ‘˜k-consistency algorithm as well as systems of linear equations over a finite Abelian group, i.e., it solves the two prime examples of tractable CSPs. Let us note that another polynomial-time CSP algorithm coming from the algebraic approach, few subpowers, does not compare well with consistency reductions. In particular, the class of CSPs having few subpowers (i.e., the class of CSPs that are solved by this algorithm) contains all CSPs of Abelian groups, and hence infinitely many problems that are incomparable by consistency reductions. We believe that confirming (or disproving) the conjecture even in the case of CSPs with a Malâ€™cev polymorphism, which form a small subclass of few subpowers, would likely lead us close to a complete resolution. We conclude by observing that several relaxation variants previously defined are at least as powerful as the â„¤â„¤\\mathbb{Z}-affine kğ‘˜k-consistency relaxation introduced here: the hierarchy of LP+AIP introduced by Brakensiek, Guruswami, Wrochna, and Å½ivnÃ½ , the hierarchy of CLAP introduced by Ciardo and Å½ivnÃ½ , and cohomological kğ‘˜k-consistency introduced by Ã“Â Conghaile .\nThe power of these relaxations is not yet well understood even in the case of CSPs. For example, the comparison of the power of cohomological kğ‘˜k-consistency with respect to the hierarchy of LP+AIP is not clear.\nNote that our conjecture implies that all variants solve exactly the same CSPs, namely, all tractable ones (assuming Pâ‰ NPPNP\\text{P}\\neq\\text{NP}).\n\nReference markers found: [8]\n\nContext windows for each [ref]:\n[ref]8: a group CSP?\nThe positive verification in the particular case ğ=âŠ¥ğbottom\\mathbf{B}=\\bot is essentially the notorious bounded width conjecture of Larose and ZÃ¡dori  confirmed by Barto and Kozik [ref]8.\nAlthough extending this proof to all ğğ\\mathbf{B} is currently out of reach, we believe that the answer will be affirmative. In particular, we conjecture the following. For every finite\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 8,\n            \"titles\": [\n                \"Combinatorial Gap Theorem and Reductions between Promise CSPs\",\n                \"ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ ê³µê²© ê·¸ë˜í”„ ìƒì„±\",\n                \"Probabilistic Checking of Proofs: A New Characterization of NP\",\n                \"Affine systems of equations and counting infinitary logic\",\n                \"(2+Ïµitalic-Ïµ\\\\epsilon)-Sat Is NP-hard\",\n                \"Symmetric Promise Constraint Satisfaction Problems: Beyond the Boolean Case\",\n                \"Algebraic approach to promise constraint satisfaction\",\n                \"Weisfeiler-Leman Invariant Promise Valued CSPs\",\n                \"Constraint Satisfaction Problems Solvable by Local Consistency Methods\",\n                \"Polymorphisms, and How to Use Them\",\n                \"The Wonderland of Reflections\",\n                \"Two-element structures modulo primitive positive constructability\",\n                \"Promise Constraint Satisfaction: Algebraic Structure and a Symmetric Boolean Dichotomy\",\n                \"The Power of the Combined Basic Linear Programming and Affine Relaxation for Promise Constraint Satisfaction Problems\",\n                \"The Complexity of Promise SAT on Non-Boolean Domains\",\n                \"Classifying the Complexity of Constraints using Finite Algebras\",\n                \"A dichotomy theorem for nonuniform CSPs\",\n                \"An Algebraic Approach to Multi-sorted Constraints\",\n                \"The Complexity of the Distributed Constraint Satisfaction Problem\",\n                \"CLAP: A New Algorithm for Promise CSPs\",\n                \"Approximate Graph Colouring and the Hollow Shadow\",\n                \"Hierarchies of Minion Tests for PCSPs through Tensors\",\n                \"Personal communication. (March 2022).\",\n                \"The Hardness of 3-Uniform Hypergraph Coloring\",\n                \"Symmetric Datalog and Constraint Satisfaction Problems in Logspace\",\n                \"The Computational Structure of Monotone Monadic SNP and Constraint Satisfaction: A Study Through Datalog and Group Theory\",\n                \"Dichotomy for symmetric Boolean PCSPs\",\n                \"The Complexity of Solving Equations over Finite Groups\",\n                \"dğ‘‘d-To-1 Hardness of Coloring 3-Colorable Graphs with Oâ€‹(1)ğ‘‚1{O}(1) Colors\",\n                \"Descriptive complexity of linear algebra\",\n                \"Improved Hardness of Approximating Chromatic Number\",\n                \"Closure properties of constraints\",\n                \"ğ‘›-permutability and linear Datalog implies symmetric Datalog\",\n                \"On the Expressive Power of Datalog: Tools and a Case Study\",\n                \"Conjunctive-Query Containment and Constraint Satisfaction\",\n                \"The complexity of 3-colouring Hğ»H-colourable graphs\",\n                \"An Invitation to the Promise Constraint Satisfaction Problem\",\n                \"Topology and adjunction in promise constraint satisfaction\",\n                \"Bounded width problems and algebras\",\n                \"Boolean symmetric vs.Â functional PCSP dichotomy\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]8 based on the context and research area of Local consistency as a reduction between constraint satisfaction problems. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}