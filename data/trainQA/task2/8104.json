{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Advancing Cyber Incident Timeline Analysis Through Rule-Based AI and Large Language Models\n\nPaper Abstract: \n\nPaper Section Text:\nUnderstanding RAG, how it works, and the process of its integration can be somewhat confusing and complex. This complexity largely depends on the scope and objectives of its application. In our approach, we narrow its use down to the contexts of TA, DF, and IR. RAG primarily aims to optimize and enhance the performance of LLMs. It utilizes an external knowledge base beyond the LLM’s pre-existing knowledge and training datasets to provide additional information during inference. This process is not exactly like fine-tuning or training an LLM but rather involves dynamically retrieving, generating, and integrating relevant external textual information from databases (external storage), local files (as a vault file), or through cloud pipelines . It is crucial to acknowledge that while an LLM alone is very powerful, its knowledge may not encompass specific contexts . For instance, organizations may possess sensitive and confidential data, as well as their contextual interpretations of rules, concepts, or topic-related information, which they wish to keep private [ref]15. Data for training LLMs are typically gathered from various sources such as cookies, third-party datasets, publicly available online content, and other means. An LLM cannot access or recognize information that was not included in its training data. This is where RAG is particularly useful, as it addresses these limitations by integrating relevant external information. Due to privacy and security concerns, this process is generally conducted within secure, context-specific, and private task environments. To maintain good cybersecurity practices in TA, it is essential to consider the level of risk, privacy, and confidentiality of data, as well as compliance with rules, guidelines, and policies during the data and digital artifacts collection phase [ref]15. Additionally, a RAG agent, which is an essential component in certain AI systems powered by an LLM , serves as an intermediary between the LLM and the user. The agent is responsible for conducting the search when a user sends a query or input, retrieving all context-based information, and providing it to the LLM, which then generates a context-based answer for the user. Complementing this, RAG agents have the capability of refining and modifying prompts crafted by humans. During inference, the RAG agent receives the input, processes it, and modifies it according to the role it is tasked with and designed to do [ref]47. A core aspect to consider is that the role of a RAG agent is assigned by a human. For instance, in an LLM-powered system with a RAG agent, Figure 5, the agent can take on the role of a cybersecurity assistant. In TA, the agent could be a \"Digital Forensics and Cybersecurity AI Analyst tasked with performing timeline analysis, correlating events, and reconstructing timelines\". Another consideration in RAG is the chunking process. Chunking is a method where text is split and structured into smaller segments based on the number of tokens. A token might be a word, number, or punctuation in a sentence. To embed text in chunks, an embedding model is needed [ref]48. Several models exist; Table IV represents some optimized models that potentially serve the context of TA. Each model has its own characteristics, such as dimension and maximum number of tokens. In TA, involving temporal digital artefact analysis, every single character counts. A second or minute (a number -token) can make a huge difference during event correlation. This points to the fact that meticulous calculation of tokens and careful consideration of the embedding model are imperative. All details are required to be embedded and stored accurately for precise and accurate TA. Table III contains valuable research on the use of RAG, including their implementation and architecture. The insights gained from our literature review and related works form the foundation for developing our framework. To begin, LLMs in Table III are the best to adopt for this scope of study. However, some of these models are not open-source, which is a disadvantage for us. This limitation restricts our ability to modify and explore the model to align it with our goals. Therefore, we opt for open-source models such as \"Llama-3.1.\" For embedding models, we apply the same principle as with LLM models, using open-source alternatives like \"mxbai-embed-large.\" Regarding the tables of relevant works, it is clear that there has been limited advancement in TA, despite progress in the field of AI. Most studies have relied on standalone tools like log2timeline. Concerning LLMs in DF and cybersecurity, they still face many limitations as research and development are ongoing. Finally, all the mentioned information about using RAG with an external knowledge base is primarily applied in research and various tasks to enhance the LLM’s knowledge, memory, and context. In our proposed approach, our aim is to exploit it differently. Instead of using the external knowledge base to broadly enhance the LLM’s knowledge, we will directly upload forensic reports (containing events of cyber incidents) into the AI system. This will allow the system to answer questions and generate forensic-based TA reports directly from these documents. It’s important to note that LLMs can process inputs in the form of documents or text. However, this introduces additional considerations, such as the number of tokens that the LLM can accept as input, the internal embedding model and its characteristics, and the level of attention mechanism used by the LLM  . For example, LLMs like GPT  use a context window to process inputs. When inputting forensic reports containing incident events, the LLM’s attention mechanism may sometimes overlook details, focusing more on the overall context and semantics of the input. This work combines multiple findings and techniques to offer an advanced automation of TA for DFIR.\n\nReference markers found: [15]\n\nContext windows for each [ref]:\n[ref]15: For instance, organizations may possess sensitive and confidential data, as well as their contextual interpretations of rules, concepts, or topic-related information, which they wish to keep private [ref]15. Data for training LLMs are typically gathered from various sources such as cookies, third-party datasets, publicly available online content, and other means. An LLM cannot access or\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 15,\n            \"titles\": [\n                \"A Comprehensive Overview of Large Language Models\",\n                \"Revolutionizing intrusion detection in industrial IoT with distributed learning and deep generative techniques\",\n                \"D4I - Digital forensics framework for reviewing and investigating cyber attacks\",\n                \"Digital Forensics and Incident Response: Incident response techniques and procedures to respond to modern cyber threats\",\n                \"A complete formalized knowledge representation model for advanced digital forensics timeline analysis\",\n                \"A comprehensive analysis of the role of artificial intelligence and machine learning in modern digital forensics and incident response\",\n                \"The Use of Artificial Intelligence in Digital Forensics and Incident Response (DFIR) in a Constrained Environment\",\n                \"Reinforcement Learning for an Efficient and Effective Malware Investigation during Cyber Incident Response\",\n                \"A Survey on Evaluation of Large Language Models\",\n                \"A Survey of Multimodal Large Language Model from A Data-centric Perspective\",\n                \"A Survey on the Memory Mechanism of Large Language Model based Agents\",\n                \"Retrieval-Augmented Generation for Large Language Models: A Survey\",\n                \"The Use of Rule-based System Technology for the Design of Man-Machine Systems\",\n                \"Closing remarks on “The integration and implications of artificial intelligence in forensic science”\",\n                \"An Event-Based Digital Forensic Investigation Framework\",\n                \"ESASCF: expertise extraction, generalization and reply framework for optimized automation of network security compliance\",\n                \"Incident Response\",\n                \"FTK Forensic Toolkit\",\n                \"Autopsy Digital Forensics\",\n                \"EnCase Forensic Suite\",\n                \"Magnet Forensics\",\n                \"An automated timeline reconstruction approach for digital forensic investigations\",\n                \"Forensic Timeline Analysis of iOS Devices\",\n                \"Automatic Timeline Construction and Analysis for Computer Forensics Purposes\",\n                \"The Phases Based Approach for Regeneration of Timeline in Digital Forensics\",\n                \"Generative AI and Large Language Models for Cyber Security: All Insights You Need\",\n                \"SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency\",\n                \"ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown\",\n                \"Enhancing Digital Investigation: Leveraging ChatGPT for Evidence Identification and Analysis in Digital Forensics\",\n                \"CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge\",\n                \"PaperQA: Retrieval-Augmented Generative Agent for Scientific Research\",\n                \"Searching for Best Practices in Retrieval-Augmented Generation\",\n                \"RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs\",\n                \"ChatGPT\",\n                \"Claude\",\n                \"Llama Models\",\n                \"Llama\",\n                \"Meta\",\n                \"GPT\",\n                \"OpenAI\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]15 based on the context and research area of Advancing Cyber Incident Timeline Analysis Through Rule-Based AI and Large Language Models. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}