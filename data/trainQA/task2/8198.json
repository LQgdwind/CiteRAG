{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: 1 Background and Main Contributions\n\nPaper Abstract: \n\nPaper Section Text:\nPapadimitriou and Yannakakis  earlier studied the computational complexity of an optimization version of SNPSNP\\mathrm{SNP}, called MAXSNPMAXSNP\\mathrm{MAXSNP}. In a similar vein, we intend to study an optimization version of SNLSNL\\mathrm{SNL} for promoting the better understandings of SNLSNL\\mathrm{SNL}. In general, an optimization problem has the form (o​p,I,S,c​o​s​t)𝑜𝑝𝐼𝑆𝑐𝑜𝑠𝑡(op,I,S,cost), where o​p∈{max,min}𝑜𝑝op\\in\\{\\max,\\min\\}, I𝐼I is a set of instances, S𝑆S is a set of (feasible) solutions, an c​o​s​t:I×S→ℕ:𝑐𝑜𝑠𝑡→𝐼𝑆ℕcost:I\\times S\\to\\mathbb{N} is a (partial) cost function.\nLet us consider a specific maximization problem, known as MAX​-​2​S​A​TMAX-2SAT\\mathrm{MAX}\\mbox{-}\\mathrm{2SAT}, in which one asks to find the truth assignment of a given 2CNF Boolean formula that maximizes the number of satisfying clauses of the formula.\nDespite a wide-range of studies on NPNP\\mathrm{NP} optimization problems, there have been a few works on logarithmic-space optimization   .\nAlong this line of studies, we further explore SNLSNL\\mathrm{SNL} optimization problems and log-space approximation schemes based on SNLSNL\\mathrm{SNL}. We define MAXSNLMAXSNL\\mathrm{MAXSNL} to be composed of all maximization problems, which are associated with SNLSNL\\mathrm{SNL} sentences ΦΦ\\Phi of the form given in Definition 2.3, and\neach maximization problem asks to find a solution (P1,P2,…,Pl)subscript𝑃1subscript𝑃2…subscript𝑃𝑙(P_{1},P_{2},\\ldots,P_{l}) satisfying ⋀i=1lF​u​n​c​(Pi)superscriptsubscript𝑖1𝑙𝐹𝑢𝑛𝑐subscript𝑃𝑖\\bigwedge_{i=1}^{l}Func(P_{i}) that maximizes the value of the objective function Π​(P1,P2,…,Pl)Πsubscript𝑃1subscript𝑃2…subscript𝑃𝑙\\Pi(P_{1},P_{2},\\ldots,P_{l}) defined to be\n|{(𝒊,𝒚)∣⋀j=1tψj​(P1,P2,…,Pl,𝒊,𝒚,𝑺,𝒄)}|,conditional-set𝒊𝒚superscriptsubscript𝑗1𝑡subscript𝜓𝑗subscript𝑃1subscript𝑃2…subscript𝑃𝑙𝒊𝒚𝑺𝒄|\\{(\\mbox{\\boldmath$i$},\\mbox{\\boldmath$y$})\\mid\\bigwedge_{j=1}^{t}\\psi_{j}(P_{1},P_{2},\\ldots,P_{l},\\mbox{\\boldmath$i$},\\mbox{\\boldmath$y$},\\mbox{\\boldmath$S$},\\mbox{\\boldmath$c$})\\}|,\nwhere P1,…,Pl,ψj,𝒊,𝒚,𝑺,𝒄subscript𝑃1…subscript𝑃𝑙subscript𝜓𝑗𝒊𝒚𝑺𝒄P_{1},\\ldots,P_{l},\\psi_{j},\\mbox{\\boldmath$i$},\\mbox{\\boldmath$y$},\\mbox{\\boldmath$S$},\\mbox{\\boldmath$c$} with 𝒊=(i1,…,ir)𝒊subscript𝑖1…subscript𝑖𝑟\\mbox{\\boldmath$i$}=(i_{1},\\ldots,i_{r}), 𝒚=(y1,…,ys)𝒚subscript𝑦1…subscript𝑦𝑠\\mbox{\\boldmath$y$}=(y_{1},\\ldots,y_{s}), 𝑺=(S1,…,Sd)𝑺subscript𝑆1…subscript𝑆𝑑\\mbox{\\boldmath$S$}=(S_{1},\\ldots,S_{d}), and 𝒄=(c1,…,cd′)𝒄subscript𝑐1…subscript𝑐superscript𝑑′\\mbox{\\boldmath$c$}=(c_{1},\\ldots,c_{d^{\\prime}}) are those in ΦΦ\\Phi.\nIt is important to note that each ψjsubscript𝜓𝑗\\psi_{j} must satisfy the second-order variable requirements (i)–(ii). It is obvious by definition that MAXSNLω⊆MAXSNL⊆MAXSNPsubscriptMAXSNL𝜔MAXSNLMAXSNP\\mathrm{MAXSNL}_{\\omega}\\subseteq\\mathrm{MAXSNL}\\subseteq\\mathrm{MAXSNP}.\nThe parameterized decision problem (2​S​A​T,mv​e​r)2SATsubscript𝑚𝑣𝑒𝑟(\\mathrm{2SAT},m_{ver}) was shown in  to be in para​-​SNLpara-SNL\\mathrm{para}\\mbox{-}\\mathrm{SNL} by constructing an appropriate SNLSNL\\mathrm{SNL} sentence for (2​S​A​T,mv​e​r)2SATsubscript𝑚𝑣𝑒𝑟(\\mathrm{2SAT},m_{ver}), where mv​e​r​(ϕ)subscript𝑚𝑣𝑒𝑟italic-ϕm_{ver}(\\phi) denotes the total number of variables appearing in a 2CNF Boolean formula ϕitalic-ϕ\\phi. From this SNLSNL\\mathrm{SNL} sentence, by carefully eliminating the presence of mv​e​rsubscript𝑚𝑣𝑒𝑟m_{ver}, we can conclude that MAX​-​2​S​A​TMAX-2SAT\\mathrm{MAX}\\mbox{-}\\mathrm{2SAT} belongs to MAXSNLMAXSNL\\mathrm{MAXSNL}.\nAs another concrete example of problems in MAXSNLMAXSNL\\mathrm{MAXSNL}, we consider MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT}, in which one is to find a set S𝑆S of vertices of a given undirected graph G=(V,E)𝐺𝑉𝐸G=(V,E) for which the number of edges crossing between S𝑆S and V−S𝑉𝑆V-S is maximized. As an instance of MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT}, we take an arbitrary undirected graph G=(VG,EG)𝐺subscript𝑉𝐺subscript𝐸𝐺G=(V_{G},E_{G}) with VG=[n]subscript𝑉𝐺delimited-[]𝑛V_{G}=[n] and EG⊆[n]×[n]subscript𝐸𝐺delimited-[]𝑛delimited-[]𝑛E_{G}\\subseteq[n]\\times[n] for a number n∈ℕ+𝑛superscriptℕn\\in\\mathbb{N}^{+}.\nWe introduce a predicate symbol E𝐸E for which E​(i,j)𝐸𝑖𝑗E(i,j) means that (i,j)𝑖𝑗(i,j) is an edge in EGsubscript𝐸𝐺E_{G}.\nGiven a second-order functional variable P𝑃P, P​(i,1)𝑃𝑖1P(i,1) (resp, P​(i,0)𝑃𝑖0P(i,0)) indicates that vertex i𝑖i belongs to a solution set S𝑆S (resp., V−S𝑉𝑆V-S).\nConsider the following SNLSNL\\mathrm{SNL} sentence indicating the existence of such a set S𝑆S: Φ≡∃fP​∀i​∀j​[ϕ1​(P,i)∧ϕ1​(P,j)∧(E​(i,j)→ϕ2​(P,E,i,j))]Φsuperscript𝑓𝑃for-all𝑖for-all𝑗delimited-[]subscriptitalic-ϕ1𝑃𝑖subscriptitalic-ϕ1𝑃𝑗→𝐸𝑖𝑗subscriptitalic-ϕ2𝑃𝐸𝑖𝑗\\Phi\\equiv\\exists^{f}P\\forall i\\forall j[\\phi_{1}(P,i)\\wedge\\phi_{1}(P,j)\\wedge(E(i,j)\\to\\phi_{2}(P,E,i,j))], where\nϕ1≡(P​(i,0)∨P​(i,1))∧¬(P​(i,0)∧P​(i,1))subscriptitalic-ϕ1𝑃𝑖0𝑃𝑖1𝑃𝑖0𝑃𝑖1\\phi_{1}\\equiv(P(i,0)\\vee P(i,1))\\wedge\\neg(P(i,0)\\wedge P(i,1)) and ϕ2≡(P​(i,1)∧P​(j,0))∨(P​(i,0)∧P​(j,1))subscriptitalic-ϕ2𝑃𝑖1𝑃𝑗0𝑃𝑖0𝑃𝑗1\\phi_{2}\\equiv(P(i,1)\\wedge P(j,0))\\vee(P(i,0)\\wedge P(j,1)). Intuitively, ϕ1​(P,i)subscriptitalic-ϕ1𝑃𝑖\\phi_{1}(P,i) means that P𝑃P forms a “function” on input i𝑖i and ϕ2​(P,E,i,j)subscriptitalic-ϕ2𝑃𝐸𝑖𝑗\\phi_{2}(P,E,i,j) means that (if (i,j)∈EG𝑖𝑗subscript𝐸𝐺(i,j)\\in E_{G}) either one of i𝑖i and j𝑗j (or both) belongs to S𝑆S. Since F​u​n​c​(P)≡∀i​[ϕ1​(P,i)]𝐹𝑢𝑛𝑐𝑃for-all𝑖delimited-[]subscriptitalic-ϕ1𝑃𝑖Func(P)\\equiv\\forall i[\\phi_{1}(P,i)], it then follows that ΦΦ\\Phi is true iff ∃fP​∀i​∀j​[F​u​n​c​(P)∧ϕ2​(P,E,i,j)]superscript𝑓𝑃for-all𝑖for-all𝑗delimited-[]𝐹𝑢𝑛𝑐𝑃subscriptitalic-ϕ2𝑃𝐸𝑖𝑗\\exists^{f}P\\forall i\\forall j[Func(P)\\wedge\\phi_{2}(P,E,i,j)]. Thus, ΦΦ\\Phi is also an SNLωsubscriptSNL𝜔\\mathrm{SNL}_{\\omega} sentence.\nThe objective function Π​(P)Π𝑃\\Pi(P) for MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT} is defined to be |{(i,j)∣ϕ1​(P,i)∧ϕ1​(P,j)∧E​(i,j)∧ϕ2​(P,E,i,j)}|conditional-set𝑖𝑗subscriptitalic-ϕ1𝑃𝑖subscriptitalic-ϕ1𝑃𝑗𝐸𝑖𝑗subscriptitalic-ϕ2𝑃𝐸𝑖𝑗|\\{(i,j)\\mid\\phi_{1}(P,i)\\wedge\\phi_{1}(P,j)\\wedge E(i,j)\\wedge\\phi_{2}(P,E,i,j)\\}|.\nWe thus conclude that MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT} belongs to MAXSNLMAXSNL\\mathrm{MAXSNL}.\n We discuss another simple example, called MAX​-​UKMAX-UK\\mathrm{MAX}\\mbox{-}\\mathrm{UK}, which is a maximization version of UKUK\\mathrm{UK} (discussed in Example 2.9) of the following specific form: one asks to find a subset S⊆[n]𝑆delimited-[]𝑛S\\subseteq[n] that maximizes ∑i∈Saisubscript𝑖𝑆subscript𝑎𝑖\\sum_{i\\in S}a_{i} within the upper bound b𝑏b for a given series (1b,1a1,1a2,…,1an)superscript1𝑏superscript1subscript𝑎1superscript1subscript𝑎2…superscript1subscript𝑎𝑛(1^{b},1^{a_{1}},1^{a_{2}},\\ldots,1^{a_{n}}) of unary strings with b,a1,a2,…,an∈ℕ+𝑏subscript𝑎1subscript𝑎2…subscript𝑎𝑛superscriptℕb,a_{1},a_{2},\\ldots,a_{n}\\in\\mathbb{N}^{+}. We assert that MAX​-​UKMAX-UK\\mathrm{MAX}\\mbox{-}\\mathrm{UK} is in MAXSNLMAXSNL\\mathrm{MAXSNL}. To prove this assertion, we recall the predicate symbol I𝐼I from Example 2.9. We introduce a second-order variable P𝑃P so that P​(k,w)𝑃𝑘𝑤P(k,w) means w=∑i∈S∩[k]ai𝑤subscript𝑖𝑆delimited-[]𝑘subscript𝑎𝑖w=\\sum_{i\\in S\\cap[k]}a_{i} for an optimal solution S𝑆S (⊆[n]absentdelimited-[]𝑛\\subseteq[n]). We also set ∑i∈S∩[k]aisubscript𝑖𝑆delimited-[]𝑘subscript𝑎𝑖\\sum_{i\\in S\\cap[k]}a_{i} to be 00 whenever k=0𝑘0k=0.\nWe then define Π​(P)Π𝑃\\Pi(P) as |{(i,s,t,j)∣0≤i<n∧0<j≤t∧P​(0,0)∧P​(i,s)∧P​(i+1,s+t)∧(t=0∨(s+t≤b∧I​(i+1,t)))}|conditional-set𝑖𝑠𝑡𝑗0𝑖𝑛0𝑗𝑡𝑃00𝑃𝑖𝑠𝑃𝑖1𝑠𝑡𝑡0𝑠𝑡𝑏𝐼𝑖1𝑡|\\{(i,s,t,j)\\mid 0\\leq i<n\\wedge 0<j\\leq t\\wedge P(0,0)\\wedge P(i,s)\\wedge P(i+1,s+t)\\wedge(t=0\\vee(s+t\\leq b\\wedge I(i+1,t)))\\}|, where the variable j𝑗j is used to include t𝑡t elements (i,s,t,0),(i,s,t,1),…,(i,s,t,t−1)𝑖𝑠𝑡0𝑖𝑠𝑡1…𝑖𝑠𝑡𝑡1(i,s,t,0),(i,s,t,1),\\ldots,(i,s,t,t-1) if variables i,s,t𝑖𝑠𝑡i,s,t satisfy the condition.\nIf P𝑃P expresses a solution of a MAX​-​UKMAX-UK\\mathrm{MAX}\\mbox{-}\\mathrm{UK} instance, then its objective function Π​(P)Π𝑃\\Pi(P) can compute ∑i∈Saisubscript𝑖𝑆subscript𝑎𝑖\\sum_{i\\in S}a_{i}. Notice that ∑i∈Saisubscript𝑖𝑆subscript𝑎𝑖\\sum_{i\\in S}a_{i} is the maximum within b𝑏b iff Π​(P)Π𝑃\\Pi(P) is the maximum. This places MAX​-​UKMAX-UK\\mathrm{MAX}\\mbox{-}\\mathrm{UK} to MAXSNLMAXSNL\\mathrm{MAXSNL}.\n For any two optimization problems in MAXSNPMAXSNP\\mathrm{MAXSNP}, a special reduction, called (polynomial-time) linear reduction, was introduced in .\nConcerning log-space computing, we instead use the notion of logarithmic-space AP-reducibility .\nGiven two optimization (i.e., either maximization or minimization) problems P1subscript𝑃1P_{1} and P2subscript𝑃2P_{2}, we say that P1subscript𝑃1P_{1} is logarithmic-space (or log-space) AP-reducible to P2subscript𝑃2P_{2} if there are two constants c1,c2>0subscript𝑐1subscript𝑐20c_{1},c_{2}>0 and two functions f𝑓f and g𝑔g in FLFL\\mathrm{FL} such that,\nfor any value r∈ℚ>1𝑟superscriptℚabsent1r\\in\\mathbb{Q}^{>1},\n(i) for any instance x𝑥x of P1subscript𝑃1P_{1}, f​(x,r)𝑓𝑥𝑟f(x,r) is an instance of P2subscript𝑃2P_{2} and\n(ii) for any solution s𝑠s to the instance f​(x,r)𝑓𝑥𝑟f(x,r) of P2subscript𝑃2P_{2}, g​(x,s,r)𝑔𝑥𝑠𝑟g(x,s,r) is a solution of the instance x𝑥x of P1subscript𝑃1P_{1} satisfying e​r​r​(x,g​(x,s,r))≤c2⋅e​r​r​(f​(x,r),s)𝑒𝑟𝑟𝑥𝑔𝑥𝑠𝑟⋅subscript𝑐2𝑒𝑟𝑟𝑓𝑥𝑟𝑠err(x,g(x,s,r))\\leq c_{2}\\cdot err(f(x,r),s). Here, e​r​r​(u,z)𝑒𝑟𝑟𝑢𝑧err(u,z) denotes the value max⁡{c​o​s​t​(o​p​t​(u))c​o​s​t​(z),c​o​s​t​(z)c​o​s​t​(o​p​t​(u))}−1𝑐𝑜𝑠𝑡𝑜𝑝𝑡𝑢𝑐𝑜𝑠𝑡𝑧𝑐𝑜𝑠𝑡𝑧𝑐𝑜𝑠𝑡𝑜𝑝𝑡𝑢1\\max\\{\\frac{cost(opt(u))}{cost(z)},\\frac{cost(z)}{cost(opt(u))}\\}-1 for stings u,z𝑢𝑧u,z, assuming that these denominators are not zero, where o​p​t​(u)𝑜𝑝𝑡𝑢opt(u) means an optimal solution to instance u𝑢u and c​o​s​t​(z)𝑐𝑜𝑠𝑡𝑧cost(z) means the value (or cost) of string z𝑧z.\nTo distinguish it from (standard) LL\\mathrm{L}-m-reductions, we use the special notation of ≤A​PLsubscriptsuperscriptL𝐴𝑃\\leq^{\\mathrm{L}}_{AP} to mean the log-space AP-reductions. Let r𝑟r denote any nondecreasing function from ℕℕ\\mathbb{N} to ℕℕ\\mathbb{N}. Given two optimization problems Ξ1subscriptΞ1\\Xi_{1} and Ξ2subscriptΞ2\\Xi_{2}, if Ξ1≤A​PLΞ2subscriptsuperscriptL𝐴𝑃subscriptΞ1subscriptΞ2\\Xi_{1}\\leq^{\\mathrm{L}}_{AP}\\Xi_{2} and Ξ2subscriptΞ2\\Xi_{2} is log-space approximable within ratio r​(n)𝑟𝑛r(n), then Ξ1subscriptΞ1\\Xi_{1} is also log-space approximable within ratio O​(r​(nt+t))𝑂𝑟superscript𝑛𝑡𝑡O(r(n^{t}+t)) for a certain fixed constant t≥1𝑡1t\\geq 1. Proof.   \nLet us take two constants c1,c2>0subscript𝑐1subscript𝑐20c_{1},c_{2}>0 and two functions f,g∈FL𝑓𝑔FLf,g\\in\\mathrm{FL} that make Ξ1subscriptΞ1\\Xi_{1} log-space AP-reducible to Ξ2subscriptΞ2\\Xi_{2} via (f,g,c1,c2)𝑓𝑔subscript𝑐1subscript𝑐2(f,g,c_{1},c_{2}).\nGiven a nondecreasing function r𝑟r, we take another function hℎh in FLFL\\mathrm{FL} such that, for any x𝑥x, h​(x)ℎ𝑥h(x) is an approximate solution to the instance x𝑥x of Ξ2subscriptΞ2\\Xi_{2} within approximation ratio r​(|x|)𝑟𝑥r(|x|).\nIn what follows, we intend to construct another function k𝑘k that produces an approximate solution to each instance of Ξ1subscriptΞ1\\Xi_{1}. Consider the composite function k=g∘h∘f𝑘𝑔ℎ𝑓k=g\\circ h\\circ f. For any instance x𝑥x, since f​(x)𝑓𝑥f(x) is an instance of Ξ2subscriptΞ2\\Xi_{2}, h∘f​(x)ℎ𝑓𝑥h\\circ f(x) is a solution to the instance f​(x)𝑓𝑥f(x). Thus, k​(x)𝑘𝑥k(x) is an approximate solution to the instance x𝑥x of Ξ1subscriptΞ1\\Xi_{1}. It then follows that c​o​s​t​(o​p​t​(x))≤c1⋅c​o​s​t​(o​p​t​(f​(x)))𝑐𝑜𝑠𝑡𝑜𝑝𝑡𝑥⋅subscript𝑐1𝑐𝑜𝑠𝑡𝑜𝑝𝑡𝑓𝑥cost(opt(x))\\leq c_{1}\\cdot cost(opt(f(x))) and e​r​r​(k​(x),o​p​t​(x))≤c2⋅e​r​r​(h∘f​(x),o​p​t​(f​(x)))𝑒𝑟𝑟𝑘𝑥𝑜𝑝𝑡𝑥⋅subscript𝑐2𝑒𝑟𝑟ℎ𝑓𝑥𝑜𝑝𝑡𝑓𝑥err(k(x),opt(x))\\leq c_{2}\\cdot err(h\\circ f(x),opt(f(x))).\nSince the approximation ratio r​(|z|)𝑟𝑧r(|z|) for Ξ2subscriptΞ2\\Xi_{2} equals e​r​r​(h​(z),o​p​t​(z))+1𝑒𝑟𝑟ℎ𝑧𝑜𝑝𝑡𝑧1err(h(z),opt(z))+1 for any instance z𝑧z to Ξ2subscriptΞ2\\Xi_{2},\nit follows that e​r​r​(h∘f​(x),o​p​t​(f​(x)))𝑒𝑟𝑟ℎ𝑓𝑥𝑜𝑝𝑡𝑓𝑥err(h\\circ f(x),opt(f(x))) equals r​(|f​(x)|)−1𝑟𝑓𝑥1r(|f(x)|)-1. Thus, the value e​r​r​(k​(x),o​p​t​(x))+1𝑒𝑟𝑟𝑘𝑥𝑜𝑝𝑡𝑥1err(k(x),opt(x))+1 is upper-bounded by c2​(r​(|f​(x)|)−1)+1subscript𝑐2𝑟𝑓𝑥11c_{2}(r(|f(x)|)-1)+1. Since |f​(x)|≤|x|t+t𝑓𝑥superscript𝑥𝑡𝑡|f(x)|\\leq|x|^{t}+t for a certain constant t∈ℕ+𝑡superscriptℕt\\in\\mathbb{N}^{+}, e​r​r​(k​(x),o​p​t​(x))+1𝑒𝑟𝑟𝑘𝑥𝑜𝑝𝑡𝑥1err(k(x),opt(x))+1 is at most c2⋅r​(|x|t+t)+1⋅subscript𝑐2𝑟superscript𝑥𝑡𝑡1c_{2}\\cdot r(|x|^{t}+t)+1. This implies that Ξ1subscriptΞ1\\Xi_{1} is approximable within ratio c2​r​(|x|t+t)+1subscript𝑐2𝑟superscript𝑥𝑡𝑡1c_{2}r(|x|^{t}+t)+1.\n □□\\Box It is important to note that every minimization problem can be log-space AP-reducible to its associated maximization problem  .\nSee also  for a similar treatment. This fact helps us focus only on maximization problems in the following statement. ≤A​PL(MAXSNP)=≤A​PL(MAXSNL)=≤A​PL(MAXSNLω)\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAXSNP})=\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAXSNL})=\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAXSNL}_{\\omega}). Papadimitriou and Yannakakis  demonstrated that every maximization problem in MAXSNPMAXSNP\\mathrm{MAXSNP} can be polynomial-time linear reducible to MAX​-​3​S​A​TMAX-3SAT\\mathrm{MAX}\\mbox{-}\\mathrm{3SAT}. Their reduction is in fact carried out using only log space. This fact immediately implies that every maximization problem in MAXSNPMAXSNP\\mathrm{MAXSNP} is log-space AP-reducible to MAX​-​3​S​A​TMAX-3SAT\\mathrm{MAX}\\mbox{-}\\mathrm{3SAT}. In other words, MAX​-​3​S​A​TMAX-3SAT\\mathrm{MAX}\\mbox{-}\\mathrm{3SAT} is complete for MAXSNPMAXSNP\\mathrm{MAXSNP} under log-space AP-reductions. MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT} is complete for MAXSNLMAXSNL\\mathrm{MAXSNL} under log-space AP-reductions. It is also possible to replace MAXSNLMAXSNL\\mathrm{MAXSNL} by MAXSNLωsubscriptMAXSNL𝜔\\mathrm{MAXSNL}_{\\omega}. Proof.   \nLet us recall from Example 4.13 that MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT} is in MAXSNLMAXSNL\\mathrm{MAXSNL}. Consider any maximization problem ΞΞ\\Xi in MAXSNLMAXSNL\\mathrm{MAXSNL} with an associated SNLSNL\\mathrm{SNL} sentence ΦΦ\\Phi of the form ∃fP1​⋯​∃fPl​∀𝒊​∀𝒚​[⋀j=1tϕj​(P1,…,Pl,𝒊,𝒚)]superscript𝑓subscript𝑃1⋯superscript𝑓subscript𝑃𝑙for-all𝒊for-all𝒚delimited-[]superscriptsubscript𝑗1𝑡subscriptitalic-ϕ𝑗subscript𝑃1…subscript𝑃𝑙𝒊𝒚\\exists^{f}P_{1}\\cdots\\exists^{f}P_{l}\\forall\\mbox{\\boldmath$i$}\\forall\\mbox{\\boldmath$y$}[\\bigwedge_{j=1}^{t}\\phi_{j}(P_{1},\\ldots,P_{l},\\mbox{\\boldmath$i$},\\mbox{\\boldmath$y$})]. We take three steps to construct a log-space AP-reduction from ΞΞ\\Xi to MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT}.\nFirstly, we reduce ΞΞ\\Xi to MAX​-​2​S​A​TMAX-2SAT\\mathrm{MAX}\\mbox{-}\\mathrm{2SAT} and then reduce MAX​-​2​S​A​TMAX-2SAT\\mathrm{MAX}\\mbox{-}\\mathrm{2SAT} to MAX​-​WTDCUTMAX-WTDCUT\\mathrm{MAX}\\mbox{-}\\mathrm{WTDCUT}. Here, MAX​-​WTDCUTMAX-WTDCUT\\mathrm{MAX}\\mbox{-}\\mathrm{WTDCUT} is a “weighted” version of MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT}, which is obtained by allowing each edge to hold a (positive integer) weight and maximizing the total weight of edges whose endpoints are assigned to two different sets S𝑆S and V−S𝑉𝑆V-S.\nFinally, we reduce MAX​-​WTDCUTMAX-WTDCUT\\mathrm{MAX}\\mbox{-}\\mathrm{WTDCUT} to MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT} to complete the proof. (1) When a domain structure 𝒟xsubscript𝒟𝑥{\\cal D}_{x} for ΦΦ\\Phi is given for an instance x𝑥x, the variables tuples (𝒊,𝒚)𝒊𝒚(\\mbox{\\boldmath$i$},\\mbox{\\boldmath$y$}) take only polynomially many different values.\nWe assign those values (ı¯,𝒚¯)bold-¯bold-italic-ıbold-¯𝒚(\\mbox{\\boldmath$\\bar{\\imath}$},\\mbox{\\boldmath$\\bar{y}$}) to (𝒊,𝒚)𝒊𝒚(\\mbox{\\boldmath$i$},\\mbox{\\boldmath$y$}) one by one to generate polynomially many “formulas” ϕj​(P1,…,Pl,ı¯,𝒚¯)subscriptitalic-ϕ𝑗subscript𝑃1…subscript𝑃𝑙bold-¯bold-italic-ıbold-¯𝒚\\phi_{j}(P_{1},\\ldots,P_{l},\\mbox{\\boldmath$\\bar{\\imath}$},\\mbox{\\boldmath$\\bar{y}$}). Notice that each ϕjsubscriptitalic-ϕ𝑗\\phi_{j} can be rewritten as a formula made up from variables of the form Pk​(ı¯,y¯)subscript𝑃𝑘¯italic-ı¯𝑦P_{k}(\\bar{\\imath},\\bar{y}) or ¬Pk​(ı¯,y¯)subscript𝑃𝑘¯italic-ı¯𝑦\\neg P_{k}(\\bar{\\imath},\\bar{y}) as well as the constants T𝑇T(true) and F𝐹F (false) because Sr​(ı¯,𝒚¯)subscript𝑆𝑟bold-¯bold-italic-ıbold-¯𝒚S_{r}(\\mbox{\\boldmath$\\bar{\\imath}$},\\mbox{\\boldmath$\\bar{y}$})’s are evaluated to be either T𝑇T or F𝐹F. The second-order variable requirement of ΦΦ\\Phi forces this formula to be expressed as a 2CNF formula. Thus, ΞΞ\\Xi is reduced to MAX​-​2​S​A​TMAX-2SAT\\mathrm{MAX}\\mbox{-}\\mathrm{2SAT}. (2) The reduction MAX​-​2​S​A​T≤A​PLMAX​-​WTDCUTsubscriptsuperscriptL𝐴𝑃MAX-2SATMAX-WTDCUT\\mathrm{MAX}\\mbox{-}\\mathrm{2SAT}\\leq^{\\mathrm{L}}_{AP}\\mathrm{MAX}\\mbox{-}\\mathrm{WTDCUT} is given as follows. We loosely follow an argument of [16, Theorem 2]. Let ϕitalic-ϕ\\phi be any 2CNF Boolean formula of the form ⋀i=1tϕisuperscriptsubscript𝑖1𝑡subscriptitalic-ϕ𝑖\\bigwedge_{i=1}^{t}\\phi_{i} with ϕi≡zi,1∨zi,2subscriptitalic-ϕ𝑖subscript𝑧𝑖1subscript𝑧𝑖2\\phi_{i}\\equiv z_{i,1}\\vee z_{i,2} for literals zi,1subscript𝑧𝑖1z_{i,1} and zi,2subscript𝑧𝑖2z_{i,2}. We then construct a weighted undirected graph G=(V,E)𝐺𝑉𝐸G=(V,E). The vertices are labeled with variables as well as their negations except for a special vertex w𝑤w. Sequentially, we choose a clause ϕisubscriptitalic-ϕ𝑖\\phi_{i} and then add three edges to form a triangle among three vertices zi,1,zi,2,wsubscript𝑧𝑖1subscript𝑧𝑖2𝑤z_{i,1},z_{i,2},w. Moreover, we add an edge between every variable x𝑥x and its negation x¯¯𝑥\\bar{x} with weight of 2​k2𝑘2k, where k𝑘k is the number of times that x𝑥x or x¯¯𝑥\\bar{x} appears in ϕitalic-ϕ\\phi. The weight of any edge in each triangle (zi,1,zi,2,w)subscript𝑧𝑖1subscript𝑧𝑖2𝑤(z_{i,1},z_{i,2},w) is 2​k′2superscript𝑘′2k^{\\prime}, where k′superscript𝑘′k^{\\prime} is the number of clauses in which the pair zi,1,zi,2subscript𝑧𝑖1subscript𝑧𝑖2z_{i,1},z_{i,2} appears simultaneously (ignoring their appearance order). Notice that any edge weight is always even.\nThis modification can be done in log space. As argued in , the objective value is twice as large as the sum of the numbers of literal occurrences and that of satisfying clauses. (3) The third reduction MAX​-​WTDCUT≤A​PLMAX​-​CUTsubscriptsuperscriptL𝐴𝑃MAX-WTDCUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{WTDCUT}\\leq^{\\mathrm{L}}_{AP}\\mathrm{MAX}\\mbox{-}\\mathrm{CUT} is done as follows.\nFrom the argument of (2), it suffices to consider the case where the weight of each edge of an undirected graph is an even number. For each edge (v1,v2)subscript𝑣1subscript𝑣2(v_{1},v_{2}) with weight 2​k2𝑘2k, we prepare k𝑘k new vertices, say, u1,u2,…,uksubscript𝑢1subscript𝑢2…subscript𝑢𝑘u_{1},u_{2},\\ldots,u_{k} and add two edges (v1,ui)subscript𝑣1subscript𝑢𝑖(v_{1},u_{i}) and (ui,v2)subscript𝑢𝑖subscript𝑣2(u_{i},v_{2}) for each index i∈[k]𝑖delimited-[]𝑘i\\in[k].\n □□\\Box Proposition 4.16 follows from Lemma 4.17 since MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT} is in MAXSNLMAXSNL\\mathrm{MAXSNL} by Example 4.13. Proof of Proposition 4.16.  \nSince MAXSNLω⊆MAXSNL⊆MAXSNPsubscriptMAXSNL𝜔MAXSNLMAXSNP\\mathrm{MAXSNL}_{\\omega}\\subseteq\\mathrm{MAXSNL}\\subseteq\\mathrm{MAXSNP}, this instantly implies that ≤A​PL(MAXSNLω)⊆≤A​PL(MAXSNL)⊆≤A​PL(MAXSNP)\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAXSNL}_{\\omega})\\subseteq\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAXSNL})\\subseteq\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAXSNP}).\nTo see another inclusion, as noted earlier, every maximization problem in MAXSNPMAXSNP\\mathrm{MAXSNP} is log-space AP-reducible to MAX​-​3​S​A​TMAX-3SAT\\mathrm{MAX}\\mbox{-}\\mathrm{3SAT}. This fact implies that MAXSNP≤A​PL(MAX​-​3​S​A​T)subscriptsuperscriptL𝐴𝑃MAXSNPMAX-3SAT\\mathrm{MAXSNP}\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAX}\\mbox{-}\\mathrm{3SAT}). Next, we consider the maximization problem MAX​-​CUTMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{CUT}, which belongs to MAXSNLωsubscriptMAXSNL𝜔\\mathrm{MAXSNL}_{\\omega} by Example 4.13.\nIt then suffices to show that (*) MAX​-​3​S​A​T≤A​PLMAX​-​CUTsubscriptsuperscriptL𝐴𝑃MAX-3SATMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{3SAT}\\leq^{\\mathrm{L}}_{AP}\\mathrm{MAX}\\mbox{-}\\mathrm{CUT}\nbecause we obtain ≤A​PL(MAX-3SAT)⊆≤A​PL(MAX-CUT)⊆≤A​PL(MAXSNLω)\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAX}\\mbox{-}\\mathrm{3SAT})\\subseteq\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAX}\\mbox{-}\\mathrm{CUT})\\subseteq\\leq^{\\mathrm{L}}_{AP}\\!(\\mathrm{MAXSNL}_{\\omega}) from Lemma 4.17.\nThe desired reduction (*) will be achieved by proving MAX​-​3​S​A​T≤A​PLMAX​-​2​S​A​TsubscriptsuperscriptL𝐴𝑃MAX-3SATMAX-2SAT\\mathrm{MAX}\\mbox{-}\\mathrm{3SAT}\\leq^{\\mathrm{L}}_{AP}\\mathrm{MAX}\\mbox{-}\\mathrm{2SAT} because MAX​-​2​S​A​T≤A​PLMAX​-​CUTsubscriptsuperscriptL𝐴𝑃MAX-2SATMAX-CUT\\mathrm{MAX}\\mbox{-}\\mathrm{2SAT}\\leq^{\\mathrm{L}}_{AP}\\mathrm{MAX}\\mbox{-}\\mathrm{CUT} has already been shown in the proof of Lemma 4.17.\nOur target reduction (*) comes from a note of Williams  on\na transformation of a clause ϕitalic-ϕ\\phi of the form z1∨z2∨z3subscript𝑧1subscript𝑧2subscript𝑧3z_{1}\\vee z_{2}\\vee z_{3}, where z1,z2,z3subscript𝑧1subscript𝑧2subscript𝑧3z_{1},z_{2},z_{3} are literals, to the following ten clauses: z1∨z1subscript𝑧1subscript𝑧1z_{1}\\vee z_{1}, z2∨z2subscript𝑧2subscript𝑧2z_{2}\\vee z_{2}, z3∨z3subscript𝑧3subscript𝑧3z_{3}\\vee z_{3}, w∨w𝑤𝑤w\\vee w, z1¯∨z2¯¯subscript𝑧1¯subscript𝑧2\\overline{z_{1}}\\vee\\overline{z_{2}}, z2¯∨z3¯¯subscript𝑧2¯subscript𝑧3\\overline{z_{2}}\\vee\\overline{z_{3}}, z1¯∨z3¯¯subscript𝑧1¯subscript𝑧3\\overline{z_{1}}\\vee\\overline{z_{3}}, z1∨w¯subscript𝑧1¯𝑤z_{1}\\vee\\overline{w}, z2∨w¯subscript𝑧2¯𝑤z_{2}\\vee\\overline{w}, z3∨w¯subscript𝑧3¯𝑤z_{3}\\vee\\overline{w}, where w𝑤w is a new variable associated with ϕitalic-ϕ\\phi and zi¯¯subscript𝑧𝑖\\overline{z_{i}} (i∈{1,2,3}𝑖123i\\in\\{1,2,3\\}) denotes x¯¯𝑥\\overline{x} (resp., x𝑥x) if zisubscript𝑧𝑖z_{i} is a variable x𝑥x (resp., if zisubscript𝑧𝑖z_{i} is the negation of a variable x𝑥x). As noted in , for any given assignment, (i) if it satisfies ϕitalic-ϕ\\phi, then exactly 777 out of ten classes are satisfied and (ii) if it does not satisfy ϕitalic-ϕ\\phi, then exactly 666 out of ten classes are satisfied.\n □□\\Box It was shown in [16, Theorem 1] that every optimization problem in MAXSNPMAXSNP\\mathrm{MAXSNP} is approximated in polynomial time within a certain fixed approximation ratio.\nIn this work, we intend to discuss how to solve optimization problems approximately using log-space computation, which were studied earlier in   .\nFollowing , we define APXLAPXL\\mathrm{APXL} (denoted APXLNLOsubscriptAPXLNLO\\mathrm{APXL}_{\\mathrm{NLO}} in ) to be the collection of NLNL\\mathrm{NL} optimization problems that can be approximated in polynomial time using log space with fixed constant approximation ratios. MAX​-​UKMAX-UK\\mathrm{MAX}\\mbox{-}\\mathrm{UK} is in APXLAPXL\\mathrm{APXL}. Proof.   \nLet x𝑥x denote any instance (1b,1a1,1a2,…,1an)superscript1𝑏superscript1subscript𝑎1superscript1subscript𝑎2…superscript1subscript𝑎𝑛(1^{b},1^{a_{1}},1^{a_{2}},\\ldots,1^{a_{n}}) given to MAX​-​UKMAX-UK\\mathrm{MAX}\\mbox{-}\\mathrm{UK}. Consider the following greedy algorithm. Since we can enumerate unary-form integers a1,a2,…,ansubscript𝑎1subscript𝑎2…subscript𝑎𝑛a_{1},a_{2},\\ldots,a_{n} given as (1a1,1a2,…,1an)superscript1subscript𝑎1superscript1subscript𝑎2…superscript1subscript𝑎𝑛(1^{a_{1}},1^{a_{2}},\\ldots,1^{a_{n}}) in descending order using log space (see, e.g., ), we assume that a1≥a2≥⋯≥ansubscript𝑎1subscript𝑎2⋯subscript𝑎𝑛a_{1}\\geq a_{2}\\geq\\cdots\\geq a_{n} in the rest of our argument. We wish to inductively construct a subset S𝑆S of [n]delimited-[]𝑛[n], starting with S=∅𝑆S=\\varnothing, as follows.\nBy incrementing i𝑖i by one from i=0𝑖0i=0, we pick aisubscript𝑎𝑖a_{i} and check whether ∑j∈Saj+ai≤bsubscript𝑗𝑆subscript𝑎𝑗subscript𝑎𝑖𝑏\\sum_{j\\in S}a_{j}+a_{i}\\leq b. If so, then we expand S𝑆S by adding i𝑖i to S𝑆S; otherwise, we do nothing. We show that this is an approximation scheme with an approximation ratio of at most 222. Let S={i1,i2,…,ik}𝑆subscript𝑖1subscript𝑖2…subscript𝑖𝑘S=\\{i_{1},i_{2},\\ldots,i_{k}\\} be the set constructed by the approximation scheme.\nIf ∑i=1nai≤bsuperscriptsubscript𝑖1𝑛subscript𝑎𝑖𝑏\\sum_{i=1}^{n}a_{i}\\leq b, then S𝑆S must be [n]delimited-[]𝑛[n], and thus the scheme correctly solves the given problem. Next, let us consider the other case of ∑i=1nai>bsuperscriptsubscript𝑖1𝑛subscript𝑎𝑖𝑏\\sum_{i=1}^{n}a_{i}>b.\nWe assume that ∑j∈Saj<b2subscript𝑗𝑆subscript𝑎𝑗𝑏2\\sum_{j\\in S}a_{j}<\\frac{b}{2}.\nIf ik<nsubscript𝑖𝑘𝑛i_{k}<n, then we obtain aik+1>b2subscript𝑎subscript𝑖𝑘1𝑏2a_{i_{k}+1}>\\frac{b}{2} because of ∑j∈Saj+aik+1>bsubscript𝑗𝑆subscript𝑎𝑗subscript𝑎subscript𝑖𝑘1𝑏\\sum_{j\\in S}a_{j}+a_{i_{k}+1}>b.\nSince ai1≥ai2≥⋯≥aik≥aik+1subscript𝑎subscript𝑖1subscript𝑎subscript𝑖2⋯subscript𝑎subscript𝑖𝑘subscript𝑎subscript𝑖𝑘1a_{i_{1}}\\geq a_{i_{2}}\\geq\\cdots\\geq a_{i_{k}}\\geq a_{i_{k}+1}, it follows that aij>b2subscript𝑎subscript𝑖𝑗𝑏2a_{i_{j}}>\\frac{b}{2} for all indices j∈[k]𝑗delimited-[]𝑘j\\in[k]. This is in contradiction with ∑j∈Saj<b2subscript𝑗𝑆subscript𝑎𝑗𝑏2\\sum_{j\\in S}a_{j}<\\frac{b}{2}.\nIn the case of ik=nsubscript𝑖𝑘𝑛i_{k}=n, we take the largest number i∗subscript𝑖i_{*} in the set [n]−{i1,i2,…,ik}delimited-[]𝑛subscript𝑖1subscript𝑖2…subscript𝑖𝑘[n]-\\{i_{1},i_{2},\\ldots,i_{k}\\} and follow a similar argument as above to reach a contradiction.\nThus, ∑j∈Saj≥b2subscript𝑗𝑆subscript𝑎𝑗𝑏2\\sum_{j\\in S}a_{j}\\geq\\frac{b}{2} must hold. Since the optimal solution has a value of at most b𝑏b, the approximation ratio cannot exceed 222.\n □□\\Box Let us analyze the proof of Proposition 4.18. Firstly, recall Π​(P)Π𝑃\\Pi(P) defined in Example 4.14 for MAX​-​UKMAX-UK\\mathrm{MAX}\\mbox{-}\\mathrm{UK}. We place a restriction on Π​(P)Π𝑃\\Pi(P) as follows.\nFor each value a∈[n]𝑎delimited-[]𝑛a\\in[n], the restriction Π(P)⌈a\\Pi(P)\\lceil_{a} is defined to be |{(i,s,t,j)∣0≤i<a∧0<j≤t∧P​(0,0)∧P​(i,s)∧P​(i+1,s+t)∧(t=0∨(s+t≤b∧I​(i+1,t)))}|conditional-set𝑖𝑠𝑡𝑗0𝑖𝑎0𝑗𝑡𝑃00𝑃𝑖𝑠𝑃𝑖1𝑠𝑡𝑡0𝑠𝑡𝑏𝐼𝑖1𝑡|\\{(i,s,t,j)\\mid 0\\leq i<a\\wedge 0<j\\leq t\\wedge P(0,0)\\wedge P(i,s)\\wedge P(i+1,s+t)\\wedge(t=0\\vee(s+t\\leq b\\wedge I(i+1,t)))\\}|.\nIt then follows by a simple calculation that P​(0,s)𝑃0𝑠P(0,s) is true iff\nΠ(P)⌈0=s\\Pi(P)\\lceil_{0}=s and that P​(a,s)𝑃𝑎𝑠P(a,s) is true iff Π(P)⌈a=s\\Pi(P)\\lceil_{a}=s. From this fact, it follows that, for any a∈[n−1]𝑎delimited-[]𝑛1a\\in[n-1], (i) Π(P)⌈a≤Π(P)⌈a+1≤Π(Po​p​t)\\Pi(P)\\lceil_{a}\\leq\\Pi(P)\\lceil_{a+1}\\leq\\Pi(P_{opt}), where Po​p​tsubscript𝑃𝑜𝑝𝑡P_{opt} is an optimal choice of P𝑃P, and (ii) when P​(a,s)∧P​(a+1,s+t)𝑃𝑎𝑠𝑃𝑎1𝑠𝑡P(a,s)\\wedge P(a+1,s+t) is true, Π(P)⌈a+t=Π(P)⌈a+1\\Pi(P)\\lceil_{a}+t=\\Pi(P)\\lceil_{a+1}.\nWe wish to rephrase Π​(P)Π𝑃\\Pi(P) in a more generic form.\nFor this purpose, we introduce another formula R𝑅R defined by R​(i+1,s,u,v,w,z)≡s=0∧0≤i<n∧u<w+u≤v∧(u=v∨(z+u=v≤b∧I​(i+1,z)))𝑅𝑖1𝑠𝑢𝑣𝑤𝑧𝑠00𝑖𝑛𝑢𝑤𝑢𝑣𝑢𝑣𝑧𝑢𝑣𝑏𝐼𝑖1𝑧R(i+1,s,u,v,w,z)\\equiv s=0\\wedge 0\\leq i<n\\wedge u<w+u\\leq v\\wedge(u=v\\vee(z+u=v\\leq b\\wedge I(i+1,z))).\nThe objective function Π​(P)Π𝑃\\Pi(P) is then rephrased as |{(i,s,u,v,w,z)∣0<i<n∧P​(0,s)∧P​(i,u)∧P​(i+1,v)∧R​(i+1,s,u,v,w,z)}|conditional-set𝑖𝑠𝑢𝑣𝑤𝑧0𝑖𝑛𝑃0𝑠𝑃𝑖𝑢𝑃𝑖1𝑣𝑅𝑖1𝑠𝑢𝑣𝑤𝑧|\\{(i,s,u,v,w,z)\\mid 0<i<n\\wedge P(0,s)\\wedge P(i,u)\\wedge P(i+1,v)\\wedge R(i+1,s,u,v,w,z)\\}|. For each triplet (s,u,v)𝑠𝑢𝑣(s,u,v), we further define gP,i+1​(s,u,v)=|{(w,z)∣R​(i+1,s,u,v,w,z)}|subscript𝑔𝑃𝑖1𝑠𝑢𝑣conditional-set𝑤𝑧𝑅𝑖1𝑠𝑢𝑣𝑤𝑧g_{P,i+1}(s,u,v)=|\\{(w,z)\\mid R(i+1,s,u,v,w,z)\\}|. It then follows that, if v𝑣v satisfies z+u=v≤b∧I​(i+1,z)𝑧𝑢𝑣𝑏𝐼𝑖1𝑧z+u=v\\leq b\\wedge I(i+1,z) for a certain number z>0𝑧0z>0, then gP,i+1​(s,u,v)=zsubscript𝑔𝑃𝑖1𝑠𝑢𝑣𝑧g_{P,i+1}(s,u,v)=z; otherwise, gP,i+1​(s,u,v)=0subscript𝑔𝑃𝑖1𝑠𝑢𝑣0g_{P,i+1}(s,u,v)=0. From this, if P​(0,s)∧P​(i,u)∧P​(i+1,v)𝑃0𝑠𝑃𝑖𝑢𝑃𝑖1𝑣P(0,s)\\wedge P(i,u)\\wedge P(i+1,v) is true, then Π(P)⌈i+1=Π(P)⌈i+gP,i+1(s,u,v)\\Pi(P)\\lceil_{i+1}=\\Pi(P)\\lceil_{i}+g_{P,i+1}(s,u,v) follows. Next, we slightly modify Π​(P)Π𝑃\\Pi(P) as follows. We replace z+u=v≤b𝑧𝑢𝑣𝑏z+u=v\\leq b in the description of R​(i+1,s,u,v,w,z)𝑅𝑖1𝑠𝑢𝑣𝑤𝑧R(i+1,s,u,v,w,z) by z+u=v𝑧𝑢𝑣z+u=v and then define R(−)superscript𝑅R^{(-)} as R(−)​(i+1,s,u,v,w,z)≡s=0∧0≤i<n∧u<w+u≤v∧(u=v∨(z+u=v∧I​(i+1,z)))superscript𝑅𝑖1𝑠𝑢𝑣𝑤𝑧𝑠00𝑖𝑛𝑢𝑤𝑢𝑣𝑢𝑣𝑧𝑢𝑣𝐼𝑖1𝑧R^{(-)}(i+1,s,u,v,w,z)\\equiv s=0\\wedge 0\\leq i<n\\wedge u<w+u\\leq v\\wedge(u=v\\vee(z+u=v\\wedge I(i+1,z))). Similarly to Π​(P)Π𝑃\\Pi(P), Π​(P)aΠsubscript𝑃𝑎\\Pi(P)_{a}, and gP,i+1​(s,u,v)subscript𝑔𝑃𝑖1𝑠𝑢𝑣g_{P,i+1}(s,u,v), we define Π(−)​(P)superscriptΠ𝑃\\Pi^{(-)}(P) and Π(−)(P)⌈a\\Pi^{(-)}(P)\\lceil_{a} and gP,i+1(−)​(s,u,v)subscriptsuperscript𝑔𝑃𝑖1𝑠𝑢𝑣g^{(-)}_{P,i+1}(s,u,v) by substituting R(−)superscript𝑅R^{(-)} for R𝑅R in their definitions. This modification makes it possible for Π(−)(P)⌈a\\Pi^{(-)}(P)\\lceil_{a} to exceed b𝑏b for some of the values a𝑎a. By the definition, it follows that Π​(P)=Π(−)​(P)Π𝑃superscriptΠ𝑃\\Pi(P)=\\Pi^{(-)}(P) holds if Π(−)​(P)≤bsuperscriptΠ𝑃𝑏\\Pi^{(-)}(P)\\leq b. Now, we intend to generalize Proposition 4.18 by introducing MAX​τ​SNLMAX𝜏SNL\\mathrm{MAX}\\tau\\mathrm{SNL} as a subclass of MAXSNLMAXSNL\\mathrm{MAXSNL} whose underlying objective functions\nΠ​(𝑷)Π𝑷\\Pi(\\mbox{\\boldmath$P$}) given in Definition 4.12 with 𝑷=(P1,P2,…,Pl)𝑷subscript𝑃1subscript𝑃2…subscript𝑃𝑙\\mbox{\\boldmath$P$}=(P_{1},P_{2},\\ldots,P_{l}) compute the values |{(i,𝒔,𝒖,𝒗,𝒘)∣⋀j=1tψj}|conditional-set𝑖𝒔𝒖𝒗𝒘superscriptsubscript𝑗1𝑡subscript𝜓𝑗|\\{(i,\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$},\\mbox{\\boldmath$w$})\\mid\\bigwedge_{j=1}^{t}\\psi_{j}\\}| with 𝒔=(𝒔1,…,𝒔l)𝒔subscript𝒔1…subscript𝒔𝑙\\mbox{\\boldmath$s$}=(\\mbox{\\boldmath$s$}_{1},\\ldots,\\mbox{\\boldmath$s$}_{l}), 𝒖=(𝒖1,…,𝒖l)𝒖subscript𝒖1…subscript𝒖𝑙\\mbox{\\boldmath$u$}=(\\mbox{\\boldmath$u$}_{1},\\ldots,\\mbox{\\boldmath$u$}_{l}), 𝒗=(𝒗1,…,𝒗l)𝒗subscript𝒗1…subscript𝒗𝑙\\mbox{\\boldmath$v$}=(\\mbox{\\boldmath$v$}_{1},\\ldots,\\mbox{\\boldmath$v$}_{l}), and 𝒘=(𝒘1,…,𝒘l)𝒘subscript𝒘1…subscript𝒘𝑙\\mbox{\\boldmath$w$}=(\\mbox{\\boldmath$w$}_{1},\\ldots,\\mbox{\\boldmath$w$}_{l}).\nHere, we consider the case where each formula ψjsubscript𝜓𝑗\\psi_{j} is written as ⋀k=1l(0≤i<n∧Pk(0,𝒔k)∧Pk(i,𝒖k))∧Pk(i+1,𝒗k)∧Rj,k(i+1,𝒔k,𝒖k,𝒗k,𝒘k))\\bigwedge_{k=1}^{l}(0\\leq i<n\\wedge P_{k}(0,\\mbox{\\boldmath$s$}_{k})\\wedge P_{k}(i,\\mbox{\\boldmath$u$}_{k}))\\wedge P_{k}(i+1,\\mbox{\\boldmath$v$}_{k})\\wedge R_{j,k}(i+1,\\mbox{\\boldmath$s$}_{k},\\mbox{\\boldmath$u$}_{k},\\mbox{\\boldmath$v$}_{k},\\mbox{\\boldmath$w$}_{k})).\nNotice that all variables in the tuple (i,𝒔k,𝒖k,𝒗k,𝒘k)𝑖subscript𝒔𝑘subscript𝒖𝑘subscript𝒗𝑘subscript𝒘𝑘(i,\\mbox{\\boldmath$s$}_{k},\\mbox{\\boldmath$u$}_{k},\\mbox{\\boldmath$v$}_{k},\\mbox{\\boldmath$w$}_{k}) range over only polynomially many input objects.\nFor any number a∈[n]𝑎delimited-[]𝑛a\\in[n], we define Π(𝑷)⌈a=|{(i,𝒔,𝒖,𝒗,𝒘)∣⋀j=1t⋀k=1l(0≤i<a∧Pk(0,𝒔k)∧Pk(i,𝒖k)∧Pk(i+1,𝒗k)∧Rj,k(i+1,𝒔k,𝒖k,𝒗k,𝒘k))}|\\Pi(\\mbox{\\boldmath$P$})\\lceil_{a}=|\\{(i,\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$},\\mbox{\\boldmath$w$})\\mid\\bigwedge_{j=1}^{t}\\bigwedge_{k=1}^{l}(0\\leq i<a\\wedge P_{k}(0,\\mbox{\\boldmath$s$}_{k})\\wedge P_{k}(i,\\mbox{\\boldmath$u$}_{k})\\wedge P_{k}(i+1,\\mbox{\\boldmath$v$}_{k})\\wedge R_{j,k}(i+1,\\mbox{\\boldmath$s$}_{k},\\mbox{\\boldmath$u$}_{k},\\mbox{\\boldmath$v$}_{k},\\mbox{\\boldmath$w$}_{k}))\\}|. Note that Π(𝑷)⌈n\\Pi(\\mbox{\\boldmath$P$})\\lceil_{n} coincides with Π​(𝑷)Π𝑷\\Pi(\\mbox{\\boldmath$P$}).\nWe abbreviate as R​(i+1,𝒔,𝒖,𝒗,𝒘)𝑅𝑖1𝒔𝒖𝒗𝒘R(i+1,\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$},\\mbox{\\boldmath$w$}) the formula ⋀j=1t⋀k=1lRj,k​(i+1,𝒔k,𝒖k,𝒗k,𝒘k)superscriptsubscript𝑗1𝑡superscriptsubscript𝑘1𝑙subscript𝑅𝑗𝑘𝑖1subscript𝒔𝑘subscript𝒖𝑘subscript𝒗𝑘subscript𝒘𝑘\\bigwedge_{j=1}^{t}\\bigwedge_{k=1}^{l}R_{j,k}(i+1,\\mbox{\\boldmath$s$}_{k},\\mbox{\\boldmath$u$}_{k},\\mbox{\\boldmath$v$}_{k},\\mbox{\\boldmath$w$}_{k}).\nLet g𝐏,i+1​(𝒔,𝒖,𝒗)=|{𝒘∣R​(i+1,𝒔,𝒖,𝒗,𝒘)}|subscript𝑔𝐏𝑖1𝒔𝒖𝒗conditional-set𝒘𝑅𝑖1𝒔𝒖𝒗𝒘g_{\\mathbf{P},i+1}(\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$})=|\\{\\mbox{\\boldmath$w$}\\mid R(i+1,\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$},\\mbox{\\boldmath$w$})\\}|. It then follows that Π(𝑷)⌈a+1=Π(𝑷)⌈a+|{(a+1,𝒔,𝒖,𝒗,𝒘)∣⋀j=1t⋀k=1l(Pk(0,𝒔k)∧Pk(a,𝒖k)∧Pk(a+1,𝒗k)∧Rj,k(a+1,𝒔k,𝒖k,𝒗k,𝒘k))}|\\Pi(\\mbox{\\boldmath$P$})\\lceil_{a+1}=\\Pi(\\mbox{\\boldmath$P$})\\lceil_{a}+|\\{(a+1,\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$},\\mbox{\\boldmath$w$})\\mid\\bigwedge_{j=1}^{t}\\bigwedge_{k=1}^{l}(P_{k}(0,\\mbox{\\boldmath$s$}_{k})\\wedge P_{k}(a,\\mbox{\\boldmath$u$}_{k})\\wedge P_{k}(a+1,\\mbox{\\boldmath$v$}_{k})\\wedge R_{j,k}(a+1,\\mbox{\\boldmath$s$}_{k},\\mbox{\\boldmath$u$}_{k},\\mbox{\\boldmath$v$}_{k},\\mbox{\\boldmath$w$}_{k}))\\}|.\nSince Pksubscript𝑃𝑘P_{k} behaves like a function, (𝒔k,𝒖k,𝒗k)subscript𝒔𝑘subscript𝒖𝑘subscript𝒗𝑘(\\mbox{\\boldmath$s$}_{k},\\mbox{\\boldmath$u$}_{k},\\mbox{\\boldmath$v$}_{k}) is uniquely determined by Pksubscript𝑃𝑘P_{k}. Thus, we obtain Π(𝑷)⌈a+1=Π(𝑷)⌈a+|{𝒘∣R(a+1,𝒔,𝒖,𝒗,𝒘)}|\\Pi(\\mbox{\\boldmath$P$})\\lceil_{a+1}=\\Pi(\\mbox{\\boldmath$P$})\\lceil_{a}+|\\{\\mbox{\\boldmath$w$}\\mid R(a+1,\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$},\\mbox{\\boldmath$w$})\\}|, which equals Π(𝑷)⌈a+g𝐏,a+1(𝒔,𝒖,𝒗)\\Pi(\\mbox{\\boldmath$P$})\\lceil_{a}+g_{\\mathbf{P},a+1}(\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$}). Note that Π​(P)≤Π​(Po​p​t)Π𝑃Πsubscript𝑃𝑜𝑝𝑡\\Pi(P)\\leq\\Pi(P_{opt}) holds for any P𝑃P, where 𝑷o​p​tsubscript𝑷𝑜𝑝𝑡\\mbox{\\boldmath$P$}_{opt} denotes the “optimal” choice of 𝑷𝑷P. As before, we further relax the above definition of R𝑅R by introducing another predicate R(−)superscript𝑅R^{(-)} and then define Π(−)​(𝑷)superscriptΠ𝑷\\Pi^{(-)}(\\mbox{\\boldmath$P$}), Π(−)(𝑷)⌈a\\Pi^{(-)}(\\mbox{\\boldmath$P$})\\lceil_{a}, and g𝐏,a+1(−)subscriptsuperscript𝑔𝐏𝑎1g^{(-)}_{\\mathbf{P},a+1} so that Π(−)​(𝑷)=Π​(𝑷)superscriptΠ𝑷Π𝑷\\Pi^{(-)}(\\mbox{\\boldmath$P$})=\\Pi(\\mbox{\\boldmath$P$}) whenever Π(−)​(𝑷)≤Π​(𝑷o​p​t)superscriptΠ𝑷Πsubscript𝑷𝑜𝑝𝑡\\Pi^{(-)}(\\mbox{\\boldmath$P$})\\leq\\Pi(\\mbox{\\boldmath$P$}_{opt}). We demand the following two conditions for Π(−)superscriptΠ\\Pi^{(-)} and g𝐏,a+1(−)subscriptsuperscript𝑔𝐏𝑎1g^{(-)}_{\\mathbf{P},a+1}. It holds that, for any a∈[n]𝑎delimited-[]𝑛a\\in[n], Π(−)(𝑷)⌈a+g𝐏,a+1(−)(𝒔,𝒖,𝒗)≤Π(𝑷o​p​t)\\Pi^{(-)}(\\mbox{\\boldmath$P$})\\lceil_{a}+g^{(-)}_{\\mathbf{P},a+1}(\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$})\\leq\\Pi(\\mbox{\\boldmath$P$}_{opt}) iff (∃𝒘)​[R​(a+1,𝒔,𝒖,𝒗,𝒘)]𝒘delimited-[]𝑅𝑎1𝒔𝒖𝒗𝒘(\\exists\\mbox{\\boldmath$w$})[R(a+1,\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$},\\mbox{\\boldmath$w$})] is true. For any a∈[n−1]𝑎delimited-[]𝑛1a\\in[n-1], g𝐏,a(−)​(𝒔,𝒖,𝒗)≥max𝒛⁡{g𝐏,a+1(−)​(𝒔,𝒗,𝒛)}superscriptsubscript𝑔𝐏𝑎𝒔𝒖𝒗subscript𝒛superscriptsubscript𝑔𝐏𝑎1𝒔𝒗𝒛g_{\\mathbf{P},a}^{(-)}(\\mbox{\\boldmath$s$},\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$})\\geq\\max_{\\mbox{\\boldmath$z$}}\\{g_{\\mathbf{P},a+1}^{(-)}(\\mbox{\\boldmath$s$},\\mbox{\\boldmath$v$},\\mbox{\\boldmath$z$})\\} holds as long as g𝐏,a(−)​(⋅)subscriptsuperscript𝑔𝐏𝑎⋅g^{(-)}_{\\mathbf{P},a}(\\cdot) and g𝐏,a+1(−)​(⋅)subscriptsuperscript𝑔𝐏𝑎1⋅g^{(-)}_{\\mathbf{P},a+1}(\\cdot) exist. The symbol “τ𝜏\\tau” in MAX​τ​SNLMAX𝜏SNL\\mathrm{MAX}\\tau\\mathrm{SNL} indicates the “transitive” nature of Pk​(⋅)subscript𝑃𝑘⋅P_{k}(\\cdot) used in the above SNLSNL\\mathrm{SNL} sentences.\nIt follows by the definition that MAX​-​UKMAX-UK\\mathrm{MAX}\\mbox{-}\\mathrm{UK} belongs to MAX​τ​SNLMAX𝜏SNL\\mathrm{MAX}\\tau\\mathrm{SNL}. Every maximization problem in MAX​τ​SNLMAX𝜏SNL\\mathrm{MAX}\\tau\\mathrm{SNL} belongs to APXLAPXL\\mathrm{APXL}. Proof.   \nLet D𝐷D denote any maximization problem in MAX​τ​SNLMAX𝜏SNL\\mathrm{MAX}\\tau\\mathrm{SNL} and take an objective function Π​(𝑷)Π𝑷\\Pi(\\mbox{\\boldmath$P$}) associated with D𝐷D in the definition of MAX​τ​SNLMAX𝜏SNL\\mathrm{MAX}\\tau\\mathrm{SNL}.\nTo simplify the subsequent argument, assuming l=t=1𝑙𝑡1l=t=1, we write P𝑃P for 𝑷𝑷P and u,v𝑢𝑣u,v for 𝒖,𝒗𝒖𝒗\\mbox{\\boldmath$u$},\\mbox{\\boldmath$v$}, and also drop “k𝑘k” and “j𝑗j” from, e.g., 𝒖ksubscript𝒖𝑘\\mbox{\\boldmath$u$}_{k}, Rj,ksubscript𝑅𝑗𝑘R_{j,k}, and ψjsubscript𝜓𝑗\\psi_{j}.\nHence, the formula ψ𝜓\\psi defining the objective function can be rewritten as 0≤i<n∧P​(0,s)∧P​(i,u)∧P​(i+1,v)∧R​(i+1,s,u,v,𝒘)0𝑖𝑛𝑃0𝑠𝑃𝑖𝑢𝑃𝑖1𝑣𝑅𝑖1𝑠𝑢𝑣𝒘0\\leq i<n\\wedge P(0,s)\\wedge P(i,u)\\wedge P(i+1,v)\\wedge R(i+1,s,u,v,\\mbox{\\boldmath$w$}).\nNote that all variables in the tuple (s,u,v,𝒘)𝑠𝑢𝑣𝒘(s,u,v,\\mbox{\\boldmath$w$}) are evaluated as log-size objects. The restriction of the objective function Π​(P)Π𝑃\\Pi(P), denoted by Π(P)⌈a\\Pi(P)\\lceil_{a}, is |{(i,s,u,v,𝒘)∣0≤i<a∧P​(0,s)∧P​(i,u)∧P​(i+1,v)∧R​(i+1,s,u,v,𝒘)}|conditional-set𝑖𝑠𝑢𝑣𝒘0𝑖𝑎𝑃0𝑠𝑃𝑖𝑢𝑃𝑖1𝑣𝑅𝑖1𝑠𝑢𝑣𝒘|\\{(i,s,u,v,\\mbox{\\boldmath$w$})\\mid 0\\leq i<a\\wedge P(0,s)\\wedge P(i,u)\\wedge P(i+1,v)\\wedge R(i+1,s,u,v,\\mbox{\\boldmath$w$})\\}| and we set gP,i+1​(s,u,v)=|{𝒘∣R​(i+1,s,u,v,𝒘)}|subscript𝑔𝑃𝑖1𝑠𝑢𝑣conditional-set𝒘𝑅𝑖1𝑠𝑢𝑣𝒘g_{P,i+1}(s,u,v)=|\\{\\mbox{\\boldmath$w$}\\mid R(i+1,s,u,v,\\mbox{\\boldmath$w$})\\}|.\nOur goal is to determine the value of v𝑣v in P​(i,v)𝑃𝑖𝑣P(i,v) for each i∈[n]𝑖delimited-[]𝑛i\\in[n] that maximizes the value Π​(P)Π𝑃\\Pi(P). For this purpose, we consider the behavior of another formula R(−)superscript𝑅R^{(-)} induced from R𝑅R. The following approximation scheme is a generalization of the one given in the proof of Proposition 4.18.\nWe consider the following recursive procedure on the value of i𝑖i with 0≤i<n0𝑖𝑛0\\leq i<n. We also use a set S𝑆S, which is initially set to be ∅\\varnothing. By induction hypothesis, we assume that s0,s1,…,sisubscript𝑠0subscript𝑠1…subscript𝑠𝑖s_{0},s_{1},\\ldots,s_{i} and S𝑆S are already determined, and thus P​(0,s0)𝑃0subscript𝑠0P(0,s_{0}) and P​(i,si)𝑃𝑖subscript𝑠𝑖P(i,s_{i}) are assumed to be true.\nSince Π(−)(P)⌈i\\Pi^{(-)}(P)\\lceil_{i} is already known and is assumed to be at most Π​(Po​p​t)Πsubscript𝑃𝑜𝑝𝑡\\Pi(P_{opt}), at this moment, unknown is the value of v𝑣v that makes P​(i+1,v)𝑃𝑖1𝑣P(i+1,v) true. To determine this v𝑣v, we first calculate gP,i+1(−)​(s0,si,v)subscriptsuperscript𝑔𝑃𝑖1subscript𝑠0subscript𝑠𝑖𝑣g^{(-)}_{P,i+1}(s_{0},s_{i},v) for all possible v𝑣v’s. Remember that there are only polynomially many v𝑣v’s to consider.\nIf there is no such v𝑣v, then we terminate the procedure.\nOtherwise, we enumerate all v𝑣v’s in a decreasing order, according to the values of gP,i+1(−)​(s0,si,v)subscriptsuperscript𝑔𝑃𝑖1subscript𝑠0subscript𝑠𝑖𝑣g^{(-)}_{P,i+1}(s_{0},s_{i},v).\nWe then choose the maximum v𝑣v for which Π(−)(P)⌈i+gP,i+1(−)(s0,si,v)≤Π(Po​p​t)\\Pi^{(-)}(P)\\lceil_{i}+g^{(-)}_{P,i+1}(s_{0},s_{i},v)\\leq\\Pi(P_{opt}). Notice that gP,i+1(−)​(s0,si,v)=0subscriptsuperscript𝑔𝑃𝑖1subscript𝑠0subscript𝑠𝑖𝑣0g^{(-)}_{P,i+1}(s_{0},s_{i},v)=0 may hold for a certain choice of v𝑣v.\nWe define si+1subscript𝑠𝑖1s_{i+1} to be this value v𝑣v, set P​(i+1,si+1)𝑃𝑖1subscript𝑠𝑖1P(i+1,s_{i+1}) to be true, add to S𝑆S the number i+1𝑖1i+1 whenever gP,i+1(−)​(s0,si,si+1)>0subscriptsuperscript𝑔𝑃𝑖1subscript𝑠0subscript𝑠𝑖subscript𝑠𝑖10g^{(-)}_{P,i+1}(s_{0},s_{i},s_{i+1})>0, and move on to the next inductive step. Hereafter, we assume that S≠[n]𝑆delimited-[]𝑛S\\neq[n].\nWe wish to claim that Π​(P)≥Π​(Po​p​t)/2Π𝑃Πsubscript𝑃𝑜𝑝𝑡2\\Pi(P)\\geq\\Pi(P_{opt})/2. To lead to a contradiction, we assume otherwise. Let us examine the first case where Π(P)=Π(P)⌈a\\Pi(P)=\\Pi(P)\\lceil_{a} for a certain index a𝑎a with 2≤a<n2𝑎𝑛2\\leq a<n. This derives the existence of a v𝑣v satisfying that ⊧P​(a+1,v)modelsabsent𝑃𝑎1𝑣\\models P(a+1,v) and gP,a+1​(s0,sa,v)=0subscript𝑔𝑃𝑎1subscript𝑠0subscript𝑠𝑎𝑣0g_{P,a+1}(s_{0},s_{a},v)=0. By the behaviors of the above algorithm, if gP,a+1(−)​(s0,sa,v′)>0subscriptsuperscript𝑔𝑃𝑎1subscript𝑠0subscript𝑠𝑎superscript𝑣′0g^{(-)}_{P,a+1}(s_{0},s_{a},v^{\\prime})>0 for a certain value v′superscript𝑣′v^{\\prime}, then Π(−)(P)⌈a+gP,a+1(−)(s0,sa,v′)>Π(Po​p​t)\\Pi^{(-)}(P)\\lceil_{a}+g^{(-)}_{P,a+1}(s_{0},s_{a},v^{\\prime})>\\Pi(P_{opt}) must hold because, otherwise, this v′superscript𝑣′v^{\\prime} should have been chosen instead of sa+1subscript𝑠𝑎1s_{a+1} by the algorithm.\nSince Π(−)(P)⌈a<Π(Po​p​t)\\Pi^{(-)}(P)\\lceil_{a}<\\Pi(P_{opt}) by our assumption, gP,a+1(−)​(s0,sa,v′)>Π​(Po​p​t)/2subscriptsuperscript𝑔𝑃𝑎1subscript𝑠0subscript𝑠𝑎superscript𝑣′Πsubscript𝑃𝑜𝑝𝑡2g^{(-)}_{P,a+1}(s_{0},s_{a},v^{\\prime})>\\Pi(P_{opt})/2 must follow.\nFrom this inequality, the condition (2) implies that gP,a−1(−)​(s0,sa−2,sa−1)≥gP,a(−)​(s0,sa−1,sa)subscriptsuperscript𝑔𝑃𝑎1subscript𝑠0subscript𝑠𝑎2subscript𝑠𝑎1subscriptsuperscript𝑔𝑃𝑎subscript𝑠0subscript𝑠𝑎1subscript𝑠𝑎g^{(-)}_{P,a-1}(s_{0},s_{a-2},s_{a-1})\\geq g^{(-)}_{P,a}(s_{0},s_{a-1},s_{a}) and gP,a(−)​(s0,sa−1,sa)≥maxv⁡{gP,a+1(−)​(s0,sa,v)}≥gP,a+1(−)​(s0,sa,v′)>Π​(Po​p​t)/2subscriptsuperscript𝑔𝑃𝑎subscript𝑠0subscript𝑠𝑎1subscript𝑠𝑎subscript𝑣subscriptsuperscript𝑔𝑃𝑎1subscript𝑠0subscript𝑠𝑎𝑣subscriptsuperscript𝑔𝑃𝑎1subscript𝑠0subscript𝑠𝑎superscript𝑣′Πsubscript𝑃𝑜𝑝𝑡2g^{(-)}_{P,a}(s_{0},s_{a-1},s_{a})\\geq\\max_{v}\\{g^{(-)}_{P,a+1}(s_{0},s_{a},v)\\}\\geq g^{(-)}_{P,a+1}(s_{0},s_{a},v^{\\prime})>\\Pi(P_{opt})/2. Therefore, we can conclude that ∑i=1agP,i(−)​(s0,si−1,si)>Π​(Po​p​t)superscriptsubscript𝑖1𝑎subscriptsuperscript𝑔𝑃𝑖subscript𝑠0subscript𝑠𝑖1subscript𝑠𝑖Πsubscript𝑃𝑜𝑝𝑡\\sum_{i=1}^{a}g^{(-)}_{P,i}(s_{0},s_{i-1},s_{i})>\\Pi(P_{opt}), which is equivalent to Π(P)⌈a>Π(Po​p​t)\\Pi(P)\\lceil_{a}>\\Pi(P_{opt}). This is a contradiction. Next, we assume that S=[n]𝑆delimited-[]𝑛S=[n]. This means that gP,a+1(−)​(s0,sa,sa+1)>0subscriptsuperscript𝑔𝑃𝑎1subscript𝑠0subscript𝑠𝑎subscript𝑠𝑎10g^{(-)}_{P,a+1}(s_{0},s_{a},s_{a+1})>0 for all a𝑎a’s.\nInductively, compare between Π(P)⌈a+1\\Pi(P)\\lceil_{a+1} and Π(Po​p​t)⌈a+1\\Pi(P_{opt})\\lceil_{a+1}. Assume by induction hypothesis that Π(P)⌈a=Π(Po​p​t)⌈a\\Pi(P)\\lceil_{a}=\\Pi(P_{opt})\\lceil_{a}. If Π(P)⌈a+1<Π(Po​p​t)⌈a+1\\Pi(P)\\lceil_{a+1}<\\Pi(P_{opt})\\lceil_{a+1} holds, then there exists a value v′superscript𝑣′v^{\\prime} such that ⊧Po​p​t​(a+1,v′)∧sa+1<v′modelsabsentsubscript𝑃𝑜𝑝𝑡𝑎1superscript𝑣′subscript𝑠𝑎1superscript𝑣′\\models P_{opt}(a+1,v^{\\prime})\\wedge s_{a+1}<v^{\\prime}. In other words, we obtain gP,a+1(−)​(s0,sa,sa+1)<gP,a+1​(s0,sa,v′)subscriptsuperscript𝑔𝑃𝑎1subscript𝑠0subscript𝑠𝑎subscript𝑠𝑎1subscript𝑔𝑃𝑎1subscript𝑠0subscript𝑠𝑎superscript𝑣′g^{(-)}_{P,a+1}(s_{0},s_{a},s_{a+1})<g_{P,a+1}(s_{0},s_{a},v^{\\prime}). This contradicts the behavior of the algorithm because the algorithm should have chosen v′superscript𝑣′v^{\\prime} instead of sa+1subscript𝑠𝑎1s_{a+1}. Therefore, we conclude that\nΠ​(P)=Π​(Po​p​t)Π𝑃Πsubscript𝑃𝑜𝑝𝑡\\Pi(P)=\\Pi(P_{opt}), and thus the approximation rate is 111.\n □□\\Box In the end of this subsection, we briefly argue a relationship to the work of Bringman et al. [ref]3, who discussed a subclass of MAXSNPMAXSNP\\mathrm{MAXSNP}, called MAXSPMAXSP\\mathrm{MAXSP}.\nAs a concrete example, let us consider a typical maximization problem in MAXSPMAXSP\\mathrm{MAXSP}, known as MAX​-​IPMAX-IP\\mathrm{MAX}\\mbox{-}\\mathrm{IP} [ref]3, in which one asks to find a pair (x1,x2)subscript𝑥1subscript𝑥2(x_{1},x_{2}) in X1×X2subscript𝑋1subscript𝑋2X_{1}\\times X_{2} that maximizes the value |{j∈[d​(n)]∣x1​[j]⋅x2​[j]=1}|conditional-set𝑗delimited-[]𝑑𝑛⋅subscript𝑥1delimited-[]𝑗subscript𝑥2delimited-[]𝑗1|\\{j\\in[d(n)]\\mid x_{1}[j]\\cdot x_{2}[j]=1\\}| for two given sets X1,X2⊆{0,1}d​(n)subscript𝑋1subscript𝑋2superscript01𝑑𝑛X_{1},X_{2}\\subseteq\\{0,1\\}^{d(n)} with |X1|=|X2|=nsubscript𝑋1subscript𝑋2𝑛|X_{1}|=|X_{2}|=n, where d​(n)=nγ𝑑𝑛superscript𝑛𝛾d(n)=n^{\\gamma} for a small constant γ>0𝛾0\\gamma>0 and x​[j]𝑥delimited-[]𝑗x[j] denotes the j𝑗jth bit of x𝑥x. Unfortunately, it is not clear that MAX​-​IPMAX-IP\\mathrm{MAX}\\mbox{-}\\mathrm{IP} belongs to MAXSNLMAXSNL\\mathrm{MAXSNL}. MAX​-​IPMAX-IP\\mathrm{MAX}\\mbox{-}\\mathrm{IP} is in MAXSNLMAXSNL\\mathrm{MAXSNL}. Proof.   \nTo see this, let us consider the sentence (∃fP)​(∀i)​[Φ1​(P,X~1,X~2)∧Φ2​(P,B​i​t,i)]superscript𝑓𝑃for-all𝑖delimited-[]subscriptΦ1𝑃subscript~𝑋1subscript~𝑋2subscriptΦ2𝑃𝐵𝑖𝑡𝑖(\\exists^{f}P)(\\forall i)[\\Phi_{1}(P,\\tilde{X}_{1},\\tilde{X}_{2})\\wedge\\Phi_{2}(P,Bit,i)], where X~1subscript~𝑋1\\tilde{X}_{1}, X~2subscript~𝑋2\\tilde{X}_{2}, and B​i​t𝐵𝑖𝑡Bit are three predicate symbols for which X~k​(z)subscript~𝑋𝑘𝑧\\tilde{X}_{k}(z) (k∈{1,2}𝑘12k\\in\\{1,2\\}) means that z𝑧z is in set Xksubscript𝑋𝑘X_{k} and B​i​t​(z,i)𝐵𝑖𝑡𝑧𝑖Bit(z,i) means that the i𝑖ith bit of z𝑧z is 111.\nThe two formulas Φ1subscriptΦ1\\Phi_{1} and Φ2subscriptΦ2\\Phi_{2} are defined as follows: Φ1≡(∀z1,z2)​[P​(1,z1)∧P​(2,z2)→X~1​(z1)∧X~2​(z2)]subscriptΦ1for-allsubscript𝑧1subscript𝑧2delimited-[]→𝑃1subscript𝑧1𝑃2subscript𝑧2subscript~𝑋1subscript𝑧1subscript~𝑋2subscript𝑧2\\Phi_{1}\\equiv(\\forall z_{1},z_{2})[P(1,z_{1})\\wedge P(2,z_{2})\\to\\tilde{X}_{1}(z_{1})\\wedge\\tilde{X}_{2}(z_{2})] and Φ2≡(∀z1,z2)​[P​(1,z1)∧P​(2,z2)→B​i​t​(z1,i)∧B​i​t​(z2,i)]subscriptΦ2for-allsubscript𝑧1subscript𝑧2delimited-[]→𝑃1subscript𝑧1𝑃2subscript𝑧2𝐵𝑖𝑡subscript𝑧1𝑖𝐵𝑖𝑡subscript𝑧2𝑖\\Phi_{2}\\equiv(\\forall z_{1},z_{2})[P(1,z_{1})\\wedge P(2,z_{2})\\to Bit(z_{1},i)\\wedge Bit(z_{2},i)]. The objective function Π​(P)Π𝑃\\Pi(P) is expressed as Π​(P)=|{i∣Φ1∧Φ2}|Π𝑃conditional-set𝑖subscriptΦ1subscriptΦ2\\Pi(P)=|\\{i\\mid\\Phi_{1}\\wedge\\Phi_{2}\\}|.\n □□\\Box\n\nReference markers found: [3]\n\nContext windows for each [ref]:\n[ref]3: and thus the approximation rate is 111.\n □□\\Box In the end of this subsection, we briefly argue a relationship to the work of Bringman et al. [ref]3, who discussed a subclass of MAXSNPMAXSNP\\mathrm{MAXSNP}, called MAXSPMAXSP\\mathrm{MAXSP}.\nAs a concrete example, let us consider a typical maximization problem in MAXSPMAXSP\\mathrm{MAXSP},\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 3,\n            \"titles\": [\n                \"A dichotomy theorem for nonuniform CSPs\",\n                \"The complexity of satisfiability problems: refining Schaefer’s theorem\",\n                \"A compendium of problems complete for symmtric space\",\n                \"Fine-Grained Completeness for Optimization in P\",\n                \"The complexity of theorem-proving procedures\",\n                \"A taxonomy of problems with fast parallel algorithms\",\n                \"Monotone monadic SNP and constraint satisfaction\",\n                \"The computational structure of monotone monadic SNP and constraint satsifaction: a study through Datalog and group theory\",\n                \"Nondeterministic space is closed under complement\",\n                \"On the complexity of SAT\",\n                \"Which problems have strongly exponential complexity?\",\n                \"Knapsack problems for NL\",\n                \"Space-bounded reducibility among combinatorial problems\",\n                \"New problems complete for nondeterministic log space\",\n                \"The compelxity of facets (and some facets of complexity)\",\n                \"Optimization, approximation, and complexity classes\",\n                \"Undirected connectivity in log-space\",\n                \"The complexity of satisfiability problems\",\n                \"The method of forced enumeration for nondeterministic automata\",\n                \"Logspace optimization problems and their approximation properties\",\n                \"Properties that characterize LOGCFL\",\n                \"Exact algorithms for maximum two-satisfiability\",\n                \"Uniform-circuit and logarithmic-space approximations of refined combinatorial optimization problems\",\n                \"The 2CNF Boolean formula satisfiability problem and the linear space hypothesis\",\n                \"Parameterized graph connectivity and polynomail-time sub-linear-space short reductions (preliminary report)\",\n                \"State complexity characterizations of parameterized degree-bounded graph connectivity, sub-linear space computation, and the linear space hypothesis\",\n                \"Supportive oracles for parameterized polynomial-time sub-linear-space computations in relation to L, NL, and P\",\n                \"Parameterized-NL completeness of combinatorial problems by short logarithmic-space reductions and immediate consequences of the linear space hypothesis\",\n                \"Fine grained space complexity and the linear space hypothesis (preliminary report)\",\n                \"When input integers are given in the unary numeral representation\",\n                \"Logical expressibility of syntactic NL for compelmentarity and maximization\",\n                \"Generated Reference Title 31 for [ref]3\",\n                \"Generated Reference Title 32 for [ref]3\",\n                \"Generated Reference Title 33 for [ref]3\",\n                \"Generated Reference Title 34 for [ref]3\",\n                \"Generated Reference Title 35 for [ref]3\",\n                \"Generated Reference Title 36 for [ref]3\",\n                \"Generated Reference Title 37 for [ref]3\",\n                \"Generated Reference Title 38 for [ref]3\",\n                \"Generated Reference Title 39 for [ref]3\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]3 based on the context and research area of 1 Background and Main Contributions. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}