{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: On Large Language Models in Mission-Critical IT Governance: Are We Ready Yet?\n\nPaper Abstract: \n\nPaper Section Text:\nIn this section, we discuss the threats to the validity of our case study. We categorized the threats in Construct, Internal, External, and Conclusion validity following established guidelines  and previous similar survey works [ref]17. Construct Validity concerns how our measurements reflect what we claim to measure . Our design choices, measurement process, and data filtering may impact our results. To address this threat, we based our choice on past studies and well-established guidelines in designing our methodology  . Moreover, threats to the construct validity may arise due to the behavior of both participants and researchers conducting the study. The participants may act differently merely because they know they are being studied . The invitation email mentioned the aim of the study to avoid hypothesis guessing and evaluation apprehension risks. The subjects were also invited to reply in light of their personal experiences. They had been assured that the questionnaire was anonymous and the identity of the persons would not be considered while considering the data. On the issue of the researcher’s expectations, which may involve bias either wittingly or unwittingly due to the expected outcome of the research, we used several researchers who would act as both internal and external reviewers of the questionnaire. This reduced this potential threat to a minimum. Internal Validity is the extent to which an experimental design accurately identifies a cause-and-effect relationship between variables . Maturation and instrumentation pose significant threats to the internal validity of this study. Instrumentation refers to the potential impact of the tools or materials used during the study, in this case, the questionnaire. A poorly designed questionnaire can compromise the reliability of the study’s results .\nTo address this threat, we designed the questionnaire with only direct questions, minimizing the need for interpretation and reducing the risk of misunderstandings that could lead to irrelevant answers. Additionally, the questionnaire underwent several rounds of validation (two internal and one external) and a pilot test to identify any inconsistencies or potential misunderstandings before the survey was conducted. Maturation refers to the possibility that participants’ responses may change over time, mainly if the questionnaire is too lengthy . Therefore, we designed the questionnaire to be completed within a reasonable timeframe. During the pilot study, we found an average completion time of about 15 minutes. An early indication that this threat was minimized is that all participants finished the survey. Even though the questionnaire included many open-ended questions, the responses were detailed and thoughtful, indicating that participants remained engaged throughout the survey. Participants who did not answer specific questions were consistent with their prior responses, suggesting a clear understanding of the content. External Validity concerns how the research elements (subjects, artifacts) represent actual elements . Our sample size, though not as large as another similar study, is justified by the niche context the company operates in and is still smaller than those reflecting all possible contexts of IT MCS practitioners. We tried to mitigate this threat by increasing the diversity of the participants in organizational size, expertise, and experience and geographical location. Nonetheless, due to the referenced process and regulations being primarily international, our findings may represent other countries, though considering the implementation allowance the international laws grant to each nation. Given these limitations, we plan to survey with overseas partners to synthesize results across time and the development of a more robust, empirically supported understanding. Another potential threat is the lack of control over the sample selection, which may cause the sample to be biased toward individuals who are very interested or biased toward the subject under study. This may, hence, outweigh the positive or negative perception results. Nevertheless, we found that a considerable proportion of participants at baseline mainly had cautious positive perceptions, so any negative bias is probably slight. Conclusion Validity focuses on how we draw conclusions based on the design of the case study, methodology, and observed results .\nIn the context of a survey, the main threat to conclusion validity originates in the coding activity itself, which is variable as a human creative process [ref]17. As discussed in the questionnaire description, due to a lack of answers, we did not proceed with coding and cited the relevant answers directly as supporting arguments in the discussions.\n\nReference markers found: [17]\n\nContext windows for each [ref]:\n[ref]17: threats to the validity of our case study. We categorized the threats in Construct, Internal, External, and Conclusion validity following established guidelines  and previous similar survey works [ref]17. Construct Validity concerns how our measurements reflect what we claim to measure . Our design choices, measurement process, and data filtering may impact our results. To address this\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 17,\n            \"titles\": [\n                \"6GSoft: Software for Edge-to-Cloud Continuum\",\n                \"Mathematical theory of enigma machine\",\n                \"Computing Machinery and Intelligence\",\n                \"Leveraging large language models for preliminary security risk analysis: A mission-critical case study\",\n                \"Validate: A deep dive into vulnerability prediction datasets\",\n                \"Can we trust the default vulnerabilities severity?\",\n                \"Common criteria for information technology security evaluation, part 5: Pre-defined packages of security requirements, cc:2022 revision 1\",\n                \"PCM-ANS TI-002: Security Standard for Military EAD Systems/Networks\",\n                \"Information technology security evaluation criteria (itsec) – provisional evaluation criteria: Document com(90) 314\",\n                \"It governance framework: Overview & best practices\",\n                \"Beyond words: On large language models actionability in mission-critical risk analysis\",\n                \"Mission-critical development with open source software: Lessons learned\",\n                \"ISO/IEC 38500:2015 Information technology – Governance of IT for the organization\",\n                \"COBIT 2019 Framework: Introduction and Methodology\",\n                \"Experimentation in Software Engineering\",\n                \"Guidelines for conducting and reporting case study research in software engineering\",\n                \"The goal question metric approach\",\n                \"The practitioners’ point of view on the concept of technical debt and its causes and consequences: a design for a global family of industrial surveys and its first results from brazil\",\n                \"Innovation and diffusion of technology: A human process.\",\n                \"Using big data for co-innovation processes: Mapping the field of data-driven innovation, proposing theoretical developments and providing a research agenda\",\n                \"Practical relevance of software engineering research: synthesizing the community’s voice\",\n                \"Software engineering of safety-critical systems: Themes from practitioners\",\n                \"Developers’ perception of github actions: A survey analysis\",\n                \"Early career developers’ perceptions of code understandability. a study of complexity metrics\",\n                \"Software developer perceptions about software project failure: a case study\",\n                \"On the origin and nature of law\",\n                \"Proposal for a regulation of the european parliament and of the council laying down harmonised rules on artificial intelligence (artificial intelligence act) and amending certain union legislative acts\",\n                \"Aiming for truth, fairness, and equity in your company’s use of ai\",\n                \"Algorithmic accountability act of 2022\",\n                \"National artificial intelligence initiative act of 2020\",\n                \"Blueprint for an ai bill of rights: Making automated systems work for the american people\",\n                \"The value of it governance\",\n                \"Acm publications policy on research involving human participants and subjects\",\n                \"A technique for the measurement of attitudes.\",\n                \"Techniques and procedures for developing grounded theory\",\n                \"Measuring and monitoring technical debt advances in computers\",\n                \"Draft ai law\",\n                \"Ai framework (2020-2025)\",\n                \"2024 resolution on safe, secure, and trustworthy ai\",\n                \"Large Language Models for Software Engineering: Survey and Open Problems\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]17 based on the context and research area of On Large Language Models in Mission-Critical IT Governance: Are We Ready Yet?. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}