{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Principles and Guidelines for Evaluating Social Robot Navigation Algorithms\n\nPaper Abstract: \n\nPaper Section Text:\nIt is often difficult for an agent to know exactly what other agents, especially humans, need to achieve, or what they feel and like, and social norms that could guide us are often not verbalized. To operationalize these concerns, we identified principles of social navigation that can be used to evaluate the quality of social behavior, including (1) safety, (2) comfort, (3) legibility, (4) politeness, (5) social competency, (6) understanding other agents, (7) proactivity, and (8) responding appropriately to context, as illustrated in Figure¬†2. Seen from the lens of optimization, the first seven principles of social navigation can be formalized as additional objectives that the robot needs to optimize for while still achieving its main objective, and the eighth principle, context, can be seen as weighting which principles are most important at any given time, as shown in Figure¬†3. These principles are not completely orthogonal: improving legibility might improve safety and even comfort, whereas nonverbal politeness depends on understanding other agents‚Äô trajectories. In addition, what is considered appropriate or polite behavior depends on both the cultural context  and the robot‚Äôs main objective: for example, a delivery robot arguably should maintain a greater distance from humans than one functioning as a guide. The principles mentioned above guide the development of metrics to evaluate social robots, discussed in more depth in Section VI. Properly studying these principles of social navigation directly impacts which metrics to measure , what datasets to collect, how to build simulators, and how to structure benchmarks.\nIn the following sections, we unpack these principles as often used in social robotics research: Principle P1: Safety - Protect humans, other robots and their environments.\nA minimal requirement for robots and human sociality is not harming others in the course of business  , as the robot fails to do in the first scenario in Figure¬†2 when it collides with a human‚Äôs toe. Avoiding collisions with humans is important but is not the only safety concern  [ref]38 ; robots can damage each other or their environments. While it might be acceptable for a factory robot to bump a guardrail defining the edge of its workspace, social robots should generally avoid damaging human environments, which often contain important objects that can be damaged or wall coverings whose visual appearance is important. Robots should also avoid damaging each other, or behaving in a way that induces humans or other robots to injure themselves. Principle P2: Comfort - Do not create annoyance or stress.\nHumans should also feel comfortable around robots, defined in  as the absence of annoyance and stress for humans in interaction with robots. Many features contribute to comfort, including maintaining human-robot distance, not cutting humans off, and naturalness of motion. Unacceptable robot speed, navigation jitter and unexpected head movements are factors that degrade humans‚Äô perception of comfort. Additionally, social robots should arguably not behave in a way that triggers the safety layers of other robots.  further argue that annoyance can be triggered by a failure to respect proxemics, the virtual personal space around a human that other humans instinctively respect¬†. Figure¬†2 illustrates proxemics with the ‚Äúintimate‚Äù distance of 0.45‚Äãm0.45ùëö0.45m shown in red and the ‚Äúpersonal‚Äù distance of 1.2‚Äãm1.2ùëö1.2m; after initially violating a human‚Äôs personal distance, the robot is shown attempting to stay in ‚Äúpersonal‚Äù or more distant ‚Äúsocial‚Äù spaces, except as required by the geometric context. Proxemics is a rich and controversial field; for an in-depth survey see¬†. Principle P3: Legibility - Behave so goals can be understood.\nLegibility refers to the property of an agent‚Äôs behavior that makes it possible for other agents to infer their goals . This includes not only the robot‚Äôs goal but also incidental interactions when performing other tasks, e.g., moving to the right or left when passing in a hallway. Dragan and colleagues  suggests that legibility involves relaxing constraints such as predictability of trajectories (in the sense of an agent‚Äôs own predictable style) in favor of more clearly understood behaviors (in the sense of moving to make goals explicit). Legibility arguably can help other robots understand another social robot‚Äôs goals. While  focused on changes to robot paths to make them legible, a robot capable of communicating could explicitly announce its intentions, the way restaurant staff are trained to call ‚Äúcorner‚Äù when entering a blind corner, as the robot does in the middle of Figure¬†2. Principle P4: Politeness - Be respectful and considerate.\nPoliteness refers to behavior that is respectful and considerate of people. There are at least two dimensions: physical politeness (how robots navigate around people, such as not cutting people off) and communicative politeness (gestures or verbal signals, such as saying ‚Äúexcuse me‚Äù, or ‚Äúon your left‚Äù, as the robot does in Figure¬†2 when a narrow hallway forces it to transgress on a human‚Äôs personal space).\nPoliteness can have a strong effect on people‚Äôs perception of robots  [ref]43. Social robots should also be considerate of each other, so they do not prevent other robots from accomplishing their tasks. Principle P5: Social Competency - Comply with social norms.\nRobots should comply with social, political, and legal norms for sharing space. Many social competencies are matters of following conventions rather than optimizing performance¬† [ref]43 . For example, in the absence of norms there is no optimization preference for driving on the left or right, but identifying and following the local norms helps prevent conflicts¬†[ref]8 in the the third hallway interaction in Figure¬†2. Some social competencies, like turn-taking, can emerge naturally , whereas others must be specifically engineered (or simulated with wizard-of-oz studies  if existing policies are not up to the task). Social norms may apply to more than just humans; conventions of behaviors may make it easier for robots to interact. Principle P6: Understanding Other Agents - Predict and accommodate the behavior of other agents. A significant portion of the discussion during the symposium revolved around the need to understand other agents in order to be able to correctly fulfill the principles listed above and be considered a capable social agent. Understanding, accommodating, and even facilitating other agents‚Äô goals, activities, and motions was agreed to be a key element of social behavior. Accommodating the goals and comfort of other agents requires understanding of what they are perceiving, doing, and trying to accomplish. For example, to pass between two agents politely, it is important to understand whether they are in conversation .\nUnderstanding when the interaction potential - the likelihood of robots entering human personal space - should be minimized   or maximized  depends on the task. Further, understanding how agents move can reduce the potential for conflicts (short-term encounters in which humans and robots would collide without intervention [ref]8 ), as in the right side of Figure¬†2, where a robot recognizes the human‚Äôs path will cross theirs and stops to prevent a conflict. Principle P7: Proactivity - Taking the Initiative to Prevent and Resolve Issues Simply understanding other agents is not enough, however: in some circumstances, being social involves taking the initiative. Perhaps the canonical example is several cars meeting at a four-way intersection: if all drivers act conservatively, there can be considerable delay¬†. To resolve the conflict in a timely fashion, one driver must either take the initiative and go first, or proactively propose a solution by waving other drivers through the intersection . Studies of self-driving vehicles suggest that non-conservative (or ‚Äúaggressive‚Äù) behavior may even be desirable if that is expected by a population of drivers  . While it is less likely that socially navigating robots will be mistaken for humans as frequently as autonomous vehicles are mistaken for human-driven ones, appropriately resolving potential issues, similar situations to the four-way intersection deadlock can arise, such as when two pedestrians dodge to the same side or contend for the same doorway. In these cases, a socially navigating robot that can take the initiative to avoid a human or proactively suggest a solution will arguably be more social than one that is not, as in the right side of Figure¬†2, where the robot proactively proposes that the human enter the elevator first to prevent this kind of deadlock. Section¬†VII discusses measuring proactivity with scenarios designed to explicitly elicit this phenomenon. Principle P8: Contextual Appropriateness - Behave properly in the current context.\nSocial navigation should be evaluated within the context that it is to be deployed. Context helps us understand the relative importance of the previous objectives, and is a complex construct in its own right, as shown in Figure¬†3. An example shared in the symposium was a Crash Cart robot in a hospital bringing an emergency drug to a doctor: politeness is less important than task success. Also, when navigating a narrow corridor, we may be ‚Äúless polite‚Äù and get closer to other agents. We identified several forms of context, including cultural context, environmental context, diversity, task context, and interpersonal context, all of which can change which response is right in a given situation: Cultural Context: Different cultures have different social norms, as notably documented in ; more recently [ref]38  and  examined cultural norms in social robotics but concluded more work needs to be done. Diversity Context: Different individuals with different abilities or different background histories may need different accommodations . Environmental Context: The environment may affect the social navigation problem , and includes both geometric factors - the shape of the space - and operational factors - how that shape is to be used. Geometric Context: The geometry of the environment may affect the social navigation problem . For example, the more crowded the space is, the smaller the acceptable distance is between the robot and other people. Operational Context: The operational domain the robot is intended to work in in affects what behaviors are considered good: for example, a robot may drive slower in a daycare than an office, even if the two settings had identical geometric layouts. Task Context: In turn, the task the robot operates in affects what behaviors are appropriate: for example, even in a single environment like a hospital, whether a robot is performing mail delivery or is a crash cart changes its weighting of politeness against speed. Interpersonal Context: While there are many different areas of context that are appropriate, interpersonal context (e.g. whether humans are independent pedestrians, are traveling in a group, or stopped and conversing is critical to know how to navigate among them) As an illustration of context, the robot in Figure¬†2 is first shown violating a person‚Äôs intimate space distance in red, then attempting to avoid proxemics violations going forward. However, the corridor around the bend is too narrow to prevent the robot from passing though a person‚Äôs personal space distance in yellow, prompting the robot to politely call out its presence. Then, in the relatively small elevator, the standard interpersonal distances are no longer easy to achieve, and both the robot and human adjust their perceived proxemics radii based on the current context, shown as a contraction of the proxemics circles from their original size. Social navigation should be evaluated within the context that it is intended to be deployed. While defining context in a sufficiently precise way for a robot to identify or respond to it is a challenging problem, at the least the intended context should be defined well enough in terms of cultural, diversity, environmental, operational, task and interpersonal context for other researchers to gauge the applicability of the ideas and findings conveyed by research.\n\nReference markers found: [38]\n\nContext windows for each [ref]:\n[ref]38: course of business  , as the robot fails to do in the first scenario in Figure¬†2 when it collides with a human‚Äôs toe. Avoiding collisions with humans is important but is not the only safety concern  [ref]38 ; robots can damage each other or their environments. While it might be acceptable for a factory robot to bump a guardrail defining the edge of its workspace, social robots should generally\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"ProxEmo: Gait-based Emotion Learning and Multi-view Proxemic Fusion for Socially-Aware Robot Navigation\",\n                \"Human-aware robot navigation: A survey\",\n                \"From proxemics theory to socially-aware navigation: A survey\",\n                \"A review of social-aware navigation frameworks for service robot in dynamic human environments\",\n                \"Recent trends in social aware robot navigation: A survey\",\n                \"Autonomous navigation by mobile robots in human environments: A survey\",\n                \"Evaluation of socially-aware robot navigation\",\n                \"Core Challenges of Social Robot Navigation: A Survey\",\n                \"Prevention and resolution of conflicts in social navigation‚Äìa survey\",\n                \"A Survey on Human-aware Robot Navigation\",\n                \"Metrics for evaluating social conformity of crowd navigation algorithms\",\n                \"ImageNet Large Scale Visual Recognition Challenge\",\n                \"A large annotated corpus for learning natural language inference\",\n                \"Squad: 100,000+ questions for machine comprehension of text\",\n                \"SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems\",\n                \"On evaluation of embodied navigation agents\",\n                \"Habitat: A Platform for Embodied AI Research\",\n                \"Interactive gibson: Benchmark for interactive navigation in cluttered environments\",\n                \"Robothor: An open simulation-to-real embodied ai platform\",\n                \"Motion Planning and Control for Mobile Robot Navigation Using Machine Learning: a Survey\",\n                \"Retrospectives on the Embodied AI Workshop\",\n                \"Arena-Bench: A Benchmarking Suite for Obstacle Avoidance Approaches in Highly Dynamic Environments\",\n                \"Safe robot navigation in dense crowds\",\n                \"Dynabarn: Benchmarking metric ground navigation in dynamic environments\",\n                \"Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning\",\n                \"HuNavSim: A ROS 2 Human Navigation Simulator for Benchmarking Human-Aware Robot Navigation\",\n                \"iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday Household Tasks\",\n                \"iGibson 1.0: A Simulation Environment for Interactive Tasks in Large Realistic Scenes\",\n                \"SocNavBench: A Grounded Simulation Testing Framework for Evaluating Social Navigation\",\n                \"SEANavBench @ ICRA 2023 workshop website\",\n                \"A Protocol for Validating Social Navigation Policies\",\n                \"Learning Model Predictive Controllers with Real-Time Attention for Real-World Navigation\",\n                \"Gesture2Path: Imitation Learning for Gesture-aware Navigation\",\n                \"The emotion machine: Commonsense thinking, artificial intelligence, and the future of the human mind\",\n                \"Human-robot interaction in social robotics\",\n                \"Diversity-aware social robots meet people: beyond context-aware embodied ai\",\n                \"A survey of methods for safe human-robot interaction\",\n                \"Epsrc principles of robotics: commentary on safety, robots as products, and responsibility\",\n                \"Sociosense: Robot navigation amongst pedestrians with social and psychological constraints\",\n                \"The hidden dimension\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]38 based on the context and research area of Principles and Guidelines for Evaluating Social Robot Navigation Algorithms. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}