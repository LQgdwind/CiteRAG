{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: An Adaptive Neuro-Fuzzy System with Integrated Feature Selection and Rule Extraction for High-Dimensional Classification Problems\n\nPaper Abstract: \n\nPaper Section Text:\nConsider a classification problem involving Cğ¶C classes. Let an instance or data point be represented by a Dğ·D-dimensional feature vector, i.e., ğ±=(x1,x2,â‹¯,xD)Tâˆˆâ„Dğ±superscriptsubscriptğ‘¥1subscriptğ‘¥2â‹¯subscriptğ‘¥ğ·ğ‘‡superscriptâ„ğ·\\mathbf{x}=(x_{1},x_{2},\\cdots,x_{D})^{T}\\in\\mathbb{R}^{D}. We assume that each feature is associated with Sğ‘†S fuzzy sets. For a CoCo-FRB based TSK Fuzzy System, the number of fuzzy rules, Rğ‘…R, is equal to Sğ‘†S   . Generally, the rtâ€‹hâ€‹(r=1,2,â‹¯,R)subscriptğ‘Ÿğ‘¡â„ğ‘Ÿ12â‹¯ğ‘…r_{th}~{}(r=1,2,\\cdots,R) fuzzy rule of the first-order TSK model for classification problems is described as below: where Ar,dâ€‹(d=1,2,â‹¯,D)subscriptğ´ğ‘Ÿğ‘‘ğ‘‘12â‹¯ğ·A_{r,d}~{}(d=1,2,\\cdots,D) is the fuzzy set associated with dtâ€‹hsubscriptğ‘‘ğ‘¡â„d_{th} feature in the rtâ€‹hsubscriptğ‘Ÿğ‘¡â„r_{th} rule, yrcâ€‹(ğ±)â€‹(c=1,2,â‹¯,C)superscriptsubscriptğ‘¦ğ‘Ÿğ‘ğ±ğ‘12â‹¯ğ¶y_{r}^{c}(\\mathbf{x})~{}(c=1,2,\\cdots,C) means the output of the rtâ€‹hsubscriptğ‘Ÿğ‘¡â„r_{th} rule for the ctâ€‹hsubscriptğ‘ğ‘¡â„c_{th} class computed from ğ±ğ±\\mathbf{x} and pr,dcsubscriptsuperscriptğ‘ğ‘ğ‘Ÿğ‘‘p^{c}_{r,d} represents the consequent parameter of the rtâ€‹hsubscriptğ‘Ÿğ‘¡â„r_{th} rule associated with the dtâ€‹hsubscriptğ‘‘ğ‘¡â„d_{th} feature for the ctâ€‹hsubscriptğ‘ğ‘¡â„c_{th} class. There are plenty of choices of membership functions (MFs) that can be used for Ar,dsubscriptğ´ğ‘Ÿğ‘‘A_{r,d}, such as triangular, trapezoidal, and Gaussian functions  . We note that the Gaussian MF is frequently employed due to its smooth and infinitely differentiable properties. Specifically, the membership value of xdsubscriptğ‘¥ğ‘‘x_{d} on Ar,dsubscriptğ´ğ‘Ÿğ‘‘A_{r,d} is: where mr,dsubscriptğ‘šğ‘Ÿğ‘‘m_{r,d} and Ïƒr,dsubscriptğœğ‘Ÿğ‘‘\\sigma_{r,d} represent respectively the center and spread of the rtâ€‹hsubscriptğ‘Ÿğ‘¡â„r_{th} Gaussian membership function defined on the dtâ€‹hsubscriptğ‘‘ğ‘¡â„d_{th} input variable. Note that, although in equation (2) the argument of Î¼r,dsubscriptğœ‡ğ‘Ÿğ‘‘\\mu_{r,d} is shown as ğ±ğ±\\mathbf{x}, the function only uses the dtâ€‹hsubscriptğ‘‘ğ‘¡â„d_{th} component of ğ±ğ±\\mathbf{x}. In , the authors used Î¼=eâˆ’(xâˆ’m)2Ïƒ2ğœ‡superscriptğ‘’superscriptğ‘¥ğ‘š2superscriptğœ2\\mu=e^{-\\frac{(x-m)^{2}}{\\sigma^{2}}} as membership function but set Ïƒ=1ğœ1\\sigma=1 for all fuzzy subsystems which means (2) is simplified as: Following , the membership values are evaluated by (3) in this paper. Clearly, these values are all between 00 and 111, i.e., 0<Î¼r,dâ€‹(ğ±)â‰¤10subscriptğœ‡ğ‘Ÿğ‘‘ğ±10<\\mu_{r,d}(\\mathbf{x})\\leq 1. Since minimum is not differentiable, the product is often used to compute the firing strength     [ref]9  : where frâ€‹(ğ±)subscriptğ‘“ğ‘Ÿğ±f_{r}(\\mathbf{x}) is the firing strength of the rtâ€‹hsubscriptğ‘Ÿğ‘¡â„r_{th} rule for the input ğ±ğ±\\mathbf{x}. Note that the product T-norm often leads to a fatal flaw when the dimension, Dğ·D, is pretty large. It easily makes frâ€‹(ğ±)subscriptğ‘“ğ‘Ÿğ±f_{r}(\\mathbf{x}) very close to 00 even beyond the scope that machines can identify, that is, â€œnumeric underflowâ€ . The output of the rtâ€‹hsubscriptğ‘Ÿğ‘¡â„r_{th} rule associated the ctâ€‹hsubscriptğ‘ğ‘¡â„c_{th} class computed from ğ±ğ±\\mathbf{x} is: If the normalized firing strength is defined as: then the ctâ€‹hsubscriptğ‘ğ‘¡â„c_{th} component of the system output on ğ±ğ±\\mathbf{x} is: For the sake of clarity, the neural network structure implementing CoCo-FRB based TSK fuzzy system described above is shown in Fig. 1. By contrast, FuCo-FRB considers all possible valid combinations of fuzzy sets defined on each feature, in which the number of rules exponentially increases with the dimension of the feature space. The details of these two fuzzy rule bases will be illustrated and compared in Subsection III-B. Assume that there are Nğ‘N training samples. There are several choices of error functions  [ref]9  that can be used to update system parameters based on back-propagation procedure or gradient descent (GD) algorithm   . The typical mean square error function is used in this paper: where ycâ€‹(ğ±n)superscriptğ‘¦ğ‘subscriptğ±ğ‘›y^{c}(\\mathbf{x}_{n}) and ycâ€‹(ğ±n)subscriptğ‘¦ğ‘subscriptğ±ğ‘›y_{c}(\\mathbf{x}_{n}) respectively correspond to the ctâ€‹hsubscriptğ‘ğ‘¡â„c_{th} component of the system output and the true label vector for the ntâ€‹hsubscriptğ‘›ğ‘¡â„n_{th} input instance, ğ±nâ€‹(n=1,2,â‹¯,N)subscriptğ±ğ‘›ğ‘›12â‹¯ğ‘\\mathbf{x}_{n}~{}(n=1,2,\\cdots,N). The gradients of the error function (8) with respect to the antecedent and consequent parameters are presented as: where xn,dsubscriptğ‘¥ğ‘›ğ‘‘x_{n,d} is the dtâ€‹hsubscriptğ‘‘ğ‘¡â„d_{th} component of sample ğ±nsubscriptğ±ğ‘›\\mathbf{x}_{n}. Then, the update formula of system parameters in the ktâ€‹hsubscriptğ‘˜ğ‘¡â„k_{th} iteration is as follows: where Ï‰ğœ”\\omega indicates the general parameters of antecedent and consequent parts, Î·>0ğœ‚0\\eta>0 is the learning rate.\n\nReference markers found: [9]\n\nContext windows for each [ref]:\n[ref]9: values are all between 00 and 111, i.e., 0<Î¼r,dâ€‹(ğ±)â‰¤10subscriptğœ‡ğ‘Ÿğ‘‘ğ±10<\\mu_{r,d}(\\mathbf{x})\\leq 1. Since minimum is not differentiable, the product is often used to compute the firing strength     [ref]9  : where frâ€‹(ğ±)subscriptğ‘“ğ‘Ÿğ±f_{r}(\\mathbf{x}) is the firing strength of the rtâ€‹hsubscriptğ‘Ÿğ‘¡â„r_{th} rule for the input ğ±ğ±\\mathbf{x}. Note that the product T-norm often leads to a fatal flaw when\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 9,\n            \"titles\": [\n                \"Optimize TSK Fuzzy Systems for Classification Problems: Mini-Batch Gradient Descent with Uniform Regularization and Batch Normalization\",\n                \"An experiment in linguistic synthesis with a fuzzy logic controller\",\n                \"Fuzzy identification of systems and its applications to modeling and control\",\n                \"Fuzzy modelling and control of multilayer incinerator\",\n                \"Integrated feature analysis and fuzzy rule-based system identification in a neuro-fuzzy paradigm\",\n                \"A neuro-fuzzy scheme for simultaneous feature selection and fuzzy rule-based classification\",\n                \"An integrated mechanism for feature selection and fuzzy rule extraction for classification\",\n                \"Feature selection with controlled redundancy in a fuzzy rule based framework\",\n                \"Conjugate gradient-based takagi-sugeno fuzzy neural network parameter identification and its convergence analysis\",\n                \"Optimize TSK Fuzzy Systems for Regression Problems: Minibatch Gradient Descent With Regularization, DropRule, and AdaBound (MBGD-RDA)\",\n                \"On fuzzy modeling using fuzzy neural networks with the back-propagation algorithm\",\n                \"Learning representations by back-propagating errors\",\n                \"Fuzzy sets and fuzzy logic - theory and applications\",\n                \"Pictorial representations of fuzzy connectives, part I: Cases of t-norms, t-conorms and averaging operators\",\n                \"Fast training of adversarial deep fuzzy classifier by downsizing fuzzy rules with gradient guided learning\",\n                \"Simultaneous structure identification and fuzzy rule generation for takagi-sugeno models\",\n                \"Feature selection using a neural network with group lasso regularization and controlled redundancy\",\n                \"A new unsupervised spectral feature selection method for mixed data: A filter approach\",\n                \"Wrappers for feature subset selection\",\n                \"A wrapper method for feature selection using support vector machines\",\n                \"A new wrapper feature selection approach using neural network\",\n                \"Hybrid feature selection by combining filters and wrappers\",\n                \"An ensemble feature selection method for short-term electrical load forecasting\",\n                \"Hybrid filter-wrapper feature selection for short-term load forecasting\",\n                \"A hybrid genetic algorithm with wrapper-embedded approaches for feature selection\",\n                \"Selecting useful groups of features in a connectionist framework\",\n                \"Feature selection using a neural framework with controlled redundancy\",\n                \"Feature selection for neural networks using group lasso regularization\",\n                \"A method for fuzzy rules extraction directly from numerical data and its application to pattern classification\",\n                \"Distributed representation of fuzzy rules and its application to pattern classification\",\n                \"Selecting fuzzy if-then rules for classification problems using genetic algorithms\",\n                \"Fuzzy rule selection by multi-objective genetic local search algorithms and rule evaluation measures in data mining\",\n                \"Fuzzy data mining by heuristic rule extraction and multiobjective genetic rule selection\",\n                \"Dropout: A simple way to prevent neural networks from overfitting\",\n                \"Regularization of neural networks using dropconnect\",\n                \"Fuzzy broad learning system: A novel neuro-fuzzy model for regression and classification\",\n                \"A Novel Deep Fuzzy Classifier by Stacking Adversarial Interpretable TSK Fuzzy Sub-Classifiers With Smooth Gradient Information\",\n                \"Back-propagation fuzzy system as nonlinear dynamic system identifiers\",\n                \"Practical recommendations for gradient-based training of deep architectures\",\n                \"Fuzzy logic approaches to structure preserving dimensionality reduction\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]9 based on the context and research area of An Adaptive Neuro-Fuzzy System with Integrated Feature Selection and Rule Extraction for High-Dimensional Classification Problems. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}