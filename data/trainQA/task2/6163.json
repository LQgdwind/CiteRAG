{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: GPT (Generative Pre-trained Transformer) – A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions\n\nPaper Abstract: \n\nPaper Section Text:\nThe e-commerce sector could significantly advance with the introduction of GPTs. GPTs can be accessed by users or customers and are intended to answer commonly asked questions and give in-depth details about many elements of the e-commerce process, such as products, delivery, refunds, and more . One of the main benefits of GPTs is their capacity for quick responses, which decreases the amount of time customers must wait to hear back from businesses [ref]131. By taking care of an important number of client inquiries, this function not only increases customer happiness but also lessens the workload on support workers. Customers will ultimately have a better purchasing experience as a result of being able to quickly acquire the information they require and interact with GPTs . Proofreading: To improve the calibre and accuracy of written content in e-commerce, GPTs can be used for proofreading. Written content is essential for product descriptions, marketing materials, customer reviews, and other text-based components in the e-commerce sector . For the purpose of projecting professionalism, fostering trust, and delivering a satisfying user experience, this text must be devoid of errors, well-written, and grammatically correct. E-commerce companies can automate the process of identifying and correcting these problems by using GPTs for proofreading, which saves time and effort as comparison to manual proofreading . This can be especially helpful in situations when users are writing product reviews or interacting with customer service. An improved user experience is facilitated by the early detection and rectification of errors, which also helps to avoid potential misunderstandings or miscommunications. Order Processing: GPTs are useful in many areas of order management and customer service because they can comprehend and produce text that looks like human speech. GPTs can help with handling consumer questions about orders . GPT is capable of interpreting the queries, providing important details like order status, tracking information, and expected delivery time, as well as suggesting corrections for frequent problems . By delivering real-time information, GPTs can assist customers in tracking their orders. Customers can customize their purchase with the help of GPTs. GPTs can help in the identification of possibly fraudulent orders by examining past transaction data, consumer behaviour patterns etc . Based on a customer’s past purchases, browsing habits, and preferences, GPTs can offer tailored product recommendations. When a consumer puts a purchase, the model can examine the information and produce recommendations for related or supplementary products that the customer might find interesting. Generating titles for products: Companies can use GPTs to produce interesting and educational material to improve the appeal of their product listings . Based on a product’s category, brand, and special characteristics, GPTs can come up with attractive titles for it. The model can produce imaginative and memorable names that aid in brand awareness and differentiation by receiving relevant information such as the characteristics of the product and the target market. GPTs are trained to produce in-depth and interesting product descriptions . These summaries can offer a thorough summary that aids clients in selecting products wisely. GPTs are capable of coming up with clever and appealing captions for product images. GPTs can be adjusted to better reflect the tone and aesthetic of a certain brand . As a result, the brand identity is consistent and unified throughout all product listings. Strategy Planning: GPTs have the ability to come up with original and distinctive concepts for marketing campaigns . The model can provide recommendations for different campaign aspects, such as slogans, taglines, themes, contests, social media strategies, and more by taking into account relevant information about the product, target audience, marketing objectives, and desired outcomes. GPTs can help with email writing that encourages readers to become partners, investors, or customers . To increase the likelihood of a favourable response or interaction, these emails can be customized to address the needs and potential benefits for the receivers. To improve their comprehension and production of appropriate material, GPTs can be trained on domain-specific knowledge bases, such as e-commerce . The models can offer more precise and situation-specific recommendations for advertising strategies, product positioning, and target audience interaction because of this specialized training. Data analysis: There are numerous ways to use GPTs for data analysis in e-commerce. E-commerce data preparation can be aided by GPTs . Data normalization, cleansing, and formatting are a few of the duties involved. GPTs can produce summaries, identify significant topics, and extract appropriate data by studying textual descriptions, reviews, and consumer feedback. This helps you know the data more thoroughly, identify trends, and find insightful information. Customer reviews and social media comments from e-commerce can be analyzed for sentiment using GPTs. The sentiment expressed in text can be evaluated using GPTs and categorized as either positive, negative, or neutral . Understanding client views, recognizing product strengths and deficiencies, and making data-driven decisions all benefit from this analysis, which also helps to increase customer happiness. Segmenting consumers based on preferences, behaviours, or past purchases can be aided by GPT models . For the purpose of detecting fraud in e-commerce transactions, GPTs can be used. GPTs can support the identification of potentially fraudulent actions by examining past transaction data, user behaviour patterns, and recognized fraudulent tendencies .\n\nReference markers found: [131]\n\nContext windows for each [ref]:\n[ref]131: as products, delivery, refunds, and more . One of the main benefits of GPTs is their capacity for quick responses, which decreases the amount of time customers must wait to hear back from businesses [ref]131. By taking care of an important number of client inquiries, this function not only increases customer happiness but also lessens the workload on support workers. Customers will ultimately\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 131,\n            \"titles\": [\n                \"GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models\",\n                \"Pre-Trained Models: Past, Present and Future\",\n                \"Introducing OpenAI\",\n                \"Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition\",\n                \"Chatting about chatgpt: how may ai and gpt impact academia and libraries?\",\n                \"Chatgpt for good? on opportunities and challenges of large language models for education\",\n                \"Pre-trained Models for Natural Language Processing: A Survey\",\n                \"Revolutionizing business communication: Exploring the potential of gpt-4 in corporate settings\",\n                \"A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\",\n                \"A short survey of pre-trained language models for conversational ai-a new age in nlp\",\n                \"Deid-gpt: Zero-shot medical text de-identification by gpt-4\",\n                \"Marketing with chatgpt: Navigating the ethical terrain of gpt-based chatbot technology\",\n                \"Thus spoke gpt-3: Interviewing a large-language model on climate finance\",\n                \"Ai as the next gpt: a political-economy perspective\",\n                \"Artificial intelligence and ten societal megatrends: An exploratory study using gpt-3\",\n                \"Chatgpt: the new panacea of the academic world\",\n                \"GENERATIVE PRE-TRAINED TRANSFORMER FOR DESIGN CONCEPT GENERATION: AN EXPLORATION\",\n                \"GPT\",\n                \"Theory of mind may have spontaneously emerged in large language models\",\n                \"GPT-1, GPT-2 and GPT-3 models explained\",\n                \"Attention mechanism, transformers, bert, and gpt: Tutorial and survey\",\n                \"Generative Pre-trained Transformer 3 by OpenAI\",\n                \"Algorithmic ghost in the research shell: Large language models and academic knowledge creation in management research\",\n                \"Generating product description with generative pre-trained transformer 2\",\n                \"“what can chatgpt do?” analyzing early reactions to the innovative ai chatbot on twitter\",\n                \"Ai model gpt-3 (dis) informs us better than humans\",\n                \"A comprehensive capability analysis of gpt-3 and gpt-3.5 series models\",\n                \"What Makes Good In-Context Examples for GPT-3?\",\n                \"Gpt takes the bar exam\",\n                \"Machine intuition: Uncovering human-like intuitive decision-making in gpt-3.5\",\n                \"Attention Is All You Need\",\n                \"Geneturing tests gpt models in genomics\",\n                \"Pre-trained Language Model Representations for Language Generation\",\n                \"End-to-end transformer-based models in textual-based nlp\",\n                \"Softermax: Hardware/software co-design of an efficient softmax for transformers\",\n                \"Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models\",\n                \"Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions about Code\",\n                \"Variational latent-state gpt for semi-supervised task-oriented dialog systems\",\n                \"GPT-3, explained: This new language AI is uncanny, funny — and a big deal\",\n                \"How good are gpt models at machine translation? a comprehensive evaluation\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]131 based on the context and research area of GPT (Generative Pre-trained Transformer) – A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}