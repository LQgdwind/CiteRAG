{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 52 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Coarse-to-Fine: Learning Compact Discriminative Representation for Single-Stage Image Retrieval\n\nPaper Abstract: Abstract Image retrieval targets to find images from a database that are visually similar to the query image. Two-stage methods following retrieve-and-rerank paradigm have achieved excellent performance, but their separate local and global modules are inefficient to real-world applications. To better trade-off retrieval efficiency and accuracy, some approaches fuse global and local feature into a joint representation to perform single-stage image retrieval. However, they are still challenging due to various situations to tackle, e.g.formulae-sequenceùëíùëîe.g., background, occlusion and viewpoint. In this work, we design a ùêÇùêÇ\\mathbf{C}oarse-to-ùêÖùêÖ\\mathbf{F}ine framework to learn ùêÇùêÇ\\mathbf{C}ompact ùêÉùêÉ\\mathbf{D}iscriminative representation (CFCD) for end-to-end single-stage image retrieval-requiring only image-level labels. Specifically, we first design a novel adaptive softmax-based loss which dynamically tunes its scale and margin within each mini-batch and increases them progressively to strengthen supervision during training and intra-class compactness. Furthermore, we propose a mechanism which attentively selects prominent local descriptors and infuse fine-grained semantic relations into the global representation by a hard negative sampling strategy to optimize inter-class distinctiveness at a global scale. Extensive experimental results have demonstrated the effectiveness of our method, which achieves state-of-the-art single-stage image retrieval performance on benchmarks such as Revisited Oxford and Revisited Paris. Code is available at https://github.com/bassyess/CFCD.\n\n{retrieved_text}\n\nGenerate exactly 52 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 52\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Aggregating deep convolutional features for image retrieval\",\n        \"Learning local feature descriptors with triplets and shallow convolutional neural networks\",\n        \"Elasticface: Elastic margin loss for deep face recognition\",\n        \"Data fusion through cross-modality metric learning using similarity-sensitive hashing\",\n        \"Unifying deep local and global features for image search\",\n        \"Deep image retrieval: A survey\",\n        \"Imagenet: A large-scale hierarchical image database\",\n        \"Sub-center arcface: Boosting face recognition by large-scale noisy web faces\",\n        \"Arcface: Additive angular margin loss for deep face recognition\",\n        \"Insclr: Improving instance retrieval with self-supervision\",\n        \"D2-net: A trainable cnn for joint detection and description of local features\",\n        \"Training vision transformers for image retrieval\",\n        \"Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography\",\n        \"Deep image retrieval: Learning global representations for image search\",\n        \"End-to-end learning of deep visual representations for image retrieval\",\n        \"Momentum contrast for unsupervised visual representation learning\",\n        \"Local descriptors optimized for average precision\",\n        \"Deep residual learning for image recognition\",\n        \"Labeled faces in the wild: A database forstudying face recognition in unconstrained environments\",\n        \"Aggregating local descriptors into a compact image representation\",\n        \"Aggregating local image descriptors into compact codes\",\n        \"Adaface: Quality adaptive margin for face recognition\",\n        \"Proxy anchor loss for deep metric learning\",\n        \"Correlation verification for image retrieval\",\n        \"Sphereface: Deep hypersphere embedding for face recognition\",\n        \"Agedb: The first manually collected in-the-wild age database\",\n        \"No fuss distance metric learning using proxies\",\n        \"A metric learning reality check\",\n        \"Solar: Second-order loss and attention for image retrieval\",\n        \"Large-scale image retrieval with attentive deep local features\",\n        \"Object retrieval with large vocabularies and fast spatial matching\",\n        \"Lost in quantization: Improving particular object retrieval in large scale image databases\",\n        \"Revisiting oxford and paris: Large-scale image retrieval benchmarking\",\n        \"Fine-tuning cnn image retrieval with no human annotation\",\n        \"Learning with average precision: Training image retrieval with a listwise loss\",\n        \"Frontal to profile face verification in the wild\",\n        \"Local features and visual words emerge in activations\",\n        \"Instance-level image retrieval using reranking transformers\",\n        \"Detect-to-retrieve: Efficient regional aggregation for image search\",\n        \"Image search with selective match kernels: aggregation across single and multiple images\",\n        \"Learning and aggregating deep local descriptors for instance-level recognition\",\n        \"Cosface: Large margin cosine loss for deep face recognition\",\n        \"Deep metric learning with angular loss\",\n        \"Learning Super-Features for Image Retrieval\",\n        \"Google landmarks dataset v2-a large-scale benchmark for instance-level recognition and retrieval\",\n        \"Learning token-based representation for image retrieval\",\n        \"Dolg: Single-stage image retrieval with deep orthogonal fusion of local and global features\",\n        \"Learning face representation from scratch\",\n        \"Adacos: Adaptively scaling cosine logits for effectively learning deep face representations\",\n        \"Sift meets cnn: A decade survey of instance retrieval\",\n        \"Cross-pose lfw: A database for studying cross-pose face recognition in unconstrained environments\",\n        \"Cross-age lfw: A database for studying cross-age face recognition in unconstrained environments\"\n    ],\n    \"reasoning\": \"Selected these 52 references because they represent foundational work and recent advances in Coarse-to-Fine: Learning Compact Discriminative Representation for Single-Stage Image Retrieval, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}