{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 141 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: PUMA: Efficient and Low-Cost Memory Allocation and Alignment Support for Processing-Using-Memory Architectures\n\nPaper Abstract: \n\n{retrieved_text}\n\nGenerate exactly 141 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 141\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Processing-in-Memory: A Workload-Driven Perspective\",\n        \"A Modern Primer on Processing in Memory\",\n        \"DAMOV: A New Methodology and Benchmark Suite for Evaluating Data Movement Bottlenecks\",\n        \"The Processing-in-Memory Paradigm: Mechanisms to Enable Adoption\",\n        \"Processing Data Where It Makes Sense: Enabling In-Memory Computation\",\n        \"Enabling Practical Processing in and Near Memory for Data-Intensive Computing\",\n        \"Research Problems and Opportunities in Memory Systems\",\n        \"Memory Scaling: A Systems Architecture Perspective\",\n        \"A Processing in Memory Taxonomy and a Case for Studying Fixed-Function PIM\",\n        \"Near-Data Processing: Insights from a MICRO-46 Workshop\",\n        \"A Logic-in-Memory Computer\",\n        \"Missing the Memory Wall: The Case for Processor/Memory Integration\",\n        \"NDA: Near-DRAM Acceleration Architecture Leveraging Commodity DRAM Devices and Standard Memory Modules\",\n        \"JAFAR: Near-Data Processing for Databases\",\n        \"The True Processing in Memory Accelerator\",\n        \"GenStore: A High-Performance and Energy-Efficient In-Storage Computing System for Genome Sequence Analysis\",\n        \"Benchmarking Memory-Centric Computing Systems: Analysis of Real Processing-in-Memory Hardware\",\n        \"Benchmarking a New Paradigm: An Experimental Analysis of a Real Processing-in-Memory Architecture\",\n        \"Benchmarking a New Paradigm: Experimental Analysis and Characterization of a Real Processing-in-Memory System\",\n        \"SynCron: Efficient Synchronization Support for Near-Data-Processing Architectures\",\n        \"NERO: A Near High-Bandwidth Memory Stencil Accelerator for Weather Prediction Modeling\",\n        \"A 1ynm 1.25V 8Gb, 16Gb/s/pin GDDR6-based Accelerator-in-Memory Supporting 1TFLOPS MAC Operation and Various Activation Functions for Deep-Learning Applications\",\n        \"Near-Memory Processing in Action: Accelerating Personalized Recommendation with AxDIMM\",\n        \"SparseP: Towards Efficient Sparse Matrix Vector Multiplication on Real Processing-in-Memory Architectures\",\n        \"McDRAM: Low Latency and Energy-Efficient Matrix Computations in DRAM\",\n        \"McDRAM v2: In-Dynamic Random Access Memory Systolic Array Accelerator to Address the Large Model Problem in Deep Neural Networks on the Edge\",\n        \"Casper: Accelerating Stencil Computation using Near-Cache Processing\",\n        \"Chameleon: Versatile and Practical Near-DRAM Acceleration Architecture for Large Memory Systems\",\n        \"A Case for Intelligent RAM\",\n        \"Computational RAM: Implementing Processors in Memory\",\n        \"Saving memory movements through vector processing in the dram\",\n        \"Beyond the wall: Near-data processing for databases\",\n        \"ABC-DIMM: Alleviating the Bottleneck of Communication in DIMM-Based Near-Memory Processing with Inter-DIMM Broadcast\",\n        \"GraphSSD: Graph Semantics Aware SSD\",\n        \"Processing in Memory: The Terasys Massively Parallel PIM Array\",\n        \"Mapping Irregular Applications to DIVA, a PIM-Based Data-Intensive Architecture\",\n        \"Opportunities and Challenges of Performing Vector Operations Inside the DRAM\",\n        \"Livia: Data-Centric Computing Throughout the Memory Hierarchy\",\n        \"A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing\",\n        \"GraphPIM: Enabling Instruction-Level PIM Offloading in Graph Computing Frameworks\",\n        \"Google Workloads for Consumer Devices: Mitigating Data Movement Bottlenecks\",\n        \"LazyPIM: An Efficient Cache Coherence Mechanism for Processing-in-Memory\",\n        \"TOP-PIM: Throughput-Oriented Programmable Processing in Memory\",\n        \"HRL: Efficient and Flexible Reconfigurable Logic for Near-Data Processing\",\n        \"GRIM-Filter: Fast Seed Location Filtering in DNA Read Mapping Using Processing-in-Memory Technologies\",\n        \"The Mondrian Data Engine\",\n        \"Operand Size Reconfiguration for Big Data Processing in Memory\",\n        \"NIM: An HMC-Based Machine for Neuron Computation\",\n        \"PIM-Enabled Instructions: A Low-Overhead, Locality-Aware Processing-in-Memory Architecture\",\n        \"TETRIS: Scalable and Efficient Neural Network Acceleration with 3D Memory\",\n        \"“Neurocube: A Programmable Digital Neuromorphic Architecture with High-Density 3D Memory\",\n        \"“Leveraging 3D Technologies for Hardware Security: Opportunities and Challenges\",\n        \"R. Ausavarungnirun\",\n        \"“Transparent Offloading and Mapping (TOM) Enabling Programmer-Transparent Near-Data Processing in GPU Systems\",\n        \"R. Balasubramonian et al\",\n        \"“Scheduling Techniques for GPU Architectures with Processing-in-Memory Capabilities\",\n        \"“Data Reorganization in Memory Using 3D-Stacked DRAM\",\n        \"“Accelerating Pointer Chasing in 3D-Stacked Memory: Challenges\",\n        \"“BSSync: Processing Near Memory for Machine Learning Workloads with Bounded Staleness Consistency Models\",\n        \"R. Narayanaswami\",\n        \"“Polynesia: Enabling High-Performance and Energy-Efficient Hybrid Transactional/Analytical Databases with Hardware/Software Co-Design\",\n        \"“Polynesia: Enabling Effective Hybrid Transactional/Analytical Databases with Specialized Hardware/Software Co-Design\",\n        \"“Practical Mechanisms for Reducing Processor-Memory Data Movement in Modern Workloads\",\n        \"“NATSA: A Near-Data Processing Accelerator for Time Series Analysis\",\n        \"“NAPEL: Near-Memory Computing Application Performance Prediction via Ensemble Learning\",\n        \"“A 20nm 6GB Function-in-Memory DRAM\",\n        \"“Hardware Architecture and Software Stack for PIM Based on Commercial DRAM Technology: Industrial Product\",\n        \"“184QPS/W 64Mb/m​m2𝑚superscript𝑚2mm^{2} 3D Logic-to-DRAM Hybrid Bonding with Process-Near-Memory Engine for Recommendation System\",\n        \"“Accelerating Sparse Matrix-Matrix Multiplication with 3D-Stacked Logic-in-Memory Hardware\",\n        \"“Logic-Base Interconnect Design for Near Memory Computing in the Smart Memory Cube\",\n        \"“Neurostream: Scalable and Energy Efficient Deep Learning with Smart Memory Cubes\",\n        \"“3D-Stacked Memory-Side Acceleration: Accelerator and System Design\",\n        \"“Design Space Exploration for PIM Architectures in 3D-Stacked Memories\",\n        \"“HAMLeT: Hardware Accelerated Memory Layout Transform within 3D-Stacked DRAM\",\n        \"“A Heterogeneous PIM Hardware-Software Co-Design for Energy-Efficient Graph Processing\",\n        \"“GraphH: A Processing-in-Memory Architecture for Large-Scale Graph Processing\",\n        \"“Processing-in-Memory for Energy-Efficient Neural Network Training: A Heterogeneous Approach\",\n        \"“Adaptive Scheduling for Systems with Asymmetric Memory Hierarchies\",\n        \"“iPIM: Programmable In-Memory Image Processing Accelerator using Near-Bank Architecture\",\n        \"“DRAMA: An Architecture for Accelerated Processing Near Memory\",\n        \"A. Farmahini-Farahani\",\n        \"“Active-Routing: Compute on the Way for Near-Data Processing\",\n        \"“Lightweight SIMT Core Designs for Intelligent 3D Stacked DRAM\",\n        \"“PIMS: A Lightweight Processing-in-Memory Accelerator for Stencil Computations\",\n        \"“GRIM-Filter: Fast Seed Filtering in Read Mapping using Emerging Memory Technologies\",\n        \"“LazyPIM: Efficient Support for Cache Coherence in Processing-in-Memory Architectures\",\n        \"“GraphQ: Scalable PIM-Based Graph Processing\",\n        \"“GraphP: Reducing Communication for PIM-Based Graph Processing with Efficient Data Partition\",\n        \"“Triple Engine Processor (TEP): A Heterogeneous Near-Memory Processor for Diverse Kernel Operations\",\n        \"“A Case for Near Memory Computation Inside the Smart Memory Cube\",\n        \"“Large Vector Extensions Inside the HMC\",\n        \"“Charon: Specialized Near-Memory Processing Architecture for Clearing Dead Objects in Memory\",\n        \"“Active Memory Cube: A Processing-in-Memory Architecture for Exascale Systems\",\n        \"“CAIRO: A Compiler-Assisted Technique for Enabling Instruction-Level Offloading of Processing-in-Memory\",\n        \"“Processing in 3D Memories to Speed Up Operations on Complex Data Structures\",\n        \"“PRIME: A Novel Processing-in-Memory Architecture for Neural Network Computation in ReRAM-Based Main Memory\",\n        \"N. Muralimanohar\",\n        \"“Ambit: In-Memory Accelerator for Bulk Bitwise Operations Using Commodity DRAM Technology\",\n        \"“In-DRAM Bulk Bitwise Execution Engine\",\n        \"“DRISA: A DRAM-Based Reconfigurable In-Situ Accelerator\",\n        \"“The Processing Using Memory Paradigm: In-DRAM Bulk Copy\",\n        \"“DrAcc: A DRAM Based Accelerator for Accurate CNN Inference\",\n        \"“ELP2IM: Efficient and Low Power Bitwise Operation Processing in DRAM\",\n        \"“GraphR: Accelerating Graph Processing Using ReRAM\",\n        \"“PipeLayer: A Pipelined ReRAM-Based Accelerator for Deep Learning\",\n        \"G. Tziantzioulis\",\n        \"“Neural Cache: Bit-Serial In-Cache Acceleration of Deep Neural Networks\",\n        \"“Duality Cache for Data Parallel Acceleration\",\n        \"“Buddy-RAM: Improving the Performance and Efficiency of Bulk Bitwise Operations Using DRAM\",\n        \"“Simple Operations in Memory to Reduce Data Movement\",\n        \"“Fast Bulk Bitwise AND and OR in DRAM\",\n        \"“Pinatubo: A Processing-in-Memory Architecture for Bulk Bitwise Operations in Emerging Non-Volatile Memories\",\n        \"“pLUTo: In-DRAM Lookup Tables to Enable Massively Parallel General-Purpose Computation\",\n        \"“pLUTo: Enabling Massively Parallel Computation in DRAM via Lookup Tables\",\n        \"“FloatPIM: In-Memory Acceleration of Deep Neural Network Training with High Precision\",\n        \"“Sparse BD-Net: A Multiplication-Less DNN with Sparse Binarized Depth-Wise Separable Convolution\",\n        \"“Flash-Cosmos: In-Flash Bulk Bitwise Operations Using Inherent Computation Capability of NAND Flash Memory\",\n        \"“Adapting the RACER Architecture to Integrate Improved In-ReRAM Logic Primitives\",\n        \"“RACER: Bit-Pipelined Processing Using Resistive Memory\",\n        \"“QUAC-TRNG: High-Throughput True Random Number Generation Using Quadruple Row Activation in Commodity DRAMs\",\n        \"“D-RaNGe: Using Commodity DRAM Devices to Generate True Random Numbers With Low Latency and High Throughput\",\n        \"“The DRAM Latency PUF: Quickly Evaluating Physical Unclonable Functions by Exploiting the Latency-Reliability Tradeoff in Modern Commodity DRAM Devices\",\n        \"“DR-STRaNGe: End-to-End System Design for DRAM-Based True Random Number Generators\",\n        \"K. Kanellopoulos\",\n        \"“In-Memory Low-Cost Bit-Serial Addition Using Commodity DRAM Technology\",\n        \"“GraphiDe: A Graph Processing Accelerator Leveraging In-DRAM-Computing\",\n        \"“SCOPE: A Stochastic Computing Engine for DRAM-Based In-Situ Accelerator\",\n        \"“Parallel Automata Processor\",\n        \"“Hyper-AP: Enhancing Associative Processing Through A Full-Stack Optimization\",\n        \"“In-Memory Data Parallel Processor\",\n        \"“CODIC: A Low-Cost Substrate for Enabling Custom In-DRAM Functionalities and Optimizations\",\n        \"“Ultra Low Power Associative Computing with Spin Neurons and Resistive Crossbar Memory\",\n        \"“SIMDRAM: A Framework for Bit-Serial SIMD Processing Using DRAM\",\n        \"“Low-Cost Inter-Linked Subarrays (LISA): Enabling Fast Inter-Subarray Data Movement in DRAM\",\n        \"“Linux and the Devicetree — The Linux Kernel Documentation\",\n        \"“Revisiting RowHammer: An Experimental Analysis of Modern DRAM Devices and Mitigation Techniques\",\n        \"“A Deeper Look into RowHammer’s Sensitivities: Experimental Analysis of Real DRAM Chips and Implications on Future Attacks and Defenses\",\n        \"“Understanding RowHammer Under Reduced Wordline Voltage: An Experimental Study Using Real DRAM Devices\",\n        \"“A Programmer’s Description of L6\",\n        \"“Near-Optimal Bin Packing Algorithms\",\n        \"a Fast and Portable Dynamic Translator\"\n    ],\n    \"reasoning\": \"Selected these 141 references because they represent foundational work and recent advances in PUMA: Efficient and Low-Cost Memory Allocation and Alignment Support for Processing-Using-Memory Architectures, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}