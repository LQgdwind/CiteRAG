{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 61 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: A GPU-Accelerated Fast Summation Method Based on Barycentric Lagrange Interpolation and Dual Tree Traversal\n\nPaper Abstract: Abstract We present the barycentric Lagrange dual tree traversal (BLDTT) fast summation method for particle interactions. The scheme replaces well-separated particle-particle interactions by adaptively chosen particle-cluster, cluster-particle, and cluster-cluster approximations given by barycentric Lagrange interpolation at proxy particles on a Chebyshev grid in each cluster. The BLDTT is kernel-independent and the approximations can be efficiently mapped onto GPUs, where target particles provide an outer level of parallelism and source particles provide an inner level of parallelism. We present an OpenACC GPU implementation of the BLDTT with MPI remote memory access for distributed memory parallelization. The performance of the GPU-accelerated BLDTT is demonstrated for calculations with different problem sizes, particle distributions, geometric domains, and interaction kernels, as well as for unequal target and source particles. Comparison with our earlier particle-cluster barycentric Lagrange treecode (BLTC) demonstrates the superior performance of the BLDTT. In particular, on a single GPU for problem sizes ranging from NùëÅN=1E5 to 1E8, the BLTC has O‚Äã(N‚Äãlog‚Å°N)ùëÇùëÅùëÅO(N\\log N) scaling, while the BLDTT has O‚Äã(N)ùëÇùëÅO(N) scaling. In addition, MPI strong scaling results are presented for the BLTC and BLDTT using NùëÅN=64E6 particles on up to 32 GPUs.\n\n{retrieved_text}\n\nGenerate exactly 61 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 61\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Computer Simulation Using Particles\",\n        \"A smooth particle mesh Ewald method\",\n        \"An efficient program for many-body simulation\",\n        \"A hierarchical O‚Äã(N‚Äãlog‚Å°N)ùëÇùëÅùëÅO(N\\\\log N) force-calculation algorithm\",\n        \"A fast algorithm for particle simulations\",\n        \"A fast adaptive multipole algorithm in three dimensions\",\n        \"On the fast matrix multiplication in the boundary element method by panel clustering\",\n        \"Hierarchical Matrices: Algorithms and Analysis\",\n        \"Multilevel summation method for electrostatic force evaluation\",\n        \"A particle method and adaptive treecode for vortex sheet motion in three-dimensional flow\",\n        \"A hierarchical O‚Äã(N)ùëÇùëÅO(N) force calculation algorithm\",\n        \"The order of Appel‚Äôs algorithm\",\n        \"A task parallel implementation of fast multipole methods\",\n        \"An FMM based on dual tree traversal for many-core architectures\",\n        \"A fast multipole method for stellar dynamics\",\n        \"Parallel dual tree traversal on multi-core and many-core architectures for astrophysical N-body simulations\",\n        \"Optimizing the accuracy and efficiency of fast hierarchical multipole expansions for MD simulations\",\n        \"The fast multipole method and point dipole moment polarizable force fields\",\n        \"A new version of the fast multipole method for screened Coulomb interactions in three dimensions\",\n        \"An adaptive treecode for computing nonbonded potential energy in classical molecular systems\",\n        \"A Cartesian treecode for screened Coulomb interactions\",\n        \"An implementation of the fast multipole method without multipoles\",\n        \"Yet another fast multipole method without multipoles‚Äìpseudoparticle multipole method\",\n        \"A kernel-independent adaptive fast multipole algorithm in two and three dimensions\",\n        \"The black-box fast multipole method\",\n        \"Barycentric Lagrange interpolation\",\n        \"A kernel-independent treecode based on barycentric Lagrange interpolation\",\n        \"Fast low-rank kernel matrix factorization using skeletonized interpolation\",\n        \"Interpolative decomposition via proxy points for kernel matrices\",\n        \"H2Pack: High-performance ‚Ñã2superscript‚Ñã2\\\\mathcal{H}^{2} matrix package for kernel matrices using the proxy point method\",\n        \"A new parallel kernel-independent fast multipole method\",\n        \"A massively parallel adaptive fast multipole method on heterogeneous architectures\",\n        \"A kernel-independent FMM in general dimensions\",\n        \"PVFMM: A parallel kernel independent FMM for particle and volume potentials\",\n        \"Algorithm 967: A distributed-memory fast multipole method for volume potentials\",\n        \"Optimization of the parallel black-box fast multipole method on CUDA\",\n        \"N-body simulation on GPUs\",\n        \"Fast NùëÅ{N}-body simulation with CUDA\",\n        \"42 TFlops hierarchical N-body simulations on GPUs with applications in both astrophysics and turbulence\",\n        \"An efficient CUDA implementation of the tree-based Barnes Hut nùëõn-body algorithm\",\n        \"Comparing the treecode with FMM on GPUs for vortex particle simulations of a leapfrogging vortex ring\",\n        \"Biomolecular electrostatics using a fast multipole BEM on up to 512 GPUs and a billion unknowns\",\n        \"A sparse octree gravitational nùëõn-body code that runs entirely on the GPU processor\",\n        \"24.77 Pflops on a gravitational tree-code to simulate the Milky Way Galaxy with 1860 GPUs\",\n        \"Hierarchical matrix operations on GPUs: Matrix-vector multiplication and compression\",\n        \"Randomized GPU algorithms for the construction of hierarchical matrices from matrix-vector operations\",\n        \"A GPU-accelerated barycentric Lagrange treecode\",\n        \"Hierarchical NùëÅN-body simulations with autotuning for heterogeneous systems\",\n        \"Dual tree traversal on integrated GPUs for astrophysical N-body simulations\",\n        \"BaryTree (2020)\",\n        \"Lagrangian interpolation at the Chebyshev points xn,ŒΩ‚â°cos‚Å°(ŒΩ‚ÄãœÄ/n),ŒΩ=0‚Äã(1)‚Äãnformulae-sequencesubscriptùë•ùëõùúàùúàùúãùëõùúà01ùëõx_{n,\\\\nu}\\\\equiv\\\\cos(\\\\nu\\\\pi/n),\\\\nu=0(1)n; some unnoted advantages\",\n        \"Astrophysical N-body simulations using hierarchical tree data structures\",\n        \"The Zoltan Project (2020)\",\n        \"The Zoltan and Isorropia parallel toolkits for combinatorial scientific computing: Partitioning, ordering, and coloring\",\n        \"On the problem of distribution in globular star clusters\",\n        \"A completely analytical family of anisotropic Plummer models\",\n        \"Cartesian treecode algorithms for electrostatic interactions in molecular dynamics simulations\",\n        \"Comparison of treecodes for computing electrostatic potentials in charged particle systems with disjoint targets and sources\",\n        \"A treecode based on barycentric hermite interpolation for electrostatic particle interactions\",\n        \"A treecode-accelerated boundary integral Poisson‚ÄìBoltzmann solver for electrostatics of solvated biomolecules\",\n        \"Treecode-accelerated Green iteration for Kohn‚ÄìSham density functional theory\"\n    ],\n    \"reasoning\": \"Selected these 61 references because they represent foundational work and recent advances in A GPU-Accelerated Fast Summation Method Based on Barycentric Lagrange Interpolation and Dual Tree Traversal, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}