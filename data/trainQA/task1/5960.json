{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 297 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Trustworthy Graph Neural Networks: Aspects, Methods and Trends\n\nPaper Abstract: Abstract Graph neural networks (GNNs) have emerged as a series of competent graph learning methods for diverse real-world scenarios, ranging from daily applications like recommendation systems and question answering to cutting-edge technologies such as drug discovery in life sciences and n-body simulation in astrophysics. However, task performance is not the only requirement for GNNs. Performance-oriented GNNs have exhibited potential adverse effects like vulnerability to adversarial attacks, unexplainable discrimination against disadvantaged groups, or excessive resource consumption in edge computing environments. To avoid these unintentional harms, it is necessary to build competent GNNs characterised by trustworthiness. To this end, we propose a comprehensive roadmap to build trustworthy GNNs from the view of the various computing technologies involved. In this survey, we introduce basic concepts and comprehensively summarise existing efforts for trustworthy GNNs from six aspects, including robustness, explainability, privacy, fairness, accountability, and environmental well-being. Additionally, we highlight the intricate cross-aspect relations between the above six aspects of trustworthy GNNs. Finally, we present a thorough overview of trending directions for facilitating the research and industrialisation of trustworthy GNNs.\n\n{retrieved_text}\n\nGenerate exactly 297 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 297\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Wild and interesting facebook statistics and facts (2021)\",\n        \"A comprehensive survey on graph neural networks\",\n        \"Graph neural networks: Architectures, stability, and transferability\",\n        \"Aligraph: A comprehensive graph neural network platform\",\n        \"Pinnersage: Multi-modal user embedding framework for recommendations at pinterest\",\n        \"Learning to simulate complex physics with graph networks\",\n        \"Study of mass composition of cosmic rays with icetop and icecube\",\n        \"Improving fake news detection with domain-adversarial and graph-attention neural network\",\n        \"Deep learning identifies synergistic drug combinations for treating COVID-19\",\n        \"Trustworthy AI: A computational perspective\",\n        \"Trustworthy AI: from principles to practices\",\n        \"Trustworthy machine learning\",\n        \"Toward trustworthy AI development: Mechanisms for supporting verifiable claims\",\n        \"Governance principles for the new generation artificial intelligence–developing responsible artificial intelligence\",\n        \"The montreal declaration of responsible ai\",\n        \"How powerful are graph neural networks?\",\n        \"Measuring and relieving the over-smoothing problem for graph neural networks from the topological view\",\n        \"Training graph neural networks with 1000 layers\",\n        \"Graph self-supervised learning: A survey\",\n        \"Binarizedattack: Structural poisoning attacks to graph-based anomaly detection\",\n        \"Say no to the discrimination: Learning fair graph neural networks with limited sensitive attribute information\",\n        \"Gnnexplainer: Generating explanations for graph neural networks\",\n        \"Definition of trustworthy\",\n        \"Trust as a social reality\",\n        \"GAZELLE: A low latency framework for secure neural network inference\",\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Deep learning with differential privacy\",\n        \"Adversarial attacks and defenses on graphs\",\n        \"Explainability in graph neural networks: A taxonomic survey\",\n        \"Towards a rigorous theoretical analysis and evaluation of GNN explanations\",\n        \"K. Balasubramanian\",\n        \"“On dyadic fairness: Exploring and mitigating bias in graph connections\",\n        \"“Inform: Individual fairness on graph mining\",\n        \"“A pipeline for fair comparison of graph neural networks in node classification tasks\",\n        \"“Hardware acceleration of graph neural networks\",\n        \"“Blockgnn: Towards efficient GNN acceleration using block-circulant weight matrices\",\n        \"“Explaining and harnessing adversarial examples\",\n        \"“”why should I trust you?”: Explaining the predictions of any classifier\",\n        \"“Deep inside convolutional networks: Visualising image classification models and saliency maps\",\n        \"“Membership inference attacks against machine learning models\",\n        \"“A survey on bias and fairness in machine learning\",\n        \"“What to account for when accounting for algorithms: a systematic literature review on algorithmic accountability\",\n        \"“Designing energy-efficient convolutional neural networks using energy-aware pruning\",\n        \"“Adversarial attacks on neural networks for graph data\",\n        \"“Stealing links from graph neural networks\",\n        \"“Node-level membership inference attacks against graph neural networks\",\n        \"“Adapting membership inference attacks to GNN for graph classification: Approaches and implications\",\n        \"“Graphsaint: Graph sampling based inductive learning method\",\n        \"“Simplifying graph convolutional networks\",\n        \"“Graph neural network: A comprehensive review on non-euclidean space\",\n        \"Deep learning on graphs. Cambridge University Press\",\n        \"“Adversarial attack on graph structured data\",\n        \"“Adversarial attacks on node embeddings via graph poisoning\",\n        \"“Attacking similarity-based link prediction in social networks\",\n        \"“Manipulating node similarity measures in networks\",\n        \"“Parameterized explainer for graph neural network\",\n        \"“Evaluating attribution for graph neural networks\",\n        \"“Explainability methods for graph convolutional neural networks\",\n        \"“Quantifying explainers of graph neural networks in computational pathology\",\n        \"“Model extraction attacks on graph neural networks: Taxonomy and realization\",\n        \"“Privacy-preserving representation learning on graphs: A mutual information perspective\",\n        \"“Netfense: Adversarial defenses against privacy attacks on neural networks for graph data\",\n        \"“Preserving the privacy of sensitive relationships in graph data\",\n        \"“Towards a unified framework for fair and stable graph representation learning\",\n        \"“Fairdrop: Biased edge dropout for enhancing fairness in graph representation learning\",\n        \"“Individual fairness for graph neural networks: A ranking based approach\",\n        \"“Accountability of AI under the law: The role of explanation\",\n        \"“Deep learning on graphs: A survey\",\n        \"“Computing graph neural networks: A survey from algorithms to accelerators\",\n        \"“A comprehensive survey on trustworthy graph neural networks: Privacy\",\n        \"“Branchy-gnn: A device-edge co-inference framework for efficient point cloud processing\",\n        \"“Graph normalizing flows\",\n        \"“Out-of-distribution generalization on graphs: A survey\",\n        \"K. Kawarabayashi\",\n        \"Fighting computer crime - a new framework for protecting information. Wiley\",\n        \"“Neural message passing for quantum chemistry\",\n        \"“Learning graph embedding with adversarial training methods\",\n        \"“Contrastive graph poisson networks: Semi-supervised learning with extremely limited labels\",\n        \"“A survey of community detection approaches: From statistical modeling to deep learning\",\n        \"“Graph neural networks\",\n        \"“TDGIA: effective injection attacks on graph neural networks\",\n        \"“Projective ranking: A transferable evasion attack method on graph neural networks\",\n        \"“ADMIRING: adversarial multi-network mining\",\n        \"“Structural attack against graph based android malware detection\",\n        \"“Graph vulnerability and robustness: A survey\",\n        \"“Cascading failure in Watts–Strogatz small-world networks\",\n        \"“Adversarial attacks on graph neural networks via meta learning\",\n        \"“VIKING: adversarial attack on network embeddings via supervised network poisoning\",\n        \"“Adversarial attacks on graph neural networks via node injections: A hierarchical reinforcement learning approach\",\n        \"“Exploratory adversarial attacks on graph neural networks\",\n        \"“Network embedding attack: An euclidean distance based method\",\n        \"“Backdoor attacks to graph neural networks\",\n        \"“Scalable attack on graph data by injecting vicious nodes\",\n        \"“Graph adversarial attack via rewiring\",\n        \"“Explainability-based backdoor attacks against graph neural networks\",\n        \"“Graph universal adversarial attacks: A few bad actors ruin graph learning models\",\n        \"“MGA: momentum gradient attack on network\",\n        \"“Topology attack and defense for graph neural networks: An optimization perspective\",\n        \"“Adversarial examples for graph data: Deep insights into attack and defense\",\n        \"“Fast gradient attack on network embedding\",\n        \"“Derivative-free optimization adversarial attacks for graph convolutional networks\",\n        \"“Adversarial attacks and defenses on graphs: A review and empirical study\",\n        \"“A hard label black-box adversarial attack against graph neural networks\",\n        \"“Graph robustness benchmark: Benchmarking the adversarial robustness of graph machine learning\",\n        \"“All you need is low (rank): Defending against adversarial attacks on graphs\",\n        \"“Graph structure learning for robust graph neural networks\",\n        \"“Graph sanitation with application to node classification\",\n        \"“Robust graph convolutional networks against adversarial attacks\",\n        \"“Transferring robustness for graph neural network against poisoning attacks\",\n        \"“Defending graph convolutional networks against adversarial attacks\",\n        \"“Gnnguard: Defending graph neural networks against adversarial attacks\",\n        \"“Graph adversarial training: Dynamically regularizing based on graph structure\",\n        \"“Robust training of graph convolutional networks via latent perturbation\",\n        \"“Certifiable robustness to graph perturbations\",\n        \"“Certifiable robustness and robust training for graph convolutional networks\",\n        \"“Adversarial immunization for certifiable robustness on graphs\",\n        \"“Comparing and detecting adversarial attacks for graph deep learning\",\n        \"“Understanding structural vulnerability in graph convolutional networks\",\n        \"“Evaluating the robustness of neural networks: An extreme value theory approach\",\n        \"“Interpreting and evaluating neural network robustness\",\n        \"“Robustness of graph neural networks at scale\",\n        \"“Graphsac: Detecting anomalies in large-scale graphs\",\n        \"“Reliable graph neural networks via robust aggregation\",\n        \"“A graph placement methodology for fast chip design\",\n        \"“Geometric graph representation learning on protein structure prediction\",\n        \"“Discovering invariant rationales for graph neural networks\",\n        \"“Counterfactual graphs for explainable classification of brain networks\",\n        \"“Jointly attacking graph neural network and its explanations\",\n        \"“Interpretability in graph neural networks\",\n        \"Interpretable machine learning. Lulu. com\",\n        \"“Network motifs: simple building blocks of complex networks\",\n        \"“XGNN: towards model-level explanations of graph neural networks\",\n        \"“Substructure assembling network for graph classification\",\n        \"“Exact and consistent interpretation for piecewise linear neural networks: A closed form solution\",\n        \"“Graphlime: Local interpretable model explanations for graph neural networks\",\n        \"“Robust counterfactual explanations on graph neural networks\",\n        \"“Feature visualization\",\n        \"“Learning to explain: An information-theoretic perspective on model interpretation\",\n        \"J. Aguilera-Iparraguirre\",\n        \"“Towards explainable representation of time-evolving graphs via spatial-temporal graph attention networks\",\n        \"“Towards self-explainable graph neural network\",\n        \"“Protgnn: Towards self-explaining graph neural networks\",\n        \"“Motif-driven contrastive learning of graph representations\",\n        \"“Graph information bottleneck for subgraph recognition\",\n        \"“Explainability techniques for graph convolutional networks\",\n        \"“Improving molecular graph neural network explainability with orthonormalization and induced sparsity\",\n        \"“N2N: network derivative mining\",\n        \"“Discerning edge influence for network embedding\",\n        \"“Causal screening to interpret graph neural networks\",\n        \"“Pgm-explainer: Probabilistic graphical model explanations for graph neural networks\",\n        \"“Higher-order explanations of graph neural networks via relevant walks\",\n        \"“Reinforcement learning enhanced explainer for graph neural networks\",\n        \"“Orphicx: A causality-inspired latent variable model for interpreting graph neural networks\",\n        \"“DEGREE: Decomposition based explanation for graph neural networks\",\n        \"“Generative causal explanations for graph neural networks\",\n        \"“Axiomatic attribution for deep networks\",\n        \"“Learning important features through propagating activation differences\",\n        \"“Cxplain: Causal explanations for model interpretation under uncertainty\",\n        \"“Hard masking for explaining graph neural networks\",\n        \"“Interpreting graph neural networks for NLP with differentiable edge masking\",\n        \"“On explainability of graph neural networks via subgraph explorations\",\n        \"“Cf-gnnexplainer: Counterfactual explanations for graph neural networks\",\n        \"“Towards multi-grained explainability for graph neural networks\",\n        \"“Learning and evaluating graph neural network explanations based on counterfactual and factual reasoning\",\n        \"“Relex: A model-agnostic relational model explainer\",\n        \"“Sanity checks for saliency maps\",\n        \"“Real time image saliency for black box classifiers\",\n        \"“Edge-cloud polarization and collaboration: A comprehensive survey\",\n        \"“Automatic detection of COVID-19 vaccine misinformation with graph link prediction\",\n        \"“A dual heterogeneous graph attention network to improve long-tail performance for shop search in e-commerce\",\n        \"“Personalized bundle recommendation in online games\",\n        \"“Pre-training of graph augmented transformers for medication recommendation\",\n        \"“Inheritance-guided hierarchical assignment for clinical automatic diagnosis\",\n        \"“Quantifying privacy leakage in graph embedding\",\n        \"“Inference attacks against graph neural networks\",\n        \"“Learning discrete structures for graph neural networks\",\n        \"“Membership inference attacks on knowledge graphs\",\n        \"“Graphmi: Extracting private graph data from graph neural networks\",\n        \"“Linkteller: Recovering private edges from graph neural networks via influence analysis\",\n        \"“Advances and open problems in federated learning\",\n        \"“Federated graph learning - A position paper\",\n        \"“kgcn: a graph-based deep learning framework for chemical structures\",\n        \"“Federated graph neural networks: Overview\",\n        \"“Federated machine learning: Concept and applications\",\n        \"“Graphfl: A federated learning framework for semi-supervised node classification on graphs\",\n        \"“ASFGNN: automated separated-federated graph neural network\",\n        \"“Financial risk analysis for smes with graph-based supply chain mining\",\n        \"” https://www.webank.it/webankpub/wbresp/home.do\",\n        \"” https://inv-veri.chinatax.gov.cn/\",\n        \"“Tencent’s webank applying “federated learning” in a.i. - digital finance\",\n        \"“Federated dynamic graph neural networks with secure aggregation for video-based distributed surveillance\",\n        \"“Federated graph classification over non-iid graphs\",\n        \"“A federated multigraph integration approach for connectional brain template learning\",\n        \"“Federated learning of molecular properties in a heterogeneous setting\",\n        \"“STFL: A temporal-spatial federated learning framework for graph neural networks\",\n        \"“Fedgnn: Federated graph neural network for privacy-preserving recommendation\",\n        \"“Federated social recommendation with graph neural network\",\n        \"“A vertical federated learning framework for graph convolutional network\",\n        \"“Vertically federated graph neural network for privacy-preserving node classification\",\n        \"“Fedgl: Federated graph learning framework with global self-supervision\",\n        \"“Cross-node federated graph neural network for spatio-temporal data modeling\",\n        \"“Subgraph federated learning with missing neighbor generation\",\n        \"“Fedgraph: Federated graph learning with intelligent sampling\",\n        \"“Towards representation identical privacy-preserving graph neural network via split learning\",\n        \"“Federated learning with non-iid data\",\n        \"“Adaptive laplace mechanism: Differential privacy preservation in deep learning\",\n        \"“Locally private graph neural networks\",\n        \"“DPNE: differentially private network embedding\",\n        \"“Graph embedding for recommendation against attribute inference attacks\",\n        \"“Information obfuscation of graph neural networks\",\n        \"“Adversarial privacy-preserving graph embedding against inference attack\",\n        \"verifiable and private execution of neural networks in trusted hardware\",\n        \"“Darknetz: towards model privacy at the edge using trusted execution environments\",\n        \"“Privcoll: Practical privacy-preserving collaborative machine learning\",\n        \"“Glyph: Fast and accurately training deep neural networks on encrypted data\",\n        \"“Secureml: A system for scalable privacy-preserving machine learning\",\n        \"“Leia: A lightweight cryptographic neural network inference system at the edge\",\n        \"“Aggregation service for federated learning: An efficient\",\n        \"“Federated learning: Challenges\",\n        \"“An efficient 3-party framework for privacy-preserving neural network inference\",\n        \"“Deep leakage from gradients\",\n        \"“See through gradients: Image batch recovery via gradinversion\",\n        \"“R-GAP: recursive gradient attack on privacy\",\n        \"“How do fairness definitions fare?: Examining public attitudes towards algorithmic definitions of fairness\",\n        \"“Fairwalk: Towards fair graph embedding\",\n        \"“Counterfactual fairness\",\n        \"“Fairness definitions explained\",\n        \"“Fairness through awareness\",\n        \"“Fair graph mining\",\n        \"“Explainable and non-explainable discrimination in classification\",\n        \"“Fairness under unawareness: Assessing disparity when protected class is unobserved\",\n        \"“A causal framework for discovering and removing direct and indirect discrimination\",\n        \"“No free lunch theorems for optimization\",\n        \"“Compositional fairness constraints for graph embeddings\",\n        \"“Signature verification using a siamese time delay neural network\",\n        \"“EDITS: modeling and mitigating data bias for graph neural networks\",\n        \"“Anomaly detection in dynamic graphs via transformer\",\n        \"“Graph neural networks for graphs with heterophily: A survey\",\n        \"“Algorithmic decision making and the cost of fairness\",\n        \"“Rawlsgcn: Towards rawlsian difference principle on graph convolutional network\",\n        \"“Lightning: Striking the secure isolation on GPU clouds with transient hardware faults\",\n        \"“Accountability in computing: Concepts and mechanisms\",\n        \"“Europe fit for the digital age: Commission proposes new rules and actions for excellence and trust in artificial intelligence\",\n        \"“A novel genetic algorithm with hierarchical evaluation strategy for hyperparameter optimisation of graph neural networks\",\n        \"“Bag of tricks of semi-supervised classification with graph neural networks\",\n        \"“Bag of tricks for training deeper graph neural networks: A comprehensive benchmark study\",\n        \"“A fair comparison of graph neural networks for graph classification\",\n        \"“HASHTAG: hash signatures for online detection of fault-injection attacks on deep neural networks\",\n        \"“Sensitive-sample fingerprinting of deep neural networks\",\n        \"V. Chandrasekaran\",\n        \"“Proof of learning (pole): Empowering machine learning with consensus building on blockchains (demo)\",\n        \"“Energy and policy considerations for deep learning in NLP\",\n        \"“Open graph benchmark: Datasets for machine learning on graphs\",\n        \"“Dropedge: Towards deep graph convolutional networks on node classification\",\n        \"“Learned low precision graph neural networks\",\n        \"“Tinygnn: Learning efficient graph neural networks\",\n        \"J. Fernández-Marqués\",\n        \"“Accelerating large scale real-time GNN inference using channel pruning\",\n        \"“Efficient data loader for fast sampling-based GNN training on large graphs\",\n        \"“DGCL: an efficient communication library for distributed GNN training\",\n        \"“Hygcn: A GCN accelerator with hybrid architecture\",\n        \"“Brief industry paper: optimizing memory efficiency of graph neural networks on edge computing platforms\",\n        \"“Graphvite: A high-performance CPU-GPU hybrid system for node embedding\",\n        \"“Gnnautoscale: Scalable and expressive graph neural networks via historical embeddings\",\n        \"A. Sanchez-Gonzalez\",\n        \"“On self-distilling graph neural network\",\n        \"“Graph-free knowledge distillation for graph neural networks\",\n        \"“A unified lottery ticket hypothesis for graph neural networks\",\n        \"“Binary graph neural networks\",\n        \"“Fast graph representation learning with PyTorch Geometric\",\n        \"“Deep graph library: Towards efficient and scalable deep learning on graphs\",\n        \"“Engn: A high-throughput and energy-efficient accelerator for large graph neural networks\",\n        \"“Characterizing and understanding gcns on GPU\",\n        \"“Alleviating irregularity in graph analytics acceleration: a hardware/software co-design approach\",\n        \"” in USENIX Security Symposium. USENIX Association\",\n        \"“Differentially private federated knowledge graphs embedding\",\n        \"“Discrete-valued neural communication\",\n        \"“Defensevgae: Defending against adversarial attacks on graph data via a variational graph autoencoder\",\n        \"“Extract the knowledge of graph neural networks and go beyond it: An effective knowledge distillation framework\",\n        \"“Topological uncertainty: Monitoring trained neural networks through persistence of activation graphs\",\n        \"“Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks\",\n        \"efficient and scalable graph embedding\",\n        \"“Graph neural architecture search\",\n        \"“Distilling knowledge from graph convolutional networks\",\n        \"“Designing adaptive neural networks for energy-constrained image classification\",\n        \"“Automated machine learning on graphs: A survey\",\n        \"“G-cos: Gnn-accelerator co-search towards both better accuracy and efficiency\",\n        \"“BSQ: exploring bit-level sparsity for mixed-precision neural network quantization\",\n        \"“Towards unsupervised deep graph structure learning\",\n        \"“A theory of justice\",\n        \"” https://research.ibm.com/teams/trusted-ai#tools\",\n        \"“Tudataset: A collection of benchmark datasets for learning with graphs\",\n        \"“Be confident! towards trustworthy graph neural networks via confidence calibration\",\n        \"“Deep graph library: A graph-centric\",\n        \"“Graphgallery: A platform for fast benchmarking and easy development of graph neural networks based intelligent software\",\n        \"“OGB-LSC: A large-scale challenge for machine learning on graphs\",\n        \"“Bursting the filter bubble: Fairness-aware network link prediction\"\n    ],\n    \"reasoning\": \"Selected these 297 references because they represent foundational work and recent advances in Trustworthy Graph Neural Networks: Aspects, Methods and Trends, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}