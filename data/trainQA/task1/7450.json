{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 52 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Explainable and Safe Reinforcement Learning for Autonomous Air Mobility\n\nPaper Abstract: Abstract Increasing traffic demands, higher levels of automation, and communication enhancements provide novel design opportunities for future air traffic controllers (ATCs). This article presents a novel deep reinforcement learning (DRL) controller to aid conflict resolution for autonomous free flight. Although DRL has achieved important advancements in this field, the existing works pay little attention to the explainability and safety issues related to DRL controllers, particularly the safety under adversarial attacks. To address those two issues, we design a fully explainable DRL framework wherein we: i) decompose the coupled Q value learning model into a safety-awareness and efficiency (reach the target) one; and ii) use information from surrounding intruders as inputs, eliminating the needs of central controllers. In our simulated experiments, we show that by decoupling the safety-awareness and efficiency, we can exceed performance on free flight control tasks while dramatically improving explainability on practical. In addition, the safety Q learning module provides rich information about the safety situation of environments. To study the safety under adversarial attacks, we additionally propose an adversarial attack strategy that can impose both safety-oriented and efficiency-oriented attacks. The adversarial aims to minimize safety/efficiency by only attacking the agent at a few time steps. In the experiments, our attack strategy increases as many collisions as the uniform attack (i.e., attacking at every time step) by only attacking the agent four times less often, which provide insight into the capabilities and restrictions of the DRL in future ATC designs. The source code is publicly available at https://github.com/WLeiiiii/Gym-ATC-Attack-Project.\n\n{retrieved_text}\n\nGenerate exactly 52 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 52\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Faa aerospace forecast: Fiscal years 2020–2040\",\n        \"Blueprint for the sky: The roadmap for the safe integration of autonomous aircraft\",\n        \"Designing for safety: the ‘free flight’air traffic management concept\",\n        \"Cost-benefit study of free flight with airborne separation assurance\",\n        \"Conflict detection and resolution for free flight\",\n        \"Multi-aircraft conflict detection and resolution based on probabilistic reach sets\",\n        \"Automatic aircraft conflict resolution using genetic algorithms\",\n        \"A strategic flight conflict avoidance approach based on a memetic algorithm\",\n        \"A two-step approach for airborne delay minimization using pretactical conflict resolution in free-route airspace\",\n        \"Research on civil aircraft conflict resolution based on tbo\",\n        \"Ant colony optimization for air traffic conflict resolution\",\n        \"Optimal strategies for free-flight air traffic conflict resolution\",\n        \"Large scale aircraft conflict resolution based on location network\",\n        \"Conflict resolution for multi-agent hybrid systems\",\n        \"Hybrid control in air traffic management systems\",\n        \"Human-level control through deep reinforcement learning\",\n        \"Autonomous aircraft sequencing and separation with hierarchical deep reinforcement learning\",\n        \"A machine learning approach for conflict resolution in dense traffic scenarios with uncertainties\",\n        \"Distributed computational guidance for high-density urban air mobility with cooperative and non-cooperative collision avoidance\",\n        \"One to any: Distributed conflict resolution with deep multi-agent reinforcement learning and long short-term memory\",\n        \"Uav’s applications, architecture, security issues and attack scenarios: a survey\",\n        \"Intriguing properties of neural networks\",\n        \"Synthesizing robust adversarial examples\",\n        \"Experimental security research of tesla autopilot\",\n        \"Context-aware symptom checking for disease diagnosis using hierarchical reinforcement learning\",\n        \"Deep reinforcement learning for autonomous driving: A survey\",\n        \"Mastering the game of go with deep neural networks and tree search\",\n        \"Dota 2 with large scale deep reinforcement learning\",\n        \"An interactive conflict solver for learning air traffic conflict resolutions\",\n        \"Improvement of conflict detection and resolution at high densities through reinforcement learning\",\n        \"Physics informed deep reinforcement learning for aircraft conflict resolution\",\n        \"Scalable multi-agent computational guidance with separation assurance for autonomous urban air mobility\",\n        \"An autonomous free airspace en-route controller using deep reinforcement learning techniques\",\n        \"Autonomous separation assurance in an high-density en route sector: A deep multi-agent reinforcement learning approach\",\n        \"A deep multi-agent reinforcement learning approach to autonomous separation assurance\",\n        \"Adversarial attacks on neural network policies\",\n        \"Vulnerability of deep reinforcement learning to policy induction attacks\",\n        \"Playing atari with deep reinforcement learning\",\n        \"Trust region policy optimization\",\n        \"Asynchronous methods for deep reinforcement learning\",\n        \"Robust deep reinforcement learning with adversarial attacks\",\n        \"Stealthy and efficient adversarial attacks against deep reinforcement learning\",\n        \"Delving into adversarial attacks on deep policies\",\n        \"Tactics of adversarial attack on deep reinforcement learning agents\",\n        \"Enhanced adversarial strategically-timed attacks against deep reinforcement learning\",\n        \"Strategically-timed state-observation attacks on deep reinforcement learning agents\",\n        \"Optimal attacks on reinforcement learning policies\",\n        \"Whatever does not kill deep reinforcement learning, makes it stronger\",\n        \"What matters in on-policy reinforcement learning? a large-scale empirical study\",\n        \"Autonomous on-demand free flight operations in urban air mobility using monte carlo tree search\",\n        \"Dueling network architectures for deep reinforcement learning\",\n        \"Flocks, herds and schools: A distributed behavioral model\"\n    ],\n    \"reasoning\": \"Selected these 52 references because they represent foundational work and recent advances in Explainable and Safe Reinforcement Learning for Autonomous Air Mobility, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}