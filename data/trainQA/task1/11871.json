{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 61 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Quantum computational complexity of matrix functions\n\nPaper Abstract: Abstract We investigate the dividing line between classical and quantum computational power in estimating properties of matrix functions. More precisely, we study the computational complexity of two primitive problems: given a function fùëìf and a Hermitian matrix Aùê¥A, compute a matrix element of f‚Äã(A)ùëìùê¥f(A) or compute a local measurement on f‚Äã(A)‚Äã|0‚ü©‚äónùëìùê¥superscriptket0tensor-productabsentùëõf(A)|0\\rangle^{\\otimes n}, with |0‚ü©‚äónsuperscriptket0tensor-productabsentùëõ|0\\rangle^{\\otimes n} an nùëõn-qubit reference state vector, in both cases up to additive approximation error. We consider four functions ‚Äî monomials, Chebyshev polynomials, the time evolution function, and the inverse function ‚Äî and probe the complexity across a broad landscape covering different problem input regimes. Namely, we consider two types of matrix inputs (sparse and Pauli access), matrix properties (norm, sparsity), the approximation error, and function-specific parameters. We identify BQP-complete forms of both problems for each function and then toggle the problem parameters to easier regimes to see where hardness remains, or where the problem becomes classically easy. As part of our results we make concrete a hierarchy of hardness across the functions; in parameter regimes where we have classically efficient algorithms for monomials, all three other functions remain robustly BQP-hard, or hard under usual computational complexity assumptions. In identifying classically easy regimes, among others, we show that for any polynomial of degree poly‚Å°(n)polyùëõ\\operatorname{poly}\\!\\left(n\\right) both problems can be efficiently classically simulated when Aùê¥A has ùí™‚Äã(log‚Å°n)ùí™ùëõ\\mathcal{O}(\\log n) non-zero coefficients in the Pauli basis. This contrasts with the fact that the problems are BQP-complete in the sparse access model even for constant row sparsity, whereas the stated Pauli access efficiently constructs sparse access with row sparsity ùí™‚Äã(log‚Å°n)ùí™ùëõ\\mathcal{O}(\\log n). Our work provides a catalog of efficient quantum and classical algorithms for fundamental linear-algebra tasks.\n\n{retrieved_text}\n\nGenerate exactly 61 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 61\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Hamiltonian Simulation by Qubitization\",\n        \"Quantum singular value transformation and beyond: Exponential improvements for quantum matrix arithmetics\",\n        \"Grand Unification of Quantum Algorithms\",\n        \"Product Decomposition of Periodic Functions in Quantum Signal Processing\",\n        \"Heisenberg-Limited Ground-State Energy Estimation for Early Fault-Tolerant Quantum Computers\",\n        \"Fourier-based quantum signal processing\",\n        \"Quantum algorithm for ground state energy estimation using circuit depth with exponentially improved dependence on precision\",\n        \"Faster ground state energy estimation on early fault-tolerant quantum computers via rejection sampling\",\n        \"Linear combination of Hamiltonian simulation for nonunitary dynamics with optimal state preparation cost\",\n        \"Quantum algorithm for linear non-unitary dynamics with near-optimal dependence on all parameters\",\n        \"Quantum eigenvalue processing\",\n        \"Circuit complexity of quantum access models for encoding classical data\",\n        \"Random Compiler for Fast Hamiltonian Simulation\",\n        \"Randomized Quantum Algorithm for Statistical Phase Estimation\",\n        \"Qubit-efficient randomized quantum algorithms for linear algebra\",\n        \"qSWIFT: High-order randomized compiler for Hamiltonian simulation\",\n        \"Quantum algorithm for linear systems of equations\",\n        \"Quantum and classical query complexities of functions of matrices\",\n        \"Dequantizing algorithms to understand quantum advantage in machine learning\",\n        \"Dequantizing the quantum singular value transformation: hardness and applications to quantum chemistry and the quantum PCP conjecture\",\n        \"Guest column: the quantum PCP conjecture\",\n        \"Faster Algorithms via Approximation Theory\",\n        \"Quantum Algorithm for Systems of Linear Equations with Exponentially Improved Dependence on Precision\",\n        \"Randomized semi-quantum matrix processing\",\n        \"Quantum walks, the discrete wave equation and Chebyshev polynomials\",\n        \"A simple PromiseBQP-complete matrix problem\",\n        \"A (simple) classical algorithm for estimating Betti numbers\",\n        \"Quantum Mechanical Computers\",\n        \"Fast universal quantum computation with railroad-switch local Hamiltonians\",\n        \"A Quantum-Inspired Classical Algorithm for Recommendation Systems\",\n        \"Quantum Principal Component Analysis Only Achieves an Exponential Speedup Because of Its State Preparation Assumptions\",\n        \"An improved quantum-inspired algorithm for linear regression\",\n        \"Sampling-Based Sublinear Low-Rank Matrix Arithmetic Framework for Dequantizing Quantum Machine Learning\",\n        \"Faster Quantum-Inspired Algorithms for Solving Linear Systems\",\n        \"Classical approximation schemes for the ground-state energy of quantum and classical ising spin hamiltonians on planar graphs\",\n        \"Logarithmic depth circuits for algebraic functions\",\n        \"Logical reversibility of computation\",\n        \"Arithmetic circuits: A survey of recent results and open questions\",\n        \"A Comprehensive Study of Quantum Arithmetic Circuits\",\n        \"Parallel Quantum Algorithm for Hamiltonian Simulation\",\n        \"BQP-complete problems concerning mixing properties of classical random walks on sparse graphs\",\n        \"Simulating physics with computers\",\n        \"Reversible logic and quantum computers\",\n        \"Simulating Hamiltonian Dynamics with a Truncated Taylor Series\",\n        \"Quantum walks: a comprehensive review\",\n        \"Quantum Power Method by a Superposition of Time-Evolved States\",\n        \"Hamiltonian Operator Approximation for Energy Measurement and Ground-State Preparation\",\n        \"Exact and efficient Lanczos method on a quantum computer\",\n        \"Partitioned Quantum Subspace Expansion\",\n        \"Adiabatic Quantum State Generation\",\n        \"Efficient Quantum Algorithms for Simulating Sparse Hamiltonians\",\n        \"Quantum measurements and the Abelian stabilizer problem\",\n        \"Quantum computation and quantum information\",\n        \"Lecture notes on quantum algorithms for scientific computation\",\n        \"Quantum Amplitude Amplification and Estimation\",\n        \"Optimal Hamiltonian Simulation by Quantum Signal Processing\",\n        \"Mixing times of markov chains: techniques and examples\",\n        \"Quantum Fingerprinting\",\n        \"Recovering low-rank matrices from few coefficients in any basis\",\n        \"Estimates of operator moduli of continuity\",\n        \"Sur une question pos√©e par Mendeleieff,\"\n    ],\n    \"reasoning\": \"Selected these 61 references because they represent foundational work and recent advances in Quantum computational complexity of matrix functions, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}