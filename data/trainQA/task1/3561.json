{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 46 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: HyCA: A Hybrid Computing Architecture for Fault Tolerant Deep Learning\n\nPaper Abstract: Abstract Hardware faults on the regular 2-D computing array of a typical deep learning accelerator (DLA) can lead to dramatic prediction accuracy loss. Prior redundancy design approaches typically have each homogeneous redundant processing element (PE) to mitigate faulty PEs for a limited region of the 2-D computing array rather than the entire computing array to avoid the excessive hardware overhead. However, they fail to recover the computing array when the number of faulty PEs in any region exceeds the number of redundant PEs in the same region. The mismatch problem deteriorates when the fault injection rate rises and the faults are unevenly distributed. To address the problem, we propose a hybrid computing architecture (HyCA) for fault-tolerant DLAs. It has a set of dot-production processing units (DPPUs) to recompute all the operations that are mapped to the faulty PEs despite the faulty PE locations. According to our experiments, HyCA shows significantly higher reliability, scalability, and performance with less chip area penalty when compared to the conventional redundancy approaches. Moreover, by taking advantage of the flexible recomputing, HyCA can also be utilized to scan the entire 2-D computing array and detect the faulty PEs effectively at runtime.\n\n{retrieved_text}\n\nGenerate exactly 46 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 46\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Deep Learning-Based Multi-scale Multi-object Detection and Classification for Autonomous Driving\",\n        \"Human Crowd Detection for Drone Flight Safety Using Convolutional Neural Networks\",\n        \"A Guide to Deep Learning in Healthcare\",\n        \"Towards a Bayesian Approach for Assessing Fault Tolerance of Deep Neural Networks\",\n        \"ML-Based Fault Injection for Autonomous Vehicles: A Case for Bayesian Fault Injection\",\n        \"Challenges of Reliability Assessment and Enhancement in Autonomous Systems\",\n        \"Dadiannao: A Machine-learning Supercomputer\",\n        \"A Hybrid Computing Architecture for Fault-tolerant Deep Learning Accelerators\",\n        \"Minerva: Enabling Low-power, Highly-accurate Deep neural Network Accelerators\",\n        \"The Impact of New Technology on Soft Error Rates\",\n        \"A Survey on Modeling and Improving Reliability of DNN Algorithms and Accelerators\",\n        \"In-datacenter Performance Analysis of A Tensor Processing Unit\",\n        \"Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks\",\n        \"Retraining-based timing error mitigation for hardware neural networks\",\n        \"Fault-Tolerant Systolic Array Based Accelerators for Deep Neural Network Execution\",\n        \"Resilient Neural Network Training for Accelerators with Computing Errors\",\n        \"Squeezing the Last MHz for CNN Acceleration on FPGAs\",\n        \"Validation of Autonomous Systems\",\n        \"A Built-in Circuit for Self-Repairing Mesh-Connected Processor Arrays by Direct Spare Replacement\",\n        \"A Built-in Circuit for Self-Repairing Mesh-Connected Processor Arrays with Spares on Diagonal\",\n        \"Reliability Evaluation and Analysis of FPGA-Based Neural Network Acceleration System\",\n        \"Persistent Fault Analysis of Neural Networks on FPGA-based Acceleration System\",\n        \"Ftt-nas: Discovering fault-tolerant neural architecture\",\n        \"Error Resilience Analysis for Systematically Employing Approximate Computing in Convolutional Neural Networks\",\n        \"Energy-Efficient Neural Network Acceleration in the Presence of Bit-Level Memory Errors\",\n        \"Joint Design of Training and Hardware Towards Efficient and Accuracy-Scalable Neural Network Inference\",\n        \"Resilience-aware Frequency Tuning for Neural-network-based Approximate Computing Chips\",\n        \"Analyzing and Mitigating the Impact of Permanent Faults on a Systolic Array based Neural Network Accelerator\",\n        \"Salvagednn: Salvaging Deep Neural Network Accelerators with Permanent Faults Through Saliency-driven Fault-aware Mapping\",\n        \"Fault-tolerant Processor Arrays Based on the 1 1/2-track Switches with Flexible Spare Distributions\",\n        \"Integrated Circuit Yield Statistics\",\n        \"Sanity-Check: Boosting the reliability of safety-critical deep neural network applications\",\n        \"Algorithm-Based Fault Tolerance for Convolutional Neural Networks\",\n        \"When Sorting Network Meets Parallel Bitstreams: A Fault-tolerant Parallel Ternary Neural Network Accelerator Based on Stochastic Computing\",\n        \"Soft Error Mitigation for Deep Convolution Neural Network on FPGA Accelerators\",\n        \"Relaxed Fault-tolerant Hardware Implementation of Neural Networks in the Presence of Multiple Transient Errors\",\n        \"A Reliability Study on CNNs for Critical Embedded Systems\",\n        \"Ares: A framework for Quantifying the Resilience of Deep Neural Networks\",\n        \"Imagenet: A Large-scale Hierarchical Image Database\",\n        \"Energy Efficient Asymmetrically Ported Register Files\",\n        \"A 4R/2W Register File Design for UDVS Microprocessors in 65-nm CMOS\",\n        \"Modeling Defect Spatial Distribution\",\n        \"A resilient on-chip router design through data path salvaging\",\n        \"Understanding the propagation of hard errors to software and implications for resilient system design\",\n        \"Optimal Reconfiguration of High-performance VLSI Subarrays with Network Flow\",\n        \"Scale-sim: Systolic CNN Accelerator Simulator\"\n    ],\n    \"reasoning\": \"Selected these 46 references because they represent foundational work and recent advances in HyCA: A Hybrid Computing Architecture for Fault Tolerant Deep Learning, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}