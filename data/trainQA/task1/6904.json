{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 54 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Reconstruction-guided attention improves the robustness and shape processing of neural networks\n\nPaper Abstract: Abstract Many visual phenomena suggest that humans use top-down generative or reconstructive processes to create visual percepts (e.g., imagery, object completion, pareidolia), but little is known about the role reconstruction plays in robust object recognition. We built an iterative encoder-decoder network that generates an object reconstruction and used it as top-down attentional feedback to route the most relevant spatial and feature information to feed-forward object recognition processes. We tested this model using the challenging out-of-distribution digit recognition dataset, MNIST-C, where 15 different types of transformation and corruption are applied to handwritten digit images. Our model showed strong generalization performance against various image perturbations, on average outperforming all other models including feedforward CNNs and adversarially trained networks. Our model is particularly robust to blur, noise, and occlusion corruptions, where shape perception plays an important role. Ablation studies further reveal two complementary roles of spatial and feature-based attention in robust object recognition, with the former largely consistent with spatial masking benefits in the attention literature (the reconstruction serves as a mask) and the latter mainly contributing to the model’s inference speed (i.e., number of time steps to reach a certain confidence threshold) by reducing the space of possible object hypotheses. We also observed that the model sometimes hallucinates a non-existing pattern out of noise, leading to highly interpretable human-like errors. Our study shows that modeling reconstruction-based feedback endows AI systems with a powerful attention mechanism, which can help us understand the role of generating perception in human visual processing.\n\n{retrieved_text}\n\nGenerate exactly 54 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 54\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Recurrent Attention Models with Object-centric Capsule Representation for Multi-object Recognition\",\n        \"Contrast sensitivity in human visual areas and its relationship to object recognition\",\n        \"Deep convolutional networks do not classify based on global object shape\",\n        \"Top-down facilitation of visual recognition\",\n        \"A Cortical Mechanism for Triggering Top-Down Facilitation in Visual Object Recognition\",\n        \"Simulation as an engine of physical scene understanding\",\n        \"Top-down and bottom-up mechanisms in biasing competition in the human brain\",\n        \"Recognition-by-components: a theory of human image understanding\",\n        \"Integrated model of visual processing\",\n        \"A neural theory of visual attention and short-term memory (NTVA)\",\n        \"Generative pretraining from pixels\",\n        \"Object-based attention: A tutorial review\",\n        \"Whatever next? Predictive brains, situated agents, and the future of cognitive science\",\n        \"The Helmholtz Machine\",\n        \"How Do Expectations Shape Perception?\",\n        \"Neural mechanisms of selective visual attention\",\n        \"How does the brain combine generative models and direct discriminative computations in high-level vision?\",\n        \"Generalization and Robustness Implications in Object-Centric Learning\",\n        \"A Study and Comparison of Human and Deep Learning Recognition Performance Under Visual Distortions\",\n        \"Selective attention and the organization of visual information\",\n        \"ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness\",\n        \"Partial success in closing the gap between human and machine vision\",\n        \"The Generative Adversarial Brain\",\n        \"On the Binding Problem in Artificial Neural Networks\",\n        \"Deep residual learning for image recognition\",\n        \"Masked Autoencoders Are Scalable Vision Learners\",\n        \"Matrix capsules with EM routing\",\n        \"Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior\",\n        \"Adam: A method for stochastic optimization\",\n        \"Object-centric learning with slot attention\",\n        \"Towards deep learning models resistant to adversarial attacks\",\n        \"Vision: A computational investigation into the human representation and processing of visual information\",\n        \"Feature-based attention in visual cortex\",\n        \"MNIST-C: A Robustness Benchmark for Computer Vision\",\n        \"Visual object representation: Interpreting neurophysiological data within a computational framework\",\n        \"Orienting of attention\",\n        \"Beyond core object recognition: Recurrent processes account for object recognition under occlusion\",\n        \"Semi-supervised learning with ladder networks\",\n        \"Brain mechanisms for invariant visual recognition and learning\",\n        \"Dynamic routing between capsules\",\n        \"Objects and attention: The state of the art\",\n        \"Towards the first adversarially robust neural network model on MNIST\",\n        \"Recurrent neural networks can explain flexible trading of speed and accuracy in biological vision\",\n        \"Intriguing properties of neural networks\",\n        \"When does human object recognition use a viewer-centered reference frame?\",\n        \"Capsules with inverted dot-product attention routing\",\n        \"Aligning pictorial descriptions: An approach to object recognition\",\n        \"Effects of illumination intensity and direction on object coding in macaque inferior temporal cortex\",\n        \"Dorsal and Ventral Attention Systems: Distinct Neural Circuits but Collaborative Roles\",\n        \"Esrgan: Enhanced super-resolution generative adversarial networks\",\n        \"The Role of Competitive Inhibition and Top-Down Feedback in Binding during Object Recognition\",\n        \"Efficient inverse graphics in biological face processing\",\n        \"Vision as Bayesian inference: analysis by synthesis?\",\n        \"Capsule Networks with Max-Min Normalization\"\n    ],\n    \"reasoning\": \"Selected these 54 references because they represent foundational work and recent advances in Reconstruction-guided attention improves the robustness and shape processing of neural networks, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}