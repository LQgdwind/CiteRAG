{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 61 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments\n\nPaper Abstract: Abstract We consider three important challenges in conference peer review: (i) reviewers maliciously attempting to get assigned to certain papers to provide positive reviews, possibly as part of quid-pro-quo arrangements with the authors; (ii) “torpedo reviewing,” where reviewers deliberately attempt to get assigned to certain papers that they dislike in order to reject them; (iii) reviewer de-anonymization on release of the similarities and the reviewer-assignment code. On the conceptual front, we identify connections between these three problems and present a framework that brings all these challenges under a common umbrella. We then present a (randomized) algorithm for reviewer assignment that can optimally solve the reviewer-assignment problem under any given constraints on the probability of assignment for any reviewer-paper pair. We further consider the problem of restricting the joint probability that certain suspect pairs of reviewers are assigned to certain papers, and show that this problem is NP-hard for arbitrary constraints on these joint probabilities but efficiently solvable for a practical special case. Finally, we experimentally evaluate our algorithms on datasets from past conferences, where we observe that they can limit the chance that any malicious reviewer gets assigned to their desired paper to 50%percent5050\\% while producing assignments with over 90%percent9090\\% of the total optimal similarity. Our algorithms still achieve this similarity while also preventing reviewers with close associations from being assigned to the same paper.\n\n{retrieved_text}\n\nGenerate exactly 61 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 61\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Peer review in a changing world: An international study measuring the attitudes of researchers\",\n        \"Peer review: Still king in the digital age\",\n        \"Peer review: Benefits, perceptions and alternatives\",\n        \"The Matthew effect in science\",\n        \"Potential organized fraud in ACM/IEEE computer architecture conferences\",\n        \"Publishing: The peer-review scam\",\n        \"Retractions: Stamp out fake peer review\",\n        \"Bidding problems\",\n        \"Safeguarding the integrity of science communication by restraining ’rational cheating’ in peer review\",\n        \"Mechanism change in a simulation of peer review: From junk support to elitism\",\n        \"I hate your paper. Many say the peer review system is broken. Here’s how some journals are trying to fix it\",\n        \"How to break anonymity of the Netflix Prize dataset\",\n        \"The Toronto Paper Matching System: An automated paper-reviewer assignment system\",\n        \"A framework for optimizing paper matching\",\n        \"On good and fair paper-reviewer assignment\",\n        \"The AI conference paper assignment problem\",\n        \"Expertise matching via constraint-based optimization\",\n        \"Novel tools to streamline the conference review process: Experiences from SIGKDD’09\",\n        \"The conference paper assignment problem: Using order weighted averages to assign indivisible goods\",\n        \"Paper matching with local fairness constraints\",\n        \"Assigning papers to referees\",\n        \"PeerReview4All: Fair and accurate reviewer assignment in peer review\",\n        \"A Bayesian model for calibrating conference review scores\",\n        \"Loss functions, axioms, and peer review\",\n        \"Your 2 is my 1, your 3 is my 9: Handling arbitrary miscalibrations in ratings\",\n        \"A SUPER* algorithm to optimize paper bidding in peer review\",\n        \"How to calibrate the scores of biased reviewers by quadratic programming\",\n        \"On testing for biases in peer review\",\n        \"The NIPS experiment\",\n        \"Design and analysis of the NIPS 2016 review process\",\n        \"Reviewer bias in single- versus double-blind peer review\",\n        \"A dataset of peer reviews (PeerRead): Collection, insights and NLP applications\",\n        \"Uncovering latent biases in text: Method and application to peer review\",\n        \"Prior and prejudice: The bias against resubmissions in conference peer review\",\n        \"Catch me if I can: Detecting strategic behaviour in peer assessment\",\n        \"On strategyproof conference peer review\",\n        \"Strategyproof peer selection using randomization, partitioning, and apportionment\",\n        \"Impartial peer review\",\n        \"Ranking wily people who rank each other\",\n        \"Impartial nominations for a prize\",\n        \"On the privacy-utility tradeoff in peer-review data analysis\",\n        \"Graph based anomaly detection and description: A survey\",\n        \"FRAUDAR: Bounding graph fraud in the face of camouflage\",\n        \"REV2: Fraudulent user prediction in rating platforms\",\n        \"Review graph based online store review spammer detection\",\n        \"Opinion fraud detection in online reviews by network effects\",\n        \"Re-scale AdaBoost for attack detection in collaborative filtering recommender systems\",\n        \"Finding deceptive opinion spam by any stretch of the imagination\",\n        \"Shilling attacks against collaborative recommender systems: A review\",\n        \"The efficient allocation of individuals to positions\",\n        \"A new solution to the random assignment problem\",\n        \"Complexity of computing optimal Stackelberg strategies in security resource allocation games\",\n        \"Three observations on linear algebra\",\n        \"A certain zero-sum two-person game equivalent to the optimal assignment problem\",\n        \"Implementing random assignments : A generalization of the Birkhoff-von Neumann theorem\",\n        \"Faster dynamic matrix inverse for faster LPs\",\n        \"Reducibility among combinatorial problems\",\n        \"PrefLib: A library of preference data http://preflib.org\",\n        \"Gurobi optimizer reference manual\",\n        \"Introduction to algorithms\",\n        \"Algorithm for solution of a problem of maximum flow in networks with power estimation\"\n    ],\n    \"reasoning\": \"Selected these 61 references because they represent foundational work and recent advances in Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}