{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 49 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Model Inversion Attack against Transfer Learning: Inverting a Model without Accessing It\n\nPaper Abstract: Abstract Transfer learning is an important approach that produces pre-trained teacher models which can be used to quickly build specialized student models. However, recent research on transfer learning has found that it is vulnerable to various attacks, e.g., misclassification and backdoor attacks. However, it is still not clear whether transfer learning is vulnerable to model inversion attacks. Launching a model inversion attack against transfer learning scheme is challenging. Not only does the student model hide its structural parameters, but it is also inaccessible to the adversary. Hence, when targeting a student model, both the white-box and black-box versions of existing model inversion attacks fail. White-box attacks fail as they need the target modelâ€™s parameters. Black-box attacks fail as they depend on making repeated queries of the target model. However, they may not mean that transfer learning models are impervious to model inversion attacks. Hence, with this paper, we initiate research into model inversion attacks against transfer learning schemes with two novel attack methods. Both are black-box attacks, suiting different situations, that do not rely on queries to the target student model. In the first method, the adversary has the data samples that share the same distribution as the training set of the teacher model. In the second method, the adversary does not have any such samples. Experiments show that highly recognizable data records can be recovered with both of these methods. This means that even if a model is an inaccessible black-box, it can still be inverted.\n\n{retrieved_text}\n\nGenerate exactly 49 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 49\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"PyTorch transfer learning tutorial.\",\n        \"What Regularized Auto-Encoders Learn from the Data-Generating Distribution.\",\n        \"Amazon Rekognition.\",\n        \"Certifiably Robust Variational Autoencoders.\",\n        \"SNIFF: Reverse Engineering of Neural Networks With Fault Attacks.\",\n        \"Extracting Training Data from Large Language Models.\",\n        \"Knowledge-aware Zero-Shot Learning: Survey and Perspective.\",\n        \"Image Block Augmentation for One-Shot Learning.\",\n        \"Multi-Level Semantic Feature Augmentation for One-Shot Learning.\",\n        \"Introduction to the Calculus of Variations.\",\n        \"An MNIST-like dataset of 70,000 28x28 labeled fashion images.\",\n        \"Interpretable Explanations of Black Boxes by Meaningful Perturbation.\",\n        \"Model Inversion Attacks That Exploit Confidence Information and Basic Countermeasures.\",\n        \"Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing.\",\n        \"Inverting Gradients - How easy is it to break privacy in federated learning?\",\n        \"Regularisation of neural networks by enforcing Lipschitz continuity.\",\n        \"TransMIA: Membership Inference Attacks Using Transfer Shadow Training.\",\n        \"Model-Reuse Attacks on Deep Learning Systems.\",\n        \"Self-Supervised Visual Feature Learning with Deep Neural Networks: A Survey.\",\n        \"Lipschitz Continuous Autoencoders in Application to Anomaly Detection.\",\n        \"Adversarial Examples in the Physical World.\",\n        \"The mnist database of handwritten digits.\",\n        \"Self-supervised Learning: Generative or Contrastive.\",\n        \"Deep Learning Face Attributes in the Wild.\",\n        \"A data-driven approach to cleaning large face datasets.\",\n        \"Boosting Self-Supervised Learning via Knowledge Transfer.\",\n        \"A Target-Agnostic Attack on Deep Models: Exploiting Security Vulnerabilities of Transfer Learning.\",\n        \"Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning.\",\n        \"ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models.\",\n        \"Membership Inference Attacks against Machine Learning Models.\",\n        \"A Survey on Image Data Augmentation for Deep Learning.\",\n        \"Very deep convolutional networks for large-scale image recognition.\",\n        \"Negative Data Augmentation.\",\n        \"With Great Training Comes Great Vulnerability: Practical Attacks against Transfer Learning.\",\n        \"Backdoor Attacks against Transfer Learning with Pre-trained Deep Learning Models.\",\n        \"A Survey of Zero-Shot Learning: Settings, Methods, and Applications.\",\n        \"Low-Shot Learning from Imaginary Data.\",\n        \"Generalizing from a Few Examples: A Survey on Few-shot Learning.\",\n        \"A Survey of Transfer Learning.\",\n        \"Neural Network Inversion in Adversarial Setting via Background Knowledge Alignment.\",\n        \"Latent Backdoor Attacks on Deep Neural Networks.\",\n        \"A self-adaptive strategy for evolution of cooperation in distributed networks.\",\n        \"See through Gradients: Image Batch Recovery via GradInversion).\",\n        \"CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features.\",\n        \"The Secret Revealer: Generative Model-Inversion Attacks against Deep Neural Networks.\",\n        \"Exploiting Explanations for Model Inversion Attacks.\",\n        \"Learning Deep Features for Discriminative Localization.\",\n        \"A Comprehensive Survey on Transfer Learning.\",\n        \"Privacy Analysis of Deep Learning in the Wild: Membership Inference Attacks against Transfer Learning.\"\n    ],\n    \"reasoning\": \"Selected these 49 references because they represent foundational work and recent advances in Model Inversion Attack against Transfer Learning: Inverting a Model without Accessing It, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}