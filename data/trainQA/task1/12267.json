{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 47 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Subsampling, aligning, and averaging to find circular coordinates in recurrent time series\n\nPaper Abstract: Abstract. We introduce a new algorithm for finding robust circular coordinates on data that is expected to exhibit recurrence, such as that which appears in neuronal recordings of Caenorhabditis elegans. Techniques exist to create circular coordinates on a simplicial complex from a dimension 1 cohomology class, and these can be applied to the Rips complex of a dataset when it has a prominent class in its dimension 1 cohomology. However, it is known this approach is extremely sensitive to uneven sampling density. Our algorithm comes with a new method to correct for uneven sampling density, adapting our prior work on averaging coordinates in manifold learning. We use rejection sampling to correct for inhomogeneous sampling and then apply Procrustes matching to align and average the subsamples. In addition to providing a more robust coordinate than other approaches, this subsampling and averaging approach has better efficiency. We validate our technique on both synthetic data sets and neuronal activity recordings. Our results reveal a topological model of neuronal trajectories for C. elegans that is constructed from loops in which different regions of the brain state space can be mapped to specific and interpretable macroscopic behaviors in the worm.\n\n{retrieved_text}\n\nGenerate exactly 47 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 47\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"On the concept of space in neuroscience\",\n        \"Towards a theoretical foundation for Laplacian-based manifold methods\",\n        \"Density estimation on an unknown submanifold\",\n        \"Orthogonal Procrustes rotation for two or more matrices\",\n        \"Graph Approximations to Geodesics on Embedded Manifolds\",\n        \"A weighted kk-nearest neighbor density estimate for geometric inference\",\n        \"Resampling and averaging coordinates on data\",\n        \"The reach, metric distortion, geodesic convexity and the variation of tangent spaces\",\n        \"One dimensional approximations of neuronal dynamics reveal computation strategy\",\n        \"A quantitative model of conserved macroscopic dynamics predicts future motor commands\",\n        \"Topological methods for data modelling\",\n        \"Geometric inference for probability measures\",\n        \"The structure and stability of persistence modules\",\n        \"Adaptive, locally linear models of complex dynamics\",\n        \"A Course in Density Estimation\",\n        \"Computational topology: an introduction\",\n        \"Unsupervised learning of control signals and their encodings in Caenorhabditis elegans whole-brain recordings\",\n        \"Discriminatory Analysis. Nonparametric Discrimination: Consistency Properties\",\n        \"Toroidal topology of population activity in grid cells\",\n        \"Barcodes: The persistent topology of data\",\n        \"A Family of Density-Scaled Filtered Complexes\",\n        \"Global Brain Dynamics Embed the Motor Command Sequence of Caenorhabditis elegans\",\n        \"Estimating mutual information\",\n        \"Studying the Shape of Data Using Topology\",\n        \"Hierarchical recurrent state space models reveal discrete and continuous dynamics of neural activity in C. elegans\",\n        \"A Nonparametric Estimate of a Multivariate Density Function\",\n        \"Zigzag persistent homology in matrix multiplication time\",\n        \"Persistent (Co)Homology in Matrix Multiplication Time\",\n        \"Nonlinear Control in the Nematode C. elegans\",\n        \"Accurate estimation of the normalized mutual information of multidimensional data\",\n        \"Distributed Computation of Persistent Cohomology\",\n        \"Persistence theory: from quiver representations to data analysis\",\n        \"Circular Coordinates for Density-Robust Analysis\",\n        \"On Estimation of a Probability Density Function and Mode\",\n        \"Multiscale Projective Coordinates via Persistent Cohomology of Sparse Filtrations\",\n        \"Sparse Circular Coordinates via Principal â„¤\\\\mathbb{Z}-Bundles\",\n        \"Topological Data Analysis for Genomics and Evolution: Topology in Biology\",\n        \"Remarks on Some Nonparametric Estimates of a Desnity Function\",\n        \"Decoding of Neural Data Using Cohomological Feature Extraction\",\n        \"Spherical coordinates from persistent cohomology\",\n        \"Multivariate Density Estimation: Theory, Practice and Visualization\",\n        \"Persistent Cohomology of Circular Coordinates\",\n        \"From Geometry to Topology: Inverse Theorems for Distributed Persistence\",\n        \"Detecting strange attractors in turbulence\",\n        \"Cohomological learning of periodic motion\",\n        \"NeuroPAL: A Multicolor Atlas for Whole-Brain Neuronal Identification in C. elegans\",\n        \"Revealing neural dynamical structure of C. elegans with deep learning\"\n    ],\n    \"reasoning\": \"Selected these 47 references because they represent foundational work and recent advances in Subsampling, aligning, and averaging to find circular coordinates in recurrent time series, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}