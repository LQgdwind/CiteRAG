{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 50 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Large Language Models Empower Personalized Valuation in Auction\n\nPaper Abstract: Abstract. Auctions, a fundamental economic mechanism, encompass the valuation of goods or services and the competitive bidding algorithms within a specific framework, serving to uncover the true market value. However, current research predominantly focuses on the bidding algorithms within a given auction mechanism, often overlooking the advantages of incorporating individual bidders’ unique preferences and the semantic information related to the items into the valuation process. Our analysis, both theoretical and empirical, shows that imprecise or noisy valuations can significantly affect the overall utility for participants. To bridge this gap, we propose a personalized valuation framework, namely Semantic-enhanced Personalized Valuation in Auction (SPVA), which integrates Large Language Models (LLMs) to incorporate semantic information into each bidder’s unique valuation process. Specifically, SPVA employs a two-stage approach: it first fine-tunes LLMs to encode bidder preferences in personalized valuations, and then constructs a Vickrey auction environment integrated with a bidding algorithm to demonstrate that SPVA’s more accurate valuations result in higher profits. Additionally, we have developed a semantic-enhanced dataset comprising over 23,000 samples and introduced new personalized evaluation metrics that reflect both bidder preferences and profit. Through simulations of various auction scenarios, our method demonstrates its ability to provide accurate valuations and capture bidder preferences, affirming the method’s effectiveness in real-world auction settings.\n\n{retrieved_text}\n\nGenerate exactly 50 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 50\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Shill Bidding Dataset\",\n        \"Auto-bidding and Auctions in Online Advertising: A Survey\",\n        \"The lovely but lonely Vickrey auction\",\n        \"Distributional Robustness: From Pricing to Auctions\",\n        \"Robust Auction Design in the Auto-bidding World\",\n        \"Learning in repeated auctions with budgets: Regret minimization and equilibrium\",\n        \"Contextual Standard Auctions with Budgets: Revenue Equivalence and Efficiency Guarantees\",\n        \"An ascending vickrey auction for selling bases of a matroid\",\n        \"Envy-free allocations respecting social networks\",\n        \"Language Models are Few-Shot Learners\",\n        \"Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena\",\n        \"Advancing Ad Auction Realism: Practical Insights & Modeling Implications\",\n        \"Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets\",\n        \"Navigating by the stars: Investigating the actual and perceived validity of online user ratings\",\n        \"LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks\",\n        \"A Survey on In-context Learning\",\n        \"The Llama 3 Herd of Models\",\n        \"Mechanism Design for Large Language Models\",\n        \"Using gpt-4 to augment unbalanced data for automatic scoring\",\n        \"Adaptive bidding for display advertising\",\n        \"Bidding in Uniform Price Auctions for Value Maximizing Buyers\",\n        \"Ad Auctions for LLMs via Retrieval Augmented Generation\",\n        \"Inference from Auction Prices\",\n        \"An executable domain-specific modeling language for simulating organizational auction-based coordination strategies for crisis response\",\n        \"LoRA: Low-Rank Adaptation of Large Language Models\",\n        \"Mistral 7B\",\n        \"Investigating the winner’s curse based on decision making in an auction environment\",\n        \"Auction theory: A guide to the literature\",\n        \"ChatGPT: Jack of all trades, master of none\",\n        \"A Practical Survey on Zero-shot Prompt Design for In-context Learning\",\n        \"AucSwap: A Vickrey auction modeled decentralized cross-blockchain asset transfer protocol\",\n        \"GPT-4 as an X data annotator: Unraveling its performance on a stance classification task\",\n        \"GPT-4 Technical Report\",\n        \"Instruction Tuning with GPT-4\",\n        \"Dynamic Pricing under Competition on Online Marketplaces: A Data-Driven Approach\",\n        \"Exploring the Vickrey-Clarke-Groves mechanism for electricity markets\",\n        \"On the Exploitability of Instruction Tuning\",\n        \"Applying the generalized Vickrey auction to pricing reliable multicasts\",\n        \"A method based on weighted F-score and SVM for feature selection\",\n        \"Llama 2: Open foundation and fine-tuned chat models\",\n        \"Learning against Non-credible Auctions\",\n        \"Microeconomic theory\",\n        \"All of Statistics: A Concise Course in Statistical Inference\",\n        \"Auction Theory: By Vijay Krishna. Academic Press, 2002\",\n        \"Finetuned Language Models are Zero-Shot Learners\",\n        \"Chain-of-thought prompting elicits reasoning in large language models\",\n        \"Sponsored Search Auction Design Beyond Single Utility Maximization\",\n        \"A Personalized Automated Bidding Framework for Fairness-Aware Online Advertising\",\n        \"Research on Railway Project Bidding Based on Vickrey Theory\",\n        \"Leveraging Social Connections to Improve Personalized Ranking for Collaborative Filtering\"\n    ],\n    \"reasoning\": \"Selected these 50 references because they represent foundational work and recent advances in Large Language Models Empower Personalized Valuation in Auction, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}