{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 155 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Multimodal Automated Fact-Checking: A Survey\n\nPaper Abstract: Abstract Misinformation is often conveyed in multiple modalities, e.g. a miscaptioned image. Multimodal misinformation is perceived as more credible by humans, and spreads faster than its text-only counterparts. While an increasing body of research investigates automated fact-checking (AFC), previous surveys mostly focus on text. In this survey, we conceptualise a framework for AFC including subtasks unique to multimodal misinformation. Furthermore, we discuss related terms used in different communities and map them to our framework. We focus on four modalities prevalent in real-world fact-checking: text, image, audio, and video. We survey benchmarks and models, and discuss limitations and promising directions for future research.††* This work was partially done during Mubashara’s research visit at Cambridge.\n\n{retrieved_text}\n\nGenerate exactly 155 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 155\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Multi-modal misinformation detection: Approaches, challenges and opportunities\",\n        \"Open-domain, content-based, multi-modal fact-checking of out-of-context images via online resources\",\n        \"Protecting world leaders against deep fakes\",\n        \"PubHealthTab: A public health table-based dataset for evidence-based fact checking\",\n        \"Reading and reasoning over chart images for evidence-based automated fact-checking\",\n        \"A survey on multimodal disinformation detection\",\n        \"FEVEROUS: fact extraction and verification over unstructured and structured information\",\n        \"Deepfake video detection through optical flow based CNN\",\n        \"EXMULF: an explainable multimodal content-based fake news detection system\",\n        \"Catching out-of-context misinformation with self-supervised learning\",\n        \"Generating fact checking explanations\",\n        \"Multimodal machine learning: A survey and taxonomy\",\n        \"The CLEF-2023 checkthat! lab: Checkworthiness, subjectivity, political bias, factuality, and authority\",\n        \"Twitter-COMMs: Detecting climate, COVID, and military multimodal misinformation\",\n        \"Challenges of computational verification in social multimedia\",\n        \"Freebase: a collaboratively created graph database for structuring human knowledge\",\n        \"Video face manipulation detection through ensemble of cnns\",\n        \"Exploring the role of visual content in fake news detection\",\n        \"MM-claims: A dataset for multimodal claim detection in social media\",\n        \"Tabfact: A large-scale dataset for table-based fact verification\",\n        \"A concise history of the fauxtography blogstorm in the 2006 lebanon war\",\n        \"Id-reveal: Identity-aware deepfake video detection\",\n        \"On the detection of digital face manipulation\",\n        \"The deepfake detection challenge (DFDC) preview dataset\",\n        \"An image is worth 16x16 words: Transformers for image recognition at scale\",\n        \"Recent developments in opensmile, the munich open-source multimedia feature extractor\",\n        \"Openear - introducing the munich open-source emotion and affect recognition toolkit\",\n        \"InfoSurgeon: Cross-media fine-grained information consistency checking for fake news detection\",\n        \"Images and misinformation in political groups: Evidence from whatsapp in india\",\n        \"Generative adversarial networks\",\n        \"Understanding the promise and limits of automated fact-checking\",\n        \"Level up the deepfake detection: a method to effectively discriminate images generated by GAN architectures and diffusion models\",\n        \"Deepfake video detection using recurrent neural networks\",\n        \"Deep multimodal representation learning: A survey\",\n        \"A survey on automated fact-checking\",\n        \"Faking sandy: characterizing and identifying fake images on twitter during hurricane sandy\",\n        \"X-fact: A new benchmark dataset for multilingual fact checking\",\n        \"MMM: an emotion and novelty-aware approach for multilingual multimodal misinformation detection\",\n        \"A picture paints a thousand lies? the effects and mechanisms of multimodal disinformation and rebuttals disseminated via social media\",\n        \"Evidence-aware multilingual fake news detection\",\n        \"The quest to automate fact-checking\",\n        \"Detecting check-worthy factual claims in presidential debates\",\n        \"Mask r-cnn\",\n        \"Deep residual learning for image recognition\",\n        \"The ps-battles dataset - an image collection for image manipulation detection\",\n        \"Long short-term memory\",\n        \"Towards automatic detection of misinformation in online medical videos\",\n        \"MR2: A benchmark for multimodal retrieval-augmented rumor detection in social media\",\n        \"Fighting fake news: Image splice detection via learned self-consistency\",\n        \"Journalism, fake news & disinformation: handbook for journalism education and training\",\n        \"Development of a video tampering dataset for forensic investigation\",\n        \"Multimedia semantic integrity assessment using joint embedding of images and text\",\n        \"Logical fallacy detection\",\n        \"Multimodal fusion with recurrent neural networks for rumor detection on microblogs\",\n        \"The israeli—hezbollah war of 2006: The media as a weapon in asymmetrical conflict\",\n        \"Multimodal political deception detection\",\n        \"A style-based generator architecture for generative adversarial networks\",\n        \"Fakeavceleb: A novel audio-video multimodal deepfake dataset\",\n        \"MVAE: multimodal variational autoencoder for fake news detection\",\n        \"Auto-encoding variational bayes\",\n        \"The asvspoof 2017 challenge: Assessing the limits of replay spoofing attack detection\",\n        \"Semi-supervised classification with graph convolutional networks\",\n        \"Detecting deception in political debates using acoustic and textual features\",\n        \"Explainable automated fact-checking: A survey\",\n        \"Explainable automated fact-checking for public health claims\",\n        \"Exfaux: A weakly supervised approach to explainable fauxtography detection\",\n        \"Kodf: A large-scale korean deepfake detection dataset\",\n        \"Multimodal cheapfakes detection by utilizing image captioning for global context\",\n        \"Contending with terms: “multimodal” and “multimedia” in the academic and public spheres\",\n        \"Phonespoof: A new dataset for spoofing attack detection in telephone channel\",\n        \"Pix2struct: Screenshot parsing as pretraining for visual language understanding\",\n        \"Debunking Handbook 2020\",\n        \"Cross-media structured common space for multimedia event extraction\",\n        \"Is a picture worth a thousand words? an empirical study of image content and social media engagement\",\n        \"Celeb-df: A large-scale challenging dataset for deepfake forensics\",\n        \"Foundations and recent trends in multimodal machine learning: Principles, challenges, and open questions\",\n        \"A joint neural model for information extraction with global features\",\n        \"Visually grounded reasoning across languages and cultures\",\n        \"COVID-VTS: fact extraction and verification on short video platforms\",\n        \"Interpretable multimodal misinformation detection with logic reasoning\",\n        \"A modality-level explainable framework for misinformation checking in social networks\",\n        \"NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media\",\n        \"Determining authenticity of video evidence in the age of artificial intelligence and in the wake of deepfake videos\",\n        \"A study of misinformation in audio messages shared in whatsapp groups\",\n        \"Han, image captioning, and forensics ensemble multimodal fake news detection\",\n        \"Efficient estimation of word representations in vector space\",\n        \"FACTIFY: A multi-modal fact verification dataset\",\n        \"Multimodal analytics for real-world news using measures of cross-modal entity consistency\",\n        \"Fakeddit: A new multimodal benchmark dataset for fine-grained fake news detection\",\n        \"Overview of the CLEF-2018 checkthat! lab on automatic identification and verification of political claims\",\n        \"Automated fact-checking for assisting human fact-checkers\",\n        \"Df-platter: Multi-face heterogeneous deepfake dataset\",\n        \"Truthiness: How Non-Probative Photos Shape Belief\",\n        \"Nonprobative photographs (or words) inflate truthiness\",\n        \"Lying words: Predicting deception from linguistic styles\",\n        \"Mumin: A large-scale multilingual multimodal fact-checked misinformation social network dataset\",\n        \"FSGAN: subject agnostic face swapping and reenactment\",\n        \"Deepfakes and cheap fakes\",\n        \"Benchmarking multi-modal entailment for fact verification\",\n        \"Deception detection using real-life trial data\",\n        \"Check mate: Prioritizing user generated multi-media content for fact-checking\",\n        \"Fakeclip: Multimodal fake caption detection with mixed languages for explainable visualization\",\n        \"Fakesv: A multimodal benchmark with rich social context for fake news detection on short video platforms\",\n        \"Exploiting multi-domain visual information for fake news detection\",\n        \"Two heads are better than one: Improving fake news video detection by correlating with neighbors\",\n        \"Hierarchical multi-modal contextual attention network for fake news detection\",\n        \"Disinfomeme: A multimodal dataset for detecting meme intentionally spreading out disinformation\",\n        \"Learning transferable visual models from natural language supervision\",\n        \"For: A dataset for synthetic speech detection\",\n        \"(mis)information dissemination in whatsapp: Gathering, analyzing and countermeasures\",\n        \"Towards the detection of diffusion model deepfakes\",\n        \"High-resolution image synthesis with latent diffusion models\",\n        \"Faceforensics: A large-scale video dataset for forgery detection in human faces\",\n        \"Mulcob-mulfav: Multimodal content based multilingual fact verification\",\n        \"Square one bias in NLP: Towards a multi-dimensional exploration of the research manifold\",\n        \"Deep multimodal image-repurposing detection\",\n        \"Recurrent convolutional strategies for face manipulation detection in videos\",\n        \"Averitec: A dataset for real-world claim verification with evidence from the web\",\n        \"Fakecovid- A multilingual cross-domain fact check news dataset for COVID-19\",\n        \"A multimodal misinformation detector for COVID-19 short videos on tiktok\",\n        \"A duo-generative approach to explainable multimodal COVID-19 misinformation detection\",\n        \"Detecting and grounding multi-modal media manipulation\",\n        \"Verification handbook\",\n        \"Very deep convolutional networks for large-scale image recognition\",\n        \"Factdrill: A data repository of fact-checked social media content to study fake news incidents in india\",\n        \"Graph interactive network with adaptive gradient for multi-modal rumor detection\",\n        \"Findings of factify 2: Multimodal fake news detection\",\n        \"Factify 2: A multimodal fake news and satire news dataset\",\n        \"Going deeper with convolutions\",\n        \"Detecting cross-modal inconsistency to defend against neural fake news\",\n        \"Multi-model fake news detection based on concatenation of visual latent features\",\n        \"Automated fact checking: Task formulations, methods and future directions\",\n        \"The fact extraction and VERification (FEVER) shared task\",\n        \"Attention is all you need\",\n        \"M2TR: multi-modal multi-scale transformers for deepfake detection\",\n        \"Deepsonar: Towards effective and robust detection of ai-synthesized fake voices\",\n        \"EANN: event adversarial neural networks for multi-modal fake news detection\",\n        \"Deepfake video detection using convolutional vision transformer\",\n        \"Generalizable synthetic image detection via language-guided contrastive learning\",\n        \"Sepmark: Deep separable watermarking for unified source tracing and deepfake detection\",\n        \"Multimodal fusion with co-attention networks for fake news detection\",\n        \"Mantra-net: Manipulation tracing network for detection and localization of image forgeries with anomalous features\",\n        \"Asvspoof 2015: the first automatic speaker verification spoofing and countermeasures challenge\",\n        \"End-to-end multimodal fact-checking and explanation generation: A challenging dataset and models\",\n        \"Half-truth: A partially fake audio detection dataset\",\n        \"Few-shot adversarial learning of realistic neural talking head models\",\n        \"Detecting image splicing in the wild (WEB)\",\n        \"Automated fact-checking: A survey\",\n        \"Fauxbuster: A content-free fauxtography detector using social media comments\",\n        \"Detecting out-of-context multimodal misinformation with interpretable neural-symbolic model\",\n        \"MFAN: multi-modal feature-enhanced attention networks for rumor detection\",\n        \"Exploring temporal coherence for more general video face forgery detection\",\n        \"Learning rich features for image manipulation detection\",\n        \"Fact-checking meets fauxtography: Verifying claims about images\",\n        \"Contrastfaux: Sparse semi-supervised fauxtography detection on the web using multi-view contrastive learning\"\n    ],\n    \"reasoning\": \"Selected these 155 references because they represent foundational work and recent advances in Multimodal Automated Fact-Checking: A Survey, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}