{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 50 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Are Large Language Models a Threat to Digital Public Goods? Evidence from Activity on Stack Overflow\n\nPaper Abstract: Abstract Large language models like ChatGPT efficiently provide users with information about various topics, presenting a potential substitute for searching the web and asking people for help online. But since users interact privately with the model, these models may drastically reduce the amount of publicly available human-generated data and knowledge resources. This substitution can present a significant problem in securing training data for future models. In this work, we investigate how the release of ChatGPT changed human-generated open data on the web by analyzing the activity on Stack Overflow, the leading online Q&A platform for computer programming. We find that relative to its Russian and Chinese counterparts, where access to ChatGPT is limited, and to similar forums for mathematics, where ChatGPT is less capable, activity on Stack Overflow significantly decreased. A difference-in-differences model estimates a 16% decrease in weekly posts on Stack Overflow. This effect increases in magnitude over time, and is larger for posts related to the most widely used programming languages. Posts made after ChatGPT get similar voting scores than before, suggesting that ChatGPT is not merely displacing duplicate or low-quality content. These results suggest that more users are adopting large language models to answer questions and they are better substitutes for Stack Overflow for languages for which they have more training data. Using models like ChatGPT may be more efficient for solving certain programming problems, but its widespread adoption and the resulting shift away from public exchange on the web will limit the open data people and models can learn from in the future.\n\n{retrieved_text}\n\nGenerate exactly 50 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 50\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Automation and new tasks: How technology displaces and reinstates labor\",\n        \"A model of growth through Creative Destruction\",\n        \"Self-consuming generative models go mad\",\n        \"Discovering value from community activity on focused question answering sites: a case study of Stack Overflow\",\n        \"Competing technologies, increasing returns, and lock-in by historical events\",\n        \"Generative AI at Work\",\n        \"Alternative transformations to handle extreme values of the dependent variable\",\n        \"ChatGPT is a Blurry JPEG of the Web\",\n        \"Beefing it up for your investor? open sourcing and startup funding: Evidence from github\",\n        \"Fit or unfit: analysis and prediction of’closed questions’ on stack overflow\",\n        \"No country for old members: User lifecycle and linguistic change in online communities\",\n        \"The great startup sellout and the rise of oligopoly\",\n        \"GPTs are GPTs: An early look at the labor market impact potential of large language models\",\n        \"Electronic publication and the narrowing of science and scholarship\",\n        \"Training with AI: Evidence from chess computers\",\n        \"Ghtorrent: Github’s data from a firehose\",\n        \"Digital dark matter and the economic contribution of apache\",\n        \"AI and the transformation of social science research\",\n        \"Artificial intelligence co-piloted auditing\",\n        \"The false promise of imitating proprietary llms\",\n        \"What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks\",\n        \"Extracting knowledge from the world wide web\",\n        \"Ideas, artifacts, and facilities: information as a common-pool resource\",\n        \"Power and Progress: Our Thousand-Year Struggle Over Technology and Prosperity\",\n        \"Accuracy of a generative artificial intelligence model in a complex diagnostic challenge\",\n        \"The Unintended Consequences of Censoring Digital Technology–Evidence from Italy’s ChatGPT Ban\",\n        \"Unemployment and digital public goods contribution\",\n        \"Cloud empires: How digital platforms are overtaking the state and how we can regain control\",\n        \"Why the world reads wikipedia: Beyond english speakers\",\n        \"Some simple economics of open source\",\n        \"The dimensions of data labor: A road map for researchers, activists, and policymakers to empower data producers\",\n        \"Design lessons from the fastest q&a site in the west\",\n        \"The substantial interdependence of Wikipedia and Google: A case study on the relationship between peer production communities and information technologies\",\n        \"Experimental evidence on the productivity effects of generative artificial intelligence\",\n        \"GPT-4 Technical Report\",\n        \"The impact of AI on developer productivity: Evidence from GitHub Copilot\",\n        \"On the Value of Wikipedia as a Gateway to the Web\",\n        \"Engineering value: The returns to technological talent and investments in artificial intelligence\",\n        \"Capitalism, socialism, and democracy\",\n        \"The curse of recursion: Training on generated data makes models forget\",\n        \"Astronomia ex machina: a history, primer and outlook on neural networks in astronomy\",\n        \"Antifragile: How to live in a world we don’t understand\",\n        \"Welcome to the era of ChatGPT et al. the prospects of large language models\",\n        \"Attention is all you need\",\n        \"Artificial artificial artificial intelligence: Crowd workers widely use large language models for text production tasks\",\n        \"Will we run out of data? An analysis of the limits of scaling datasets in Machine Learning\",\n        \"A deeper investigation of the importance of wikipedia links to search engine results\",\n        \"Examining Wikipedia with a broader lens: Quantifying the value of Wikipedia’s relationships with other large-scale online communities\",\n        \"What makes geeks tick? A study of Stack Overflow careers\",\n        \"ChatGPT vs. Google: A Comparative Study of Search Performance and User Experience\"\n    ],\n    \"reasoning\": \"Selected these 50 references because they represent foundational work and recent advances in Are Large Language Models a Threat to Digital Public Goods? Evidence from Activity on Stack Overflow, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}