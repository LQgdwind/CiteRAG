{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 53 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: BATFormer: Towards Boundary-Aware Lightweight Transformer for Efficient Medical Image Segmentation\n\nPaper Abstract: Abstract Objective: Transformers, born to remedy the inadequate receptive fields of CNNs, have drawn explosive attention recently. However, the daunting computational complexity of global representation learning, together with rigid window partitioning, hinders their deployment in medical image segmentation. This work aims to address the above two issues in transformers for better medical image segmentation. Methods: We propose a boundary-aware lightweight transformer (BATFormer) that can build cross-scale global interaction with lower computational complexity and generate windows flexibly under the guidance of entropy. Specifically, to fully explore the benefits of transformers in long-range dependency establishment, a cross-scale global transformer (CGT) module is introduced to jointly utilize multiple small-scale feature maps for richer global features with lower computational complexity. Given the importance of shape modeling in medical image segmentation, a boundary-aware local transformer (BLT) module is constructed. Different from rigid window partitioning in vanilla transformers which would produce boundary distortion, BLT adopts an adaptive window partitioning scheme under the guidance of entropy for both computational complexity reduction and shape preservation. Results: BATFormer achieves the best performance in Dice of 92.84%percent\\%, 91.97%percent\\%, 90.26%percent\\%, and 96.30%percent\\% for the average, right ventricle, myocardium, and left ventricle respectively on the ACDC dataset and the best performance in Dice, IoU, and ACC of 90.76%percent\\%, 84.64%percent\\%, and 96.76%percent\\% respectively on the ISIC 2018 dataset. More importantly, BATFormer requires the least amount of model parameters and the lowest computational complexity compared to the state-of-the-art approaches. Conclusion and Significance: Our results demonstrate the necessity of developing customized transformers for efficient and better medical image segmentation. We believe the design of BATFormer is inspiring and extendable to other applications/frameworks. The source code is publicly available at https://github.com/xianlin7/BATFormer.\n\n{retrieved_text}\n\nGenerate exactly 53 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 53\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"U-Net: Convolutional networks for biomedical image segmentation\",\n        \"Weighted ResUNet for high-quality retina vessel segmentation\",\n        \"Attention gated networks: Learning to leverage salient regions in medical images\",\n        \"A nested U-Net architecture for medical image segmentation\",\n        \"Joint segment-level and pixel-wise losses for deep learning based retinal vessel segmentation\",\n        \"Attention is all you need\",\n        \"Swin transformer: Hierarchical vision transformer using shifted windows\",\n        \"Masked autoencoders are scalable vision learners\",\n        \"Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers\",\n        \"Medical image segmentation using squeeze-and-expansion transformers\",\n        \"More than encoder: Introducing transformer decoder to upsample\",\n        \"Convolution-free medical image segmentation using transformers\",\n        \"TransClaw U-Net: Claw U-Net with transformers for medical image segmentation\",\n        \"LeViT-UNet: Make faster encoders with transformer for medical image segmentation\",\n        \"TransUNet: Transformers make strong encoders for medical image segmentation\",\n        \"Medical transformer: Gated axial-attention for medical image segmentation\",\n        \"UNETR: Transformers for 3D medical image segmentation\",\n        \"CoTr: Efficiently bridging CNN and transformer for 3D medical image segmentation\",\n        \"Swin-UNet: UNet-like pure transformer for medical image segmentation\",\n        \"UTNet: A hybrid transformer architecture for medical image segmentation\",\n        \"GT U-Net: A U-Net like group transformer network for tooth root segmentation\",\n        \"DS-TransUNet: Dual swin transformer U-Net for medical image segmentation\",\n        \"TransAttUNet: Multi-level attention-guided U-Net with transformer for medical image segmentation\",\n        \"MISSFormer: An effective medical image segmentation transformer\",\n        \"Mixed transformer U-Net for medical image segmentation\",\n        \"Skin lesion analysis toward melanoma detection 2018: A challenge hosted by the international skin imaging collaboration (ISIC)\",\n        \"The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions\",\n        \"Deep learning techniques for automatic MRI cardiac multi-structures segmentation and diagnosis: Is the problem solved?\",\n        \"Non-maximum suppression for object detection by passing messages between windows\",\n        \"Mask R-CNN\",\n        \"An image is worth 16x16 words: Transformers for image recognition at scale\",\n        \"SoftSeg: Advantages of soft versus binary training for image segmentation\",\n        \"Cardiac MRI segmentation with a dilated CNN incorporating domain-specific constraints\",\n        \"Cardiac MRI Segmentation With Sparse Annotations: Ensembling Deep Learning Uncertainty and Shape Priors\",\n        \"Automatic cardiac disease assessment on cine-MRI via time-series segmentation and domain specific features\",\n        \"Convolutional neural network with shape prior applied to cardiac MRI segmentation\",\n        \"Cardiac segmentation with strong anatomical guarantees\",\n        \"Learning with context feedback loop for robust medical image segmentation\",\n        \"Densely connected fully convolutional network for short-axis cardiac cine MR image segmentation and heart diagnosis using random forest\",\n        \"An exploration of 2D and 3D deep learning techniques for cardiac MR image segmentation\",\n        \"AdaEn-Net: An ensemble of adaptive 2Dâ€“3D Fully Convolutional Networks for medical image segmentation\",\n        \"Automatic segmentation and disease classification using cardiac cine MR images\",\n        \"Ms RED: A novel multi-scale residual encoding and decoding network for skin lesion segmentation\",\n        \"CPFNet: Context pyramid fusion network for medical image segmentation\",\n        \"CA-Net: Comprehensive attention convolutional neural networks for explainable medical image segmentation\",\n        \"FAT-Net: Feature adaptive transformers for automated skin lesion segmentation\",\n        \"Ce-net: Context encoder network for 2d medical image segmentation\",\n        \"nnFormer: Interleaved transformer for volumetric segmentation\",\n        \"D-Former: A U-shaped dilated transformer for 3D medical image segmentation\",\n        \"nnU-Net: A self-configuring method for deep learning-based biomedical image segmentation\",\n        \"GridNet with automatic shape prior registration for automatic MRI cardiac segmentation\",\n        \"2D-3D fully convolutional neural networks for cardiac MR segmentation\",\n        \"Boundary-sensitive loss function with location constraint for hard region segmentation\"\n    ],\n    \"reasoning\": \"Selected these 53 references because they represent foundational work and recent advances in BATFormer: Towards Boundary-Aware Lightweight Transformer for Efficient Medical Image Segmentation, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}