{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 660 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\nPaper Abstract: Abstract The trustworthiness of machine learning has emerged as a critical topic in the field, encompassing various applications and research areas such as robustness, security, interpretability, and fairness. Over the past decade, dedicated efforts have been made to address these issues, resulting in a proliferation of methods tailored to each specific challenge. In this survey paper, we provide a systematic overview of the technical advancements in trustworthy machine learning, focusing on robustness, adversarial robustness, interpretability, and fairness from a data-centric perspective, as we believe that achieving trustworthiness in machine learning often involves overcoming challenges posed by the data structures that traditional empirical risk minimization (ERM) training cannot resolve. Interestingly, we observe a convergence of methods introduced from this perspective, despite their development as independent solutions across various subfields of trustworthy machine learning. Furthermore, we find that Pearl’s hierarchy of causality serves as a unifying framework for categorizing these techniques. Consequently, this survey first presents the background of trustworthy machine learning development using a unified set of concepts, connects this unified language to Pearl’s hierarchy of causality, and finally discusses methods explicitly inspired by causality literature. By doing so, we established a unified language with mathematical vocabulary as a principled connection between these methods across robustness, adversarial robustness, interpretability, and fairness under a data-centric perspective, fostering a more cohesive understanding of the field. Further, we extend our study to the trustworthiness of large pretrained models. We first present a brief summary of the dominant techniques in these models, such as fine-tuning, parameter-efficient fine-tuning, prompting, and reinforcement learning with human feedback. We then connect these techniques with standard ERM, upon which previous trustworthy machine learning solutions were built. This connection allows us to immediately build upon the principled understanding of the trustworthy method established in previous sections, applying it to these new techniques in large pretrained models, openning up possibilities for many new methods. We also survey the current existing methods under this perspective. Finally, we offer a brief summary of the applications of these methods and also discuss about some future aspects relating to our survey111For more information, please visit trustAI.one.\n\n{retrieved_text}\n\nGenerate exactly 660 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 660\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Explaining individual predictions when features are dependent: More accurate approximations to shapley values\",\n        \"Deep learning with differential privacy\",\n        \"Counterfactual vision and language learning\",\n        \"Gpt-3-driven pedagogical agents to train children’s curious question-asking skills\",\n        \"Persistent anti-muslim bias in large language models\",\n        \"Sanity checks for saliency maps\",\n        \"One-network adversarial fairness\",\n        \"Bias-resilient neural network\",\n        \"Learning optimal and fair decision trees for non-discriminative decision-making\",\n        \"Intrinsic dimensionality explains the effectiveness of language model fine-tuning\",\n        \"Vqa: Visual question answering\",\n        \"Invariance principle meets information bottleneck for out-of-distribution generalization\",\n        \"Domain-adversarial neural networks\",\n        \"Threat of adversarial attacks on deep learning in computer vision: A survey\",\n        \"Cx-tom: Counterfactual explanations with theory-of-mind for enhancing human trust in image recognition models\",\n        \"Adversarial invariant feature learning with accuracy constraint for domain generalization\",\n        \"What learning algorithm is in-context learning? investigations with linear models\",\n        \"Flamingo: a visual language model for few-shot learning\",\n        \"Towards understanding ensemble, knowledge distillation and self-distillation in deep learning\",\n        \"Advanced econometrics\",\n        \"Uncovering and mitigating algorithmic bias through learned latent structure\",\n        \"Estimation of the parameters of a single equation in a complete system of stochastic equations\",\n        \"Square attack: a query-efficient black-box adversarial attack via random search\",\n        \"Exploring length generalization in large language models\",\n        \"Palm 2 technical report\",\n        \"Invariant risk minimization\",\n        \"Logic-guided data augmentation and regularization for consistent question answering\",\n        \"A general language assistant as a laboratory for alignment\",\n        \"Craft: A benchmark for causal reasoning about forces and interactions\",\n        \"Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples\",\n        \"Understanding confounding and mediation\",\n        \"On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation\",\n        \"An actor-critic algorithm for sequence prediction\",\n        \"Learning to understand goal specifications by modelling reward\",\n        \"Learning de-biased representations with biased representations\",\n        \"Training a helpful and harmless assistant with reinforcement learning from human feedback, 2022\",\n        \"Instrumental variable methods for causal inference\",\n        \"Your fairness may vary: Pretrained language model fairness in toxic text classification\",\n        \"Adversarial transformation networks: Learning to generate adversarial examples\",\n        \"On pearl’s hierarchy and the foundations of causal inference\",\n        \"Explainable artificial intelligence (xai): Concepts, taxonomies, opportunities and challenges toward responsible ai\",\n        \"Longformer: The long-document transformer, 2020\",\n        \"Pada: Example-based prompt learning for on-the-fly adaptation to unseen domains, 2022\",\n        \"A theory of learning from different domains\",\n        \"Analysis of representations for domain adaptation\",\n        \"On the dangers of stochastic parrots: Can language models be too big?\",\n        \"Curriculum learning\",\n        \"A convex framework for fair regression\",\n        \"Data decisions and theoretical implications when adversarially learning fair representations\",\n        \"Interventional aspect-based sentiment analysis, 2021\",\n        \"Let there be a clock on the beach: Reducing object hallucination in image captioning\",\n        \"Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification\",\n        \"Language (technology) is power: A critical survey of “bias” in NLP\",\n        \"Better rewards yield better summaries: Learning to summarise without references\",\n        \"On the opportunities and risks of foundation models, 2022\",\n        \"Coin: Counterfactual image generation for vqa interpretation\",\n        \"Unsupervised pixel-level domain adaptation with generative adversarial networks\",\n        \"Domain separation networks\",\n        \"Approximating cnns with bag-of-local-features models works surprisingly well on imagenet, 2019\",\n        \"Distributionally robust finetuning bert for covariate drift in spoken language understanding\",\n        \"Language models are few-shot learners\",\n        \"Exploiting domain-specific features to enhance domain generalization\",\n        \"Learning to perform complex tasks through compositional fine-tuning of language models\",\n        \"Docogen: Domain counterfactual generation for low resource domain adaptation\",\n        \"End-to-end object detection with transformers, 2020\",\n        \"Towards evaluating the robustness of neural networks\",\n        \"Agnostic domain generalization\",\n        \"Unlabeled data improves adversarial robustness\",\n        \"Causality matters in medical imaging\",\n        \"Fairness in machine learning: A survey\",\n        \"Classification with fairness constraints: A meta-algorithm with provable guarantees\",\n        \"Improved adversarial learning for fair classification\",\n        \"ireason: Multimodal commonsense reasoning using videos and natural language with interpretability, 06 2021\",\n        \"Fairlex: A multilingual benchmark for evaluating fairness in legal text processing\",\n        \"Adapting pretrained vision-language foundational models to medical imaging domains\",\n        \"Towards robust classification model by counterfactual and invariant data generation, 2021\",\n        \"Neural network attributions: A causal perspective\",\n        \"Human trajectory prediction via counterfactual analysis, 2021\",\n        \"Can rationalization improve robustness?\",\n        \"Adversarial training for improving model robustness? look at both prediction and interpretation, 2022\",\n        \"Gradual domain adaptation without indexed intermediate domains\",\n        \"Rays: A ray searching method for hard-label adversarial attack\",\n        \"Counterfactual samples synthesizing for robust visual question answering, 2020\",\n        \"Improving in-context few-shot learning via self-supervised training\",\n        \"Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models\",\n        \"Recall and learn: Fine-tuning deep pretrained language models with less forgetting\",\n        \"Fine-tuning deteriorates general textual out-of-distribution detection by distorting task-agnostic features\",\n        \"Large language models are few(1)-shot table reasoners, 2023\",\n        \"Dependent multi-task learning with causal intervention for image captioning\",\n        \"Causal intervention for subject-deconfounded facial action unit recognition, 2022\",\n        \"Towards unbiased visual emotion recognition via causal intervention, 2021\",\n        \"On the relation between sensitivity and accuracy in in-context learning, 2023\",\n        \"Sign-opt: A query-efficient hard-label adversarial attack\",\n        \"Palm: Scaling language modeling with pathways, 2022\",\n        \"Deep reinforcement learning from human preferences\",\n        \"Houdini: Fooling deep structured prediction models\",\n        \"Electra: Pre-training text encoders as discriminators rather than generators\",\n        \"Training verifiers to solve math word problems, 2021\",\n        \"Optimization with non-differentiable constraints with applications to fairness, recall, churn, and other goals\",\n        \"Understanding global feature contributions with additive importance measures\",\n        \"Explaining by removing: A unified framework for model explanation\",\n        \"Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks, 2020\",\n        \"Domain adaptation for visual applications: A comprehensive survey\",\n        \"Chatlaw: Open-source legal large language model with integrated external knowledge bases, 2023\",\n        \"Real time image saliency for black box classifiers\",\n        \"A too-good-to-be-true prior to reduce shortcut reliance\",\n        \"Why can gpt learn in-context? language models implicitly perform gradient descent as meta-optimizers, 2023\",\n        \"Adversarial training methods for network embedding, 2019\",\n        \"Advcodemix: Adversarial attack on code-mixed data\",\n        \"Frustratingly easy domain adaptation\",\n        \"Commonsense knowledge mining from pretrained models\",\n        \"A continual learning survey: Defying forgetting in classification tasks\",\n        \"Robustifying sentiment classification by maximally exploiting few counterfactuals\",\n        \"Measuring fairness with biased rulers: A comparative study on bias metrics for pre-trained language models\",\n        \"Comprehensive knowledge distillation with causal intervention\",\n        \"Cross-domain image captioning with discriminative finetuning, 2023\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Margin-aware adversarial domain adaptation with optimal transport\",\n        \"Explanations based on the missing: Towards contrastive explanations with pertinent negatives\",\n        \"Counterfactual fairness: removing direct effects through regularization\",\n        \"Mma training: Direct input space margin maximization through adversarial training\",\n        \"Explanations can be manipulated and geometry is to blame\",\n        \"Decaf: A deep convolutional activation feature for generic visual recognition\",\n        \"Raft: Reward ranked finetuning for generative foundation model alignment, 2023\",\n        \"A survey on in-context learning, 2023\",\n        \"Multi-fact correction in abstractive text summarization\",\n        \"Towards a rigorous science of interpretable machine learning\",\n        \"Fairness in deep learning: A computational perspective\",\n        \"Opinion paper: “so what if chatgpt wrote it?” multidisciplinary perspectives on opportunities, challenges and implications of generative conversational ai for research, practice and policy\",\n        \"Decoupled classifiers for group-fair and efficient machine learning\",\n        \"Domain generalization with domain-specific aggregation modules\",\n        \"Align-deform-subtract: An interventional framework for explaining object differences, 2022\",\n        \"Discriminative attribution from counterfactuals, 2021\",\n        \"Krona: Parameter efficient tuning with kronecker adapter\",\n        \"Censoring representations with an adversary\",\n        \"Amnesic probing: Behavioral explanation with amnesic counterfactuals, 2021\",\n        \"Adversarial robustness as a prior for learned representations, 2019\",\n        \"Learning perceptually-aligned representations via adversarial robustness\",\n        \"Visualizing higher-layer features of a deep network\",\n        \"Dermatologist-level classification of skin cancer with deep neural networks\",\n        \"Causal inference in natural language processing: Estimation, prediction, interpretation and beyond\",\n        \"CausaLM: Causal model explanation through counterfactual language models\",\n        \"Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity, 2022\",\n        \"Learning fair representations via an adversarial framework\",\n        \"A survey of race, racism, and anti-racism in NLP\",\n        \"Counterfactual vision-and-language navigation via adversarial path sampling, 2020\",\n        \"Semi-supervised specific emitter identification method using metric-adversarial training\",\n        \"Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned, 2022\",\n        \"Fast convergence of detr with spatially modulated co-attention\",\n        \"Making pre-trained language models better few-shot learners\",\n        \"Evaluating models’ local decision boundaries via contrast sets\",\n        \"Counterfactual fairness in text classification through robustness, 2019\",\n        \"Supervised adversarial alignment of single-cell rna-seq data\",\n        \"Improving zero-shot generalization and robustness of multi-modal models\",\n        \"Causal abstractions of neural networks\",\n        \"Inducing causal structure for interpretable neural networks\",\n        \"Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness\",\n        \"Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness, 2022\",\n        \"A systematic literature review of medical chatbot research from a behavior change perspective\",\n        \"A new pac-bayesian perspective on domain adaptation\",\n        \"Fast r-cnn\",\n        \"Rich feature hierarchies for accurate object detection and semantic segmentation, 2014\",\n        \"Causal inference in statistics: A primer\",\n        \"Non-discriminatory machine learning through convex fairness criteria\",\n        \"Satisfying real-world goals with dataset constraints\",\n        \"Dlow: Domain flow for adaptation and generalization\",\n        \"Generative adversarial nets\",\n        \"Explaining and harnessing adversarial examples (2014)\",\n        \"Translational lung imaging analysis through disentangled representations, 2022\",\n        \"Uncovering the limits of adversarial training against norm-bounded adversarial examples\",\n        \"Finetune like you pretrain: Improved finetuning of zero-shot vision models\",\n        \"Making the v in vqa matter: Elevating the role of image understanding in visual question answering\",\n        \"Counterfactual visual explanations\",\n        \"Confounding and collapsibility in causal inference\",\n        \"Covariate shift by kernel mean matching\",\n        \"Towards deep neural network architectures robust to adversarial examples, 2014\",\n        \"The false promise of imitating proprietary llms\",\n        \"Employment tests and discriminatory hiring\",\n        \"Low frequency adversarial perturbation\",\n        \"Parameter-efficient transfer learning with diff pruning\",\n        \"Visual attention consistency under image transforms for multi-label image classification\",\n        \"Auto-debias: Debiasing masked language models with automated biased prompts\",\n        \"Mitigating gender bias in distilled language models via counterfactual role reversal\",\n        \"Rationalization for explainable nlp: A survey\",\n        \"Retrieval augmented language model pre-training\",\n        \"Differential privacy in deep learning: An overview\",\n        \"WARP: Word-level Adversarial ReProgramming\",\n        \"Learning domain invariant representations in goal-conditioned block mdps\",\n        \"Ptr: Prompt tuning with rules for text classification, 2021\",\n        \"Learning from dialogue after deployment: Feed yourself, chatbot!\",\n        \"Investigating learning dynamics of BERT fine-tuning\",\n        \"Mitigating bias in facial recognition with fairgan\",\n        \"Trustworthy artificial intelligence in medical imaging\",\n        \"BERTese: Learning to speak to BERT\",\n        \"Learning universal adversarial perturbations with generative models\",\n        \"Preserving pre-trained features helps calibrate fine-tuned language models\",\n        \"On distribution shift in learning-based bug detectors\",\n        \"MABEL: Attenuating gender bias using textual entailment data\",\n        \"{DEBERTA}: {DECODING}-{enhanced} {bert} {with} {disentangled} {attention}\",\n        \"CPL: Counterfactual prompt learning for vision and language models\",\n        \"Fooling neural network interpretations via adversarial model manipulation\",\n        \"The origins and prevalence of texture bias in convolutional neural networks\",\n        \"Attack-less adversarial training for a robust adversarial defense\",\n        \"Cycada: Cycle-consistent adversarial domain adaptation\",\n        \"A Benchmark for Interpretability Methods in Deep Neural Networks\",\n        \"Class-aware domain adaptation for improving adversarial robustness\",\n        \"Parameter-efficient transfer learning for nlp\",\n        \"Towards compositional adversarial robustness: Generalizing adversarial training to composite semantic perturbations\",\n        \"Lora: Low-rank adaptation of large language models\",\n        \"Does distributionally robust supervised learning give robust classifiers?\",\n        \"Distilling causal effect of data in class-incremental learning\",\n        \"Llm-adapters: An adapter family for parameter-efficient fine-tuning of large language models\",\n        \"Causal information bottleneck boosts adversarial robustness of deep neural network\",\n        \"Towards reasoning in large language models: A survey, 2023\",\n        \"Fsdr: Frequency space domain randomization for domain generalization\",\n        \"Stable and fair classification\",\n        \"Causal intervention for object detection\",\n        \"The two dimensions of worst-case training and their integrated effect for out-of-domain generalization\",\n        \"Self-challenging improves cross-domain generalization\",\n        \"How to lie with statistics\",\n        \"Ecinn: Efficient counterfactuals from invertible neural networks, 2021\",\n        \"Deduce: Generating counterfactual explanations efficiently, 2021\",\n        \"Reward learning from human preferences and demonstrations in atari\",\n        \"Adversarial examples are not bugs, they are features\",\n        \"Atlas: Few-shot learning with retrieval augmented language models, 2022\",\n        \"Training calibration-based counterfactual explainers for deep learning models in medical image analysis\",\n        \"Way off-policy batch deep reinforcement learning of implicit human preferences in dialog, 2019\",\n        \"Survey of hallucination in natural language generation\",\n        \"Prompt-based distribution alignment for domain generalization in text classification\",\n        \"Embedding hallucination for few-shot language fine-tuning\",\n        \"Identifying and correcting label bias in machine learning\",\n        \"ROSE: Robust selective fine-tuning for pre-trained language models\",\n        \"Tsmobn: Generalization for unseen clients in federated learning via causal intervention, 2021\",\n        \"Wasserstein fair classification\",\n        \"How can we know what language models know?\",\n        \"Randomized adversarial training via taylor expansion\",\n        \"Robust convolutional neural networks under adversarial noise\",\n        \"Measuring the tendency of cnns to learn surface statistical regularities\",\n        \"Are all spurious features in natural language alike? an analysis through a causal lens\",\n        \"Highly accurate protein structure prediction with alphafold\",\n        \"Counterfactual explanation based on gradual construction for deep networks, 2021\",\n        \"An analysis of visual question answering algorithms\",\n        \"Does invariant risk minimization capture invariance?\",\n        \"De-biasing facial detection system using vae\",\n        \"Unmasking the mask – evaluating social biases in masked language models\",\n        \"Adversarial logit pairing\",\n        \"Mitigating fooling with competitive overcomplete output layer neural networks\",\n        \"Chatgpt for good? on opportunities and challenges of large language models for education\",\n        \"Learning the difference that makes a difference with counterfactually-augmented data, 2020\",\n        \"Instrumental variable estimation of average partial causal effects\",\n        \"Undoing the damage of dataset bias\",\n        \"Art of singular vectors and universal adversarial perturbations\",\n        \"Causal reasoning and large language models: Opening a new frontier for causality\",\n        \"Learning not to learn: Training deep neural networks with biased data\",\n        \"Demystifying causal features on adversarial examples and causal inoculation for robust network by adversarial instrumental variable regression, 2023\",\n        \"Learning texture invariant representation for domain adaptation of semantic segmentation\",\n        \"Learning to discover cross-domain relations with generative adversarial networks\",\n        \"Auto-encoding variational bayes, 2022\",\n        \"Segment anything\",\n        \"Examining gender and race bias in two hundred sentiment analysis systems, 2018\",\n        \"Meltr: Meta loss transformer for learning to fine-tune video foundation models\",\n        \"CausalGAN: Learning causal implicit generative models with adversarial training\",\n        \"Large language models are zero-shot reasoners\",\n        \"Efficient counterfactual debiasing for visual question answering\",\n        \"Free lunch for co-saliency detection: Context adjustment, 2021\",\n        \"Offline reinforcement learning with implicit q-learning\",\n        \"Adaptive sensitive reweighting to mitigate bias in fairness-aware classification\",\n        \"Can neural machine translation be improved with user feedback?\",\n        \"Imagenet classification with deep convolutional neural networks\",\n        \"Dense associative memory is robust to adversarial inputs\",\n        \"Understanding self-training for gradual domain adaptation\",\n        \"Fine-tuning can distort pretrained features and underperform out-of-distribution\",\n        \"Language generation models can cause harm: So what can we do about it? an actionable survey\",\n        \"Adversarial examples in the physical world\",\n        \"Albert: A lite bert for self-supervised learning of language representations\",\n        \"Robust text classification in the presence of confounding bias\",\n        \"Sustainable modular debiasing of language models, 2021\",\n        \"Improving a neural semantic parser by counterfactual learning from human bandit feedback\",\n        \"c3superscript𝑐3c^{3}: Compositional counterfactual constrastive learning for video-grounded dialogues, 2021\",\n        \"Hallucinations in neural machine translation, 2019\",\n        \"Manifold regularized deep neural networks using adversarial examples\",\n        \"Surgical fine-tuning improves adaptation to distribution shifts\",\n        \"Rationalizing neural predictions\",\n        \"Causal models as minimal descriptions of multivariate systems, 2006\",\n        \"The power of scale for parameter-efficient prompt tuning, 2021\",\n        \"Driver-centric risk object identification\",\n        \"Domain generalization with adversarial feature learning\",\n        \"Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation\",\n        \"The closeness of in-context learning and weight shifting for softmax regression, 2023\",\n        \"Confounder identification-free causal visual feature learning\",\n        \"Prefix-tuning: Optimizing continuous prompts for generation, 2021\",\n        \"SPE: Symmetrical prompt enhancement for fact probing\",\n        \"Deep domain generalization via conditional invariant adversarial networks\",\n        \"Interventional Video Relation Detection\",\n        \"Sibling-attack: Rethinking transferable adversarial attacks against face recognition\",\n        \"Learning noise-invariant representations for robust speech recognition, 2018\",\n        \"Learning to contrast the counterfactual samples for robust visual question answering\",\n        \"Defense against adversarial attacks using high-level representation guided denoiser\",\n        \"Gendered mental health stigma in masked language models\",\n        \"Focal loss for dense object detection\",\n        \"Beyond one-model-fits-all: A survey of domain specialization for large language models\",\n        \"The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery\",\n        \"Detecting and correcting for label shift with black box predictors\",\n        \"Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning\",\n        \"What makes good in-context examples for GPT-3?\",\n        \"Adversarial attacks and defenses: An interpretation perspective, 2020\",\n        \"Webglm: Towards an efficient web-enhanced question answering system with human preferences, 2023\",\n        \"Gpt understands, too, 2021\",\n        \"The blessings of unlabeled background in untrimmed videos, 2021\",\n        \"Roberta: A robustly optimized bert pretraining approach, 2019\",\n        \"Enhanced attacks on defensively distilled deep neural networks, 2017\",\n        \"Twins: A fine-tuning framework for improved transferability of adversarial robustness and generalization, 2023\",\n        \"Domain confused contrastive learning for unsupervised domain adaptation\",\n        \"Gender and representation bias in GPT-3 generated stories\",\n        \"A unified approach to interpreting model predictions\",\n        \"Foveation-based mechanisms alleviate adversarial examples\",\n        \"A unified gradient regularization family for adversarial examples\",\n        \"Increasing-margin adversarial ({ima}) training to improve adversarial robustness of neural networks, 2021\",\n        \"Learning adversarially fair and transferable representations\",\n        \"Towards deep learning models resistant to adversarial attacks\",\n        \"Low-resource interactive active labeling for fine-tuning language models\",\n        \"Domain generalization using causal matching, 2021\",\n        \"Understanding deep image representations by inverting them\",\n        \"Cascading biases: Investigating the effect of heuristic annotation strategies on data and models\",\n        \"Domain adaptation: Learning bounds and algorithms\",\n        \"Doubly right object recognition: A why prompt for visual rationales\",\n        \"Few-shot self-rationalization with natural language prompts\",\n        \"Counterfactual explanation of brain activity classifiers using image-to-image transfer by generative adversarial network, 2021\",\n        \"Understanding stereotypes in language models: Towards robust measurement and zero-shot debiasing\",\n        \"On faithfulness and factuality in abstractive summarization\",\n        \"Segment anything model for medical image analysis: an experimental study, 2023\",\n        \"Confounding variables\",\n        \"Causalcity: Complex simulations with agency for causal discovery and reasoning, 06 2021\",\n        \"An empirical survey of the effectiveness of debiasing techniques for pre-trained language models\",\n        \"A survey on bias and fairness in machine learning\",\n        \"Locating and editing factual associations in gpt, 2023\",\n        \"What happens to BERT embeddings during fine-tuning?\",\n        \"Ganterfactual—counterfactual explanations for medical non-experts using generative adversarial learning\",\n        \"Efficient estimation of word representations in vector space\",\n        \"Instrumental processes using integrated covariances, 2023\",\n        \"Methods for interpreting and understanding deep neural networks\",\n        \"Multi-modal understanding and generation for medical images and text via vision-language pre-training\",\n        \"Foundation models for generalist medical artificial intelligence\",\n        \"Deepfool: a simple and accurate method to fool deep neural networks\",\n        \"Universal adversarial perturbations\",\n        \"On the interplay between fine-tuning and sentence-level probing for linguistic knowledge in pre-trained transformers\",\n        \"Unified deep supervised domain adaptation and generalization\",\n        \"Domain generalization via invariant feature representation\",\n        \"Semi-supervised domain adaptation with cyclegan guided by a downstream task loss\",\n        \"Cascade adversarial machine learning regularized with a unified embedding\",\n        \"Stereoset: Measuring stereotypical bias in pretrained language models\",\n        \"Webgpt: Browser-assisted question-answering with human feedback, 2022\",\n        \"Learning from failure: Training debiased classifier from biased classifier\",\n        \"Stochastic gradient methods for distributionally robust optimization with f-divergences\",\n        \"Interventional video grounding with dual contrastive learning, 2021\",\n        \"CrowS-pairs: A challenge dataset for measuring social biases in masked language models\",\n        \"Learning with complex loss functions and constraints\",\n        \"Simple black-box adversarial perturbations for deep networks, 2016\",\n        \"Biologically inspired protection of deep networks from adversarial attacks\",\n        \"Synthesizing the preferred inputs for neurons in neural networks via deep generator networks\",\n        \"Domain invariant representation learning with domain density transformations\",\n        \"‘a learning and masking approach to secure learning, 2017\",\n        \"Counterfactual vqa: A cause-effect look at language bias, 2021\",\n        \"HONEST: Measuring hurtful sentence completion in language models\",\n        \"Causal affect prediction model using a past facial image sequence\",\n        \"Born identity network: Multi-way counterfactual map generation to explain a classifier’s decision, 2021\",\n        \"Adversarial image perturbation for privacy protection a game theory perspective\",\n        \"Taking advantage of multitask learning for fair classification\",\n        \"Gpt-4 technical report, 2023\",\n        \"Dinov2: Learning robust visual features without supervision, 2023\",\n        \"Counterfactual data augmentation via perspective transition for open-domain dialogues\",\n        \"Causality-inspired single-source domain generalization for medical image segmentation, 2021\",\n        \"Training language models to follow instructions with human feedback\",\n        \"A survey on transfer learning\",\n        \"Bag of tricks for adversarial training\",\n        \"Boosting adversarial training with hypersphere embedding\",\n        \"Transferability in machine learning: from phenomena to black-box attacks using adversarial samples\",\n        \"Practical black-box attacks against machine learning\",\n        \"The limitations of deep learning in adversarial settings\",\n        \"Distillation as a defense to adversarial perturbations against deep neural networks\",\n        \"Data augmentation for fairness-aware machine learning: Preventing algorithmic bias in law enforcement systems\",\n        \"Deep structural causal models for tractable counterfactual inference\",\n        \"Causal diagrams for empirical research\",\n        \"Causality: Models, Reasoning, and Inference, 2nd ed\",\n        \"Models, reasoning and inference\",\n        \"The book of why: the new science of cause and effect\",\n        \"Zero-shot deep domain adaptation\",\n        \"Glove: Global vectors for word representation\",\n        \"Elements of causal inference: foundations and learning algorithms\",\n        \"Deep contextualized word representations, 2018\",\n        \"Language models as knowledge bases?\",\n        \"Rise: Randomized input sampling for explanation of black-box models\",\n        \"Adapterfusion: Non-destructive task composition for transfer learning\",\n        \"Mad-x: An adapter-based framework for multi-task cross-lingual transfer\",\n        \"Identifiability of sparse causal effects using instrumental variables, 2022\",\n        \"Finding and fixing spurious patterns with explanations, 2021\",\n        \"How to control confounding effects by statistical analysis\",\n        \"Extracting causal visual features for limited label classification, 03 2021\",\n        \"Two causal principles for improving visual dialog, 2020\",\n        \"Learning how to ask: Querying LMs with mixtures of soft prompts\",\n        \"Causal interventional training for image recognition\",\n        \"Medical image understanding with pretrained vision language models: A comprehensive study, 2023\",\n        \"Learning transferable visual models from natural language supervision\",\n        \"Language models are unsupervised multitask learners, 2019\",\n        \"Scaling language models: Methods, analysis & insights from training gopher\",\n        \"Exploring the limits of transfer learning with a unified text-to-text transformer, 2020\",\n        \"Detecting anomalous inputs to dnn classifiers by joint statistical testing at the layers, 07 2020\",\n        \"Frameworks and results in distributionally robust optimization\",\n        \"Discriminative domain-invariant adversarial network for deep domain generalization\",\n        \"Explain yourself! leveraging language models for commonsense reasoning\",\n        \"In-context retrieval-augmented language models, 2023\",\n        \"Is reinforcement learning (not) for natural language processing: Benchmarks, baselines, and building blocks for natural language policy optimization\",\n        \"Hierarchical text-conditional image generation with clip latents, 2022\",\n        \"Zero-shot text-to-image generation\",\n        \"Counterfactual attention learning for fine-grained visual categorization and re-identification, 2021\",\n        \"Multiple adversarial domains adaptation approach for mitigating adversarial attacks effects\",\n        \"The curious case of hallucinations in neural machine translation\",\n        \"On causally disentangled representations, 2021\",\n        \"Faster r-cnn: Towards real-time object detection with region proposal networks\",\n        \"Crossing the gap: Domain generalization for image captioning\",\n        \"Causal scene bert: Improving object detection by searching for challenging groups of data, 02 2022\",\n        \"” why should i trust you?” explaining the predictions of any classifier\",\n        \"Beyond trivial counterfactual explanations with diverse valuable explanations, 2021\",\n        \"Object hallucination in image captioning\",\n        \"High-resolution image synthesis with latent diffusion models\",\n        \"U-net: Convolutional networks for biomedical image segmentation\",\n        \"Are vqa systems rad? measuring robustness to augmented data with focused interventions, 2021\",\n        \"The risks of invariant risk minimization\",\n        \"Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients, 2017\",\n        \"The programmer’s assistant: Conversational interaction with a large language model for software development\",\n        \"Adversarial diversity and hard positive generation\",\n        \"Learning to retrieve prompts for in-context learning\",\n        \"Adapterdrop: On the efficiency of adapters in transformers\",\n        \"Adversarial training improves model interpretability in single-cell rna-seq analysis\",\n        \"Exploiting independent instruments: Identification and distribution generalization\",\n        \"Adapting visual category models to new domains\",\n        \"Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization\",\n        \"Distributionally robust neural networks\",\n        \"Regularization with stochastic transformations and perturbations for deep semi-supervised learning, 2016\",\n        \"Chatgpt utility in healthcare education, research, and practice: systematic review on the promising perspectives and valid concerns\",\n        \"Evaluating the visualization of what a deep neural network has learned\",\n        \"Explaining the behavior of black-box prediction algorithms with causal learning, 2021\",\n        \"Upset and angri: Breaking high performance image classifiers\",\n        \"Counterfactual generative networks, 2021\",\n        \"Exploiting cloze questions for few shot text classification and natural language inference, 2021\",\n        \"Few-shot text generation with pattern-exploiting training, 2021\",\n        \"Self-diagnosis and self-debiasing: A proposal for reducing corpus-based bias in nlp, 2021\",\n        \"On causal and anticausal learning\",\n        \"Proximal policy optimization algorithms, 2017\",\n        \"Cxplain: Causal explanations for model interpretation under uncertainty\",\n        \"Grad-cam: Visual explanations from deep networks via gradient-based localization\",\n        \"Learning to optimize domain specific normalization for domain generalization\",\n        \"Distributionally robust logistic regression, 2015\",\n        \"Customizing contextualized language models for legal document reviews\",\n        \"The pitfalls of simplicity bias in neural networks\",\n        \"Cycle-consistency for robust visual question answering, 2019\",\n        \"Generalizing across domains via cross-gradient training\",\n        \"Improving weakly-supervised object localization via causal intervention, 2021\",\n        \"How sensitive are translation systems to extra contexts? mitigating gender bias in neural machine translation models through relevant contexts\",\n        \"Data augmentation for discrimination prevention and bias disambiguation\",\n        \"Conterfactual generative zero-shot semantic segmentation, 2021\",\n        \"ChatGPT and other large language models are double-edged swords\",\n        \"Towards out-of-distribution generalization: A survey\",\n        \"The woman worked as a babysitter: On biases in language generation\",\n        \"Generalist vision foundation models for medical imaging: A case study of segment anything model on zero-shot medical segmentation\",\n        \"Just fine-tune twice: Selective differential privacy for large language models\",\n        \"Constrained language models yield few-shot semantic parsers\",\n        \"Autoprompt: Eliciting knowledge from language models with automatically generated prompts, 2020\",\n        \"Learning important features through propagating activation differences\",\n        \"Retrieval augmentation reduces hallucination in conversation\",\n        \"Deep inside convolutional networks: Visualising image classification models and saliency maps\",\n        \"Large language models encode clinical knowledge\",\n        \"Salient imagenet: How to discover spurious features in deep learning?, 2022\",\n        \"Explaining the black-box smoothly- a counterfactual approach, 2021\",\n        \"Using causal analysis for conceptual deep learning explanation\",\n        \"Counterfactual explanation and causal inference in service of robustness in robot control, 2020\",\n        \"Offline RL for natural language generation with implicit language q learning\",\n        \"An information-theoretic approach to prompt engineering without ground truth labels\",\n        \"Estimating causal effects of tone in online debates, 2019\",\n        \"Learning to summarize with human feedback\",\n        \"When training and test sets are different: characterizing learning transfer\",\n        \"Ensemble methods as a defense to adversarial perturbations against deep neural networks\",\n        \"An efficient explanation of individual classifications using game theory\",\n        \"Explaining instance classifications with interactions of subsets of feature values\",\n        \"One pixel attack for fooling deep neural networks\",\n        \"A comparison of strategies for source-free domain adaptation\",\n        \"Counterfactual Debiasing Inference for Compositional Action Recognition\",\n        \"BERTScore is unfair: On social bias in language model-based metrics for text generation\",\n        \"Hypernetworks with statistical filtering for defending adversarial examples\",\n        \"Axiomatic attribution for deep networks\",\n        \"Lst: Ladder side-tuning for parameter and memory efficient transfer learning\",\n        \"Training neural networks with fixed sparse masks\",\n        \"Robustly disentangled causal mechanisms: Validating deep representations for interventional robustness\",\n        \"Intriguing properties of neural networks\",\n        \"Consistency regularization for adversarial robustness, 2021\",\n        \"Masktune: Mitigating spurious correlations by forcing to explore, 2022\",\n        \"Transitive transfer learning\",\n        \"Distant domain transfer learning\",\n        \"Assessing social and intersectional biases in contextualized word representations, 2019\",\n        \"Unbiased scene graph generation from biased training, 2020\",\n        \"Adversarial visual robustness by causal intervention, 2021\",\n        \"Adversarial training reduces information and improves transferability, 2020\",\n        \"Identifying causal effects using instrumental time series: Nuisance iv and correcting for the past, 2022\",\n        \"ChatGPT, bard, and large language models for biomedical research: Opportunities and pitfalls\",\n        \"Estimation and simultaneous correlation in complete equation systems\",\n        \"A gold standard methodology for evaluating accuracy in data-to-text systems\",\n        \"Lamda: Language models for dialog applications\",\n        \"Neuron coverage-guided domain generalization\",\n        \"Trainable projected gradient method for robust fine-tuning, 2023\",\n        \"A deeper look at dataset bias, 2015\",\n        \"Unbiased look at dataset bias\",\n        \"Llama: Open and efficient foundation language models, 2023\",\n        \"Llama 2: Open foundation and fine-tuned chat models, 2023\",\n        \"Multimodal few-shot learning with frozen language models, 2021\",\n        \"Simultaneous deep transfer across domains and tasks\",\n        \"Adversarial discriminative domain adaptation\",\n        \"Mitigating spurious correlation in natural language understanding with counterfactual inference\",\n        \"When and how to fool explainable models (and humans) with adversarial examples, 2023\",\n        \"Toward robustness against label noise in training deep discriminative neural networks, 2017\",\n        \"On the definition of a confounder\",\n        \"Attention is all you need\",\n        \"Explainable image classification with evidence counterfactual, 2020\",\n        \"Investigating gender bias in language models using causal mediation analysis\",\n        \"Spurious correlations\",\n        \"Transformers learn in-context by gradient descent, 2023\",\n        \"Efficient fine-tuning of bert models on the edge\",\n        \"Achieving fairness through adversarial learning: an application to recidivism prediction\",\n        \"Universal adversarial triggers for attacking and analyzing NLP\",\n        \"Iteratively prompt pre-trained language models for chain of thought\",\n        \"Proactive pseudo-intervention: Causally informed contrastive learning for interpretable vision models, 2021\",\n        \"Learning robust global representations by penalizing local predictive power\",\n        \"Learning robust representations by projecting superficial statistics out\",\n        \"Toward learning robust and invariant representations with alignment regularization and data augmentation\",\n        \"Toward learning human-aligned cross-domain robust models by countering misaligned features\",\n        \"Understanding gradual domain adaptation: Improved analysis, optimal path and beyond\",\n        \"Select-additive learning: Improving generalization in multimodal sentiment analysis\",\n        \"Repairing without retraining: Avoiding disparate impact with counterfactual distributions\",\n        \"High-frequency component helps explain the generalization of convolutional neural networks\",\n        \"On the robustness of chatgpt: An adversarial and out-of-distribution perspective\",\n        \"Generalizing to unseen domains: A survey on domain generalization\",\n        \"Assessing multilingual fairness in pre-trained multimodal representations\",\n        \"Dynamically disentangling social bias from task-oriented representations with adversarial attack\",\n        \"Spanning attack: Reinforce black-box attacks with unlabeled data\",\n        \"Deep visual domain adaptation: A survey\",\n        \"Mitigating bias in face recognition using skewness-aware reinforcement learning\",\n        \"Learning robust representations for continual relation extraction via adversarial class augmentation\",\n        \"Scout: Self-aware discriminant counterfactual explanations, 2020\",\n        \"Using non-invertible data transformations to build adversary-resistant deep neural networks\",\n        \"Learning adversary-resistant deep neural networks\",\n        \"Adversary resistant deep neural networks with an application to malware detection\",\n        \"What do neural networks learn in image classification? a frequency shortcut perspective, 2023\",\n        \"Causal intervention improves implicit sentiment analysis\",\n        \"Visual commonsense r-cnn\",\n        \"Identifying and mitigating spurious correlations for improving robustness in nlp models\",\n        \"Causal attention for unbiased visual recognition\",\n        \"Weakly-supervised video object grounding via causal intervention, 2021\",\n        \"Self-consistency improves chain of thought reasoning in language models\",\n        \"On the convergence and robustness of adversarial training, 2022\",\n        \"Adamix: Mixture-of-adapter for parameter-efficient tuning of large language models\",\n        \"Ad-aug: Adversarial data augmentation for counterfactual recommendation\",\n        \"Improving adversarial robustness requires revisiting misclassified examples\",\n        \"Fairness-aware adversarial perturbation towards bias mitigation for deployed deep models\",\n        \"Finetuned language models are zero-shot learners\",\n        \"Chain of thought prompting elicits reasoning in large language models\",\n        \"Cfa: Class-wise calibrated fair adversarial training\",\n        \"A survey of transfer learning\",\n        \"Contrastive counterfactual visual explanations with overdetermination, 2021\",\n        \"Measuring association between labels and free-text rationales\",\n        \"Black-box sparse adversarial attack via multi-objective optimisation\",\n        \"Wasserstein adversarial examples via projected sinkhorn iterations, 2019\",\n        \"Robust fine-tuning of zero-shot models\",\n        \"Tariff on animal and vegetable oils\",\n        \"Learning instrumental variable from data fusion for treatment effect estimation, 2022\",\n        \"Adversarial weight perturbation helps robust generalization\",\n        \"Adversarial soft prompt tuning for cross-domain sentiment analysis\",\n        \"Recursively summarizing books with human feedback, 2021\",\n        \"Bloomberggpt: A large language model for finance\",\n        \"Polyjuice: Generating counterfactuals for explaining, evaluating, and improving models, 2021\",\n        \"Regularized adversarial training (rat) for robust cellular electron cryo tomograms classification\",\n        \"Generating data to mitigate spurious correlations in natural language inference datasets\",\n        \"Domain adaptation with asymmetrically-relaxed distribution alignment\",\n        \"Continual machine reading comprehension via uncertainty-aware fixed memory and adversarial domain adaptation\",\n        \"Masked images are counterfactual samples for robust fine-tuning, 2023\",\n        \"Hyper-class augmented and regularized deep learning for fine-grained image classification\",\n        \"Achieving causal fairness through generative adversarial networks\",\n        \"Robust regression and lasso, 2008\",\n        \"Imagereward: Learning and evaluating human preferences for text-to-image generation, 2023\",\n        \"Show, attend and tell: Neural image caption generation with visual attention\",\n        \"Does your model classify entities reasonably? diagnosing and mitigating spurious correlations in entity typing\",\n        \"Improving stability of fine-tuning pretrained language models via component-wise gradient norm clipping\",\n        \"When causal intervention meets adversarial examples and image masking for deep neural networks\",\n        \"Generative counterfactuals for neural networks via attribute-informed perturbation, 2021\",\n        \"An adversarial training framework for mitigating algorithmic biases in clinical machine learning\",\n        \"Towards interpretable mental health analysis with chatgpt, 2023\",\n        \"Causalvae: Disentangled representation learning via neural structural causal models\",\n        \"Ml-loo: Detecting adversarial examples with feature attribution\",\n        \"Causal attention for vision-language tasks\",\n        \"Gram: Fast fine-tuning of pre-trained language models for content-based collaborative filtering\",\n        \"Xlnet: Generalized autoregressive pretraining for language understanding\",\n        \"Clevrer: Collision events for video representation and reasoning, 2020\",\n        \"Improved ood generalization via adversarial training and pre-training, 2021\",\n        \"Towards coherent and engaging spoken dialog response generation using automatic conversation evaluators\",\n        \"Understanding neural networks through deep visualization\",\n        \"Interventional training for out-of-distribution natural language understanding\",\n        \"Actune: Uncertainty-based active self-training for active fine-tuning of pretrained language models\",\n        \"COCO-DR: Combating the distribution shift in zero-shot dense retrieval with contrastive and distributionally robust learning\",\n        \"Bartscore: Evaluating generated text as text generation, 2021\",\n        \"Rrhf: Rank responses to align language models with human feedback without tears, 2023\",\n        \"Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data\",\n        \"Counterfactual zero-shot and open-set visual recognition, 2021\",\n        \"QA domain adaptation using hidden space augmentation and self-supervised contrastive adaptation\",\n        \"Interventional few-shot learning\",\n        \"Domain adaptation in multilingual and multi-domain monolingual settings for complex word identification\",\n        \"Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models\",\n        \"Efficient defenses against adversarial attacks\",\n        \"Pearl causal hierarchy on image data: Intricacies & challenges\",\n        \"Visualizing and understanding convolutional networks\",\n        \"Learning fair representations\",\n        \"Mitigating unwanted biases with adversarial learning\",\n        \"Causal intervention for weakly-supervised semantic segmentation\",\n        \"Fine-tuning pre-trained language models for few-shot intent detection: Supervised pre-training and isotropization\",\n        \"Theoretically principled trade-off between robustness and accuracy\",\n        \"Transferable adversarial attacks on vision transformers with token gradient regularization\",\n        \"Domain adaptation under target and conditional shift\",\n        \"What if we could not see? counterfactual analysis for egocentric action anticipation\",\n        \"Interpreting adversarially trained convolutional neural networks, 2019\",\n        \"Bridging theory and algorithm for domain adaptation\",\n        \"A survey on neural network interpretability\",\n        \"RoChBert: Towards robust BERT fine-tuning for Chinese\",\n        \"Fine-mixing: Mitigating backdoors in fine-tuned language models\",\n        \"Regularizing neural machine translation by target-bidirectional agreement, 2018\",\n        \"Counterfactual contrastive learning for weakly-supervised vision-language grounding\",\n        \"On learning invariant representations for domain adaptation\",\n        \"Certified robustness against natural language attacks by causal intervention\",\n        \"Gender bias in contextualized word embeddings, 2019\",\n        \"Gender bias in coreference resolution: Evaluation and debiasing methods\",\n        \"Training confounder-free deep learning models for medical applications\",\n        \"Domain generalization via entropy regularization\",\n        \"Generating natural counterfactual visual explanations\",\n        \"Fast real-time counterfactual explanations, 2020\",\n        \"Slic-hf: Sequence likelihood calibration with human feedback, 2023\",\n        \"Generating natural adversarial examples\",\n        \"Improving the robustness of deep neural networks via stability training, 2016\",\n        \"Learning deep features for discriminative localization\",\n        \"Lima: Less is more for alignment, 2023\",\n        \"Examining and combating spurious features under distribution shift, 2021\",\n        \"Least-to-most prompting enables complex reasoning in large language models\",\n        \"Deep domain-adversarial image generation for domain generalisation\",\n        \"Learning to compare for better training and evaluation of open domain natural language generation models\",\n        \"A closer look at how fine-tuning changes bert\",\n        \"Ligaa: Generative adversarial attack method based on low-frequency information\",\n        \"Deformable {detr}: Deformable transformers for end-to-end object detection\",\n        \"Supervised representation learning: Transfer learning with deep autoencoders\",\n        \"A pilot study of query-free adversarial attack against stable diffusion\",\n        \"Fine-tuning language models from human preferences, 2020\",\n        \"Visualizing deep neural network decisions: Prediction difference analysis\",\n        \"Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology\",\n        \"Segment everything everywhere all at once, 2023\",\n        \"Controllable generation from pre-trained language models via inverse prompting\",\n        \"Explaining visual models by causal attribution, 2019\"\n    ],\n    \"reasoning\": \"Selected these 660 references because they represent foundational work and recent advances in Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}