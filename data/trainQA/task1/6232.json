{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 186 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and Future Directions\n\nPaper Abstract: Abstract. Clustering is a fundamental machine learning task which has been widely studied in the literature. Classic clustering methods follow the assumption that data are represented as features in a vectorized form through various representation learning techniques. As the data become increasingly complicated and complex, the shallow (traditional) clustering methods can no longer handle the high-dimensional data type. With the huge success of deep learning, especially the deep unsupervised learning, many representation learning techniques with deep architectures have been proposed in the past decade. One straightforward way to incorporate the benefit of deep learning is to first learn the deep representation before feeding it into shallow clustering methods. However, this is suboptimal due to: i) the representation is not directly learned for clustering which limits the clustering performance; ii) the clustering relies on the relationship among instances which is complicated rather than linear; iii) the clustering and representation learning is dependent on each other which should be mutually enhanced. To tackle the above challenges, the concept of Deep Clustering, i.e., jointly optimizing the representation learning and clustering, has been proposed and hence attracted growing attention in the community. Motivated by the tremendous success of deep learning in clustering, one of the most fundamental machine learning tasks, and the large number of recent advances in this direction, in this paper we conduct a comprehensive survey on deep clustering by proposing a new taxonomy of different state-of-the-art approaches. We summarize the essential components of deep clustering and categorize existing methods by the ways they design interactions between deep representation learning and clustering. Moreover, this survey also provides the popular benchmark datasets, evaluation metrics and open-source implementations to clearly illustrate various experimental settings. Last but not least, we discuss the practical applications of deep clustering and suggest challenging topics deserving further investigations as future directions.\n\n{retrieved_text}\n\nGenerate exactly 186 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 186\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A survey of unsupervised generative models for exploratory data analysis and representation learning\",\n        \"Unsupervised neural networks for automatic Arabic text summarization using document clustering and topic modeling\",\n        \"Clustering with deep learning: Taxonomy and new methods\",\n        \"Self-supervised learning by cross-modal audio-video clustering\",\n        \"Image segmentation by histogram thresholding using hierarchical cluster analysis\",\n        \"Wasserstein generative adversarial networks\",\n        \"Learning representations by maximizing mutual information across views\",\n        \"Trajectory clustering of road traffic in urban environments using incremental machine learning in combination with hyperdimensional computing\",\n        \"Mutual information neural estimation\",\n        \"Gaussian mixture generative adversarial networks for diverse datasets, and the unsupervised clustering of images\",\n        \"Representation learning: A review and new perspectives\",\n        \"A survey of clustering data mining techniques\",\n        \"Spectral clustering with graph neural networks for graph pooling\",\n        \"Fast unfolding of communities in large networks\",\n        \"Structural deep clustering network\",\n        \"Protein function prediction via graph kernels\",\n        \"MARS: discovering novel cell types across heterogeneous single-cell experiments\",\n        \"Language models are few-shot learners\",\n        \"A systematic study of the class imbalance problem in convolutional neural networks\",\n        \"Density-based clustering over an evolving data stream with noise\",\n        \"Deep clustering for unsupervised learning of visual features\",\n        \"Unsupervised learning of visual features by contrasting cluster assignments\",\n        \"A comparative study of efficient initialization methods for the k-means clustering algorithm\",\n        \"Anomaly detection in temperature data using DBSCAN algorithm\",\n        \"Data minersâ€™ little helper: data transformation activity cues for cluster analysis on document collections\",\n        \"Using topic keyword clusters for automatic document clustering\",\n        \"Deep discriminative clustering analysis\",\n        \"Deep adaptive image clustering\",\n        \"Self-Supervised Image Representation Learning with Geometric Set Consistency\",\n        \"A simple framework for contrastive learning of visual representations\",\n        \"Anomaly detection based on enhanced DBScan algorithm\",\n        \"Scalable clustering of signed networks using balance normalized cut\",\n        \"Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks\",\n        \"An unsupervised autoregressive model for speech representation learning\",\n        \"Combining artificial immune system and clustering analysis: A stock market anomaly detection model\",\n        \"Image segmentation by clustering\",\n        \"Mean shift: A robust approach toward feature space analysis\",\n        \"Doubly contrastive deep clustering\",\n        \"Nearest Neighbor Matching for Deep Clustering\",\n        \"Inferring cancer subnetwork markers using density-constrained biclustering\",\n        \"Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity\",\n        \"Cluster alignment with a teacher for unsupervised domain adaptation\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Weighted graph cuts without eigenvectors a multilevel approach\",\n        \"Deep unsupervised clustering with gaussian mixture variational autoencoders\",\n        \"Clustering by maximizing mutual information across views\",\n        \"An image is worth 16x16 words: Transformers for image recognition at scale\",\n        \"Text classification using different feature extraction approaches\",\n        \"Single-cell RNA-seq denoising using a deep count autoencoder\",\n        \"Density-based clustering\",\n        \"A density-based algorithm for discovering clusters in large spatial databases with noise.\",\n        \"Hans-Peter Kriegel\",\n        \"Unbalanced Incomplete Multi-view Clustering via the Scheme of View Evolution: Weak Views are Meat; Strong Views do Eat\",\n        \"Self-organization and identification of web communities\",\n        \"Community detection in graphs\",\n        \"Overview on techniques in cluster analysis\",\n        \"Learning the Precise Feature for Cluster Assignment\",\n        \"Amirhossein Herandi\",\n        \"Community structure in social and biological networks\",\n        \"Xavier Glorot and Yoshua Bengio\",\n        \"Generative adversarial nets\",\n        \"Cluster analysis of wine market segmentationâ€“a consumer based study in the mid-atlantic usa\",\n        \"Bootstrap your own latent-a new approach to self-supervised learning\",\n        \"CURE: An efficient clustering algorithm for large databases\",\n        \"Combining structured node content and topology information for networked graph clustering\",\n        \"Inductive representation learning on large graphs\",\n        \"A novel cluster detection of COVID-19 patients and medical disease conditions using improved evolutionary clustering algorithm star\",\n        \"Distilling the knowledge in a neural network\",\n        \"Learning deep representations by mutual information estimation and maximization\",\n        \"Probabilistic latent semantic analysis\",\n        \"Cnn-based joint clustering and representation learning with feature drift compensation for large-scale image data\",\n        \"Iterative transfer learning with neural network for clustering and cell type classification in single-cell RNA-seq analysis\",\n        \"Deep clustering by semantic contrastive learning\",\n        \"Exploring Non-Contrastive Representation Learning for Deep Clustering\",\n        \"A survey on generative adversarial networks: Variants, applications, and training\",\n        \"Data clustering: a review\",\n        \"A survey on contrastive self-supervised learning\",\n        \"Green market segmentation and consumer profiling: a cluster approach to an emerging consumer market\",\n        \"Text document clustering using spectral clustering algorithm with particle swarm optimization\",\n        \"Deep subspace clustering networks\",\n        \"A Decoder-Free Variational Deep Embedding for Unsupervised Clustering\",\n        \"Joao F Henriques\",\n        \"Variational deep embedding: An unsupervised and generative approach to clustering\",\n        \"A survey of community detection approaches: From statistical modeling to deep learning\",\n        \"Self-supervised visual feature learning with deep neural networks: A survey\",\n        \"Hierarchical clustering schemes\",\n        \"Monte carlo methods\",\n        \"Unsupervised clustering for deep learning: A tutorial survey\",\n        \"DeepMCAT: Large-Scale Deep Clustering for Medical Image Categorization\",\n        \"A fast and high quality multilevel scheme for partitioning irregular graphs\",\n        \"Supervised contrastive learning\",\n        \"Auto-encoding variational bayes\",\n        \"Equitability, mutual information, and the maximal information coefficient\",\n        \"Semi-supervised classification with graph convolutional networks\",\n        \"Michael Bendersky\",\n        \"Estimating mutual information\",\n        \"The Hungarian method for the assignment problem\",\n        \"Contrastive representation learning: A framework and review\",\n        \"Gradient-based learning applied to document recognition\",\n        \"Discriminatively boosted image clustering with fully convolutional auto-encoders\",\n        \"Disentangled Contrastive Learning on Graphs\",\n        \"Prototypical contrastive learning of unsupervised representations\",\n        \"Schain-iram: An efficient and effective semi-supervised clustering algorithm for attributed heterogeneous information networks\",\n        \"Joey Tianyi Zhou\",\n        \"LR-SMOTEâ€”An improved unbalanced data set oversampling based on K-means and SVM\",\n        \"Deep learning for community detection: progress, challenges and opportunities\",\n        \"Clustering with outlier removal\",\n        \"The emerging trends of multi-label learning\",\n        \"Self-supervised learning: Generative or contrastive\",\n        \"Least squares quantization in PCM\",\n        \"Pseudo-supervised deep subspace clustering\",\n        \"A comprehensive survey on graph anomaly detection with deep learning\",\n        \"Lihi Zelnik-Manor\",\n        \"The group lasso for logistic regression\",\n        \"StÃ©phane LathuiliÃ¨re\",\n        \"Efficient estimation of word representations in vector space\",\n        \"A survey of clustering with deep learning: From the perspective of network architecture\",\n        \"A new clustering method for the diagnosis of CoVID19 using medical images\",\n        \"Sign prediction in sparse social networks using clustering and collaborative filtering\",\n        \"On spectral clustering: Analysis and an algorithm\",\n        \"Spice: Semantic pseudo-labeling for image clustering\",\n        \"f-gan: Training generative neural samplers using variational divergence minimization\",\n        \"Image clustering using an augmented generative adversarial network and information maximization\",\n        \"Information Maximization Clustering via Multi-View Self-Labelling\",\n        \"An introduction to deep clustering\",\n        \"Trajectory clustering of air traffic flows around airports\",\n        \"Representation learning with contrastive predictive coding\",\n        \"Sentiment analysis on microblogging with K-means clustering and artificial bee colony\",\n        \"Adversarially regularized graph autoencoder for graph embedding\",\n        \"A survey on transfer learning\",\n        \"A simple and fast algorithm for K-medoids clustering\",\n        \"Scikit-learn: Machine Learning in Python\",\n        \"Deep video action clustering via spatio-temporal feature learning\",\n        \"Hybrid topic cluster models for social healthcare data\",\n        \"Pre-trained models for natural language processing: A survey\",\n        \"The infinite Gaussian mixture model\",\n        \"Gaussian mixture models\",\n        \"Learning Statistical Representation with Joint Deep Embedded Clustering\",\n        \"Learning internal representations by error propagation\",\n        \"A novel anomaly detection algorithm using DBSCAN and SVM in wireless sensor networks\",\n        \"Density-based clustering in spatial databases: The algorithm gdbscan and its applications\",\n        \"DBSCAN revisited, revisited: why and how you should (still) use DBSCAN\",\n        \"Robust continuous clustering\",\n        \"Deep continuous clustering\",\n        \"You never cluster alone\",\n        \"Normalized cuts and image segmentation\",\n        \"Parallel local graph clustering\",\n        \"A comparison of document clustering techniques\",\n        \"A comprehensive survey on community detection with deep learning\",\n        \"Cluster Analysis with Deep Embeddings and Contrastive Learning\",\n        \"Clustering-friendly representation learning via instance discrimination and feature decorrelation\",\n        \"A hybrid approach for text document clustering using Jaya optimization algorithm\",\n        \"Clustering single-cell RNA-seq data with a model-based deep learning approach\",\n        \"Generic title labeling for clustered documents\",\n        \"Graph clustering with graph neural networks\",\n        \"A survey on representation learning efforts in cybersecurity domain\",\n        \"Visualizing data using t-SNE\",\n        \"Simon Vandenhende\",\n        \"Graph attention networks\",\n        \"Ehsan Elhamifar RenÃ© Vidal\",\n        \"A tutorial on spectral clustering\",\n        \"Tongzhou Wang and Phillip Isola\",\n        \"Neural generative model for clustering by separating particularity and commonality\",\n        \"Multi-label active learning algorithms for image classification: Overview and future promise\",\n        \"Bag constrained structure pattern mining for multi-graph classification\",\n        \"Overlapping community detection in networks: The state-of-the-art and comparative study\",\n        \"A comprehensive survey of clustering algorithms\",\n        \"Survey of clustering algorithms\",\n        \"Nicholas D Sidiropoulos\",\n        \"Graph contrastive learning with augmentations\",\n        \"A survey of sentiment analysis in social media\",\n        \"Supporting clustering with contrastive learning\",\n        \"Deep Descriptive Clustering\",\n        \"Fast multi-resolution transformer fine-tuning for extreme multi-label text classification\",\n        \"A review on multi-label learning algorithms\",\n        \"Salient subsequence learning for time series clustering\",\n        \"Mehrtash Harandi\",\n        \"BIRCH: an efficient data clustering method for very large databases\",\n        \"Hierarchical graph pooling with structure learning\",\n        \"Deep learning on graphs: A survey\",\n        \"Deep robust clustering by contrastive learning\",\n        \"Network Representation Learning: From Preprocessing, Feature Extraction to Node Embedding\",\n        \"Cluster adaptation networks for unsupervised domain adaptation\",\n        \"HAHE: Hierarchical attentive heterogeneous information network embedding\",\n        \"Cross multi-type objects clustering in attributed heterogeneous information network\",\n        \"Deep learning for learning graph representations\"\n    ],\n    \"reasoning\": \"Selected these 186 references because they represent foundational work and recent advances in A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and Future Directions, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}