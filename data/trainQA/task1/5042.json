{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 48 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Recurrent Neural Networks (RNNs) with dimensionality reduction and break down in computational mechanics; application to multi-scale localization step\n\nPaper Abstract: Abstract Artificial Neural Networks (NNWs) are appealing functions to substitute high dimensional and non-linear history-dependent problems in computational mechanics since they offer the possibility to drastically reduce the computational time. This feature has recently been exploited in the context of multi-scale simulations, in which the NNWs serve as surrogate model of micro-scale finite element resolutions. Nevertheless, in the literature, mainly the macro-stress-macro-strain response of the meso-scale boundary value problem was considered and the micro-structure information could not be recovered in a so-called localization step. In this work, we develop Recurrent Neural Networks (RNNs) as surrogates of the RVE response while being able to recover the evolution of the local micro-structure state variables for complex loading scenarios. The main difficulty is the high dimensionality of the RNNs output which consists in the internal state variable distribution in the micro-structure. We thus propose and compare several surrogate models based on a dimensionality reduction: i) direct RNN modeling with implicit NNW dimensionality reduction, ii) RNN with PCA dimensionality reduction, and iii) RNN with PCA dimensionality reduction and dimensionality break down, i.e. the use of several RNNs instead of a single one. Besides, we optimize the sequential training strategy of the latter surrogate for GPU usage in order to speed up the process. Finally, through RNN modeling of the principal components coefficients, the connection between the physical state variables and the hidden variables of the RNN is revealed, and exploited in order to select the hyper-parameters of the RNN-based surrogate models in their design stage.\n\n{retrieved_text}\n\nGenerate exactly 48 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 48\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Implicit constitutive modelling for viscoplasticity using neural networks\",\n        \"Accurate cyclic plastic analysis using a neural network material model\",\n        \"Meta-modeling game for deriving theory-consistent, microstructure-based traction–separation laws via deep reinforcement learning\",\n        \"Application of artificial neural networks for the prediction of interface mechanics: a study on grain boundary constitutive behavior\",\n        \"Artificial neural network as an incremental non-linear constitutive model for a finite element code\",\n        \"Numerical implementation of a neural network based material model in finite element analysis\",\n        \"Using neural networks to represent von mises plasticity with isotropic hardening\",\n        \"Characterizing rate-dependent material behaviors in self-learning simulation\",\n        \"Bayesian inference of non-linear multiscale model parameters accelerated by a deep neural network\",\n        \"Artificial neural network for parameter identifications for an elasto-plastic model of superconducting cable under cyclic loading\",\n        \"Multiscale methodology for bone remodelling simulation using coupled finite element and neural network computation\",\n        \"Effective properties\",\n        \"Solid mechanics and its applications\",\n        \"Multiscale fe2 elastoviscoplastic analysis of composite structures\",\n        \"Computational micro-macro transitions and overall moduli in the analysis of polycrystals at large strains\",\n        \"Simulation of the multi-scale convergence in computational homogenization approaches\",\n        \"An approach to micro-macro modeling of heterogeneous materials\",\n        \"Computational homogenization of nonlinear elastic materials using neural networks\",\n        \"A framework for data-driven analysis of materials under uncertainty: Countering the curse of dimensionality\",\n        \"On-the-fly adaptivity for nonlinear twoscale simulations using artificial neural networks and reduced order modeling\",\n        \"Coupling of scales in a multiscale simulation using neural networks\",\n        \"A hybrid approach to simulate the homogenized irreversible elastic–plastic deformations and damage of foams by neural networks\",\n        \"Thermodynamics-based artificial neural networks for constitutive modeling\",\n        \"Micromechanics-based surrogate models for the response of composites: A critical comparison between a classical mesoscale constitutive model, hyper-reduction and neural networks\",\n        \"Three-dimensional convolutional neural network (3d-cnn) for heterogeneous material homogenization\",\n        \"A stochastic fe2 data-driven method for nonlinear multiscale modeling\",\n        \"Accelerating multiscale finite element simulations of history-dependent materials using a recurrent neural network\",\n        \"An intelligent nonlinear meta element for elastoplastic continua: deep learning using a new time-distributed residual u-net architecture\",\n        \"Deep learning predicts path-dependent plasticity\",\n        \"On the potential of recurrent neural networks for modeling path dependent plasticity\",\n        \"Smart constitutive laws: Inelastic homogenization through machine learning\",\n        \"A recurrent neural network-accelerated multi-scale model for elasto-plastic heterogeneous materials subjected to random cyclic and non-proportional loading paths\",\n        \"Fatigue life predictions for glassy polymers: A constitutive approach\",\n        \"Multiscale high cycle fatigue models for neat and short fiber reinforced thermoplastic polymers\",\n        \"Multiaxial fatigue criterion for polypropylene – automotive applications\",\n        \"Principal Component Analysis\",\n        \"The reduced model multiscale method (r3m) for the non-linear homogenization of hyperelastic media at finite strains\",\n        \"A hybrid rnn-gpod surrogate model for real-time settlement predictions in mechanised tunnelling\",\n        \"An efficient monte carlo simulation strategy based on model order reduction and artificial neural networks\",\n        \"Neural-network acceleration of projection-based model-order-reduction for finite plasticity: Application to rves\",\n        \"Effective properties of composite materials with periodic microstructure: a computational approach\",\n        \"Unified treatment of microscopic boundary conditions and efficient algorithms for estimating tangent operators of the homogenized behavior in the computational homogenization method\",\n        \"Homogenization of the thermoelastic properties of silicon nitride\",\n        \"Imposing periodic boundary condition on arbitrary meshes by polynomial interpolation\",\n        \"Reducing the dimensionality of data with neural networks\",\n        \"A material-independent method for extending stress update algorithms from small-strain plasticity to finite plasticity with multiplicative kinematics\",\n        \"Micromechanics-based material networks revisited from the interaction viewpoint; robust and efficient implementation for multi-phase composites\",\n        \"Data of recurrent neural networks (rnns) with dimensionality reduction and break down in computational mechanics; application to multi-scale localization step\"\n    ],\n    \"reasoning\": \"Selected these 48 references because they represent foundational work and recent advances in Recurrent Neural Networks (RNNs) with dimensionality reduction and break down in computational mechanics; application to multi-scale localization step, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}