{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 57 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Multi-source adversarial transfer learning based on similar source domains with local features\n\nPaper Abstract: Abstract Transfer learning leverages knowledge from other domains and has been successful in many applications. Transfer learning methods rely on the overall similarity of the source and target domains. However, in some cases, it is impossible to provide an overall similar source domain, and only some source domains with similar local features can be provided. Can transfer learning be achieved? In this regard, we propose a multi-source adversarial transfer learning method based on local feature similarity to the source domain to handle transfer scenarios where the source and target domains have only local similarities. This method extracts transferable local features between a single source domain and the target domain through a sub-network. Specifically, the feature extractor of the sub-network is induced by the domain discriminator to learn transferable knowledge between the source domain and the target domain. The extracted features are then weighted by an attention module to suppress non-transferable local features while enhancing transferable local features. In order to ensure that the data from the target domain in different sub-networks in the same batch is exactly the same, we designed a multi-source domain independent strategy to provide the possibility for later local feature fusion to complete the key features required. In order to verify the effectiveness of the method, we made the dataset ”Local Carvana Image Masking Dataset”. Applying the proposed method to the image segmentation task of the proposed dataset achieves better transfer performance than other multi-source transfer learning methods. It is shown that the designed transfer learning method is feasible for transfer scenarios where the source and target domains have only local similarities.\n\n{retrieved_text}\n\nGenerate exactly 57 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 57\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A survey of transfer learning\",\n        \"A survey on transfer learning\",\n        \"A survey on deep transfer learning\",\n        \"Research on the deep learning of the small sample data based on transfer learning\",\n        \"Federated transfer learning for iiot devices with low computing power based on blockchain and edge computing\",\n        \"A lightweight cnn based on transfer learning for covid-19 diagnosis\",\n        \"Adaptive transfer learning\",\n        \"Representation similarity analysis for efficient task taxonomy & transfer learning\",\n        \"End-to-end ego lane estimation based on sequential transfer learning for self-driving cars\",\n        \"Ct2us: Cross-modal transfer learning for kidney segmentation in ultrasound images with synthesized data\",\n        \"Transfer learning for time series classification\",\n        \"Transferable attention networks for adversarial domain adaptation\",\n        \"How transferable are features in deep neural networks?\",\n        \"Multi-source deep transfer learning for cross-sensor biometrics\",\n        \"A multi-source ensemble domain adaptation method for rotary machine fault diagnosis\",\n        \"Adversarial multi-source transfer learning in healthcare: Application to glucose prediction for diabetic people\",\n        \"Uav swarm based radar signal sorting via multi-source data fusion: A deep transfer learning framework\",\n        \"Multi-source deep transfer neural network algorithm\",\n        \"Multi-source selection transfer learning with privacy-preserving\",\n        \"A reinforcement ensemble deep transfer learning network for rolling bearing fault diagnosis with multi-source domains\",\n        \"Multi-source manifold feature transfer learning with domain selection for brain-computer interfaces\",\n        \"Domain consistency regularization for unsupervised multi-source domain adaptive classification\",\n        \"A general multi-source ensemble transfer learning framework integrate of lstm-dann and similarity metric for building energy prediction\",\n        \"A three-stage transfer learning framework for multi-source cross-project software defect prediction\",\n        \"A survey of multi-source domain adaptation\",\n        \"Classification of tumor from computed tomography images: A brain-inspired multisource transfer learning under probability distribution adaptation\",\n        \"A multi-source information transfer learning method with subdomain adaptation for cross-domain fault diagnosis\",\n        \"Multi-source sintering transfer learning in small dataset sintering prediction scenario\",\n        \"Multi-source transfer learning guided ensemble lstm for building multi-load forecasting\",\n        \"Multi-source transfer learning network to complement knowledge for intelligent diagnosis of machines with unseen faults\",\n        \"On handling negative transfer and imbalanced distributions in multiple source transfer learning\",\n        \"Integrating multi-source transfer learning, active learning and metric learning paradigms for time series prediction\",\n        \"A multi-atl method for transfer learning across multiple domains with arbitrarily different distribution\",\n        \"Multi-source transfer learning based on label shared subspace\",\n        \"Boosting for transfer learning with multiple sources\",\n        \"Multi-source unsupervised domain adaptation for object detection\",\n        \"Geodesic flow kernel for unsupervised domain adaptation\",\n        \"Caltech-256 object category dataset\",\n        \"Attention-based multi-source domain adaptation\",\n        \"Gradient-based learning applied to document recognition\",\n        \"Unsupervised domain adaptation by backpropagation\",\n        \"A database for handwritten text recognition research\",\n        \"Reading digits in natural images with unsupervised feature learning\",\n        \"Attention is all you need\",\n        \"Attention clusters: Purely attention based local feature integration for video classification\",\n        \"Carvana image masking challenge\",\n        \"A novel domain adaptive deep recurrent network for multivariate time series prediction\",\n        \"Generative adversarial networks\",\n        \"Self-attention generative adversarial networks\",\n        \"Transferability vs. discriminability: Batch spectral penalization for adversarial domain adaptation\",\n        \"Github - mpitid/pylabelme: Simple image annotation tool\",\n        \"Mobileunet-fpn: a semantic segmentation model for fetal ultrasound four-chamber segmentation in edge computing environments\",\n        \"Deep learning-based intravascular ultrasound segmentation for the assessment of coronary artery disease\",\n        \"A comparative study of pre-trained convolutional neural networks for semantic segmentation of breast tumors in ultrasound\",\n        \"Domain generalization: A survey\",\n        \"Calibrating eeg features in motor imagery classification tasks with a small amount of current data using multisource fusion transfer learning\",\n        \"Adam: A method for stochastic optimization\"\n    ],\n    \"reasoning\": \"Selected these 57 references because they represent foundational work and recent advances in Multi-source adversarial transfer learning based on similar source domains with local features, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}