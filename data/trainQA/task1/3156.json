{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 253 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Review of end-to-end speech synthesis technology based on deep learning\n\nPaper Abstract: Abstract As an indispensable part of modern human-computer interaction system, speech synthesis technology helps users get the output of intelligent machine more easily and intuitively, thus has attracted more and more attention. Due to the limitations of high complexity and low efficiency of traditional speech synthesis technology, the current research focus is the deep learning-based end-to-end speech synthesis technology, which has more powerful modeling ability and a simpler pipeline. It mainly consists of three modules: text front-end, acoustic model, and vocoder. This paper reviews the research status of these three parts, and classifies and compares various methods according to their emphasis. Moreover, this paper also summarizes the open-source speech corpus of English, Chinese and other languages that can be used for speech synthesis tasks, and introduces some commonly used subjective and objective speech quality evaluation method. Finally, some attractive future research directions are pointed out.\n\n{retrieved_text}\n\nGenerate exactly 253 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 253\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Acoustic features modelling for statistical parametric speech synthesis: a review\",\n        \"Using vaes and normalizing flows for one-shot text-to-speech synthesis of expressive speech\",\n        \"Deep voice: Real-time neural text-to-speech\",\n        \"Neural voice cloning with a few samples\",\n        \"Statistical parametric speech synthesis: A review\",\n        \"Speech analysis and synthesis by linear prediction of the speech wave\",\n        \"Neural machine translation by jointly learning to align and translate\",\n        \"Chinese standard mandarin speech copus\",\n        \"Introducing the geneva multimodal expression corpus for experimental research on emotion perception\",\n        \"Location-relative attention mechanisms for robust long-form speech synthesis\",\n        \"A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains\",\n        \"Talknet: Fully-convolutional non-autoregressive speech synthesis model\",\n        \"Scheduled sampling for sequence prediction with recurrent neural networks\",\n        \"Deep feed-forward sequential memory networks for speech synthesis\",\n        \"Multi-reference tacotron by intercross training for style disentangling, transfer and control in speech synthesis\",\n        \"Demystifying mmd gans\",\n        \"High fidelity speech synthesis with adversarial networks\",\n        \"A database of german emotional speech\",\n        \"Iemocap: Interactive emotional dyadic motion capture database\",\n        \"Msp-improv: An acted corpus of dyadic interactions to study emotion perception\",\n        \"Polyphone disambiguation for mandarin chinese using conditional neural network with multi-level embedding features\",\n        \"From speaker verification to multispeaker speech synthesis, deep transfer with feedback constraint\",\n        \"Crema-d: Crowd-sourced emotional multimodal actors dataset\",\n        \"Siri on-device deep learning-guided unit selection text-to-speech system\",\n        \"An attentive survey of attention models\",\n        \"A deep generative architecture for postfiltering in statistical parametric speech synthesis\",\n        \"Wavegrad: Estimating gradients for waveform generation\",\n        \"Infogan: Interpretable representation learning by information maximizing generative adversarial nets\",\n        \"Variational lossy autoencoder\",\n        \"Sample efficient adaptive text-to-speech\",\n        \"Attention-based models for speech recognition\",\n        \"Unsupervised speech representation learning using wavenet autoencoders\",\n        \"Multi-target voice conversion without parallel data by adversarially learning disentangled audio representations\",\n        \"One-shot voice conversion by separating speaker and content representations with instance normalization\",\n        \"Locating boundaries for prosodic constituents in unrestricted mandarin texts\",\n        \"Microsoft mulan-a bilingual tts system\",\n        \"Reducing f0 frame error of f0 tracking algorithms under noisy conditions with an unvoiced/voiced classification frontend\",\n        \"Empirical evaluation of gated recurrent neural networks on sequence modeling\",\n        \"Semi-supervised training for improving data efficiency in end-to-end speech synthesis\",\n        \"Scalable multilingual frontend for tts\",\n        \"Zero-shot multi-speaker text-to-speech with state-of-the-art neural speaker embeddings\",\n        \"Language modeling with gated convolutional networks\",\n        \"The historical review and current trends in speech synthesis by bibliometric approach\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Nice: Non-linear independent components estimation\",\n        \"Density estimation using real nvp\",\n        \"End-to-end adversarial text-to-speech\",\n        \"The zero resource speech challenge 2019: Tts without t\",\n        \"Parallel tacotron: Non-autoregressive and controllable tts\",\n        \"High quality streaming speech synthesis with low, sentence-length-independent latency\",\n        \"Tts synthesis with bidirectional lstm based recurrent neural networks\",\n        \"Hoory R (2013) F0 contour prediction with a deep belief network-gaussian process hybrid model. In: 2013 IEEE International Conference on Acoustics\",\n        \"Hoory R (2014) Prosody contour prediction with long short-term memory\",\n        \"Bethge M (2015) A neural algorithm of artistic style. arXiv preprint arXiv:150806576\",\n        \"Bethge M (2016) Image style transfer using convolutional neural networks\",\n        \"Dauphin YN (2017) Convolutional sequence to sequence learning. In: International Conference on Machine Learning\",\n        \"Zhou Y (2017) Deep voice 2: Multi-speaker neural text-to-speech. In: NIPS\",\n        \"Raftery AE (2007) Strictly proper scoring rules\",\n        \"Silen H (2016) Recent advances in google real-time hmm-driven unit selection synthesizer\",\n        \"Bengio Y (2014) Generative adversarial networks. arXiv preprint arXiv:14062661\",\n        \"Graves A (2013) Generating sequences with recurrent neural networks\",\n        \"Lim J (1984) Signal estimation from modified short-time fourier transform. IEEE Transactions on acoustics\",\n        \"Kalchbrenner N (2020) A spectral energy distance for parallel speech synthesis. arXiv preprint arXiv:200801160\",\n        \"Li VO (2018) Meta-learning for low-resource neural machine translation. arXiv preprint arXiv:180808437\",\n        \"Xie L (2019a) Exploiting syntactic features in a parsed tree to improve end-to-end tts. arXiv preprint arXiv:190404764\",\n        \"Xie L (2019b) A new gan-based end-to-end tts training algorithm. arXiv preprint arXiv:190404775\",\n        \"et al. (2020) Didispeech: A large scale mandarin speech corpus. arXiv preprint arXiv:201009275\",\n        \"In: 2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\n        \"Pinto J (2019) Prosody transfer in neural text to speech using global pitch and loudness features. arXiv preprint arXiv:191109645\",\n        \"Livescu K (2019) Pre-trained text embeddings for enhanced text-to-speech synthesis. In: INTERSPEECH\",\n        \"He L (2019) Robust sequence-to-sequence acoustic modeling with stepwise monotonic attention for neural tts. arXiv preprint arXiv:190600672\",\n        \"Hochreiter S (2017) Gans trained by a two time-scale update rule converge to a local nash equilibrium. arXiv preprint arXiv:170608500\",\n        \"Abbeel P (2020) Denoising diffusion probabilistic models. arXiv preprint arXiv:200611239\",\n        \"Schmidhuber J (1997) Long short-term memory. Neural computation 9(8):1735–1780\",\n        \"Yamagishi J (2017) The siwis french speech synthesis database? design and recording of a high quality french database for speech synthesis\",\n        \"Speech and Signal Processing (ICASSP)\",\n        \"Lin XW (2010) Disambiguation for polyphones of chinese based on two-pass unified approach. In: 2010 International Computer Symposium (ICS2010)\",\n        \"Yu K (2015) Bidirectional lstm-crf models for sequence tagging. arXiv preprint arXiv:150801991\",\n        \"Lei M (2020) Devicetts: A small-footprint\",\n        \"Black AW (1996) Unit selection in a concatenative speech synthesis system using a large speech database\",\n        \"Lorenzo-Trueba J (2020) Low-resource expressive text-to-speech using data augmentation. arXiv preprint arXiv:201105707\",\n        \"Furuichi C (1983) Mel log spectrum approximation (mlsa) filter for speech synthesis\",\n        \"Johnson L (2017) The lj speech dataset. https://keithito.com/LJ-Speech-Dataset/\",\n        \"Yang X (2020) A comprehensive survey on deep music generation: Multi-level representations\",\n        \"et al. (2018) Transfer learning from speaker verification to multispeaker text-to-speech synthesis. arXiv preprint arXiv:180604558\",\n        \"Liu Q (2019) Tinybert: Distilling bert for natural language understanding. arXiv preprint arXiv:190910351\",\n        \"Lu J (2018) Fftnet: A real-time speaker-dependent neural vocoder. In: 2018 IEEE International Conference on Acoustics\",\n        \"Fei-Fei L (2016) Perceptual losses for real-time style transfer and super-resolution. In: European conference on computer vision\",\n        \"Kavukcuoglu K (2018) Efficient neural audio synthesis. In: International Conference on Machine Learning\",\n        \"International Journal of Advanced Research in Computer and Communication Engineering 6(4):428–430\",\n        \"Hojo N (2018) Stargan-vc: Non-parallel many-to-many voice conversion using star generative adversarial networks\",\n        \"Hong Y (2011) Formant synthesis of haegeum: a sound analysis/synthesis system using cepstral envelope\",\n        \"Massey N (1998) Text-to-speech conversion with neural networks: A recurrent tdnn approach. arXiv preprint cs/9811032\",\n        \"Banno H (2008) Tandem-straight: A temporally stable power spectral representation for periodic signals and applications to interference-free spectrum\",\n        \"Kearns J (2014) Librivox: Free public domain audiobooks\",\n        \"Vit J (2019) Chive: Varying prosody in speech synthesis with a linguistically driven dynamic hierarchical conditional variational network\",\n        \"Saiyod S (2014) Thai speech synthesis with emotional tone: Based on formant synthesis for home robot\",\n        \"Yoon S (2020) Glow-tts: A generative flow for text-to-speech via monotonic alignment search. arXiv preprint arXiv:200511129\",\n        \"Yoon S (2018) Flowavenet: A generative flow for raw audio. arXiv preprint arXiv:181102155\",\n        \"Rush AM (2016) Sequence-level knowledge distillation. arXiv preprint arXiv:160607947\",\n        \"Dhariwal P (2018) Glow: Generative flow with invertible 1x1 convolutions. arXiv preprint arXiv:180703039\",\n        \"Welling M (2013) Auto-encoding variational bayes. arXiv preprint arXiv:13126114\",\n        \"Welling M (2016) Improving variational inference with inverse autoregressive flow. arXiv preprint arXiv:160604934\",\n        \"Schiel F (2017) Multilingual processing of speech via web services. Computer Speech & Language 45:326–347\",\n        \"Klatt DH (1980) Software for a cascade/parallel formant synthesizer\",\n        \"Klatt DH (1987) Review of text-to-speech conversion for english\",\n        \"et al. (2003) Fast exact inference with a factored model for natural language parsing. Advances in neural information processing systems pp 3–10\",\n        \"Ver V (2003) Cmu arctic databases for speech synthesis\",\n        \"Bae J (2020a) Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis. arXiv preprint arXiv:201005646\",\n        \"Catanzaro B (2020b) Diffwave: A versatile diffusion model for audio synthesis. arXiv preprint arXiv:200909761\",\n        \"In: Proceedings of IEEE Pacific Rim Conference on Communications Computers and Signal Processing\",\n        \"Courville A (2019) Melgan: Generative adversarial networks for conditional waveform synthesis. arXiv preprint arXiv:191006711\",\n        \"Kang HG (2019a) An effective style token weight control technique for end-to-end emotional speech synthesis\",\n        \"Kang HG (2019b) Effective parameter estimation methods for an excitnet model in generative text-to-speech systems. arXiv preprint arXiv:190508486\",\n        \"Bengio Y (2016) Professor forcing: A new algorithm for training recurrent networks. arXiv preprint arXiv:161009038\",\n        \"Łańcucki A (2020) Fastpitch: Parallel text-to-speech with pitch prediction\",\n        \"Liu M (2019) Neural speech synthesis with transformer network. In: Proceedings of the AAAI Conference on Artificial Intelligence\",\n        \"Liu M (2020) Robutrans: A robust transformer-based text-to-speech model. In: Proceedings of the AAAI Conference on Artificial Intelligence\",\n        \"In: 2021 12th International Symposium on Chinese Spoken Language Processing (ISCSLP)\",\n        \"et al. (2020) Jdi-t: Jointly trained duration informed transformer for text-to-speech without explicit alignment. arXiv preprint arXiv:200507799\",\n        \"Ling J (2017) Coarse-to-fine attention models for document summarization\",\n        \"Lee HY (2018) Improving unsupervised style transfer in end-to-end speech synthesis with end-to-end speech recognition\",\n        \"Yu D (2019a) Maximizing mutual information for tacotron. arXiv preprint arXiv:190901145\",\n        \"Liu M (2019b) A new end-to-end long-time speech synthesis system based on tacotron2\",\n        \"Li H (2020a) Graphspeech: Syntax-aware graph attention network for neural speech synthesis. arXiv preprint arXiv:201012423\",\n        \"Li H (2020b) Teacher-student training for robust tacotron-based tts. In: ICASSP 2020-2020 IEEE International Conference on Acoustics\",\n        \"Russo FA (2018) The ryerson audio-visual database of emotional speech and song (ravdess): A dynamic\",\n        \"Loizou PC (2013) Speech enhancement: theory and practice\",\n        \"Watts O (2013) Combining a vector space representation of linguistic context with a deep neural network for text-to-speech synthesis\",\n        \"(2018a) Stacl: Simultaneous translation with implicit anticipation and controllable latency using prefix-to-prefix framework\",\n        \"Huang L (2019) Incremental text-to-speech synthesis with prefix-to-prefix framework. arXiv preprint arXiv:191102750\",\n        \"Song Y (2018b) Neural tts stylization with adversarial and collaborative games. In: International Conference on Learning Representations\",\n        \"Sonderegger M (2017) Montreal forced aligner: Trainable text-speech alignment using kaldi. In: Interspeech\",\n        \"Bengio Y (2016) Samplernn: An unconditional end-to-end neural audio generation model. arXiv preprint arXiv:161207837\",\n        \"Ney H (2019) An analysis of local monotonic attention variants. In: INTERSPEECH\",\n        \"Dean J (2013) Efficient estimation of word representations in vector space. arXiv preprint arXiv:13013781\",\n        \"In: Thirteenth Annual Conference of the International Speech Communication Association\",\n        \"Mysore GJ (2020) Controllable neural prosody synthesis. arXiv preprint arXiv:200803388\",\n        \"Charpentier F (1990) Pitch-synchronous waveform processing techniques for text-to-speech synthesis using diphones\",\n        \"Rohwer EA (1996) Emotional stress in synthetic speech: Progress and future directions. Speech Communication 20(1-2):85–91\",\n        \"Wolf L (2018) Fitting new speakers based on a short untranscribed sample. In: International Conference on Machine Learning\",\n        \"Kondo T (2008) A method for fundamental frequency estimation and voicing decision: Application to infant utterances recorded in real acoustical environments\",\n        \"Dušek O (2020) One model\",\n        \"Zhang LJ (2019) A review of deep learning based speech synthesis. Applied Sciences 9(19):4050\",\n        \"Nose T (2016) Efficient implementation of global variance compensation for parametric speech synthesis\",\n        \"et al. (2018) Parallel wavenet: Fast high-fidelity speech synthesis. In: International conference on machine learning\",\n        \"Kavukcuoglu K (2016) Wavenet: A generative model for raw audio. arXiv preprint arXiv:160903499\",\n        \"Kavukcuoglu K (2017) Neural discrete representation learning. arXiv preprint arXiv:171100937\",\n        \"Hasegawa-Johnson MA\",\n        \"Huang Z (2019) A mandarin prosodic boundary prediction model based on multi-task learning. In: INTERSPEECH\",\n        \"Khudanpur S (2015) Librispeech: an asr corpus based on public domain audio books. In: 2015 IEEE international conference on acoustics\",\n        \"Lee S (2020) g2pm: A neural grapheme-to-phoneme conversion package for mandarinchinese based on a new open benchmark dataset\",\n        \"Mulc T (2019) Css10: A collection of single speaker speech datasets for 10 languages. arXiv preprint arXiv:190311269\",\n        \"Zhao K (2020) Non-autoregressive neural text-to-speech. In: International Conference on Machine Learning\",\n        \"Miller J (2017) Deep voice 3: Scaling text-to-speech with convolutional sequence learning. arXiv preprint arXiv:171007654\",\n        \"Chen J (2018) Clarinet: Parallel wave generation in end-to-end text-to-speech. arXiv preprint arXiv:180707281\",\n        \"Song Z (2020) Waveflow: A compact flow-based model for raw audio. In: International Conference on Machine Learning\",\n        \"Mitchell T (2018) Contextual parameter generation for universal neural machine translation. arXiv preprint arXiv:180808493\",\n        \"Catanzaro B (2019) Waveglow: A flow-based generative network for speech synthesis. In: ICASSP 2019-2019 IEEE International Conference on Acoustics\",\n        \"Hasegawa-Johnson M (2019) Autovc: Zero-shot voice style transfer with only autoencoder loss. In: International Conference on Machine Learning\",\n        \"Hasegawa-Johnson M\",\n        \"Soong F (2010) Automatic prosody prediction and detection with conditional random field (crf) models\",\n        \"Sutskever I (2019) Language models are unsupervised multitask learners. OpenAI blog 1(8):9\",\n        \"Eck D (2017) Online and linear-time attention by enforcing monotonic alignments. In: International Conference on Machine Learning\",\n        \"“method for the subjective assessment of intermediate sound quality (mushra)”. International Telecommunications Union\",\n        \"Liu TY (2019a) Fastspeech: Fast\",\n        \"Liu TY (2019b) Almost unsupervised text to speech and automatic speech recognition. In: International Conference on Machine Learning\",\n        \"Liu TY (2020) Fastspeech 2: Fast and high-quality end-to-end text-to-speech. arXiv preprint arXiv:200604558\",\n        \"Mohamed S (2015) Variational inference with normalizing flows. In: International Conference on Machine Learning\",\n        \"Seltzer M (2011) Crowdmos: An approach for crowdsourcing mean opinion score studies. In: 2011 IEEE international conference on acoustics\",\n        \"Hekstra AP (2001) Perceptual evaluation of speech quality (pesq)-a new method for speech quality assessment of telephone networks and codecs\",\n        \"Saruwatari H (2017) Statistical parametric speech synthesis incorporating generative adversarial networks. IEEE/ACM Transactions on Audio\",\n        \"In: Seventh European Conference on Speech Communication and Technology\",\n        \"Fukumizu K (2013) Equivalence of distance-based and rkhs-based statistics in hypothesis testing. The Annals of Statistics pp 2263–2291\",\n        \"Birch A (2015) Neural machine translation of rare words with subword units. arXiv preprint arXiv:150807909\",\n        \"Series B (2014) Method for the subjective assessment of intermediate quality level of audio systems\",\n        \"Segura C (2019) Blow: a single-scale hyperconditioned flow for non-parallel raw-audio voice conversion. arXiv preprint arXiv:190600794\",\n        \"De Freitas N (2015) Taking the human out of the loop: A review of bayesian optimization. Proceedings of the IEEE 104(1):148–175\",\n        \"Yao K (2016) A bi-directional lstm approach for polyphone disambiguation in mandarin chinese\",\n        \"Sarawagi S (2018) Surprisingly easy hard-attention for sequence to sequence learning\",\n        \"Vaswani A (2018) Self-attention with relative position representations. arXiv preprint arXiv:180302155\",\n        \"Vogelstein JT (2020) The exact equivalence of distance and kernel methods in hypothesis testing. AStA Advances in Statistical Analysis pp 1–19\",\n        \"et al. (2018) Natural tts synthesis by conditioning wavenet on mel spectrogram predictions. In: 2018 IEEE International Conference on Acoustics\",\n        \"Wu Y (2020) Non-attentive tacotron: Robust and controllable neural tts synthesis including unsupervised duration modeling\",\n        \"Li M (2020) Aishell-3: A multi-speaker mandarin tts corpus and the baselines. arXiv preprint arXiv:201011567\",\n        \"Saurous RA (2018) Towards end-to-end prosody transfer for expressive speech synthesis with tacotron. In: international conference on machine learning\",\n        \"Maheswaranathan N\",\n        \"Ermon S (2020) Improved techniques for training score-based generative models. arXiv preprint arXiv:200609011\",\n        \"Ermon S (2020) Sliced score matching: A scalable approach to density and score estimation. In: Uncertainty in Artificial Intelligence\",\n        \"Bengio Y (2017) Char2wav: End-to-end speech synthesis\",\n        \"In: 2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)\",\n        \"Hueber T (2020) What the future brings: Investigating the impact of lookahead for incremental neural tts. arXiv preprint arXiv:200902035\",\n        \"Besacier L (2021) Alternate endings: Improving prosody for incremental neural tts with predicted future text input. arXiv preprint arXiv:210209914\",\n        \"Gustafson J (2020) Breathing and speech planning in spontaneous speech synthesis. In: ICASSP 2020-2020 IEEE International Conference on Acoustics\",\n        \"Lolive D (2018) Can we generate emotional pronunciations for expressive speech synthesis? IEEE Transactions on Affective Computing 11(4):684–695\",\n        \"Nachmani E (2017) Voiceloop: Voice fitting and synthesis via a phonological loop. arXiv preprint arXiv:170706588\",\n        \"Richmond K (2019) Analysis of pronunciation learning in end-to-end speech synthesis. In: INTERSPEECH\",\n        \"Taylor P (2009) Text-to-speech synthesis\",\n        \"Dutoit T (2019) Emotional speech datasets for english speech synthesis purpose: A review. In: Proceedings of SAI Intelligent Systems Conference\",\n        \"Nakamura S (2017) Listening while speaking: Speech chain by deep learning\",\n        \"Nakamura S (2018) Machine speech chain with one-shot speaker adaptation. arXiv preprint arXiv:180310525\",\n        \"Oura K (2013) Speech synthesis based on hidden markov models. Proceedings of the IEEE 101(5):1234–1252\",\n        \"Welling M (2016) Improving variational auto-encoders using householder flow. arXiv preprint arXiv:161109630\",\n        \"Lee HY (2019) End-to-end text-to-speech for low-resource languages by cross-lingual transfer learning. arXiv preprint arXiv:190406508\",\n        \"Robinson T (1993) Speech synthesis using artificial neural networks trained on cepstral coefficients\",\n        \"Kang HG (2020) Emotional speech synthesis with rich and granularized control. In: ICASSP 2020-2020 IEEE International Conference on Acoustics\",\n        \"Dušek O (2020) Speedyspeech: Efficient neural speech synthesis. arXiv preprint arXiv:200803802\",\n        \"Yamagishi J (2018) Speech enhancement of noisy and reverberant speech for text-to-speech. IEEE/ACM Transactions on Audio\",\n        \"Catanzaro B (2020a) Mellotron: Multispeaker expressive voice synthesis by conditioning on rhythm\",\n        \"Catanzaro B (2020b) Flowtron: an autoregressive flow-based generative network for text-to-speech synthesis. arXiv preprint arXiv:200505957\",\n        \"Kavukcuoglu K (2016) Pixel recurrent neural networks. In: International Conference on Machine Learning\",\n        \"Lewis M (2019) Melnet: A generative model for audio in the frequency domain. arXiv preprint arXiv:190601083\",\n        \"Polosukhin I (2017) Attention is all you need. arXiv preprint arXiv:170603762\",\n        \"et al. (2016) Superseded-cstr vctk corpus: English multi-speaker corpus for cstr voice cloning toolkit\",\n        \"Berendsen E (1988) From text to speech: the mitalk system. Journal of Phonetics 16(3):371–375\",\n        \"Wang G (2019) Deep text-to-speech system with seq2seq model\",\n        \"In: Proceedings of the IEEE conference on computer vision and pattern recognition\",\n        \"et al. (2017) Tacotron: Towards end-to-end speech synthesis. arXiv preprint arXiv:170310135\",\n        \"Saurous RA (2018b) Style tokens: Unsupervised style modeling\",\n        \"Song Y (2019) Multi-reference neural tts stylization with adversarial cycle consistency. arXiv preprint arXiv:191011958\",\n        \"Talkin DT (1997) The aligner: Text-to-speech alignment using markov models. In: Progress in speech synthesis\",\n        \"Auli M (2019) Pay less attention with lightweight and dynamic convolutions. arXiv preprint arXiv:190110430\",\n        \"Liu TY (2020) Lrspeech: Extremely low-resource speech synthesis and recognition\",\n        \"Bengio Y (2015) Show\",\n        \"Nakamura S (2019) Neural itts: Toward synthesizing speech in real-time with end-to-end neural text-to-speech framework\",\n        \"Liu S (2019) Pre-trained text representations for improving front-end text processing in mandarin text-to-speech synthesis. In: INTERSPEECH\",\n        \"Xie L (2021) Multi-band melgan: Faster waveform generation for high-quality text-to-speech. In: 2021 IEEE Spoken Language Technology Workshop (SLT)\",\n        \"Lu J (2014) Deep learning theory and its application in speech recognition. Commun Countermeas 33:1–5\",\n        \"Kim I (2020) Vocgan: A high-fidelity real-time vocoder with a hierarchically-nested adversarial network. arXiv preprint arXiv:200715256\",\n        \"Yamagishi J (2019) Initial investigation of an encoder-decoder end-to-end tts framework using marginalization of monotonic hard latent alignments\",\n        \"Kitamura T (1999) Simultaneous modeling of spectrum\",\n        \"Tokuda K (2018) Mel-cepstrum-based quantization noise shaping applied to neural-network-based speech waveform synthesis\",\n        \"et al. (2019) Durian: Duration informed attention network for multimodal synthesis. arXiv preprint arXiv:190901700\",\n        \"Kocisky T (2016a) The neural noisy channel. arXiv preprint arXiv:161102554\",\n        \"Blunsom P (2016b) Online segment to segment neural transduction. arXiv preprint arXiv:160908194\",\n        \"Sutskever I (2015) Reinforcement learning neural turing machines-revised. arXiv preprint arXiv:150500521\",\n        \"Schuster M (2013) Statistical parametric speech synthesis using deep neural networks. In: 2013 ieee international conference on acoustics\",\n        \"Tokuda K (2007) The hmm-based speech synthesis system (hts) version 2.0. In: SSW\",\n        \"Black AW (2009) Statistical parametric speech synthesis. speech communication 51(11):1039–1064\",\n        \"Senior A (2014) Statistical parametric speech synthesis based on recurrent neural networks. In: Poster presentation given at UKSpeech Conference\",\n        \"Agiomyrgiannakis Y\",\n        \"Wu Y (2019) Libritts: A corpus derived from librispeech for text-to-speech. arXiv preprint arXiv:190402882\",\n        \"Lin Y (2020) Unsupervised learning for sequence-to-sequence text-to-speech for low-resource languages. arXiv preprint arXiv:200804549\",\n        \"Metaxas DN (2018a) Stackgan++: Realistic image synthesis with stacked generative adversarial networks\",\n        \"Odena A (2019a) Self-attention generative adversarial networks. In: International conference on machine learning\",\n        \"Dai LR (2018b) Forward attention in sequence-to-sequence acoustic modeling for speech synthesis. In: 2018 IEEE International Conference on Acoustics\",\n        \"Dai L (2018c) Deep-fsmn for large vocabulary continuous speech recognition. In: 2018 IEEE International Conference on Acoustics\",\n        \"Wang L (2019b) Deep learning for mandarin-tibetan cross-lingual speech synthesis. IEEE Access 7:167884–167894\",\n        \"Wang Y (2020b) Unified mandarin tts front-end based on distilled bert model. arXiv preprint arXiv:201215404\",\n        \"Zhou F (2016) Mandarin prosodic phrase prediction based on syntactic trees. In: SSW\",\n        \"Liu S (2020c) Adadurian: Few-shot adaptation for neural text-to-speech with durian. arXiv preprint arXiv:200505642\",\n        \"Li Y (2018) Blstm-crf based end-to-end prosodic boundary prediction with context sensitive embeddings in a text-to-speech front-end. In: Interspeech\",\n        \"Yi J (2019) Forward–backward decoding sequence for regularizing end-to-end tts. IEEE/ACM Transactions on Audio\"\n    ],\n    \"reasoning\": \"Selected these 253 references because they represent foundational work and recent advances in Review of end-to-end speech synthesis technology based on deep learning, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}