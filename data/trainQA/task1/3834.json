{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 211 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling\n\nPaper Abstract: Abstract Warning: this paper contains example data that may be offensive or upsetting. Over the last several years, end-to-end neural conversational agents have vastly improved in their ability to carry a chit-chat conversation with humans. However, these models are often trained on large datasets from the internet, and as a result, may learn undesirable behaviors from this data, such as toxic or otherwise harmful language. Researchers must thus wrestle with the issue of how and when to release these models. In this paper, we survey the problem landscape for safety for end-to-end conversational AI and discuss recent and related work. We highlight tensions between values, potential positive impact and potential harms, and provide a framework for making decisions about whether and how to release these models, following the tenets of value-sensitive design. We additionally provide a suite of tools to enable researchers to make better-informed decisions about training and releasing end-to-end conversational AI models.\n\n{retrieved_text}\n\nGenerate exactly 211 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 211\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Alexa, Google, Siri: What are your pronouns? Gender and anthropomorphism in the design and perception of conversational assistants\",\n        \"Towards a human-like open-domain chatbot\",\n        \"History for visual dialog: Do we really need it?\",\n        \"Breakdown of will\",\n        \"Living up to the chatbot hype: The influence of anthropomorphic design cues and communicative agency framing on conversational agent and company perceptions\",\n        \"How to do things with words\",\n        \"The computational therapeutic: exploring weizenbaum’s eliza as a history of the present\",\n        \"Bad is stronger than good\",\n        \"The pushshift reddit dataset\",\n        \"Climbing towards NLU: On meaning, form, and understanding in the age of data\",\n        \"On the dangers of stochastic parrots: Can language models be too big?\",\n        \"Multitask learning for mental health conditions with limited social media data\",\n        \"On the gap between adoption and understanding in nlp\",\n        \"Patient and consumer safety risks when using conversational assistants for medical information: An observational study of siri, alexa, and google assistant\",\n        \"Language (technology) is power: A critical survey of” bias” in nlp\",\n        \"Distributional justice: Theory and measurement, volume 47\",\n        \"SHIHbot: A Facebook chatbot for sexual health information on HIV/AIDS\",\n        \"Language models are few-shot learners\",\n        \"‘have you thought about…’: Talking about ethical implications of research\",\n        \"The secret sharer: Evaluating and testing unintended memorization in neural networks\",\n        \"Extracting training data from large language models\",\n        \"Property-driven training: All you (n)ever wanted to know about\",\n        \"I feel offended, don’t be abusive! implicit/explicit messages in offensive and abusive language\",\n        \"Privacy by design: The 7 foundational principles\",\n        \"# metoo: How conversational systems respond to sexual harassment\",\n        \"A crowd-based evaluation of abuse response strategies in conversational agents\",\n        \"Alana v2: Entertaining and informative open-domain social dialogue using ontologies and entity linking\",\n        \"BioMedBERT: A pre-trained biomedical language model for QA and IR\",\n        \"Question-answering dialogue system for emergency operations\",\n        \"Should an agent be ignoring it?: A study of verbal abuse types and conversational agents’ response styles\",\n        \"Empathy is all you need: How a conversational agent should respond to verbal abuse\",\n        \"Law enforcement chatbots, case study: 4\",\n        \"Excellence and trust in artificial intelligence\",\n        \"Quantifying mental health signals in Twitter\",\n        \"Artificial intelligence research needs responsible publication norms\",\n        \"Plug and play language models: a simple approach to controlled text generation\",\n        \"I hate you! disinhibition with virtual partners\",\n        \"Stupid computer! abuse and social identities\",\n        \"Predicting depression via social media\",\n        \"Spot the bot: A robust and efficient framework for the evaluation of conversational dialogue systems\",\n        \"BERT: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Accountability in algorithmic decision making\",\n        \"Algorithm aversion: People erroneously avoid algorithms after seeing them err\",\n        \"Queens are powerful too: Mitigating gender bias in dialogue generation\",\n        \"Build it break it fix it for dialogue safety: Robustness from adversarial human attack\",\n        \"Wizard of Wikipedia: Knowledge-powered conversational agents\",\n        \"Multi-dimensional gender bias classification\",\n        \"The second conversational intelligence challenge (ConvAI2)\",\n        \"Measuring and mitigating unintended bias in text classification\",\n        \"Show your work: Improved reporting of experimental results\",\n        \"Evaluating the state-of-the-art of end-to-end natural language generation: The e2e nlg challenge\",\n        \"OlloBot - towards a text-based Arabic health conversational agent: Evaluation and results\",\n        \"The affect heuristic in judgments of risks and benefits\",\n        \"Gender, race, and perceived risk: The’white male’effect\",\n        \"Returning the N to NLP: Towards contextually personalized classification models\",\n        \"Gender, race, and perception of environmental health risks\",\n        \"A survey on automatic detection of hate speech in text\",\n        \"Toxic, hateful, offensive or abusive? what are we really classifying? an empirical analysis of hate speech datasets\",\n        \"Automatic detection of hate speech in text: an overview of the topic and dataset annotation with hierarchical classes\",\n        \"Value sensitive design and information systems\",\n        \"A survey of value sensitive design methods\",\n        \"Byu-eve: Mixed initiative dialog via structured knowledge graph traversal and conversational scaffolding\",\n        \"Japanese: A heavily culture-laden language\",\n        \"Neural approaches to conversational ai\",\n        \"Realtoxicityprompts: Evaluating neural toxic degeneration in language models\",\n        \"Cyberbullying detection with fairness constraints\",\n        \"XHate-999: Analyzing and detecting abusive language across domains and languages\",\n        \"How short is too short? implications of length and framing on the effectiveness of privacy notices\",\n        \"Logic and conversation\",\n        \"Strategy and plan of action on hate speech\",\n        \"Safe by design: where are we now?\",\n        \"Fortifying toxic speech detectors against veiled toxicity, 2020\",\n        \"Learning from dialogue after deployment: Feed yourself, chatbot!\",\n        \"Harm inflation: Making sense of concept creep\",\n        \"Machine learning for dialog state tracking: A review\",\n        \"Something’s brewing! early prediction of controversy-causing posts from discussion features\",\n        \"Moving beyond “algorithmic bias is a data problem”\",\n        \"The social impact of natural language processing\",\n        \"The importance of modeling social factors of language: Theory and practice\",\n        \"Twenty years of confusion in human evaluation: Nlg needs evaluation sheets and standardised definitions\",\n        \"VADER: A parsimonious rule-based model for sentiment analysis of social media text\",\n        \"When choice is demotivating: Can one desire too much of a good thing?\",\n        \"Revisiting visual question answering baselines\",\n        \"A South Korean chatbot shows just how sloppy tech companies can be with user data\",\n        \"Suicidal ideation detection: A review of machine learning methods and applications\",\n        \"A just and comprehensive strategy for using NLP to address online abuse\",\n        \"Politeness in East Asia\",\n        \"Thinking, fast and slow\",\n        \"Prospect theory: An analysis of decision under risk\",\n        \"Anomalies: The endowment effect, loss aversion, and status quo bias\",\n        \"The social amplification of risk: A conceptual framework\",\n        \"CTRL: A conditional transformer language model for controllable generation\",\n        \"A distributional approach to controlled text generation\",\n        \"Advancing the state of the art in open domain dialog systems through the Alexa prize\",\n        \"The hateful memes challenge: Detecting hate speech in multimodal memes\",\n        \"Dynabench: Rethinking benchmarking in NLP\",\n        \"Towards ethics by design in online abusive content detection, 2020\",\n        \"Learning from the covid-19 pandemic to address climate change\",\n        \"Tartan: A retrieval-based socialbot powered by a dynamic finite-state machine architecture, 2018\",\n        \"Pitfalls of static language modelling\",\n        \"Revisiting the evaluation of theory of mind through question answering\",\n        \"Exploring social bias in chatbots using stereotype knowledge\",\n        \"Retrieval-augmented generation for knowledge-intensive NLP tasks\",\n        \"Crisis MT: Developing a cookbook for MT in crisis situations\",\n        \"ACUTE-EVAL: Improved dialogue evaluation with optimized questions and multi-turn comparisons\",\n        \"On-the-fly controlled text generation with experts and anti-experts, 2021\",\n        \"Does gender matter? towards fairness in dialogue systems\",\n        \"Chat as expected: Learning to manipulate black-box neural dialogue models\",\n        \"Community-level research on suicidality prediction in a secure environment: Overview of the CLPsych 2021 shared task\",\n        \"Politeness transfer: A tag and generate approach\",\n        \"USR: An unsupervised and reference free evaluation metric for dialog generation\",\n        \"Value tensions in design: the value sensitive design, development, and appropriation of a corporation’s groupware system\",\n        \"Why we should have seen that coming\",\n        \"Model cards for model reporting\",\n        \"Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning\",\n        \"A framework and tool for collaborative extraction of reliable information\",\n        \"Getting started with neurips 2020, 2020\",\n        \"On learning and representing social meaning in NLP: a sociolinguistic perspective\",\n        \"Adversarial NLI: A new benchmark for natural language understanding\",\n        \"Adversarial over-sensitivity and over-stability strategies for dialogue models\",\n        \"Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp\",\n        \"RankME: Reliable human ratings for natural language generation\",\n        \"HONEST: Measuring hurtful sentence completion in language models\",\n        \"The hitchhiker’s guide to computational linguistics in suicide prevention\",\n        \"Reducing malicious use of synthetic media research: Considerations and potential release practices for machine learning\",\n        \"Physicians’ perceptions of chatbots in health care: Cross-sectional web-based survey\",\n        \"Opportunity cost\",\n        \"Alana: Social dialogue using an ensemble model and a ranker trained on user feedback\",\n        \"Neural generation meets real people: Towards emotionally engaging mixed-initiative conversations\",\n        \"Managing the risks of ai research: Six recommendations for responsible publication, 2021\",\n        \"Publication norms for responsible ai: Ongoing initiative, 2020\",\n        \"A deep reinforced model for abstractive summarization\",\n        \"Using health chatbots for behavior change: A mapping study\",\n        \"Boosting low-resource biomedical QA via entity-aware masking strategies\",\n        \"Numeracy and decision making\",\n        \"The psychology of judgment and decision making\",\n        \"Case study: Deontological ethics in nlp\",\n        \"Institutionalizing ethics in AI through broader impact requirements\",\n        \"Language models are unsupervised multitask learners\",\n        \"Conversational AI: The science behind the Alexa Prize\",\n        \"Towards empathetic open-domain conversation models: A new benchmark and dataset\",\n        \"Naturally occurring language as a source of evidence in suicide prevention\",\n        \"How numeracy influences risk comprehension and medical decision making\",\n        \"Automatic learning and evaluation of user-centered objective functions for dialogue system optimisation\",\n        \"Recipes for building an open-domain chatbot\",\n        \"Hatecheck: Functional tests for hate speech detection models\",\n        \"Conversational ai: Social and ethical considerations\",\n        \"Do neural dialog systems use the conversation history effectively? an empirical study\",\n        \"The risk of racial bias in hate speech detection\",\n        \"Suicide ideation detection via social and temporal user representations using hyperbolic learning\",\n        \"Self-diagnosis and self-debiasing: A proposal for reducing corpus-based bias in NLP\",\n        \"A survey on hate speech detection using natural language processing\",\n        \"An experimental test of loss aversion\",\n        \"What makes a good conversation? how controllable attributes affect human judgments\",\n        \"BLEURT: Learning robust metrics for text generation\",\n        \"Building end-to-end dialogue systems using generative hierarchical neural network models\",\n        \"How much choice is too much? contributions to 401 (k) retirement plans\",\n        \"Otters: One-turn topic transitions for open-domain dialogue\",\n        \"Predictive biases in natural language processing models: A conceptual framework and overview\",\n        \"Neural responding machine for short-text conversation\",\n        \"The woman worked as a babysitter: On biases in language generation\",\n        \"Revealing persona biases in dialogue systems\",\n        \"Membership inference attacks against machine learning models\",\n        \"Deploying lifelong open-domain dialogue learning\",\n        \"Perception of risk\",\n        \"Perceived risk, trust, and democracy\",\n        \"Trust, emotion, sex, politics, and science: Surveying the risk-assessment battlefield\",\n        \"If i look at the mass i will never act: Psychic numbing and genocide\",\n        \"Risk perception and affect\",\n        \"Risk as analysis and risk as feelings: Some thoughts about affect, reason, risk and rationality\",\n        \"Can you put it all together: Evaluating conversational agents’ ability to blend skills\",\n        \"Controlling style in generated dialogue, 2020b\",\n        \"Release strategies and the social impacts of language models\",\n        \"Process for adapting language models to society (palms) with values-targeted datasets\",\n        \"Energy and policy considerations for deep learning in NLP\",\n        \"Nudge: Improving decisions about health, wealth, and happiness\",\n        \"Detecting ‘dirt’and ‘toxicity’: Rethinking content moderation as pollution behaviour\",\n        \"Ask diana: A keyword-based chatbot system for water-related disaster management\",\n        \"Four-stage framework for implementing a chatbot system in disaster emergency operation data management: A flood disaster management case study\",\n        \"Rational choice and the framing of decisions\",\n        \"Loss aversion in riskless choice: A reference-dependent model\",\n        \"Mamabot: a system based on ML and NLP for supporting women and families during pregnancy\",\n        \"Translating values into design requirements\",\n        \"Design for value change\",\n        \"Thinking ethically\",\n        \"Directions in abusive language training data: Garbage in, garbage out, 2020\",\n        \"Challenges and frontiers in abusive content detection\",\n        \"Learning from the worst: Dynamically generated datasets to improve online hate detection\",\n        \"A neural conversational model\",\n        \"PARADISE: A framework for evaluating spoken dialogue agents\",\n        \"Detect all abuse! toward universal abusive language detection models\",\n        \"The impact of culture on loss aversion\",\n        \"Hateful symbols or hateful people? Predictive features for hate speech detection on Twitter\",\n        \"Eliza — a computer program for the study of natural language communication between man and machine\",\n        \"Chatbots RESET: A framework for governing responsible use of conversational AI in healthcare, 2020\",\n        \"Ex machina: Personal attacks seen at scale\",\n        \"Demoting racial bias in hate speech detection\",\n        \"Detoxifying language models risks marginalizing minority voices, 2021a\",\n        \"Recipes for safety in open-domain chatbots, 2020\",\n        \"Bot-adversarial dialogue for safe conversational agents\",\n        \"Better conversations by modeling, filtering, and optimizing for coherence and diversity\",\n        \"Depression and self-harm risk assessment in online forums\",\n        \"Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval)\",\n        \"Semeval-2020 task 12: Multilingual offensive language identification in social media (offenseval 2020)\",\n        \"Personalizing dialogue agents: I have a dog, do you have pets too?\",\n        \"Bertscore: Evaluating text generation with bert\",\n        \"Detecting and classifying malevolent dialogue responses: Taxonomy, data and methodology\",\n        \"DialoGPT: Large-scale generative pre-training for conversational response generation\",\n        \"Men also like shopping: Reducing gender bias amplification using corpus-level constraints\",\n        \"Challenges in automated debiasing for toxic language detection\",\n        \"Challenges in automated debiasing for toxic language detection, 2021b\"\n    ],\n    \"reasoning\": \"Selected these 211 references because they represent foundational work and recent advances in Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}