{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 50 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: A Family of Density-Scaled Filtered ComplexesThe author acknowledges support from the Eugene V. Cota‚ÄìRobles fellowship.\n\nPaper Abstract: Abstract We develop novel methods for using persistent homology to infer the homology of an unknown Riemannian manifold (M,g)ùëÄùëî(M,g) from a point cloud sampled from an arbitrary smooth probability density function. Standard distance-based filtered complexes, such as the ƒåech complex, often have trouble distinguishing noise from features that are simply small. We address this problem by defining a family of ‚Äúdensity-scaled filtered complexes‚Äù that includes a density-scaled ƒåech complex and a density-scaled Vietoris‚ÄìRips complex. We show that the density-scaled ƒåech complex is homotopy-equivalent to MùëÄM for filtration values in an interval whose starting point converges to 00 in probability as the number of points N‚Üí‚àû‚ÜíùëÅN\\to\\infty and whose ending point approaches infinity as N‚Üí‚àû‚ÜíùëÅN\\to\\infty. By contrast, the standard ƒåech complex may only be homotopy-equivalent to MùëÄM for a very small range of filtration values. The density-scaled filtered complexes also have the property that they are invariant under conformal transformations, such as scaling. We implement a filtered complex DVR^^DVR\\widehat{\\textnormal{DVR}} that approximates the density-scaled Vietoris‚ÄìRips complex, and we empirically test the performance of our implementation. As examples, we use DVR^^DVR\\widehat{\\textnormal{DVR}} to identify clusters that have different densities, and we apply DVR^^DVR\\widehat{\\textnormal{DVR}} to a time-delay embedding of the Lorenz dynamical system. Our implementation is stable (under conditions that are almost surely satisfied) and designed to handle outliers in the point cloud that do not lie on MùëÄM.\n\n{retrieved_text}\n\nGenerate exactly 50 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 50\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Persistence images: A stable vector representation of persistent homology\",\n        \"Surface reconstruction by voronoi filtering\",\n        \"Laplacian eigenmaps for dimensionality reduction and data representation\",\n        \"Weighted persistent homology\",\n        \"Persistent homology analysis of brain artery trees\",\n        \"A Panoramic View of Riemannian Geometry, 1st edn., chap. 6.5.3.\",\n        \"Topological consistency via kernel estimation\",\n        \"On the vanishing of homology in random ƒåech complexes\",\n        \"Intrinsic persistent homology via density-based metric learning\",\n        \"On the imbedding of systems of compacta in simplicial complexes\",\n        \"Persistent homology detects curvature\",\n        \"Persistent homology and materials informatics\",\n        \"The Structure and Stability of Persistence Modules, 1st edn.\",\n        \"Persistence stability for geometric complexes\",\n        \"Robust topological inference: Distance to a measure and kernel distance\",\n        \"Persistence diagrams of cortical surface data\",\n        \"Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data\",\n        \"Computational Topology: An Introduction\",\n        \"Persistent homology of geospatial data: A case study with voting\",\n        \"Random coverings\",\n        \"An algorithm for finding intrinsic dimensionality of data\",\n        \"Elementary Applied Topology, 1st edn.\",\n        \"Nonhomogeneous Euclidean first-passage percolation and distance learning\",\n        \"Bounded geometries, fractals, and low-distortion embeddings\",\n        \"Algebraic Topology, 1st edn.\",\n        \"Finding the homology of manifolds using ellipsoids\",\n        \"Dimension reduction by local principal component analysis\",\n        \"Finding nearest neighbors in growth-restricted metrics\",\n        \"A nonparametric estimate of a multivariate density function\",\n        \"Deterministic nonperiodic flow\",\n        \"Topology of cyclooctane energy landscape\",\n        \"Finding the homology of submanifolds with high confidence from random samples\",\n        \"A roadmap for the computation of persistent homology\",\n        \"Submanifold density estimation\",\n        \"Intrinsic statistics on riemannian manifolds: Basic tools for geometric measurements\",\n        \"Riemannian Geometry, Graduate Texts in Mathematics, vol. 171, 2nd edn.\",\n        \"Nonlinear dimensionality reduction by locally linear embedding\",\n        \"Multivariate Density Estimation: Theory, Practice, and Visualization\",\n        \"Global versus local methods in nonlinear dimensionality reduction\",\n        \"Density Estimation for Statistics and Data Analysis, Monographs on Statistics and Applied Probability, vol. 26, 1st edn.\",\n        \"Persistent homology of time-dependent functional networks constructed from coupled time series\",\n        \"A topological perspective on weather regimes\",\n        \"Detecting strange attractors in turbulence\",\n        \"A global geometric framework for nonlinear dimensionality reduction\",\n        \"Topological data analysis of biological aggregation models\",\n        \"Consistent manifold representation for topological data analysis\",\n        \"SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python\",\n        \"Conical dimension as an intrinsic dimension estimator and its applications\",\n        \"A Handbook on Curves and their Properties, p. 8.\",\n        \"Computing persistent homology\"\n    ],\n    \"reasoning\": \"Selected these 50 references because they represent foundational work and recent advances in A Family of Density-Scaled Filtered ComplexesThe author acknowledges support from the Eugene V. Cota‚ÄìRobles fellowship., providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}