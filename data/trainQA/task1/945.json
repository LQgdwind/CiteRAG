{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 65 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Algorithmic recourse under imperfect causal knowledge: a probabilistic approach\n\nPaper Abstract: Abstract Recent work has discussed the limitations of counterfactual explanations to recommend actions for algorithmic recourse, and argued for the need of taking causal relationships between features into consideration. Unfortunately, in practice, the true underlying structural causal model is generally unknown. In this work, we first show that it is impossible to guarantee recourse without access to the true structural equations. To address this limitation, we propose two probabilistic approaches to select optimal actions that achieve recourse with high probability given limited causal knowledge (e.g., only the causal graph). The first captures uncertainty over structural equations under additive Gaussian noise, and uses Bayesian model averaging to estimate the counterfactual distribution. The second removes any assumptions on the structural equations by instead computing the average effect of recourse actions on individuals similar to the person who seeks recourse, leading to a novel subpopulation-based interventional notion of recourse. We then derive a gradient-based procedure for selecting optimal recourse actions, and empirically show that the proposed approaches lead to more reliable recommendations under imperfect causal knowledge than non-probabilistic baselines.\n\n{retrieved_text}\n\nGenerate exactly 65 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 65\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Estimating conditional average treatment effects\",\n        \"Bayesian inference of individualized treatment effects using multi-task gaussian processes\",\n        \"Identification of causal effects using instrumental variables\",\n        \"Counterfactual probabilities: Computational methods, bounds and applications\",\n        \"The hidden assumptions behind counterfactual explanations and principal reasons\",\n        \"Bandwidth selection for kernel conditional density estimation\",\n        \"Explainable machine learning in deployment\",\n        \"Mixture density networks\",\n        \"The tradeoffs of large scale learning\",\n        \"Path-specific counterfactual fairness\",\n        \"Causal discovery from a mixture of experimental and observational data\",\n        \"Analyse des liaisons de probabilité\",\n        \"Gaussian process networks\",\n        \"A kernel two-sample test\",\n        \"Equalizing recourse across groups\",\n        \"Nonlinear causal discovery with additive noise models\",\n        \"Nonlinear independent component analysis: Existence and uniqueness results\",\n        \"Causal inference using the algorithmic markov condition\",\n        \"Towards realistic individual recourse and actionable explanations in black-box decision making systems\",\n        \"Model-agnostic counterfactual explanations for consequential decisions\",\n        \"A survey of algorithmic recourse: definitions, formulations, solutions, and prospects\",\n        \"Algorithmic recourse: from counterfactual explanations to interventions\",\n        \"Minima of functions of several variables with inequalities as side conditions\",\n        \"Avoiding discrimination through causal reasoning\",\n        \"Fair decisions despite imperfect predictions\",\n        \"Adam: A method for stochastic optimization\",\n        \"Auto-encoding variational Bayes\",\n        \"Nonlinear programming\",\n        \"Counterfactual fairness\",\n        \"Counterfactuals\",\n        \"Causal effect inference with deep latent-variable models\",\n        \"Preserving causal constraints in counterfactual explanations for machine learning classifiers\",\n        \"Explaining machine learning classifiers through diverse counterfactual explanations\",\n        \"UCI repository of machine learning databases\",\n        \"Causality\",\n        \"Predictive policing: The role of crime forecasting in law enforcement operations\",\n        \"Identifiability of gaussian structural equation models with equal error variances\",\n        \"Elements of causal inference: foundations and learning algorithms\",\n        \"FACE: Feasible and actionable counterfactual explanations\",\n        \"Stochastic backpropagation and approximate inference in deep generative models\",\n        \"Preface to the special issue on data mining for personalised educational systems\",\n        \"When worlds collide: integrating different counterfactual assumptions in fairness\",\n        \"Reliable decision support using counterfactual models\",\n        \"Certifai: A common framework to provide explanations and analyse the fairness and robustness of black-box models\",\n        \"Identification of conditional interventional distributions\",\n        \"Complete identification methods for the causal hierarchy\",\n        \"Gaussian process structural equation models with latent variables\",\n        \"Learning structured output representation using deep conditional generative models\",\n        \"Probabilities of causation: Bounds and identification\",\n        \"Causal discovery from changes\",\n        \"A general identification condition for causal effects\",\n        \"Lecture notes: Gaussian identities\",\n        \"Conditional density estimation with bayesian normalising flows\",\n        \"Actionable recourse in linear classification\",\n        \"The philosophical basis of algorithmic recourse\",\n        \"Optimal experimental design via Bayesian optimization: active causal structure learning for Gaussian process networks\",\n        \"On the fairness of causal algorithmic recourse\",\n        \"Why a right to explanation of automated decision-making does not exist in the general data protection regulation\",\n        \"Counterfactual explanations without opening the black box: Automated decisions and the GDPR\",\n        \"Graphical models, exponential families, and variational inference\",\n        \"The blessings of multiple causes\",\n        \"Gaussian processes for machine learning, volume 2\",\n        \"Equality of opportunity in classification: A causal approach\",\n        \"Fairness in decision-making—the causal explanation formula\",\n        \"On the identifiability of the post-nonlinear causal model\"\n    ],\n    \"reasoning\": \"Selected these 65 references because they represent foundational work and recent advances in Algorithmic recourse under imperfect causal knowledge: a probabilistic approach, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}