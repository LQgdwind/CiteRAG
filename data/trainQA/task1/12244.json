{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 53 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Multi-Strided Access Patterns to Boost Hardware Prefetching\n\nPaper Abstract: Abstract. Important memory-bound kernels, such as linear algebra, convolutions, and stencils, rely on SIMD instructions as well as optimizations targeting improved vectorized data traversal and data re-use to attain satisfactory performance. On contemporary CPU architectures, the hardware prefetcher is of key importance for efficient utilization of the memory hierarchy. In this paper, we demonstrate that transforming a memory access pattern consisting of a single stride to one that concurrently accesses multiple strides, can boost the utilization of the hardware prefetcher, and in turn improves the performance of memory-bound kernels significantly. Using a set of micro-benchmarks, we establish that accessing memory in a multi-strided manner enables more cache lines to be concurrently brought into the cache, resulting in improved cache hit ratios and higher effective memory bandwidth without the introduction of costly software prefetch instructions. Subsequently, we show that multi-strided variants of a collection of six memory-bound dense compute kernels outperform state-of-the-art counterparts on three different micro-architectures. More specifically, for kernels among which Matrix Vector Multiplication, Convolution Stencil and kernels from PolyBench, we achieve significant speedups of up to 12.55x over Polly, 2.99x over MKL, 1.98x over OpenBLAS, 1.08x over Halide and 1.87x over OpenCV. The code transformation to take advantage of multi-strided memory access is a natural extension of the loop unroll and loop interchange techniques, allowing this method to be incorporated into compiler pipelines in the future.\n\n{retrieved_text}\n\nGenerate exactly 53 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 53\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Learning to optimize halide with tree search and random programs\",\n        \"Graph Prefetching Using Data Structure Knowledge\",\n        \"High performance implementation of 2D convolution using Intel’s advanced vector extensions\",\n        \"An effective on-chip preloading scheme to reduce data access penalty\",\n        \"An Associativity Threshold Phenomenon in Set-Associative Caches\",\n        \"Perceptron-Based Prefetch Filtering\",\n        \"An Improving Method for Loop Unrolling\",\n        \"A performance study of software and hardware data prefetching schemes\",\n        \"Intel Memory Latency Checker\",\n        \"Improving instruction-level parallelism by loop unrolling and dynamic memory disambiguation\",\n        \"DTAP: Accelerating Strongly-Typed Programs with Data Type-Aware Hardware Prefetching\",\n        \"In-Core Optimization of High-Order Stencil Computations.\",\n        \"A Primer on Hardware Prefetching\",\n        \"Cache write policy for streaming output data\",\n        \"Loop-Aware Memory Prefetching Using Code Block Working Sets\",\n        \"CrossPrefetch: Accelerating I/O Prefetching for Modern Storage\",\n        \"Prefetch Tuning Optimizations. Vol. 2\",\n        \"Optimizing matrix-matrix multiplication on Intel’s advanced vector extensions multicore processor\",\n        \"Machine Learning for Fine-Grained Hardware Prefetcher Control\",\n        \"Generalized loop-unrolling: a method for program speedup\",\n        \"APT-GET: profile-guided timely software prefetching\",\n        \"Merging Similar Patterns for Hardware Prefetching\",\n        \"A method for estimating optimal unrolling times for nested loops\",\n        \"How to Be Fast and Not Furious: Looking Under the Hood of CPU Cache Prefetching\",\n        \"SQRL: hardware accelerator for collecting software data structures\",\n        \"When Prefetching Works, When It Doesn’t, and Why\",\n        \"Differentiable programming for image processing and deep learning in halide\",\n        \"PolyBench/C\",\n        \"Sparm: A Sparse Matrix Multiplication Accelerator Supporting Multiple Dataflows\",\n        \"Diagnosis and optimization of application prefetching performance\",\n        \"Exploiting Vector Code Semantics for Efficient Data Cache Prefetching\",\n        \"STREAM: Sustainable Memory Bandwidth in High Performance Computers\",\n        \"Memory Bandwidth and Machine Balance in Current High Performance Computers\",\n        \"TurboTiling: Leveraging prefetching to boost performance of tiled codes\",\n        \"Best-offset hardware prefetching\",\n        \"Tolerating latency through software-controlled prefetching in shared-memory multiprocessors\",\n        \"Design and evaluation of a compiler algorithm for prefetching\",\n        \"Automatically scheduling halide image processing pipelines\",\n        \"Data Cache Prefetching Using a Global History Buffer\",\n        \"The Game of Latency, Bandwidth, and Hardware Prefetching\",\n        \"Expert Prefetch Prediction: An Expert Predicting the Usefulness of Hardware Prefetchers\",\n        \"Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines\",\n        \"Maximizing Hardware Prefetch Effectiveness with Machine Learning\",\n        \"Optimized unrolling of nested loops\",\n        \"The evicted-address filter: a unified mechanism to address both cache pollution and thrashing\",\n        \"Loop transformations leveraging hardware prefetching\",\n        \"Sequential Program Prefetching in Memory Hierarchies\",\n        \"Page-Level Behavior of Cache Contention\",\n        \"Data prefetch mechanisms\",\n        \"On the Efficacy of Source Code Optimizations for Cache-Based Systems\",\n        \"Guided region prefetching: a cooperative hardware/software approach\",\n        \"Combining loop transformations considering caches and scheduling\",\n        \"Scalarization Using Loop Alignment and Loop Skewing\"\n    ],\n    \"reasoning\": \"Selected these 53 references because they represent foundational work and recent advances in Multi-Strided Access Patterns to Boost Hardware Prefetching, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}