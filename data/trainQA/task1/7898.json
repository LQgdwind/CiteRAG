{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 46 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation\n\nPaper Abstract: Abstract Previous studies have shown that leveraging domain index can significantly boost domain adaptation performance (Wang et al., 2020; Xu et al., 2022). However, such domain indices are not always available. To address this challenge, we first provide a formal definition of domain index from the probabilistic perspective, and then propose an adversarial variational Bayesian framework that infers domain indices from multi-domain data, thereby providing additional insight on domain relations and improving domain adaptation performance. Our theoretical analysis shows that our adversarial variational Bayesian framework finds the optimal domain index at equilibrium. Empirical results on both synthetic and real data verify that our model can produce interpretable domain indices which enable us to achieve superior performance compared to state-of-the-art domain adaptation methods. Code is available at https://github.com/Wang-ML-Lab/VDI.\n\n{retrieved_text}\n\nGenerate exactly 46 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 46\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A theory of learning from different domains\",\n        \"Adapting to continuously shifting domains\",\n        \"Modern multidimensional scaling: Theory and applications\",\n        \"Gradual domain adaptation without indexed intermediate domains\",\n        \"Big self-supervised models are strong semi-supervised learners\",\n        \"Blending-target domain adaptation by adversarial meta-adaptation networks\",\n        \"Adaptation across extreme variations using unlabeled domain bridges\",\n        \"Visual representation learning over latent domains\",\n        \"Adarnn: Adaptive learning and forecasting of time series\",\n        \"Unsupervised domain adaptation by backpropagation\",\n        \"Domain-adversarial training of neural networks\",\n        \"Deep residual learning for image recognition. corr abs/1512.03385 (2015)\",\n        \"Understanding self-training for gradual domain adaptation\",\n        \"Conditional adversarial domain adaptation\",\n        \"Generalized representations learning for time series classification\",\n        \"Adagraph: Unifying predictive and continuous domain adaptation through graphs\",\n        \"Autodial: Automatic domain alignment layers\",\n        \"Domain generalization using a mixture of multiple latent domains\",\n        \"Unsupervised multi-target domain adaptation through knowledge distillation\",\n        \"A survey on transfer learning\",\n        \"Domain adaptation via transfer component analysis\",\n        \"Moment matching for multi-source domain adaptation\",\n        \"Domain2vec: Domain embedding for unsupervised domain adaptation\",\n        \"Sentry: Selective entropy optimization via committee consistency for unsupervised domain adaptation\",\n        \"Neural unsupervised domain adaptation in nlp—a survey\",\n        \"Learning multiple visual domains with residual adapters\",\n        \"Bridging the day and night domain gap for semantic segmentation\",\n        \"The earth mover’s distance as a metric for image retrieval\",\n        \"Maximum classifier discrepancy for unsupervised domain adaptation\",\n        \"Generate to adapt: Aligning domains using generative adversarial networks\",\n        \"Deep CORAL: correlation alignment for deep domain adaptation\",\n        \"An unsupervised deep domain adaptation approach for robust speech recognition\",\n        \"Standardgan: Multi-source domain adaptation for semantic segmentation of very high resolution satellite images by data standardization\",\n        \"Deep domain confusion: Maximizing for domain invariance\",\n        \"Adversarial discriminative domain adaptation\",\n        \"Towards bayesian deep learning: A framework and some existing methods\",\n        \"A survey on bayesian deep learning\",\n        \"Collaborative deep learning for recommender systems\",\n        \"Continuously indexed domain adaptation\",\n        \"A bit more bayesian: Domain-invariant learning with uncertainty\",\n        \"Graph-relational domain adaptation\",\n        \"A large-scale car dataset for fine-grained categorization and verification\",\n        \"Darec: Deep domain adaptation for cross-domain recommendation via transferring rating patterns\",\n        \"Bridging theory and algorithm for domain adaptation\",\n        \"Learning sleep stages from radio signals: A conditional adversarial architecture\",\n        \"Unsupervised domain adaptation for semantic segmentation via class-balanced self-training\"\n    ],\n    \"reasoning\": \"Selected these 46 references because they represent foundational work and recent advances in Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}