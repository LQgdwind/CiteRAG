{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 49 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Uncertainty Aware Neural Network from Similarity and Sensitivity\n\nPaper Abstract: Abstract Researchers have proposed several approaches for neural network (NN) based uncertainty quantification (UQ). However, most of the approaches are developed considering strong assumptions. Uncertainty quantification algorithms often perform poorly in an input domain and the reason for poor performance remains unknown. Therefore, we present a neural network training method that considers similar samples with sensitivity awareness in this paper. In the proposed NN training method for UQ, first, we train a shallow NN for the point prediction. Then, we compute the absolute differences between prediction and targets and train another NN for predicting those absolute differences or absolute errors. Domains with high average absolute errors represent a high uncertainty. In the next step, we select each sample in the training set one by one and compute both prediction and error sensitivities. Then we select similar samples with sensitivity consideration and save indexes of similar samples. The ranges of an input parameter become narrower when the output is highly sensitive to that parameter. After that, we construct initial uncertainty bounds (UB) by considering the distribution of sensitivity aware similar samples. Prediction intervals (PIs) from initial uncertainty bounds are larger and cover more samples than required. Therefore, we train bound correction NN. As following all the steps for finding UB for each sample requires a lot of computation and memory access, we train a UB computation NN. The UB computation NN takes an input sample and provides an uncertainty bound. The UB computation NN is the final product of the proposed approach. Scripts of the proposed method are available in the following GitHub repository: https://github.com/dipuk0506/UQ\n\n{retrieved_text}\n\nGenerate exactly 49 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 49\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Evaluating state-of-the-art classification models against bayes optimality\",\n        \"On a sparse shortcut topology of artificial neural networks\",\n        \"If you like it, gan it—probabilistic multivariate times series forecast with gan\",\n        \"Simple and scalable predictive uncertainty estimation using deep ensembles\",\n        \"Towards a mathematical framework to inform neural network modelling via polynomial regression\",\n        \"Neural network-based interval forecasting of construction material prices\",\n        \"An evolutionary deep learning-based anomaly detection model for securing vehicles\",\n        \"Optimal energy management of automated grids considering the social and technical objectives with electric vehicles\",\n        \"Accurate prediction using triangular type-2 fuzzy linear regression: Simplifying complex t2f calculations\",\n        \"Effective demand response and gans for optimal constraint unit commitment in solar-tidal based microgrids\",\n        \"Multi-agent and fuzzy inference-based framework for traffic light optimization\",\n        \"Uncertainty model for quantitative precipitation estimation using weather radars\",\n        \"Automated ecg analysis for localizing thrombus in culprit artery using rule based information fuzzy network\",\n        \"Learning prediction intervals for model performance\",\n        \"Directed acyclic graph-based neural networks for tunable low-power computer vision\",\n        \"On plasticity, invariance, and mutually frozen weights in sequential task learning\",\n        \"Predictive uncertainty estimation via prior networks\",\n        \"Hw-forest: Deep forest with hashing screening and window screening\",\n        \"Backup resource allocation of virtual machines for probabilistic protection under capacity uncertainty\",\n        \"Artificial intelligence for dynamical systems in wireless communications: Modeling for the future\",\n        \"Uncertainty quantification neural network from similarity and sensitivity\",\n        \"A review of uncertainty quantification in deep learning: Techniques, applications and challenges\",\n        \"Dropout as a bayesian approximation: Representing model uncertainty in deep learning\",\n        \"Neural network-based uncertainty quantification: A survey of methodologies and applications\",\n        \"Text recognition from images\",\n        \"Alzheimer’s patient analysis using image and gene expression data and explainable-ai to present associated genes\",\n        \"Sparse variational inference: Bayesian coresets from scratch\",\n        \"A survey on epistemic (model) uncertainty in supervised learning: Recent advances and applications\",\n        \"Bayesian neural networks for uncertainty quantification in data-driven materials modeling\",\n        \"Probabilistic forecasting using monte carlo dropout neural networks\",\n        \"Correlated parameters to accurately measure uncertainty in deep neural networks\",\n        \"Hands-on bayesian neural networks—a tutorial for deep learning users\",\n        \"Robustness via uncertainty-aware cycle consistency\",\n        \"Lower upper bound estimation method for construction of neural network-based prediction intervals\",\n        \"Comprehensive review of neural network-based prediction intervals and new advances\",\n        \"Optimal uncertainty-guided neural network training\",\n        \"Prediction interval based on type-2 fuzzy systems for wind power generation and loads in microgrid control design\",\n        \"An advanced approach for construction of optimal wind power prediction intervals\",\n        \"Similarity to a model and self-evaluation\",\n        \"A correlation for the prediction of interaction energy parameters for mixtures of small molecules\",\n        \"Revisiting spatial-temporal similarity: A deep learning framework for traffic prediction\",\n        \"Natural convection flow of a nanofluid over a vertical plate with uniform surface heat flux\",\n        \"Determination of teleseismic relative phase arrival times using multi-channel cross-correlation and least squares\",\n        \"Neural network training for uncertainty quantification over time-range\",\n        \"Synthetic datasets for numeric uncertainty quantification: Proposing datasets for future researchers\",\n        \"Life expectancy (who): Statistical analysis on factors influencing life expectancy\",\n        \"Weight uncertainty in neural network\",\n        \"Bayesian regression tutorial\",\n        \"Graddiv: Adversarial robustness of randomized neural networks via gradient diversity regularization\"\n    ],\n    \"reasoning\": \"Selected these 49 references because they represent foundational work and recent advances in Uncertainty Aware Neural Network from Similarity and Sensitivity, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}