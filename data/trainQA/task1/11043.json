{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 159 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Specification Overfitting in Artificial Intelligence\n\nPaper Abstract: Abstract Machine learning (ML) and artificial intelligence (AI) approaches are often criticized for their inherent bias and for their lack of control, accountability, and transparency. Consequently, regulatory bodies struggle with containing this technology’s potential negative side effects. High-level requirements such as fairness and robustness need to be formalized into concrete specification metrics, imperfect proxies that capture isolated aspects of the underlying requirements. Given possible trade-offs between different metrics and their vulnerability to over-optimization, integrating specification metrics in system development processes is not trivial. This paper defines specification overfitting, a scenario where systems focus excessively on specified metrics to the detriment of high-level requirements and task performance. We present an extensive literature survey to categorize how researchers propose, measure, and optimize specification metrics in several AI fields (e.g., natural language processing, computer vision, reinforcement learning). Using a keyword-based search on papers from major AI conferences and journals between 2018 and mid-2023, we identify and analyze 74 papers that propose or optimize specification metrics. We find that although most papers implicitly address specification overfitting (e.g., by reporting more than one specification metric), they rarely discuss which role specification metrics should play in system development or explicitly define the scope and assumptions behind metric formulations.\n\n{retrieved_text}\n\nGenerate exactly 159 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 159\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Machine Bias\",\n        \"Deep reinforcement learning: A brief survey\",\n        \"Neural machine translation by jointly learning to align and translate\",\n        \"Big data’s disparate impact\",\n        \"Fairness and Machine Learning: Limitations and Opportunities\",\n        \"Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation\",\n        \"A theory of learning from different domains\",\n        \"Machine learning techniques for credit risk evaluation: a systematic literature review\",\n        \"FlipTest: Fairness testing via optimal transport\",\n        \"Deep neural networks and tabular data: A survey\",\n        \"Geometric Deep Learning: Going beyond Euclidean data\",\n        \"SizeShiftReg: A Regularization Method for Improving Size-Generalization in Graph Neural Networks\",\n        \"Gender shades: Intersectional accuracy disparities in commercial gender classification\",\n        \"Fairness Under Unawareness: Assessing Disparity When Protected Class Is Unobserved\",\n        \"Pareto Invariant Risk Minimization: Towards Mitigating the Optimization Dilemma in Out-of-Distribution Generalization\",\n        \"Evaluating and Enhancing the Robustness of Dialogue Systems: A Case Study on a Negotiation Agent\",\n        \"Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples\",\n        \"CAT: Customized Adversarial Training for Improved Robustness\",\n        \"ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators\",\n        \"Why adversarial training can hurt robust accuracy\",\n        \"et al (2020) Counterfactual risk assessments\",\n        \"In: Proceedings of the 36th International Conference on Machine Learning\",\n        \"Andriushchenko M\",\n        \"et al (2022) Underspecification presents challenges for credibility in modern machine learning\",\n        \"et al (2022) Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness\",\n        \"et al (2017) Automated hate speech detection and the problem of offensive language\",\n        \"et al (2009) Imagenet: A large-scale hierarchical image database. In: 2009 IEEE conference on computer vision and pattern recognition\",\n        \"2023. OpenReview.net\",\n        \"Volume 1 (Long and Short Papers). Association for Computational Linguistics\",\n        \"et al (2021) An image is worth 16x16 words: Transformers for image recognition at scale. In: International Conference on Learning Representations\",\n        \"et al (2018) A Challenge Set and Methods for Noun-Verb Ambiguity\",\n        \"et al (2021) Deep learning-enabled medical computer vision. npj Digital Medicine 4(1):5. 10.1038/s41746-020-00376-2\",\n        \"European Parliament and Council of the European Union (2012) Regulation (EU) No 1025/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation\",\n        \"et al (2019) Graph Neural Networks for Social Recommendation. In: The World Wide Web Conference. Association for Computing Machinery\",\n        \"et al (2023) Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting. In: Rogers A\",\n        \"et al (2020) Principled artificial intelligence: Mapping consensus in ethical and rights-based approaches to principles for AI\",\n        \"et al (2018) Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior\",\n        \"Venkatasubramanian S (2021) The (im)possibility of fairness: different value systems require different mechanisms for fair decision making\",\n        \"Fukushima K (1980) Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position\",\n        \"Ng HT (2019) Improving the Robustness of Question Answering Systems to Question Paraphrasing\",\n        \"URL https://aclanthology.org/2020.findings-emnlp.117\",\n        \"In: International Conference on Learning Representations\",\n        \"Szegedy C (2015) Explaining and harnessing adversarial examples. In: International Confserence on Learning Representations\",\n        \"et al (2021) Improving Robustness using Generated Data. In: Advances in Neural Information Processing Systems\",\n        \"CVPR Workshops 2022\",\n        \"et al (2018) Sparse DNNs with Improved Adversarial Robustness. In: Advances in Neural Information Processing Systems\",\n        \"Hagendorff T (2020) The Ethics of AI Ethics: An Evaluation of Guidelines\",\n        \"et al (2023) A Survey on Vision Transformer\",\n        \"Srebro N (2016) Equality of opportunity in supervised learning. Advances in neural information processing systems 29\",\n        \"et al (2020) Training independent subnetworks for robust prediction. In: International Conference on Learning Representations\",\n        \"et al (2016) Deep residual learning for image recognition. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\n        \"et al (2005) Face recognition using Laplacianfaces\",\n        \"Dietterich T (2018) Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\",\n        \"et al (2019a) Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty. In: Advances in Neural Information Processing Systems\",\n        \"et al (2019b) AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty. In: International Conference on Learning Representations\",\n        \"High-Level Expert Group on AI (2019) Ethics guidelines for trustworthy AI\",\n        \"et al (2023) Planning-oriented autonomous driving. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\n        \"In: Proceedings of the 17th International Conference on Software Engineering\",\n        \"Wallach H (2021) Measurement and fairness. In: Proceedings of the 2021 ACM Conference on Fairness\",\n        \"Giryes R (2018) Improving DNN Robustness to Adversarial Attacks Using Jacobian Regularization. In: Ferrari V\",\n        \"et al (2023) Survey of Hallucination in Natural Language Generation. ACM Comput Surv 55(12). 10.1145/3571730\",\n        \"Vayena E (2019) The global landscape of AI ethics guidelines. Nature Machine Intelligence 1(9):389–399\",\n        \"et al (2022) Re-weighting Based Group Fairness Regularization via Classwise Robust Optimization\",\n        \"et al (2019) Training on Synthetic Noise Improves Robustness to Natural Noise in Machine Translation\",\n        \"URL https://www.sciencedirect.com/science/article/pii/S1041608023000195\",\n        \"In: The Eleventh International Conference on Learning Representations\",\n        \"In: Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n        \"Leibniz International Proceedings in Informatics (LIPIcs)\",\n        \"et al (2018) Nonconvex Optimization for Regression with Fairness Constraints\",\n        \"URL https://www.sciencedirect.com/science/article/pii/S093336570100077X\",\n        \"Hinton GE (2012) Imagenet classification with deep convolutional neural networks. In: Pereira F\",\n        \"Baroni M (2018) Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In: Dy J\",\n        \"et al (2016) Neural Architectures for Named Entity Recognition. In: Knight K\",\n        \"et al (1989) Backpropagation Applied to Handwritten Zip Code Recognition\",\n        \"URL https://ojs.aaai.org/index.php/AAAI/article/view/20699\",\n        \"Journal of Machine Learning Research 17(39):1–40\",\n        \"Berant J (2023) Diverse Demonstrations Improve In-context Compositional Generalization. In: Rogers A\",\n        \"perspectives. In: International symposium on string processing and information retrieval\",\n        \"et al (2023a) Squeeze Training for Adversarial Robustness. In: The Eleventh International Conference on Learning Representations\",\n        \"vol 37. AAAI Press\",\n        \"et al (2022) Efficient Adversarial Training without Attacking: Worst-Case-Aware Robust Reinforcement Learning\",\n        \"Evans O (2022) TruthfulQA: Measuring how models mimic human falsehoods. In: Muresan S\",\n        \"In: Proceedings of the 38th International Conference on Machine Learning\",\n        \"et al (2019b) RoBERTa: A Robustly Optimized BERT Pretraining Approach\",\n        \"How JP (2020) Certified adversarial robustness for deep reinforcement learning. In: Kaelbling LP\",\n        \"Roth B (2023) Cross-functional Analysis of Generalization in Behavioral Learning\",\n        \"et al (2022) Are Multimodal Transformers Robust to Missing Modality? In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\n        \"Wortman Vaughan J\",\n        \"Zemel R (2018) Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer. In: Advances in Neural Information Processing Systems\",\n        \"Malik MM (2020) A hierarchy of limitations in machine learning\",\n        \"et al (2021) A Survey on Bias and Fairness in Machine Learning. ACM Comput Surv 54(6). 10.1145/3457607\",\n        \"In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n        \"et al (2022) Image Segmentation Using Deep Learning: A Survey\",\n        \"Chouldechova A (2021) Fairness in Risk Assessment Instruments: Post-Processing to Achieve Counterfactual Equalized Odds\",\n        \"et al (2015) Human-level control through deep reinforcement learning. Nature 518(7540):529–533. 10.1038/nature14236\",\n        \"In: Proceedings of the 27th International Conference on Computational Linguistics\",\n        \"et al (2020) CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models. In: Webber B\",\n        \"Gupta M (2019) Optimizing Generalized Rate Metrics with Three Players. In: Advances in Neural Information Processing Systems\",\n        \"OECD AI Policy Observatory URL https://oecd\",\n        \"et al (2022) Training language models to follow instructions with human feedback. In: Koyejo S\",\n        \"Shmueli E (2023) A Review on Fairness in Machine Learning. ACM Computing Surveys 55(3):1–44. 10.1145/3494672\",\n        \"et al (2023) On (assessing) the fairness of risk score models. In: Proceedings of the 2023 ACM Conference on Fairness\",\n        \"et al (2022a) Net Benefit\",\n        \"et al (2022b) A comparison of approaches to improve worst-case predictive model performance over patient subpopulations\",\n        \"et al (2021) Learning transferable visual models from natural language supervision. In: Meila M\",\n        \"et al (2020) Exploring the limits of transfer learning with a unified text-to-text transformer\",\n        \"et al (2021) Fair influence maximization: a welfare optimization approach. In: Proceedings of the AAAI Conference on Artificial Intelligence\",\n        \"et al (2021) Zero-Shot Text-to-Image Generation. In: Meila M\",\n        \"et al (2021) Data Augmentation Can Improve Robustness. In: Advances in Neural Information Processing Systems\",\n        \"In: Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining\",\n        \"et al (2020) Beyond Accuracy: Behavioral Testing of NLP Models with CheckList\",\n        \"et al (2021) Sample Selection for Fair and Robust Training. In: Advances in Neural Information Processing Systems\",\n        \"Doshi-Velez F (2018) Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing Their Input Gradients\",\n        \"et al (2021) HateCheck: Functional Tests for Hate Speech Detection Models\",\n        \"et al (2020) A Benchmark for Systematic Generalization in Grounded Language Understanding. In: Advances in Neural Information Processing Systems\",\n        \"et al (2015) ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision 115(3):211–252. 10.1007/s11263-015-0816-y\",\n        \"Schütze H (2021) Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP\",\n        \"et al (2020) Improving Robustness against Common Corruptions by Covariate Shift Adaptation. In: Advances in Neural Information Processing Systems\",\n        \"2022. OpenReview.net\",\n        \"Ben-David S (2014) Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press\",\n        \"Krasheninnikov D\",\n        \"et al (2013) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank. In: Yarowsky D\",\n        \"Saleem Durai MA (2019) Intelligent video surveillance: a review through deep learning techniques for crowd analysis\",\n        \"et al (2023) Adversarial Attack and Defense on Graph Data: A Survey\",\n        \"In: Proceedings of the 37th International Conference on Machine Learning\",\n        \"Barto AG (2018) Reinforcement Learning: An Introduction. A Bradford Book\",\n        \"et al (2016) Rethinking the Inception Architecture for Computer Vision. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\n        \"et al (2021) A Statistical Test for Probabilistic Fairness. In: Proceedings of the 2021 ACM Conference on Fairness\",\n        \"Cenelec and ETSI and the European Commission and the European Free Trade Association\",\n        \"The European Comission (2008) New legislative framework\",\n        \"The European Comission (2018) Factsheet: Artificial Intelligence for Europe\",\n        \"et al (2023) Large language models in medicine. Nature Medicine 29(8):1930–1940. 10.1038/s41591-023-02448-8\",\n        \"2019. OpenReview.net\",\n        \"et al (2020) An Empirical Study on Robustness to Spurious Correlations using Pre-trained Language Models\",\n        \"et al (2017) Attention is all you need. In: Advances in neural information processing systems\",\n        \"Borgesius FZ (2021) Demystifying the Draft EU Artificial Intelligence Act—Analysing the good\",\n        \"Russell C (2017) Counterfactual explanations without opening the black box: Automated decisions and the GDPR. Harv JL & Tech 31:841\",\n        \"et al (2020a) InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective\",\n        \"et al (2020b) Robust Optimization for Fairness with Noisy Protected Groups. In: Advances in Neural Information Processing Systems\",\n        \"et al (2022a) Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models\",\n        \"URL https://aclanthology.org/2022.naacl-main.339\",\n        \"Volume 2 (Short Papers). Association for Computational Linguistics\",\n        \"et al (2019) Improving Adversarial Robustness Requires Revisiting Misclassified Examples. In: International Conference on Learning Representations\",\n        \"et al (2022a) Finetuned language models are zero-shot learners. In: International Conference on Learning Representations\",\n        \"et al (2022b) Emergent abilities of large language models. Transactions on Machine Learning Research URL https://openreview.net/forum?id=yzkSU5zdwD\",\n        \"et al (2018) Evaluating the robustness of neural networks: An extreme value theory approach\",\n        \"Wiener N (1960) Some Moral and Technical Consequences of Automation: As machines learn they may develop unforeseen strategies at rates that baffle their programmers\",\n        \"et al (2020) INT: An Inequality Benchmark for Evaluating Generalization in Theorem Proving. In: International Conference on Learning Representations\",\n        \"et al (2021) A comprehensive survey on graph neural networks\",\n        \"van der Maaten L\",\n        \"et al (2020) Pushing the Boundaries of Molecular Representation for Drug Discovery with the Graph Attention Mechanism\",\n        \"et al (2022) Wordcraft: Story Writing With Large Language Models\",\n        \"et al (2023) Large language models meet NL2Code: A survey. In: Rogers A\",\n        \"et al (2022a) Chasing All-Round Graph Representation Robustness: Model\",\n        \"et al (2019) Towards Stable and Efficient Training of Verifiably Robust Neural Networks. In: International Conference on Learning Representations\",\n        \"Finn C (2022b) MEMO: Test Time Robustness via Adaptation and Augmentation. Advances in Neural Information Processing Systems 35:38629–38642\",\n        \"In: Proceedings of the 39th International Conference on Machine Learning\",\n        \"et al (2020) Adversarial attacks on deep-learning models in natural language processing: A survey\",\n        \"et al (2023) On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex. In: Vlachos A\"\n    ],\n    \"reasoning\": \"Selected these 159 references because they represent foundational work and recent advances in Specification Overfitting in Artificial Intelligence, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}