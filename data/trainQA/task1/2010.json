{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 59 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Slice and Dice: A Physicalization Workflow for Anatomical Edutainment\n\nPaper Abstract: Abstract During the last decades, anatomy has become an interesting topic in education—even for laymen or schoolchildren. As medical imaging techniques become increasingly sophisticated, virtual anatomical education applications have emerged. Still, anatomical models are often preferred, as they facilitate 3D localization of anatomical structures. Recently, data physicalizations (i.e., physical visualizations) have proven to be effective and engaging—sometimes, even more than their virtual counterparts. So far, medical data physicalizations involve mainly 3D printing, which is still expensive and cumbersome. We investigate alternative forms of physicalizations, which use readily available technologies (home printers) and inexpensive materials (paper or semi-transparent films) to generate crafts for anatomical edutainment. To the best of our knowledge, this is the first computer-generated crafting approach within an anatomical edutainment context. Our approach follows a cost-effective, simple, and easy-to-employ workflow, resulting in assemblable data sculptures (i.e., semi-transparent sliceforms). It primarily supports volumetric data (such as CT or MRI), but mesh data can also be imported. An octree slices the imported volume and an optimization step simplifies the slice configuration, proposing the optimal order for easy assembly. A packing algorithm places the resulting slices with their labels, annotations, and assembly instructions on a paper or transparent film of user-selected size, to be printed, assembled into a sliceform, and explored. We conducted two user studies to assess our approach, demonstrating that it is an initial positive step towards the successful creation of interactive and engaging anatomical physicalizations. {CCSXML} <ccs2012> <concept> <concept_id>10003120.10003145.10003147</concept_id> <concept_desc>Human-centered computing Visualization application domains</concept_desc> <concept_significance>500</concept_significance> </concept> <concept> <concept_id>10010405.10010444</concept_id> <concept_desc>Applied computing Life and medical sciences</concept_desc> <concept_significance>500</concept_significance> </concept> </ccs2012> \\ccsdesc [500]Human-centered computing Visualization application domains \\ccsdesc[500]Applied computing Life and medical sciences \\printccsdesc\n\n{retrieved_text}\n\nGenerate exactly 59 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 59\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Physicalizing cardiac blood flow data via 3D printing\",\n        \"Papier-mâché anatomical models, 1820\",\n        \"Google body: 3D human anatomy in the browser\",\n        \"Multidimensional binary search trees used for associative searching\",\n        \"Volumeshop: An interactive system for direct volume illustration\",\n        \"Illustrative context-preserving exploration of volume data\",\n        \"Interactive visualization of muscle activity during limb movements: Towards enhanced anatomy learning\",\n        \"3-D Structures for the Encoding of Geometry and Internal Properties\",\n        \"Geschichte und Bibliographie der anatomischen Abbildung nach ihrer Beziehung auf anatomische Wissenschaft und bildende Kunst\",\n        \"Generative computer-aided design: multi-modality large-scale direct physical production\",\n        \"Shop class for the next millenium: Education through computer-enriched handicrafts\",\n        \"Rearrangeable wooden model of brain scan, 2008\",\n        \"From patient education to patient engagement: implications for the field of patient education\",\n        \"High-quality two-level volume rendering of segmented data sets on consumer graphics hardware\",\n        \"The open anatomy browser: a collaborative web-based viewer for interoperable anatomy atlases\",\n        \"Investigating learners’ attitudes toward virtual reality learning environments: Based on a constructivist approach\",\n        \"Computational design of iris folding patterns\",\n        \"Evaluating the efficiency of physical visualizations\",\n        \"Opportunities and challenges for data physicalization\",\n        \"The use of stereoscopy in a neurosurgery training virtual environment\",\n        \"Direct manipulation is better than passive viewing for learning anatomy in a three-dimensional virtual reality environment\",\n        \"A thousand ways to pack the bin—a practical approach to two-dimensional rectangle bin packing\",\n        \"Hybrid 3D printing: A game-changer in personalized cardiac medicine?\",\n        \"Empirical studies in information visualization: Seven scenarios\",\n        \"State of the art in transfer functions for direct volume rendering\",\n        \"Surface and contour-preserving origamic architecture paper pop-ups\",\n        \"Least squares quantization in pcm\",\n        \"Automatic paper sliceform design from 3D solid models\",\n        \"Popup: automatic paper architectures from 3d models\",\n        \"Sline: Seamless line illustration for interactive biomedical visualization\",\n        \"Bodyparts3d: 3D structure database for anatomical concepts\",\n        \"Development of anatomical models-chronology\",\n        \"Beyond the tyranny of the pixel: Exploring the physicality of information visualization\",\n        \"An interactive 3D virtual anatomy puzzle for learning and simulation - initial demonstration and evaluation\",\n        \"The IKEA effect: When labor leads to love\",\n        \"Wax, wooden, ivory, cardboard, bronze, fabric, plaster, rubber and plastic anatomical models: Praiseworthy precursors of plastinated specimens\",\n        \"Using mutual information for exploring optimal light source placements\",\n        \"Visual computing for medicine: theory, algorithms, and applications\",\n        \"PaperCraft3D: paper-based 3D modeling and scene fabrication\",\n        \"On lines and planes of closest fit to systems of points in space\",\n        \"Creating a high-resolution spatial/symbolic model of the inner organs based on the visible human\",\n        \"Supporting anatomy education with a 3D puzzle in a vr environment-results from a pilot study\",\n        \"A survey of virtual human anatomy education systems\",\n        \"The biodigital human: a web-based 3D platform for medical visualization and education\",\n        \"Generating multi-style paper pop-up designs using 3D primitive fitting\",\n        \"Multi-style paper pop-up designs from 3D models\",\n        \"Generating animated paper pop-ups from the motion of articulated characters\",\n        \"3d printing based on imaging data: Review of medical applications\",\n        \"Vol2velle: Printable interactive volume visualization\",\n        \"Embodied prototyping: exploration of a design-fabrication framework for large-scale model manufacturing\",\n        \"Data physicalization for improving communication and memorization\",\n        \"The online anatomical human: Web-based anatomy education\",\n        \"Semi-immersive 3D sketching of vascular structures for medical education\",\n        \"Who belongs in the family?\",\n        \"De humani corporis fabrica libri septem, 1543\",\n        \"Smart visibility in visualization\",\n        \"An interactive 3D framework for anatomical education\",\n        \"Computational design of transforming pop-up books\",\n        \"Embodiment in data sculpture: a model of the physical visualization of information\"\n    ],\n    \"reasoning\": \"Selected these 59 references because they represent foundational work and recent advances in Slice and Dice: A Physicalization Workflow for Anatomical Edutainment, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}