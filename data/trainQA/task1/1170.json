{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 49 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Irregular Accesses Reorder Unit: Improving GPGPU Memory Coalescing for Graph-Based Workloads\n\nPaper Abstract: Abstract GPGPU architectures have become the dominant platform for massively parallel workloads, delivering high performance and energy efficiency for popular applications such as machine learning, computer vision or self-driving cars. However, irregular applications, such as graph processing, fail to fully exploit GPGPU resources due to their divergent memory accesses that saturate the memory hierarchy. To reduce the pressure on the memory subsystem for divergent memory-intensive applications, programmers must take into account SIMT execution model and memory coalescing in GPGPUs, devoting significant efforts in complex optimization techniques. Despite these efforts, we show that irregular graph processing still suffers from low GPGPU performance. We observe that in many irregular applications the mapping of data to threads can be safely changed. In other words, it is possible to relax the strict relationship between thread and data processed to reduce memory divergence. Based on this observation, we propose the Irregular accesses Reorder Unit (IRU), a novel hardware extension tightly integrated in the GPGPU pipeline. The IRU reorders data processed by the threads on irregular accesses to improve memory coalescing, i.e. it tries to assign data elements to threads as to produce coalesced accesses in SIMT groups. Furthermore, the IRU is capable of filtering and merging duplicated accesses, significantly reducing the workload. Programmers can easily utilize the IRU with a simple API, or let the compiler issue instructions from our extended ISA. We evaluate our proposal for state-of-the-art graph-based algorithms and a wide selection of applications. Results show that the IRU achieves a memory coalescing improvement of 1.32x and a 46% reduction in the overall traffic in the memory hierarchy, which results in 1.33x speedup and 13% energy savings on average, while incurring in a small 5.6% area overhead.\n\n{retrieved_text}\n\nGenerate exactly 49 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 49\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Efficient sparse matrix-vector multiplication on cuda\",\n        \"Strassen’s matrix multiplication on gpus\",\n        \"Mapd: a gpu-powered big data analytics and visualization platform\",\n        \"Characterizing and understanding gcns on gpu\",\n        \"Efficient automatic speech recognition on the gpu\",\n        \"Imagenet classification with deep convolutional neural networks\",\n        \"Autoware on board: Enabling autonomous vehicles with embedded systems\",\n        \"Scu: a gpu stream compaction unit for graph processing\",\n        \"Tigr: Transforming irregular graphs for gpu-friendly graph processing\",\n        \"Understanding and improving graph algorithm performance\",\n        \"A quantitative study of irregular programs on gpus\",\n        \"Microarchitectural performance characterization of irregular gpu kernels\",\n        \"Efficient parallel scan algorithms for gpus\",\n        \"Efficient stream compaction on wide simd many-core architectures\",\n        \"Graphlab: A new framework for parallel machine learning\",\n        \"The graph neural network model\",\n        \"Apache spark: a unified engine for big data processing\",\n        \"Challenges in parallel graph processing\",\n        \"Graph processing on gpus: Where are the bottlenecks?\",\n        \"High-performance and scalable gpu graph traversal\",\n        \"Work-efficient parallel gpu methods for single-source shortest paths\",\n        \"Wtf, gpu! computing twitter’s who-to-follow on the gpu\",\n        \"Implementing sparse matrix-vector multiplication on throughput-oriented processors\",\n        \"Analyzing cuda workloads using a detailed gpu simulator\",\n        \"Mcpat: an integrated power, area, and timing modeling framework for multicore and manycore architectures\",\n        \"Gpuwattch: enabling energy optimizations in gpgpus\",\n        \"The university of florida sparse matrix collection\",\n        \"10th DIMACS Implementation Challenge - Graph Partitioning and Graph Clustering\",\n        \"Scalable simd-efficient graph processing on gpus\",\n        \"Dynamic warp formation and scheduling for efficient gpu control flow\",\n        \"Efficient large-scale graph processing on hybrid cpu and gpu systems\",\n        \"Gunrock: A high-performance graph processing library on the gpu\",\n        \"Traversing large graphs on gpus with unified memory\",\n        \"Optimization of sparse matrix–vector multiplication using reordering techniques on gpus\",\n        \"Ism2: Optimizing irregular-shaped matrix-matrix multiplication on gpus\",\n        \"A novel data transformation and execution strategy for accelerating sparse matrix multiplication on gpus\",\n        \"Complexity analysis and algorithm design for reorganizing data to minimize non-coalesced memory accesses on gpu\",\n        \"Amoeba-cache: Adaptive blocks for eliminating waste in the memory hierarchy\",\n        \"Elastic-cache: Gpu cache architecture for efficient fine-and coarse-grained cache-line management\",\n        \"Dycache: Dynamic multi-grain cache management for irregular memory accesses on gpu\",\n        \"Adaptive cache management for energy-efficient gpu computing\",\n        \"A locality-aware memory hierarchy for energy-efficient gpu architectures\",\n        \"Alleviating irregularity in graph analytics acceleration: a hardware/software co-design approach\",\n        \"Spare register aware prefetching for graph algorithms on gpus\",\n        \"D2ma: Accelerating coarse-grained data transfer for gpus\",\n        \"Stash: Have your scratchpad and cache it too\",\n        \"Tunao: A high-performance and energy-efficient reconfigurable accelerator for graph processing\",\n        \"Graphicionado: A high-performance and energy-efficient accelerator for graph analytics\",\n        \"Graphh: A processing-in-memory architecture for large-scale graph processing\"\n    ],\n    \"reasoning\": \"Selected these 49 references because they represent foundational work and recent advances in Irregular Accesses Reorder Unit: Improving GPGPU Memory Coalescing for Graph-Based Workloads, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}