{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 51 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Gap Amplification for Reconfiguration Problems\n\nPaper Abstract: Abstract Combinatorial reconfiguration is an emerging field of theoretical computer science that studies the reachability between a pair of feasible solutions for a particular combinatorial problem. We study the hardness of accomplishing ‚Äúapproximate‚Äù reconfigurability, which affords to relax the feasibility of solutions. For example, in Minmax Set Cover Reconfiguration, given a pair of covers ùíûùóåsubscriptùíûùóå\\mathcal{C}_{\\mathsf{s}} and ùíûùóçsubscriptùíûùóç\\mathcal{C}_{\\mathsf{t}} for a set system ‚Ñ±‚Ñ±\\mathcal{F}, we aim to transform ùíûùóåsubscriptùíûùóå\\mathcal{C}_{\\mathsf{s}} into ùíûùóçsubscriptùíûùóç\\mathcal{C}_{\\mathsf{t}} by repeatedly adding or removing a single set of ‚Ñ±‚Ñ±\\mathcal{F} so as to minimize the maximum size of covers during transformation. The recent study by Ohsaka (STACS 2023) [Ohs23] gives evidence that a host of reconfiguration problems are PSPACE-hard to approximate assuming the Reconfiguration Inapproximability Hypothesis (RIH), which postulates that a gap version of Maxmin CSP Reconfiguration is PSPACE-hard. One limitation of this approach is that inapproximability factors are not explicitly shown, so that even a 1.00‚Äã‚ãØ‚Äã0011.00‚ãØ0011.00\\cdots 001-approximation algorithm for Minmax Set Cover Reconfiguration may not be ruled out, whereas it admits 222-approximation as per Ito, Demaine, Harvey, Papadimitriou, Sideri, Uehara, and Uno (Theor. Comput. Sci., 2011) [IDHPSU+11]. In this paper, we demonstrate gap amplification for reconfiguration problems. In particular, we prove an explicit factor of PSPACE-hardness of approximation for three popular reconfiguration problems only assuming RIH. Our main result is that under RIH, Maxmin Binary CSP Reconfiguration is PSPACE-hard to approximate within a factor of 0.99420.99420.9942. Moreover, the same result holds even if the constraint graph is restricted to (d,Œª)ùëëùúÜ(d,\\lambda)-expander for arbitrarily small ŒªdùúÜùëë\\frac{\\lambda}{d}. The crux of its proof is an alteration of the gap amplification technique due to Dinur (J. ACM, 2007) [Din07], which amplifies the 111 vs. 1‚àíŒµ1ùúÄ1-\\varepsilon gap for arbitrarily small Œµ>0ùúÄ0\\varepsilon>0 up to the 111 vs. 1‚àí0.005810.00581-0.0058 gap. As an application of the main result, we demonstrate that Minmax Set Cover Reconfiguration and Minmax Dominating Set Reconfiguration are PSPACE-hard to approximate within a factor of 1.00291.00291.0029 under RIH. Our proof is based on a gap-preserving reduction from Label Cover to Set Cover due to Lund and Yannakakis (J. ACM, 1994) [LY94]. However, unlike Lund‚ÄìYannakakis‚Äô reduction, the expander mixing lemma is essential to use. We highlight that all results hold unconditionally as long as ‚ÄúPSPACE-hard‚Äù is replaced by ‚ÄúNP-hard,‚Äù and are the first explicit inapproximability results for reconfiguration problems without resorting to the parallel repetition theorem. We finally complement the main result by showing that it is NP-hard to approximate Maxmin Binary CSP Reconfiguration within a factor better than 3434\\frac{3}{4}.\n\n{retrieved_text}\n\nGenerate exactly 51 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 51\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Explicit construction of linear sized tolerant networks\",\n        \"On the solution-space geometry of random constraint satisfaction problems\",\n        \"Proof Verification and the Hardness of Approximation Problems\",\n        \"Explicit Expanders of Every Degree and Size\",\n        \"The Probabilistic Method\",\n        \"Probabilistic Checking of Proofs: A New Characterization of NP\",\n        \"Finding paths between graph colourings: PSPACE-completeness and superpolynomial distances\",\n        \"Shortest Reconfiguration of Colorings Under Kempe Changes\",\n        \"Decremental optimization of dominating sets under the reconfiguration framework\",\n        \"Gap Amplification Fails Below 1/2121/2\",\n        \"Connectedness of the graph of vertex-colourings\",\n        \"Finding paths between 3-colorings\",\n        \"The PCP Theorem by Gap Amplification\",\n        \"Analytical approach to parallel repetition\",\n        \"A Threshold of ln‚Å°nùëõ\\\\ln n for Approximating Set Cover\",\n        \"On the Power of Multi-Prover Interactive Protocols\",\n        \"The Overlap Gap Property: A Topological Barrier to Optimizing over Random Structures\",\n        \"Course notes of CSE 533: The PCP Theorem and Hardness of Approximation\",\n        \"Course notes of 15-854(B): Advanced Approximation Algorithms\",\n        \"Limits of local algorithms over sparse random graphs\",\n        \"Some optimal inapproximability results\",\n        \"Clique is hard to approximate within n1‚àíŒµsuperscriptùëõ1ùúÄn^{1-\\\\varepsilon}\",\n        \"PSPACE-Completeness of Sliding-Block Puzzles and Other Problems through the Nondeterministic Constraint Logic Model of Computation\",\n        \"Games, Puzzles, and Computation\",\n        \"The Complexity of Dominating Set Reconfiguration\",\n        \"Approximability of the subset sum reconfiguration problem\",\n        \"On the Complexity of Reconfiguration Problems\",\n        \"Shortest Reconfiguration of Perfect Matchings via Alternating Cycles\",\n        \"Incremental optimization of independent sets under the reconfiguration framework\",\n        \"Shortest Paths Between Shortest Paths\",\n        \"Complexity of Independent Set Reconfigurability Problems\",\n        \"The Complexity of Independent Set Reconfiguration on Bipartite Graphs\",\n        \"On the Hardness of Approximating Minimization Problems\",\n        \"Clustering of Solutions in the Random Satisfiability Problem\",\n        \"Approximation and Hardness of Token Swapping\",\n        \"Explicit Near-Ramanujan Graphs of Every Degree\",\n        \"Introduction to Reconfiguration\",\n        \"Gap Preserving Reductions Between Reconfiguration Problems\",\n        \"On Approximate Reconfigurability of Label Cover\",\n        \"Reconfiguration Problems on Submodular Functions\",\n        \"Non Deterministic Polynomial Optimization Problems and Their Approximations\",\n        \"Optimization, Approximation, and Complexity Classes\",\n        \"Gap Amplification in PCPs Using Lazy Random Walks\",\n        \"A parallel repetition theorem\",\n        \"On Dinur‚Äôs Proof of the PCP Theorem\",\n        \"Gap Amplification for Small-Set Expansion via Random Walks\",\n        \"Reconfiguration of dominating sets\",\n        \"The Complexity of Change\",\n        \"Optimal low-degree hardness of maximum independent set\",\n        \"Parameterized Inapproximability for Steiner Orientation by Gap Amplification\",\n        \"Decremental Optimization of Vertex-Coloring Under the Reconfiguration Framework\"\n    ],\n    \"reasoning\": \"Selected these 51 references because they represent foundational work and recent advances in Gap Amplification for Reconfiguration Problems, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}