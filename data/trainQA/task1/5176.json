{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 44 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Scalable In Situ Compression of Transient Simulation Data Using Time-Dependent Bases\n\nPaper Abstract: Abstract Large-scale simulations of time-dependent problems generate a massive amount of data and with the explosive increase in computational resources the size of the data generated by these simulations has increased significantly. This has imposed severe limitations on the amount of data that can be stored and has elevated the issue of input/output (I/O) into one of the major bottlenecks of high-performance computing. In this work, we present an in situ compression technique to reduce the size of the data storage by orders of magnitude. This methodology is based on time-dependent subspaces and it extracts low-rank structures from multidimensional streaming data by decomposing the data into a set of time-dependent bases and a core tensor. We derive closed-form evolution equations for the core tensor as well as the time-dependent bases. The presented methodology does not require the data history and the computational cost of its extractions scales linearly with the size of data — making it suitable for large scale streaming datasets. To control the compression error, we present an adaptive strategy to add/remove modes to maintain the reconstruction error below a given threshold. We present four demonstration cases: (i) analytical example, (ii) incompressible unsteady reactive flow, (iii) stochastic turbulent reactive flow, and (iv) three-dimensional turbulent channel flow.\n\n{retrieved_text}\n\nGenerate exactly 44 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 44\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"CFD vision 2030 study: a path to revolutionary computational aerosciences\",\n        \"Nasa cfd vision 2030 visualization and knowledge extraction: Panel summary from aiaa aviation 2015 conference\",\n        \"Applied mathematics research for exascale computing\",\n        \"Data reduction for science\",\n        \"Combining in-situ and in-transit processing to enable extreme-scale scientific analysis\",\n        \"Data compression for the exascale computing era-survey\",\n        \"Data reduction techniques for simulation, visualization and data analysis\",\n        \"Fast and efficient compression of floating-point data\",\n        \"An adaptive prediction-based approach to lossless compression of floating-point volume data\",\n        \"On the compression of low rank matrices\",\n        \"Pass-efficient methods for compression of high-dimensional turbulent flow data\",\n        \"Discrete random signals and statistical signal processing\",\n        \"Practical sketching algorithms for low-rank matrix approximation\",\n        \"Higher Order Tensors for DNS Data Analysis and Compression\",\n        \"Decomposition of big tensors with low multilinear rank\",\n        \"Recovering missing cfd data for high-order discretizations using deep neural networks and dynamics learning\",\n        \"Deep learning for in situ data compression of large turbulent flow simulations\",\n        \"A novel in situ compression method for cfd data based on generative adversarial network\",\n        \"Mloc: Multi-level layout optimization framework for compressed scientific data exploration with heterogeneous access patterns\",\n        \"Dynamically orthogonal field equations for continuous stochastic dynamical systems\",\n        \"A dynamically bi-orthogonal method for time-dependent stochastic partial differential equations i: Derivation and algorithms\",\n        \"On the equivalence of dynamically orthogonal and bi-orthogonal methods: Theory and numerical simulations\",\n        \"Dual dynamically orthogonal approximation of incompressible N]avier [Stokes equations with random boundary conditions\",\n        \"An observation-driven time-dependent basis for a reduced description of transient stochastic systems\",\n        \"Real-time reduced-order modeling of stochastic partial differential equations via time-dependent subspaces\",\n        \"A minimization principle for the description of modes associated with finite-time instabilities\",\n        \"Control of linear instabilities by dynamically consistent order reduction on optimally time-dependent modes\",\n        \"Computing sensitivities in evolutionary systems: A real-time reduced order modeling strategy\",\n        \"Skeletal model reduction with forced optimally time dependent modes\",\n        \"The multiconfiguration time-dependent Hartree (MCTDH) method: a highly efficient algorithm for propagating wavepackets\",\n        \"Mean field dynamics of fermions and the time-dependent Hartree–Fock equation\",\n        \"Dynamical tensor approximation\",\n        \"Dynamically orthogonal tensor methods for high-dimensional nonlinear pdes\",\n        \"Tensor decompositions and applications\",\n        \"On-the-fly reduced order modeling of passive and reactive species via time-dependent manifolds\",\n        \"Reduced-order description of transient instabilities and computation of finite-time Lyapunov exponents\",\n        \"Optimal prediction and the mori–zwanzig representation of irreversible processes\",\n        \"High-ratio lossy compression: Exploring the autoencoder to compress scientific data\",\n        \"Wavelet-based deep auto encoder-decoder (wdaed)-based image compression\",\n        \"Transport dissipative particle dynamics model for mesoscopic advection-diffusion-reaction problems\",\n        \"Adjoint-based sensitivity analysis of flames\",\n        \"Adjoint-based sensitivity analysis of quantities of interest of complex combustion models\",\n        \"Adjoint sensitivity analysis of kinetic, thermochemical, and transport data of nitrogen and ammonia chemistry\",\n        \"Dnslab: A gateway to turbulent flow simulation in matlab\"\n    ],\n    \"reasoning\": \"Selected these 44 references because they represent foundational work and recent advances in Scalable In Situ Compression of Transient Simulation Data Using Time-Dependent Bases, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}