{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 51 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Dynamic Multi-Network Mining of Tensor Time Series\n\nPaper Abstract: Abstract. Subsequence clustering of time series is an essential task in data mining, and interpreting the resulting clusters is also crucial since we generally do not have prior knowledge of the data. Thus, given a large collection of tensor time series consisting of multiple modes, including timestamps, how can we achieve subsequence clustering for tensor time series and provide interpretable insights? In this paper, we propose a new method, Dynamic Multi-network Mining (DMM), that converts a tensor time series into a set of segment groups of various lengths (i.e., clusters) characterized by a dependency network constrained with ℓ1subscriptℓ1\\ell_{1}-norm. Our method has the following properties. (a) Interpretable: it characterizes the cluster with multiple networks, each of which is a sparse dependency network of a corresponding non-temporal mode, and thus provides visible and interpretable insights into the key relationships. (b) Accurate: it discovers the clusters with distinct networks from tensor time series according to the minimum description length (MDL). (c) Scalable: it scales linearly in terms of the input data size when solving a non-convex problem to optimize the number of segments and clusters, and thus it is applicable to long-range and high-dimensional tensors. Extensive experiments with synthetic datasets confirm that our method outperforms the state-of-the-art methods in terms of clustering accuracy. We then use real datasets to demonstrate that DMM is useful for providing interpretable insights from tensor time series.\n\n{retrieved_text}\n\nGenerate exactly 51 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 51\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Time-series clustering–a decade review\",\n        \"Time series motifs discovery under DTW allows more robust discovery of conserved structure\",\n        \"STG2Seq: Spatial-Temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting\",\n        \"Analysis of Temporal Tensor Datasets on Product Grassmann Manifold\",\n        \"Using Dynamic Time Warping to Find Patterns in Time Series\",\n        \"Ric: Parameter-free noise-robust clustering\",\n        \"Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers\",\n        \"Facets: Fast Comprehensive Mining of Coevolving High-order Time Series\",\n        \"Techniques for interpretable machine learning\",\n        \"Sparse inverse covariance estimation with the graphical lasso\",\n        \"Tensor analysis with n-mode generalized difference subspace\",\n        \"The minimum description length principle\",\n        \"Network Inference via the Time-Varying Graphical Lasso\",\n        \"Toeplitz Inverse Covariance-Based Clustering of Multivariate Time Series Data\",\n        \"Efficient Covariance Estimation from Temporal Data\",\n        \"Cluster analysis of time-series medical data based on the trajectory representation and multiscale comparison techniques\",\n        \"Network of Tensor Time Series\",\n        \"Ssmf: Shifting seasonal matrix factorization\",\n        \"Exact Indexing of Dynamic Time Warping\",\n        \"An Online Algorithm for Segmenting Time Series\",\n        \"Tensor decompositions and applications\",\n        \"Generalizing tensor decomposition for n-ary relational knowledge bases\",\n        \"Image analysis and machine learning in digital pathology: Challenges and opportunities\",\n        \"AutoPlait: Automatic Mining of Co-Evolving Time Sequences\",\n        \"Non-Linear Mining of Competing Local Activities\",\n        \"Sparse graphical modeling via stochastic complexity\",\n        \"Driver modeling based on driving behavior and its evaluation in driver identification\",\n        \"Node-Based Learning of Multiple Gaussian Graphical Models\",\n        \"Estimating time-varying brain connectivity networks from functional MRI time series\",\n        \"Fast and Multi-aspect Mining of Complex Time-stamped Event Streams\",\n        \"Network analysis of a financial market based on genuine correlation and threshold method\",\n        \"Streaming pattern discovery in multiple time-series\",\n        \"Inconco: interpretable clustering of numerical and categorical objects\",\n        \"Multivariate Clustering by Dynamics\",\n        \"Multilinear Dynamical Systems for Tensor Time Series\",\n        \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead\",\n        \"Gaussian Markov random fields: theory and applications\",\n        \"Correlating Financial Time Series with Micro-Blogging Activity\",\n        \"AutoCyclone: Automatic Mining of Cyclic Online Activities with Robust Tensor Factorization\",\n        \"The cluster graphical lasso for improved estimation of Gaussian graphical models\",\n        \"Temporal Pattern Detection in Time-Varying Graphical Models\",\n        \"Latent Variable Time-varying Network Inference\",\n        \"Statistical Models Coupling Allows for Complex Local Multivariate Time Series Analysis\",\n        \"Discovering similar multidimensional trajectories\",\n        \"Trend-Aware Tensor Factorization for Job Skill Demand Analysis.\",\n        \"Sparse Gaussian conditional random fields: Algorithms, theory, and application to energy forecasting\",\n        \"Time series clustering with ARMA mixtures\",\n        \"Modeling Changing Dependency Structure in Multivariate Time Series\",\n        \"Model selection and estimation in regression with grouped variables\",\n        \"Cautionary tales on air-quality improvement in Beijing\",\n        \"A review of subsequence time series clustering\"\n    ],\n    \"reasoning\": \"Selected these 51 references because they represent foundational work and recent advances in Dynamic Multi-Network Mining of Tensor Time Series, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}