{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 58 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: LL-GNN: Low Latency Graph Neural Networks on FPGAs for High Energy Physics\n\nPaper Abstract: Abstract. This work presents a novel reconfigurable architecture for Low Latency Graph Neural Network (LL-GNN) designs for particle detectors, delivering unprecedented low latency performance. Incorporating FPGA-based GNNs into particle detectors presents a unique challenge since it requires sub-microsecond latency to deploy the networks for online event selection with a data rate of hundreds of terabytes per second in the Level-1 triggers at the CERN Large Hadron Collider experiments. This paper proposes a novel outer-product based matrix multiplication approach, which is enhanced by exploiting the structured adjacency matrix and a column-major data layout. In addition, we propose a custom code transformation for the matrix multiplication operations, which leverages the structured sparsity patterns and binary features of adjacency matrices to reduce latency and improve hardware efficiency. Moreover, a fusion step is introduced to further reduce the end-to-end design latency by eliminating unnecessary boundaries. Furthermore, a GNN-specific algorithm-hardware co-design approach is presented which not only finds a design with a much better latency but also finds a high accuracy design under given latency constraints. To facilitate this, a customizable template for this low latency GNN hardware architecture has been designed and open-sourced, which enables the generation of low-latency FPGA designs with efficient resource utilization using a high-level synthesis tool. Evaluation results show that our FPGA implementation is up to 9.0 times faster and achieves up to 13.1 times higher power efficiency than a GPU implementation. Compared to the previous FPGA implementations, this work achieves 6.51 to 16.7 times lower latency. Moreover, the latency of our FPGA design is sufficiently low to enable deployment of GNNs in a sub-microsecond, real-time collider trigger system, enabling it to benefit from improved accuracy. The proposed LL-GNN design advances the next generation of trigger systems by enabling sophisticated algorithms to process experimental data efficiently.\n\n{retrieved_text}\n\nGenerate exactly 58 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 58\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Xilinx AI Engines and Their Applications\",\n        \"GenGNN: A Generic FPGA Framework for Graph Neural Network Acceleration\",\n        \"Interaction networks for learning about objects, relations and physics\",\n        \"Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis\",\n        \"FINN-R: An end-to-end deep-learning framework for fast exploration of quantized neural networks\",\n        \"ATLAS jet trigger performance during Run1 and preparation for Run2\",\n        \"ReGraph: Scaling Graph Processing on HBM-enabled FPGAs with Heterogeneous Pipelines\",\n        \"Automatic heterogeneous quantization of deep neural networks for low-latency inference on the edge for particle detectors\",\n        \"The Phase-2 Upgrade of the CMS Level-1 Trigger\",\n        \"HLS4ML LHC Jet dataset (30 particles)\",\n        \"Fast inference of deep neural networks in FPGAs for particle physics\",\n        \"HLS4ML LHC Jet dataset (50 particles)\",\n        \"Graph Neural Networks for Charged Particle Tracking on FPGAs\",\n        \"Graph neural networks for social recommendation\",\n        \"Protein interface prediction using graph convolutional networks\",\n        \"Understanding the design-space of sparse/dense multiphase GNN dataflows on spatial accelerators\",\n        \"AWB-GCN: A graph convolutional network accelerator with runtime workload rebalancing\",\n        \"I-GCN: A graph convolutional network accelerator with runtime locality enhancement through islandization\",\n        \"MALOC: A fully pipelined FPGA accelerator for convolutional neural networks with all layers mapped on chip\",\n        \"ESE: Efficient speech recognition engine with sparse LSTM on FPGA\",\n        \"EGCN: An Efficient GCN Accelerator for Minimizing Off-Chip Memory Access\",\n        \"Distance-weighted graph neural networks on FPGAs for real-time particle reconstruction in high energy physics\",\n        \"Performance of a geometric deep learning pipeline for HL-LHC particle tracking\",\n        \"GROW: A Row-Stationary Sparse-Dense GEMM Accelerator for Memory-Efficient Graph Convolutional Neural Networks\",\n        \"Stratix 10 NX Architecture and Applications\",\n        \"EnGN: A high-throughput and energy-efficient accelerator for large graph neural networks\",\n        \"HP-GNN: Generating High Throughput GNN Training Implementation on CPU-FPGA Heterogeneous Platform\",\n        \"GCN Inference Acceleration using High-Level Synthesis\",\n        \"JEDI-net: a jet identification algorithm based on interaction networks\",\n        \"Accelerating Large-Scale Graph Neural Network Training on Crossbar Diet\",\n        \"Learning representations of irregular particle-detector geometry with distance-weighted graph networks\",\n        \"Reconfigurable acceleration of Recurrent Neural Networks\",\n        \"MetaML: Automating Customizable Cross-Stage Design-Flow for Deep Learning Acceleration\",\n        \"Optimizing Graph Neural Networks for Jet Tagging in Particle Physics on FPGAs\",\n        \"Reconfigurable Acceleration of Graph Neural Networks for Jet Identification in Particle Physics\",\n        \"Recurrent Neural Networks With Column-Wise Matrix-Vector Multiplication on FPGAs\",\n        \"Accelerating recurrent neural networks for gravitational wave experiments\",\n        \"FlowGNN: A Dataflow Architecture for Universal Graph Neural Network Inference via Multi-Queue Streaming\",\n        \"Maximizing CNN accelerator efficiency through resource partitioning\",\n        \"StreamGCN: Accelerating Graph Convolutional Networks with Streaming Processing\",\n        \"Graph Sampling with Fast Random Walker on HBM-enabled FPGA Accelerators\",\n        \"Multi-node Acceleration for Large-scale GCNs\",\n        \"Graph neural networks in particle physics: Implementations, innovations, and challenges\",\n        \"G-NMP: Accelerating Graph Neural Networks with DIMM-based Near-Memory Processing\",\n        \"Enhancing high-level synthesis using a meta-programming approach\",\n        \"MoleculeNet: a benchmark for molecular machine learning\",\n        \"HyGCN: A GCN accelerator with hybrid architecture\",\n        \"DRGN: a dynamically reconfigurable accelerator for graph neural networks\",\n        \"Aligraph: A comprehensive graph neural network platform\",\n        \"Graph convolutional neural networks for web-scale recommender systems\",\n        \"Gcod: Graph convolutional network acceleration via dedicated algorithm and accelerator co-design\",\n        \"GraphACT: Accelerating GCN training on CPU-FPGA heterogeneous platforms\",\n        \"BoostGCN: A framework for optimizing GCN inference on FPGA\",\n        \"DNNBuilder: an automated tool for building high-performance DNN hardware accelerators for FPGAs\",\n        \"DNNExplorer: a framework for modeling and exploring a novel paradigm of FPGA-based DNN accelerator\",\n        \"G-CoS: GNN-accelerator co-search towards both better accuracy and efficiency\",\n        \"CoGNN: An Algorithm-Hardware Co-Design Approach to Accelerate GNN Inference with Mini-Batch Sampling\",\n        \"Model-Architecture Co-Design for High Performance Temporal GNN Inference on FPGA\"\n    ],\n    \"reasoning\": \"Selected these 58 references because they represent foundational work and recent advances in LL-GNN: Low Latency Graph Neural Networks on FPGAs for High Energy Physics, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}