{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 49 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: REAL-X — Robot open-Ended Autonomous Learning Architectures: Achieving Truly End-to-End Sensorimotor Autonomous Learning Systems This research has received funding from the European Union Horizon 2020 Research and Innovation Programme under Grant Agreement No 713010, Project Goal-Robots – Goal-based Open-ended Autonomous Learning Robots, http://www.goal-robots.eu/.\n\nPaper Abstract: Abstract Open-ended learning is a core research field of developmental robotics and AI aiming to build learning machines and robots that can autonomously acquire knowledge and skills incrementally as infants and children. The first contribution of this work is to study the challenges posed by the previously proposed benchmark ‘REAL competition’ aiming to foster the development of truly open-ended learning robot architectures. The competition involves a simulated camera-arm robot that: (a) in a first ‘intrinsic phase’ acquires sensorimotor competence by autonomously interacting with objects; (b) in a second ‘extrinsic phase’ is tested with tasks unknown in the intrinsic phase to measure the quality of knowledge previously acquired. This benchmark requires the solution of multiple challenges usually tackled in isolation, in particular exploration, sparse-rewards, object learning, generalisation, task/goal self-generation, and autonomous skill learning. As a second contribution, we present a set of ‘REAL-X’ robot architectures that are able to solve different versions of the benchmark, where we progressively release initial simplifications. The architectures are based on a planning approach that dynamically increases abstraction, and intrinsic motivations to foster exploration. REAL-X achieves a good performance level in very demanding conditions. We argue that the REAL benchmark represents a valuable tool for studying open-ended learning in its hardest form.\n\n{retrieved_text}\n\nGenerate exactly 49 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 49\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Conflict, arousal, and curiosity\",\n        \"What are intrinsic motivations? a biological perspective\",\n        \"Information-seeking, curiosity, and attention: computational and neural mechanisms\",\n        \"Intrinsically Motivated Learning in Natural and Artificial Systems\",\n        \"Open-ended learning: A conceptual framework based on representational redescription\",\n        \"Developmental robotics: a survey\",\n        \"Developmental robotics: From babies to robots\",\n        \"Intrinsically motivated learning of hierarchical collections of skills\",\n        \"Evolving childhood’s length and learning parameters in an intrinsically motivated reinforcement learning robot\",\n        \"Intrinsic motivation systems for autonomous mental development\",\n        \"Formal theory of creativity, fun, and intrinsic motivation (1990–2010)\",\n        \"A unified model of the joint development of disparity selectivity and vergence control\",\n        \"Cumulative learning through intrinsic reinforcements\",\n        \"Intrinsic motivation and mental replay enable efficient online adaptation in stochastic recurrent networks\",\n        \"Active efficient coding explains the development of binocular vision and its failure in amblyopia\",\n        \"Multilevel darwinist brain (mdb): Artificial evolution in a cognitive architecture for real robots\",\n        \"Reinforcement learning: An introduction\",\n        \"Recent advances in hierarchical reinforcement learning\",\n        \"Intrinsic motivation signals for driving the acquisition of multiple tasks: a simulated robotic study\",\n        \"Autonomous selection of the “what” and the “how” of learning: an intrinsically motivated system tested with a two armed robot\",\n        \"Intrinsically motivated goal exploration processes with automatic curriculum learning\",\n        \"Visual reinforcement learning with imagined goals\",\n        \"Automatic goal generation for reinforcement learning agents\",\n        \"Developing grounded goals through instant replay learning\",\n        \"Autonomous development of goals: From generic rewards to goal and self detection\",\n        \"GRAIL: A goal-discovering robotic architecture for intrinsically-motivated learning\",\n        \"Intrinsically motivated discovered outcomes boost user’s goals achievement in a humanoid robot\",\n        \"From exploration to control: learning object manipulation skills through novelty search and local adaptation\",\n        \"Bio-inspired model learning visual goals and attention skills through contingencies and intrinsic motivations\",\n        \"A laplacian framework for option discovery in reinforcement learning\",\n        \"Unifying count-based exploration and intrinsic motivation\",\n        \"Diversity is all you need: Learning skills without a reward function\",\n        \"Variational option discovery algorithms\",\n        \"Real-2019: Robot open-ended autonomous learning competition\",\n        \"An embodied agent learning affordances with intrinsic motivations and solving extrinsic tasks with attention and one-step planning\",\n        \"Principles of psychology\",\n        \"Curiosity-driven Exploration by Self-supervised Prediction\",\n        \"Large-Scale Study of Curiosity-Driven Learning\",\n        \"Self-supervised exploration via disagreement\",\n        \"Planning to Explore via Self-Supervised World Models\",\n        \"Skew-Fit: State-Covering Self-Supervised Reinforcement Learning\",\n        \"Which is the best intrinsic motivation signal for learning multiple skills?\",\n        \"Mutual Information Maximization for Robust Plannable Representations\",\n        \"Sparse Graphical Memory for Robust Planning\",\n        \"Unsupervised Visuomotor Control through Distributional Planning Networks\",\n        \"Learning Robotic Manipulation through Visual Planning and Acting\",\n        \"Optimal options for multi-task reinforcement learning under time constraints\",\n        \"Auto-encoding variational bayes\",\n        \"Dream to Control: Learning Behaviors by Latent Imagination\"\n    ],\n    \"reasoning\": \"Selected these 49 references because they represent foundational work and recent advances in REAL-X — Robot open-Ended Autonomous Learning Architectures: Achieving Truly End-to-End Sensorimotor Autonomous Learning Systems This research has received funding from the European Union Horizon 2020 Research and Innovation Programme under Grant Agreement No 713010, Project Goal-Robots – Goal-based Open-ended Autonomous Learning Robots, http://www.goal-robots.eu/., providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}