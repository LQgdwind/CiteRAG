{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 48 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: ASE: Anomaly Scoring Based Ensemble Learning for Highly Imbalanced Datasets\n\nPaper Abstract: Abstract. Nowadays, many classification algorithms have been applied to various industries to help them work out their problems met in real-life scenarios. However, in many binary classification tasks, samples in the minority class only make up a small part of all instances, which leads to the datasets we get usually suffer from high imbalance ratio. Existing models sometimes treat minority classes as noise or ignore them as outliers encountering data skewing. In order to solve this problem, we propose a bagging ensemble learning framework A‚ÄãS‚ÄãEùê¥ùëÜùê∏ASE (Anomaly Scoring Based Ensemble Learning). This framework has a scoring system based on anomaly detection algorithms which can guide the resampling strategy by divided samples in the majority class into subspaces. Then specific number of instances will be under-sampled from each subspace to construct subsets by combining with the minority class. And we calculate the weights of base classifiers trained by the subsets according to the classification result of the anomaly detection model and the statistics of the subspaces. Experiments have been conducted which show that our ensemble learning model can dramatically improve the performance of base classifiers and is more efficient than other existing methods under a wide range of imbalance ratio, data scale and data dimension. A‚ÄãS‚ÄãEùê¥ùëÜùê∏ASE can be combined with various classifiers and every part of our framework has been proved to be reasonable and necessary.\n\n{retrieved_text}\n\nGenerate exactly 48 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 48\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A novel outlier detection method for multivariate data\",\n        \"Fast outlier detection in high dimensional spaces\",\n        \"UCI machine learning repository\",\n        \"Prediction of software fault-prone classes using ensemble random forest with adaptive synthetic sampling algorithm\",\n        \"SMOTE: synthetic minority over-sampling technique\",\n        \"SMOTEBoost: Improving prediction of the minority class in boosting\",\n        \"Cost-sensitive large margin distribution machine for classification of imbalanced data\",\n        \"Credit card fraud detection: a realistic modeling and a novel learning strategy\",\n        \"On the use of mapreduce for imbalanced big data using random forest\",\n        \"Analysing the classification of imbalanced data-sets with multiple classes: Binarization techniques and ad-hoc approaches\",\n        \"A decision-theoretic generalization of on-line learning and an application to boosting\",\n        \"A new under-sampling method using genetic algorithm for imbalanced data classification\",\n        \"Learning from class-imbalanced data: Review of methods and applications\",\n        \"Borderline-SMOTE: a new over-sampling method in imbalanced data sets learning\",\n        \"Subfeat: Feature subspacing ensemble classifier for function prediction of dna, rna and protein sequences\",\n        \"The condensed nearest neighbor rule (corresp.)\",\n        \"ADASYN: Adaptive synthetic sampling approach for imbalanced learning\",\n        \"EPX: An R package for the ensemble of subsets of variables for highly unbalanced binary classification\",\n        \"Ensemble dynamic behavior detection method for adversarial malware\",\n        \"An improved ensemble approach for imbalanced classification problems\",\n        \"Addressing the curse of imbalanced training sets: one-sided selection\",\n        \"Improving identification of difficult small classes by balancing class distribution\",\n        \"Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning\",\n        \"Gradient harmonized single-stage detector\",\n        \"A binary PSO-based ensemble under-sampling model for rebalancing imbalanced training data\",\n        \"Isolation forest\",\n        \"Exploratory undersampling for class-imbalance learning\",\n        \"Self-paced ensemble for highly imbalanced massive data classification\",\n        \"MESA: boost ensemble imbalanced learning with meta-sampler\",\n        \"One-class SVMs for document classification\",\n        \"Training and assessing classification rules with imbalanced data\",\n        \"Hashing-based undersampling ensemble for imbalanced pattern classification problems\",\n        \"Scikit-learn: Machine Learning in Python\",\n        \"SMOTE-RSB*: a hybrid preprocessing approach based on oversampling and undersampling for high imbalanced data-sets using SMOTE and rough sets theory\",\n        \"Deep one-class classification\",\n        \"SMOTE‚ÄìIPF: Addressing the noisy and borderline examples problem in imbalanced classification by a re-sampling method with filtering\",\n        \"RUSBoost: A hybrid approach to alleviating class imbalance\",\n        \"A mathematical theory of communication\",\n        \"An instance level analysis of data complexity\",\n        \"SVMs modeling for highly imbalanced classification\",\n        \"Two modifications of CNN\",\n        \"Combination approach of SMOTE and biased-SVM for imbalanced datasets\",\n        \"Diversity analysis on imbalanced data sets by using ensemble models\",\n        \"Multiclass imbalance problems: Analysis and potential solutions\",\n        \"Ensemble of kernel extreme learning machine based random forest classifiers for automatic heartbeat classification\",\n        \"Intelligent fault diagnosis of machines with small & imbalanced data: A state-of-the-art review and possible extensions\",\n        \"Anomaly detection with robust deep autoencoders\",\n        \"Boosted SVM with active learning strategy for imbalanced data\"\n    ],\n    \"reasoning\": \"Selected these 48 references because they represent foundational work and recent advances in ASE: Anomaly Scoring Based Ensemble Learning for Highly Imbalanced Datasets, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}