{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 54 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Verifying Functional Correctness Properties At the Level of Java BytecodeWork partially supported by SNF grant 200021-207919 (LastMile).\n\nPaper Abstract: Abstract The breakneck evolution of modern programming languages aggravates the development of deductive verification tools, which struggle to timely and fully support all new language features. To address this challenge, we present ByteBack: a verification technique that works on Java bytecode. Compared to high-level languages, intermediate representations such as bytecode offer a much more limited and stable set of features; hence, they may help decouple the verification process from changes in the source-level language. ByteBack offers a library to specify functional correctness properties at the level of the source code, so that the bytecode is only used as an intermediate representation that the end user does not need to work with. Then, ByteBack reconstructs some of the information about types and expressions that is erased during compilation into bytecode but is necessary to correctly perform verification. Our experiments with an implementation of ByteBack demonstrate that it can successfully verify bytecode compiled from different versions of Java, and including several modern language features that even state-of-the-art Java verifiers (such as KeY and OpenJML) do not directly support—thus revealing how ByteBack’s approach can help keep up verification technology with language evolution.\n\n{retrieved_text}\n\nGenerate exactly 54 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 54\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"The KeY Platform for Verification and Analysis of Java Programs\",\n        \"Deductive Software Verification—The KeY Book\",\n        \"Abstract object creation in dynamic logic\",\n        \"Modern compiler implementation\",\n        \"Boogie: A Modular Reusable Verifier for Object-Oriented Programs\",\n        \"Specification and verification: the Spec# experience\",\n        \"The Satisfiability Modulo Theories Library (SMT-LIB)\",\n        \"CVC4\",\n        \"Preservation of proof obligations from Java to the Java virtual machine\",\n        \"Horn clause solvers for program verification\",\n        \"An overview of the Leon verification system: verification by translation to recursive functions\",\n        \"The VerCors Tool for Verification of Concurrent Programs\",\n        \"Formal Specification and Verification of JDK’s Identity Hash Map Implementation\",\n        \"Reasoning about JML: differences between KeY and OpenJML\",\n        \"Triggerless happy – intermediate verification with a first-order prover\",\n        \"BML and Related Tools\",\n        \"VCC: A Practical System for Verifying Concurrent C\",\n        \"Local verification of global invariants in concurrent programs\",\n        \"OpenJML: Software verification for Java 7 using JML, OpenJDK, and Eclipse\",\n        \"Java automated deductive verification in practice: Lessons from industrial proof-based projects\",\n        \"JML and OpenJML for Java 16\",\n        \"Reasoning with triggers\",\n        \"The JastAdd system – modular extensible compiler construction\",\n        \"Why3 - Where Programs Meet Provers\",\n        \"AutoProof: Auto-active functional verification of object-oriented programs\",\n        \"Verifying OpenJDK’s Sort Method for Generic Collections\",\n        \"The SeaHorn Verification Framework\",\n        \"Verifying OpenJDK’s LinkedList using KeY\",\n        \"Formal security verification of concurrent firmware in SoCs using instruction-level abstraction for hardware\",\n        \"VeriFast: A Powerful, Sound, Predictable, Fast Verifier for C and Java\",\n        \"Dynamic frames: Support for framing, dependencies and sharing without restrictions\",\n        \"Frama-C: A software analysis perspective\",\n        \"LLVM: A compilation framework for lifelong program analysis & transformation\",\n        \"The Java Modeling Language (JML) (NII shonan meeting 2013-3)\",\n        \"Formal Translation of Bytecode into BoogiePL\",\n        \"Dafny: An automatic program verifier for functional correctness\",\n        \"Usable auto-active verification\",\n        \"Object invariants in dynamic contexts\",\n        \"Trigger selection strategies to stabilize program verifiers\",\n        \"Using history invariants to verify observers\",\n        \"The KRAKATOA tool for certificationof JAVA/JAVACARD programs annotated in JML\",\n        \"Introduction to the Theory of Programming Languages\",\n        \"Z3: An Efficient SMT Solver\",\n        \"Proof-transforming compilation of programs with abrupt termination\",\n        \"Proof-carrying code\",\n        \"Byteback fm 2023 replication package\",\n        \"Verifying Whiley programs with Boogie\",\n        \"Flexible invariants through semantic collaboration\",\n        \"SMACK: Decoupling Source Language Details from Verifier Implementations\",\n        \"JayHorn: a Java model checker\",\n        \"The need for flexible object invariants\",\n        \"CANAL: A Cache Timing Analysis Framework via LLVM Transformation\",\n        \"Soot - a java bytecode optimization framework\",\n        \"Formal Verification of Optimizing Compilers\"\n    ],\n    \"reasoning\": \"Selected these 54 references because they represent foundational work and recent advances in Verifying Functional Correctness Properties At the Level of Java BytecodeWork partially supported by SNF grant 200021-207919 (LastMile)., providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}