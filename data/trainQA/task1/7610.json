{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 273 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Graph Learning and Its Advancements on Large Language Models: A Holistic Survey\n\nPaper Abstract: Abstract Graph learning is a prevalent domain that endeavors to learn the intricate relationships among nodes and the topological structure of graphs. Over the years, graph learning has transcended from graph theory to graph data mining. With the advent of representation learning, it has attained remarkable performance in diverse scenarios. Owing to its extensive application prospects, graph learning attracts copious attention. While some researchers have accomplished impressive surveys on graph learning, they failed to connect related objectives, methods, and applications in a more coherent way. As a result, they did not encompass current ample scenarios and challenging problems due to the rapid expansion of graph learning. Particularly, large language models have recently had a disruptive effect on human life, but they also show relative weakness in structured scenarios. The question of how to make these models more powerful with graph learning remains open. Our survey focuses on the most recent advancements in integrating graph learning with pre-trained language models, specifically emphasizing their application within the domain of large language models. Different from previous surveys on graph learning, we provide a holistic review that analyzes current works from the perspective of graph structure, and discusses the latest applications, trends, and challenges in graph learning. Specifically, we commence by proposing a taxonomy and then summarize the methods employed in graph learning. We then provide a detailed elucidation of mainstream applications. Finally, we propose future directions.\n\n{retrieved_text}\n\nGenerate exactly 273 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 273\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Birds of a feather: Homophily in social networks\",\n        \"Cosnet: Connecting heterogeneous social networks with local and global consistency\",\n        \"Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks\",\n        \"metapath2vec: Scalable representation learning for heterogeneous networks\",\n        \"Heterogeneous graph transformer\",\n        \"Social recommendation: a review\",\n        \"Hypersorec: Exploiting hyperbolic user and item representations with multiple aspects for social-aware recommendation\",\n        \"Delinquent events prediction in temporal networked-guarantee loans\",\n        \"Financial risk analysis for smes with graph-based supply chain mining\",\n        \"Heterogeneous information network based default analysis on banking micro and small enterprise users\",\n        \"Relation networks for object detection\",\n        \"Superglue: Learning feature matching with graph neural networks\",\n        \"Qa-gnn: Reasoning with language models and knowledge graphs for question answering\",\n        \"Graph convolutional networks for text classification\",\n        \"Graph networks as learnable physics engines for inference and control\",\n        \"Physics-guided graph meta learning for predicting water temperature and streamflow in stream networks\",\n        \"Modeling relational data with graph convolutional networks\",\n        \"Self-supervised graph transformer on large-scale molecular data\",\n        \"Random-walk computation of similarities between nodes of a graph with application to collaborative recommendation\",\n        \"Symmetric nonnegative matrix factorization for graph clustering\",\n        \"Graph embedding techniques, applications, and performance: A survey\",\n        \"Graph neural networks: A review of methods and applications\",\n        \"A comprehensive survey on graph neural networks\",\n        \"Graph self-supervised learning: A survey\",\n        \"Scan: a structural clustering algorithm for networks\",\n        \"Pathsim: Meta path-based top-k similarity search in heterogeneous information networks\",\n        \"A new neural network model for contextual processing of graphs\",\n        \"The graph neural network model\",\n        \"Multilevel k-way hypergraph partitioning\",\n        \"Maximizing the spread of influence through a social network\",\n        \"Learning to discover social circles in ego networks\",\n        \"Pte: Predictive text embedding through large-scale heterogeneous text networks\",\n        \"Grarep: Learning graph representations with global structural information\",\n        \"Revisiting semi-supervised learning with graph embeddings\",\n        \"Node2vec: Scalable feature learning for networks\",\n        \"Semi-supervised classification with graph convolutional networks\",\n        \"Variational graph auto-encoders\",\n        \"Inductive representation learning on large graphs\",\n        \"Fastgcn: fast learning with graph convolutional networks via importance sampling\",\n        \"Graph attention networks\",\n        \"Structural deep embedding for hyper-networks\",\n        \"Density-adaptive local edge representation learning with generative adversarial network multi-label edge classification\",\n        \"Heterogeneous graph attention network\",\n        \"Self-attention graph pooling\",\n        \"Dysat: Deep neural representation learning on dynamic graphs via self-attention networks\",\n        \"Beyond homophily in graph neural networks: Current limitations and effective designs\",\n        \"Self-supervised graph learning for recommendation\",\n        \"Controlling graph dynamics with reinforcement learning and graph neural networks\",\n        \"Think global, act local: Dual-scale graph transformer for vision-and-language navigation\",\n        \"Not too little, not too much: a theoretical analysis of graph (over) smoothing\",\n        \"“Sancus: sta le n ess-aware c omm u nication-avoiding full-graph decentralized training in large-scale graph neural networks\",\n        \"“Learning causal effects on hypergraphs\",\n        \"“A gentle introduction to deep learning for graphs\",\n        \"“A comprehensive survey of graph embedding: Problems\",\n        \"“Graph learning: A survey\",\n        \"“Deep learning on graphs: A survey\",\n        \"“A survey of heterogeneous information network analysis\",\n        \"“Knowledge graph embedding: A survey of approaches and applications\",\n        \"“A survey on network embedding\",\n        \"“Origins of homophily in an evolving social network\",\n        \"“Exploiting homophily effect for trust prediction\",\n        \"“Heterophily in social groups formation: a social network analysis\",\n        \"“Simplified graph convolution with heterophily\",\n        \"“Breaking the limit of graph neural networks by improving the assortativity of graphs with local mixing patterns\",\n        \"“The pagerank citation ranking: Bringing order to the web\",\n        \"“Weighted pagerank algorithm\",\n        \"“Fast incremental and personalized pagerank\",\n        \"“Hierarchical representation learning for bipartite graphs.” in IJCAI\",\n        \"“Learning bi-typed multi-relational heterogeneous graph via dual hierarchical attention networks\",\n        \"“Stock movement prediction based on bi-typed and hybrid-relational market knowledge graph via dual attention networks\",\n        \"“Attention is all you need\",\n        \"“Reinforcement learning based meta-path discovery in large-scale heterogeneous information networks\",\n        \"“Parallel graph decompositions using random shifts\",\n        \"“Graph measures and network robustness\",\n        \"“Approximate distance oracles for unweighted graphs in expected o (n 2) time\",\n        \"“Minority-weighted graph neural network for imbalanced node classification in social networks of internet of people\",\n        \"“Core decomposition and maintenance in weighted graph\",\n        \"“Compression of weighted graphs\",\n        \"“Weighted graph cuts without eigenvectors a multilevel approach\",\n        \"“An eigendecomposition approach to weighted graph matching problems\",\n        \"“Finding and evaluating community structure in networks.” Physical Review E\",\n        \"“Large-scale hierarchical text classification with recursively regularized deep graph-cnn\",\n        \"“Skeleton-based action recognition with directed graph neural networks\",\n        \"“Hypergraph neural networks\",\n        \"Hypergraphs: combinatorics of finite sets. Elsevier\",\n        \"“Hypergraph spectral learning for multi-label classification\",\n        \"“Heterogeneous hypergraph embedding for graph classification\",\n        \"“Influential groups for seeding and sustaining nonlinear contagion in heterogeneous hypergraphs\",\n        \"“Heterogeneous graph neural network\",\n        \"“Learning the evolutionary and multi-scale graph structure for multivariate time series forecasting\",\n        \"“Evolvegcn: Evolving graph convolutional networks for dynamic graphs\",\n        \"“Convolutional sequence to sequence learning\",\n        \"“Dyrep: Learning representations over dynamic graphs\",\n        \"“Streaming graph neural networks\",\n        \"“Dynamic hypergraph structure learning.” in IJCAI\",\n        \"“Dynamic hypergraph neural networks.” in IJCAI\",\n        \"“Unsupervised spectral feature selection with dynamic hyper-graph learning\",\n        \"“Simrank: a measure of structural-context similarity\",\n        \"“Big-align: Fast bipartite graph alignment\",\n        \"“User profile preserving social network embedding\",\n        \"“Pine: Universal deep embedding for graph nodes via partial permutation invariant set functions\",\n        \"“Scene graph generation by iterative message passing\",\n        \"“Edge-labeling graph neural network for few-shot learning\",\n        \"“Co-embedding of nodes and edges with graph neural networks\",\n        \"“Hierarchical graph representation learning with differentiable pooling\",\n        \"“Adversarially regularized graph autoencoder for graph embedding\",\n        \"“Unsupervised attributed multiplex network embedding\",\n        \"“Struc2vec: Learning node representations from structural identity\",\n        \"“Label informed attributed network embedding\",\n        \"“Individual fairness for graph neural networks: A ranking based approach\",\n        \"“Compressing network graphs\",\n        \"“Towards distributed node similarity search on graphs\",\n        \"“Nodesim: node similarity based network embedding for diverse link prediction\",\n        \"“Hierarchical structure and the prediction of missing links in networks\",\n        \"“Neural bellman-ford networks: A general graph neural network framework for link prediction\",\n        \"“On exploring semantic meanings of links for embedding social networks\",\n        \"“Community detection on evolving graphs\",\n        \"“Supervised community detection with line graph neural networks\",\n        \"“Overlapping community detection with graph neural networks\",\n        \"“Task sensitive feature exploration and learning for multitask graph classification\",\n        \"S. Narayanamurthy\",\n        \"“Asymmetric transitivity preserving graph embedding\",\n        \"“Distributed representations of words and phrases and their compositionality\",\n        \"“Efficient estimation of word representations in vector space\",\n        \"“Deepwalk: Online learning of social representations\",\n        \"“Deep neural networks for learning graph representations\",\n        \"“Deep graph infomax\",\n        \"“Graphvae: Towards generation of small graphs using variational autoencoders\",\n        \"“Fisrebp: Enterprise bankruptcy prediction via fusing its intra-risk and spillover-risk\",\n        \"“Connecting embeddings based on multiplex relational graph attention networks for knowledge graph entity typing\",\n        \"“Motif-matching based subgraph-level attentional convolutional network for graph classification\",\n        \"“Heterogeneous graph attention networks for semi-supervised short text classification\",\n        \"“Contrastive and generative graph convolutional networks for graph-based semi-supervised learning\",\n        \"“Semi-supervised learning with graph learning-convolutional networks\",\n        \"“Multi-stage self-supervised learning for graph convolutional networks on graphs with few labeled nodes\",\n        \"“Deepcluster: A general clustering framework based on deep learning\",\n        \"“Gpt-gnn: Generative pre-training of graph neural networks\",\n        \"“Self-supervised heterogeneous graph neural network with co-contrastive learning\",\n        \"“Neural relational inference for interacting systems\",\n        \"“Unsupervised feature selection for linked social media data\",\n        \"“Inductive relation prediction by subgraph reasoning\",\n        \"“Emergence of scaling in random networks\",\n        \"“Community structure in social and biological networks\",\n        \"“Finding and evaluating community structure in networks\",\n        \"“Community detection in graphs\",\n        \"“Convolutional neural networks on graphs with fast localized spectral filtering\",\n        \"“The link prediction problem for social networks\",\n        \"“Translating embeddings for modeling multi-relational data\",\n        \"“Neural message passing for quantum chemistry\",\n        \"“Finding community structure in networks using the eigenvectors of matrices\",\n        \"“Line: Large-scale information network embedding\",\n        \"“Spectral networks and locally connected networks on graphs\",\n        \"“How powerful are graph neural networks?” in ICLR\",\n        \"“The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains\",\n        \"“Friends and neighbors on the web\",\n        \"“Graph embedding and extensions: A general framework for dimensionality reduction\",\n        \"J. Aguilera-Iparraguirre\",\n        \"“Knowledge graph and text jointly embedding\",\n        \"“Graphs over time: densification laws\",\n        \"“Graph evolution: Densification and shrinking diameters\",\n        \"“The dynamics of viral marketing\",\n        \"“Social structure from multiple networks. i. blockmodels of roles and positions\",\n        \"“A measure of betweenness centrality based on random walks\",\n        \"“Detecting community structure in networks\",\n        \"“Graph neural networks for social recommendation\",\n        \"“A survey of knowledge-intensive nlp with pre-trained language models\",\n        \"“Greaselm: Graph reasoning enhanced language models for question answering\",\n        \"“Chatgraph: Interpretable text classification by converting chatgpt knowledge to graphs\",\n        \"“Linkbert: Pretraining language models with document links\",\n        \"“Deep bidirectional language-knowledge graph pretraining\",\n        \"“Dynamic heterogeneous-graph reasoning with language models and knowledge representation learning for commonsense question answering\",\n        \"“Incorporating explicit knowledge in pre-trained language models for passage re-ranking\",\n        \"“Explanation graph generation via pre-trained language models: An empirical study with contrastive learning\",\n        \"“Jaket: Joint pre-training of knowledge graph and language understanding\",\n        \"“Enhancing chinese pre-trained language model via heterogeneous linguistics graph\",\n        \"“A survey of knowledge enhanced pre-trained language models\",\n        \"“Opt: Open pre-trained transformer language models\",\n        \"“Palm 2 technical report\",\n        \"“Gpt-4 technical report\",\n        \"“Autoalign: Fully automatic and effective knowledge graph alignment enabled by large language models\",\n        \"“Explanations as features: Llm-based features for text-attributed graphs\",\n        \"“Towards open-world recommendation with knowledge augmentation from large language models\",\n        \"“Graphcare: Enhancing healthcare predictions with open-world personalized knowledge graphs\",\n        \"“Enhanced story comprehension for large language models through dynamic document-based knowledge graphs\",\n        \"“Codekgc: Code language model for generative knowledge graph construction\",\n        \"“Complex logical reasoning over knowledge graphs using large language models\",\n        \"“Lmexplainer: a knowledge-enhanced explainer for language models\",\n        \"“Structgpt: A general framework for large language model to reason over structured data\",\n        \"“Disentangled representation learning with large language models for text-attributed graphs\",\n        \"“Graphgpt: Graph instruction tuning for large language models\",\n        \"“Reasoning on graphs: Faithful and interpretable large language model reasoning\",\n        \"“Mindmap: Knowledge graph prompting sparks graph of thoughts in large language models\",\n        \"“Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt\",\n        \"“Can language models solve graph problems in natural language?” arXiv\",\n        \"“Llms for knowledge graph construction and reasoning: Recent capabilities and future opportunities\",\n        \"“Gpt4graph: Can large language models understand graph structured data? an empirical evaluation and benchmarking\",\n        \"“Towards graph foundation models: A survey and beyond\",\n        \"“Exploring the potential of large language models (llms) in learning on graphs\",\n        \"“Unifying large language models and knowledge graphs: A roadmap\",\n        \"“Chatgpt is not enough: Enhancing large language models with knowledge graphs for fact-aware language modeling\",\n        \"“Link prediction and recommendation across heterogeneous social networks\",\n        \"“Semantic path based personalized recommendation on weighted heterogeneous information networks\",\n        \"“Heterogeneous information network embedding for recommendation\",\n        \"“Self-supervised multi-channel hypergraph convolutional network for social recommendation\",\n        \"“Multi-behavior hypergraph-enhanced transformer for sequential recommendation\",\n        \"“Self-supervised hypergraph transformer for recommender systems\",\n        \"“Session-based social recommendation via dynamic graph attention networks\",\n        \"“Dynamic graph neural networks for sequential recommendation\",\n        \"“Are graph augmentations necessary? simple graph contrastive learning for recommendation\",\n        \"“Bertgcn: Transductive text classification by combining gcn and bert\",\n        \"“Multi-granularity heterogeneous graph attention networks for extractive document summarization\",\n        \"“Injecting logical background knowledge into embeddings for relation extraction\",\n        \"“N-ary relation extraction using graph state lstm\",\n        \"“Graph convolution over pruned dependency trees improves relation extraction\",\n        \"“Eigat: Incorporating global information in local attention for knowledge representation learning\",\n        \"“Connecting embeddings for knowledge graph entity typing\",\n        \"“Knowledge graph embedding by translating on hyperplanes.” in AAAI\",\n        \"“Indigo: Gnn-based inductive knowledge graph completion using pair-wise encoding\",\n        \"“Graph-structured representations for visual question answering\",\n        \"“Out of the box: Reasoning with graph convolution nets for factual visual question answering\",\n        \"“Graph r-cnn for scene graph generation\",\n        \"“Structural-rnn: Deep learning on spatio-temporal graphs\",\n        \"“Dynamic graph cnn for learning on point clouds\",\n        \"“A machine learning approach for predicting hidden links in supply chain with graph neural networks\",\n        \"“Modeling the momentum spillover effect for stock prediction via attribute-driven graph attention networks\",\n        \"“Contagious chain risk rating for networked-guarantee loans\",\n        \"“Finhgnn: A conditional heterogeneous graph learning to address relational attributes for stock predictions\",\n        \"“Asset pricing via deep graph learning to incorporate heterogeneous predictors\",\n        \"“Subsequence-based graph routing network for capturing multiple risk propagation processes\",\n        \"“Risk assessment for networked-guarantee loans using high-order graph attention representation.” in IJCAI\",\n        \"“Modeling the stock relation with graph network for overnight stock movement prediction\",\n        \"“Heterogeneous graph attention network for small and medium-sized enterprises bankruptcy prediction\",\n        \"“Graph neural network for fraud detection via spatial-temporal attention\",\n        \"“Pick and choose: a gnn-based imbalanced learning approach for fraud detection\",\n        \"“Antibenford subgraphs: Unsupervised anomaly detection in financial networks\",\n        \"“Convolutional embedding of attributed molecular graphs for physical property prediction\",\n        \"K. Tunyasuvunakool\",\n        \"“Graphbind: protein structural context embedded rules learned by hierarchical graph neural networks for recognizing nucleic-acid-binding residues\",\n        \"“Utilizing graph machine learning within drug discovery and development\",\n        \"“Physics-aware difference graph networks for sparsely-observed dynamics\",\n        \"“Learning to solve np-complete problems: A graph neural network for decision tsp\",\n        \"“Weakly-supervised text classification based on keyword graph\",\n        \"“Naturalistic physical adversarial patch for object detectors\",\n        \"“Searching for efficient multi-scale architectures for dense image prediction\",\n        \"“Dgraph: A large-scale financial dataset for graph anomaly detection\",\n        \"“xfraud: explainable fraud transaction detection\",\n        \"A. Krishnamurthy\",\n        \"“Graph meta learning via local subgraphs\",\n        \"“Meta relational learning for few-shot link prediction in knowledge graphs\",\n        \"“Hybrid graph neural networks for few-shot learning\",\n        \"“Ease: Unsupervised discriminant subspace learning for transductive few-shot learning\",\n        \"“Embedding compression with hashing for efficient representation learning in large-scale graph\",\n        \"“Exact: Scalable graph neural networks training via extreme activation compression\",\n        \"“Allie: Active learning on large-scale imbalanced graphs\",\n        \"“Gnnexplainer: Generating explanations for graph neural networks\",\n        \"“Neural additive models: Interpretable machine learning with neural nets\",\n        \"“Graphframex: Towards systematic evaluation of explainability methods for graph neural networks\",\n        \"“Towards self-explainable graph neural network\",\n        \"“Discovering invariant rationales for graph neural networks\",\n        \"“Parameterized explainer for graph neural network\",\n        \"“Xgnn: Towards model-level explanations of graph neural networks\",\n        \"“Predict then propagate: Graph neural networks meet personalized pagerank\",\n        \"“Simple and deep graph convolutional networks\",\n        \"“Graph convolutional neural networks with node transition probability-based message passing and dropnode regularization\",\n        \"“Decoupling the depth and scope of graph neural networks\",\n        \"“Universal invariant and equivariant graph neural networks\",\n        \"“E(n) equivariant graph neural networks\",\n        \"“E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials\",\n        \"“Edits: Modeling and mitigating data bias for graph neural networks\",\n        \"“Guide: Group equality informed individual fairness in graph neural networks\",\n        \"“Fairness in graph-based semi-supervised learning\",\n        \"“Netfense: Adversarial defenses against privacy attacks on neural networks for graph data\",\n        \"“A federated graph neural network framework for privacy-preserving personalization\"\n    ],\n    \"reasoning\": \"Selected these 273 references because they represent foundational work and recent advances in Graph Learning and Its Advancements on Large Language Models: A Holistic Survey, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}