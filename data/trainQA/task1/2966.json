{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 208 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Time Series Analysis and Modeling to Forecast: a Survey\n\nPaper Abstract: Abstract Time series modeling for predictive purpose has been an active research area of machine learning for many years. However, no sufficiently comprehensive and meanwhile substantive survey was offered so far. This survey strives to meet this need. A unified presentation has been adopted for entire parts of this compilation. A red thread guides the reader from time series preprocessing to forecasting. Time series decomposition is a major preprocessing task, to separate nonstationary effects (the deterministic components) from the remaining stochastic constituent, assumed to be stationary. The deterministic components are predictable and contribute to the prediction through estimations or extrapolation. Fitting the most appropriate model to the remaining stochastic component aims at capturing the relationship between past and future values, to allow prediction. We cover a sufficiently broad spectrum of models while nonetheless offering substantial methodological developments. We describe three major linear parametric models, together with two nonlinear extensions, and present five categories of nonlinear parametric models. Beyond conventional statistical models, we highlight six categories of deep neural networks appropriate for time series forecasting in nonlinear framework. Finally, we enlighten new avenues of research for time series modeling and forecasting. We also report software made publicly available for the models presented.\n\n{retrieved_text}\n\nGenerate exactly 208 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 208\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A review on distance based time series classification\",\n        \"Time-series clustering - a decade review\",\n        \"Simulation of sea state parameters process to study the profitability of a maritime line\",\n        \"Non-homogeneous hidden Markov-switching models for wind time series\",\n        \"Markovian representation of stochastic processes and its application to the analysis of autoregressive moving average processes\",\n        \"Attentive state-space modeling of disease progression\",\n        \"Markov switching component GARCH model: stability and forecasting\",\n        \"Clustering and classification for time series data in visual analytics: a survey\",\n        \"A review of deep learning methods applied on load forecasting\",\n        \"High-dimensional VAR with low-rank transition\",\n        \"Deep neural networks for energy load forecasting\",\n        \"Introduction to the fundamentals of time series data and analysis\",\n        \"Comparing the forecasting performance of seasonal Arima and Holt-Winters methods of births at a tertiary healthcare facility in Ghana\",\n        \"Practical Time Series Analysis: Master Time Series Data Processing, Visualization, and Modeling using Python\",\n        \"An empirical evaluation of generic convolutional and recurrent networks for sequence modeling\",\n        \"A deep learning framework for financial time series using stacked autoencoders and long-short term memory\",\n        \"A nonparametric test for stationarity based on local Fourier analysis\",\n        \"A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains\",\n        \"Nonlinear prediction via Volterra series and applications to geophysical data\",\n        \"Neural forecasting: introduction and literature overview\",\n        \"Bagging exponential smoothing methods using STL decomposition and Box‚ÄìCox transformation\",\n        \"Monbet V (2016) Comparison of hidden and observed regime-switching autoregressive models for (u\",\n        \"Lozano J (2021) A review on outlier/anomaly detection in time series data. ACM Computing Surveys 54(3):56:1‚Äì56:33\",\n        \"Bollerslev T (1986a) Generalized autoregressive conditional heteroskedasticity\",\n        \"Bollerslev T (1986b) Generalized autoregressive conditional heteroskedasticity\",\n        \"Picard N (1992) Stationarity of GARCH processes and some nonnegative time series. Journal of Econometrics 52:115‚Äì127\",\n        \"Cox DR (1964) An analysis of transformations. Journal of the Royal Statistical Society: Series B (Methodological) 26(2):211‚Äì243\",\n        \"Ljung GM (2015) Time series analysis: forecasting and control\",\n        \"Wagner S (2020) Anomaly detection in univariate time-series: a survey on the state-of-the-art. arXiv:2004.00433v1\",\n        \"Fienberg SE (1991) Time series: theory and methods. Springer\",\n        \"4th edn. Cambridge University Press\",\n        \"CNNs and LSTMs in Python. https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/\",\n        \"https://machinelearningmastery\",\n        \"Cai J (1994) A Markov model of switching-regime ARCH\",\n        \"Nason GP (2013) Costationarity of locally stationary time series using costat. Journal of Statistical Software 55(1):1‚Äì22\",\n        \"Malerba D (2014) Completion time and next activity prediction of processes using sequential pattern mining\",\n        \"MozeticÀòÀòùëê\\\\breve{c} I (2020) Evaluating time series forecasting models: an empirical study on performance estimation methods\",\n        \"Zhang RM (2015) LASSO estimation of threshold autoregressive models. Journal of Econometrics 189(2):285‚Äì296\",\n        \"Chand S (2016) Evaluation of co-evolutionary neural network architectures for time series prediction with mobile application in finance\",\n        \"Tsay RS (1993) Functional-coefficient autoregressive models. Journal of the American Statistical Association 88(421):298‚Äì308\",\n        \"Cheng J (2016) A transitional Markov switching autoregressive model\",\n        \"Li X (2017) Electric load forecasting in smart grids using Long-Short-Term-Memory based Recurrent Neural Network\",\n        \"Lai KS (1995) Lag order and critical values of the augmented Dickey‚ÄìFuller test. Journal of Business & Economic Statistics 13(3):277‚Äì280\",\n        \"Shin Ks (2018) Genetic algorithm-optimized long short-term memory network for stock market prediction. Sustainability 10:3765\",\n        \"Yang B (2018) Correlated time series forecasting using multi-task deep neural networks\",\n        \"Krolzig HM (1998) A comparison of the forecast performance of Markov-switching and threshold autoregressive models of US GNP\",\n        \"Terpenning I (1990) STL: a seasonal-trend decomposition. Journal of Official Statistics 6(1):3‚Äì73\",\n        \"Shyu WM (2017) Local regression models. In: Hastie T (ed) Statistical models in S\",\n        \"Stephens A Mickael (1986) Goodness-of-fit-techniques\",\n        \"Bianconcini S (2016) Seasonal adjustment methods and real time trend-cycle estimation. Statistics for Social and Behavioral Sciences\",\n        \"Sinoquet C (2021) Partially Hidden Markov Chain Linear Autoregressive model: inference and forecasting. arXiv:2102.12584\",\n        \"Sinoquet C (2021\",\n        \"Eichler M (2018) Locally stationary functional time series. Electronic Journal of Statistics 12:107‚Äì170\",\n        \"Deschamps PJ (2008) Comparing smooth transition and Markov switching autoregressive models of US unemployment\",\n        \"Vetter M (2011) A measure of stationarity in locally stationary processes with applications to testing\",\n        \"Zhou Z (2015) Change point analysis of second order characteristics in non-stationary time series. arXiv:150308610\",\n        \"Fuller WA (1979) Distribution of the estimators for autoregressive time series with a unit root\",\n        \"Mayoral L (2002) A fractional dickey‚Äìfuller test for unit roots. Econometrica 70(5):1963‚Äì2006\",\n        \"Gomez-Rodriguez M\",\n        \"Durbin J (1959) Efficient estimation of parameters in moving-average models\",\n        \"Durbin J (1960) The fitting of time-series models\",\n        \"Watson GS (1950) Testing for Serial Correlation in Least Squares Regression: I. Biometrika 37(3/4):409‚Äì428\",\n        \"Watson GS (1951) Testing for Serial Correlation in Least Squares Regression: II. Biometrika 38(1/2):159‚Äî77\",\n        \"Liboschik T (2015) Robust estimation of (partial) autocorrelation. Tech. rep\",\n        \"Journal of Time Series Analysis 32(1):68‚Äì91\",\n        \"Ter√§svirta T (1996) Testing the adequacy of smooth transition autoregressive models. Journal of Econometrics 74(1):59‚Äì75\",\n        \"Stock JH (1996) Efficient tests for an autoregressive unit root. Econometrica 64(4):813‚Äì836\",\n        \"Timmermann A (2015) Complete subset regressions with large-dimensional sets of predictors. Journal of Economic Dynamics and Control 54:86‚Äì110\",\n        \"Schmidt-Thieme L\",\n        \"Engle RF (1982) Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation\",\n        \"Bollerslev T (1986) Modelling the persistence of conditional variance. Econometric Reviews 5(1):1‚Äì50\",\n        \"Escanciano JC (2006) Goodness-of-fit tests for linear and nonlinear time series models\",\n        \"Gijbels I (1996) Local polynomial modelling and its applications\",\n        \"Muller PA (2019) Deep learning for time series classification: a review. Data Mining and Knowledge Discovery 33(4):917‚Äì963\",\n        \"Favier G (2010) MIMO volterra modeling for nonlinear communication channels. Learning and Nonlinear Models 2(8):71‚Äì92\",\n        \"Krauss C (2018) Deep learning with long short-term memory networks for financial market predictions\",\n        \"Franke J (1985) A Levinson-Durbin recursion for autoregressive-moving average processes\",\n        \"Zinde-Walsh V (1994) A simple noniterative estimator for moving average models. Biometrika 81(1):143‚Äì155\",\n        \"Gardner Jr E (1985) Exponential smoothing: the state of the art\",\n        \"Gardner Jr E (2006) Exponential smoothing: The state of the art - Part II\",\n        \"Mc Kenzie E (1985) Forecasting trends in time series. Management Science 31:1237‚Äì1246\",\n        \"Alippi C (2019) Deep learning for time series forecasting: the electric load case. arXiv:1907.09207\",\n        \"Kerrigan EC (2016) Short-term ocean wave forecasting using an autoregressive moving average model\",\n        \"Croux C (2010) Robust forecasting with exponential and Holt‚ÄìWinters smoothing. Journal of Forecasting 29(3):285‚Äì300\",\n        \"Raabe N (2016) Deep learning for solar power forecasting - an approach using AutoEncoder and LSTM neural networks\",\n        \"Poggi JM (2021) Random Forests for time series. hal-03129751\",\n        \"Castro R (2012) Wind speed and wind power forecasting using statistical models: autoregressive moving average (ARMA) and artificial neural networks (ANN)\",\n        \"Crujeiras RM (2013) An updated review of goodness-of-fit tests for regression models. Test 22(3):361‚Äì411\",\n        \"Gospodinov N (2005) Testing for threshold nonlinearity in short-term interest rates\",\n        \"Haber R (2010) Nonlinear predictive control of smooth nonlinear systems based on Volterra models\",\n        \"Guerrero VM (1993) Time-series analysis supported by power transformations\",\n        \"Hagerud GE (1996) A smooth transition ARCH model for asset returns\",\n        \"Hamilton JD (1989) A new approach to the economic analysis of nonstationary time series and the business cycle\",\n        \"Hamilton JD (1990) Analysis of time series subject to changes in regime\",\n        \"vol 2. Princeton University Press\",\n        \"Kavalieris L (1984) A method for autoregressive-moving average estimation. Biometrika 71(2):273‚Äì280\",\n        \"Rissanen J (1982) Recursive estimation of mixed autoregressive-moving average order. Biometrika 69(1):81‚Äì94\",\n        \"Hansen BE (2011) Threshold autoregression in economics\",\n        \"Chen R (1997) A review of nonparametric time series analysis. International Statistical Review 65(1):49‚Äì72\",\n        \"He W (2017) Load forecasting via deep neural networks\",\n        \"Bandara K (2021) Recurrent neural networks for time series forecasting: current status and future directions\",\n        \"Gopalakrishnan E\",\n        \"Carnegie Institute of Technology\",\n        \"Holt CC (2004) Forecasting seasonals and trends by exponentially weighted moving averages\",\n        \"Hossain MZ (2011) The use of Box-Cox transformation technique in economic and statistical analyses\",\n        \"Zhang H (2019) Deep learning with Long Short-Term Memory for time series prediction. IEEE Communications Magazine 57(6):114‚Äì119\",\n        \"Weinberger K (2017) Snapshot ensembles: train 1\",\n        \"Wetzel R (2017) Marked point process for severity of illness assessment. In: Proceedings of Machine Learning for Healthcare (MLHC)\",\n        \"Jones RH (1980) Maximum likelihood fitting of ARMA models to time series with missing observations\",\n        \"Placet V (2021) Autoregressive Hidden Markov Models with partial knowledge on latent space applied to aero-engines prognostics. arXiv:2105.00211\",\n        \"Kheddouci H (2020) A generative time series clustering framework based on an ensemble mixture of HMMs\",\n        \"Altinkaya MA (2015) Estimation of the nonlinearity degree for polynomial autoregressive processes with RJMCMC\",\n        \"Altinkaya MA (2017) One-day ahead wind speed/power prediction based on polynomial autoregressive model\",\n        \"Nelson PI (1978) On conditional least squares estimation for stochastic processes. The Annals of statistics pp 629‚Äì642\",\n        \"Esaki H (2018) Mining causality of network events in log data. IEEE Transactions on Network and Service Management 15(1):53‚Äì67\",\n        \"Vasconcelos G (2020) Penalized time series regression. In: (eds) FP (ed) Macroeconomic Forecasting in the Era of Big Data\",\n        \"Wang Z (2018) Convolutional neural networks for energy time series forecasting. In: International Joint Conference on Neural Networks (IJCNN)\",\n        \"Huang CJ (2018) A high precision artificial neural networks model for short-term energy load forecasting. Energies 11(1):213\",\n        \"Kuruoglu EE (2002) Nonlinear least lp-norm filters for nonlinear autoregressive alpha-stable processes\",\n        \"Shin Y (1992) Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root? Journal of econometrics 54(1-3):159‚Äì178\",\n        \"Garnero L (2003) Functional connectivity: studying nonlinear\",\n        \"Liu H (2018) Modeling long-and short-term temporal patterns with deep neural networks\",\n        \"Carranza-Garc√≠a M\",\n        \"Lee D (2011) Short-term prediction of wind farm output using the recurrent quadratic Volterra model\",\n        \"Na S (2003) The cusum test for parameter change in time series models. Scandinavian Journal of Statistics 30(4):781‚Äì796\",\n        \"In: 33rd Conference on Neural Information Processing Systems (NeurIPS)\",\n        \"Zohren S (2020) Time series forecasting with deep learning: a survey. https://arxiv.org/abs/2004.13408\",\n        \"Ter√§svirta T (1994) Testing the constancy of regression parameters against continuous structural change. Journal of Econometrics 62(2):211‚Äì228\",\n        \"Elkan C (2015) A critical review of recurrent neural networks for sequence learning. arXiv:1506.00019\",\n        \"Box GE (1978) On a measure of lack of fit in time series models. Biometrika 65(2):297‚Äì303\",\n        \"In: 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)\",\n        \"Wang Y (2015) Long short-term memory neural network for traffic speed prediction using remote microwave sensor data\",\n        \"MacKay Altman R (2004) Assessing the goodness-of-fit of hidden Markov models\",\n        \"Caiado J (2019) Time series clustering and classification. Chapman and Hall\",\n        \"Yohai VJ (2006) Robust statistics. J. Wiley\",\n        \"Aparecida Soares da Silva E\",\n        \"Zilberman E (2021) Forecasting inflation in a data-rich environment: the benefits of machine learning methods\",\n        \"Berg A (2003) Stochastic volatility: Bayesian computation using automatic differentiation and the extended Kalman filter\",\n        \"In: 4th International Conference on Networked Computing and Advanced Information Management\",\n        \"Mohammadi M (2017) Prediction of Œ±ùõº\\\\alpha-stable GARCH and ARMA-GARCH-M models\",\n        \"Tappert CC (2018) The partially observable hidden Markov model and its application to keystroke dynamics. Pattern Recognition 76:449‚Äì462\",\n        \"Kulahci M (2016) Introduction to Time Series Analysis and Forecasting\",\n        \"Kronauer R (1973) Maximum likelihood estimation for moving average models. SankhyƒÅ: The Indian Journal of Statistics\",\n        \"Journal of the Royal Statistical Society: Series B (Statistical Methodology) 75(5):879‚Äì904\",\n        \"Nielsen A (2019) Practical Time Series Analysis\",\n        \"Journal of the Royal Statistical Society: Series B (Statistical Methodology) 68(4):707‚Äì720\",\n        \"Princeton University\",\n        \"University Library of Munich\",\n        \"Research & Evaluation 15(12):1‚Äì9\",\n        \"Rachev S (1995) Stable GARCH models for financial time series. Applied Mathematics Letters 8:33‚Äì37\",\n        \"Arma and Garch. Wiley Series in Probability and Statistics\",\n        \"Paparoditis E (2010) Validating stationarity assumptions in time series analysis by rolling local periodograms\",\n        \"Meek C (2012) Conjoint modeling of temporal dependencies in event streams. In: Proceedings of the 9th UAI Bayesian Modeling Applications Workshop\",\n        \"Choi JW (2018) Sequence-to-sequence prediction of vehicle trajectory via LSTM encoder-decoder architecture\",\n        \"Pegels CC (1969) Exponential forecasting: some new variations\",\n        \"Wang L (2018) Effective long short-term memory with differential evolution algorithm for electricity price prediction. Energy 162:1301‚Äì1314\",\n        \"the oil price shock\",\n        \"John Wiley & Sons\",\n        \"Yang BS (2010) Estimation and forecasting of machine health condition using ARMA/GARCH model. Mechanical Systems and Signal Processing 24(2):546‚Äì558\",\n        \"Richter S (2020) Forecasting time series with encoder-decoder neural networks. arXiv:2009.08848\",\n        \"Phillips PC (1987) Time series regression with a unit root\",\n        \"Perron P (1988) Testing for a unit root in time series regression. Biometrika 75(2):335‚Äì346\",\n        \"Portilla JM (2018) Using Python and Auto ARIMA to forecast seasonal time series\",\n        \"Dette H (2013) A test for stationarity based on empirical processes. Bernoulli 19(5B):2715‚Äì2749\",\n        \"Rao TS (1969) A test for non-stationarity of time-series. Journal of the Royal Statistical Society: Series B (Methodological) 31(1):140‚Äì149\",\n        \"Preu√ü P (2016) Testing for stationarity in multivariate locally stationary processes. Journal of Time Series Analysis 37(1):3‚Äì29\",\n        \"Schmidt E (2020) Survey of deep learning for scientific discovery. arXiv:2003.11755\",\n        \"Januschowski T (2018) Deep state space models for time series forecasting. In: 32nd Conference on Neural Information Processing Systems (NeurIPS)\",\n        \"In: 9th International Conference on Learning Representations (ICLR)\",\n        \"R√©millard B (2017) Goodness-of-fit tests for copulas of multivariate time series\",\n        \"Bagnall AJ (2021) The great multivariate time series classification bake off: a review and experimental evaluation of recent algorithmic advances\",\n        \"Journal of the Royal Statistical Society: Series D (The Statistician) 41(2):169‚Äì178\",\n        \"Acharaya A (2019) Time series based air pollution forecasting using SARIMA and Prophet model\",\n        \"Babu P (2012) On moving average parameter estimation. In: 20th European Signal Processing Conference (EUSIPCO)\",\n        \"Dhillon IS (2019) Think globally\",\n        \"Gal A (2017) Temporal network representation of event logs for improved performance modelling in business processes\",\n        \"Murat A (2020) Financial time series forecasting with deep learning : a systematic literature review: 2005‚Äì2019. Applied Soft Computing 90:106181\",\n        \"Xiao G (2019) A novel time series forecasting model with deep learning. Neurocomputing 396(5):302‚Äì313\",\n        \"Chen MT (2005) A Bayesian threshold nonlinearity test for financial time series. Journal of Forecasting 24(1):61‚Äì75\",\n        \"Solarwinds (2019) Holt-winters forecasting simplified\",\n        \"Sumathi K (1998) Innovation algorithm in ARMA process. Korean Journal of Computational & Applied Mathematics 5(2):331‚Äì340\",\n        \"Salakhutdinov R (2014) Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research 15(1):1929‚Äì1958\",\n        \"Terzi M (2018) Time-series classification methods: review and applications to power systems data. In: Big Data Application in Power Systems\",\n        \"Taylor JW (2003a) Exponential smoothing with a damped multiplicative trend\",\n        \"Taylor JW (2003b) Short-term electricity demand forecasting using double seasonal exponential smoothing\",\n        \"Zhan P (2018) A deep neural network model for short-term load forecast based on Long Short-Term Memory network and convolutional neural network\",\n        \"Tong H (1990) Non-linear time series: a dynamical system approach\",\n        \"Mart√≠nez-√Ålvarez F\",\n        \"Tsay RS (1989) Testing and modeling threshold autoregressive processes\",\n        \"Chen R (2018) Nonlinear time series analysis. Wiley\",\n        \"Helmers CG (2013) Forecasting ENSO with a smooth transition autoregressive model. Environmental modelling & software 40:181‚Äì190\",\n        \"Abubakar I (2019) Trend of neonatal mortality in Nigeria from 1990 to 2017 using time series analysis\",\n        \"Valipour M (2015) Long-term runoff study using SARIMA and ARIMA models in the united states\",\n        \"Polosukhin I (2017) Attention is all you need. In: 31st Conference on Neural Information Processing Systems (NeurIPS)\",\n        \"Real LA (2003) Monte Carlo assessments of goodness-of-fit for ecological simulation models. Ecological Modelling 164(1):49‚Äì63\",\n        \"Januschowski T (2019) Deep factors for forecasting. In: 36th International Conference on Machine Learning (ICML)\",\n        \"Whittle P (1953) Estimation and information in stationary time series\",\n        \"Willems P (2009) A time series tool to support the multi-criteria performance evaluation of rainfall-runoff models\",\n        \"Winters PR (1960) Forecasting sales by exponentially weighted moving averages\",\n        \"second revised edn. Almqvist and Wiksell Book Co\",\n        \"O‚ÄôBanion S (2020) Deep transformer models for time series forecasting:the influenza prevalence case. arXiv:2001.08317\",\n        \"Chu SM (2017) Modeling the intensity function of point process via recurrent neural networks\",\n        \"Wang Y (2018) Bridge structure deformation prediction based on GNSS data using Kalman-ARIMA-GARCH model. Sensors 18(1):298\",\n        \"Yang E (2019) Modeling a nonlinear process using the exponential autoregressive time series model. Nonlinear Dynamics 95(3):2079‚Äì2092\",\n        \"Mukherjee S (2020) Stanza: a nonlinear state space model for probabilistic inference in non-stationary time series. arXiv:2006.06553\",\n        \"In: 30th Conference on Neural Information Processing Systems (NeurIPS)\",\n        \"Zhou Z (2013) Heteroscedasticity and autocorrelation robust structural change detection\",\n        \"Andrews DWK (2002) Further evidence on the great crash\"\n    ],\n    \"reasoning\": \"Selected these 208 references because they represent foundational work and recent advances in Time Series Analysis and Modeling to Forecast: a Survey, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}