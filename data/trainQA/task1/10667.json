{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 63 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: A Dynamical View of the Question of Why\n\nPaper Abstract: Abstract We address causal reasoning in multivariate time series data generated by stochastic processes. Existing approaches are largely restricted to static settings, ignoring the continuity and emission of variations across time. In contrast, we propose a learning paradigm that directly establishes causation between events in the course of time. We present two key lemmas to compute causal contributions and frame them as reinforcement learning problems. Our approach offers formal and computational tools for uncovering and quantifying causal relationships in diffusion processes, subsuming various important settings such as discrete-time Markov decision processes. Finally, in fairly intricate experiments and through sheer learning, our framework reveals and quantifies causal links, which otherwise seem inexplicable.\n\n{retrieved_text}\n\nGenerate exactly 63 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 63\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Causation\",\n        \"Counterfactual dependence and timeâ€™s arrow\",\n        \"Postscripts to causation\",\n        \"Causation as influence\",\n        \"Scientific explanation and the causal structure of the world\",\n        \"Physical causation\",\n        \"Causation, prediction, and search\",\n        \"Models, reasoning and inference\",\n        \"Causes and explanations: Part 1: Causes\",\n        \"Causes and explanations: A structural-model approach. part ii: Explanations\",\n        \"Hunting causes and using them: Approaches in philosophy and economics\",\n        \"Causal inference without counterfactuals\",\n        \"Causality: Statistical perspectives and applications\",\n        \"An anytime algorithm for causal inference\",\n        \"Causation and the flow of energy\",\n        \"Causation and laws of nature\",\n        \"Discussion: Salmon on explanatory relevance\",\n        \"A dynamical systems approach to causation\",\n        \"On the general theory of control systems\",\n        \"A Second Course in Stochastic Processes\",\n        \"The Economics of Inaction: Stochastic Control Models with Fixed Costs\",\n        \"The Metaphysics of Causation\",\n        \"Medical dead-ends and learning to identify High-Risk states and treatments\",\n        \"Keeping track of the time: Emending the counterfactual analysis of causation\",\n        \"Probabilistic graphical models: principles and techniques\",\n        \"Causal models for dynamical systems\",\n        \"Causal interpretation of stochastic differential equations\",\n        \"The arcade learning environment: An evaluation platform for general agents\",\n        \"Human-level control through deep reinforcement learning\",\n        \"In silico preclinical trials: a proof of concept in closed-loop control of type 1 diabetes\",\n        \"Probabilities of causation: three counterfactual interpretations and their identification\",\n        \"Probabilities of causation: Bounds and identification\",\n        \"The probability of causation\",\n        \"Causes of effects: Learning individual responses from population data\",\n        \"Causal sufficiency and actual causation\",\n        \"A principled approach to defining actual causation\",\n        \"A modification of the halpern-pearl definition of causality\",\n        \"A partial theory of actual causation\",\n        \"The intransitivity of causation revealed in equations and graphs\",\n        \"Prevention, preemption, and the principle of sufficient reason\",\n        \"Investigating causal relations by econometric models and cross-spectral methods\",\n        \"Granger causality and dynamic structural systems\",\n        \"Causal inference on time series using restricted structural equation models\",\n        \"Invariant causal prediction for sequential data\",\n        \"Causal reasoning in graphical time series models\",\n        \"Causal discovery from heterogeneous/nonstationary data\",\n        \"From ordinary differential equations to structural causal models: the deterministic case\",\n        \"Generalized structural causal models\",\n        \"Causal modeling of dynamical systems\",\n        \"From deterministic odes to dynamic structural causal models\",\n        \"Causality: models, reasoning, and inference\",\n        \"Actual causality\",\n        \"Making things happen: A theory of causal explanation\",\n        \"System Identification: Theory for the User\",\n        \"Multivariable Feedback Control: Analysis and Design\",\n        \"Dead-ends and secure exploration in reinforcement learning\",\n        \"A distributional perspective on reinforcement learning\",\n        \"Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning\",\n        \"Semi-Markov offline reinforcement learning for healthcare\",\n        \"Systematic rectification of language models via dead-end analysis\",\n        \"The uva/padova type 1 diabetes simulator: new features\",\n        \"The uva/padova type 1 diabetes simulator goes from single meal to single day\",\n        \"Prioritized experience replay\"\n    ],\n    \"reasoning\": \"Selected these 63 references because they represent foundational work and recent advances in A Dynamical View of the Question of Why, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}