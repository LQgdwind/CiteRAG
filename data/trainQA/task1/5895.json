{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 48 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Time-multiplexed Neural Holography: A Flexible Framework for Holographic Near-eye Displays with Fast Heavily-quantized Spatial Light Modulators\n\nPaper Abstract: Abstract. Holographic near-eye displays offer unprecedented capabilities for virtual and augmented reality systems, including perceptually important focus cues. Although artificial intelligenceâ€“driven algorithms for computer-generated holography (CGH) have recently made much progress in improving the image quality and synthesis efficiency of holograms, these algorithms are not directly applicable to emerging phase-only spatial light modulators (SLM) that are extremely fast but offer phase control with very limited precision. The speed of these SLMs offers time multiplexing capabilities, essentially enabling partially-coherent holographic display modes. Here we report advances in camera-calibrated wave propagation models for these types of holographic near-eye displays and we develop a CGH framework that robustly optimizes the heavily quantized phase patterns of fast SLMs. Our framework is flexible in supporting runtime supervision with different types of content, including 2D and 2.5D RGBD images, 3D focal stacks, and 4D light fields. Using our framework, we demonstrate state-of-the-art results for all of these scenarios in simulation and experiment.\n\n{retrieved_text}\n\nGenerate exactly 48 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 48\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Adapting Texas Instruments DLP technology to demonstrate a phase spatial light modulator\",\n        \"Estimating or propagating gradients through stochastic neurons for conditional computation\",\n        \"Survey Of Holographic Stereograms\",\n        \"Convex optimization\",\n        \"Wirtinger Holography for Near-eye Displays\",\n        \"Learned hardware-in-the-loop phase retrieval for holographic near-eye displays\",\n        \"Toward the next-generation VR/AR optics: a review of holographic near-eye displays from a human-centric perspective\",\n        \"Multi-depth hologram generation using stochastic gradient descent algorithm with complex loss function\",\n        \"Improved layer-based method for rapid hologram generation and real-time interactive holographic display applications\",\n        \"Computer generated hologram with geometric occlusion using GPU-accelerated depth buffer rasterization for three-dimensional display\",\n        \"Neural 3D Holography: Learning Accurate Wave Propagation Models for 3D Holographic Virtual and Augmented Reality Displays\",\n        \"Optimizing image quality for holographic near-eye displays with michelson holography\",\n        \"Hierarchical multiscale recurrent neural networks\",\n        \"Phase retrieval algorithms: a comparison\",\n        \"A practical algorithm for the determination of phase from image and diffraction plane pictures\",\n        \"Holography Viewed from the Perspective of the Light Field Camera\",\n        \"Three-dimensional deeply generated holography\",\n        \"Deep-learning-generated holography\",\n        \"Computer-generated double-phase holograms\",\n        \"Retinal 3D: augmented reality near-eye display via pupil-tracked light field projection on retina\",\n        \"Categorical reparameterization with gumbel-softmax\",\n        \"Roadmap on digital holography\",\n        \"Accurate phase-added stereogram to improve the coherent stereogram\",\n        \"Learned holographic light transport\",\n        \"Diffraction efficiency characteristics for MEMS-based phase-only spatial light modulator with nonlinear phase distribution\",\n        \"Vision-correcting holographic display: evaluation of aberration correcting hologram\",\n        \"Holographic glasses for virtual reality\",\n        \"High-contrast, speckle-free, true 3D holography via binary CGH optimization\",\n        \"Sampled Fourier transform hologram generated by computer\",\n        \"Rendering interactive holographic images\",\n        \"The concrete distribution: A continuous relaxation of discrete random variables\",\n        \"Holographic near-eye displays for virtual and augmented reality\",\n        \"Holographic Optics for Thin and Lightweight Virtual Reality\",\n        \"Extremely high-definition full-parallax computer-generated hologram created by the polygon-based method\",\n        \"Holographic Near-eye Displays Based on Overlap-add Stereograms\",\n        \"Recent progress in computer-generated holography for three-dimensional scenes\",\n        \"Speckle-free holography with partially coherent light sources and camera-in-the-loop calibration\",\n        \"Neural holography with camera-in-the-loop training\",\n        \"Near-eye Light Field Holographic Rendering with Spherical Waves for Wide Field of View Interactive 3D Computer Graphics\",\n        \"Towards real-time photorealistic 3D holography with deep neural networks\",\n        \"Occlusion culling for computer generated hologram based on ray-wavefront conversion\",\n        \"State of the Art in Holographic Displays: A Survey\",\n        \"Optimization of computer-generated holograms featuring phase randomness control\",\n        \"Superspike: Supervised learning in multilayer spiking neural networks\",\n        \"Computer-generated hologram with occlusion effect using layer-based processing\",\n        \"Full parallax three-dimensional display with occlusion effect using computer generated hologram\",\n        \"Wigner distributions and how they relate to the light field\",\n        \"A Bidirectional Light Field-Hologram Transform\"\n    ],\n    \"reasoning\": \"Selected these 48 references because they represent foundational work and recent advances in Time-multiplexed Neural Holography: A Flexible Framework for Holographic Near-eye Displays with Fast Heavily-quantized Spatial Light Modulators, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}