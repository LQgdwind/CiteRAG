{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 268 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: From SLAM to Situational Awareness: Challenges and Survey\n\nPaper Abstract: Abstract The capability of a mobile robot to efficiently and safely perform complex missions is limited by its knowledge of the environment, namely the situation. Advanced reasoning, decision-making, and execution skills enable an intelligent agent to act autonomously in unknown environments. Situational Awareness (SA) is a fundamental capability of humans that has been deeply studied in various fields, such as psychology, military, aerospace, and education. Nevertheless, it has yet to be considered in robotics, which has focused on single compartmentalized concepts such as sensing, spatial perception, sensor fusion, state estimation, and Simultaneous Localization and Mapping (SLAM). Hence, the present research aims to connect the broad multidisciplinary existing knowledge to pave the way for a complete SA system for mobile robotics that we deem paramount for autonomy. To this aim, we define the principal components to structure a robotic SA and their area of competence. Accordingly, this paper investigates each aspect of SA, surveying the state-of-the-art robotics algorithms that cover them, and discusses their current limitations. Remarkably, essential aspects of SA are still immature since the current algorithmic development restricts their performance to only specific environments. Nevertheless, Artificial Intelligence (AI), particularly Deep Learning (DL), has brought new methods to bridge the gap that maintains these fields apart from the deployment to real-world scenarios. Furthermore, an opportunity has been discovered to interconnect the vastly fragmented space of robotic comprehension algorithms through the mechanism of Situational Graph (S-Graph), a generalization of the well-known scene graph. Therefore, we finally shape our vision for the future of robotic Situational Awareness by discussing interesting recent research directions.\n\n{retrieved_text}\n\nGenerate exactly 268 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 268\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Mobile robot control and navigation: A global overview\",\n        \"Advanced applications of industrial robotics: New trends and possibilities\",\n        \"Springer Handbook of Robotics\",\n        \"Introduction to autonomous mobile robots\",\n        \"Autonomous robots for harsh environments: a holistic overview of current solutions and ongoing challenges\",\n        \"Situational awareness\",\n        \"Toward a theory of situation awareness in dynamic systems\",\n        \"Situational awareness: Techniques, challenges, and prospects\",\n        \"A review of mobile robots: Concepts, methods, theoretical framework, and applications\",\n        \"Noise modeling and analysis of an imu-based attitude sensor: improvement of performance by filtering and sensor fusion\",\n        \"A stochastic approach to noise modeling for barometric altimeters\",\n        \"Precise Positioning of Uavs - Dealing with Challenging Rtk-Gps Measurement Conditions during Automated Uav Flights\",\n        \"Visual slam: What are the current trends and what to expect?\",\n        \"A 128× 128 120 db 15 micro-sec latency asynchronous temporal contrast vision sensor\",\n        \"A 240 × 180 130 db 3 µs latency global shutter spatiotemporal vision sensor\",\n        \"A qvga 143 db dynamic range frame-free pwm image sensor with lossless pixel-level video compression and time-domain cds\",\n        \"Event-based vision: A survey\",\n        \"Millimeter wave fmcw radars for perception, recognition and localization in automotive applications: A survey\",\n        \"A review of radio frequency based localisation for aerial and ground robots with 5g future perspectives\",\n        \"Papers with code\",\n        \"“Rapid object detection using a boosted cascade of simple features\",\n        \"“Object detection using scale invariant feature transform\",\n        \"“Image classification based on sift and svm\",\n        \"“Hog based fast human detection\",\n        \"“Monocular pedestrian detection: Survey and experiments\",\n        \"“Vision-based bicycle/motorcycle classification\",\n        \"“Distinctive image features from scale-invariant keypoints\",\n        \"“Surf: Speeded up robust features\",\n        \"“Histograms of oriented gradients for human detection\",\n        \"“Support vector machines\",\n        \"” in 2017 IEEE International Conference on Computer Vision (ICCV)\",\n        \"“Focal loss for dense object detection\",\n        \"“Tensormask: A foundation for dense object segmentation\",\n        \"“Scale-aware trident networks for object detection\",\n        \"“Yolov4: Optimal speed and accuracy of object detection\",\n        \"“Fully convolutional networks for semantic segmentation\",\n        \"“Encoder-decoder with atrous separable convolution for semantic image segmentation\",\n        \"“Pointrend: Image segmentation as rendering\",\n        \"“Fast-scnn: Fast semantic segmentation network\",\n        \"“Rethinking atrous convolution for semantic image segmentation\",\n        \"“Panoptic feature pyramid networks\",\n        \"“Panoptic-deeplab: A simple\",\n        \"“Scene graph generation by iterative message passing\",\n        \"“Bridging knowledge graphs to generate scene graphs\",\n        \"“Energy-based learning for scene graph generation\",\n        \"“Improved human detection and classification in thermal images\",\n        \"“Thermal object detection in difficult weather conditions using yolo\",\n        \"“Object detection using thermal imaging\",\n        \"“Event-based moving object detection and tracking\",\n        \"“Asynchronous convolutional networks for object detection in neuromorphic cameras\",\n        \"“Ev-segnet: Semantic segmentation for event-based cameras\",\n        \"“Pointnet: Deep learning on point sets for 3d classification and segmentation\",\n        \"“Frustum pointnets for 3d object detection from rgb-d data\",\n        \"“Contour-based object detection in range images\",\n        \"“Lidar-based 3d object perception\",\n        \"“Object detection and terrain classification in agricultural fields using 3d lidar data\",\n        \"“Rangenet ++: Fast and accurate lidar semantic segmentation\",\n        \"“Learning to segment 3d point clouds in 2d image space\",\n        \"“Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud\",\n        \"“Squeezesegv2: Improved model structure and unsupervised domain adaptation for road-object segmentation from a lidar point cloud\",\n        \"“Pointnet++: Deep hierarchical feature learning on point sets in a metric space\",\n        \"“Tangent convolutions for dense prediction in 3d\",\n        \"“Dops: Learning to detect 3d objects and predict their 3d shapes\",\n        \"“Randla-net: Efficient semantic segmentation of large-scale point clouds\",\n        \"“On-board object detection: Multicue\",\n        \"“Holistic scene understanding for 3d object detection with rgbd cameras\",\n        \"“Rgb-d object detection and semantic segmentation for autonomous manipulation in clutter\",\n        \"“Posecnn: A convolutional neural network for 6d object pose estimation in cluttered scenes\",\n        \"R. Martin-Martin\",\n        \"“Normalized object coordinate space for category-level 6d object pose and size estimation\",\n        \"“Multi-view fusion for multi-level robotic scene understanding\",\n        \"“Mfnet: Towards real-time semantic segmentation for autonomous vehicles with multi-spectral scenes\",\n        \"“Rtfnet: Rgb-thermal fusion network for semantic segmentation of urban scenes\",\n        \"“Pst900: Rgb-thermal calibration\",\n        \"“Fuseseg: Semantic segmentation of urban scenes based on rgb and thermal data fusion\",\n        \"“Issafe: Improving semantic segmentation in accidents by fusing event-based data\",\n        \"“Joint 3d proposal generation and object detection from view aggregation\",\n        \"“Deep continuous fusion for multi-sensor 3d object detection\",\n        \"“Multi-view 3d object detection network for autonomous driving\",\n        \"“Pointfusion: Deep sensor fusion for 3d bounding box estimation\",\n        \"“An introduction to multisensor data fusion\",\n        \"“Context-aware fusion of rgb and thermal imagery for traffic monitoring\",\n        \"“Ecffnet: Effective and consistent feature fusion network for rgb-t salient object detection\",\n        \"“Rgb-d and thermal sensor fusion-application in person tracking.” in VISIGRAPP (3: VISAPP)\",\n        \"“Tri-modal person re-identification with rgb\",\n        \"“Rgb-d-e: Event camera calibration for fast 6-dof object tracking\",\n        \"“Monte carlo localization for mobile robots\",\n        \"“Robust monte carlo localization for mobile robots\",\n        \"“Sensor data fusion using unscented kalman filter for accurate localization of mobile robots\",\n        \"“Mobile robot localization based on extended kalman filter\",\n        \"“Ekf-based localization of a wheeled mobile robot in structured environments\",\n        \"“Ekf based mobile robot localization\",\n        \"“Mobile robot localization using odometry and kinect sensor\",\n        \"“Dynamic ultrasonic hybrid localization system for indoor mobile robots\",\n        \"“A robust and modular multi-sensor fusion approach applied to mav navigation\",\n        \"V. Arellano-Quintana\",\n        \"“A generalized extended kalman filter implementation for the robot operating system\",\n        \"“Robust and precise vehicle localization based on multi-sensor fusion in diverse city scenes\",\n        \"“Slip-aware motion estimation for off-road mobile robots via multi-innovation unscented kalman filter\",\n        \"“Vehicle localization by sensor fusion of lrs measurement and odometry information based on moving horizon estimation\",\n        \"“Moving horizon estimation for mobile robots with multirate sampling\",\n        \"“Performance evaluation of a moving horizon estimator for multi-rate sensor fusion with time-delayed measurements\",\n        \"“A generic multi-sensor fusion scheme for localization of autonomous platforms using moving horizon estimation\",\n        \"“Fast 3d pose estimation with out-of-sequence measurements\",\n        \"“Square root sam: Simultaneous localization and mapping via square root information smoothing\",\n        \"“Factor graph based incremental smoothing in inertial navigation systems\",\n        \"“isam2: Incremental smoothing and mapping using the bayes tree\",\n        \"“Pose fusion with chain pose graphs for automated driving\",\n        \"“Sensor Fusion for Self-Localisation of Automated Vehicles\",\n        \"“Gomsf: Graph-optimization based multi-sensor fusion for robust uav pose estimation\",\n        \"“A general optimization-based framework for global pose estimation with multiple sensors\",\n        \"“Semi-tightly coupled integration of multi-GNSS PPP and S-VINS for precise positioning in GNSS-challenged environments\",\n        \"” IEEE Transactions on Robotics\",\n        \"“Globally consistent range scan alignment for environment mapping\",\n        \"“A computationally efficient method for large-scale concurrent mapping and localization\",\n        \"“Optimization of the simultaneous localization and map-building algorithm for real-time implementation\",\n        \"“Consistency of the ekf-slam algorithm\",\n        \"“Fastslam: An efficient solution to the simultaneous localization and mapping problem with unknown data association\",\n        \"“ORB-SLAM2: an open-source SLAM system for monocular\",\n        \"“Suma++: Efficient lidar-based semantic SLAM\",\n        \"“Graphical slam for outdoor applications\",\n        \"“Fast iterative alignment of pose graphs with poor initial estimates\",\n        \"“The graph slam algorithm with applications to large-scale mapping of urban structures\",\n        \"“Orb-slam: A versatile and accurate monocular slam system\",\n        \"“The new college vision and laser data set\",\n        \"“Direct sparse visual-inertial odometry using dynamic marginalization\",\n        \"“Ldso: Direct sparse odometry with loop closure\",\n        \"“A benchmark for the evaluation of rgb-d slam systems\",\n        \"“A photometrically calibrated benchmark for monocular visual odometry\",\n        \"“The euroc micro aerial vehicle datasets\",\n        \"“Are we ready for autonomous driving? the kitti vision benchmark suite\",\n        \"“Lsd-slam: Large-scale direct monocular slam\",\n        \"“Dpptam: Dense piecewise planar tracking and mapping from a monocular sequence\",\n        \"“Direct sparse mapping\",\n        \"“Loosely-coupled semi-direct monocular slam\",\n        \"“Magicvo: End-to-end monocular visual odometry through deep bi-directional recurrent convolutional neural network\",\n        \"“Deepvo: Towards end-to-end visual odometry with deep recurrent convolutional neural networks\",\n        \"“Orb-slam3: An accurate open-source library for visual\",\n        \"“The tum vi benchmark for evaluating visual-inertial odometry\",\n        \"“Online temporal calibration for monocular visual-inertial systems\",\n        \"“Svo: Semidirect visual odometry for monocular and multicamera systems\",\n        \"“A benchmark for rgb-d visual odometry\",\n        \"“Cpa-slam: Consistent plane-model alignment for direct rgb-d slam\",\n        \"“Real-time monocular object slam\",\n        \"“Quadricslam: Constrained dual quadrics from object detections as landmarks in semantic SLAM\",\n        \"“Cubeslam: Monocular 3d object detection and SLAM without prior models\",\n        \"“VDO-SLAM: A Visual Dynamic Object-aware SLAM System\",\n        \"“The oxford multimotion dataset: Multiple SE(3) motions with ground truth\",\n        \"“Kimera: an open-source library for real-time metric-semantic localization and mapping\",\n        \"“Real-time loop closure in 2d lidar slam\",\n        \"“Loam: Lidar odometry and mapping in real-time\",\n        \"“F-LOAM : Fast LiDAR odometry and mapping\",\n        \"“Efficient surfel-based slam using 3d laser range data in urban environments.” in Robotics: Science and Systems\",\n        \"“LIMO: lidar-monocular visual odometry\",\n        \"“A portable three-dimensional LIDAR-based system for long-term and wide-area people behavior measurement\",\n        \"“Lego-loam: Lightweight and ground-optimized lidar odometry and mapping on variable terrain\",\n        \"“Semantickitti: A dataset for semantic scene understanding of lidar sequences\",\n        \"“Ford campus vision and lidar data set\",\n        \"“Octomap: An efficient probabilistic 3d mapping framework based on octrees\",\n        \"“Voxblox: Incremental 3d euclidean signed distance fields for on-board MAV planning\",\n        \"“Voxgraph: Globally consistent\",\n        \"“Volumetric instance-aware semantic mapping and 3d object discovery\",\n        \"“iMAP: Implicit Mapping and Positioning in Real-Time\",\n        \"“Urban radiance fields\",\n        \"“Mega-nerf: Scalable construction of large-scale nerfs for virtual fly-throughs\",\n        \"“Elasticfusion: Dense slam without a pose graph.” Robotics: Science and Systems\",\n        \"“Surfelmeshing: Online surfel-based mesh reconstruction\",\n        \"“Real-time scalable dense surfel mapping\",\n        \"“3d scene graph: A structure for unified semantics\",\n        \"“Hydra: A real-time spatial perception system for 3d scene graph construction and optimization\",\n        \"“Remode: Probabilistic\",\n        \"“Semi-dense visual odometry for a monocular camera\",\n        \"“Svo: Fast semi-direct monocular visual odometry\",\n        \"“D3vo: Deep depth\",\n        \"“Initialization techniques for 3d slam: A survey on rotation estimation and its use in pose graph optimization\",\n        \"“Lift-slam: A deep-learning feature-based monocular visual slam method\",\n        \"“Rwt-slam: Robust visual slam for highly weak-textured environments\",\n        \"“Deep introspective slam: Deep reinforcement learning based approach to avoid tracking failure in visual slam\",\n        \"“Multi-objective location and mapping based on deep learning and visual slam\",\n        \"“Digging into self-supervised monocular depth estimation\",\n        \"“Unsupervised learning of depth and ego-motion from video\",\n        \"“UnDeepVO: Monocular Visual Odometry Through Unsupervised Deep Learning\",\n        \"“Continual slam: Beyond lifelong simultaneous localization and mapping through continual learning\",\n        \"“Deep online correction for monocular visual odometry\",\n        \"“Raum-vo: Rotational adjusted unsupervised monocular visual odometry\",\n        \"“Direct optimization of frame-to-frame rotation\",\n        \"“Keyframe-based visual–inertial odometry using nonlinear optimization\",\n        \"“Vins-mono: A robust and versatile monocular visual-inertial state estimator\",\n        \"“On-manifold preintegration for real-time visual–inertial odometry\",\n        \"“Visual-inertial mapping with non-linear factor recovery\",\n        \"“A benchmark comparison of monocular visual-inertial odometry algorithms for flying robots\",\n        \"“Keyframe-based direct thermal–inertial odometry\",\n        \"“Graph-based subterranean exploration path planning using aerial and legged robots\",\n        \"“Autonomous search for underground mine rescue using aerial robots\",\n        \"“Tp-tio: A robust thermal-inertial odometry with deep thermalpoint\",\n        \"“Graph-based thermal-inertial slam with probabilistic neural networks\",\n        \"“Continuous-time visual-inertial odometry for event cameras\",\n        \"T. Horstschaefer\",\n        \"“A flexible and scalable slam system with full 3d motion estimation\",\n        \"“Lvi-sam: Tightly-coupled lidar-visual-inertial odometry via smoothing and mapping\",\n        \"“Liro: Tightly coupled lidar-inertia-ranging odometry\",\n        \"“Viral slam: Tightly coupled camera-imu-uwb-lidar slam\",\n        \"“Lio-sam: Tightly-coupled lidar inertial odometry via smoothing and mapping\",\n        \"“Slam++: Simultaneous localisation and mapping at the level of objects\",\n        \"“Localization from semantic observations via the matrix permanent\",\n        \"“Probabilistic data association for semantic slam\",\n        \"“VSO: Visual Semantic Odometry\",\n        \"“Probabilistic data association via mixture models for robust semantic slam\",\n        \"“Vps-slam: Visual planar semantic slam for aerial robotic systems\",\n        \"M. Castillo-Lopez\",\n        \"“Sa-loam: Semantic-aided lidar slam with loop closure\",\n        \"“RDMO-SLAM: Real-time Visual SLAM for Dynamic Environments using Semantic Label Prediction with Optical Flow\",\n        \"“Semantic-rtab-map (srm): A semantic slam system with cnns on depth images\",\n        \"“3d semantic map construction system based on visual SLAM and CNNs\",\n        \"“An online semantic mapping system for extending and enhancing visual SLAM\",\n        \"“Semanticfusion: Dense 3d semantic mapping with convolutional neural networks\",\n        \"“Kimera-multi: Robust\",\n        \"“A computationally efficient semantic slam solution for dynamic scenes\",\n        \"“Dms-slam: A general visual slam system for dynamic scenes with multiple sensors\",\n        \"“Dp-slam: A visual slam with moving probability towards dynamic environments\",\n        \"“Signed distance fields: A natural representation for both mapping and planning\",\n        \"“Safe local exploration for replanning in cluttered unknown environments for microaerial vehicles\",\n        \"“Neural Unsigned Distance Fields for Implicit Function Learning\",\n        \"“FIESTA: Fast incremental euclidean distance fields for online motion planning of aerial robots\",\n        \"“Chomp: Covariant hamiltonian optimization for motion planning\",\n        \"“Freetures: Localization in signed distance function maps\",\n        \"“Voxfield: Non-projective signed distance fields for online planning and 3d reconstruction\",\n        \"“PanopticFusion: Online Volumetric Semantic Mapping at the Level of Stuff and Things\",\n        \"“Panoptic Multi-TSDFs: A Flexible Representation for Online Multi-resolution Volumetric Mapping and Long-term Dynamic Scene Consistency\",\n        \"“Scene representation networks: Continuous 3d-structure-aware neural scene representations\",\n        \"“Implicit Neural Representations with Periodic Activation Functions\",\n        \"“Nerf: Representing scenes as neural radiance fields for view synthesis\",\n        \"“Nicer-slam: Neural implicit scene encoding for rgb slam\",\n        \"“Nice-slam: Neural implicit scalable encoding for slam\",\n        \"“Nerf-slam: Real-time dense monocular slam with neural radiance fields\",\n        \"“Kimera: from slam to spatial perception with 3d dynamic scene graphs\",\n        \"“Learning 3d semantic scene graphs from 3d indoor reconstructions\",\n        \"“SceneGraphFusion: Incremental 3d scene graph prediction from RGB-d sequences\",\n        \"“3d dynamic scene graphs: Actionable spatial perception with places\",\n        \"“Hierarchical representations and explicit memory: Learning effective navigation policies on 3d scene graphs using graph neural networks\",\n        \"K. Jatavallabhula\",\n        \"J. Rodriguez-Puigvert\",\n        \"“A real-time approach for chance-constrained motion planning with dynamic obstacles\",\n        \"“Interaction-aware motion prediction for autonomous driving: A multiple model kalman filtering scheme\",\n        \"“Behavioral intention prediction in driving scenes: A survey\",\n        \"“Autonomous vehicles that interact with pedestrians: A survey of theory and practice\",\n        \"“Is it safe to drive? an overview of factors\",\n        \"“Social interactions for autonomous driving: A review and perspectives\",\n        \"“Pedestrian intention prediction based on dynamic fuzzy automata for vehicle driving at nighttime\",\n        \"“Driver lane change intention inference for intelligent vehicles: Framework\",\n        \"“Intention recognition of pedestrians and cyclists by 2d pose estimation\",\n        \"D. Fernandez-Llorca\",\n        \"“Multi-modal hybrid architecture for pedestrian action prediction\",\n        \"“Pedestrian graph +: A fast pedestrian crossing prediction model based on graph convolutional networks\",\n        \"“Is attention to bounding boxes all you need for pedestrian action prediction?” in 2022 IEEE Intelligent Vehicles Symposium (IV). IEEE\",\n        \"“Who make drivers stop? towards driver-centric risk assessment: Risk object identification via causal inference\",\n        \"“Carla: An open urban driving simulator\",\n        \"“Domain generalization: A survey\",\n        \"“Human motion trajectory prediction: A survey\",\n        \"“A Survey on Trajectory-Prediction Methods for Autonomous Driving\",\n        \"“Deep Learning-Based Vehicle Behavior Prediction for Autonomous Driving Applications: A Review\",\n        \"“A Literature Review on the Prediction of Pedestrian Behavior in Urban Scenarios\",\n        \"“A comprehensive survey of scene graphs: Generation and application\",\n        \"“Audio Visual Language Maps for Robot Navigation\",\n        \"“ConceptFusion: Open-set Multimodal 3D Mapping\",\n        \"R. Ticona-Herrera\",\n        \"“Situational graphs for robot navigation in structured indoor environments\",\n        \"“S-graphs+: Real-time localization and mapping leveraging hierarchical representations\"\n    ],\n    \"reasoning\": \"Selected these 268 references because they represent foundational work and recent advances in From SLAM to Situational Awareness: Challenges and Survey, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}