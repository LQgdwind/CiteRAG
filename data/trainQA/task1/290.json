{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 49 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: The STEM-ECR Dataset: Grounding Scientific Entity References in STEM Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources\n\nPaper Abstract: Abstract We introduce the STEM (Science, Technology, Engineering, and Medicine) Dataset for Scientific Entity Extraction, Classification, and Resolution, version 1.0 (STEM-ECR v1.0). The STEM-ECR v1.0 dataset has been developed to provide a benchmark for the evaluation of scientific entity extraction, classification, and resolution tasks in a domain-independent fashion. It comprises abstracts in 10 STEM disciplines that were found to be the most prolific ones on a major publishing platform. We describe the creation of such a multidisciplinary corpus and highlight the obtained findings in terms of the following features: 1) a generic conceptual formalism for scientific entities in a multidisciplinary scientific context; 2) the feasibility of the domain-independent human annotation of scientific entities under such a generic formalism; 3) a performance benchmark obtainable for automatic extraction of multidisciplinary scientific entities using BERT-based neural models; 4) a delineated 3-step entity resolution procedure for human annotation of the scientific entities via encyclopedic entity linking and lexicographic word sense disambiguation; and 5) human evaluations of Babelfy returned encyclopedic links and lexicographic senses for our entities. Our findings cumulatively indicate that human annotation and automatic learning of multidisciplinary scientific concepts as well as their semantic disambiguation in a wide-ranging setting as STEM is reasonable. Keywords: Entity Recognition, Entity Classification, Entity Resolution, Entity Linking, Word Sense Disambiguation, Evaluation Corpus, Language Resource\n\n{retrieved_text}\n\nGenerate exactly 49 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 49\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"The ai2 system at semeval-2017 task 10 (scienceie): semi-supervised end-to-end entity and relation extraction\",\n        \"Construction of the literature graph in semantic scholar\",\n        \"Dbpedia: A nucleus for a web of open data\",\n        \"Semeval 2017 task 10: Scienceie - extracting keyphrases and relations from scientific publications\",\n        \"Scibert: A pretrained language model for scientific text\",\n        \"Domain-independent extraction of scientific concepts from research articles\",\n        \"Using encyclopedic knowledge for named entity disambiguation\",\n        \"A coefficient of agreement for nominal scales\",\n        \"The document components ontology (doco)\",\n        \"Frame-based ontology population with pikes\",\n        \"Linking text and knowledge using the inception annotation platform\",\n        \"BERT: pre-training of deep bidirectional transformers for language understanding\",\n        \"WordNet: An Electronic Lexical Database\",\n        \"Tagme: on-the-fly annotation of short text fragments (by wikipedia entities)\",\n        \"A multi-layered annotated corpus of scientific papers\",\n        \"Semeval-2018 task 7: Semantic relation extraction and classification in scientific papers\",\n        \"Semantic web machine reading with fred\",\n        \"Allennlp: A deep semantic natural language processing platform\",\n        \"Entity resolution: theory, practice & open challenges\",\n        \"The acl rd-tec: a dataset for benchmarking terminology extraction and classification in computational linguistics\",\n        \"Collaboratively built semi-structured content and artificial intelligence: The story so far\",\n        \"Open research knowledge graph: Next generation infrastructure for semantic scholarly knowledge\",\n        \"Genia corpus–a semantically annotated corpus for bio-textmining\",\n        \"Semeval-2010 task 5: Automatic keyphrase extraction from scientific articles\",\n        \"The cassini enceladus encounters 2005–2010 in the view of energetic electron measurements\",\n        \"Corpora for the conceptualisation and zoning of scientific papers\",\n        \"Automatic recognition of conceptualization zones in scientific articles and two life science applications\",\n        \"Scientific information extraction with semi-supervised neural tagging\",\n        \"Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction\",\n        \"End-to-end sequence labeling via bi-directional lstm-cnns-crf\",\n        \"Dbpedia spotlight: shedding light on the web of documents\",\n        \"Wiktionary: A new rival for expert-built lexicons? exploring the possibilities of collaborative lexicography\",\n        \"Wikify!: linking documents to encyclopedic knowledge\",\n        \"Semeval-2015 task 13: Multilingual all-words sense disambiguation and entity linking\",\n        \"Multilingual Word Sense Disambiguation and Entity Linking for Everybody\",\n        \"Entity Linking meets Word Sense Disambiguation: a Unified Approach\",\n        \"Word sense disambiguation: A survey\",\n        \"A case study on inter-annotator agreement for word sense disambiguation\",\n        \"Scholarly ontology: modelling scholarly practices\",\n        \"Entity linking: Finding extracted entities in a knowledge base\",\n        \"Fine-grained evaluation for entity linking\",\n        \"Multiword expressions: A pain in the neck for nlp\",\n        \"Old is gold: linguistic driven approach for entity and relation linking of short text\",\n        \"Introducing the knowledge graph: Things, not strings\",\n        \"An ontology of scientific experiments\",\n        \"Brat: a web-based tool for nlp-assisted text annotation\",\n        \"An annotation scheme for discourse-level argumentation in research articles\",\n        \"Gerbil: general entity annotator benchmarking framework\",\n        \"Extracting lexical semantic knowledge from wikipedia and wiktionary\"\n    ],\n    \"reasoning\": \"Selected these 49 references because they represent foundational work and recent advances in The STEM-ECR Dataset: Grounding Scientific Entity References in STEM Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}