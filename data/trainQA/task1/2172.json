{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 55 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Backpropagation-Free Learning Method for Correlated Fuzzy Neural Networks\n\nPaper Abstract: Abstract In this paper, a novel stepwise learning approach based on estimating desired premise parts’ outputs by solving a constrained optimization problem is proposed. This learning approach does not require backpropagating the output error to learn the premise parts’ parameters. Instead, the near best output values of the rules premise parts are estimated and their parameters are changed to reduce the error between current premise parts’ outputs and the estimated desired ones. Therefore, the proposed learning method avoids error backpropagation, which lead to vanishing gradient and consequently getting stuck in a local optimum. The proposed method does not need any initialization method. This learning method is utilized to train a new Takagi-Sugeno-Kang (TSK) Fuzzy Neural Network with correlated fuzzy rules including many parameters in both premise and consequent parts, avoiding getting stuck in a local optimum due to vanishing gradient. To learn the proposed network parameters, first, a constrained optimization problem is introduced and solved to estimate the desired values of premise parts’ output values. Next, the error between these values and the current ones is utilized to adapt the premise parts’ parameters based on the gradient-descent (GD) approach. Afterward, the error between the desired and network’s outputs is used to learn consequent parts’ parameters by the GD method. The proposed paradigm is successfully applied to real-world time-series prediction and regression problems. According to experimental results, its performance outperforms other methods with a more parsimonious structure. Keywords: Takagi-Sugeno-Kang (TSK) Fuzzy Neural Networks, Correlated Fuzzy Rules, Constrained Optimization Problem, Gradient Descent, Nonlinear Function Approximation, Time-Series Prediction. The full version of this preprint is accepted for publication in Neurocomputing as: A. Salimi-Badr, M.M. Ebadzadeh, \"A novel learning algorithm based on computing the rules’ desired outputs of a TSK fuzzy neural network with non-separable fuzzy rules,\" Neurocomputing, vol. 470, pp. 139-153, 2022. DOI : 10.1016/j.neucom.2021.10.103\n\n{retrieved_text}\n\nGenerate exactly 55 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 55\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Simpl_ets: A simplified method for learning evolving takagi-sugeno fuzzy models\",\n        \"Cerebellum-inspired neural network solution of the inverse kinematics problem\",\n        \"It2-gsetsk: An evolving interval type-ii tsk fuzzy neural system for online modeling of noisy data\",\n        \"ANCFIS: A neurofuzzy architecture employing complex fuzzy sets\",\n        \"An evolving interval type-2 neurofuzzy inference system and its metacognitive sequential learning algorithm\",\n        \"SOFMLS: Online self-organizing fuzzy modified least-squares network\",\n        \"MSAFIS: an evolving fuzzy inference system\",\n        \"CFNN: correlated fuzzy neural network\",\n        \"IC-FNN: a novel fuzzy neural network with interpretable, intuitive, and correlated-contours fuzzy rules for function approximation\",\n        \"Fuzzy broad learning system: A novel neuro-fuzzy model for regression and classification\",\n        \"Support vector-based fuzzy classifier with adaptive kernel\",\n        \"A self-organizing fuzzy neural network based on a growing-and-pruning algorithm\",\n        \"Adaptive fuzzy neural network control for a constrained robot using impedance learning\",\n        \"A generalized growing and pruning RBF (GGAP-RBF) neural network for function approximation\",\n        \"Hybrid fuzzy wavelet neural networks architecture based on polynomial neural networks and fuzzy set/relation inference-based wavelet neurons\",\n        \"ANFIS: adaptive-network-based fuzzy inference system\",\n        \"A fuzzy system constructed by rule generation and iterative linear SVR for antecedent and consequent parameter optimization\",\n        \"A self-evolving interval type-2 fuzzy neural network with online structure and parameter learning\",\n        \"A function estimation approach to sequential learning with neural networks\",\n        \"Evolving fuzzy neural networks for supervised/unsupervised online knowledge-based learning\",\n        \"DENFIS: dynamic evolving neural-fuzzy inference system and its application for time-series prediction\",\n        \"A novel hybrid algorithm for creating self-organizing fuzzy neural networks\",\n        \"Fuzzy neural network with support vector-based learning for classification and regression\",\n        \"Multivariable gaussian evolving fuzzy modeling system\",\n        \"Design for self-organizing fuzzy neural networks based on genetic algorithms\",\n        \"A fast and accurate online sequential learning algorithm for feedforward networks\",\n        \"Adaptive neural network learning controller design for a class of nonlinear systems with time-varying state constraints\",\n        \"Brain dynamics in predicting driving fatigue using a recurrent self-evolving fuzzy neural network\",\n        \"Dynamical and static multisynchronization of coupled multistable neural networks via impulsive control\",\n        \"Three new fuzzy neural networks learning algorithms based on clustering, training error and genetic algorithm\",\n        \"Application of fuzzy logic to approximate reasoning using linguistic synthesis\",\n        \"Evaluation of peak and residual conditions of actively confined concrete using neuro-fuzzy and neural computing techniques\",\n        \"Gsetsk: a generic self-evolving tsk fuzzy neural network with a novel hebbian-based rule reduction approach\",\n        \"A resource-allocating network for function interpolation\",\n        \"PANFIS: A novel incremental learning machine\",\n        \"GENEFIS: Toward an effective localist network\",\n        \"An expert system for predicting longitudinal dispersion coefficient in natural streams by using ANFIS\",\n        \"Online sequential fuzzy extreme learning machine for function approximation and classification problems\",\n        \"Anfis system for classification of brain signals\",\n        \"Fuzzy neuronal model of motor control inspired by cerebellar pathways to online and gradually learn inverse biomechanical functions in the presence of delay\",\n        \"A novel self-organizing fuzzy neural network to learn and mimic habitual sequential tasks\",\n        \"Mixed h-infinity and passive filtering for discrete fuzzy neural networks with stochastic jumps and time delays\",\n        \"Structure identification of fuzzy model\",\n        \"Fuzzy neural network control of a flexible robotic manipulator using assumed mode method\",\n        \"Fuzzy identification of systems and its applications to modeling and control\",\n        \"Nonlinear system identification by gustafson–kessel fuzzy clustering and supervised local model network learning for the drug absorption spectra process\",\n        \"eT2fis: An evolving type-2 neural fuzzy inference system\",\n        \"A fast and accurate online self-organizing scheme for parsimonious fuzzy neural networks\",\n        \"A comparative study on sufficient conditions for takagi-sugeno fuzzy systems as universal approximators\",\n        \"Anfis construction with sparse data via group rule interpolation\",\n        \"General SISO takagi-sugeno fuzzy systems with linear rule consequent are universal approximators\",\n        \"Performance evaluation of a sequential minimal radial basis function (RBF) neural network learning algorithm\",\n        \"Extended robust exponential stability of fuzzy switched memristive inertial neural networks with time-varying delays on mode-dependent destabilizing impulsive control protocol\",\n        \"The concept of a linguistic variable and its application to approximate reasoning\",\n        \"Nonlinear decoupling control with anfis-based unmodeled dynamics compensation for a class of complex industrial processes\"\n    ],\n    \"reasoning\": \"Selected these 55 references because they represent foundational work and recent advances in Backpropagation-Free Learning Method for Correlated Fuzzy Neural Networks, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}