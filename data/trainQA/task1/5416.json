{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 47 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Rule Mining over Knowledge Graphs via Reinforcement Learning\n\nPaper Abstract: Abstract Knowledge graphs (KGs) are an important source repository for a wide range of applications and rule mining from KGs recently attracts wide research interest in the KG-related research community. Many solutions have been proposed for the rule mining from large-scale KGs, which however are limited in the inefficiency of rule generation and ineffectiveness of rule evaluation. To solve these problems, in this paper we propose a generation-then-evaluation rule mining approach guided by reinforcement learning. Specifically, a two-phased framework is designed. The first phase aims to train a reinforcement learning agent for rule generation from KGs, and the second is to utilize the value function of the agent to guide the step-by-step rule generation. We conduct extensive experiments on several datasets and the results prove that our rule mining solution achieves state-of-the-art performance in terms of efficiency and effectiveness.\n\n{retrieved_text}\n\nGenerate exactly 47 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 47\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Freebase: a collaboratively created graph database for structuring human knowledge\",\n        \"Dbpedia: A nucleus for a web of open data\",\n        \"Wikidata: a free collaborative knowledgebase\",\n        \"Adrl: An attention-based deep reinforcement learning framework for knowledge graph reasoning\",\n        \"Multi-modal knowledge-aware reinforcement learning network for explainable recommendation\",\n        \"Fast rule mining in ontological knowledge bases with amie+\",\n        \"Mining semantic association rules from rdf data\",\n        \"Arm–amo: An efficient association rule mining algorithm based on animal migration optimization\",\n        \"Scalable rule learning via learning representation.\",\n        \"Fast and exact rule mining with amie 3\",\n        \"Playing atari with deep reinforcement learning\",\n        \"Mastering the game of go without human knowledge\",\n        \"Deep reinforcement learning for transportation network combinatorial optimization: A survey\",\n        \"Translating embeddings for modeling multi-relational data\",\n        \"Reasoning with neural tensor networks for knowledge base completion\",\n        \"Embedding entities and relations for learning and inference in knowledge bases\",\n        \"Compositional vector space models for knowledge base completion\",\n        \"Learning rules from incomplete kgs using embeddings\",\n        \"Curriculum learning\",\n        \"Scalekb: scalable learning and inference over large knowledge bases\",\n        \"Rotate: Knowledge graph embedding by relational rotation in complex space\",\n        \"Long short-term memory\",\n        \"An introduction to mcmc for machine learning\",\n        \"Svm-boosting based on markov resampling: Theory and algorithm\",\n        \"Learning performance of weighted distributed learning with support vector machines\",\n        \"Reinforcement learning: An introduction\",\n        \"Deterministic policy gradient algorithms\",\n        \"Horizon: Facebook’s open source applied reinforcement learning platform\",\n        \"Amie: association rule mining under incomplete evidence in ontological knowledge bases\",\n        \"Yago: a core of semantic knowledge\",\n        \"Robust discovery of positive and negative rules in knowledge bases\",\n        \"Reinforced anytime bottom up rule learning for knowledge graph completion\",\n        \"An embedding-based approach to rule learning in knowledge graphs\",\n        \"Canonical tensor decomposition for knowledge base completion\",\n        \"Tucker: Tensor factorization for knowledge graph completion\",\n        \"Rnnlogic: Learning logic rules for reasoning on knowledge graphs\",\n        \"Rule-aware reinforcement learning for knowledge graph reasoning\",\n        \"Differentiable learning of logical rules for knowledge base reasoning\",\n        \"Drum: End-to-end differentiable rule mining on knowledge graphs\",\n        \"Learn to explain efficiently via neural logic inductive learning\",\n        \"Towards learning instantiated logical rules from knowledge graphs\",\n        \"Modeling relational data with graph convolutional networks\",\n        \"Joint entity linking with deep reinforcement learning\",\n        \"Automated curriculum learning for neural networks\",\n        \"Intrinsic motivation and automatic curricula via asymmetric self-play\",\n        \"Automatic goal generation for reinforcement learning agents\",\n        \"Unsupervised curricula for visual meta-reinforcement learning\"\n    ],\n    \"reasoning\": \"Selected these 47 references because they represent foundational work and recent advances in Rule Mining over Knowledge Graphs via Reinforcement Learning, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}