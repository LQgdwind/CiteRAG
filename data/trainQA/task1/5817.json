{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 237 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Enabling High-Performance and Energy-Efficient Hybrid Transactional/Analytical Databases with Hardware/Software Cooperation\n\nPaper Abstract: Abstract A growth in data volume, combined with increasing demand for real-time analysis (using the most recent data), has resulted in the emergence of database systems that concurrently support transactions and data analytics. These hybrid transactional and analytical processing (HTAP) database systems can support real-time data analysis without the high costs of synchronizing across separate single-purpose databases. Unfortunately, for many applications that perform a high rate of data updates, state-of-the-art HTAP systems incur significant losses in transactional (up to 74.6%) and/or analytical (up to 49.8%) throughput compared to performing only transactional or only analytical queries in isolation, due to (1) data movement between the CPU and memory, (2) data update propagation from transactional to analytical workloads, and (3) the cost to maintain a consistent view of data across the system. \\Copy CR1/1AWe propose Polynesia, a hardwareâ€“software co-designed system for in-memory HTAP databases that avoids the large throughput losses of traditional HTAP systems. Polynesia (1) divides the HTAP system into transactional and analytical processing islands, (2) implements new custom hardware that unlocks software optimizations to reduce the costs of update propagation and consistency, and (3) exploits processing-in-memory for the analytical islands to alleviate data movement overheads. Our evaluation shows that Polynesia outperforms three state-of-the-art HTAP systems, with average transactional/analytical throughput improvements of 1.7Ã—\\times/3.7Ã—\\times, and reduces energy consumption by 48% over the prior lowest-energy HTAP system.\n\n{retrieved_text}\n\nGenerate exactly 237 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 237\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Cisco Global Cloud Index: Forecast and Methodology, 2016-2021\",\n        \"TitAnt: Online Real-Time Transaction Fraud Detection in Ant Financial\",\n        \"Real-Time Constrained Cycle Detection in Large Dynamic Graphs\",\n        \"Real-Time Credit Card Fraud Detection Using Computational Intelligence\",\n        \"Real-Time Analytical Processing with SQL Server\",\n        \"SnappyData: Streaming, Transactions, and Interactive Analytics in a Unified Engine\",\n        \"Real Time Business Intelligence in Supply Chain Analytics\",\n        \"Adopting Medical Technologies and Diagnostics Recommended by NICE: The Health Technologies Adoption Programme\",\n        \"Big Data Stream Computing in Healthcare Real-Time Analytics\",\n        \"WiSer: A Highly Available HTAP DBMS for IoT Applications\",\n        \"Kunpeng: Parameter Server Based Distributed Learning Systems and Its Applications in Alibaba and Ant Financial\",\n        \"TiDB: A Raft-Based HTAP Database\",\n        \"Hybrid Transaction/Analytical Processing Will Foster Opportunities for Dramatic Business Innovation\",\n        \"SAP HANA: The Evolution from a Modern Main-Memory Data Platform to an Enterprise Application Platform\",\n        \"Hybrid OLTP and OLAP\",\n        \"Bridging the Archipelago Between Row-Stores and Column-Stores for Hybrid Workloads\",\n        \"BatchDB: Efficient Isolated Execution of Hybrid OLTP+OLAP Workloads for Interactive Applications\",\n        \"Hybrid Transactional/Analytical Processing: A Survey\",\n        \"CoNDA: Efficient Cache Coherence Support for Near-Data Accelerators\",\n        \"LazyPIM: An Efficient Cache Coherence Mechanism for Processing-in-Memory\",\n        \"Practical Mechanisms for Reducing Processor-Memory Data Movement in Modern Workloads\",\n        \"A Modern Primer on Processing in Memory\",\n        \"Processing Data Where It Makes Sense: Enabling In-Memory Computation\",\n        \"Processing-in-Memory: A Workload-Driven Perspective\",\n        \"Cellular Logic-in-Memory Arrays\",\n        \"A Logic-in-Memory Computer\",\n        \"EXECUBE: A New Architecture for Scaleable MPPs\",\n        \"Processing in Memory: The Terasys Massively Parallel PIM Array\",\n        \"A Case for Intelligent RAM\",\n        \"Active Pages: A Computation Model for Intelligent Memory\",\n        \"The Architecture of the DIVA Processing-in-Memory Chip\",\n        \"Ambit: In-Memory Accelerator for Bulk Bitwise Operations Using Commodity DRAM Technology\",\n        \"Buddy-RAM: Improving the Performance and Efficiency of Bulk Bitwise Operations Using DRAM\",\n        \"RowClone: Fast and Energy-Efficient In-DRAM Bulk Data Copy and Initialization\",\n        \"RowClone: Accelerating Data Movement and Initialization Using DRAM\",\n        \"GraphidDe: A Graph Processing Accelerator Leveraging In-DRAM-Computing\",\n        \"The DRAM Latency PUF: Quickly Evaluating Physical Unclonable Functions by Exploiting the Latencyâ€“Reliability Tradeoff in Modern DRAM Devices\",\n        \"D-RaNGe: Using Commodity DRAM Devices to Generate True Random Numbers with Low Latency and High Throughput\",\n        \"Low-Cost Inter-Linked Subarrays (LISA): Enabling Fast Inter-Subarray Data Movement in DRAM\",\n        \"SIMDRAM: A Framework for Bit-Serial SIMD Processing Using DRAM\",\n        \"NoM: Network-on-Memory for Inter-Bank Data Transfer in Highly-Banked Memories\",\n        \"FIGARO: Improving System Performance via Fine-Grained In-DRAM Data Relocation and Caching\",\n        \"SynCron: Efficient Synchronization Support for Near-Data-Processing Architectures\",\n        \"NATSA: A Near-Data Processing Accelerator for Time Series Analysis\",\n        \"Accelerating Genome Analysis: A Primer on an Ongoing Journey\",\n        \"GenASM: A High-Performance, Low-Power Approximate String Matching Acceleration Framework for Genome Sequence Analysis\",\n        \"GRIM-Filter: Fast Seed Filtering in Read Mapping Using Emerging Memory Technologies\",\n        \"GRIM-Filter: Fast Seed Location Filtering in DNA Read Mapping Using Processing-in-Memory Technologies\",\n        \"PIM-Enabled Instructions: A Low-Overhead, Locality-Aware Processing-in-Memory Architecture\",\n        \"A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing\",\n        \"â€œGoogle Workloads for Consumer Devices: Mitigating Data Movement Bottlenecks\",\n        \"â€œLazyPIM: Efficient Support for Cache Coherence in Processing-in-Memory Architectures\",\n        \"â€œNAPEL: Near-Memory Computing Application Performance Prediction via Ensemble Learning\",\n        \"â€œJAFAR: Near-Data Processing for Databases\",\n        \"â€œNDA: Near-DRAM Acceleration Architecture Leveraging Commodity DRAM Devices and Standard Memory Modules\",\n        \"â€œPractical Near-Data Processing for In-Memory Analytics Frameworks\",\n        \"â€œHRL: Efficient and Flexible Reconfigurable Logic for Near-Data Processing\",\n        \"â€œBiscuit: A Framework for Near-Data Processing of Big Data Workloads\",\n        \"â€œ3D-Stacked Memory-Side Acceleration: Accelerator and System Design\",\n        \"â€œAccelerating Dependent Cache Misses with an Enhanced Memory Controller\",\n        \"â€œContinuous Runahead: Transparent Hardware Acceleration for Memory Intensive Workloads\",\n        \"â€œTransparent Offloading and Mapping (TOM): Enabling Programmer-Transparent Near-Data Processing in GPU Systems\",\n        \"â€œNeuroCube: A Programmable Digital Neuromorphic Architecture with High-Density 3D Memory\",\n        \"â€œToward Standardized Near-Data Processing with Unrestricted Data Placement for GPUs\",\n        \"â€œBSSync: Processing Near Memory for Machine Learning Workloads with Bounded Staleness Consistency Models\",\n        \"â€œConcurrent Data Structures for Near-Memory Computing\",\n        \"â€œGP-SIMD Processing-in-Memory\",\n        \"â€œGraphPIM: Enabling Instruction-Level PIM Offloading in Graph Computing Frameworks\",\n        \"â€œScheduling Techniques for GPU Architectures with Processing-in-Memory Capabilities\",\n        \"â€œNDC: Analyzing the Impact of 3D-Stacked Memory+Logic Devices on MapReduce Workloads\",\n        \"â€œTOP-PIM: Throughput-Oriented Programmable Processing in Memory\",\n        \"â€œAccelerating Sparse Matrix-Matrix Multiplication with 3D-Stacked Logic-in-Memory Hardware\",\n        \"â€œData Reorganization in Memory Using 3D-Stacked DRAM\",\n        \"â€œTETRIS: Scalable and Efficient Neural Network Acceleration with 3D Memory\",\n        \"â€œThe Mondrian Data Engine\",\n        \"â€œGraphH: A Processing-in-Memory Architecture for Large-Scale Graph Processing\",\n        \"â€œGraphP: Reducing Communication for PIM-Based Graph Processing with Efficient Data Partition\",\n        \"â€œA Heterogeneous PIM Hardware-Software Co-Design for Energy-Efficient Graph Processing\",\n        \"â€œGraphQ: Scalable PIM-Based Graph Processing\",\n        \"â€œOperand Size Reconfiguration for Big Data Processing in Memory\",\n        \"â€œA Workload and Programming Ease Driven Perspective of Processing-in-Memory\",\n        \"â€œSISA: Set-Centric Instruction Set Architecture for Graph Mining on Processing-in-Memory Systems\",\n        \"â€œpLUTo: In-DRAM Lookup Tables to Enable Massively Parallel General-Purpose Computation\",\n        \"â€œQUAC-TRNG: High-Throughput True Random Number Generation Using Quadruple Row Activation in Commodity DRAMs\",\n        \"â€œIn-Memory Data Rearrangement for Irregular\",\n        \"â€œComputational RAM: Implementing Processors in Memory\",\n        \"â€œCombining Emulation and Simulation to Evaluate a Near Memory Key/Value Lookup Accelerator\",\n        \"â€œTowards a Scatter-Gather Architecture: Hardware and Software Issues\",\n        \"â€œNear Memory Key/Value Lookup Acceleration\",\n        \"â€œNear Memory Data Structure Rearrangement\",\n        \"â€œActive Memory Cube: A Processing-in-Memory Architecture for Exascale Systems\",\n        \"â€œExploring the Processing-in-Memory Paradigm for Future Computing Systems (Fall 2021)\",\n        \"â€œPiDRAM: A Holistic End-to-End FPGA-Based Framework for Processing-in-DRAM\",\n        \"16Gb/s/Pin GDDR6-Based Accelerator-in-Memory Supporting 1TFLOPS MAC Operation and Various Activation Functions for Deep-Learning Applications\",\n        \"â€œNear-Memory Processing in Action: Accelerating Personalized Recommendation with AxDIMM\",\n        \"â€œ25.4 A 20nm 6GB Function-In-Memory DRAM\",\n        \"â€œHardware Architecture and Software Stack for PIM Based on Commercial DRAM Technology: Industrial Product\",\n        \"â€œEnabling Fast and Energy-Efficient FM-Index Exact Matching Using Processing-Near-Memory\",\n        \"â€œFPGA-Based Near-Memory Acceleration of Modern Data-Intensive Applications\",\n        \"â€œAccelerating Weather Prediction Using Near-Memory Reconfigurable Fabric\",\n        \"â€œDAMOV: A New Methodology and Benchmark Suite for Evaluating Data Movement Bottlenecks\",\n        \"â€œGoogle Neural Network Models for Edge Devices: Analyzing and Mitigating Machine Learning Inference Bottlenecks\",\n        \"â€œCasper: Accelerating Stencil Computation Using Near-Cache Processing\",\n        \"â€œGenStore: A High-Performance and Energy-Efficient In-Storage Computing System for Genome Sequence Analysis\",\n        \"â€œNIM: An HMC-Based Machine for Neuron Computation\",\n        \"â€œ184QPS/W 64Mb/mâ€‹m2ğ‘šsuperscriptğ‘š2mm^{2} 3D Logic-to-DRAM Hybrid Bonding with Process-Near-Memory Engine for Recommendation System\",\n        \"â€œThe True Processing in Memory Accelerator\",\n        \"â€œBenchmarking a New Paradigm: An Experimental Analysis of a Real Processing-in-Memory Architecture\",\n        \"â€œBenchmarking Memory-Centric Computing Systems: Analysis of Real Processing-in-Memory Hardware\",\n        \"â€œMythic â€” Power-Efficient AI Acceleration for the Edge\",\n        \"â€œHMC Specification 2.0\",\n        \"â€œSimultaneous Multi-Layer Access: Improving 3D-Stacked Memory Bandwidth at Low Cost\",\n        \"â€œHyPer: A Hybrid OLTP&OLAP Main Memory Database System Based on Virtual Memory Snapshots\",\n        \"â€œAccelerating Analytical Processing in MVCC Using Fine-Granular High-Frequency Virtual Snapshotting\",\n        \"â€œPolynesia â€” GitHub Repository\",\n        \"â€œThe SAP HANA Database â€“ An Architecture Overview\",\n        \"â€œOracle Database In-Memory: A Dual Format In-Memory Database\",\n        \"â€œTowards Scalable Real-Time Analytics: An Architecture for Scale-Out of OLxP Workloads\",\n        \"â€œHYRISE: A Main Memory Hybrid Storage Engine\",\n        \"â€œThe Case For Heterogeneous HTAP\",\n        \"â€œL-Store: A Real-Time OLTP and OLAP System\",\n        \"â€œScyPer: A Hybrid OLTP and OLAP Distributed Main Memory Database System for Scalable Real-Time Analytics\",\n        \"â€œJanus: A Hybrid Scalable Multi-Representation Cloud Datastore\",\n        \"â€œJanus: Transaction Processing of Navigation and Analytic Graph Queries on Many-Core Servers\",\n        \"â€œParallel Replication across Formats in SAP HANA for Scaling Out Mixed OLTP/OLAP Workloads\",\n        \"The Relational Model for Database Management: Version 2. Addison-Wesley\",\n        \"â€œThe Notions of Consistency and Predicate Locks in a Database System\",\n        \"â€œVirtual Lightweight Snapshots for Consistent Analytics in NoSQL Stores\",\n        \"â€œFast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems\",\n        \"â€œA Critique of ANSI SQL Isolation Levels\",\n        \"â€œSerializable Isolation for Snapshot Databases\",\n        \"â€œA Comparison of the Use of Virtual Versus Physical Snapshots for Supporting Update-Intensive Workloads\",\n        \"â€œH-Store: A High-Performance\",\n        \"â€œA Decomposition Storage Model\",\n        \"â€œC-Store: A Column-oriented DBMS\",\n        \"â€œMISE: Providing Performance Predictability and Improving Fairness in Shared Main Memory Systems\",\n        \"â€œApplication-to-Core Mapping Policies to Reduce Memory System Interference in Multi-Core Systems\",\n        \"â€œStall-Time Fair Memory Access Scheduling for Chip Multiprocessors\",\n        \"â€œParallelism-Aware Batch Scheduling: Enhancing Both Performance and Fairness of Shared DRAM Systems\",\n        \"â€œReducing Memory Interference in Multicore Systems via Application-Aware Memory Channel Partitioning\",\n        \"â€œFairness via Source Throttling: A Configurable and High-Performance Fairness Substrate for Multi-Core Memory Systems\",\n        \"â€œMemory Scaling: A Systems Architecture Perspective\",\n        \"â€œResearch Problems and Opportunities in Memory Systems\",\n        \"â€œMain Memory Scaling: Challenges and Solution Directions\",\n        \"â€œThe Application Slowdown Model: Quantifying and Controlling the Impact of Inter-Application Interference at Shared Caches and Main Memory\",\n        \"â€œProviding High and Controllable Performance in Multicore Systems Through Shared Resource Management\",\n        \"â€œATLAS: A Scalable and High-Performance Scheduling Algorithm for Multiple Memory Controllers\",\n        \"â€œThread Cluster Memory Scheduling: Exploiting Differences in Memory Access Behavior\",\n        \"â€œMemory Performance Attacks: Denial of Memory Service in Multi-Core Systems\",\n        \"â€œDASH: Deadline-Aware High-Performance Memory Scheduler for Heterogeneous Systems With Hardware Accelerators\",\n        \"â€œBLISS: Balancing Performance\",\n        \"â€œDecoupled Direct Memory Access: Isolating CPU and IO Traffic by Leveraging a Dual-Data-Port DRAM\",\n        \"â€œStaged Memory Scheduling: Achieving High Performance and Scalability in Heterogeneous Systems\",\n        \"â€œKilo-NOC: A Heterogeneous Network-on-Chip Architecture for Scalability and Service Guarantees\",\n        \"â€œFair Queuing Memory Systems\",\n        \"â€œMulticore Resource Management\",\n        \"â€œMultiversion Concurrency Controlâ€”Theory and Algorithms\",\n        \"â€œScaling Up Concurrent Main-Memory Column-Store Scans: Towards Adaptive NUMA-Aware Data and Task Placement\",\n        \"â€œDictionary-Based Order-Preserving String Compression for Main Memory Column Stores\",\n        \"â€œSpeeding Up Queries in Column Stores: A Case for Compression\",\n        \"â€œStaring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores\",\n        \"â€œMorsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age\",\n        \"â€œFast Updates on Read-Optimized Databases Using Multi-Core CPUs\",\n        \"â€œDatabase Compression on Graphics Processors\",\n        \"â€œFixed-Function Hardware Sorting Accelerators for Near Data MapReduce Execution\",\n        \"â€œQ100: The Architecture and Design of a Database Processing Unit\",\n        \"â€œMaterialization Strategies in a Column-Oriented DBMS\",\n        \"â€œHardware Acceleration for Memory to Memory Copies\",\n        \"â€œComputeDRAM: In-Memory Compute Using Off-the-Shelf DRAMs\",\n        \"â€œIn-DRAM Bulk Bitwise Execution Engine\",\n        \"â€œEncapsulation of Parallelism in the Volcano Query Processing System\",\n        \"â€œEfficiently Compiling Efficient Query Plans for Modern Hardware\",\n        \"â€œQTM: Modelling Query Execution With Tasks\",\n        \"â€œBeyond the Wall: Near-Data Processing for Databases\",\n        \"â€œJESD235B: High Bandwidth Memory (HBM) DRAM\",\n        \"â€œA Logic-Base Interconnect for Supporting Near Memory Computation in the Hybrid Memory Cube\",\n        \"â€œPerformance Implications of NoCs on 3D-Stacked Memories: Insights from the Hybrid Memory Cube\",\n        \"â€œThere and Back Again: Optimizing the Interconnect in Networks of Memory Cubes\",\n        \"â€œLogic-Base Interconnect Design for Near Memory Computing in the Smart Memory Cube\",\n        \"â€œHigh Performance AXI-4.0 Based Interconnect for Extensible Smart Memory Cubes\",\n        \"â€œA Comparison of Receiver-Initiated and Sender-Initiated Adaptive Load Sharing\",\n        \"â€ https://cloud.google.com/tpu\",\n        \"â€œTen Lessons from Three Generations Shaped Googleâ€™s TPUv4i: Industrial Product\",\n        \"â€œHabana Labs Purpose-Built AI Inference and Training Processor Architectures: Scaling AI Training Systems Using Standard Ethernet with Gaudi Processor\",\n        \"â€œAWS Trainium - Amazon Web Services (AWS)\",\n        \"â€œWarehouse-Scale Video Acceleration: Co-Design and Deployment in the Wild\",\n        \"â€œImproved Cloud Service Performance Through ASIC Acceleration\",\n        \"â€œAquabolt-XL: Samsung HBM2-PIM with In-Memory Processing for ML Accelerators and Beyond\",\n        \"â€œASIC Clouds: Specializing the Datacenter\",\n        \"â€ https://github.com/yxymit/DBx1000\",\n        \"â€œThe gem5 Simulator\",\n        \"â€ https://developer.arm.com/ip-products/processors/cortex-a/cortex-a7\",\n        \"â€œNear-Memory Address Translation\",\n        \"â€œA Low-Overhead Coherence Solution for Multiprocessors with Private Cache Memories\",\n        \"â€œA New Solution to Coherence Problems in Multicache Systems\",\n        \"â€œMEG: A RISCV-Based System Emulation Infrastructure for Near-Data Processing Using FPGAs and High-Bandwidth Memory\",\n        \"â€œTask Scheduling for Highly Concurrent Analytical and Transactional Main-Memory Workloads\",\n        \"â€œScaling Up Mixed Workloads: A Battle of Data Freshness\",\n        \"â€œAdaptive HTAP Through Elastic Resource Scheduling\",\n        \"â€œHekaton: SQL Serverâ€™s Memory-Optimized OLTP Engine\",\n        \"â€œTicToc: Time Traveling Optimistic Concurrency Control\",\n        \"â€œTaurus: Lightweight Parallel Logging for In-Memory Database Management Systems\",\n        \"â€œSundial: Harmonizing Concurrency Control and Caching in a Distributed OLTP Database Management System\",\n        \"â€œAccelerating Pointer Chasing in 3D-Stacked Memory: Challenges\",\n        \"â€œThe Volcano Optimizer Generator: Extensibility and Efficient Search\",\n        \"â€œMonetDB/X100: Hyper-Pipelining Query Execution\",\n        \"â€œCompiling Database Queries into Machine Code\",\n        \"â€œLecture Notes for Data Processing On Modern Hardware â€“ Lecture 3: Cache Awareness for Query Execution Models\",\n        \"â€œTPC-C Benchmark\",\n        \"â€œTPC-H Benchmark\",\n        \"â€œTPC-H Analyzed: Hidden Messages and Lessons Learned from an Influential Benchmark\",\n        \"â€œRunahead Execution: An Alternative to Very Large Instruction Windows for Out-of-Order Processors\",\n        \"â€œA Case for MLP-Aware Cache Replacement\",\n        \"â€œEfficient Runahead Execution: Power-Efficient Memory Latency Tolerance\",\n        \"â€œTechniques for Efficient Processing in Runahead Execution Engines\",\n        \"â€œMicroarchitecture Optimizations for Exploiting Memory-Level Parallelism\",\n        \"â€œScalable Cache Miss Handling for High Memory-Level Parallelism\",\n        \"â€œImproving Memory Bank-Level Parallelism in the Presence of Prefetching\",\n        \"â€œMemory-Centric System Interconnect Design with Hybrid Memory Cubes\",\n        \"â€œHybrid Memory Cube New DRAM Architecture Increases Density and Performance\",\n        \"â€œOptimizing NUCA Organizations and Wiring Alternatives for Large Caches with CACTI 6.0\",\n        \"â€œCatapult High-Level Synthesis\",\n        \"â€œA Comparison of Intelâ€™s 32nm and 22nm Core i5 CPUs: Power\",\n        \"â€œPerformance Characterization of HTAP Workloads\",\n        \"â€œOracle GoldenGate 12c: Real-Time Access to Real-Time Information\",\n        \"â€œMeet the Walkers: Accelerating Index Traversals for In-Memory Databases\",\n        \"â€œNavigating Big Data with High-Throughput\",\n        \"â€œSort vs. Hash Join Revisited for Near-Memory Execution\",\n        \"â€œProcessing-in-Memory Enabled Graphics Processors for 3D Rendering\",\n        \"â€œCAIRO: A Compiler-Assisted Technique for Enabling Instruction-Level Offloading of Processing-in-Memory\",\n        \"â€œAdaptive Scheduling for Systems with Asymmetric Memory Hierarchies\",\n        \"â€œ3D-Stacked Many-Core Architecture for Biological Sequence Analysis Problems\",\n        \"â€œProcessing in 3D Memories to Speed Up Operations on Complex Data Structures\",\n        \"â€œNear-Data Processing: Insights from a MICRO-46 Workshop\",\n        \"â€œHAMLeT: Hardware Accelerated Memory Layout Transform within 3D-Stacked DRAM\",\n        \"â€œ3D-Stacked Memory Architectures for Multi-Core Processors\",\n        \"â€œHIPE: HMC Instruction Predication Extension Applied on Database Processing\"\n    ],\n    \"reasoning\": \"Selected these 237 references because they represent foundational work and recent advances in Enabling High-Performance and Energy-Efficient Hybrid Transactional/Analytical Databases with Hardware/Software Cooperation, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}