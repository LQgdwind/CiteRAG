{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 297 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Ethical and social risks of harm from Language Models\n\nPaper Abstract: \n\n{retrieved_text}\n\nGenerate exactly 297 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 297\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Deep Learning with Differential Privacy\",\n        \"Anti-Muslim Bias in GPT-3\",\n        \"Persistent Anti-Muslim Bias in Large Language Models\",\n        \"Artificial Intelligence, Automation and Work\",\n        \"MasakhaNER: Named Entity Recognition for African Languages\",\n        \"Physiognomy’s New Clothes\",\n        \"WES: Agent-based User Interaction Simulation on Real Infrastructure\",\n        \"The Illustrated Transformer\",\n        \"Trends in the diffusion of misinformation on social media\",\n        \"The Panopticon Is Already Here\",\n        \"Machine Bias\",\n        \"Thinking Inside the Box: Controlling and Using an Oracle AI\",\n        \"New Frontiers: The Evolving Content and Geography of New Work in the 20th Century - David Autor\",\n        \"Stochastic modeling for automatic speech understanding\",\n        \"Big Data’s Disparate Impact\",\n        \"Fairness and machine learning\",\n        \"Analysis Methods in Neural Language Processing: A Survey\",\n        \"The #BenderRule: On Naming the Languages We Study and Why It Matters\",\n        \"On Achieving and Evaluating Language-Independence in NLP\",\n        \"Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science\",\n        \"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data\",\n        \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\",\n        \"Neural net language models\",\n        \"Race After Technology: Abolitionist Tools for the New Jim Code\",\n        \"‘I’d Blush if I Could’: Digital Assistants, Disembodied Cyborgs and the Problem of Gender\",\n        \"Patient and Consumer Safety Risks When Using Conversational Assistants for Medical Information: An Observational Study of Siri, Alexa, and Google Assistant\",\n        \"Racial Disparity in Natural Language Processing: A Case Study of Social Media African-American English\",\n        \"Demographic Dialectal Variation in Social Media: A Case Study of African-American English\",\n        \"Language (Technology) is Power: A Critical Survey of \\\"Bias\\\" in NLP\",\n        \"Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets\",\n        \"Secrecy and Openness in Science: Ethical Considerations\",\n        \"On the Opportunities and Risks of Foundation Models\",\n        \"Superintelligence: paths, dangers, strategies\",\n        \"Information hazards: A typology of potential harms from knowledge\",\n        \"Sorting Things Out: Classification and Its Consequences\",\n        \"GPT-3 Creative Fiction, June 2020\",\n        \"Infant-like Social Interactions between a Robot and a Human Caregiver\",\n        \"Language Models are Few-Shot Learners\",\n        \"Dark Matters\",\n        \"Truth, Lies, and Truth, Lies, and Automation: How Language Models Could Change DisinformationAutomation: How Language Models Could Change Disinformation\",\n        \"Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification\",\n        \"Semantics derived automatically from language corpora contain human-like biases\",\n        \"Toward Gender-Inclusive Coreference Resolution\",\n        \"The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks\",\n        \"Extracting Training Data from Large Language Models\",\n        \"Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets\",\n        \"The Whiteness of AI\",\n        \"Conversational Assistants and Gender Stereotypes: Public Perceptions and Desiderata for Voice Personas\",\n        \"Evaluating Large Language Models Trained on Code\",\n        \"Synthetic data in machine learning for medicine and healthcare\",\n        \"The Frontiers of Fairness in Machine Learning\",\n        \"Echo Chamber or Public Sphere? Predicting Political Orientation and Measuring Political Homophily in Twitter Using Big Data\",\n        \"GitHub Copilot · Your AI pair programmer, 2021\",\n        \"“Explaining” machine learning reveals policy challenges\",\n        \"Language and Discrimination: Generating Meaning, Perceiving Identities, and Discriminating Outcomes\",\n        \"Atlas of AI\",\n        \"On Intersectionality: Essential Writings\",\n        \"Behind the One-Way Mirror: A Deep Dive Into the Technology of Corporate Surveillance\",\n        \"GPT-3: What’s it good for?\",\n        \"Amazon scraps secret AI recruiting tool that showed bias against women\",\n        \"Fair Hate Speech Detection through Evaluation of Social Group Counterfactuals\",\n        \"Bringing the People Back In: Contesting Benchmark Machine Learning Datasets\",\n        \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n        \"Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms\",\n        \"Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling\",\n        \"Measuring and Mitigating Unintended Bias in Text Classification\",\n        \"Korean app-maker Scatter Lab fined for using private data to create homophobic and lewd chatbot\",\n        \"Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus\",\n        \"Towards A Rigorous Science of Interpretable Machine Learning\",\n        \"Doxing: a conceptual analysis\",\n        \"Online Harassment 2017\",\n        \"Disentangling polarisation and civic empowerment in the digital age : The role of filter bubbles and echo chambers in the rise of populism\",\n        \"Calibrating Noise to Sensitivity in Private Data Analysis\",\n        \"DeepMind AI Reduces Google Data Centre Cooling Bill by 40%, July 2016\",\n        \"Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity\",\n        \"Discovering and Categorising Language Biases in Reddit\",\n        \"The Effects of Culturally Congruent Educational Technologies on Student Achievement\",\n        \"Fake news infiltrates financial markets\",\n        \"A Survey on Automatic Detection of Hate Speech in Text\",\n        \"Discipline and punish: the birth of the prison\",\n        \"Artificial Intelligence, Values, and Alignment\",\n        \"DeepMind x UCL | Deep Learning Lectures: Responsible Innovation, July 2020b\",\n        \"The Challenge of Value Alignment: from Fairer Algorithms to AI Safety\",\n        \"Collective aspects of privacy in the Twitter social network\",\n        \"Counterfactual Fairness in Text Classification through Robustness\",\n        \"Datasheets for Datasets\",\n        \"RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models\",\n        \"What happened to jobs at high risk of automation?\",\n        \"GPT-3 Contains Disturbing Bias Against Muslims, January 2021\",\n        \"The algorithms that detect hate speech online are biased against black people\",\n        \"Bias Mitigated Learning from Differentially Private Synthetic Data: A Cautionary Tale\",\n        \"Predicting Alcoholism Recovery from Twitter\",\n        \"Algorithmic content moderation: Technical and political challenges in the automation of platform governance\",\n        \"Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass\",\n        \"XAI—Explainable artificial intelligence\",\n        \"Black Feminist Musings on Algorithmic Oppression\",\n        \"Parasite and catalyst: the polarizing influence of chatbots in political discourse\",\n        \"Epistemic values in feature importance methods: Lessons from feminist epistemology\",\n        \"How AI Is Learning to Identify Toxic Online Content\",\n        \"Situated knowledges: The science question in feminism and the privilege of partial perspective\",\n        \"The Haraway Reader\",\n        \"Feminism and Methodology: Social Science Issues\",\n        \"Equality of Opportunity in Supervised Learning\",\n        \"Excessive use of online video streaming services: Impact of recommender system use, psychological factors, and motives\",\n        \"DeBERTa: Decoding-enhanced BERT with Disentangled Attention\",\n        \"Aligning AI With Shared Human Values\",\n        \"Toward an Afrocentric Feminist Epistemology\",\n        \"FCC Net Neutrality Online Public Comments Contain Many Inaccuracies and Duplicates\",\n        \"Google’s ’Verse by Verse’ AI can help you write in the style of famous poets\",\n        \"The Curious Case of Neural Text Degeneration\",\n        \"The Social Impact of Natural Language Processing\",\n        \"The Importance of Modeling Social Factors of Language: Theory and Practice\",\n        \"Universal Language Model Fine-tuning for Text Classification\",\n        \"Transformer Poetry\",\n        \"Reducing Sentiment Bias in Language Models via Counterfactual Evaluation\",\n        \"Tay, Microsoft’s AI chatbot, gets a crash course in racism from Twitter\",\n        \"China ’employs 2 million to police internet’\",\n        \"Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure\",\n        \"It Sounds Like A Woman: Exploring Gender Stereotypes in South Korean Voice Assistants\",\n        \"How rising inequality hurts everyone, even the rich\",\n        \"Privacy concerns in chatbot interactions\",\n        \"Rising Income Inequality: Technology, or Trade and Financial Globalization?\",\n        \"Automatic Detection of Machine Generated Text: A Critical Survey\",\n        \"Continuous speech recognition by statistical methods\",\n        \"Pride and Prejudiced: On the Reclamation of Slurs\",\n        \"Unintended Bias and Identity Terms, October 2021\",\n        \"Lessons from archives: strategies for collecting sociocultural data in machine learning\",\n        \"How to stop data centres from gobbling up the world’s electricity\",\n        \"The State and Fate of Linguistic Diversity and Inclusion in the NLP World\",\n        \"Speech and language processing\",\n        \"Reasons, Values, Stakeholders: A Philosophical Framework for Explainable Artificial Intelligence\",\n        \"Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly\",\n        \"Alignment of Language Agents\",\n        \"The Misgendering Machines: Trans/HCI Implications of Automatic Gender Recognition\",\n        \"A Distributional Approach to Controlled Text Generation\",\n        \"Chatbot Gone Awry Starts Conversations About AI Ethics in South Korea\",\n        \"Intersectional Bias in Hate Speech and Abusive Language Datasets\",\n        \"Anthropomorphism of computers: Is it mindful or mindless?\",\n        \"Offensive, aggressive, and hate speech analysis: From data-centric to human-centered approach\",\n        \"Racial disparities in automated speech recognition\",\n        \"Eddie Murphy and the Dangers of Counterfactual Causal Thinking About Detecting Racial Discrimination\",\n        \"Algorithmic bias: review, synthesis, and future research directions\",\n        \"Private traits and attributes are predictable from digital records of human behavior\",\n        \"Misinformation Dissemination in Twitter in the COVID-19 Era\",\n        \"Measuring Bias in Contextualized Word Representations\",\n        \"Unspeaking on Facebook? Testing network effects on self-censorship of political expressions in social network sites\",\n        \"Duplicate and fake publications in the scientific literature: how many SCIgen papers in computer science?\",\n        \"Giving GPT-3 a Turing Test, July 2020\",\n        \"How Robots Change the World - What automation really means for jobs, productivity and regions\",\n        \"How Bots Broke the FCC’s Public Comment System\",\n        \"Pitfalls of Static Language Modelling\",\n        \"Media Manipulation and Disinformation Online\",\n        \"Gender stereotypes are reflected in the distributional structure of 25 languages\",\n        \"Deal or No Deal? End-to-End Learning for Negotiation Dialogues\",\n        \"Question and Answer Test-Train Overlap in Open-Domain Question Answering Datasets\",\n        \"TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models\",\n        \"Racial mirroring effects on human-agent interaction in psychotherapeutic conversations\",\n        \"TruthfulQA: Measuring How Models Mimic Human Falsehoods\",\n        \"Explainable AI: A Review of Machine Learning Interpretability Methods\",\n        \"English with an Accent: Language, Ideology and Discrimination in the United States\",\n        \"The Mythos of Model Interpretability: In machine learning, the concept of interpretability is both important and slippery\",\n        \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\",\n        \"Doxing is a toxic practice – no matter who is targeted | Media@LSE, August 2017\",\n        \"What’s in the Box? A Preliminary Analysis of Undesirable Content in the Common Crawl Corpus\",\n        \"Gender and Representation Bias in GPT-3 Generated Stories\",\n        \"Epistemic Relativism\",\n        \"The role of language in the persistence of stereotypes\",\n        \"Predicting political preference of Twitter users\",\n        \"The role of social media in sex education: Dispatches from queer, trans, and racialized communities:\",\n        \"Can Conversing with a Computer Increase Turnout? Mobilization Using Chatbot Communication\",\n        \"Loose tweets: an analysis of privacy leaks on twitter\",\n        \"On the importance of ethnographic methods in AI research\",\n        \"The Racial Formation of Chatbots\",\n        \"Essai d’une recherche statistique sur le texte du roman “eugène oněgin”, illustrant la liaison des épreuves en chaîne\",\n        \"Participatory Problem Formulation for Fairer Machine Learning Through Community Based System Dynamics\",\n        \"The Radicalization Risks of GPT-3 and Advanced Neural Language Models\",\n        \"Understanding Human Impressions of Artificial Intelligence\",\n        \"A Survey on Bias and Fairness in Machine Learning\",\n        \"Recommender systems and their ethical challenges\",\n        \"Explanation in Artificial Intelligence: Insights from the Social Sciences\",\n        \"Smartphone-Based Conversational Agents and Responses to Questions About Mental Health, Interpersonal Violence, and Physical Health\",\n        \"Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence\",\n        \"Facilitating benign deceit in mediated communication\",\n        \"Providing Adaptive Health Updates Across the Personal Social Network\",\n        \"Predicting age groups of Twitter users based on language and metadata features\",\n        \"Ethical Considerations in AI-Based Recruitment\",\n        \"DeepMind’s Lila Ibrahim: ‘It’s hard not to go through imposter syndrome’\",\n        \"Data centre water consumption\",\n        \"Do not blame it on the algorithm: an empirical assessment of multiple recommender systems and their impact on content diversity\",\n        \"StereoSet: Measuring stereotypical bias in pretrained language models\",\n        \"CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models\",\n        \"How to Recognize AI Snake Oil, January 2021\",\n        \"How Old Do You Think I Am?\\\" A Study of Language and Age in Twitter\",\n        \"Synthetic Data for Deep Learning, volume 174 of Springer Optimization and Its Applications\",\n        \"Workshop on NLP for Positive Impact at ACL-IJCNLP, 2021\",\n        \"Algorithms of Oppression\",\n        \"HONEST: Measuring Hurtful Sentence Completion in Language Models\",\n        \"Dissecting racial bias in an algorithm used to manage the health of populations\",\n        \"Interpreters and Translators: Occupational Outlook Handbook\",\n        \"Misinformation in action: Fake news exposure is linked to lower trust in media, higher trust in government when your side is in power\",\n        \"Online censors are a barrier to sex education, 2016\",\n        \"Down the (White) Rabbit Hole: The Extreme Right and Online Recommender Systems\",\n        \"People + AI Guidebook\",\n        \"The Emotional Chatbots Are Here to Probe Our Feelings\",\n        \"Automatic personality assessment through social media language\",\n        \"The Black Box Society\",\n        \"Carbon Emissions and Large Neural Network Training\",\n        \"Conversational Agents and Natural Language Interaction: Techniques and Effective Practices\",\n        \"Social Media and Democracy: The State of the Field, Prospects for Reform\",\n        \"Perspective API | Developers, 2021\",\n        \"UNKs Everywhere: Adapting Multilingual Language Models to New Scripts\",\n        \"GPT-3 Powers the Next Generation of Apps, March 2021\",\n        \"Beyond Binary Labels: Political Ideology Prediction of Twitter Users\",\n        \"Our Twitter Profiles, Our Selves: Predicting Personality with Twitter\",\n        \"Improving Language Understanding by Generative Pre-Training\",\n        \"Language Models are Unsupervised Multitask Learners\",\n        \"Scaling language models: Methods, analysis & insights from training Gopher\",\n        \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\",\n        \"Handle with Care: Lessons for Data Science from Black Female Scholars\",\n        \"Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing\",\n        \"Training Production Language Models without Memorizing User Data\",\n        \"Generating Fake Cyber Threat Intelligence Using Transformer-Based Models\",\n        \"Reclaiming Queer: Activist & Academic Rhetorics of Resistance\",\n        \"Could NLG systems injure or even kill people?, October 2020\",\n        \"Patent-Busting: The Public Patent Foundation, Gene Patents and the Seed Wars\",\n        \"A group of YouTubers is claiming the site systematically demonetizes queer content\",\n        \"Unsettling race and language: Toward a raciolinguistic perspective\",\n        \"Turing-NLG: A 17-billion-parameter language model by Microsoft, February 2020\",\n        \"Agency Laundering and Algorithmic Decision Systems\",\n        \"Why You Should Do NLP Beyond English, August 2020\",\n        \"Teaching GPT-3 to Identify Nonsense, July 2020\",\n        \"Secrecy and National Security Investigations\",\n        \"Toward responsible AI for the next billion users\",\n        \"Re-imagining Algorithmic Fairness in India and Beyond\",\n        \"The Risk of Racial Bias in Hate Speech Detection\",\n        \"The Law and Ethics of Trade Secrets: A Case Study\",\n        \"A Survey on Hate Speech Detection using Natural Language Processing\",\n        \"The ethics of nudging: An overview\",\n        \"Bots Are Destroying Political Discourse As We Know It\",\n        \"How AI is getting better at detecting hate speech, November 2020\",\n        \"Green AI\",\n        \"Tackling threats to informed decision-making in democratic societies\",\n        \"Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview\",\n        \"Social Media Surveillance\",\n        \"A mathematical theory of communication\",\n        \"Societal Biases in Language Generation: Progress and Challenges\",\n        \"Participation is not a Design Fix for Machine Learning\",\n        \"Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets\",\n        \"Release Strategies and the Social Impacts of Language Models\",\n        \"Language modelling’s generative model: is it rational?\",\n        \"Political Discourse Analysis: A Case Study of Code Mixing and Code Switching in Political Speeches\",\n        \"Indiscriminate mass surveillance and the public sphere\",\n        \"The Stanford Natural Language Processing Group, 2021\",\n        \"Who’s driving innovation\",\n        \"Developing a framework for responsible innovation\",\n        \"Energy and Policy Considerations for Deep Learning in NLP\",\n        \"Race and epistemologies of ignorance\",\n        \"Fiction by Neil Gaiman and Terry Pratchett by GPT-3, July 2020\",\n        \"Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models\",\n        \"The impact of climate change and the social cost of carbon\",\n        \"Fairness for Unobserved Characteristics: Insights from Technological Impacts on Queer Communities\",\n        \"More Time on Technology, Less Happiness? Associations Between Digital-Media Use and Psychological Well-Being\",\n        \"Chatbot advertising effectiveness: When does the message get through?\",\n        \"Publishers withdraw more than 120 gibberish papers\",\n        \"Attention is All you Need\",\n        \"Verse by Verse, 2020\",\n        \"The invention of AI ‘gaydar’ could be the start of something much worse\",\n        \"The Right to Explanation\",\n        \"Privacy matters because it empowers us all | Aeon Essays\",\n        \"Does GPT-2 Know Your Phone Number?, December 2020\",\n        \"Directional Bias Amplification\",\n        \"Superglue: A stickier benchmark for general-purpose language understanding systems\",\n        \"Deep neural networks are more accurate than humans at detecting sexual orientation from facial images\",\n        \"Systematic Literature Review on the Spread of Health-related Misinformation on Social Media\",\n        \"Towards Zero-Label Language Learning\",\n        \"The Impact of Artificial Intelligence on the Labor Market\",\n        \"Challenges in Detoxifying Language Models\",\n        \"A Network-based End-to-End Trainable Task-oriented Dialogue System\",\n        \"I’d blush if I could : closing gender divides in digital skills through education\",\n        \"Language Models are Few-shot Multilingual Learners\",\n        \"Do Artifacts Have Politics?\",\n        \"Detoxifying Language Models Risks Marginalizing Minority Voices\",\n        \"Censorship of Online Encyclopedias: Implications for NLP Models\",\n        \"XLNet: Generalized Autoregressive Pretraining for Language Understanding\",\n        \"Image Cropping on Twitter: Fairness Metrics, their Limitations, and the Importance of Representation, Design, and Agency\",\n        \"A systematic review: The YouTube recommender system and pathways to problematic content\",\n        \"Computer-based personality judgments are more accurate than those made by humans\",\n        \"“Just Roll Your Mouse Over Me”: Designing Virtual Women for Customer Service on the Web\",\n        \"Defending Against Neural Fake News\",\n        \"A Survey On Universal Adversarial Attack\",\n        \"Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners\",\n        \"Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints\",\n        \"Gender Bias in Contextualized Word Embeddings\",\n        \"Calibrate Before Use: Improving Few-Shot Performance of Language Models\",\n        \"AI can be sexist and racist — it’s time to make it fair\",\n        \"The age of surveillance capitalism: the fight for a human future at the new frontier of power\",\n        \"Anthropomorphism: Opportunities and Challenges in Human–Robot Interaction\"\n    ],\n    \"reasoning\": \"Selected these 297 references because they represent foundational work and recent advances in Ethical and social risks of harm from Language Models, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}