{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 46 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: TSC-PCAC: Voxel Transformer and Sparse Convolution Based Point Cloud Attribute Compression for 3D Broadcasting\n\nPaper Abstract: Abstract Point cloud has been the mainstream representation for advanced 3D applications, such as virtual reality and augmented reality. However, the massive data amounts of point clouds is one of the most challenging issues for transmission and storage. In this paper, we propose an end-to-end voxel Transformer and Sparse Convolution based Point Cloud Attribute Compression (TSC-PCAC) for 3D broadcasting. Firstly, we present a framework of the TSC-PCAC, which include Transformer and Sparse Convolutional Module (TSCM) based variational autoencoder and channel context module. Secondly, we propose a two-stage TSCM, where the first stage focuses on modeling local dependencies and feature representations of the point clouds, and the second stage captures global features through spatial and channel pooling encompassing larger receptive fields. This module effectively extracts global and local inter-point relevance to reduce informational redundancy. Thirdly, we design a TSCM based channel context module to exploit inter-channel correlations, which improves the predicted probability distribution of quantized latent representations and thus reduces the bitrate. Experimental results indicate that the proposed TSC-PCAC method achieves an average of 38.53%, 21.30%, and 11.19% Bjøntegaard Delta bitrate reductions compared to the Sparse-PCAC, NF-PCAC, and G-PCC v23 methods, respectively. The encoding/decoding time costs are reduced up to 97.68%/98.78% on average compared to the Sparse-PCAC. The source code and the trained models of the TSC-PCAC are available at https://github.com/igizuxo/TSC-PCAC.\n\n{retrieved_text}\n\nGenerate exactly 46 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 46\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"G-PCC codec description v2\",\n        \"Video-based and hierarchical approaches point cloud compression\",\n        \"Learned image compression with mixed transformer-cnn architectures\",\n        \"3d point cloud geometry compression on deep learning\",\n        \"Point cloud geometry compression via neural graph sampling\",\n        \"Multiscale point cloud geometry compression\",\n        \"Pcgformer: Lossy point cloud geometry compression via local self-attention\",\n        \"Lossy point cloud geometry compression via end-to-end learning\",\n        \"Lossless point cloud attribute compression using cross-scale, cross-group, and cross-color prediction\",\n        \"Lossless point cloud geometry and attribute compression using a learned conditional probability model\",\n        \"Deep-pcac: An end-to-end deep lossy compression framework for point cloud attributes\",\n        \"Sparse tensor-based point cloud attribute compression\",\n        \"3dac: Learning attribute compression for point clouds\",\n        \"Nf-pcac: Normalizing flow based point cloud attribute compression\",\n        \"Compression of 3d point clouds using a region-adaptive hierarchical transform\",\n        \"Compression of sparse and dense dynamic point clouds—methods and standards\",\n        \"An overview of ongoing point cloud compression standardization activities: Video-based (v-pcc) and geometry-based (g-pcc)\",\n        \"A comparative measurement study of point cloud-based volumetric video codecs\",\n        \"Multi-resolution intra-predictive coding of 3d point cloud attributes\",\n        \"Point cloud compression based on joint optimization of graph transform and entropy coding for efficient data broadcasting\",\n        \"Perceptually weighted rate distortion optimization for video-based point cloud compression\",\n        \"Subjective quality database and objective study of compressed point clouds with 6dof head-mounted display\",\n        \"Mfe-net: A multi-layer feature extraction network for no-reference quality assessment of 3-d point clouds\",\n        \"Deep learning based just noticeable difference and perceptual quality prediction models for compressed video\",\n        \"Gqe-net: a graph-based quality enhancement network for point cloud color attribute\",\n        \"Variational image compression with a scale hyperprior\",\n        \"Joint graph attention and asymmetric convolutional neural network for deep image compression\",\n        \"The devil is in the details: Window-based attention for image compression\",\n        \"Channel-wise autoregressive entropy models for learned image compression\",\n        \"Joint autoregressive and hierarchical priors for learned image compression\",\n        \"Efficient hierarchical entropy model for learned point cloud compression\",\n        \"Inception-v4, inception-resnet and the impact of residual connections on learning\",\n        \"Inter-frame compression for dynamic point cloud geometry coding\",\n        \"Scalable point cloud attribute compression\",\n        \"Pointnet++: Deep hierarchical feature learning on point sets in a metric space\",\n        \"4d spatio-temporal convnets: Minkowski convolutional neural networks\",\n        \"Codedvtr: Codebook-based sparse voxel transformer with geometric guidance\",\n        \"Pnp-3d: A plug-and-play for 3d point clouds\",\n        \"Common test conditions for point cloud compression\",\n        \"Updates and Integration of Evaluation Metric Software for PCC\",\n        \"Calculation of average PSNR differences between RD-curves\",\n        \"8i Voxelized Full Bodies-a Voxelized Point Cloud Dataset\",\n        \"Owlii Dynamic human mesh sequence dataset\",\n        \"8i Voxelized Surface Light Field (8iVSLF) Dataset\",\n        \"Volograms & V-SENSE Volumetric Video Dataset\",\n        \"Microsoft Voxelized Upper Bodies-a Voxelized Point Cloud Dataset\"\n    ],\n    \"reasoning\": \"Selected these 46 references because they represent foundational work and recent advances in TSC-PCAC: Voxel Transformer and Sparse Convolution Based Point Cloud Attribute Compression for 3D Broadcasting, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}