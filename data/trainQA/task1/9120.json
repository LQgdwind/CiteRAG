{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 52 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: A Domain-Independent Agent Architecture for Adaptive Operation in Evolving Open Worlds\n\nPaper Abstract: Abstract Model-based reasoning agents are ill-equipped to act in novel situations in which their model of the environment no longer sufficiently represents the world. We propose HYDRA - a framework for designing model-based agents operating in mixed discrete-continuous worlds, that can autonomously detect when the environment has evolved from its canonical setup, understand how it has evolved, and adapt the agents’ models to perform effectively. HYDRA is based upon PDDL+, a rich modeling language for planning in mixed, discrete-continuous environments. It augments the planning module with visual reasoning, task selection, and action execution modules for closed-loop interaction with complex environments. HYDRA implements a novel meta-reasoning process that enables the agent to monitor its own behavior from a variety of aspects. The process employs a diverse set of computational methods to maintain expectations about the agent’s own behavior in an environment. Divergences from those expectations are useful in detecting when the environment has evolved and identifying opportunities to adapt the underlying models. HYDRA builds upon ideas from diagnosis and repair and uses a heuristics-guided search over model changes such that they become competent in novel conditions. The HYDRA framework has been used to implement novelty-aware agents for three diverse domains - CartPole++ (a higher dimension variant of a classic control problem), Science Birds (an IJCAI competition problem111Angry Birds Competition), and PogoStick (a specific problem domain in Minecraft222Minecraft). We report empirical observations from these domains to demonstrate the efficacy of various components in the novelty meta-reasoning process.\n\n{retrieved_text}\n\nGenerate exactly 52 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 52\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Simultaneous debugging of software faults\",\n        \"Learning action models with minimal observability\",\n        \"A comprehensive framework for learning declarative action models\",\n        \"A review of learning planning action models\",\n        \"An extensible framework for customizable model repair\",\n        \"Towards automatic state recovery for replanning\",\n        \"Plan repair in hybrid planning\",\n        \"Maintaining evolving domain models\",\n        \"Plan explanations as model reconciliation–an empirical study\",\n        \"Plan explanations as model reconciliation: Moving beyond explanation as soliloquy\",\n        \"Model repair for markov decision processes\",\n        \"Evolution of the icarus cognitive architecture\",\n        \"Generalised domain model acquisition from action traces\",\n        \"Acquiring planning domain models using locm\",\n        \"Replanning: A new perspective\",\n        \"Fundamentals of model-based diagnosis\",\n        \"Diagnosing multiple faults\",\n        \"Updating action domain descriptions\",\n        \"An artificial intelligence paradigm for troubleshooting software bugs\",\n        \"Efficient model-based diagnosis of sequential circuits\",\n        \"Plan stability: Replanning versus plan repair.\",\n        \"Modelling mixed discrete-continuous domains for planning\",\n        \"Reflecting on planning models: A challenge for self-modeling systems\",\n        \"The belief-desire-intention model of agency\",\n        \"Repair suggestions for planning domains with missing actions effects\",\n        \"Val: Automatic plan validation, continuous effects and mixed initiative planning using pddl\",\n        \"Safe learning of lifted action models\",\n        \"Learning probably approximately complete and safe action models for stochastic worlds\",\n        \"Designing artificial intelligence for open worlds\",\n        \"Domain-independent multi-agent plan repair\",\n        \"The Soar cognitive architecture\",\n        \"Open-World Learning for Radically Autonomous Agents\",\n        \"An integrated architecture for online adaptation to novelty in open worlds using probabilistic programming and novelty-aware planning\",\n        \"Model-based diagnosis: A frequency domain view\",\n        \"Playing atari with deep reinforcement learning\",\n        \"Discoverhistory: Understanding the past in planning and execution\",\n        \"A novelty-centric agent architecture for changing worlds\",\n        \"Cpef: A continuous planning and execution framework\",\n        \"Differential assessment of black-box ai agents\",\n        \"Plan reuse versus plan generation: A theoretical and empirical analysis\",\n        \"On the diagnosis of cyber-physical production systems\",\n        \"Model-based development of automation systems\",\n        \"Learning behavior models for hybrid timed systems\",\n        \"A greedy approach for the efficient repair of stochastic models\",\n        \"Efficient, safe, and probably approximately complete learning of action models\",\n        \"A framework for model-based repair\",\n        \"An architecture for novelty handling in a multi-agent stochastic environment: Case study in open-world monopoly\",\n        \"On exploiting hitting sets for model reconciliation\",\n        \"Learning action models from plan examples using weighted MAX-SAT\",\n        \"Meaningful update and repair of markov decision processes for self-adaptive systems\",\n        \"Action-model acquisition from noisy plan traces\",\n        \"Refining incomplete planning domain models through plan traces\"\n    ],\n    \"reasoning\": \"Selected these 52 references because they represent foundational work and recent advances in A Domain-Independent Agent Architecture for Adaptive Operation in Evolving Open Worlds, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}