{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 59 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: What can the millions of random treatments in nonexperimental data reveal about causes?\n\nPaper Abstract: Abstract We propose a new method to estimate causal effects from nonexperimental data. Each pair of sample units is first associated with a stochastic ‚Äôtreatment‚Äô - differences in factors between units - and an effect - a resultant outcome difference. It is then proposed that all such pairs can be combined to provide more accurate estimates of causal effects in observational data, provided a statistical model connecting combinatorial properties of treatments to the accuracy and unbiasedness of their effects. The article introduces one such model and a Bayesian approach to combine the O‚Äã(n2)ùëÇsuperscriptùëõ2O(n^{2}) pairwise observations typically available in nonexperimnetal data. This also leads to an interpretation of nonexperimental datasets as incomplete, or noisy, versions of ideal factorial experimental designs. This approach to causal effect estimation has several advantages: (1) it expands the number of observations, converting thousands of individuals into millions of observational treatments; (2) starting with treatments closest to the experimental ideal, it identifies noncausal variables that can be ignored in the future, making estimation easier in each subsequent iteration while departing minimally from experiment-like conditions; (3) it recovers individual causal effects in heterogeneous populations. We evaluate the method in simulations and the National Supported Work (NSW) program, an intensively studied program whose effects are known from randomized field experiments. We demonstrate that the proposed approach recovers causal effects in common NSW samples, as well as in arbitrary subpopulations and an order-of-magnitude larger supersample with the entire national program data, outperforming Statistical, Econometrics and Machine Learning estimators in all cases. As a tool, the approach also allows researchers to represent and visualize possible causes, and heterogeneous subpopulations, in their samples.\n\n{retrieved_text}\n\nGenerate exactly 59 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 59\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Does matching overcome lalonde‚Äôs critique of nonexperimental estimators?\",\n        \"Large sample properties of matching estimators for average treatment effects\",\n        \"Comparative politics and the synthetic control method\",\n        \"Mostly harmless econometrics :an empiricist‚Äôs companion\",\n        \"Instrumental variables and the search for identification: From supply and demand to natural experiments\",\n        \"Beyond prediction: Using big data for policy problems\",\n        \"Recursive partitioning for heterogeneous causal effects\",\n        \"Comment on: ‚Äùthe blessings of multiple causes‚Äù by yixin wang and david m. blei\",\n        \"Inference on treatment effects after selection among high-dimensional controls\",\n        \"Variable selection for propensity score models\",\n        \"On the fourier spectrum of monotone functions\",\n        \"Post-selection and post-regularization inference in linear models with many controls and instruments ‚Ä†\",\n        \"Optimizing matching and analysis combinations for estimating causal effects\",\n        \"Causal inference from 2k factorial designs by using potential outcomes\",\n        \"Instruments, randomization, and learning about development\",\n        \"Causal effects in nonexperimental studies: Reevaluating the evaluation of training programs\",\n        \"Propensity score-matching methods for nonexperimental causal studies\",\n        \"Genetic matching for estimating causal effects: A general multivariate matching method for achieving balance in observational studies\",\n        \"Using Randomization in Development Economics Research: A Toolkit, volume 4 of Handbook of Development Economics, chapter 61, pages 3895‚Äì3962\",\n        \"On sample selection bias and its efficient correction via model averaging and unlabeled examples\",\n        \"Adaptive sparseness for supervised learning\",\n        \"Arrangement of field experiments\",\n        \"Improved learning of ac0 functions\",\n        \"Handbook of multisensor data fusion :theory and practice\",\n        \"The Elements of Statistical Learning : Data Mining, Inference, and Prediction\",\n        \"Sample selection bias as a specification error\",\n        \"Assessing the case for social experiments\",\n        \"Matching as an econometric evaluation estimator\",\n        \"Matching as nonparametric preprocessing for reducing model dependence in parametric causal inference\",\n        \"Causal inference without balance checking: Coarsened exact matching\",\n        \"Misunderstandings between experimentalists and observationalists about causal inference\",\n        \"Better late than nothing: Some comments on deaton (2009) and heckman and urzua (2009)\",\n        \"Stochastic estimation of the maximum of a regression function\",\n        \"Why propensity scores should not be used for matching\",\n        \"Evaluating the econometric evaluations of training programs with experimental data\",\n        \"Deep learning\",\n        \"Causal effect inference with deep latent-variable models\",\n        \"Information theory, inference, and learning algorithms\",\n        \"Human- level control through deep reinforcement learning\",\n        \"Matching estimators of causal effects: Prospects and pitfalls in theory and practice\",\n        \"Counterfactuals and causal inference : methods and principles for social research\",\n        \"Causality : models, reasoning, and inference\",\n        \"3. the foundations of causal inference\",\n        \"The seven tools of causal inference, with reflections on machine learning\",\n        \"An experimental-design perspective on population genetic variation\",\n        \"The central role of the propensity score in observational studies for causal effects\",\n        \"Estimating causal effects of treatments in randomized and nonrandomized studies\",\n        \"Affinely invariant matching methods with discriminant mixtures of proportional ellipsoidally symmetric distributions\",\n        \"Equivalence of distance-based and rkhs-based statistics in hypothesis testing\",\n        \"On learning monotone dnf under product distributions\",\n        \"Matching methods for causal inference: A review and a look forward\",\n        \"Inverse problem theory and methods for model paramenter estimation\",\n        \"Super learner\",\n        \"A new criterion for confounder selection\",\n        \"The blessings of multiple causes\",\n        \"Population heterogeneity and causal inference\",\n        \"Learning and evaluating classifiers under sample selection bias\",\n        \"Matching estimators and the data from the national supported work demonstration again\",\n        \"Sensitivity of propensity score methods to the specifications\"\n    ],\n    \"reasoning\": \"Selected these 59 references because they represent foundational work and recent advances in What can the millions of random treatments in nonexperimental data reveal about causes?, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}