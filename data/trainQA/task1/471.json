{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 45 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Coded Secure Multi-Party Computation for Massive Matrices with Adversarial Nodes\n\nPaper Abstract: Abstract In this work, we consider the problem of secure multi-party computation (MPC), consisting of ŒìŒì\\Gamma sources, each has access to a large private matrix, NùëÅN processing nodes or workers, and one data collector or master. The master is interested in the result of a polynomial function of the input matrices. Each source sends a randomized functions of its matrix, called as its share, to each worker. The workers process their shares in interaction with each other, and send some results to the master such that it can derive the final result. There are several constraints: (1) each worker can store a function of each input matrix, with the size of 1m1ùëö\\frac{1}{m} fraction of that input matrix, (2) up to tùë°t of the workers, for some integer tùë°t, are adversary and may collude to gain information about the private inputs or can do malicious actions to make the final result incorrect. The objective is to design an MPC scheme with the minimum number the workers, called the recovery threshold, such that the final result is correct, workers learn no information about the input matrices, and the master learns nothing beyond the final result. In this paper, we propose an MPC scheme that achieves the recovery threshold of 3‚Äãt+2‚Äãm‚àí13ùë°2ùëö13t+2m-1 workers, which is order-wise less than the recovery threshold of the conventional methods. The challenge in dealing with this set up is that when nodes interact with each other, the malicious messages that adversarial nodes generate propagate through the system, and can mislead the honest nodes. To deal with this challenge, we design some subroutines that can detect erroneous messages, and correct or drop them.\n\n{retrieved_text}\n\nGenerate exactly 45 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 45\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A practical implementation of secure auctions based on multiparty integer computation\",\n        \"An improved e-voting scheme using secret sharing based secure multi-party computation\",\n        \"Privacy preserving data mining: ‚Äòa state of the art‚Äô\",\n        \"Verifiable signature sharing\",\n        \"Private information retrieval\",\n        \"FairplayMP: a system for secure multi-party computation\",\n        \"Cryptographic computation: Secure fault-tolerant protocols and the public-key model\",\n        \"Adaptively secure multi-party computation\",\n        \"Secure multi-party computation\",\n        \"Simplified VSS and fast-track multiparty computations with applications to threshold cryptography\",\n        \"Completeness theorems for non-cryptographic fault-tolerant distributed computation\",\n        \"Entangled polynomial coding in limited-sharing multi-party computation\",\n        \"Limited-sharing multi-party computation for massive matrix operations\",\n        \"Secure coded multi-party computation for massive matrix operations\",\n        \"Non-interactive and information-theoretic secure verifiable secret sharing\",\n        \"Verifiable secret sharing and multiparty protocols with honest majority\",\n        \"General secure multi-party computation from any linear secret-sharing scheme\",\n        \"The tail at scale\",\n        \"Speeding up distributed machine learning using codes\",\n        \"High-dimensional coded matrix multiplication\",\n        \"Polynomial codes: an optimal design for high-dimensional coded matrix multiplication\",\n        \"Straggler mitigation in distributed matrix multiplication: Fundamental limits and optimal coding\",\n        \"On the optimal recovery threshold of coded matrix multiplication\",\n        \"CodedSketch: A coding scheme for distributed computation of approximated matrix multiplications\",\n        \"Lagrange coded computing: Optimal design for resiliency, security and privacy\",\n        \"GASP codes for secure distributed matrix multiplication\",\n        \"Secure distributed computing with straggling servers using polynomial codes\",\n        \"Private secure coded computation\",\n        \"Private and secure distributed matrix multiplication with flexible communication load\",\n        \"Entangled polynomial codes for secure, private, and batch distributed matrix multiplication: Breaking the‚Äùcubic‚Äùbarrier\",\n        \"On the capacity of secure distributed matrix multiplication\",\n        \"On the upload versus download cost for secure and private matrix multiplication\",\n        \"The need for alignment in rate-efficient distributed two-sided secure matrix computation\",\n        \"GCSA codes with noise alignment for secure coded multi-party batch matrix multiplication\",\n        \"How to share a secret\",\n        \"Safeguarding cryptographic keys\",\n        \"Verifiable secret sharing and achieving simultaneity in the presence of faults\",\n        \"A practical scheme for non-interactive verifiable secret sharing\",\n        \"Secret sharing homomorphisms: Keeping shares of a secret secret\",\n        \"Unconditionally secure proactive secret sharing scheme with combinatorial structures\",\n        \"Efficient statistical asynchronous verifiable secret sharing with optimal resilience\",\n        \"A full proof of the BGW protocol for perfectly-secure multiparty computation.\",\n        \"A full proof of the BGW protocol for perfectly secure multiparty computation\",\n        \"Reed-Solomon codes and their applications\",\n        \"Elements of information theory\"\n    ],\n    \"reasoning\": \"Selected these 45 references because they represent foundational work and recent advances in Coded Secure Multi-Party Computation for Massive Matrices with Adversarial Nodes, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}