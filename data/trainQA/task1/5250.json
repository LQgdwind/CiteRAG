{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 48 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Validation and Generalizability of Self-Supervised Image Reconstruction Methods for Undersampled MRI\n\nPaper Abstract: Abstract Deep learning methods have become the state of the art for undersampled MR reconstruction. Particularly for cases where it is infeasible or impossible for ground truth, fully sampled data to be acquired, self-supervised machine learning methods for reconstruction are becoming increasingly used. However potential issues in the validation of such methods, as well as their generalizability, remain underexplored. In this paper, we investigate important aspects of the validation of self-supervised algorithms for reconstruction of undersampled MR images: quantitative evaluation of prospective reconstructions, potential differences between prospective and retrospective reconstructions, suitability of commonly used quantitative metrics, and generalizability. Two self-supervised algorithms based on self-supervised denoising and the deep image prior were investigated. These methods are compared to a least squares fitting and a compressed sensing reconstruction using in-vivo and phantom data. Their generalizability was tested with prospectively under-sampled data from experimental conditions different to the training. We show that prospective reconstructions can exhibit significant distortion relative to retrospective reconstructions/ground truth. Furthermore, pixel-wise quantitative metrics may not capture differences in perceptual quality accurately, in contrast to a perceptual metric. In addition, all methods showed potential for generalization; however, generalizability is more affected by changes in anatomy/contrast than other changes. We further showed that no-reference image metrics correspond well with human rating of image quality for studying generalizability. Finally, we showed that a well-tuned compressed sensing reconstruction and learned denoising perform similarly on all data. The datasets acquired for this paper will be made available online; see https://www.melba-journal.org/papers/2022:022.html for details.\n\n{retrieved_text}\n\nGenerate exactly 48 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 48\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Ssfd: Self-supervised feature distance as an mr image reconstruction quality metric\",\n        \"Unsupervised deep learning methods for biological image reconstruction\",\n        \"On instabilities of deep learning in image reconstruction and the potential costs of ai\",\n        \"Noise2self: Blind denoising by self-supervision\",\n        \"The perception-distortion tradeoff\",\n        \"Fast poisson disk sampling in arbitrary dimensions\",\n        \"Accelerated mri with un-trained neural networks\",\n        \"Measuring robustness in deep learning based compressive sensing\",\n        \"Skm-tea: A dataset for accelerated mri reconstruction with dense image labels for quantitative clinical evaluation\",\n        \"Creation of fully sampled mr data repository for compressed sensing of the knee\",\n        \"Generalized autocalibrating partially parallel acquisitions (grappa)\",\n        \"Chapter 2 - machine learning for image reconstruction\",\n        \"Learning a variational network for reconstruction of accelerated mri data\",\n        \"Systematic evaluation of iterative deep neural networks for fast parallel mri reconstruction with sensitivity-weighted coil combination\",\n        \"Deep decoder: Concise image representations from untrained non-convolutional networks\",\n        \"Compressive sensing with un-trained neural networks: Gradient descent finds a smooth approximation\",\n        \"Perceptual losses for real-time style transfer and super-resolution\",\n        \"Adam: A method for stochastic optimization\",\n        \"Assessment of the generalization of learned image reconstruction and the potential for transfer learning\",\n        \"Deep-learning methods for parallel magnetic resonance imaging reconstruction: A survey of the current approaches, trends, and issues\",\n        \"fastmri: A publicly available raw k-space and dicom dataset of knee images for accelerated mr image reconstruction using machine learning\",\n        \"Unsupervised mri reconstruction via zero-shot learned adversarial transformers\",\n        \"Rare: Image reconstruction using deep priors learned without groundtruth\",\n        \"NTIRE 2020 challenge on real-world image super-resolution: Methods and results\",\n        \"Sparse mri: The application of compressed sensing for rapid mr imaging\",\n        \"Blind/referenceless image spatial quality evaluator\",\n        \"Results of the 2020 fastmri challenge for machine learning mr image reconstruction\",\n        \"Accelerated mp2rage imaging using cartesian phyllotaxis readout and compressed sensing reconstruction\",\n        \"Sigpy: a python package for high performance iterative reconstruction\",\n        \"Pytorch: An imperative style, high-performance deep learning library\",\n        \"Sense: sensitivity encoding for fast mri\",\n        \"Advances in sensitivity encoding with arbitrary k-space trajectories\",\n        \"Using deep learning to accelerate knee mri at 3 t: results of an interchangeability study\",\n        \"U-net: Convolutional networks for biomedical image segmentation\",\n        \"Mri t2 mapping of the knee providing synthetic morphologic images: comparison to conventional turbo spin-echo mri\",\n        \"Data compression: the complete reference\",\n        \"Deep admm-net for compressive sensing mri\",\n        \"Espiritâ€”an eigenvalue approach to autocalibrating parallel mri: where sense meets grappa\",\n        \"Deep image prior\",\n        \"Blind image quality evaluation using perception based features\",\n        \"High-fidelity reconstruction with instance-wise discriminative feature matching loss\",\n        \"No-reference perceptual quality assessment of jpeg compressed images\",\n        \"Image quality assessment: from error visibility to structural similarity\",\n        \"No-reference image quality metrics for structural mri\",\n        \"Self-supervised learning of physics-guided reconstruction neural networks without fully sampled reference data\",\n        \"Instabilities in conventional multi-coil mri reconstruction with small adversarial perturbations\",\n        \"Can signal-to-noise ratio perform as a baseline indicator for medical image quality assessment\",\n        \"fastmri+: Clinical pathology annotations for knee and brain fully sampled multi-coil mri data\"\n    ],\n    \"reasoning\": \"Selected these 48 references because they represent foundational work and recent advances in Validation and Generalizability of Self-Supervised Image Reconstruction Methods for Undersampled MRI, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}