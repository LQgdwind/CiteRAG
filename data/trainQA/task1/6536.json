{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 270 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: ACKNOWLEDGMENTS\n\nPaper Abstract: \n\n{retrieved_text}\n\nGenerate exactly 270 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 270\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"State abstractions for lifelong reinforcement learning\",\n        \"Spinning up in deep reinforcement learning\",\n        \"Life-long disentangled representation learning with cross-domain latent homologies\",\n        \"Continual learning with adaptive weights (CLAW)\",\n        \"One network fits all? Modular versus monolithic task formulations in neural networks\",\n        \"CausalWorld: A robotic manipulation benchmark for causal structure and transfer learning\",\n        \"Uncertainty-based continual learning with adaptive regularization\",\n        \"CoSE: Compositional stroke embeddings\",\n        \"Robust visual reasoning via language guided neural module networks\",\n        \"Learning to recombine and resample data for compositional generalization\",\n        \"Continuous adaptation via meta-learning in nonstationary and competitive environments\",\n        \"Modular meta-learning\",\n        \"Neural relational inference with fast modular meta-learning\",\n        \"Online continual learning with maximal interfered retrieval\",\n        \"Expert gate: Lifelong learning with a network of experts\",\n        \"Gradient based sample selection for online continual learning\",\n        \"Measuring compositionality in representation learning\",\n        \"Neural module networks\",\n        \"Compositional transformers for scene generation\",\n        \"A causal view of compositional zero-shot recognition\",\n        \"EEC: Learning to encode and regenerate images for continual learning\",\n        \"The option-critic architecture\",\n        \"Systematic generalization: What is required and can it be learned?\",\n        \"The strong law of large numbers for L-statistics with dependent data\",\n        \"Transfer in deep reinforcement learning using successor features and generalised policy improvement\",\n        \"Learning to continually learn\",\n        \"The arcade learning environment: An evaluation platform for general agents\",\n        \"Measuring and regularizing networks in function space\",\n        \"Convergence of probability measures\",\n        \"Optimization problems with perturbations: A guided tour\",\n        \"Coresets via bilevel optimization for continual learning and streaming\",\n        \"Programming with a differentiable Forth interpreter\",\n        \"On-line learning and stochastic approximations\",\n        \"Autonomous cross-domain knowledge transfer in lifelong policy gradient reinforcement learning\",\n        \"Online multi-task learning for policy gradient methods\",\n        \"OpenAI Gym\",\n        \"PAC-inspired option discovery in lifelong reinforcement learning\",\n        \"Leveraging grammar and reinforcement learning for neural program synthesis\",\n        \"Dark experience for general continual learning: A strong, simple baseline\",\n        \"Composable geometric motion policies using multi-task pullback bundle dynamical systems\",\n        \"Online learned continual compression with adaptive quantization modules\",\n        \"Online fast adaptation and knowledge accumulation (OSAKA): A new approach to continual learning\",\n        \"Making neural programming architectures generalize via recursion\",\n        \"CPR: Classifier-projection regularization for continual learning\",\n        \"Automatically composing representation transformations as a means for generalization\",\n        \"Modularity in reinforcement learning via algorithmic independence in credit assignment\",\n        \"Riemannian walk for incremental learning: Understanding forgetting and intransigence\",\n        \"Continual learning in low-rank orthogonal subspaces\",\n        \"Efficient lifelong learning with A-GEM\",\n        \"On tiny episodic memories in continual learning\",\n        \"Mitigating forgetting in online continual learning via instance-aware parameterization\",\n        \"Long live the lottery: The existence of winning tickets in lifelong learning\",\n        \"Compositional generalization via neural-symbolic stack machines\",\n        \"Modular meta-learning with shrinkage\",\n        \"Lifelong machine learning\",\n        \"RMPflow: A geometric framework for generation of multitask motion policies\",\n        \"BabyAI: First steps towards grounded language learning with a human in the loop\",\n        \"Minimalistic gridworld environment for OpenAI Gym\",\n        \"Online continual learning from imbalanced data\",\n        \"Learning to adapt in dynamic, real-world environments through meta-reinforcement learning\",\n        \"CURIOUS: Intrinsically motivated modular multi-goal reinforcement learning\",\n        \"Are neural nets modular? Inspecting functional modularity through differentiable weight masks\",\n        \"How modular should neural module networks be for systematic generalization?\",\n        \"Feudal reinforcement learning\",\n        \"Episodic memory in lifelong language learning\",\n        \"RATT: Recurrent attention to transient tasks for continual image captioning\",\n        \"Flattening sharpness for dynamic gradient projection memory benefits in continual learning\",\n        \"ImageNet: A large-scale hierarchical image database\",\n        \"Kernel continual learning\",\n        \"Compositional plan vectors\",\n        \"Learning modular neural network policies for multi-task and multi-robot transfer\",\n        \"BERT: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Hierarchical reinforcement learning with the MAXQ value function decomposition\",\n        \"A truth maintenance system\",\n        \"Compositional visual generation with energy based models\",\n        \"Organizing recurrent network dynamics by task-computation to enable continual learning\",\n        \"BooVAE: Boosting approach for continual learning of VAE\",\n        \"Continual learning in recurrent neural networks\",\n        \"PathNet: Evolution channels gradient descent in super neural networks\",\n        \"The lottery ticket hypothesis: Finding sparse, trainable neural networks\",\n        \"Recovery of exact sparse representations in the presence of bounded noise\",\n        \"Benchmarking batch deep reinforcement learning algorithms\",\n        \"Off-policy deep reinforcement learning without exploration\",\n        \"Addressing function approximation error in actor-critic methods\",\n        \"A meta-MDP approach to exploration for lifelong reinforcement learning\",\n        \"Image style transfer using convolutional neural networks\",\n        \"Differentiable programs with neural libraries\",\n        \"Recursive sketches for modular deep learning\",\n        \"Learning sparse networks using targeted dropout\",\n        \"Permutation equivariant models for compositional generalization in language\",\n        \"Recurrent independent mechanisms\",\n        \"Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates\",\n        \"Hierarchical poset decoding for compositional generalization in language\",\n        \"Improved schemes for episodic memory-based lifelong learning\",\n        \"Look-ahead meta learning for continual learning\",\n        \"Neural module networks for reasoning over text\",\n        \"Neural topic modeling with continual lifelong learning\",\n        \"Environment generation for zero-shot compositional reinforcement learning\",\n        \"Composable deep reinforcement learning for robotic manipulation\",\n        \"Benchmark environments for multitask learning in continuous domains\",\n        \"Posterior meta-replay for continual learning\",\n        \"Improving neural networks by preventing co-adaptation of feature detectors\",\n        \"Learning to reason: End-to-end module networks for visual question answering\",\n        \"Overcoming catastrophic forgetting via model adaptation\",\n        \"One policy to control them all: Shared modular policies for agent-agnostic control\",\n        \"Compacting, picking and growing for unforgetting continual learning\",\n        \"Optimizing reusable knowledge for continual learning via metalearning\",\n        \"Note on the quadratic penalties in elastic weight consolidation\",\n        \"Compositional zero-shot learning via fine-grained dense feature composition\",\n        \"Selective experience replay for lifelong learning\",\n        \"Using task features for zero-shot knowledge transfer in lifelong learning\",\n        \"RLBench: The robot learning benchmark & learning environment\",\n        \"Meta-learning representations for continual learning\",\n        \"Reconciling meta-learning and continual learning with online mixtures of tasks\",\n        \"Gradient-based editing of memory examples for online task-free continual learning\",\n        \"Inferring and executing programs for visual reasoning\",\n        \"Meta-consolidation for continual learning\",\n        \"A composable specification language for reinforcement learning tasks\",\n        \"Compositional reinforcement learning from logical specifications\",\n        \"Continual learning with node-importance based adaptive group sparse regularization\",\n        \"A natural policy gradient\",\n        \"Natural continual learning: Success is a journey, not (just) a destination\",\n        \"Policy consolidation for continual reinforcement learning\",\n        \"Variational auto-regressive Gaussian processes for continual learning\",\n        \"Continual learning of a mixed sequence of similar and dissimilar tasks\",\n        \"Achieving forgetting prevention and knowledge transfer in continual learning\",\n        \"Measuring compositional generalization: A comprehensive method on realistic data\",\n        \"Visual reasoning by progressive module networks\",\n        \"Overcoming catastrophic forgetting in neural networks\",\n        \"Modular networks: Learning to decompose neural computation\",\n        \"Optimal continual learning has perfect memory and is NP-hard\",\n        \"Actor-critic–type learning algorithms for Markov decision processes\",\n        \"Skill discovery in continuous reinforcement learning domains using skill chaining\",\n        \"Learning multiple layers of features from tiny images\",\n        \"Bayesian structural adaptation for continual learning\",\n        \"Stabilizing off-policy Q-learning via bootstrapping error reduction\",\n        \"Understanding self-training for gradual domain adaptation\",\n        \"Continual learning with Bayesian neural networks for non-stationary data\",\n        \"Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks\",\n        \"Compositional generalization through meta sequence-to-sequence learning\",\n        \"Human-level concept learning through probabilistic program induction\",\n        \"Continuous domain adaptation with variational domain-agnostic feature replay\",\n        \"Safe policy improvement with baseline bootstrapping\",\n        \"Gradient-based learning applied to document recognition\",\n        \"Sharing less is more: Lifelong learning in deep networks with selective layer transfer\",\n        \"Continual learning in the teacher-student setup: Impact of task similarity\",\n        \"A neural Dirichlet process mixture model for task-free continual learning\",\n        \"Learning shared knowledge for deep lifelong learning using deconvolutional networks\",\n        \"Composing complex skills by learning transition policies with proximity reward induction\",\n        \"Offline reinforcement learning: Tutorial, review, and perspectives on open problems\",\n        \"RMP2: A structured composable policy class for robot learning\",\n        \"Learn to grow: A continual structure learning framework for overcoming catastrophic forgetting\",\n        \"Learning compositional Koopman operators for model-based control\",\n        \"Solving compositional reinforcement learning problems via task reduction\",\n        \"Compositional language continual learning\",\n        \"Learning without forgetting\",\n        \"Continuous control with deep reinforcement learning\",\n        \"RD2: Reward decomposition with representation disentanglement\",\n        \"Distributional reward decomposition for reinforcement learning\",\n        \"Compositional generalization by learning analytical expressions\",\n        \"Generalized variational continual learning\",\n        \"Gradient episodic memory for continual learning\",\n        \"Reset-free lifelong learning with skill-space planning\",\n        \"Catastrophic interference in connectionist networks: The sequential learning problem\",\n        \"Beyond shared hierarchies: Deep multitask learning through soft layer ordering\",\n        \"Modular universal reparameterization: Deep multi-task learning across diverse domains\",\n        \"Linear mode connectivity in multitask and continual learning\",\n        \"Understanding the role of training regimes in continual learning\",\n        \"Learning to combine top-down and bottom-up signals in recurrent neural networks with attention over modules\",\n        \"Asynchronous methods for deep reinforcement learning\",\n        \"Human-level control through deep reinforcement learning\",\n        \"Refactoring policy for compositional generalizability using self-supervised object proposals\",\n        \"Deep online learning via meta-learning: Continual adaptation for model-based RL\",\n        \"A Boolean task algebra for reinforcement learning\",\n        \"Continuous coordination as a realistic scenario for lifelong learning\",\n        \"Variational continual learning\",\n        \"Learning compositional rules via neural program synthesis\",\n        \"Learning dexterous in-hand manipulation\",\n        \"Continual learning via local module composition\",\n        \"Structure learning for neural module networks\",\n        \"Continual deep learning by functional regularisation of memorable past\",\n        \"Learning to control self-assembling morphologies: A study of generalization via modularity\",\n        \"MCP: Learning composable hierarchical control with multiplicative compositional policies\",\n        \"DualNet: Continual learning, fast and slow\",\n        \"Contextual transformation networks for online continual learning\",\n        \"Piaget’s theory\",\n        \"Learning compositional neural programs with recursive tree search and planning\",\n        \"BNS: Building network structures dynamically for continual learning\",\n        \"Formalizing the generalization-forgetting trade-off in continual learning\",\n        \"Spatially structured recurrent modules\",\n        \"Random path selection for incremental learning\",\n        \"Towards generalization and simplicity in continuous control\",\n        \"Anatomy of catastrophic forgetting: Hidden representations and task semantics\",\n        \"Continual unsupervised representation learning\",\n        \"Neural programmers-interpreters\",\n        \"Wandering within a world: Online contextualized few-shot learning\",\n        \"Compositional languages emerge in a neural iterated learning model\",\n        \"Learning to learn without forgetting by maximizing transfer and minimizing interference\",\n        \"Online structured Laplace approximations for overcoming catastrophic forgetting\",\n        \"Experience replay for continual learning\",\n        \"Routing networks and the challenges of modular and compositional computation\",\n        \"Routing networks: Adaptive selection of non-linear functions for multi-task learning\",\n        \"Lifelong domain adaptation via consolidated internal distribution\",\n        \"Using task descriptions in lifelong machine learning for improved performance and zero-shot transfer\",\n        \"Independent prototype propagation for zero-shot compositionality\",\n        \"Progressive neural networks\",\n        \"ELLA: An efficient lifelong learning algorithm\",\n        \"Planning in a hierarchy of abstraction spaces\",\n        \"Gradient projection memory for continual learning\",\n        \"Multimodal graph networks for compositional generalization in visual question answering\",\n        \"Trust region policy optimization\",\n        \"Proximal policy optimization algorithms\",\n        \"Progress & compress: A scalable framework for continual learning\",\n        \"Overcoming catastrophic forgetting with hard attention to the task\",\n        \"Outrageously large neural networks: The sparsely-gated mixture-of-experts layer\",\n        \"Continual learning with deep generative replay\",\n        \"Mastering the game of Go with deep neural networks and tree search\",\n        \"Mastering the game of Go without human knowledge\",\n        \"Calibrating CNNs for lifelong learning\",\n        \"Evaluating logical generalization in graph neural networks\",\n        \"Class normalization for (continual)? generalized zero-shot learning\",\n        \"Memory-based parameter adaptation\",\n        \"LAMOL: LAnguage MOdeling for lifelong language learning\",\n        \"Reinforcement learning: An introduction\",\n        \"Policy gradient methods for reinforcement learning with function approximation\",\n        \"Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction\",\n        \"Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning\",\n        \"Locality and compositionality in zero-shot learning\",\n        \"Graph-based continual learning\",\n        \"A deep hierarchical approach to lifelong learning in Minecraft\",\n        \"Lifelong learning algorithms\",\n        \"Functional regularisation for continual learning with Gaussian processes\",\n        \"Compositionality of optimal control laws\",\n        \"MuJoCo: A physics engine for model-based control\",\n        \"dm_control: Software and tasks for continuous control\",\n        \"Houdini: Lifelong learning as program synthesis\",\n        \"Brain-inspired replay for continual learning with artificial neural networks\",\n        \"Three scenarios for continual learning\",\n        \"Asymptotic statistics, volume 3\",\n        \"Composing value functions in reinforcement learning\",\n        \"Hybrid reward architecture for reinforcement learning\",\n        \"CAM-GAN: Continual adaptation modules for generative adversarial networks\",\n        \"Efficient continual learning with modular networks and task-driven priors\",\n        \"FeUdal networks for hierarchical reinforcement learning\",\n        \"StarCraft II: A new challenge for reinforcement learning\",\n        \"Continual learning with hypernetworks\",\n        \"Learning where to learn: Gradient sparsity in meta and continual learning\",\n        \"AFEC: Active forgetting of negative transfer in continual learning\",\n        \"Learning from delayed rewards\",\n        \"Caltech-UCSD birds 200\",\n        \"Simple statistical gradient-following algorithms for connectionist reinforcement learning\",\n        \"Continual World: A robotic benchmark for continual reinforcement learning\",\n        \"Improving compositionality of neural networks by decoding representations to inputs\",\n        \"Fashion-MNIST: A novel image dataset for benchmarking machine learning algorithms\",\n        \"Deep reinforcement learning amidst continual structured non-stationarity\",\n        \"Neural task programming: Learning to generalize across hierarchical tasks\",\n        \"Continual learning of control primitives : Skill discovery via reset-games\",\n        \"Multi-task reinforcement learning with soft modularization\",\n        \"Mitigating forgetting in online continual learning with neuron calibration\",\n        \"Federated continual learning with weighted inter-client transfer\",\n        \"Scalable and order-robust continual learning with additive parameter decomposition\",\n        \"Lifelong learning with dynamically expandable networks\",\n        \"Meta-World: A benchmark and evaluation for multi-task and meta reinforcement learning\",\n        \"Learning simple algorithms from examples\",\n        \"Continual learning through synaptic intelligence\",\n        \"Task agnostic continual learning using online variational Bayes\",\n        \"Task-agnostic continual learning using online variational Bayes with fixed-point updates\",\n        \"Variational continual Bayesian meta-learning\",\n        \"Tensor based knowledge transfer across skill categories for robot control\",\n        \"robosuite: A modular simulation framework and benchmark for robot learning\"\n    ],\n    \"reasoning\": \"Selected these 270 references because they represent foundational work and recent advances in ACKNOWLEDGMENTS, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}