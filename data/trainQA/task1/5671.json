{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 57 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Does Configuration Encoding Matter in Learning Software Performance? An Empirical Study on Encoding Schemes\n\nPaper Abstract: Abstract. Learning and predicting the performance of a configurable software system helps to provide better quality assurance. One important engineering decision therein is how to encode the configuration into the model built. Despite the presence of different encoding schemes, there is still little understanding of which is better and under what circumstances, as the community often relies on some general beliefs that inform the decision in an ad-hoc manner. To bridge this gap, in this paper, we empirically compared the widely used encoding schemes for software performance learning, namely label, scaled label, and one-hot encoding. The study covers five systems, seven models, and three encoding schemes, leading to 105 cases of investigation. Our key findings reveal that: (1) conducting trial-and-error to find the best encoding scheme in a case by case manner can be rather expensive, requiring up to 400++ hours on some models and systems; (2) the one-hot encoding often leads to the most accurate results while the scaled label encoding is generally weak on accuracy over different models; (3) conversely, the scaled label encoding tends to result in the fastest training time across the models/systems while the one-hot encoding is the slowest; (4) for all models studied, label and scaled label encoding often lead to relatively less biased outcomes between accuracy and training time, but the paired model varies according to the system. We discuss the actionable suggestions derived from our findings, hoping to provide a better understanding of this topic for the community. To promote open science, the data and code of this work can be publicly accessed at https://github.com/ideas-labo/MSR2022-encoding-study.\n\n{retrieved_text}\n\nGenerate exactly 57 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 57\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Binarsity: a penalization for one-hot encoded features in linear supervised learning\",\n        \"ACTGAN: Automatic Configuration Tuning for Software Systems with Generative Adversarial Networks\",\n        \"Root mean square error (RMSE) or mean absolute error (MAE)?â€“Arguments against avoiding RMSE in the literature\",\n        \"All versus one: an empirical comparison on retrained and incremental machine learning for modeling performance of adaptable software\",\n        \"Lifelong dynamic optimization for self-adaptive systems: fact or fiction?\",\n        \"Self-adaptive and sensitivity-aware QoS modeling for the cloud\",\n        \"Symbiotic and sensitivity-aware architecture for globally-optimal benefit in self-adaptive cloud\",\n        \"Self-Adaptive and Online QoS Modeling for Cloud-Based Software Services\",\n        \"Self-Adaptive Trade-off Decision Making for Autoscaling Cloud-Based Services\",\n        \"To Adapt or Not to Adapt?: Technical Debt and Learning Driven Self-Adaptation for Managing Runtime Performance\",\n        \"Online QoS Modeling in the Cloud: A Hybrid and Adaptive Multi-learners Approach\",\n        \"A Survey and Taxonomy of Self-Aware and Self-Adaptive Cloud Autoscaling Systems\",\n        \"Synergizing Domain Expertise With Self-Awareness in Software Systems: A Patternized Architecture Guideline\",\n        \"FEMOSAA: Feature-Guided and Knee-Driven Multi-Objective Optimization for Self-Adaptive Software\",\n        \"MMO: Meta Multi-Objectivization for Software Configuration Tuning\",\n        \"Multi-objectivizing software configuration tuning\",\n        \"Support-vector networks\",\n        \"Enhancing Performance Prediction Robustness by Combining Analytical Modeling and Machine Learning\",\n        \"Mastering Uncertainty in Performance Estimations of Configurable Software Systems\",\n        \"Compressor performance prediction using a novel feed-forward neural network based on Gaussian kernel function\",\n        \"Discriminatory analysis: nonparametric discrimination, consistency properties\",\n        \"Adapting a system with noisy outputs with statistical guarantees\",\n        \"Review: Statistical Models: Theory and Practice (Revised Edition). Cambridge University Press, New York, New York, 2009, xiv + 442 pp., ISBN 978-0-521-74385-3, $40. by David A. Freedman\",\n        \"Baloo: Measuring and Modeling the Performance Configurations of Distributed DBMS\",\n        \"Variability-aware performance prediction: A statistical learning approach\",\n        \"DeepPerf: performance prediction for configurable software with deep sparse neural network\",\n        \"An Empirical Study on Performance Bugs for Highly Configurable Software Systems\",\n        \"Does encoding matter? A novel view on the quantitative genetic trait prediction problem\",\n        \"A Practical Guide to Training Restricted Boltzmann Machines\",\n        \"Random decision forests\",\n        \"Transfer Learning for Cross-Model Regression in Performance Modeling for the Cloud\",\n        \"Performance Evaluation of Different Feature Encoding Schemes on Cybersecurity Logs\",\n        \"An Uncertainty-Aware Approach to Optimal Configuration of Stream Processing Systems\",\n        \"Performance Prediction in Dynamic Clouds using Transfer Learning\",\n        \"The Interplay of Sampling and Machine Learning for Software Performance Prediction\",\n        \"Understanding the automated parameter optimization on transfer learning for cross-project defect prediction: an empirical study\",\n        \"How to Evaluate Solutions in Pareto-based Search-Based Software Engineering? A Critical Review and Methodological Guidance\",\n        \"Ranking and Clustering Software Cost Estimation Models through a Multiple Comparisons Algorithm\",\n        \"Predicting Machine Learning Pipeline Runtimes in the Context of Automated Machine Learning\",\n        \"Using bad learners to find good configurations\",\n        \"Finding Faster Configurations Using FLASH\",\n        \"The impact of data normalization on stock market prediction: using SVM and technical indicators\",\n        \"Scikit-learn: Machine Learning in Python\",\n        \"VEER: Disagreement-Free Multi-objective Configuration\",\n        \"Towards predicting feature defects in software product lines\",\n        \"Data Mining with Decision Trees - Theory and Applications. 2ndnd Edition. Series in Machine Perception and Artificial Intelligence, Vol. 81\",\n        \"Learning to Sample: An Active Learning Framework\",\n        \"Performance-influence models for highly configurable systems\",\n        \"Predicting performance via automated feature-interaction detection\",\n        \"Empirical comparison of regression methods for variability-aware performance prediction\",\n        \"A Critique and Improvement of the CL Common Language Effect Size Statistics of McGraw and Wong\",\n        \"Kernel ridge regression\",\n        \"Artificial neural network\",\n        \"Hyperparameter Optimization for Effort Estimation\",\n        \"Hey, you have given me too many knobs!: understanding and dealing with over-designed configuration in system software\",\n        \"Active Learning for Multi-Objective Optimization\",\n        \"Guillaume Sergent\"\n    ],\n    \"reasoning\": \"Selected these 57 references because they represent foundational work and recent advances in Does Configuration Encoding Matter in Learning Software Performance? An Empirical Study on Encoding Schemes, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}