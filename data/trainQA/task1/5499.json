{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 51 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: ùíú¬≥‚Å¢ùíü: A Platform of Searching for Robust Neural Architectures and Efficient Adversarial Attacks\n\nPaper Abstract: Abstract The robustness of deep neural networks (DNN) models has attracted increasing attention due to the urgent need for security in many applications. Numerous existing open-sourced tools or platforms are developed to evaluate the robustness of DNN models by ensembling the majority of adversarial attack or defense algorithms. Unfortunately, current platforms do not possess the ability to optimize the architectures of DNN models or the configuration of adversarial attacks to further enhance the robustness of models or the performance of adversarial attacks. To alleviate these problems, in this paper, we first propose a novel platform called auto adversarial attack and defense (A3‚ÄãDsuperscriptùê¥3ùê∑A^{3}D), which can help search for robust neural network architectures and efficient adversarial attacks. In A3‚ÄãDsuperscriptùê¥3ùê∑A^{3}D, we employ multiple neural architecture search methods, which consider different robustness evaluation metrics, including four types of noises: adversarial noise, natural noise, system noise, and quantified metrics, resulting in finding robust architectures. Besides, we propose a mathematical model for auto adversarial attack, and provide multiple optimization algorithms to search for efficient adversarial attacks. In addition, we combine auto adversarial attack and defense together to form a unified framework. Among auto adversarial defense, the searched efficient attack can be used as the new robustness evaluation to further enhance the robustness. In auto adversarial attack, the searched robust architectures can be utilized as the threat model to help find stronger adversarial attacks. Experiments on CIFAR10, CIFAR100, and ImageNet datasets demonstrate the feasibility and effectiveness of the proposed platform, which can also provide a benchmark and toolkit for researchers in the application of automated machine learning in evaluating and improving the DNN model robustnesses.\n\n{retrieved_text}\n\nGenerate exactly 51 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 51\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Remote sensing scene classification via multi-branch local attention network\",\n        \"Residual attention network for image classification\",\n        \"A survey of image classification methods and techniques for improving classification performance\",\n        \"Instant-teaching: An end-to-end semi-supervised object detection framework\",\n        \"Object detection with deep learning: A review\",\n        \"Deep neural networks for object detection\",\n        \"Explaining and harnessing adversarial examples\",\n        \"Towards deep learning models resistant to adversarial attacks\",\n        \"Towards evaluating the robustness of neural networks\",\n        \"Technical report on the cleverhans v2. 1.0 adversarial examples library\",\n        \"Foolbox: A python toolbox to benchmark the robustness of machine learning models\",\n        \"Adversarial robustness toolbox v1. 0.0\",\n        \"Benchmarking adversarial robustness on image classification\",\n        \"Openattack: An open-source textual adversarial attack toolkit\",\n        \"Deeprobust: A pytorch library for adversarial attacks and defenses\",\n        \"Darts: Differentiable architecture search\",\n        \"Pc-darts: Partial channel connections for memory-efficient architecture search\",\n        \"DSRNA: differentiable search of robust neural architectures\",\n        \"Advrush: Searching for adversarially robust neural architectures\",\n        \"Composite adversarial attacks\",\n        \"Automated discovery of adaptive attacks on adversarial defenses\",\n        \"An alternative surrogate loss for pgd-based adversarial testing\",\n        \"Boosting adversarial attacks with momentum\",\n        \"Decoupling direction and norm for efficient gradient-based l2 adversarial attacks and defenses\",\n        \"Distillation as a defense to adversarial perturbations against deep neural networks\",\n        \"Dimensionality reduction as a defense against evasion attacks on machine learning classifiers\",\n        \"Countering adversarial images using input transformations\",\n        \"Stochastic activation pruning for robust adversarial defense\",\n        \"Efficient neural architecture search via proximal iterations\",\n        \"Automated decision-based adversarial attacks\",\n        \"Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks\",\n        \"When NAS meets robustness: In search of robust architectures against adversarial attacks\",\n        \"Multi-objective search of robust neural architectures against multiple types of adversarial attacks\",\n        \"Evolving robust neural architectures to defend from adversarial attacks\",\n        \"Anti-bandit neural architecture search for model defense\",\n        \"Real world robustness from systematic noise\",\n        \"Adversarial weight perturbation helps robust generalization\",\n        \"Improving adversarial robustness requires revisiting misclassified examples\",\n        \"Theoretically principled trade-off between robustness and accuracy\",\n        \"Defense against adversarial attacks using feature scattering-based adversarial training\",\n        \"Adversarial interpolation training: A simple approach for improving model robustness\",\n        \"Manifold regularization for adversarial robustness\",\n        \"Fixing data augmentation to improve adversarial robustness\",\n        \"Towards achieving adversarial robustness beyond perceptual limits\",\n        \"Learnable boundary guided adversarial training\",\n        \"Overfitting in adversarially robust deep learning\",\n        \"Luring of adversarial perturbations\",\n        \"Fast is better than free: Revisiting adversarial training\",\n        \"Label smoothing and logit squeezing: a replacement for adversarial training?\",\n        \"Ensemble adversarial training: Attacks and defenses\",\n        \"Do adversarially robust imagenet models transfer better?\"\n    ],\n    \"reasoning\": \"Selected these 51 references because they represent foundational work and recent advances in ùíú¬≥‚Å¢ùíü: A Platform of Searching for Robust Neural Architectures and Efficient Adversarial Attacks, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}