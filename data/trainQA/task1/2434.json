{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 59 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: UFA-FUSE: A novel deep supervised and hybrid model for multi-focus image fusion\n\nPaper Abstract: Abstract Traditional and deep learning-based fusion methods generated the intermediate decision map to obtain the fusion image through a series of post-processing procedures. However, the fusion results generated by these methods are easy to lose some source image details or results in artifacts. Inspired by the image reconstruction techniques based on deep learning, we propose a multi-focus image fusion network framework without any post-processing to solve these problems in the end-to-end and supervised learning ways. To sufficiently train the fusion model, we have generated a large-scale multi-focus image dataset with ground-truth fusion images. What’s more, to obtain a more informative fusion image, we further designed a novel fusion strategy based on unity fusion attention, which is composed of a channel attention module and a spatial attention module. Specifically, the proposed fusion approach mainly comprises three key components: feature extraction, feature fusion and image reconstruction. We first utilize seven convolutional blocks to extract the image features from source images. Then, the extracted convolutional features are fused by the proposed fusion strategy in the feature fusion layer. Finally, the fused image features are reconstructed by four convolutional blocks. Experimental results demonstrate that the proposed approach for multi-focus image fusion achieves remarkable fusion performance and superior time efficiency compared to 19 state-of-the-art fusion methods.\n\n{retrieved_text}\n\nGenerate exactly 59 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 59\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Image fusion using adjustable non-subsampled shearlet transform\",\n        \"Drf: Disentangled representation for visible and infrared image fusion\",\n        \"Sedrfuse: A symmetric encoder–decoder with residual block network for infrared and visible image fusion\",\n        \"Multimodal medical image fusion based on weighted local energy matching measurement and improved spatial frequency\",\n        \"Medical image fusion with parameter-adaptive pulse coupled neural network in nonsubsampled shearlet transform domain\",\n        \"Efficient misalignment-robust multi-focus microscopical images fusion\",\n        \"Structural characterization and measurement of nonwoven fabrics based on multi-focus image fusion\",\n        \"Region-based multifocus image fusion for the precise acquisition of pap smear images\",\n        \"Image fusion: algorithms and applications\",\n        \"A morphological pyramidal image decomposition\",\n        \"Multisensor image fusion using the wavelet transform\",\n        \"A novel image decomposition-based hybrid technique with super-resolution method for multi-focus image fusion\",\n        \"Pixel- and region-based image fusion with complex wavelets\",\n        \"Multifocus image fusion using the nonsubsampled contourlet transform\",\n        \"Quadtree-based multi-focus image fusion using a weighted focus-measure\",\n        \"Image fusion with guided filtering\",\n        \"Multifocus image fusion using region segmentation and spatial frequency\",\n        \"Multi-scale weighted gradient-based fusion for multi-focus images\",\n        \"Multi-focus image fusion with dense sift\",\n        \"Multi-focus image fusion with a deep convolutional neural network\",\n        \"Pixel convolutional neural network for multi-focus image fusion\",\n        \"Sesf-fuse: An unsupervised deep model for multi-focus image fusion\",\n        \"Deepfuse: A deep unsupervised approach for exposure fusion with extreme exposure image pairs\",\n        \"Densefuse: A fusion approach to infrared and visible images\",\n        \"Ifcnn: A general image fusion framework based on convolutional neural network\",\n        \"Remote sensing image fusion using the curvelet transform\",\n        \"Robust multi-focus image fusion using edge model and multi-matting\",\n        \"Drpl: Deep regression pair learning for multi-focus image fusion\",\n        \"Mff-gan: An unsupervised generative adversarial network with adaptive and gradient joint constraints for multi-focus image fusion\",\n        \"Brain medical image fusion based on dual-branch cnns in nsst domain\",\n        \"Deepanf: A deep attentive neural framework with distributed representation for chromatin accessibility prediction\",\n        \"Squeeze-and-excitation networks\",\n        \"Multigrained attention network for infrared and visible image fusion\",\n        \"Nestfuse: An infrared and visible image fusion architecture based on nest connection and spatial/channel attention models\",\n        \"Global-feature encoding u-net (geu-net) for multi-focus image fusion\",\n        \"Cbam: Convolutional block attention module\",\n        \"Loss functions for image restoration with neural networks\",\n        \"Microsoft coco: Common objects in context\",\n        \"Image quality assessment: from error visibility to structural similarity\",\n        \"Learning to detect salient objects with image-level supervision\",\n        \"Adam: A method for stochastic optimization\",\n        \"Multifocus image fusion and restoration with sparse representation\",\n        \"A new image fusion performance metric based on visual information fidelity\",\n        \"An image fusion method based on directional contrast and area-based standard deviation\",\n        \"Fusion of multispectral and panchromatic satellite images based on contourlet transform and local average gradient\",\n        \"Gradient-based/evolutionary relay hybrid for computing pareto front approximations maximizing the s-metric\",\n        \"Improved bounds on the local mean-square error and the bias of parameter estimators (corresp.)\",\n        \"A new automated quality assessment algorithm for image fusion\",\n        \"A novel image fusion metric based on multi-scale analysis\",\n        \"Multi-focus image fusion using dictionary-based sparse representation\",\n        \"Infrared and visible image fusion via gradient transfer and total variation minimization\",\n        \"Perceptual fusion of infrared and visible images through a hybrid multi-scale decomposition with gaussian and bilateral filters\",\n        \"Vif-net: an unsupervised framework for infrared and visible image fusion\",\n        \"A medical image fusion method based on convolutional neural networks\",\n        \"Multimodal medical image fusion using hybrid layer decomposition with cnn-based feature mapping and structural clustering\",\n        \"Laplacian re-decomposition for multimodal medical image fusion\",\n        \"On the use of a joint spatial-frequency representation for the fusion of multi-focus images\",\n        \"Multifocus image fusion using the log-gabor transform and a multisize windows technique\",\n        \"Multi-focus- ing algorithm for microscopy imagery in assembly line using low-cost camera\"\n    ],\n    \"reasoning\": \"Selected these 59 references because they represent foundational work and recent advances in UFA-FUSE: A novel deep supervised and hybrid model for multi-focus image fusion, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}