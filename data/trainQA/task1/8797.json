{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 360 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation\n\nPaper Abstract: Abstract Large Language Models (LLMs) have exploded a new heatwave of AI for their ability to engage end-users in human-level conversations with detailed and articulate answers across many knowledge domains. In response to their fast adoption in many industrial applications, this survey concerns their safety and trustworthiness. First, we review known vulnerabilities and limitations of the LLMs, categorising them into inherent issues, attacks, and unintended bugs. Then, we consider if and how the Verification and Validation (V&V) techniques, which have been widely developed for traditional software and deep learning models such as convolutional neural networks as independent processes to check the alignment of their implementations against the specifications, can be integrated and further extended throughout the lifecycle of the LLMs to provide rigorous analysis to the safety and trustworthiness of LLMs and their applications. Specifically, we consider four complementary techniques: falsification and evaluation, verification, runtime monitoring, and regulations and ethical use. In total, 370+ references are considered to support the quick understanding of the safety and trustworthiness issues from the perspective of V&V. While intensive research has been conducted to identify the safety and trustworthiness issues, rigorous yet practical methods are called for to ensure the alignment of LLMs with safety and trustworthiness requirements.\n\n{retrieved_text}\n\nGenerate exactly 360 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 360\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Bitcoin energy consumption index\",\n        \"The carbon footprint of gpt-4\",\n        \"Gpt-4’s details are leaked\",\n        \"Italy became the first western country to ban chatgpt\",\n        \"March 20 chatgpt outage: Here’s what happened\",\n        \"Openai says a bug leaked sensitive chatgpt user data\",\n        \"Pause giant ai experiments: An open letter\",\n        \"Prompt engineering guide\",\n        \"Tools such as chatgpt threaten transparent science; here are our ground rules for their use\",\n        \"Quality management systems - process validation guidance\",\n        \"Eu gdpr\",\n        \"The data protection act\",\n        \"Ethics guidelines for trustworthy ai\",\n        \"China’s regulations on the administration of deep synthesis internet information services\",\n        \"Ai risk management framework\",\n        \"China’s regulations on recommendation algorithms\",\n        \"Content at scale\",\n        \"Copyleaks\",\n        \"New meta ai demo writes racist and inaccurate scientific literature, gets pulled\",\n        \"Originality ai\",\n        \"Prompt injection attacks against gpt-3\",\n        \"Blueprint for an ai bill of rights\",\n        \"Chatgpt: get instant answers, find creative inspiration, and learn something new\",\n        \"Chatgpt: Us lawyer admits using ai for case research\",\n        \"China’s algorithm registry\",\n        \"Eu ai act\",\n        \"Eu data act\",\n        \"’he would still be here’: Man dies by suicide after talking with ai chatbot, widow says\",\n        \"A pro-innovation approach to ai regulation\",\n        \"Prompt leaking\",\n        \"Responsible ai priciples from microsoft\",\n        \"Three samsung employees reportedly leaked sensitive data to chatgpt\",\n        \"Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of ai systems in the public sector.\",\n        \"Trojanpuzzle: Covertly poisoning code-suggestion models\",\n        \"Large language models are zero-shot clinical information extractors\",\n        \"Can we trust the evaluation on chatgpt?\",\n        \"Truenorth: Design and tool flow of a 65 mw 1 million neuron programmable neurosynaptic chip\",\n        \"Safe reinforcement learning via shielding\",\n        \"Generating natural language adversarial examples\",\n        \"Types of out-of-distribution texts and how to detect them\",\n        \"Training a helpful and harmless assistant with reinforcement learning from human feedback\",\n        \"Constitutional ai: Harmlessness from ai feedback\",\n        \"ediffi: Text-to-image diffusion models with an ensemble of expert denoisers\",\n        \"Specifying and evaluating quality metrics for vision-based perception systems\",\n        \"A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity\",\n        \"Lectures on runtime verification\",\n        \"Runtime verification for ltl and tltl\",\n        \"Synthetic and natural noise both break neural machine translation\",\n        \"What, indeed, is an achievable provable guarantee for learning-enabled safety critical systems\",\n        \"Formal specification for learning-enabled autonomous systems\",\n        \"Invest: A tool for the verification of invariants\",\n        \"Powerful techniques for the automatic generation of invariants\",\n        \"Abstraction and symbolic execution of deep neural networks with bayesian approximation of hidden features\",\n        \"Automated theorem proving\",\n        \"Gpt-neox-20b: An open-source autoregressive language model\",\n        \"Fast and precise certification of transformers\",\n        \"A categorical archive of chatgpt failures\",\n        \"Gpthreats-3: Is automatic malware generation a threat?\",\n        \"Large language models in machine translation\",\n        \"Language models are few-shot learners\",\n        \"Introduction to red teaming large language models (llms)\",\n        \"Attacks against machine learning — an overview\",\n        \"Scamming the scammers: Using chatgpt to reply mails for wasting time and resources\",\n        \"Tasa: Deceiving question answering models by twin answer sentences attack\",\n        \"Poisoning web-scale training datasets is practical\",\n        \"Detecting backdoor attacks on deep neural networks by activation clustering\",\n        \"How is chatgpt’s behavior changing over time?\",\n        \"Evaluating large language models trained on code\",\n        \"Holistic sentence embeddings for better out-of-distribution detection\",\n        \"The utility of chatgpt for cancer treatment information\",\n        \"Fine-tuning deteriorates general textual out-of-distribution detection by distorting task-agnostic features\",\n        \"Badnl: Backdoor attacks against nlp models with semantic-preserving improvements\",\n        \"Runtime monitoring neuron activation patterns\",\n        \"Prioritizing corners in ood detectors via symbolic string manipulation\",\n        \"Seq2sick: Evaluating the robustness of sequence-to-sequence models with adversarial examples\",\n        \"Robust neural machine translation with doubly adversarial inputs\",\n        \"Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality\",\n        \"Enhancing out-of-distribution detection in natural language understanding via implicit layer ensemble\",\n        \"Palm: Scaling language modeling with pathways\",\n        \"Deep reinforcement learning from human preferences\",\n        \"Electra: Pre-training text encoders as discriminators rather than generators\",\n        \"Training verifiers to solve math word problems\",\n        \"Certified adversarial robustness via randomized smoothing\",\n        \"Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks\",\n        \"A backdoor attack against lstm-based text classification systems\",\n        \"On the effects of transformer size on in-and out-of-domain calibration\",\n        \"Loihi: A neuromorphic manycore processor with on-chip learning\",\n        \"Z3: An efficient smt solver\",\n        \"Revisiting bitcoin’s carbon footprint\",\n        \"Calibration of pre-trained transformers\",\n        \"Toxicity in chatgpt: Analyzing persona-assigned language models\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Learning confidence for out-of-distribution detection in neural networks\",\n        \"Gpt: A family of open, compute-efficient, large language models\",\n        \"Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping\",\n        \"Glam: Efficient scaling of language models with mixture-of-experts\",\n        \"Cert-rnn: Towards certifying the robustness of recurrent neural networks\",\n        \"BARLE: Background-aware representation learning for background shift out-of-distribution detection\",\n        \"Are diffusion models vulnerable to membership inference attacks?\",\n        \"A review of user interface design for interactive machine learning\",\n        \"Gpt-4: Everything you want to know about openai’s new ai model\",\n        \"Hotflip: White-box adversarial examples for text classification\",\n        \"Study claims chatgpt is losing capability, but some experts aren’t convinced\",\n        \"Zonohedra and zonotopes\",\n        \"Taming transformers for high-resolution image synthesis\",\n        \"How trustworthy is chatgpt? the case of bibliometric analyses\",\n        \"Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity\",\n        \"Detecting adversarial samples from artifacts\",\n        \"First-Order Logic and Automated Theorem Proving, Second Edition\",\n        \"Optimal brain compression: A framework for accurate post-training quantization and pruning\",\n        \"Gptq: Accurate quantization for generative pre-trained transformers\",\n        \"Mathematical capabilities of chatgpt\",\n        \"Likelihood ratios and generative classifiers for unsupervised out-of-domain detection in task oriented dialog\",\n        \"The capacity for moral self-correction in large language models\",\n        \"Black-box generation of adversarial text sequences to evade deep learning classifiers\",\n        \"Pal: Program-aided language models, 2023\",\n        \"A comprehensive survey on safe reinforcement learning\",\n        \"The challenge of verification and testing of machine learning\",\n        \"Generative adversarial networks\",\n        \"Explaining and harnessing adversarial examples\",\n        \"Hackers are selling a service that bypasses chatgpt restrictions on malware\",\n        \"Symbolic execution for deep neural networks\",\n        \"Knowledge distillation: A survey\",\n        \"On the effectiveness of interval bound propagation for training verifiably robust models\",\n        \"A survey in adversarial defences and robustness in nlp\",\n        \"More than you’ve asked for: A comprehensive analysis of novel prompt injection threats to application-integrated large language models\",\n        \"Speaker-aware bert for multi-turn response selection in retrieval-based chatbots\",\n        \"A human-centered safe robot reinforcement learning framework with interactive behaviors\",\n        \"A review of safe reinforcement learning: Methods, theory and applications\",\n        \"Badnets: Evaluating backdooring attacks on deep neural networks\",\n        \"Knowledge distillation of large language models\",\n        \"Xai—explainable artificial intelligence\",\n        \"How close is chatgpt to human experts? comparison corpus, evaluation, and detection\",\n        \"A baseline for detecting misclassified and out-of-distribution examples in neural networks\",\n        \"Pretrained transformers improve out-of-distribution robustness\",\n        \"Outside the box: Abstraction-based monitoring of neural networks\",\n        \"Distilling the knowledge in a neural network\",\n        \"Chatgpt believes it is conscious\",\n        \"Training compute-optimal large language models\",\n        \"Evaluating large language models on a highly-specialized topic, radiation oncology physics\",\n        \"Deceiving google’s perspective api built for detecting toxic comments\",\n        \"Parameter-efficient transfer learning for nlp\",\n        \"Correction of automatic speech recognition with transformer sequence-to-sequence model\",\n        \"Lora: Low-rank adaptation of large language models\",\n        \"Toward controlled generation of text\",\n        \"Feature space singularity for out-of-distribution detection\",\n        \"Achieving verified robustness to symbol substitutions via interval bound propagation\",\n        \"Coverage-guided testing for recurrent neural networks\",\n        \"Hierarchical distribution-aware testing of deep learning\",\n        \"Safari: Versatile and efficient evaluations for robustness of interpretability\",\n        \"Neuroninspect: Detecting backdoors in neural networks via output explanations\",\n        \"Machine learning basics\",\n        \"A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability\",\n        \"Safety verification of deep neural networks\",\n        \"Bridging formal methods and&nbsp;machine learning with&nbsp;global optimisation\",\n        \"Adversarial examples are not bugs, they are features\",\n        \"Fooling explanations in text classifiers\",\n        \"Adversarial example generation with syntactically controlled paraphrase networks\",\n        \"A survey on contrastive self-supervised learning\",\n        \"Consistency analysis of chatgpt\",\n        \"Safe reinforcement learning using probabilistic shields\",\n        \"Shielded decision-making in mdps\",\n        \"Exploring chatgpt’s ability to rank content: A preliminary study on consistency with human preferences, 2023\",\n        \"Adversarial examples for evaluating reading comprehension systems\",\n        \"Certified robustness to adversarial word substitutions\",\n        \"Draft, sketch, and prove: Guiding formal theorem provers with informal proofs\",\n        \"Is chatgpt a good translator? a preliminary study\",\n        \"Is bert really robust? a strong baseline for natural language attack on text classification and entailment\",\n        \"Ammus: A survey of transformer-based pretrained models in natural language processing\",\n        \"Changing the nature of ai research\",\n        \"Llm-assisted generation of hardware assertions\",\n        \"Exploiting programmatic behavior of llms: Dual-use through standard security attacks\",\n        \"The ethics of ai-generated maps: A study of dalle 2 and implications for cartography\",\n        \"Scaling laws for neural language models\",\n        \"Gpt-4 passes the bar exam\",\n        \"How secure is code generated by chatgpt?\",\n        \"Data and fair use\",\n        \"Popqorn: Quantifying robustness of recurrent neural networks\",\n        \"Generating images with multimodal language models\",\n        \"Adversarial examples for natural language classification problems\",\n        \"Syntax-guided controlled generation of paraphrases\",\n        \"Weight poisoning attacks on pretrained models\",\n        \"Assessing robustness of text classification through maximal safe radius computation\",\n        \"Compilers: principles, techniques, and tools\",\n        \"Illustrating reinforcement learning from human feedback (rlhf)\",\n        \"Albert: A lite bert for self-supervised learning of language representations\",\n        \"Mixout: Effective regularization to finetune large-scale pretrained language models\",\n        \"Can an artificial intelligence chatbot be the author of a scholarly article?\",\n        \"Aligning text-to-image models using human feedback\",\n        \"Misinformation has high perplexity\",\n        \"Learning from tay’s introduction\",\n        \"Phrase-level textual adversarial attack with label preservation\",\n        \"Gshard: Scaling giant models with conditional computation and automatic sharding\",\n        \"BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension\",\n        \"Multi-step jailbreaking privacy attacks on chatgpt\",\n        \"Halueval: A large-scale hallucination evaluation benchmark for large language models\",\n        \"Textbugger: Generating adversarial text against real-world applications\",\n        \"Pretrained language models for text generation: A survey\",\n        \"Hidden backdoors in human-centric language models\",\n        \"kfolden: k-fold ensemble for out-of-distribution detection-fold ensemble for out-of-distribution detection\",\n        \"On the decision boundary of deep neural networks\",\n        \"Deep text classification can be fooled\",\n        \"Enhancing the reliability of out-of-distribution image detection in neural networks\",\n        \"Microsoft coco: Common objects in context\",\n        \"Caire: An empathetic neural chatbot\",\n        \"Algorithms for verifying deep neural networks\",\n        \"Evaluating the logical reasoning ability of chatgpt and gpt-4\",\n        \"Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation\",\n        \"Energy-based out-of-distribution detection\",\n        \"Self-supervised learning: Generative or contrastive\",\n        \"Summary of chatgpt/gpt-4 research and perspective towards the future of large language models\",\n        \"Roberta: A robustly optimized bert pretraining approach\",\n        \"Post-training quantization for vision transformer\",\n        \"Deid-gpt: Zero-shot medical text de-identification by gpt-4\",\n        \"Generate your counterfactuals: Towards controlled counterfactual generation for text\",\n        \"Towards deep learning models resistant to adversarial attacks\",\n        \"On the educational impact of chatgpt: Is artificial intelligence ready to obtain a university degree?\",\n        \"The temporal logic of reactive and concurrent systems: Specification\",\n        \"Adversarial prompting for black box foundation models\",\n        \"Prover9 and mace4\",\n        \"Announcing the next wave of ai innovation with microsoft bing and edge, May 2023\",\n        \"Rethinking the role of demonstrations: What makes in-context learning work?\",\n        \"Differentiable abstract interpretation for provably robust neural networks\",\n        \"Generalizable adversarial examples detection based on bi-model decision mismatch\",\n        \"Up or down? adaptive rounding for post-training quantization\",\n        \"Exploiting machine learning to subvert your spam filter\",\n        \"Wormgpt: New ai tool allows cybercriminals to launch sophisticated cyber attacks\",\n        \"Lever: Learning to verify language-to-code generation with execution\",\n        \"Glide: Towards photorealistic image generation and editing with text-guided diffusion models\",\n        \"Adversarial nli: A new benchmark for natural language understanding\",\n        \"GPT-4 Technical Report\",\n        \"Training language models to follow instructions with human feedback\",\n        \"Unifying large language models and knowledge graphs: A roadmap, 2023\",\n        \"Deep learning for anomaly detection: A review\",\n        \"nuqmm: Quantized matmul for efficient inference of large-scale generative language models\",\n        \"The carbon footprint of machine learning training will plateau, then shrink\",\n        \"Examining zero-shot vulnerability repair with large language models\",\n        \"To chatgpt, or not to chatgpt: That is the question!\",\n        \"Instruction tuning with gpt-4\",\n        \"Glove: Global vectors for word representation\",\n        \"Ignore previous prompt: Attack techniques for language models\",\n        \"Revisiting mahalanobis distance for transformer-based out-of-domain detection\",\n        \"safety analysis in the era of large language models: a case study of stpa using chatgpt\",\n        \"Learning to generate reviews and discovering sentiment\",\n        \"Improving language understanding by generative pre-training\",\n        \"Scaling language models: Methods, analysis & insights from training gopher\",\n        \"Exploring the limits of transfer learning with a unified text-to-text transformer\",\n        \"Is reinforcement learning (not) for natural language processing?: Benchmarks, baselines, and building blocks for natural language policy optimization\",\n        \"Hierarchical text-conditional image generation with clip latents\",\n        \"Zero-shot text-to-image generation\",\n        \"Testing the reliability of chatgpt for text annotation and classification: A cautionary remark\",\n        \"Likelihood ratios for out-of-distribution detection\",\n        \"Generating natural language adversarial examples through probability weighted word saliency\",\n        \"Pangu-σ𝜎\\\\sigma: Towards trillion parameter language model with sparse heterogeneous computing\",\n        \"why should I trust you?\\\": Explaining the predictions of any classifier\",\n        \"Discrete variational autoencoders\",\n        \"High-resolution image synthesis with latent diffusion models\",\n        \"Reachability analysis of deep neural networks with provable guarantees\",\n        \"Global robustness evaluation of deep neural networks with provable guarantees for the hamming distance\",\n        \"Transfer learning in natural language processing\",\n        \"Conversion of continuous-valued deep networks to efficient event-driven networks for image classification\",\n        \"The self-perception and political biases of chatgpt\",\n        \"Scalable polyhedral verification of recurrent neural networks\",\n        \"Photorealistic text-to-image diffusion models with deep language understanding\",\n        \"Towards crafting text adversarial samples\",\n        \"Lost at c: A user study on the security implications of large language model code assistants\",\n        \"Bloom: A 176b-parameter open-access multilingual language model\",\n        \"Proximal policy optimization algorithms\",\n        \"Senate judiciary subcommittee hearing on oversight of ai\",\n        \"Towards verified artificial intelligence\",\n        \"Talking about large language models\",\n        \"Backdoor pre-trained models can transfer to all\",\n        \"Enhancing the generalization for intent classification and out-of-domain detection in slu\",\n        \"Robustness verification for transformers\",\n        \"Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion\",\n        \"Retrieval augmentation reduces hallucination in conversation\",\n        \"Certifying some distributional robustness with principled adversarial training\",\n        \"Understanding measures of uncertainty for adversarial example detection\",\n        \"Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model\",\n        \"An analysis of the automatic bug fixing performance of chatgpt\",\n        \"Alexatm 20b: Few-shot learning using a large-scale multilingual seq2seq model\",\n        \"Rickrolling the artist: Injecting invisible backdoors into text-guided image generation models\",\n        \"Safety assessment of chinese large language models\",\n        \"Testing deep neural networks\",\n        \"Structural test coverage criteria for deep neural networks\",\n        \"Concolic testing for deep neural networks\",\n        \"Intriguing properties of neural networks\",\n        \"Natural language processing for aviation safety reports: From classification to interactive analysis\",\n        \"Stanford alpaca: An instruction-following llama model, 2023\",\n        \"Galactica: A large language model for science\",\n        \"Defending against patch-based backdoor attacks on self-supervised learning\",\n        \"Benchmarking large language models for automated verilog rtl code generation\",\n        \"Lamda: Language models for dialog applications\",\n        \"Fever: A large-scale dataset for fact extraction and verification\",\n        \"Llama: Open and efficient foundation language models\",\n        \"Survey on virtual assistant: Google assistant, siri, cortana, alexa\",\n        \"Understanding individual and team-based human factors in detecting deepfake texts\",\n        \"An automata-theoretic approach to automatic program verification\",\n        \"Attention is all you need\",\n        \"Does ibp scale?\",\n        \"Adversarial glue: A multi-task benchmark for robustness evaluation of language models\",\n        \"Towards verifying the geometric robustness of large-scale neural networks\",\n        \"Kernel fusion: An effective method for better power efficiency on multithreaded gpu\",\n        \"On the robustness of chatgpt: An adversarial and out-of-distribution perspective\",\n        \"Certified robustness to word substitution attack with differential privacy\",\n        \"Self-consistency improves chain of thought reasoning in language models\",\n        \"Robust machine comprehension models via adversarial training\",\n        \"Leveraging large language models to power chatbots for collecting user self-reported data\",\n        \"Chain of thought prompting elicits reasoning in large language models\",\n        \"Evaluating the robustness of neural networks: An extreme value theory approach\",\n        \"Large language models are reasoners with self-verification\",\n        \"Neural comprehension: Language models with compiled neural networks\",\n        \"Feature-guided black-box safety testing of deep neural networks\",\n        \"Fundamental limitations of alignment in large language models\",\n        \"Fast is better than free: Revisiting adversarial training\",\n        \"Optimising event-driven spiking neural network with regularisation and cutoff\",\n        \"A little energy goes a long way: Build an energy-efficient, accurate spiking neural network from convolutional neural network\",\n        \"Chatgpt or grammarly? evaluating chatgpt on grammatical error correction benchmark\",\n        \"Lamini-lm: A diverse herd of distilled models from large-scale instructions\",\n        \"A game-based approximate verification of deep neural networks with provable guarantees\",\n        \"Bloomberggpt: A large language model for finance\",\n        \"Better aligning text-to-image models with human preference\",\n        \"Autoformalization with large language models\",\n        \"Explainable ai: A brief survey on history, research areas, approaches and challenges\",\n        \"A deep generative distance-based classifier for out-of-domain detection with mahalanobis space\",\n        \"Adversarial attacks and defenses in images, graphs and text: A review\",\n        \"Imagereward: Learning and evaluating human preferences for text-to-image generation\",\n        \"Quantifying safety risks of deep neural networks\",\n        \"Yandex/yalm-100b: Pretrained language model with 100b parameters\",\n        \"Harnessing the power of llms in practice: A survey on chatgpt and beyond\",\n        \"Generalized out-of-distribution detection: A survey\",\n        \"Be careful about poisoned word embeddings: Exploring the vulnerability of the embedding layers in nlp models\",\n        \"Chinese tech giant baidu just released its answer to chatgpt, Mar 2023\",\n        \"Xlnet: Generalized autoregressive pretraining for language understanding\",\n        \"React: Synergizing reasoning and acting in language models\",\n        \"Zeroquant: Efficient and affordable post-training quantization for large-scale transformers\",\n        \"Safer: A structure-free approach for certified robustness to adversarial word substitutions\",\n        \"Complementary explanations for effective in-context learning\",\n        \"D2u: Distance-to-uniform learning for out-of-scope detection\",\n        \"Scaling autoregressive models for content-rich text-to-image generation\",\n        \"Certified robustness to text adversarial attacks by randomized [mask]\",\n        \"Pangu-α𝛼\\\\alpha: Large-scale autoregressive pretrained chinese language models with auto-parallel computation\",\n        \"Modeling discriminative representations for out-of-domain detection with supervised contrastive learning\",\n        \"Model-agnostic reachability analysis on deep neural networks\",\n        \"Reachability analysis of neural network control systems\",\n        \"PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization\",\n        \"Opt: Open pre-trained transformer language models\",\n        \"Benchmarking large language models for news summarization\",\n        \"Certified robustness to programmable transformations in lstms\",\n        \"Can chatgpt-like generative models guarantee factual accuracy? on the mistakes of new generation search engines\",\n        \"A survey of large language models\",\n        \"Baylime: Bayesian local interpretable model-agnostic explanations\",\n        \"Detecting operational adversarial examples for reliable deep learning\",\n        \"Generating natural adversarial examples\",\n        \"Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert\",\n        \"A comprehensive survey on pretrained foundation models: A history from bert to chatgpt\",\n        \"Contrastive out-of-distribution detection for pretrained transformers\",\n        \"Knn-contrastive learning for out-of-domain intent classification\",\n        \"Spikegpt: Generative pre-trained language model with spiking neural networks\",\n        \"Fine-tuning language models from human preferences\"\n    ],\n    \"reasoning\": \"Selected these 360 references because they represent foundational work and recent advances in A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}