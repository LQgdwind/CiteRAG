{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 57 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Cooperation or Competition: Avoiding Player Domination for Multi-Target Robustness via Adaptive Budgets\n\nPaper Abstract: Abstract Despite incredible advances, deep learning has been shown to be susceptible to adversarial attacks. Numerous approaches have been proposed to train robust networks both empirically and certifiably. However, most of them defend against only a single type of attack, while recent work takes steps forward in defending against multiple attacks. In this paper, to understand multi-target robustness, we view this problem as a bargaining game in which different players (adversaries) negotiate to reach an agreement on a joint direction of parameter updating. We identify a phenomenon named player domination in the bargaining game, namely that the existing max-based approaches, such as MAX and MSD, do not converge. Based on our theoretical analysis, we design a novel framework that adjusts the budgets of different adversaries to avoid any player dominance. Experiments on standard benchmarks show that employing the proposed framework to the existing approaches significantly advances multi-target robustness.\n\n{retrieved_text}\n\nGenerate exactly 57 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 57\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples\",\n        \"Adversarial training and provable defenses: Bridging the gap\",\n        \"Decision-based adversarial attacks: Reliable attacks against black-box machine learning models\",\n        \"Accurate, reliable and fast robustness evaluation\",\n        \"Towards evaluating the robustness of neural networks\",\n        \"Class-aware robust adversarial training for object detection\",\n        \"Provable robustness against all adversarial lpsubscriptùëôùëùl_{p}-perturbations for p‚â•1ùëù1p\\\\geq 1\",\n        \"Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks\",\n        \"Imagenet: A large-scale hierarchical image database\",\n        \"Adaptive Subgradient Methods for Online Learning and Stochastic Optimization\",\n        \"A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations\",\n        \"Intelligent driving intelligence test for autonomous vehicles with naturalistic and adversarial environment\",\n        \"Fast and reliable evaluation of adversarial robustness with minimum-margin attack\",\n        \"Explaining and Harnessing Adversarial Examples\",\n        \"Deep residual learning for image recognition\",\n        \"Fooling detection alone is not enough: Adversarial attack against multiple object tracking\",\n        \"Transfer of Adversarial Robustness Between Perturbation Types\",\n        \"Adversarial Logit Pairing\",\n        \"Adam: A method for stochastic optimization\",\n        \"Learning multiple layers of features from tiny images\",\n        \"Adversarial examples in the physical world\",\n        \"Gradient-based learning applied to document recognition\",\n        \"Nattack: Learning the distributions of adversarial examples for an improved black-box attack on deep neural networks\",\n        \"Towards deep learning models resistant to adversarial attacks\",\n        \"Adversarial Robustness Against the Union of Multiple Perturbation Models\",\n        \"Logit pairing methods can fool gradient-based attacks\",\n        \"Mixup inference: Better exploiting mixup to defend adversarial attacks\",\n        \"Bag of tricks for adversarial training\",\n        \"Boosting adversarial training with hypersphere embedding\",\n        \"Distillation as a defense to adversarial perturbations against deep neural networks\",\n        \"PyTorch: An Imperative Style, High-Performance Deep Learning Library\",\n        \"Certified Defenses against Adversarial Examples\",\n        \"A stochastic approximation method\",\n        \"Towards the first adversarially robust neural network model on MNIST\",\n        \"Are adversarial examples inevitable?\",\n        \"Informative dropout for robust representation learning: A shape-bias perspective\",\n        \"A disciplined approach to neural network hyper-parameters: Part 1 - learning rate, batch size, momentum, and weight decay\",\n        \"Intriguing properties of neural networks\",\n        \"Chapter 35 Cooperative models of bargaining\",\n        \"Adversarial Training and Robustness for Multiple Perturbations\",\n        \"Ensemble adversarial training: Attacks and defenses\",\n        \"Robustness May Be at Odds with Accuracy\",\n        \"Once-for-all adversarial training: In-situ tradeoff between robustness and accuracy for free\",\n        \"Self-ensemble adversarial training for improved robustness\",\n        \"Probabilistic margins for instance reweighting in adversarial training\",\n        \"Searching privately by imperceptible lying: A novel private hashing method with differential privacy\",\n        \"An adversarial domain adaptation network for cross-domain fine-grained recognition\",\n        \"Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope\",\n        \"Adversarial weight perturbation helps robust generalization\",\n        \"Adversarial weight perturbation improves generalization in graph neural network\",\n        \"Retrievalguard: Provably robust 1-nearest neighbor image retrieval\",\n        \"Building robust ensembles via margin boosting\",\n        \"You only propagate once: Accelerating adversarial training via maximal principle\",\n        \"Theoretically principled trade-off between robustness and accuracy\",\n        \"Attacks which do not kill training make adversarial learning stronger\",\n        \"Adversarial robustness through the lens of causality\",\n        \"Efficient adversarial training with transferable adversarial examples\"\n    ],\n    \"reasoning\": \"Selected these 57 references because they represent foundational work and recent advances in Cooperation or Competition: Avoiding Player Domination for Multi-Target Robustness via Adaptive Budgets, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}