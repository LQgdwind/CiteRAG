{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 61 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Steady-State Planning in Expected Reward Multichain MDPs\n\nPaper Abstract: Abstract The planning domain has experienced increased interest in the formal synthesis of decision-making policies. This formal synthesis typically entails finding a policy which satisfies formal specifications in the form of some well-defined logic. While many such logics have been proposed with varying degrees of expressiveness and complexity in their capacity to capture desirable agent behavior, their value is limited when deriving decision-making policies which satisfy certain types of asymptotic behavior in general system models. In particular, we are interested in specifying constraints on the steady-state behavior of an agent, which captures the proportion of time an agent spends in each state as it interacts for an indefinite period of time with its environment. This is sometimes called the average or expected behavior of the agent and the associated planning problem is faced with significant challenges unless strong restrictions are imposed on the underlying model in terms of the connectivity of its graph structure. In this paper, we explore this steady-state planning problem that consists of deriving a decision-making policy for an agent such that constraints on its steady-state behavior are satisfied. A linear programming solution for the general case of multichain Markov Decision Processes (MDPs) is proposed and we prove that optimal solutions to the proposed programs yield stationary policies with rigorous guarantees of behavior.\n\n{retrieved_text}\n\nGenerate exactly 61 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 61\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"The steady-state control problem for Markov decision processes\",\n        \"Constrained Markov decision processes with total cost criteria: Lagrangian approach and dual linear program\",\n        \"Constrained Markov decision processes\",\n        \"Constrained Markov decision processes with total expected cost criteria\",\n        \"Steady-state policy synthesis in multichain Markov decision processes\",\n        \"Formal synthesis of control policies for continuous time markov processes from time-bounded temporal logic specifications\",\n        \"Confronting Space Debris: Strategies and Warnings from Comparable Examples Including Deepwater Horizon\",\n        \"Heuristic search planning with multi-objective probabilistic LTL constraints\",\n        \"Dynamic programming and optimal control, Vol. 2\",\n        \"Introduction to Linear Optimization (1st edition)\",\n        \"An online actor–critic algorithm with function approximation for constrained Markov decision processes\",\n        \"Markov decision processes with asymptotic average failure rate constraint\",\n        \"Non-ergodic Markov decision processes with a constraint on the asymptotic failure rate: general class of policies\",\n        \"Planning for LTLf /LDLf goals in non-Markovian fully observable nondeterministic domains\",\n        \"Experiments on graph clustering algorithms\",\n        \"OpenAI Gym\",\n        \"Strong fully observable non-deterministic planning with LTL and LTLf goals\",\n        \"The complexity of probabilistic verification\",\n        \"Les problèmes de décisions séquentielles\",\n        \"Two-player game structures for generalized planning and agent composition\",\n        \"Multichain Markov renewal programs\",\n        \"Finite State Markovian Decision Processes\",\n        \"Cooperative epistemic multi-agent planning with implicit coordination\",\n        \"Adaptive computation of optimal nonrandomized policies in constrained average-reward MDPs\",\n        \"Constrained discounted Markov decision processes and Hamiltonian cycles\",\n        \"An Introduction to Probability Theory and its Applications (3rd edition)., Vol. 1\",\n        \"Stochastic Processes: Theory for Applications\",\n        \"Graph implementations for nonsmooth convex programs\",\n        \"CVX: Matlab software for disciplined convex programming, version 2.1.\",\n        \"Probabilistic motion planning under temporal tasks and soft constraints\",\n        \"Exploring network structure, dynamics, and function using networkx\",\n        \"Strategic planning through model checking of atl formulae\",\n        \"Safe autonomy under perception uncertainty using chance-constrained temporal logic\",\n        \"Linear programming and finite Markovian control problems\",\n        \"Finite Markov chains\",\n        \"Achieving target state-action frequencies in multichain average-reward Markov decision processes\",\n        \"Automated verification and strategy synthesis for probabilistic systems\",\n        \"A novel Q-learning algorithm with function approximation for constrained Markov decision processes\",\n        \"Optimal flow control of a class of queueing networks in equilibrium\",\n        \"Robust motion planning employing signal temporal logic\",\n        \"Linear programming and sequential decisions\",\n        \"Correct-by-construction adaptive cruise control: Two approaches\",\n        \"Markov Chains\",\n        \"A bilinear programming approach for multiagent planning\",\n        \"Symbolic techniques for planning with extended goals in non-deterministic domains\",\n        \"Understanding Markov Chains: Examples and Applications\",\n        \"Markov decision processes : discrete stochastic dynamic programming\",\n        \"Randomized and past-dependent policies for Markov decision processes with multiple constraints\",\n        \"Real Analysis (4th edition)\",\n        \"Planning and decision-making for autonomous vehicles\",\n        \"New concepts in multi-user communication, Vol. 43\",\n        \"Planning for stochastic games with co-safe objectives\",\n        \"Depth-first search and linear graph algorithms\",\n        \"United states law and policy on space debris\",\n        \"Occupation measure heuristics for probabilistic planning\",\n        \"Heuristic search in dual space for constrained stochastic shortest path problems\",\n        \"I-dual: solving constrained ssps via heuristic search in the dual space\",\n        \"Steady-state policy synthesis for verifiable control\",\n        \"TuLiP: a software toolbox for receding horizon temporal logic planning\",\n        \"Resource-driven mission-phasing techniques for constrained agents in stochastic environments\",\n        \"Timed automata approach for motion planning using metric interval temporal logic\"\n    ],\n    \"reasoning\": \"Selected these 61 references because they represent foundational work and recent advances in Steady-State Planning in Expected Reward Multichain MDPs, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}