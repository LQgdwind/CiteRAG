{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 50 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation and Beyond\n\nPaper Abstract: Abstract Logical reasoning consistently plays a fundamental and significant role in the domains of knowledge engineering and artificial intelligence. Recently, Large Language Models (LLMs) have emerged as a noteworthy innovation in natural language processing (NLP), exhibiting impressive achievements across various classic NLP tasks. However, the question of whether LLMs can effectively address the task of logical reasoning, which requires gradual cognitive inference similar to human intelligence, remains unanswered. To this end, we aim to bridge this gap and provide comprehensive evaluations in this paper. Firstly, to offer systematic evaluations, we select fifteen typical logical reasoning datasets and organize them into deductive, inductive, abductive and mixed-form reasoning settings. Considering the comprehensiveness of evaluations, we include three representative LLMs (i.e., text-davinci-003, ChatGPT and BARD) and evaluate them on all selected datasets under zero-shot, one-shot and three-shot settings. Secondly, different from previous evaluations relying only on simple metrics (e.g., accuracy), we propose fine-level evaluations from objective and subjective manners, covering both answers and explanations. These evaluations include answer correctness, explain correctness, explain completeness and explain redundancy. Additionally, to uncover the logical flaws of LLMs, problematic cases will be attributed to five error types from two dimensions, i.e., evidence selection process and reasoning process. The former one includes wrong selection and hallucination, while the latter one includes no reasoning, perspective mistake and process mistake. Thirdly, to avoid the influences of knowledge bias and concentrate purely on benchmarking the logical reasoning capability of LLMs, we propose a new dataset with neutral content. It contains 3,000 samples and covers deductive, inductive and abductive settings. Based on the in-depth evaluations, this paper finally forms a general evaluation scheme of logical reasoning capability from six dimensions (i.e., Correct, Rigorous, Self-aware, Active, Oriented and No hallucination). It reflects the pros and cons of LLMs and gives guiding directions for future works.\n\n{retrieved_text}\n\nGenerate exactly 50 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 50\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Dr-prolog: A system for defeasible reasoning with rules and ontologies on the semantic web\",\n        \"A novel combination of answer set programming with description logics for the semantic web\",\n        \"Contrastive graph representations for logical formulas embedding\",\n        \"Towards high-order complementary recommendation via logical reasoning network\",\n        \"Incorporating context graph with logical reasoning for inductive relation prediction\",\n        \"Multi-hop reasoning question generation and its application\",\n        \"Logical reasoning in formal and everyday reasoning tasks\",\n        \"Logical reasoning over natural language as knowledge representation: A survey\",\n        \"Instruction tuning with GPT-4\",\n        \"A survey of large language models\",\n        \"Will affective computing emerge from foundation models and general artificial intelligence? A first evaluation of chatgpt\",\n        \"A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity\",\n        \"Chatgpt is a knowledgeable but inexperienced solver: An investigation of commonsense problem in large language models\",\n        \"Mathprompter: Mathematical reasoning using large language models\",\n        \"Abductive and inductive reasoning: background and issues\",\n        \"Training language models to follow instructions with human feedback\",\n        \"Palm 2 technical report\",\n        \"Is chatgpt a general-purpose natural language processing task solver?\",\n        \"Chatlog: Recording and analyzing chatgpt across time\",\n        \"C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models\",\n        \"Benchmarking large language models for news summarization\",\n        \"Inductive relation prediction with logical reasoning using contrastive representations\",\n        \"Line: Logical query reasoning over hierarchical knowledge graphs\",\n        \"Rlogic: Recursive logical rule learning from knowledge graphs\",\n        \"Deductive reasoning\",\n        \"Anatomy of deductive reasoning\",\n        \"Relations between inductive reasoning and deductive reasoning.\",\n        \"Nature language reasoning, a survey\",\n        \"Abductive inference: Computation, philosophy, technology\",\n        \"Abductive, presumptive and plausible arguments\",\n        \"Explaining answers with entailment trees\",\n        \"FOLIO: natural language reasoning with first-order logic\",\n        \"Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge\",\n        \"CLUTRR: A diagnostic benchmark for inductive reasoning from text\",\n        \"Reclor: A reading comprehension dataset requiring logical reasoning\",\n        \"Logiqa: A challenge dataset for machine reading comprehension with logical reasoning\",\n        \"Evaluating the logical reasoning ability of chatgpt and GPT-4\",\n        \"Towards ai-complete question answering: A set of prerequisite toy tasks\",\n        \"Transformers as soft reasoners over language\",\n        \"Abductive commonsense reasoning\",\n        \"Abductionrules: Training transformers to explain unexpected inputs\",\n        \"Proofwriter: Generating implications, proofs, and abductive statements over natural language\",\n        \"Learning reasoning strategies in end-to-end differentiable proving\",\n        \"Merit: Meta-path guided contrastive learning for logical reasoning\",\n        \"A survey for in-context learning\",\n        \"Self-adaptive in-context learning\",\n        \"Chain-of-thought prompting elicits reasoning in large language models\",\n        \"A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level\",\n        \"Survey of hallucination in natural language generation\",\n        \"SenticNet 7: A commonsense-based neurosymbolic AI framework for explainable sentiment analysis\"\n    ],\n    \"reasoning\": \"Selected these 50 references because they represent foundational work and recent advances in Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation and Beyond, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}