{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 221 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Trustworthy Representation Learning Across Domains\n\nPaper Abstract: Abstract As AI systems have obtained significant performance to be deployed widely in our daily live and human society, people both enjoy the benefits brought by these technologies and suffer many social issues induced by these systems. To make AI systems good enough and trustworthy, plenty of researches have been done to build guidelines for trustworthy AI systems. Machine learning is one of the most important parts for AI systems and representation learning is the fundamental technology in machine learning. How to make the representation learning trustworthy in real-world application, e.g., cross domain scenarios, is very valuable and necessary for both machine learning and AI system fields. Inspired by the concepts in trustworthy AI, we proposed the first trustworthy representation learning across domains framework which includes four concepts, i.e, robustness, privacy, fairness, and explainability, to give a comprehensive literature review on this research direction. Specifically, we first introduce the details of the proposed trustworthy framework for representation learning across domains. Second, we provide basic notions and comprehensively summarize existing methods for the trustworthy framework from four concepts. Finally, we conclude this survey with insights and discussions on future research directions.\n\n{retrieved_text}\n\nGenerate exactly 221 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 221\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A completed modeling of local binary pattern operator for texture classification\",\n        \"Object recognition from local scale-invariant features\",\n        \"Histograms of oriented gradients for human detection\",\n        \"A survey on deep learning: Algorithms, techniques, and applications\",\n        \"Deep learning for visual understanding: A review\",\n        \"Convolutional networks for images, speech, and time series\",\n        \"Serial order: A parallel distributed processing approach\",\n        \"The graph neural network model\",\n        \"Generative adversarial networks\",\n        \"Attention is all you need\",\n        \"A style-based generator architecture for generative adversarial networks\",\n        \"Learning implicit functions for topology-varying dense 3d shape correspondence\",\n        \"Decaf: A deep convolutional activation feature for generic visual recognition\",\n        \"Domain generalization: A survey\",\n        \"Deep visual domain adaptation: A survey\",\n        \"Generalizing to unseen domains: A survey on domain generalization\",\n        \"Benchmarking neural network robustness to common corruptions and perturbations\",\n        \"Do imagenet classifiers generalize to imagenet?\",\n        \"Learning and transferring mid-level image representations using convolutional neural networks\",\n        \"How transferable are features in deep neural networks?\",\n        \"Learning transferable features with deep adaptation networks\",\n        \"Simultaneous deep transfer across domains and tasks\",\n        \"Conditional adversarial domain adaptation\",\n        \"Information technology-artificial intelligence-overview of trustworthiness in artificial intelligence\",\n        \"Ethics guidelines for trustworthy ai\",\n        \"Trustworthy ai: From principles to practices\",\n        \"Trustworthy artificial intelligence: a review\",\n        \"Explaining and harnessing adversarial examples\",\n        \"Deep inside convolutional networks: Visualising image classification models and saliency maps\",\n        \"Explainable deep classification models for domain generalization\",\n        \"How do fairness definitions fare? examining public attitudes towards algorithmic definitions of fairness\",\n        \"A survey on bias and fairness in machine learning\",\n        \"Fairness through awareness\",\n        \"Equality of opportunity in supervised learning\",\n        \"Counterfactual fairness\",\n        \"Trustworthy ai: A computational perspective\",\n        \"Trustworthy artificial intelligence\",\n        \"A review of single-source deep unsupervised visual domain adaptation\",\n        \"A review of domain adaptation without target labels\",\n        \"A broader study of cross-domain few-shot learning\",\n        \"Cross-domain graph convolutions for adversarial unsupervised domain adaptation\",\n        \"Domain generalization with adversarial feature learning\",\n        \"Federated adversarial domain adaptation\",\n        \"Continual learning for domain adaptation in chest x-ray classification\",\n        \"Geodesic flow kernel for unsupervised domain adaptation\",\n        \"Unsupervised domain adaptation by backpropagation\",\n        \"Maximum classifier discrepancy for unsupervised domain adaptation\",\n        \"Learning invariant representations and risks for semi-supervised domain adaptation\",\n        \"Partial adversarial domain adaptation\",\n        \"Open set domain adaptation\",\n        \"Towards novel target discovery through open-set domain adaptation\",\n        \"Universal domain adaptation\",\n        \"Domain consensus clustering for universal domain adaptation\",\n        \"Reusing the task-specific classifier as a discriminator: Discriminator-free adversarial domain adaptation\",\n        \"Cross-domain gradient discrepancy minimization for unsupervised domain adaptation\",\n        \"Drop to adapt: Learning discriminative features for unsupervised domain adaptation\",\n        \"Deep coral: Correlation alignment for deep domain adaptation\",\n        \"Implicit semantic response alignment for partial domain adaptation\",\n        \"Adversarial reweighting for partial domain adaptation\",\n        \"A balanced and uncertainty-aware approach for partial domain adaptation\",\n        \"Partial transfer learning with selective adversarial networks\",\n        \"On the effectiveness of image rotation for open set domain adaptation\",\n        \"Progressive graph learning for open-set domain adaptation\",\n        \"Exploring category-agnostic clusters for open-set domain adaptation\",\n        \"Learning factorized representations for open-set domain adaptation\",\n        \"Learning to detect open classes for universal domain adaptation\",\n        \"Ovanet: One-vs-all network for universal domain adaptation\",\n        \"Geometric anchor correspondence mining with uncertainty modeling for universal domain adaptation\",\n        \"Self-supervised universal domain adaptation with adaptive memory separation\",\n        \"Analysis of representations for domain adaptation\",\n        \"Deep domain confusion: Maximizing for domain invariance\",\n        \"Bridging theory and algorithm for domain adaptation\",\n        \"Deep transfer learning with joint adaptation networks\",\n        \"Gcan: Graph convolutional adversarial network for unsupervised domain adaptation\",\n        \"Adversarial discriminative domain adaptation\",\n        \"Gradually vanishing bridge for adversarial domain adaptation\",\n        \"A survey of unsupervised domain adaptation for visual recognition\",\n        \"Optimal kernel choice for large-scale two-sample tests\",\n        \"Unsupervised domain adaptation with residual transfer networks\",\n        \"Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation\",\n        \"Deep unsupervised convolutional domain adaptation\",\n        \"Minimal-entropy correlation alignment for unsupervised deep domain adaptation\",\n        \"Joint domain alignment and discriminative feature learning for unsupervised deep domain adaptation\",\n        \"Central moment discrepancy (cmd) for domain-invariant representation learning\",\n        \"Homm: Higher-order moment matching for unsupervised domain adaptation\",\n        \"Wasserstein distance guided representation learning for domain adaptation\",\n        \"Resource efficient domain adaptation\",\n        \"Jensen-shannon divergence and hilbert space embedding\",\n        \"Adaptive batch normalization for practical domain adaptation\",\n        \"Domain-adversarial training of neural networks\",\n        \"Adversarial domain adaptation with domain mixup\",\n        \"Toalign: Task-oriented alignment for unsupervised domain adaptation\",\n        \"Invariance principle meets information bottleneck for out-of-distribution generalization\",\n        \"Domain generalization with mixstyle\",\n        \"Ishaan Gulrajani and David Lopez-Paz\",\n        \"Domain generalization via entropy regularization\",\n        \"Domain generalization via model-agnostic learning of semantic features\",\n        \"Generalizing across domains via cross-gradient training\",\n        \"Domain generalization via invariant feature representation\",\n        \"Learning to generate novel domains for domain generalization\",\n        \"Learning to learn single domain generalization\",\n        \"Learning to diversify for single domain generalization\",\n        \"Adversarially adaptive normalization for single domain generalization\",\n        \"Progressive domain expansion network for single domain generalization\",\n        \"Meta convolutional neural networks for single domain generalization\",\n        \"Attention consistency on visual corruptions for single-source domain generalization\",\n        \"Open domain generalization with domain-augmented meta-learning\",\n        \"Crossmatch: Cross-classifier consistency regularization for open-set single domain generalization\",\n        \"Semi-supervised domain generalization with stochastic stylematch\",\n        \"Deep domain generalization via conditional invariant adversarial networks\",\n        \"Domain generalization using a mixture of multiple latent domains\",\n        \"Model-agnostic meta-learning for fast adaptation of deep networks\",\n        \"Learning to generalize: Meta-learning for domain generalization\",\n        \"Metareg: Towards domain generalization using meta-regularization\",\n        \"Learning to learn with variational information bottleneck for domain generalization\",\n        \"Metanorm: Learning to normalize few-shot batches across domains\",\n        \"A survey on image data augmentation for deep learning\",\n        \"Adversarial attacks and defences: A survey\",\n        \"Generalizing to unseen domains via adversarial data augmentation\",\n        \"Maximum-entropy adversarial data augmentation for improved generalization and robustness\",\n        \"Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data\",\n        \"Deep domain-adversarial image generation for domain generalisation\",\n        \"Adversarial teacher-student representation learning for domain generalization\",\n        \"mixup: Beyond empirical risk minimization\",\n        \"A closer look at few-shot classification\",\n        \"Generalizing from a few examples: A survey on few-shot learning\",\n        \"A comprehensive survey of few-shot learning: Evolution, applications, challenges, and opportunities\",\n        \"Cross-domain few-shot classification via learned feature-wise transformation\",\n        \"Communication-efficient learning of deep networks from decentralized data, 2017\",\n        \"A survey on federated learning\",\n        \"Uncertainty-guided model generalization to unseen domains\",\n        \"Dataset shift in machine learning\",\n        \"Self-balanced learning for domain generalization\",\n        \"Self-challenging improves cross-domain generalization\",\n        \"Gradient matching for domain generalization\",\n        \"Fishr: Invariant gradient variances for out-of-distribution generalization\",\n        \"Supportingtrust in autonomous driving\",\n        \"Are face-detection cameras racist?\",\n        \"Adversarial attacks on medical machine learning\",\n        \"Asymmetric tri-training for unsupervised domain adaptation\",\n        \"Learning semantic representations for unsupervised domain adaptation\",\n        \"Collaborative and adversarial network for unsupervised domain adaptation\",\n        \"Cluster alignment with a teacher for unsupervised domain adaptation\",\n        \"Progressive feature alignment for unsupervised domain adaptation\",\n        \"Implicit class-conditioned domain alignment for unsupervised domain adaptation\",\n        \"Cycle self-training for domain adaptation\",\n        \"Unsupervised domain adaptation through self-supervision\",\n        \"Joint contrastive learning for unsupervised domain adaptation\",\n        \"Universal domain adaptation through self supervision\",\n        \"Cds: Cross-domain self-supervised pre-training\",\n        \"Open set domain adaptation by backpropagation\",\n        \"Attract or distract: Exploit the margin of open set\",\n        \"Separate to adapt: Open set domain adaptation via progressive separation\",\n        \"Self-supervised visual feature learning with deep neural networks: A survey\",\n        \"Unsupervised representation learning by predicting image rotations\",\n        \"Unsupervised learning of visual representations by solving jigsaw puzzles\",\n        \"Unsupervised feature learning via non-parametric instance discrimination\",\n        \"Cross-domain few-shot classification via adversarial task augmentation\",\n        \"Boosting the generalization capability in cross-domain few-shot learning via noise-enhanced supervised autoencoder\",\n        \"Switch to generalize: Domain-switch learning for cross-domain few-shot classification\",\n        \"Confess: A framework for single source cross-domain few-shot learning\",\n        \"Cross-domain few-shot learning with task-specific adapters\",\n        \"Federated learning with domain generalization\",\n        \"Feddg: Federated domain generalization on medical image segmentation via episodic learning in continuous frequency space\",\n        \"Federated multi-target domain adaptation\",\n        \"An overview of privacy in machine learning\",\n        \"Deep domain adaptation with differential privacy\",\n        \"Differentially private correlation alignment for domain adaptation\",\n        \"Towards unsupervised domain adaptation for deep face recognition under privacy constraints via federated learning\",\n        \"A privacy-preserving unsupervised domain adaptation framework for clinical text analysis\",\n        \"Privacy preserving domain adaptation for semantic segmentation of medical images\",\n        \"Partialfed: Cross-domain personalized federated learning via partial initialization\",\n        \"Adaptive federated optimization\",\n        \"Privacy-preserving transfer learning via secure maximum mean discrepancy\",\n        \"Privacy-preserving heterogeneous federated transfer learning\",\n        \"Privacy-preserving unsupervised domain adaptation in federated setting\",\n        \"Transfer learning in differential privacy’s hybrid-model\",\n        \"Fairness transferability subject to bounded distribution shift\",\n        \"Fair transfer learning with missing protected attributes\",\n        \"Robust fairness under covariate shift\",\n        \"Concrete problems in ai safety\",\n        \"Return of frustratingly easy domain adaptation\",\n        \"Improving predictive inference under covariate shift by weighting the log-likelihood function\",\n        \"Covariate shift adaptation by importance weighted cross validation\",\n        \"Covariate shift by kernel mean matching\",\n        \"On causal and anticausal learning\",\n        \"Detecting and correcting for label shift with black box predictors\",\n        \"Regularized learning for domain adaptation under label shifts\",\n        \"Learning fair and transferable representations with theoretical guarantees\",\n        \"Fairness violations and mitigation under covariate shift\",\n        \"Towards fair cross-domain adaptation via generative learning\",\n        \"Fairness-aware online meta-learning\",\n        \"Fair meta-learning for few-shot classification\",\n        \"Ensuring fairness beyond the training data\",\n        \"Federated adversarial debiasing for fair and transferable representations\",\n        \"Fairness constraints: Mechanisms for fair classification\",\n        \"Towards a rigorous science of interpretable machine learning\",\n        \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead\",\n        \"Machine learning interpretability: A survey on methods and metrics\",\n        \"Interpretability and explainability: A machine learning zoo mini-tour\",\n        \"The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery\",\n        \"Explainable supervised domain adaptation\",\n        \"Domain adversarial tangent subspace alignment for explainable domain adaptation\",\n        \"Semantic autoencoder for zero-shot learning\",\n        \"Conditional generative adversarial nets\",\n        \"Zero-vae-gan: Generating unseen features for generalized and transductive zero-shot learning\",\n        \"Leveraging the invariant side of generative zero-shot learning\",\n        \"Visualizing adapted knowledge in domain transfer\",\n        \"Visda: The visual domain adaptation challenge\",\n        \"Scaling up visual and vision-language representation learning with noisy text supervision\",\n        \"Align before fuse: Vision and language representation learning with momentum distillation\",\n        \"Learning transferable visual models from natural language supervision\",\n        \"Exploiting unlabeled data with vision and language models for object detection\",\n        \"Generating representative samples for few-shot classification\",\n        \"Adversarial feature hallucination networks for few-shot learning\",\n        \"Segment anything\",\n        \"Domain adaptation via prompt learning\",\n        \"Autolabel: Clip-based framework for open-set video domain adaptation\",\n        \"Clipood: Generalizing clip to out-of-distributions\",\n        \"Dear: Debiasing vision-language models with additive residuals\",\n        \"Contrastive language-vision ai models pretrained on web-scraped multimodal data exhibit sexual objectification bias\"\n    ],\n    \"reasoning\": \"Selected these 221 references because they represent foundational work and recent advances in Trustworthy Representation Learning Across Domains, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}