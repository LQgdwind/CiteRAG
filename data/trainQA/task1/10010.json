{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 163 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Victima: Drastically Increasing Address Translation Reach by Leveraging Underutilized Cache Resources\n\nPaper Abstract: Abstract. Address translation is a performance bottleneck in data-intensive workloads due to large datasets and irregular access patterns that lead to frequent high-latency page table walks (PTWs). PTWs can be reduced by using (i) large hardware TLBs or (ii) large software-managed TLBs. Unfortunately, both solutions have significant drawbacks: increased access latency, power and area (for hardware TLBs), and costly memory accesses, the need for large contiguous memory blocks, and complex OS modifications (for software-managed TLBs). We present Victima, a new software-transparent mechanism that drastically increases the translation reach of the processor by leveraging the underutilized resources of the cache hierarchy. The key idea of Victima is to repurpose L2 cache blocks to store clusters of TLB entries, thereby providing an additional low-latency and high-capacity component that backs up the last-level TLB and thus reduces PTWs. Victima has two main components. First, a PTW cost predictor (PTW-CP) identifies costly-to-translate addresses based on the frequency and cost of the PTWs they lead to. Leveraging the PTW-CP, Victima uses the valuable cache space only for TLB entries that correspond to costly-to-translate pages, reducing the impact on cached application data. Second, a TLB-aware cache replacement policy prioritizes keeping TLB entries in the cache hierarchy by considering (i) the translation pressure (e.g., last-level TLB miss rate) and (ii) the reuse characteristics of the TLB entries. Our evaluation results show that in native (virtualized) execution environments Victima improves average end-to-end application performance by 7.4% (28.7%) over the baseline four-level radix-tree-based page table design and by 6.2% (20.1%) over a state-of-the-art software-managed TLB, across 11 diverse data-intensive workloads. Victima delivers similar performance as a system that employs an optimistic 128K-entry L2 TLB, while avoiding the associated area and power overheads. Victima (i) is effective in both native and virtualized environments, (ii) is completely transparent to application and system software, (iii) unlike large software-managed TLBs, does not require contiguous physical allocations, (iv) is compatible with modern large page mechanisms and (iv) incurs very small area and power overheads of 0.04%percent0.040.04\\% and 0.08%percent0.080.08\\%, respectively, on a modern high-end CPU. The source code of Victima is freely available at https://github.com/CMU-SAFARI/Victima.\n\n{retrieved_text}\n\nGenerate exactly 163 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 163\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Efficient Virtual Memory for Big Memory Servers\",\n        \"Performance Analysis of the Memory Management Unit Under Scale-out Workloads\",\n        \"Translation Caching: Skip, Don’t Walk (the Page Table)\",\n        \"5 Level Paging\",\n        \"Contiguitas: the Pursuit of Physical Memory Contiguity in Datacenters\",\n        \"Radiant: Efficient Page Table Management for Tiered Memory Systems\",\n        \"Characterizing the TLB Behavior of Emerging Parallel Workloads On Chip Multiprocessors\",\n        \"Devirtualizing Memory in Heterogeneous Systems\",\n        \"Hash, Don’t Cache (the Page Table)\",\n        \"Performance ImplicatiOns of Extended Page Tables On Virtualized X86 Processors\",\n        \"A Study of Virtual Memory Usage and Implications for Large Memory\",\n        \"AMD-V Nested Paging, White Paper\",\n        \"Compute Engine: Enabling Nested Virtualization for VM Instances\",\n        \"Shared Last-Level TLBs for Chip Multiprocessors\",\n        \"Scalable Distributed Last-Level TLBs Using Low-Latency Interconnects\",\n        \"Improving GPU Multi-tenancy with Page Walk Stealing\",\n        \"RethInking TLB Designs in Virtualized Environments: A Very Large Part-of-Memory TLB\",\n        \"CSALT: Context Switch Aware Large TLB\",\n        \"Comparisons of Memory Virtualization Solutions for Architectures with Software-Managed TLBs\",\n        \"Improving Virtualization in the Presence of Software Managed Translation Lookaside Buffers\",\n        \"Design Tradeoffs for Software-Managed TLBs\",\n        \"A Look At Several Memory Management Units, TLB-Refill Mechanisms, and Page Table OrganizAtions\",\n        \"Software-Controlled Caches in the VMP Multiprocessor\",\n        \"Software Prefetching and Caching for Translation Lookaside Buffers\",\n        \"CACTI 7.0: A Tool to Model Large Caches\",\n        \"Criticality Aware Tiered Cache Hierarchy: A Fundamental Relook At Multi-Level Cache Hierarchies\",\n        \"Clearing the Clouds: A Study of Emerging Scale-Out Workloads On Modern Hardware\",\n        \"Harvesting L2 Caches in Server Processors\",\n        \"DAMOV: A New Methodology and Benchmark Suite for Evaluating Data Movement Bottlenecks\",\n        \"Domain-specialized Cache Management for Graph Analytics\",\n        \"Analysis and Optimization of the Memory Hierarchy for Graph Processing Workloads\",\n        \"Many-Core Graph Workload Analysis\",\n        \"Hermes: Accelerating Long-Latency Load Requests Via Perceptron-Based Off-Chip Load Prediction\",\n        \"Line Distillation: Increasing Cache Capacity By Filtering Unused Words in Cache Lines\",\n        \"Adaptive Spill-Receive for Robust high-performance Caching in CMPs\",\n        \"Adaptive Insertion Policies for High Performance Caching\",\n        \"A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing\",\n        \"Stream-based Memory Access Specialization for General Purpose Processors\",\n        \"The Dynamic Granularity Memory System\",\n        \"Sniper: Exploring the Level of Abstraction for Scalable and Accurate Parallel Multi-Core Simulations\",\n        \"Victima - Github Repository\",\n        \"GraphBIG: Understanding Graph Computing in the Context of Industrial Solutions\",\n        \"A Simple Synchronous Distributed-Memory Algorithm for the HPCC RandomAccess Benchmark\",\n        \"XSBench - The Development and Verification of a Performance Abstraction for Monte Carlo Reactor Analysis\",\n        \"Deep Learning Recommendation Model for Personalization and Recommendation Systems\",\n        \"GenomicsBench: A Benchmark Suite for Genomics\",\n        \"Agile Paging: Exceeding the Best of Nested and Shadow Paging\",\n        \"Intel Raptor Lake\",\n        \"Breaking the Address Translation Wall By Accelerating Memory Replays\",\n        \"Self-Paging in the Nemesis Operating System\",\n        \"Memory Coherence in Shared Virtual Memory Systems\",\n        \"Virtual Memory Primitives for User Programs\",\n        \"Machine-independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures\",\n        \"Lightweight Recoverable Virtual Memory\",\n        \"Generic Virtual Memory Management for Operating System Kernels\",\n        \"WSCLOCK – A Simple and Effective Algorithm for Virtual Memory Management\",\n        \"CRAMM: Virtual Memory Support for Garbage-Collected Applications\",\n        \"Virtual Memory\",\n        \"Virtual Memory System, 1973\",\n        \"Survey of Virtual Machine Research\",\n        \"A Comparative Study of Set Associative Memory Mapping Algorithms and Their Use for Cache and Main Memory\",\n        \"An In-Cache Address Translation Mechanism\",\n        \"A Simulation Based Study of TLB Performance\",\n        \"Architecture Support for Single Address Space Operating Systems\",\n        \"The Grand Unified Theory of Address Spaces\",\n        \"Virtual Memory in Contemporary Microprocessors\",\n        \"AVM: Application-Level Virtual Memory\",\n        \"Architectural Support for Translation Table Management in Large Address Space Machines\",\n        \"The Interaction of Architecture and Operating System Design\",\n        \"Introduction and Overview of the Multics System\",\n        \"Arm Architecture Reference Manual for A-profile Architecture\",\n        \"Intel Cascade Lake\",\n        \"Trident: Harnessing Architectural Resources for All Page Sizes in X86 Processors\",\n        \"Practical, Transparent Operating System Support for Superpages\",\n        \"Hawkeye: Efficient Fine-grained Os Support for Huge Pages\",\n        \"Translation Ranger: Operating System Support for Contiguity-Aware TLBs\",\n        \"Enhancing and Exploiting Contiguity for Fast Memory Virtualization\",\n        \"TMO: Transparent Memory Offloading in Datacenters\",\n        \"Memtrade: Marketplace for Disaggregated Memory Clouds\",\n        \"Software-Defined Far Memory in Warehouse-Scale Computers\",\n        \"Elastic Cuckoo Page Tables: Rethinking Virtual Memory Translation for Parallelism\",\n        \"Memory-Efficient Hashed Page Tables\",\n        \"Every Walk’s a Hit: Making Page Walks Single-Access Cache Hits\",\n        \"Parallel Virtualized Memory Translation with Nested Elastic Cuckoo Page Tables\",\n        \"ASID in Linux\",\n        \"Graphfire: Synergizing Fetch, Insertion, and Replacement Policies for Graph Analytics\",\n        \"High Performance Cache Replacement Using Re-Reference Interval Prediction (RRIP)\",\n        \"Neural Networks: a Comprehensive Foundation\",\n        \"Intel® 64 and ia-32 architectures software developer’s manual volume 2a: Instruction set reference\",\n        \"A Case Against (Most) Context Switches\",\n        \"XPC: Architectural Support for Secure and Efficient Cross Process Call\",\n        \"Latr: Lazy Translation Coherence\",\n        \"Stride Directed Prefetching in Scalar Processors\",\n        \"Effective Hardware-based Data Prefetching for High-performance Processors\",\n        \"Transparent Hugepage Support\",\n        \"Compendia: Reducing Virtual-Memory Costs Via Selective Densification\",\n        \"Rebooting Virtual Memory with Midgard\",\n        \"Increasing gpu translation reach by leveraging under-utilized on-chip resources\",\n        \"Ducati: High-performance address translation by extending tlb reach of gpu-accelerated systems\",\n        \"CHiRP: Control-Flow History Reuse Prediction\",\n        \"Prediction-Based Superpage-Friendly TLB Designs\",\n        \"Reducing TLB Power Requirements\",\n        \"Reducing TLB and Memory Overhead Using Online Superpage Promotion\",\n        \"Compiler-directed Physical Address Generation for Reducing dTLB Power\",\n        \"SpecTLB: A Mechanism for Speculative Address Translation\",\n        \"SIPT: Speculatively Indexed, Physically Tagged Caches\",\n        \"Concurrent Support of Multiple Page Sizes on a Skewed Associative TLB\",\n        \"Exploiting Page Table Locality for Agile TLB Prefetching\",\n        \"Morrigan: A Composite Instruction TLB Prefetcher\",\n        \"Prefetched Address Translation\",\n        \"Going the Distance for TLB Prefetching: An Application-driven Study\",\n        \"Recency-based TLB Preloading\",\n        \"Large-Reach Memory Management Unit Caches\",\n        \"Dead Page and Dead Block Predictors: Cleaning TLBs and Caches Together\",\n        \"Exploiting Parallelization On Address Translation: Shared Page Walk Cache\",\n        \"Pinning Page Structure Entries to Last-Level Cache for Fast Address Translation\",\n        \"Address Translation Conscious Caching and Prefetching for High Performance Cache Hierarchy\",\n        \"Devirtualizing Virtual Memory for Heterogeneous Systems\",\n        \"Mosaic Pages: Big TLB Reach with Small Pages\",\n        \"Utopia: Fast and Efficient Address Translation via Hybrid Flexible & Restrictive Virtual-to-Physical Address Mappings\",\n        \"Near-Memory Address Translation\",\n        \"Accelerating Pointer Chasing in 3D-stacked Memory: Challenges, Mechanisms, Evaluation\",\n        \"Mitosis: Transparently Self-Replicating Page-Tables for Large-Memory Machines\",\n        \"Do-It-Yourself Virtual Memory Translation\",\n        \"Space Efficient Hash Tables with Worst Case Constant Access Time\",\n        \"Perforated Page: Supporting Fragmented Memory Allocation for Large Pages\",\n        \"Tailored Page Sizes\",\n        \"Coordinated and Efficient Huge Page Management with Ingens\",\n        \"Tradeoffs in Supporting Two Page Sizes\",\n        \"Making Huge Pages Actually Useful\",\n        \"Large Pages and Lightweight Memory Management in Virtualized Environments: Can You Have It Both Ways?\",\n        \"Mosaic: A GPU Memory Manager with Application-Transparent Support for Multiple Page Sizes\",\n        \"Reevaluating Online Superpage Promotion with Hardware Support\",\n        \"Increasing TLB Reach Using Superpages Backed By Shadow Memory\",\n        \"Supporting Superpages in Non-Contiguous Physical Memory\",\n        \"Surpassing the TLB Performance of Superpages with Less Operating System Support\",\n        \"Supporting Superpage Allocation Without Additional Hardware Support\",\n        \"Predicting Execution Times with Partial Simulations in Virtual Memory Research: Why and How\",\n        \"General Purpose Operating System Support for Multiple Page Sizes\",\n        \"Energy-Efficient Address Translation\",\n        \"Redundant Memory Mappings for Fast Access to Large Memories\",\n        \"Hybrid TLB Coalescing: Improving TLB Translation Coverage Under Diverse Fragmented Memory Allocations\",\n        \"FlexPointer: Fast Address TranslatiOn Based On Range TLB and Tagged Pointers\",\n        \"CoLT: Coalesced Large-Reach TLBs\",\n        \"Efficient Memory Virtualization: Reducing Dimensionality of Nested Page Walks\",\n        \"Using TLB Speculation to Overcome Page Splintering in Virtual Machines\",\n        \"Accelerating Two-Dimensional Page Walks for Virtualized Systems\",\n        \"Hardware Translation Coherence for Virtualized Systems\",\n        \"BabelFish: Fusing Address Translations for Containers\",\n        \"PTEMagnet: FIne-graIned Physical Memory Reservation for Faster Page Walks in Public Clouds\",\n        \"Fast Local Page-tables for Virtualized Numa Servers with vmitosis\",\n        \"A New Perspective for Efficient Virtual-Cache Coherence\",\n        \"SEESAW: Using Superpages to Improve VIPT Caches\",\n        \"Reducing Memory Reference Energy with Opportunistic Virtual Caching\",\n        \"Virtual-Address Caches Part 1: Problems and Solutions in Uniprocessors\",\n        \"Coherency for Multiprocessor Virtual Address Caches\",\n        \"Consistency Management for Virtually Indexed Caches\",\n        \"Organization and Performance of a Two-Level Virtual-Real Cache Hierarchy\",\n        \"Enigma: Architectural and Operating System Support for Reducing the Impact of Address Translation\",\n        \"The Virtual Block Interface: A Flexible Alternative to the Conventional Virtual Memory Framework\",\n        \"PowerPC Architecture Book 2003\",\n        \"Virtual-Address Caches Part 2: Multiprocessor Issues\",\n        \"Slurm: Simple Linux Utility for Resource Management\"\n    ],\n    \"reasoning\": \"Selected these 163 references because they represent foundational work and recent advances in Victima: Drastically Increasing Address Translation Reach by Leveraging Underutilized Cache Resources, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}