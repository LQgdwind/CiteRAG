{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 497 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Unlocking the Emotional World of Visual Media:An Overview of the Science, Research, and Impact of Understanding Emotion Drawing insights from psychology, engineering, and the arts, this article provides a comprehensive overview of the field of emotion analysis in visual media, and discusses the latest research, systems, challenges, ethical implications, and potential impact of artificial emotional intelligence on society.\n\nPaper Abstract: Abstract The emergence of artificial emotional intelligence technology is revolutionizing the fields of computers and robotics, allowing for a new level of communication and understanding of human behavior that was once thought impossible. Whereas recent advancements in deep learning have transformed the field of computer vision, automated understanding of evoked or expressed emotions in visual media remains in its infancy. This foundering stems from the absence of a universally accepted definition of “emotion,” coupled with the inherently subjective nature of emotions and their intricate nuances. In this paper, we provide a comprehensive, multidisciplinary overview of the field of emotion analysis in visual media, drawing on insights from psychology, engineering, and the arts. We begin by exploring the psychological foundations of emotion and the computational principles that underpin the understanding of emotions from images and videos. We then review the latest research and systems within the field, accentuating the most promising approaches. We also discuss the current technological challenges and limitations of emotion analysis, underscoring the necessity for continued investigation and innovation. We contend that this represents a “Holy Grail” research problem in computing and delineate pivotal directions for future inquiry. Finally, we examine the ethical ramifications of emotion-understanding technologies and contemplate their potential societal impacts. Overall, this article endeavors to equip readers with a deeper understanding of the domain of emotion analysis in visual media and to inspire further research and development in this captivating and rapidly evolving field.\n\n{retrieved_text}\n\nGenerate exactly 497 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 497\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Smart speakers - Statistics & Facts\",\n        \"Artificial (emotional) intelligence\",\n        \"Automatic detection of pain from facial expressions: A survey\",\n        \"Deep facial expression recognition: A survey\",\n        \"Multiview facial expression recognition, a survey\",\n        \"Graph-based facial affect analysis: A review\",\n        \"Video-based facial micro-expression analysis: A survey of datasets, features and algorithms\",\n        \"Towards reading hidden emotions: A comparative study of spontaneous micro-expression spotting and recognition methods\",\n        \"Deep learning for micro-expression recognition: A survey\",\n        \"A survey on aspect-based sentiment classification\",\n        \"Issues and challenges of aspect-based sentiment analysis: A comprehensive survey\",\n        \"A survey of textual emotion recognition and its challenges\",\n        \"Speech emotion recognition: Emotional models, databases, features, preprocessing methods, supporting modalities, and classifiers\",\n        \"Audio features for music emotion recognition: A survey\",\n        \"Survey of deep representation learning for speech emotion recognition\",\n        \"Affective image content analysis: Two decades review and new perspectives\",\n        \"Survey on emotional body gesture recognition\",\n        \"Emotion expression in human body posture and movement: A survey on intelligible motion factors, quantification and validation\",\n        \"EEG based emotion recognition: A tutorial and review\",\n        \"Emotion recognition for everyday life using physiological signals from wearables: A systematic literature review\",\n        \"Emotion recognition using multi-modal data and machine learning techniques: A tutorial and review\",\n        \"Emotion recognition from multiple modalities: Fundamentals and methodologies\",\n        \"What lies beneath-a survey of affective theory use in computational models of emotion\",\n        \"Affective computing and sentiment analysis\",\n        \"A review of affective computing: From unimodal analysis to multimodal fusion\",\n        \"A systematic review on affective computing: Emotion models, databases, and recent advances\",\n        \"Basic Dimensions for a General Psychological Theory: Implications for Personality, Social, Environmental, and Developmental Studies\",\n        \"Toward a consensual structure of mood\",\n        \"The Biopsychology of Mood and Arousal\",\n        \"Promises and problems with the circumplex model of emotion\",\n        \"Facial expressions of emotion influence interpersonal trait inferences\",\n        \"The Expression of the Emotions in Man and Animals\",\n        \"What is an Emotion?\",\n        \"Embodying emotion\",\n        \"Universals and cultural differences in facial expressions of emotion\",\n        \"Solving the emotion paradox: Categorization and the experience of emotion\",\n        \"The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology\",\n        \"On the bipolarity of positive and negative affect\",\n        \"Emotion and Personality Vol. I. Psychological Aspects\",\n        \"Cognitive, social, and physiological determinants of emotional state\",\n        \"An Approach to Environmental Psychology\",\n        \"Core affect and the psychological construction of emotion\",\n        \"Emotional category data on images from the international affective picture system\",\n        \"Affective image classification using features inspired by psychology and art theory\",\n        \"International Affective Picture System (IAPS): Affective ratings of pictures and instruction manual\",\n        \"On shape and the computability of emotions\",\n        \"Identifying emotions aroused from paintings\",\n        \"An investigation into three visual characteristics of complex scenes that evoke human emotion\",\n        \"Probabilistic multigraph modeling for improving the quality of crowdsourced affective data\",\n        \"Development and validation of image stimuli for emotion elicitation (ISEE): A novel affective pictorial system with test-retest repeatability\",\n        \"ARBEE: Towards automated recognition of bodily expression of emotion in the wild\",\n        \"“Studying aesthetics in photographic images using a computational approach\",\n        \"Human Facial Expression: An evolutionary view. Academic press\",\n        \"“Interpretation of faces: A cross-cultural study of a prediction from fridlund’s theory\",\n        \"“Facial expressions as modes of action readiness\",\n        \"Emotion and Affective Style: Hemispheric substrates. SAGE Publications Sage CA: Los Angeles\",\n        \"“Analysis of the form of conflict reactions\",\n        \"“Clarifying the emotive functions of asymmetrical frontal cortical activity\",\n        \"“Affective incoherence: when affective concepts and embodied reactions clash\",\n        \"“Emotional expressions forecast approach-avoidance behavior\",\n        \"“Approach-avoidance movement influences the decoding of anger and fear expressions\",\n        \"“A semantic atlas of emotional concepts\",\n        \"“Emotion recognition in context\",\n        \"“Development of short forms of the empathy quotient (eq-short) and the systemizing quotient (sq-short)\",\n        \"“Latent multi-group membership graph model\",\n        \"“Muse-toolbox: The multimodal sentiment analysis continuous annotation fusion and discrete class transformation toolbox\",\n        \"“Evaluation of natural emotions using self assessment manikins\",\n        \"“Canonical time warping for alignment of human behavior\",\n        \"“Video affective content analysis: A survey of state-of-the-art methods\",\n        \"“Multimodal sentiment analysis: A systematic review of history\",\n        \"“Building a large scale dataset for image emotion recognition: The fine print and the benchmark\",\n        \"“Predicting emotions in user-generated videos\",\n        \"“Heterogeneous knowledge transfer in video emotion recognition\",\n        \"“Identifying emotions from walking using affective and deep features\",\n        \"“iMiGUE: An identity-free video dataset for micro-gesture understanding and emotion analysis\",\n        \"“The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression\",\n        \"“Deep affect prediction in-the-wild: Aff-wild database and challenge\",\n        \"“Affectnet: A database for facial expression\",\n        \"“EMOTIC: Emotions in context dataset\",\n        \"“Collecting large\",\n        \"“Context-aware emotion recognition networks\",\n        \"“DFEW: A large-scale database for recognizing dynamic facial expressions in the wild\",\n        \"“Ferv39k: A large-scale multi-scene dataset for facial expression recognition in videos\",\n        \"“Samm: A spontaneous micro-facial movement dataset\",\n        \"“Cas (me) 2: A database for spontaneous macro-expression and micro-expression spotting and recognition\",\n        \"“YouTube movie reviews: Sentiment analysis in an audio-visual context\",\n        \"“Multimodal language analysis in the wild: CMU-MOSEI dataset and interpretable dynamic fusion graph\",\n        \"Facial Action Coding System: A technique for the measurement of facial movement. Consulting Psychologists Press\",\n        \"“Recognizing action units for facial expression analysis\",\n        \"“Fully automatic facial action unit detection and temporal analysis\",\n        \"“Facial action unit detection with transformers\",\n        \"“Automatic analysis of facial actions: A survey\",\n        \"“A comprehensive survey on automatic facial action unit analysis\",\n        \"“Facial feature point detection: A comprehensive survey\",\n        \"“Facial landmark detection: A literature survey\",\n        \"“Microsoft coco: Common objects in context\",\n        \"“Deep high-resolution representation learning for human pose estimation\",\n        \"“Simple baselines for human pose estimation and tracking\",\n        \"“Integral human pose regression\",\n        \"“MEBOW: Monocular estimation of body orientation in the wild\",\n        \"“Camera distance-aware top-down approach for 3d multi-person pose estimation from a single rgb image\",\n        \"“MUG: Multi-human graph network for 3D mesh reconstruction from 2D pose\",\n        \"“SMPL: A skinned multi-person linear model\",\n        \"“Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image\",\n        \"“Emotion recognition from body movement\",\n        \"“How shall I count the ways? A method for quantifying the qualitative aspects of unscripted movement with Laban Movement Analysis\",\n        \"“Bodily communication of emotion: Evidence for extrafacial behavioral expressions and available coding systems\",\n        \"“Affective body expression perception and recognition: A survey\",\n        \"“An overview of emotion recognition from body movement\",\n        \"N. Bianchi-Berthouze\",\n        \"“Critical features for the perception of emotion from gait\",\n        \"Body Movement: Coping with the environment. Gordon and Breach Science Publishers\",\n        \"Everybody is a Body. Dog Ear Publishing\",\n        \"“How do we recognize emotion from movement? Specific motor components contribute to the recognition of each emotion\",\n        \"“Emotion regulation through movement: Unique sets of movement characteristics are associated with and enhance basic emotions\",\n        \"“A study on emotion recognition from body gestures using Kinect sensor\",\n        \"“Emotion recognition from 3D motion capture data using deep CNNs\",\n        \"“Skeleton-based emotion recognition based on two-stream self-attention enhanced spatial-temporal graph convolutional network\",\n        \"“Skeleton-based explainable bodily expressed emotion recognition through graph convolutional networks\",\n        \"“Human motions and emotions recognition inspired by LMA qualities\",\n        \"“Emotion analysis and classification: Understanding the performers’ emotions using the lma entities\",\n        \"“Laban movement analysis to classify emotions from motion\",\n        \"“Continuous body emotion recognition system during theater performances\",\n        \"“Dance emotion recognition based on Laban motion analysis using convolutional neural network and long short-term memory\",\n        \"“Laban-inspired task-constrained variable motion generation on expressive aerial robots\",\n        \"“Development of an emotional expression platform based on LMA-shape and interactive evolution computation\",\n        \"“Effort-shape and kinematic assessment of bodily expression of emotion during gait\",\n        \"Actor Training the Laban Way: An integrated approach to voice\",\n        \"“A somatic movement approach to fostering emotional resiliency through Laban Movement Analysis\",\n        \"The Moving Researcher: Laban/Bartenieff movement analysis in performing arts education and creative arts therapies. Jessica Kingsley Publishers\",\n        \"“Animation principles and Laban movement analysis: Movement frameworks for creating empathic character performances\",\n        \"“Move and be moved: The effect of moving specific movement elements on the experience of happiness\",\n        \"“Learning-based linguistic indexing of pictures with 2–d mhmms\",\n        \"Machine Learning and Statistical Modeling Approaches to Image Retrieval. Springer Science & Business Media\",\n        \"“Image retrieval: Ideas\",\n        \"“Context based emotion recognition using EMOTIC dataset\",\n        \"“Emoticon: Context-aware multimodal emotion recognition using frege’s principle\",\n        \"action recognition? a new model and the kinetics dataset\",\n        \"“Using actor portrayals to systematically study multimodal emotion expression: The gemep corpus\",\n        \"“The cultural construction of emotions\",\n        \"“Emotion perception from dynamic and static body expressions in point-light and full-light displays\",\n        \"“Gender stereotypes of emotional reactions: How we judge an emotion as valid\",\n        \"“Gender and emotion expression: A developmental contextual perspective\",\n        \"“Universals and cultural variations in 22 emotional expressions across five cultures.” Emotion\",\n        \"“Effect of acting experience on emotion expression and recognition in voice: Non-actors provide better stimuli than expected\",\n        \"“Emotional expression: Advances in basic emotion theory\",\n        \"“Actors and emotion in performance\",\n        \"“Disentangling the components of surface acting in emotion work: Experiencing emotions may be as important as regulating them\",\n        \"“On the universality and cultural specificity of emotion recognition: A meta-analysis.” Psychological Bulletin\",\n        \"What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS). Oxford University Press\",\n        \"“Cultural similarities and differences in display rules\",\n        \"“The intersection of gender-related facial appearance and facial displays of emotion\",\n        \"“Gender and culture differences in emotion.” Emotion\",\n        \"“Angry white faces: A contradiction of racial stereotypes and emotion-resembling appearance\",\n        \"“American-japanese cultural differences in judgements of expression intensity and subjective experience\",\n        \"“Perceiving through culture: The socialized attention hypothesis\",\n        \"“Which are the stimuli in facial displays of anger and happiness? configurational bases of emotion recognition.” J. Personality and Social Psychology\",\n        \"“Very first impressions.” Emotion\",\n        \"“Perceptually valid facial expressions for character-based applications\",\n        \"“Spontaneous trait inferences: Are they linked to the actor or to the action?” Personality and Social Psychology Bulletin\",\n        \"“Structural resemblance to emotional expressions predicts evaluation of emotionally neutral faces.” Emotion\",\n        \"“What emotional reactions can tell us about the nature of others: An appraisal perspective on person perception\",\n        \"“Why do fear and anger look the way they do? form and social function in facial expressions\",\n        \"“Quantifying the links between personality sub-traits and the basic emotions\",\n        \"“Personality traits and emotion regulation: A targeted review and recommendations.” Emotion\",\n        \"“Distinguishing evaluation from description in the personality-emotion relationship\",\n        \"“Personality structure: Emergence of the five-factor model\",\n        \"“The structure of phenotypic personality traits.” American Psychologist\",\n        \"“Emotion in the neutral face: A mechanism for impression formation?” Cognition & Emotion\",\n        \"“The expressive triad: Structure\",\n        \"“Personality and the enactment of emotion\",\n        \"“Personality and emotion\",\n        \"“Predicting the Big 5 personality traits from digital footprints on social media: A meta-analysis\",\n        \"The Conceptual Representation and the Measurement of Psychological Forces. Duke University Press\",\n        \"“Control theory: A useful conceptual framework for personality–social\",\n        \"“Self-discrepancy theory: What patterns of self-beliefs cause people to suffer?” in Advances in Experimental Social Psychology. Elsevier\",\n        \"“Affective style and affective disorders: Perspectives from affective neuroscience\",\n        \"The Neuropsychology of Emotion and Personality. Oxford University Press\",\n        \"“Behavioral inhibition\",\n        \"The Asymmetrical Brain. MIT Press Cambridge\",\n        \"“Anger and frontal brain activity: EEG asymmetry consistent with approach motivation despite negative affective valence\",\n        \"“Aesthetics and emotions in images\",\n        \"J. C. van Gemert\",\n        \"“Deep multimodal learning for affective analysis and retrieval\",\n        \"“Retrieving and classifying affective images via deep metric learning\",\n        \"“Multi-scale blocks based image emotion classification using multiple instance learning\",\n        \"“Recognizing induced emotions of movie audiences from multimodal information\",\n        \"“Exploring principles-of-art features for image emotion recognition\",\n        \"“Artemis: Affective language for visual art\",\n        \"“A mixed bag of emotions: Model\",\n        \"“Liris-accede: A video database for affective content analysis\",\n        \"“Continuous probability distribution prediction of image emotions via multitask shared sparse regression\",\n        \"“Predicting personalized image emotion perceptions in social networks\",\n        \"“Discrete probability distribution prediction of image emotions with shared sparse learning\",\n        \"““i have no text in my post”: Using visual hints to model user emotions in social media\",\n        \"“Interpretable aesthetic features for affective image classification\",\n        \"“Affective image classification by jointly using interpretable art features and semantic annotations\",\n        \"“Who’s afraid of itten: Using the art theory of color combination to analyze emotions in abstract paintings\",\n        \"“Sentribute: image sentiment analysis from a mid-level perspective\",\n        \"“Large-scale visual sentiment ontology and detectors using adjective noun pairs\",\n        \"“Visual affect around the world: A large-scale multilingual visual sentiment ontology\",\n        \"“A comprehensive study on mid-level representation and ensemble learning for emotional analysis of video material\",\n        \"“Imagenet classification with deep convolutional neural networks\",\n        \"“Very deep convolutional networks for large-scale image recognition\",\n        \"“Deep residual learning for image recognition\",\n        \"“Visual sentiment prediction with deep convolutional neural networks\",\n        \"“Recognition of emotions in user-generated videos with kernelized features\",\n        \"“An end-to-end visual-audio attention network for emotion recognition in user-generated videos\",\n        \"“Visual sentiment classification via low-rank regularization and label relaxation\",\n        \"“User-generated video emotion recognition based on key frames\",\n        \"“Recognition of advertisement emotions with application to computational advertising\",\n        \"“Simple but powerful\",\n        \"“Representation learning through multimodal attention and time-sync comments for affective video content analysis\",\n        \"“Emotion in context: Deep semantic feature fusion for video emotion recognition\",\n        \"“Robust image sentiment analysis using progressively trained and domain transferred deep networks\",\n        \"“From pixels to sentiment: Fine-tuning CNNs for visual sentiment prediction\",\n        \"“Joint image emotion classification and distribution learning via deep convolutional neural network\",\n        \"“A circular-structured representation for visual emotion distribution learning\",\n        \"“Stimuli-aware visual emotion analysis\",\n        \"“Chain centre loss: A psychology inspired loss function for image sentiment analysis\",\n        \"“Learning spatiotemporal features with 3D convolutional networks\",\n        \"“Multimodal local-global attention network for affective video content analysis\",\n        \"“Visual sentiment analysis by attending on local image regions\",\n        \"“Boosting image sentiment analysis with visual attention\",\n        \"“Emotional attention: A study of image sentiment and visual attention\",\n        \"“Pdanet: Polarity-consistent deep attention network for fine-grained visual emotion regression\",\n        \"“Weakly supervised coupled networks for visual sentiment analysis\",\n        \"“Weakly supervised discriminate enhancement network for visual sentiment analysis\",\n        \"“Dependency exploitation: A unified CNN-RNN approach for visual emotion recognition\",\n        \"“Multi-level region-based convolutional neural network for image emotion classification\",\n        \"“Learning multi-level deep representations for image emotion classification\",\n        \"“Solver: Scene-object interrelated visual emotion reasoning network\",\n        \"“Multiscale emotion representation learning for affective image recognition\",\n        \"“Mdan: Multi-level dependent attention network for visual emotion analysis\",\n        \"“Image sentiment classification via multi-level sentiment region correlation analysis\",\n        \"“Video emotion recognition with concept selection\",\n        \"“Gla in mediaeval 2018 emotional impact of movies task\",\n        \"“Context-aware based visual-audio feature fusion for emotion recognition\",\n        \"“Deepsentibank: Visual sentiment concept classification with deep convolutional neural networks\",\n        \"“Sentiment key frame extraction in user-generated micro-videos via low-rank and sparse representation\",\n        \"“Color enhanced cross correlation net for image sentiment analysis\",\n        \"“Opensmile: the munich versatile and fast open-source audio feature extractor\",\n        \"“Survey on speech emotion recognition: Features\",\n        \"“A survey on multi-task learning\",\n        \"“Facial expression recognition based on local binary patterns: A comprehensive study\",\n        \"“Graph-preserving sparse nonnegative matrix factorization with application to facial expression recognition\",\n        \"“Histograms of oriented gradients for human detection\",\n        \"“Real time facial expression recognition in video using support vector machines\",\n        \"“A survey of affect recognition methods: Audio\",\n        \"“Automatic analysis of facial affect: A survey of registration\",\n        \"“Automatic analysis of facial expressions: The state of the art\",\n        \"“Automatic facial expression analysis: A survey\",\n        \"“EmotioNet: An accurate\",\n        \"“Learning supervised scoring ensemble for emotion recognition in the wild\",\n        \"“Emotion recognition in the wild from videos using images\",\n        \"“A discriminative feature learning approach for deep face recognition\",\n        \"“Island loss for learning discriminative features in facial expression recognition\",\n        \"“Adaptive deep metric learning for identity-aware facial expression recognition\",\n        \"“Facial expression recognition based on deep evolutional spatial-temporal networks\",\n        \"“Multi-cue fusion for emotion recognition in the wild\",\n        \"“Audio-visual emotion recognition using deep transfer learning and multiple temporal models\",\n        \"“Using synthetic data to improve facial expression analysis with 3D convolutional networks\",\n        \"“Facial expression recognition with inconsistently annotated datasets\",\n        \"“Suppressing uncertainties for large-scale facial expression recognition\",\n        \"“Label distribution learning on auxiliary label space graphs for facial expression recognition\",\n        \"“Dive into ambiguity: Latent distribution mining and pairwise uncertainty estimation for facial expression recognition\",\n        \"“Understanding and mitigating annotation bias in facial expression recognition\",\n        \"“Face2exp: Combating data biases for facial expression recognition\",\n        \"“Adaptively learning facial expression representation via cf labels and distillation\",\n        \"“Region attention networks for pose and occlusion robust facial expression recognition\",\n        \"“Learning a facial expression embedding disentangled from identity\",\n        \"“Identity-and pose-robust facial expression recognition through adversarial feature learning\",\n        \"“Feature decomposition and reconstruction learning for effective facial expression recognition\",\n        \"“Facial expression recognition in the wild via deep attentive center loss\",\n        \"“Transfer: Learning relation-aware facial expression representations with transformers\",\n        \"“An image is worth 16x16 words: Transformers for image recognition at scale\",\n        \"“Classifying emotions and engagement in online learning based on a single facial expression recognition neural network\",\n        \"“Efficientnet: Rethinking model scaling for convolutional neural networks\",\n        \"“Adaptive deep disturbance-disentangled learning for facial expression recognition\",\n        \"“Bodily expression of emotion\",\n        \"C. C. van Heijnsbergen\",\n        \"“Towards the neurobiology of emotional body language\",\n        \"not facial expressions\",\n        \"“Adults’ and children’s perception of facial expressions is influenced by body postures even for dynamic stimuli\",\n        \"“Does body context affect facial emotion perception and eliminate emotional ambiguity without visual awareness?” Visual Cognition\",\n        \"“Bi-modal emotion recognition from expressive face and body gestures\",\n        \"“Cross-cultural differences in recognizing affect from body posture\",\n        \"“Recognizing emotions expressed by body pose: A biologically inspired neural model\",\n        \"“Emotion expression in body action and posture\",\n        \"“Identifying emotions from non-contact gaits information based on microsoft kinects\",\n        \"“Body expression recognition from animated 3D skeleton\",\n        \"“Take an emotion walk: Perceiving emotions from gaits using hierarchical attention pooling and affective mapping\",\n        \"“Step: Spatial temporal graph convolutional networks for emotion perception from gaits\",\n        \"“Spatial temporal graph convolutional networks for skeleton-based action recognition\",\n        \"“Learning unseen emotions from gestures via semantically-conditioned zero-shot perception with adversarial autoencoders\",\n        \"“Proxemo: Gait-based emotion learning and multi-view proxemic fusion for socially-aware robot navigation\",\n        \"“Tntc: two-stream network with transformer-based complementarity for gait-based emotion recognition\",\n        \"“Two-stream convolutional networks for action recognition in videos\",\n        \"“Temporal segment networks: Towards good practices for deep action recognition\",\n        \"S. Vijayanarasimhan\",\n        \"“Emotion recognition based on body and context fusion in the wild\",\n        \"“Emotion understanding in videos through body\",\n        \"” in Proc. IEEE Int. Conf. Automatic Face and Gesture Recognition (FG 2021)\",\n        \"“Learning transferable visual models from natural language supervision\",\n        \"“Learning emotion representations from verbal and nonverbal communication\",\n        \"“SMG: A micro-gesture dataset towards spontaneous body gestures for emotional stress state analysis\",\n        \"“Bodily expressed emotion understanding through integrating laban movement analysis\",\n        \"“Global-local attention for emotion recognition\",\n        \"“Vilt: Vision-and-language transformer without convolution or region supervision\",\n        \"“BERT: Pre-training of deep bidirectional transformers for language understanding\",\n        \"“End-to-end multimodal emotion recognition using deep neural networks\",\n        \"“An audiovisual and contextual approach for categorical and continuous emotion recognition in-the-wild\",\n        \"“Dynamic emotion modeling with learnable graphs and graph inception network\",\n        \"“Multi-task learning for multi-modal emotion recognition and sentiment analysis\",\n        \"“Learning modality-specific representations with self-supervised multi-task learning for multimodal sentiment analysis\",\n        \"“A multitask learning framework for multimodal sentiment analysis\",\n        \"“Disentangled representation learning for multimodal emotion recognition\",\n        \"“Multimodal sentiment recognition with multi-task learning\",\n        \"“Real-time video emotion recognition based on reinforcement learning and domain knowledge\",\n        \"“Multimodal and context-aware emotion perception model with multiplicative fusion\",\n        \"“Sentic blending: Scalable multimodal fusion for the continuous interpretation of semantics and sentics\",\n        \"“Tensor fusion network for multimodal sentiment analysis\",\n        \"“Efficient low-rank multimodal fusion with modality-specific factors\",\n        \"“Learning factorized multimodal representations\",\n        \"“Learning relationships between text\",\n        \"“Misa: Modality-invariant and-specific representations for multimodal sentiment analysis\",\n        \"“Momentum contrast for unsupervised visual representation learning\",\n        \"“Masked autoencoders are scalable vision learners\",\n        \"“Masked autoencoders as spatiotemporal learners\",\n        \"“Benchmarking and error diagnosis in multi-instance pose estimation\",\n        \"“Deep multi-patch aggregation network for image style\",\n        \"“The effects of explainability and causability on perception\",\n        \"A. Mojsilovic et al\",\n        \"“Explaining explanations: An overview of interpretability of machine learning\",\n        \"“Model-agnostic interpretability of machine learning\",\n        \"““Why should I trust you?” Explaining the predictions of any classifier\",\n        \"“Mixture of linear models co-supervised by deep neural networks\",\n        \"“A survey on bias and fairness in machine learning\",\n        \"“Rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers\",\n        \"“The lottery ticket hypothesis: Finding sparse\",\n        \"“Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks\",\n        \"“A survey on knowledge graphs: Representation\",\n        \"“HICEM: A high-coverage emotion model for artificial emotional intelligence\",\n        \"“Parallel massive clustering of discrete distributions\",\n        \"“Rhythmic brushstrokes distinguish van Gogh from his contemporaries: Findings via automated brushstroke extraction\",\n        \"“OSCAR: On-site composition and aesthetics feedback through exemplars for photographers\",\n        \"“Photo composition feedback and enhancement\",\n        \"“Discovering triangles in portraits for supporting photographic creation\",\n        \"“Detecting dominant vanishing points in natural scenes with application to composition-sensitive image retrieval\",\n        \"Emotional Design: Why we love (or hate) everyday things. Civitas Books\",\n        \"“Emotion regulation and psychopathology\",\n        \"Diagnostic and Statistical Manual of mental Disorders (DSM-5). American Psychiatric Association\",\n        \"“Examining emotion regulation in depression: A review and future directions\",\n        \"“Understanding positive emotion deficits in depression: From emotion preferences to emotion regulation\",\n        \"“Facial expression and emotional face recognition in schizophrenia and depression\",\n        \"“Facial expressivity in the course of schizophrenia and depression\",\n        \"L. Bernabei et al\",\n        \"“Some nonverbal aspects of depression and schizophrenia occurring during the interview\",\n        \"“Gender differences in depression: An ethological study of nonverbal behavior during interviews\",\n        \"“Psychomotor symptoms of depression\",\n        \"“Artificial intelligent system for automatic depression level analysis through visual and vocal expressions\",\n        \"“Automated depression diagnosis based on deep networks to encode facial appearance and dynamics\",\n        \"“Clinical depression detection in adolescent by face\",\n        \"“Automatic depression analysis using dynamic facial appearance descriptor and dirichlet process fisher encoding\",\n        \"“Human behaviour-based automatic depression analysis using hand-crafted statistics and deep learned spectral features\",\n        \"“A review on depression detection and diagnoses based on visual facial cues\",\n        \"“Artificial intelligence based techniques for the detection of socio-behavioral disorders: A systematic review\",\n        \"“Predicting depression\",\n        \"“Automated assessment of psychiatric disorders using speech: A systematic review\",\n        \"“A cross-modal review of indicators for depression detection systems\",\n        \"“Voice patterns in schizophrenia: A systematic review and bayesian meta-analysis\",\n        \"“Psychomotor symptoms in depression: A diagnostic\",\n        \"“Nonverbal behavior during clinical interviews: similarities and dissimilarities among schizophrenia\",\n        \"P. Harrison-Read\",\n        \"C.-M. Vazakopoulou\",\n        \"“Detecting depression severity by interpretable representations of motion dynamics\",\n        \"“Nonverbal social withdrawal in depression: Evidence from manual and automatic analyses\",\n        \"“Audiovisual behavior descriptors for depression assessment\",\n        \"“Verbal and nonverbal correlates for depression: A review\",\n        \"“Major depression: Behavioral markers of depression and recovery\",\n        \"“Social skills deficits associated with depression\",\n        \"“Ethology and psychotherapy\",\n        \"“Automatic behavior descriptors for psychological disorder analysis\",\n        \"“A review of depression and suicide risk assessment using speech analysis\",\n        \"“On the relative importance of vocal source\",\n        \"“Mono-and multi-lingual depression prediction based on speech processing\",\n        \"“Vocal-source biomarkers for depression: A link to psychomotor activity\",\n        \"“Psychomotor retardation in depression: biological underpinnings\",\n        \"D. Hadzi-Pavlovic\",\n        \"“Spatiotemporal gait patterns during over ground locomotion in major depression compared with healthy controls\",\n        \"“Gait patterns of depressed patients and normal subjects\",\n        \"“Gait unsteadiness and fall risk in two affective disorders: A preliminary study\",\n        \"“Embodiment of sadness and depression—gait patterns associated with dysphoric mood\",\n        \"“Sitting posture makes a difference—embodiment effects on depressive memory bias\",\n        \"“Upright posture improves affect and fatigue in people with depressive symptoms\",\n        \"“Investigation of associations between recurrence of major depressive disorder and spinal posture alignment: A quantitative cross-sectional study\",\n        \"“Differences and similarities in postural alterations caused by sadness and depression\",\n        \"V. Thomas-Ollivier\",\n        \"“Dual task performance of working memory and postural control in major depressive disorder\",\n        \"“Physical performance\",\n        \"“Gait characteristics in patients with major depression performing cognitive and motor tasks while walking\",\n        \"“Gait and its assessment in psychiatry\",\n        \"“Theory of mind in major depressive disorder: A meta-analysis\",\n        \"“Deficiencies in theory of mind in patients with schizophrenia\",\n        \"“The expression and experience of emotion in schizophrenia: A study of social interactions\",\n        \"“Features of vocal frequency contour and speech rhythm in bipolar disorder\",\n        \"“Analysis of running speech for the characterization of mood state in bipolar patients\",\n        \"“Analysis on speech signal features of manic patients\",\n        \"A. Muñoz-Meléndez\",\n        \"“Postural control in bipolar disorder: increased sway area and decreased dynamical complexity\",\n        \"“Contextual social cognition impairments in schizophrenia and bipolar disorder\",\n        \"“Social cognition in bipolar disorder versus schizophrenia: comparability in mental state decoding deficits\",\n        \"“Emotional experience and expression in schizophrenia and depression\",\n        \"“Stability of emotional responding in schizophrenia\",\n        \"“Fine analysis of abnormal facial expressions in chronic schizophrenic patients–a pilot study\",\n        \"“Facial expression of schizophrenic patients and their interaction partners\",\n        \"“Interaction regulations used by schizophrenic and psychosomatic patients: studies on facial behavior in dyadic interactions\",\n        \"“Facial expressivity during the clinical interview as a predictor functional disability in schizophrenia. a pilot study\",\n        \"“Is nonverbal communication disrupted in interactions involving patients with schizophrenia?” Schizophrenia Bulletin\",\n        \"“Ethological research in clinical psychiatry: the study of nonverbal behavior during interviews\",\n        \"“Nonverbal behavior during standardized interviews in patients with schizophrenia spectrum disorders\",\n        \"“Non-verbal behaviour deficits in schizophrenia: An ethological study of drug-free patients\",\n        \"“Prosodic analysis of speech and the underlying mental state\",\n        \"“Evidence for depression and schizophrenia in speech prosody\",\n        \"“Linguistic production and syntactic comprehension in schizophrenia and bipolar disorder\",\n        \"N. A. binte Abdul Rashid\",\n        \"“Acoustic and temporal analysis of speech: A potential biomarker for schizophrenia\",\n        \"“Postural changes in different stages of schizophrenia is associated with inflammation and pain: A cross-sectional observational study\",\n        \"“Motor deficits in schizophrenia quantified by nonlinear analysis of postural sway\",\n        \"“A quantitative measure of postural sway deficits in schizophrenia\",\n        \"“Standing postural instability in patients with schizophrenia: Relationships with psychiatric symptoms\",\n        \"“Postural stability of patients with schizophrenia during challenging sensory conditions: Implication of sensory integration for postural control\",\n        \"“Quantitative analysis of ataxic gait in patients with schizophrenia: the influence of age and visual control\",\n        \"“Gait control and executive dysfunction in early schizophrenia\",\n        \"“Gait disturbances in patients with schizophrenia and adaptation to treadmill walking\",\n        \"“Social cognition\",\n        \"“Physiological and nonverbal correlates of extraversion\",\n        \"J. Graff-Dolezal\",\n        \"“Personality correlates of nonverbal interview behavior\",\n        \"“Threat and trait anxiety affect stability of gaze fixation\",\n        \"“Image-based stress recognition using a model-based dynamic face tracking system\",\n        \"“The assessment of anxiety states by rating\",\n        \"“Optical computer recognition of facial expressions associated with stress induced by performance demands\",\n        \"“Head movement correlates of juncture and stress at sentence level\",\n        \"“A real-time human stress monitoring system using dynamic bayesian network\",\n        \"“Stress and anxiety detection using facial cues from videos\",\n        \"“Detecting anxiety and defensiveness from visual and auditory cues\",\n        \"“Blink rate as a function of induced muscular tension and manifest anxiety\",\n        \"“Detecting deception from the body or face\",\n        \"“Interpersonal consequences of social anxiety\",\n        \"“Correlations among nonverbal expressions of anxiety\",\n        \"“The ecology of anxiety: Situational stress and rate of self-stimulation in turkey\",\n        \"“Man vs. machine: A comparison of human and computer assessment of nonverbal behavior in social anxiety disorder\",\n        \"“The role of auditory cues in the detection of state anxiety 1\",\n        \"“Voice traces of anxiety: Acoustic parameters affected by anxiety disorder\",\n        \"“Do social anxiety individuals hesitate more? the prosodic profile of hesitation disfluencies in social anxiety disorder individuals\",\n        \"M. B. van Iersel\",\n        \"“Threat assessment and locomotion: clinical applications of an integrated model of anxiety and postural control\",\n        \"“Recognising falls risk in older adult mental health patients and acknowledging the difference from the general older adult population\",\n        \"“Neural substrates linking balance control and anxiety\",\n        \"“Balance treatment ameliorates anxiety and increases self-esteem in children with comorbid anxiety and balance disorder\",\n        \"“Mood states and anxiety influence abilities to maintain balance control in healthy human subjects\",\n        \"mobility and muscle strength in people with anxiety compared to healthy individuals\",\n        \"“The role of trait anxiety on static balance performance in control and anxiogenic situations\",\n        \"“Facial emotion recognition in trait anxiety\",\n        \"“Worry amplifies theory-of-mind reasoning for negatively valenced social stimuli in generalized anxiety disorder\",\n        \"“Speech-based markers for posttraumatic stress disorder in us veterans\",\n        \"“Self-reported symptoms of depression and PTSD are associated with reduced vowel space in screening interviews\",\n        \"“A voice-based automated system for PTSD screening and monitoring\",\n        \"“Automatic nonverbal behavior indicators of depression and ptsd: Exploring gender differences\",\n        \"“Facial expression and experience of emotions in psychodynamic interviews with patients with ptsd in comparison to healthy subjects\",\n        \"“Gait pattern and motor performance during discrete gait perturbation in children with autism spectrum disorders\",\n        \"“Theory of mind and autism: A review\",\n        \"K. Bertakis et al\",\n        \"“Posture and body image in individuals with major depressive disorder: A controlled study\",\n        \"balance and posture in major mental illnesses: Depression\",\n        \"” Psychiatry Research\",\n        \"“Theory of mind impairments in social anxiety disorder\",\n        \"“Decreased theory of mind skills\",\n        \"““theory of mind” in schizophrenia: A review of the literature\",\n        \"“Theory of mind impairments in euthymic bipolar patients\",\n        \"“Impaired recognition of emotions from body movements is associated with elevated motion coherence thresholds in autism spectrum disorders\",\n        \"” Multimedia Tools and Applications\",\n        \"“Robots and emotion: A survey of trends\",\n        \"“Emotion modelling for social robotics applications: A review\",\n        \"“Emotional intelligence in robotics: A scoping review\",\n        \"“Distinguishing robot personality from motion\",\n        \"“Harnessing AI for augmenting creativity: Application to movie trailer creation\",\n        \"“Cost of Fatigue at Work\",\n        \"“Monitoring worker fatigue using wearable devices: A case study to detect changes in gait parameters\",\n        \"“A driver face monitoring system for fatigue and distraction detection\",\n        \"“A data-driven model to identify fatigue level based on the motion data from a smartphone\",\n        \"“Driver fatigue detection systems: A review\",\n        \"“Facial image processing for sleepiness estimation\",\n        \"“Fatigue detection model for older adults using eye-tracking data gathered while watching video: Evaluation against diverse fatiguing tasks\",\n        \"“Detecting mental fatigue from eye-tracking data gathered while watching video: Evaluation in younger and older adults\",\n        \"“Fatigue is a brain-derived emotion that regulates the exercise behavior to ensure the protection of whole body homeostasis\"\n    ],\n    \"reasoning\": \"Selected these 497 references because they represent foundational work and recent advances in Unlocking the Emotional World of Visual Media:An Overview of the Science, Research, and Impact of Understanding Emotion Drawing insights from psychology, engineering, and the arts, this article provides a comprehensive overview of the field of emotion analysis in visual media, and discusses the latest research, systems, challenges, ethical implications, and potential impact of artificial emotional intelligence on society., providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}