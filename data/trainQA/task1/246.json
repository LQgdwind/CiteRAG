{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 59 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Symbolic Learning and Reasoning with Noisy Data for Probabilistic Anchoring\n\nPaper Abstract: Abstract Robotic agents should be able to learn from sub-symbolic sensor data, and at the same time, be able to reason about objects and communicate with humans on a symbolic level. This raises the question of how to overcome the gap between symbolic and sub-symbolic artificial intelligence. We propose a semantic world modeling approach based on bottom-up object anchoring using an object-centered representation of the world. Perceptual anchoring processes continuous perceptual sensor data and maintains a correspondence to a symbolic representation. We extend the definitions of anchoring to handle multi-modal probability distributions and we couple the resulting symbol anchoring system to a probabilistic logic reasoner for performing inference. Furthermore, we use statistical relational learning to enable the anchoring framework to learn symbolic knowledge in the form of a set of probabilistic logic rules of the world from noisy and sub-symbolic sensor input. The resulting framework, which combines perceptual anchoring and statistical relational learning, is able to maintain a semantic world model of all the objects that have been perceived over time, while still exploiting the expressiveness of logical rules to reason about the state of objects which are not directly observed through sensory input data. To validate our approach we demonstrate, on the one hand, the ability of our system to perform probabilistic reasoning over multi-modal probability distributions, and on the other hand, the learning of probabilistic logical rules from anchored objects produced by perceptual observations. The learned logical rules are, subsequently, used to assess our proposed probabilistic anchoring procedure. We demonstrate our system in a setting involving object interactions where object occlusions arise and where probabilistic inference is needed to correctly anchor objects. \\helveticabold 1 Keywords: Semantic World Modeling, Perceptual Anchoring, Probabilistic Anchoring, Statistical Relational Learning, Probabilistic Logic Programming, Object Tracking, Relational Particle Filtering, Probabilistic Rule Learning.\n\n{retrieved_text}\n\nGenerate exactly 59 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 59\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Declarative bias for specific-to-general ilp systems\",\n        \"Bayesian learning of bayesian networks with informative priors\",\n        \"Distributional logic programming for bayesian knowledge representation\",\n        \"Representing meaning with a combination of logical and distributional models\",\n        \"Perception and probabilistic anchoring for dynamic world state logging\",\n        \"Perceptual anchoring via conceptual spaces\",\n        \"Anchoring symbols to conceptual spaces: the case of dynamic scenarios\",\n        \"Anchoring symbols to sensor data: preliminary report\",\n        \"Perceptual anchoring of symbols for action\",\n        \"Statistical relational artificial intelligence: Logic, probability, and computation\",\n        \"Probabilistic (logic) programming concepts\",\n        \"Semantic world modeling using probabilistic multiple hypothesis anchoring\",\n        \"Inference and learning in probabilistic logic programs using weighted boolean formulas\",\n        \"Learning probabilistic relational models\",\n        \"Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning\",\n        \"Incorporating vector space similarity in random walk inference over knowledge bases\",\n        \"Probabilistic soft logic: A scalable approach for markov random fields over continuous-valued variables\",\n        \"Introduction to Statistical Relational Learning (Adaptive Computation and Machine Learning)\",\n        \"Explaining explanations: An overview of interpretability of machine learning\",\n        \"The magic of logical inference in probabilistic programming\",\n        \"Context-aware 3d object anchoring for mobile robots\",\n        \"Safety verification of deep neural networks\",\n        \"Visual object-action recognition: Inferring object affordances from human demonstration\",\n        \"Probabilistic Graphical Models: Principles and Techniques\",\n        \"Learning human activities and object affordances from rgb-d videos\",\n        \"Physically grounded spatio-temporal object affordances\",\n        \"The hungarian method for the assignment problem\",\n        \"Learning distributional programs for relational autocompletion\",\n        \"Cooperative anchoring in heterogeneous multi-robot systems\",\n        \"Odour Recognition using Electronic Noses in Robotic and Intelligent Systems\",\n        \"Smell, think and act: A cognitive robot discriminating odours\",\n        \"Using knowledge representation for perceptual anchoring in a robotic system\",\n        \"Maintaining coherent perceptual information using anchoring\",\n        \"Deepproblog: Neural probabilistic logic programming\",\n        \"The state-of-the-art in handling occlusions for visual object tracking\",\n        \"1 blog: Probabilistic models with unknown objects\",\n        \"Learning relational affordance models for robots in multi-object manipulation tasks\",\n        \"Relational dependency networks\",\n        \"A particle filter for hybrid relational domains\",\n        \"Relational object tracking and learning\",\n        \"Probabilistic logic programming for hybrid relational domains\",\n        \"Learning the structure of dynamic hybrid relational models\",\n        \"Learning actions to improve the perceptual anchoring of objects\",\n        \"Semantic relational object tracking\",\n        \"Learning relational dependency networks in hybrid domains\",\n        \"Markov logic networks\",\n        \"Foundations of Probabilistic Logic Programming\",\n        \"Online context-based object recognition for mobile robots\",\n        \"A statistical learning method for logic programs with distribution semantics\",\n        \"Parameter learning of logic programs for symbolic-statistical modeling\",\n        \"Mastering the game of go with deep neural networks and tree search\",\n        \"Visual tracking: An experimental survey\",\n        \"The art of Prolog: advanced programming techniques\",\n        \"Going deeper with convolutions\",\n        \"Discriminative probabilistic models for relational data\",\n        \"Probabilistic people tracking with appearance models and occlusion classification: The ad-hoc system\",\n        \"Data association for semantic world modeling from partial views\",\n        \"Online object tracking: A benchmark\",\n        \"The best of both modes: Separately leveraging rgb and depth for unseen object instance segmentation\"\n    ],\n    \"reasoning\": \"Selected these 59 references because they represent foundational work and recent advances in Symbolic Learning and Reasoning with Noisy Data for Probabilistic Anchoring, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}