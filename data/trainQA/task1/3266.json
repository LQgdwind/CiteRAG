{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 47 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: An Intelligent Passive Food Intake Assessment System with Egocentric Cameras\n\nPaper Abstract: Abstract Malnutrition is a major public health concern in low-and-middle-income countries (LMICs). Understanding food and nutrient intake across communities, households and individuals is critical to the development of health policies and interventions. To ease the procedure in conducting large-scale dietary assessments, we propose to implement an intelligent passive food intake assessment system via egocentric cameras particular for households in Ghana and Uganda. Algorithms are first designed to remove redundant images for minimising the storage memory. At run time, deep learning-based semantic segmentation is applied to recognise multi-food types and newly-designed handcrafted features are extracted for further consumed food weight monitoring. Comprehensive experiments are conducted to validate our methods on an in-the-wild dataset captured under the settings which simulate the unique LMIC conditions with participants of Ghanaian and Kenyan origin eating common Ghanaian/Kenyan dishes. To demonstrate the efficacy, experienced dietitians are involved in this research to perform the visual portion size estimation, and their predictions are compared to our proposed method. The promising results have shown that our method is able to reliably monitor food intake and give feedback on users’ eating behaviour which provides guidance for dietitians in regular dietary assessment.\n\n{retrieved_text}\n\nGenerate exactly 47 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 47\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"World Health Organisation - Malnutrition\",\n        \"Development and Validation of an Objective, Passive Dietary Assessment Method for Estimating Food and Nutrient Intake in Households in Low-and Middle-Income Countries: A Study Protocol\",\n        \"Multiple hypotheses image segmentation and classification with application to dietary assessment\",\n        \"An image analysis system for dietary assessment and evaluation\",\n        \"The use of mobile devices in aiding dietary assessment and evaluation\",\n        \"Im2calories: towards an automated mobile vision food diary\",\n        \"Automatic Food Intake Monitoring Based on Chewing Activity: A Survey\",\n        \"Recognition of nutrition intake using time-frequency decomposition in a wearable necklace using a piezoelectric sensor\",\n        \"Segmentation and characterization of chewing bouts by monitoring temporalis muscle using smart glasses with piezoelectric sensor\",\n        \"Comparison between human and bite-based methods of estimating caloric intake\",\n        \"Automated estimation of food type and amount consumed from body-worn audio and motion sensors\",\n        \"Detection of food intake events from throat microphone recordings using convolutional neural networks\",\n        \"AutoDietary: A wearable acoustic sensor system for food intake recognition in daily life\",\n        \"Accelerometer-based detection of food intake in free-living individuals\",\n        \"An Accelerometer based EyeGlass to Monitor Food Intake in Free-Living and Lab Environment\",\n        \"Your glasses know your diet: Dietary monitoring using electromyography sensors\",\n        \"Monitoring chewing and eating in free-living using smart eyeglasses\",\n        \"Assessing the accuracy of a wrist motion tracking method for counting bites across demographic and food variables\",\n        \"Bite weight prediction from acoustic recognition of chewing\",\n        \"Counting Bites and Recognizing Consumed Food from Videos for Passive Dietary Monitoring\",\n        \"Point2Volume: A Vision-based Dietary Assessment Approach using View Synthesis\",\n        \"Two-view 3D Reconstruction for Food Volume Estimation\",\n        \"Food volume estimation in a mobile phone based dietary assessment system\",\n        \"Single-View Food Portion Estimation Based on Geometric Models\",\n        \"Accuracy of food portion size estimation from digital pictures acquired by a chest-worn camera\",\n        \"Model-based food volume estimation using 3D pose\",\n        \"Image-based food portion size estimation using a smartphone without a fiducial marker\",\n        \"Imaged based estimation of food volume using circular referents in dietary assessment\",\n        \"Image-based Food Classification and Volume Estimation for Dietary Assessment: A Review\",\n        \"An exploratory study on a chest-worn computer for evaluation of diet, physical activity and lifestyle\",\n        \"Depth Estimation based on a Single Close-up Image with Volumetric Annotations in the Wild: A Pilot Study\",\n        \"Comparison of the YOLOv3 and Mask R-CNN architectures’ efficiency in the smart refrigerator’s computer vision\",\n        \"Vineyard trunk detection using deep learning–An experimental device benchmark\",\n        \"The VGG image annotator (VIA)\",\n        \"Automatic detection of dining plates for image-based dietary evaluation\",\n        \"Automatic food detection in egocentric images using artificial intelligence technology\",\n        \"Food image analysis: Segmentation, identification and weight estimation\",\n        \"GrabCut interactive foreground extraction using iterated graph cuts\",\n        \"DeepFood: Food Image Analysis and Dietary Assessment via Deep Model\",\n        \"Mask r-cnn\",\n        \"Mask r-cnn for object detection and instance segmentation on keras and tensorflow\",\n        \"Microsoft coco: Common objects in context\",\n        \"Diabetes60 - Inferring Bread Units From Food Images Using Fully Convolutional Neural Networks\",\n        \"Random forests\",\n        \"eButton: a wearable computer for health monitoring and personal assistance\",\n        \"Automatic Ingestion Monitor Version 2”-A Novel Wearable Device for Automatic Food Intake Detection and Passive Capture of Food Images\",\n        \"Estimating Dining Plate Size From an Egocentric Image Sequence Without a Fiducial Marker\"\n    ],\n    \"reasoning\": \"Selected these 47 references because they represent foundational work and recent advances in An Intelligent Passive Food Intake Assessment System with Egocentric Cameras, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}