{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 177 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Partially Observable Markov Decision Processes in Robotics: A Survey\n\nPaper Abstract: Abstract Noisy sensing, imperfect control, and environment changes are defining characteristics of many real-world robot tasks. The partially observable Markov decision process (POMDP) provides a principled mathematical framework for modeling and solving robot decision and control tasks under uncertainty. Over the last decade, it has seen many successful applications, spanning localization and navigation, search and tracking, autonomous driving, multi-robot systems, manipulation, and human-robot interaction. This survey aims to bridge the gap between the development of POMDP models and algorithms at one end and application to diverse robot decision tasks at the other. It analyzes the characteristics of these tasks and connects them with the mathematical and algorithmic properties of the POMDP framework for effective modeling and solution. For practitioners, the survey provides some of the key task characteristics in deciding when and how to apply POMDPs to robot tasks successfully. For POMDP algorithm designers, the survey provides new insights into the unique challenges of applying POMDPs to robot systems and points to promising new directions for further research.\n\n{retrieved_text}\n\nGenerate exactly 177 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 177\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"FIRM: Sampling-based feedback motion-planning under motion uncertainty and imperfect measurements\",\n        \"Health aware stochastic planning for persistent package delivery missions using quadrotors\",\n        \"Safe policy synthesis in multi-agent POMDPs via discrete-time barrier functions\",\n        \"Policy search for multi-robot coordination under uncertainty\",\n        \"Oracular partially observable Markov decision processes: A very special case\",\n        \"Optimal control of Markov processes with incomplete state information\",\n        \"Nonmyopic view planning for active object classification and pose estimation\",\n        \"A Bayesian reinforcement learning approach for customizing human-robot interfaces\",\n        \"A bayesian method for learning POMDP observation parameters for robot interaction management systems\",\n        \"Intention-aware online POMDP planning for autonomous driving in a crowd\",\n        \"Unmanned aircraft collision avoidance using continuous-state POMDPs\",\n        \"Integrated perception and planning in the continuous space: A POMDP approach\",\n        \"Monte Carlo value iteration for continuous-state POMDPs\",\n        \"Planning how to learn\",\n        \"Unifying system health management and automated decision making\",\n        \"Dynamic programming\",\n        \"The complexity of decentralized control of Markov decision processes\",\n        \"Dynamic programming and suboptimal control: A survey from ADP to MPC\",\n        \"Dec-MCTS: Decentralized planning for multi-robot active perception\",\n        \"Multiagent rollout and policy iteration for POMDP with application to multi-robot repair problems\",\n        \"Data-driven grasp synthesis—a survey\",\n        \"Estimation of soft tissue mechanical parameters from robotic manipulation data\",\n        \"Solving continuous POMDPs: Value iteration with incremental learning of an efficient space representation\",\n        \"Probabilistic decision-making under uncertainty for autonomous driving using continuous POMDPs\",\n        \"A survey of Monte Carlo tree search methods\",\n        \"Designing POMDP models of socially situated tasks\",\n        \"Continuous-state POMDPs with hybrid dynamics\",\n        \"The factored policy-gradient planner\",\n        \"Optimal continuous state POMDP planning with semantic observations: A variational approach\",\n        \"HyP-DESPOT: A hybrid parallel algorithm for online planning under uncertainty\",\n        \"TARE: A hierarchical framework for efficiently exploring complex 3D environments\",\n        \"Decentralized multi-robot cooperation with auctioned POMDPs\",\n        \"Incremental pruning: A simple, fast, exact method for partially observable Markov decision processes\",\n        \"Acting optimally in partially observable stochastic domains\",\n        \"Deterministic equivalents for optimizing and satisficing under chance constraints\",\n        \"Sampling-based algorithms for continuous-time POMDPs\",\n        \"POMDP-lite for robust robot planning under uncertainty\",\n        \"Planning with trust for human-robot collaboration\",\n        \"Bayesian filtering: From Kalman filters to particle filters, and beyond\",\n        \"Distributed matroid-constrained submodular maximization for multi-robot exploration: theory and practice\",\n        \"MPDM: Multipolicy decision-making in dynamic, uncertain environments for autonomous driving\",\n        \"Bayesian reinforcement learning in continuous POMDPs with Gaussian processes\",\n        \"RAO*: An algorithm for chance-constrained POMDP’s\",\n        \"Maximum likelihood from incomplete data via the EM algorithm\",\n        \"Simultaneous localization and mapping: part I\",\n        \"Active perception and scene modeling by planning with probabilistic 6D object poses\",\n        \"Map-based navigation in mobile robots:: I. a review of localization strategies\",\n        \"Predictive control of robot velocity to avoid obstacles in dynamic environments\",\n        \"Learning to grasp under uncertainty using POMDPs\",\n        \"Online replanning in belief space for partially observable task and motion problems\",\n        \"“Bayesian reinforcement learning: A survey\",\n        \"“Searching and tracking people with cooperative mobile robots\",\n        \"“Automated model approximation for robotic navigation with POMDPs\",\n        \"“Extending the applicability of POMDP solutions to robotic tasks\",\n        \"“A survey of deep learning techniques for autonomous driving\",\n        \"“A decision-theoretic approach to detection-based target search with a UAV\",\n        \"“Learning latent dynamics for planning from pixels\",\n        \"“Value-function approximations for partially observable Markov decision processes\",\n        \"“Utilizing human feedback in POMDP execution and specification\",\n        \"“Automated handwashing assistance for persons with dementia using video and a partially observable Markov decision process\",\n        \"“Efficient multi-robot search for a moving target\",\n        \"“Interactive non-prehensile manipulation for grasping via POMDPs\",\n        \"“Grasping POMDPs\",\n        \"“Robust belief-based execution of manipulation programs\",\n        \"“A POMDP treatment of vehicle-pedestrian interaction: Implicit coordination via uncertainty-aware planning\",\n        \"“Decision making for autonomous driving considering interaction and uncertain prediction of surrounding vehicles\",\n        \"“Planning in the continuous domain: A generalized belief space approach for autonomous navigation in unknown environments\",\n        \"“A formal framework for robot learning and control under model uncertainty\",\n        \"“Planning and acting in partially observable stochastic domains\",\n        \"“Pre-image backchaining in belief space for mobile manipulation\",\n        \"“Integrated task and motion planning in belief space\",\n        \"“Differentiable algorithm networks for composable robot learning\",\n        \"“Probabilistic roadmaps for path planning in high-dimensional configuration spaces\",\n        \"“Review of machine learning methods in soft robotics\",\n        \"“PLGRIM: Hierarchical value learning for large-scale exploration in unknown environments\",\n        \"“TAPIR: A software toolkit for approximating and adapting POMDP solutions online\",\n        \"“Reinforcement learning in robotics: A survey\",\n        \"Xavier: A robot navigation architecture based on partially observable markov decision process models. MIT Press\",\n        \"“No belief propagation required: Belief space planning in high-dimensional state spaces via factor graphs\",\n        \"“A comprehensive taxonomy for multi-robot task allocation\",\n        \"“Pre-and post-contact policy decomposition for planar contact manipulation under uncertainty\",\n        \"“SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces\",\n        \"“An online POMDP solver for uncertainty planning in dynamic environment\",\n        \"“Least-squares policy iteration\",\n        \"“A survey of methods for safe human-robot interaction\",\n        \"“Multi-robot active information gathering with periodic communication\",\n        \"“Multi-agent active perception with prediction rewards\",\n        \"“Multi-agent active information gathering in discrete and continuous-state decentralized POMDPs by policy graph improvement\",\n        \"“Planning for robotic exploration based on forward simulation\",\n        \"“Monte-Carlo Tree Search for Constrained POMDPs\",\n        \"“MAGIC: learning macro-actions for online POMDP planning\",\n        \"“Act to see and see to act: POMDP planning for objects search in clutter\",\n        \"“Learning policies for partially observable environments: Scaling up\",\n        \"“Towards optimally decentralized multi-robot collision avoidance via deep reinforcement learning\",\n        \"“A survey of algorithmic methods for partially observed Markov decision processes\",\n        \"“PORCA: Modeling and planning for autonomous driving among many pedestrians\",\n        \"“A Bayesian exploration-exploitation approach for optimal online sensing and planning with a visually guided mobile robot\",\n        \"“Coordinated multi-robot exploration under communication constraints using decentralized Markov decision processes\",\n        \"“A POMDP framework for coordinated guidance of autonomous UAVs for multitarget tracking\",\n        \"“State of the art—a survey of partially observable Markov decision processes: theory\",\n        \"“POMDP approach to robotized clothes separation\",\n        \"“The expectation-maximization algorithm\",\n        \"“From bandits to Monte-Carlo tree search: The optimistic principle applied to optimization and planning\",\n        \"“Belief-grounded networks for accelerated robot learning under partial observability\",\n        \"A concise introduction to decentralized POMDPs. Springer\",\n        \"A. Agha-mohammadi\",\n        \"A.-A. Agha-Mohammadi\",\n        \"“Planning under uncertainty for robotic tasks with mixed observability\",\n        \"“Robotic manipulation in object composition space\",\n        \"“Robotic manipulation of multiple objects as a POMDP\",\n        \"“POMDP planning under object composition uncertainty: Application to robotic manipulation\",\n        \"“FIG-OP: exploring large-scale unknown environments on a fixed time budget\",\n        \"“Hierarchical POMDP framework for a robot-assisted ASD diagnostic protocol\",\n        \"“Combined task and motion planning under partial observability: An optimization-based approach\",\n        \"“Point-based value iteration: An anytime algorithm for POMDPs\",\n        \"“Anytime point-based approximations for large POMDPs\",\n        \"“Towards robotic assistants in nursing homes: Challenges and results\",\n        \"“ALVINN: An autonomous land vehicle in a neural network\",\n        \"“Exploiting structure to efficiently solve large scale partially observable Markov decision processes\",\n        \"“Hybrid online POMDP planning and deep reinforcement learning for safer self-driving cars\",\n        \"Markov Decision Processes: Discrete Stochastic Dynamic Programming\",\n        \"“Decentralized guidance control of UAVs with explicit optimization of communication\",\n        \"“Personalized robot tutoring using the assistive tutor POMDP (AT-POMDP)\",\n        \"Gaussian Processes for Machine Learning. MIT Press\",\n        \"“Mixed reality as a bidirectional communication interface for human-robot interaction\",\n        \"“Modeling humans as observation providers using POMDPs\",\n        \"“Bayesian reinforcement learning in continuous POMDPs with application to robot navigation\",\n        \"“Online planning algorithms for POMDPs\",\n        \"“Exploiting submodular value functions for scaling up active perception\",\n        \"“Learning flexible\",\n        \"T. Graepel et al\",\n        \"“A survey of point-based POMDP solvers\",\n        \"“Monte-carlo planning in large POMDPs\",\n        \"“Simultaneous active parameter estimation and control using sampling-based Bayesian reinforcement learning\",\n        \"“The optimal control of partially observable Markov processes over a finite horizon\",\n        \"“Heuristic search value iteration for POMDPs\",\n        \"“Point-based POMDP algorithms: Improved analysis and implementation\",\n        \"“DESPOT: Online POMDP planning with regularization\",\n        \"“The optimal control of partially observable Markov processes\",\n        \"“Intention-aware autonomous driving decision-making in an uncontrolled intersection\",\n        \"“Cooperative active perception using POMDPs\",\n        \"“Active cooperative perception in network robot systems using POMDPs\",\n        \"“Perseus: Randomized point-based value iteration for POMDPs\",\n        \"“Planning to see: A hierarchical approach to planning visual actions on a robot using POMDPs\",\n        \"“Multi-robot region-of-interest reconstruction with Dec-MCTS\",\n        \"“The value of inferring the internal state of traffic participants for autonomous freeway driving\",\n        \"“Online algorithms for POMDPs with continuous state\",\n        \"“Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning\",\n        \"“MAA*: A heuristic search algorithm for solving decentralized POMDPs\",\n        \"“A POMDP framework for modelling human interaction with assistive robots\",\n        \"“Autonomous vehicle speed control for safe navigation of occluded pedestrian crosswalk\",\n        \"“Towards tactical lane change behavior planning for automated vehicles\",\n        \"“An online algorithm for constrained POMDPs\",\n        \"“Semi-supervised learning of decision-making models for human-robot collaboration\",\n        \"“Decision-making for bidirectional communication in sequential human-robot collaborative tasks\",\n        \"“Optimizing gaze direction in a visual navigation task\",\n        \"“Efficient approximate value iteration for continuous Gaussian POMDPs\",\n        \"“UAV based target finding and tracking in GPS-denied and cluttered environments\",\n        \"“DeepIG: Multi-robot information gathering with deep reinforcement learning\",\n        \"“Multi-object search using object-oriented POMDPs\",\n        \"“Model-based reinforcement learning for decentralized multiagent rendezvous\",\n        \"“POMP: POMCP-based Online Motion Planning for active visual search in indoor environments\",\n        \"“Bounded Policy Synthesis for POMDPs with Safe-Reachability Objectives\",\n        \"“Anticipatory action selection for human–robot table tennis\",\n        \"“A point-based MDP for robust single-lane autonomous driving behavior under uncertainties\",\n        \"“A survey of solution techniques for the partially observed Markov decision process\",\n        \"S. Hagaribommanahalli\",\n        \"“Online decision-making for scalable autonomous systems\",\n        \"“Learning multi-robot decentralized macro-action-based policies via a centralized Q-net\",\n        \"“Online planning for target object search in clutter under partial observability\",\n        \"“A review on mechanical and hydraulic system modeling of excavator manipulator system\",\n        \"“Indoor pursuit-evasion with hybrid hierarchical partially observable Markov decision processes for multi-robot systems\",\n        \"“A role-based POMDPs approach for decentralized implicit cooperation of multiple agents\",\n        \"“Active visual planning for mobile robot teams using hierarchical POMDPs\",\n        \"“Multi-resolution POMDP planning for multi-object search in 3D\",\n        \"“POMDP model learning for human robot collaboration\",\n        \"“A probabilistic planning framework for planar grasping under uncertainty\"\n    ],\n    \"reasoning\": \"Selected these 177 references because they represent foundational work and recent advances in Partially Observable Markov Decision Processes in Robotics: A Survey, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}