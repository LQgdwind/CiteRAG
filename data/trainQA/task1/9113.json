{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 236 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Evaluating the Social Impact of Generative AI Systems in Systems and Society\n\nPaper Abstract: Abstract Generative AI systems across modalities, ranging from text, image, audio, and video, have broad social impacts, but there exists no official standard for means of evaluating those impacts and which impacts should be evaluated. We move toward a standard approach in evaluating a generative AI system for any modality, in two overarching categories: what is able to be evaluated in a base system that has no predetermined application and what is able to be evaluated in society. We describe specific social impact categories and how to approach and conduct evaluations in the base technical system, then in people and society. Our framework for a base system defines seven categories of social impact: bias, stereotypes, and representational harms; cultural values and sensitive content; disparate performance; privacy and data protection; financial costs; environmental costs; and data and content moderation labor costs. Suggested methods for evaluation apply to all modalities and analyses of the limitations of existing evaluations serve as a starting point for necessary investment in future evaluations. We offer five overarching categories for what is able to be evaluated in society, each with their own subcategories: trustworthiness and autonomy; inequality, marginalization, and violence; concentration of authority; labor and creativity; and ecosystem and environment. Each subcategory includes recommendations for mitigating harm. We are concurrently crafting an evaluation repository for the AI research community to contribute existing evaluations along the given categories. This version will be updated following a CRAFT session at ACM FAccT 2023.\n\n{retrieved_text}\n\nGenerate exactly 236 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 236\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Analyse and automate every message\",\n        \"Global Comprehensive Privacy Law Mapping Chart\",\n        \"Methodologies and Tools to Evaluate Climate Change Impacts and Adaptation\",\n        \"California Consumer Privacy Act of 2018\",\n        \"AB-5 Worker status: employees and independent contractors.\",\n        \"DOD Adopts Ethical Principles for Artificial Intelligence\",\n        \"COM (2021) 762: Proposal for a DIRECTIVE OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on improving working conditions in platform work\",\n        \"Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE (ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION LEGISLATIVE ACTS\",\n        \"Americans’ Views on Generative Artificial Intelligence, Hate and Harassment\",\n        \"Cyber violence is a growing threat, especially for women and girls\",\n        \"REAIM 2023\",\n        \"A Systematic Review of the Empirical Literature Evaluating IRBs: What We Know and What We Still Need to Learn\",\n        \"Mirages: On Anthropomorphism in Dialogue Systems, May 2023\",\n        \"The Low-Resource Double Bind: An Empirical Study of Pruning for Low-Resource Machine Translation\",\n        \"Behavioural consequences of child abuse\",\n        \"Protecting One’s Own Privacy in a Big Data Economy\",\n        \"The Limitations of Online Surveys\",\n        \"What We Can’t Measure, We Can’t Understand: Challenges to Demographic Data Procurement in the Pursuit of Fairness\",\n        \"The Labor Market Impacts of Technological Change: From Unbridled Enthusiasm to Qualified Optimism to Vast Uncertainty, May 2022\",\n        \"Marginalization: Conceptualizing patient vulnerabilities in the framework of social determinants of health – An integrative review\",\n        \"Differential privacy has disparate impact on model accuracy\",\n        \"T. Telleen-Lawton\",\n        \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\",\n        \"State of AI Report 2022\",\n        \"“It’s Complicated”: Negotiating Accessibility and (Mis)Representation in Image Descriptions of Race, Gender, and Disability\",\n        \"Digital Labour Platforms and the Future of Work: Towards Decent Work in the Online World\",\n        \"Bloom: A 176b-parameter open-access multilingual language model, 2023\",\n        \"Power to the people? opportunities and challenges for participatory AI\",\n        \"The Forgotten Margins of AI Ethics\",\n        \"Language (Technology) is Power: A Critical Survey of “Bias” in NLP\",\n        \"On the Opportunities and Risks of Foundation Models, 2022-07-12\",\n        \"Sorting Things Out Classification and Its Consequences\",\n        \"Beyond ethnography: engagement and reciprocity as foundations for design research out here\",\n        \"F. Mireshghallah\",\n        \"Language Models are Few-Shot Learners, 2020-07-22\",\n        \"Truth, Lies, and Automation, May 2021\",\n        \"Do Opt-Outs Really Opt Me Out?\",\n        \"Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification\",\n        \"Human Rights and National Security: The Strategic Correlation\",\n        \"To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making\",\n        \"Semantics derived automatically from language corpora contain human-like biases\",\n        \"The Boundaries of Privacy Harm\",\n        \"Intercultural information ethics\",\n        \"Quantifying Memorization Across Neural Language Models\",\n        \"Extracting Training Data from Diffusion Models\",\n        \"The CARE Principles for Indigenous Data Governance\",\n        \"Operationalizing the CARE and FAIR Principles for Indigenous data futures\",\n        \"Harms from Increasingly Agentic Algorithmic Systems, May 2023\",\n        \"Inmates in Finland are training AI as part of prison labor, 2019-03-28T16:05:06\",\n        \"Evaluating Large Language Models Trained on Code, July 2021\",\n        \"Net Job Creation in an Increasingly Autonomous Economy: The Challenge of a Generation\",\n        \"Feminist Data Manifest-No\",\n        \"AI assistants help developers produce code that’s insecure\",\n        \"About CodeCarbon, 2023-05-12T16:13:58Z\",\n        \"The decolonial turn in data and technology research: what is at stake and where is it heading?\",\n        \"Mapping the Margins: Intersectionality, Identity Politics, and Violence against Women of Color\",\n        \"Sentiment analysis based on deep learning: A comparative study\",\n        \"Racial Bias in Hate Speech and Abusive Language Detection Datasets\",\n        \"Establishing a pro-innovation approach to regulating AI, 2022\",\n        \"Next Generation Artificial Intelligence Development Plan, 2017\",\n        \"CrowdWorkSheets: Accounting for Individual and Collective Identities Underlying Crowdsourced Dataset Annotation\",\n        \"Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling, 2021-07-23\",\n        \"Purity and Danger: An Analysis of Concepts of Pollution and Taboo\",\n        \"Ethical pluralism and global information ethics\",\n        \"Proposal for a Regulation laying down harmonised rules on artificial intelligence | Shaping Europe’s digital future, 2021-04-21\",\n        \"About Fairwork, 2023\",\n        \"Creating, Using, Misusing, and Detecting Deep Fakes\",\n        \"Protections Against Discrimination and Other Prohibited Practices, 2013-07-16T10:34:31-04:00\",\n        \"Working the Crowd: Employment and Labor Law in the Crowdsourcing Industry\",\n        \"Generating Harms: Generative AI’s Impact & Paths Forward – EPIC – Electronic Privacy Information Center\",\n        \"A Survey of Race, Racism, and Anti-Racism in NLP\",\n        \"Effectiveness of a chatbot for eating disorders prevention: A randomized clinical trial\",\n        \"The (Im)possibility of fairness: Different value systems require different mechanisms for fair decision making\",\n        \"Value Sensitive Design and Information Systems\",\n        \"Datasheets for datasets\",\n        \"RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models\",\n        \"Garbage in, garbage out?: Do machine learning application papers in social computing report where human-labeled training data comes from?\",\n        \"Improving alignment of dialogue agents via targeted human judgements, 2022-09-28\",\n        \"Moderating with the Mob: Evaluating the Efficacy of Real-Time Crowdsourced Fact-Checking\",\n        \"This prompt is measuring <mask>: Evaluating bias evaluation in language models, 2023\",\n        \"Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass\",\n        \"Evidence-Based Misinformation Interventions: Challenges and Opportunities for Measurement and Collaboration\",\n        \"The consequences of online partisan media\",\n        \"Chasing Carbon: The Elusive Environmental Footprint of Computing\",\n        \"Disproportionate Removals and Differing Content Moderation Experiences for Conservative, Transgender, and Black Social Media Users: Marginalization and Moderation Gray Areas\",\n        \"How the AI industry profits from catastrophe, 2022\",\n        \"“It’s Kind of Like Code-Switching”: Black Older Adults’ Experiences with a Voice Assistant for Health Information Seeking\",\n        \"ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection, July 2022\",\n        \"Why Meta’s latest large language model survived only three days online\",\n        \"Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning\",\n        \"Do you Trust an AI-Journalist? A Credibility Analysis of News Content with AI-Authorship\",\n        \"Moving beyond “algorithmic bias is a data problem”\",\n        \"Characterising Bias in Compressed Models, 2020-12-18\",\n        \"The Social Impact of Natural Language Processing\",\n        \"AI and Human Rights: Building a Tech Future Aligned With the Public Interest — All Tech Is Human\",\n        \"50 Years of Test (Un)fairness: Lessons for Machine Learning\",\n        \"Evaluation Gaps in Machine Learning Practice\",\n        \"Unequal Treatment: Confronting Racial and Ethnic Disparities in Health Care\",\n        \"How time-stamping works in eac markets\",\n        \"Language Models for Code-switch Detection of te reo Māori and English in a Low-resource Setting\",\n        \"Let’s talk about biases in machine learning! Ethics and Society Newsletter #2, 2022\",\n        \"Data governance in the age of large-scale data-driven language technology\",\n        \"Work without the Worker: Labour in the Age of Platform Capitalism\",\n        \"Aligning artificial intelligence with climate change mitigation\",\n        \"Don’t ask if artificial intelligence is good or fair, ask how it shifts power\",\n        \"Revenge Pornography: Mental Health Implications and Related Legislation\",\n        \"Regulating the Risks of AI\",\n        \"Taxonomizing and Measuring Representational Harms: A Look at Image Tagging, 2023-05-02\",\n        \"Good practice in the conduct and reporting of survey research\",\n        \"A Hazard Analysis Framework for Code Synthesis Large Language Models, July 2022\",\n        \"A Watermark for Large Language Models, June 2023\",\n        \"FAIR-Ensemble: When Fairness Naturally Emerges From Deep Ensembling, 2023-03-01\",\n        \"Racial disparities in automated speech recognition\",\n        \"Emotional Risks to Respondents in Survey Research: Some Empirical Evidence\",\n        \"Quantifying the Carbon Emissions of Machine Learning\",\n        \"Benchmarking Intersectional Biases in NLP\",\n        \"How We Analyzed the COMPAS Recidivism Algorithm, 2016\",\n        \"Automation as Part of the Solution\",\n        \"OpenAI’s GPT-3 Language Model: A Technical Overview, 2020-06-03\",\n        \"UNQOVERing stereotyping biases via underspecified questions\",\n        \"Holistic Evaluation of Language Models\",\n        \"Socially Aware Bias Measurements for Hindi Language Representations\",\n        \"How do people feel about AI?\",\n        \"The penalty for privacy violations: How privacy violations impact trust online\",\n        \"The AI Index 2023 Annual Report\",\n        \"Between Subjectivity and Imposition: Power Dynamics in Data Annotation for Computer Vision\",\n        \"Minister of Innovation Science and Industry\",\n        \"Dall·e 2 preview - risks and limitations\",\n        \"Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence\",\n        \"ETHOS: A multi-label hate speech detection dataset\",\n        \"Privacy: Studies in Social and Cultural History\",\n        \"National Eating Disorder Association will utilize an AI chatbot | Fortune Well, 2023\",\n        \"Predators Exploit AI Tools to Generate Images of Child Abuse\",\n        \"Stereoset: Measuring stereotypical bias in pretrained language models, 2020\",\n        \"CrowS-pairs: A challenge dataset for measuring social biases in masked language models\",\n        \"Māori are trying to save their language from Big Tech\",\n        \"National Institute of Standards and Technology\",\n        \"The Danger of Misinformation in the COVID-19 Crisis\",\n        \"A Taxonomy of Trustworthiness for Artificial Intelligence\",\n        \"Behind the Millions: Estimating the Scale of Large Language Models, 2023-04-28T17:53:12\",\n        \"Global Research on Artificial Intelligence from 1990–2014: Spatially-Explicit Bibliometric Analysis\",\n        \"HONEST: Measuring Hurtful Sentence Completion in Language Models\",\n        \"Pipelines for social bias testing of large language models\",\n        \"Dissecting racial bias in an algorithm used to manage the health of populations\",\n        \"OECD Framework for the Classification of AI Systems: A tool for effective AI policies, 2023-04-27\",\n        \"Intriguing properties of compression on multilingual models\",\n        \"DALL-E 2 Preview - Risks and Limitations, 2022\",\n        \"Training language models to follow instructions with human feedback\",\n        \"I’m fully who I am\\\": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation, June 2023\",\n        \"Humans and Automation: Use, Misuse, Disuse, Abuse\",\n        \"BBQ: A hand-built bias benchmark for question answering\",\n        \"ABOUT ML Resources Library\",\n        \"Investigating the emotional appeal of fake news using artificial intelligence and human contributions\",\n        \"Overreliance on AI: Literature Review\",\n        \"Prior exposure increases perceived accuracy of fake news\",\n        \"Shifting attention to accuracy can reduce misinformation online\",\n        \"Inside Facebook’s African Sweatshop, 2022\",\n        \"Perspective API\",\n        \"The ROOTS Search Tool: Data Transparency for LLMs, 2023-02-27\",\n        \"On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research, 2023-04-24\",\n        \"Online Abuse and Human Rights: WOAH Satellite Session at RightsCon 2020\",\n        \"On Releasing Annotator-Level Labels and Information in Datasets\",\n        \"The Legal Protection of Crowdworkers: Four Avenues for Workers’ Rights in the Virtual Realm\",\n        \"Digital technologies: tensions in privacy and data\",\n        \"Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing\",\n        \"AI and the Everything in the Whole Wide World Benchmark\",\n        \"The human side of human-chatbot interaction: A systematic literature review of ten years of research on text-based chatbots\",\n        \"Characteristics of harmful text: Towards rigorous benchmarking of language models, 2022\",\n        \"Common but Different Futures: AI Inequity and Climate Change\",\n        \"English Is the Internet’s Universal Language, 2022-02-21\",\n        \"The AI techno-economic complex System: Worldwide landscape, thematic subdomains and technological collaborations\",\n        \"Behind the Screen: Content Moderation in the Shadows of Social Media\",\n        \"A Conversation With Bing’s Chatbot Left Me Deeply Unsettled\",\n        \"RightWingGPT – An AI Manifesting the Opposite Political Biases of ChatGPT, 2023-02-16\",\n        \"“Dangerous organizations: Facebook’s content moderation decisions and ethnic visibility in Myanmar”\",\n        \"S. Balasubramanian\",\n        \"Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding, 2022-05-23\",\n        \"Re-imagining Algorithmic Fairness in India and Beyond\",\n        \"Whose opinions do language models reflect?, 2023\",\n        \"The Risk of Racial Bias in Hate Speech Detection\",\n        \"Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection\",\n        \"Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development\",\n        \"Towards a Standard for Identifying and Managing Bias in Artificial Intelligence, 2022-03-15\",\n        \"Do Massively Pretrained Language Models Make Better Storytellers?\",\n        \"Decolonizing Content Moderation: Does Uniform Global Community Standard Resemble Utopian Equality or Western Power Hegemony?\",\n        \"Work transformed; automation and labor in the computer age\",\n        \"Glaze: Protecting artists from style mimicry by text-to-image models, 2023\",\n        \"No Classification without Representation: Assessing Geodiversity Issues in Open Data Sets for the Developing World\",\n        \"The Cost of Training NLP Models: A Concise Overview\",\n        \"Identifying Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction, 2023-02-08\",\n        \"Narrative Economics\",\n        \"User perceptions and trust of explainable machine learning fake news detectors\",\n        \"When It Comes to Gorillas, Google Photos Remains Blind\",\n        \"On Ethnographic Refusal: Indigeneity, ‘Voice’ and Colonial Citizenship\",\n        \"My Chatbot Companion - a Study of Human-Chatbot Relationships\",\n        \"Beyond the individual: governing ai’s societal harm\",\n        \"The Gradient of Generative AI Release: Methods and Considerations\",\n        \"Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets, 2021-11-23\",\n        \"A Taxonomy of Privacy\",\n        \"Why open-source generative ai models are an ethical way forward for science\",\n        \"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models, June 2022\",\n        \"Energy and Policy Considerations for Deep Learning in NLP\",\n        \"Are You a Racist or Am I Seeing Things? Annotator Influence on Hate Speech Detection on Twitter\",\n        \"Understanding Abuse: A Typology of Abusive Language Detection Subtasks\",\n        \"Disembodied Machine Learning: On the Illusion of Objectivity in NLP\",\n        \"You reap what you sow: On the challenges of bias evaluation under multilingual settings\",\n        \"Generative AI and the protection of intellectual property rights, May 2023\",\n        \"Trade and Industry\",\n        \"Generative AI: Now is the Time for Safety by Design, May 2023\",\n        \"Detecting ‘Dirt’ and ‘Toxicity’: Rethinking Content Moderation as Pollution Behaviour\",\n        \"Cultural Imperialism\",\n        \"On standpoint epistemology and epistemic peerhood: A defense of epistemic privilege\",\n        \"Algorithmic Impact Assessment Tool, 2021-03-22\",\n        \"Enhancing equality and countering discrimination\",\n        \"Algorithmic Accountability Act of 2022, 2022-02-04\",\n        \"Deepfakes and Disinformation: Exploring the Impact of Synthetic Political Video on Deception, Uncertainty, and Trust in News\",\n        \"Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data\",\n        \"Mosaic LLMs (Part 2): GPT-3 quality for <$absentcurrency-dollar<\\\\$500k, 2022\",\n        \"AI art tools Stable Diffusion and Midjourney targeted with copyright lawsuit - The Verge\",\n        \"Twitter taught Microsoft’s AI chatbot to be a racist asshole in less than a day - The Verge, 2016\",\n        \"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\",\n        \"Towards Intersectionality in Machine Learning: Including More Identities, Handling Underrepresentation, and Performing Evaluation\",\n        \"Ethical and social risks of harm from Language Models, 2021-12-08\",\n        \"Using the Veil of Ignorance to align AI systems with principles of justice, 2023\",\n        \"Here’s What Happens When Your Lawyer Uses ChatGPT\",\n        \"Racial discrimination in the criminal justice system: Findings and problems in the literature\",\n        \"Characteristics of publicly available skin cancer image datasets: a systematic review\",\n        \"Opt out of privacy or \\\"go home\\\": understanding reluctant privacy behaviours through the FoMO-centric design paradigm\",\n        \"Evaluating the relationship between marginalization and participation in undeclared work: lessons from Bosnia and Herzegovina\",\n        \"Do Artifacts Have Politics?\",\n        \"National Security\\\" as an Ambiguous Symbol\",\n        \"Sustainable AI: Environmental Implications, Challenges and Opportunities\",\n        \"A Simple Theory of the Survey Response: Answering Questions versus Revealing Preferences\",\n        \"OPT: Open Pre-trained Transformer Language Models, 2022-06-21\",\n        \"Gender bias in contextualized word embeddings\",\n        \"Randomness In Neural Network Training: Characterizing The Impact of Tooling, 2021-06-22\"\n    ],\n    \"reasoning\": \"Selected these 236 references because they represent foundational work and recent advances in Evaluating the Social Impact of Generative AI Systems in Systems and Society, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}