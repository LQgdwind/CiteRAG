{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 48 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Denoising User-aware Memory Network for Recommendation\n\nPaper Abstract: Abstract. For better user satisfaction and business effectiveness, more and more attention has been paid to the sequence-based recommendation system, which is used to infer the evolution of users’ dynamic preferences, and recent studies have noticed that the evolution of users’ preferences can be better understood from the implicit and explicit feedback sequences. However, most of the existing recommendation techniques do not consider the noise contained in implicit feedback, which will lead to the biased representation of user interest and a suboptimal recommendation performance. Meanwhile, the existing methods utilize item sequence for capturing the evolution of user interest. The performance of these methods is limited by the length of the sequence, and can not effectively model the long-term interest in a long period of time. Based on this observation, we propose a novel CTR model named denoising user-aware memory network (DUMN). Specifically, the framework: (i) proposes a feature purification module based on orthogonal mapping, which use the representation of explicit feedback to purify the representation of implicit feedback, and effectively denoise the implicit feedback; (ii) designs a user memory network to model the long-term interests in a fine-grained way by improving the memory network, which is ignored by the existing methods; and (iii) develops a preference-aware interactive representation component to fuse the long-term and short-term interests of users based on gating to understand the evolution of unbiased preferences of users. Extensive experiments on two real e-commerce user behavior datasets show that DUMN has a significant improvement over the state-of-the-art baselines. The code of DUMN model has been uploaded as an additional material.\n\n{retrieved_text}\n\nGenerate exactly 48 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 48\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"LiJAR: A system for job application redistribution towards efficient career marketplace\",\n        \"Fast adaptively weighted matrix factorization for recommendation with implicit feedback\",\n        \"Wide & deep learning for recommender systems\",\n        \"Deep neural networks for youtube recommendations\",\n        \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n        \"Deep Session Interest Network for Click-Through Rate Prediction\",\n        \"Algorithms for nonnegative matrix factorization with the ββ\\\\beta-divergence\",\n        \"Using collaborative filtering to weave an information tapestry\",\n        \"Neural turing machines\",\n        \"Deep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems\",\n        \"DeepFM: a factorization-machine based neural network for CTR prediction\",\n        \"Rank and rate: multi-task learning for recommender systems\",\n        \"Session-based Recommendations with Recurrent Neural Networks\",\n        \"Collaborative filtering for implicit feedback datasets\",\n        \"Densely connected convolutional networks\",\n        \"Unifying explicit and implicit feedback for rating prediction and ranking recommendation tasks\",\n        \"An Efficient Neighborhood-based Interaction Model for Recommendation on Heterogeneous Graph\",\n        \"Self-attentive sequential recommendation\",\n        \"Semi-supervised classification with graph convolutional networks\",\n        \"Factorization meets the neighborhood: a multifaceted collaborative filtering model\",\n        \"Matrix factorization techniques for recommender systems\",\n        \"Neural attentive session-based recommendation\",\n        \"Interpretable Click-Through Rate Prediction through Hierarchical Attention\",\n        \"xdeepfm: Combining explicit and implicit feature interactions for recommender systems\",\n        \"Unifying explicit and implicit feedback for collaborative filtering\",\n        \"SDM: Sequential deep matching model for online large-scale recommender system\",\n        \"Unclicked User Behaviors Enhanced SequentialRecommendation\",\n        \"Perceive your users in depth: Learning universal user representations from multiple e-commerce tasks\",\n        \"Personalized news recommendation using classified keywords to capture user preference\",\n        \"Practice on long sequential user behavior modeling for click-through rate prediction\",\n        \"Feature projection for improved text classification\",\n        \"Product-based neural networks for user response prediction\",\n        \"You only look once: Unified, real-time object detection\",\n        \"RecVAE: A new variational autoencoder for Top-N recommendations with implicit feedback\",\n        \"Heterogeneous information network embedding for recommendation\",\n        \"Autoint: Automatic feature interaction learning via self-attentive neural networks\",\n        \"Personalized top-n sequential recommendation via convolutional sequence embedding\",\n        \"Deep content-based music recommendation\",\n        \"Attention is All you Need\",\n        \"Deep & cross network for ad click predictions\",\n        \"Graph-Refined Convolutional Network for Multimedia Recommendation with Implicit Feedback\",\n        \"Deep Feedback Network for Recommendation\",\n        \"Personalized entity recommendation: A heterogeneous information network approach\",\n        \"Coupledcf: Learning explicit and implicit user-item couplings in recommendation for deep collaborative filtering\",\n        \"Recommendations with negative feedback via pairwise deep reinforcement learning\",\n        \"Atrank: An attention-based user behavior modeling framework for recommendation\",\n        \"Deep interest evolution network for click-through rate prediction\",\n        \"Deep interest network for click-through rate prediction\"\n    ],\n    \"reasoning\": \"Selected these 48 references because they represent foundational work and recent advances in Denoising User-aware Memory Network for Recommendation, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}