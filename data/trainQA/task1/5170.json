{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 54 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Benchmarking Subset Selection from Large Candidate Solution Sets in Evolutionary Multi-objective Optimization\n\nPaper Abstract: Abstract In the evolutionary multi-objective optimization (EMO) field, the standard practice is to present the final population of an EMO algorithm as the output. However, it has been shown that the final population often includes solutions which are dominated by other solutions generated and discarded in previous generations. Recently, a new EMO framework has been proposed to solve this issue by storing all the non-dominated solutions generated during the evolution in an archive and selecting a subset of solutions from the archive as the output. The key component in this framework is the subset selection from the archive which usually stores a large number of candidate solutions. However, most studies on subset selection focus on small candidate solution sets for environmental selection. There is no benchmark test suite for large-scale subset selection. This paper aims to fill this research gap by proposing a benchmark test suite for subset selection from large candidate solution sets, and comparing some representative methods using the proposed test suite. The proposed test suite together with the benchmarking studies provides a baseline for researchers to understand, use, compare, and develop subset selection methods in the EMO field.\n\n{retrieved_text}\n\nGenerate exactly 54 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 54\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Distributed Pareto optimization for large-scale noisy subset selection\",\n        \"Maximizing the spread of influence through a social network\",\n        \"Subset selection in regression\",\n        \"An efficient greedy method for unsupervised feature selection\",\n        \"Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies.\",\n        \"A threshold of ln n for approximating set cover\",\n        \"Non-metric affinity propagation for unsupervised image categorization\",\n        \"Two-dimensional subset selection for hypervolume and epsilon-indicator\",\n        \"Hypervolume subset selection in two dimensions: Formulations and algorithms\",\n        \"Greedy hypervolume subset selection in low dimensions\",\n        \"Performance assessment of multiobjective optimizers: an analysis and review\",\n        \"Distance-based subset selection for benchmarking in evolutionary multi/many-objective optimization\",\n        \"Distance-based subset selection revisited\",\n        \"Clustering-based subset selection in evolutionary multiobjective optimization\",\n        \"An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, Part I: Solving problems with box constraints\",\n        \"A study of the parallelization of a coevolutionary multi-objective evolutionary algorithm\",\n        \"Modified distance calculation in generational distance and inverted generational distance\",\n        \"A new framework of evolutionary multi-objective algorithms with an unbounded external archive\",\n        \"An empirical investigation of the optimality and monotonicity properties of multiobjective archiving methods\",\n        \"A fast and elitist multiobjective genetic algorithm: NSGA-II\",\n        \"Substitute distance assignments in NSGA-II for handling many-objective optimization problems\",\n        \"SPEA2: Improving the strength Pareto evolutionary algorithm\",\n        \"Shift-based density estimation for Pareto-based algorithms in many-objective optimization\",\n        \"Indicator-based selection in multiobjective search\",\n        \"SMS-EMOA: Multiobjective selection based on dominated hypervolume\",\n        \"MOEA/D: A multiobjective evolutionary algorithm based on decomposition\",\n        \"Evolutionary many-objective algorithm based on fractional dominance relation and improved objective space decomposition strategy\",\n        \"A self-guided reference vector strategy for many-objective optimization\",\n        \"A new many-objective evolutionary algorithm based on generalized Pareto dominance\",\n        \"Two-archive evolutionary algorithm for constrained multiobjective optimization\",\n        \"Enhancing MOEA/D with information feedback models for large-scale many-objective optimization\",\n        \"A decision variable clustering-based evolutionary algorithm for large-scale many-objective optimization\",\n        \"A simple and fast hypervolume indicator-based multiobjective evolutionary algorithm\",\n        \"Maximum volume subset selection for anchored boxes\",\n        \"A survey on the hypervolume indicator in evolutionary multiobjective optimization\",\n        \"Incrementally maximising hypervolume for selection in multi-objective evolutionary algorithms\",\n        \"Selecting a small number of representative non-dominated solutions by a hypervolume-based solution selection approach\",\n        \"Maximizing submodular functions under matroid constraints by multi-objective evolutionary algorithms\",\n        \"Measuring the quality of discrete representations of efficient sets in multiple objective mathematical programming\",\n        \"Representative subset selection\",\n        \"Normal-boundary intersection: A new method for generating the Pareto surface in nonlinear multicriteria optimization problems\",\n        \"Performance of decomposition-based many-objective algorithms strongly depends on Pareto front shapes\",\n        \"Bounding the effectiveness of hypervolume-based (Œºùúá+ŒªùúÜ)-archiving algorithms\",\n        \"Fast greedy subset selection from large candidate solution sets in evolutionary multi-objective optimization\",\n        \"An analysis of approximations for maximizing submodular set functions‚ÄîI\",\n        \"Uniform distributions and random variate generation over generalized lp balls and spheres\",\n        \"Scalable test problems for evolutionary multiobjective optimization\",\n        \"A review of multiobjective test problems and a scalable test problem toolkit\",\n        \"A fast way of calculating exact hypervolumes\",\n        \"Greedy approximated hypervolume subset selection for many-objective optimization\",\n        \"R2-based hypervolume contribution approximation\",\n        \"PlatEMO: A MATLAB platform for evolutionary multi-objective optimization [educational forum]\",\n        \"Comparison of hypervolume, IGD and IGD+ from the viewpoint of optimal distributions of solutions\",\n        \"Reference point specification in inverted generational distance for triangular linear Pareto front\"\n    ],\n    \"reasoning\": \"Selected these 54 references because they represent foundational work and recent advances in Benchmarking Subset Selection from Large Candidate Solution Sets in Evolutionary Multi-objective Optimization, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}