{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Ethical Considerations for Responsible Data Curation\n\nPaper Abstract: \n\nPaper Section Text:\nObtain self-reported annotations.\nPractitioners are cautious about inferring labels about people to avoid biases . Moreover, data access request rights, e.g., as offered by GDPR, California Consumer Privacy Act, and PIPL, may require data holders to disclose inferred information. To avoid stereotypical annotations and minimize harm from misclassification , labels should be collected directly from image subjects, who inherently possess contextual knowledge of their environment and awareness of their own attributes. Provide open-ended response options.\nClosed-ended questions, such as those on census forms, may lead to incongruous responses and inadequate options for self-identification  6 9. Open-ended questions provide more accurate answers but can be taxing, require extensive coding, and are harder to analyze    . To balance this, closed-ended questions should be augmented with an open-ended response option, avoiding the term “other”, which implies othering norms . This gives subjects a voice   and allows for future question design improvement. Acknowledge the mutability and multiplicity of identity.\nIdentity shift—the intentional self-transformation in mediated contexts —is often overlooked. To address this, we propose collecting self-identified information on a per-image basis, acknowledging that identity is temporal and nonstatic. Specifically, for sensitive attributes, allowing the selection of multiple identity categories without limitations is preferable  [ref]309. This prevents oversimplification and marginalization. While we acknowledge the potential burden of self-identification on fluid and dynamic identities, an image captures a single moment. Thus, evolving identity may not require metadata updates; however, we recommend providing subjects with mechanisms for updates when needed. Collect age, pronouns, and ancestry.\nFirst, to capture accurate age information, dataset curators should collect the exact biological age in years from image subjects, corresponding to their age at the time of image capture. This approach offers flexibility, insofar as permitting the appropriate aggregation of the collected data. This is particularly important given the lack of consistent age groupings in the literature. Second, dataset curators should consider opting to collect self-identified pronouns. This promotes mutual respect and common courtesy, reducing the likelihood of causing harm through misgendering 7. Self-identified pronouns are particularly important for sexual and gender minority communities as they “convey and affirm gender identity” . Significantly, pronoun use is increasingly prevalent in social media platforms   , workplaces , and education settings  , fostering gender inclusivity . However, subjects should always have the option of not disclosing this information. Finally, to address issues with ethnic and racial classification systems  , dataset creators should consider collecting ancestry information instead. Ancestry is defined by historically shaped borders and has been shown to offer a more stable and less confusing concept . The United Nations’ M49 geoscheme can be used to operationalize ancestry , where subjects select regions that best describe their ancestry. To situate responses, subjects could be asked, e.g., “Where do your ancestors (e.g., great-grandparents) come from?”. This avoids reliance on proxies, e.g., skin tone, that risk normalizing their inadequacies without reflecting their limitations . Collect aggregate data for commonly ignored groups.\nAdditional sensitive attributes should also be collected, such as disability and pregnancy status, when voluntarily disclosed by subjects. These attributes should be reported in aggregate data to reduce the safety concerns of subjects [ref]309 . Given that definitions of these attributes may be inconsistent and tied to culture, identity, and histories of oppression [ref]37 , navigating tensions between benefits and risks is necessary. Despite potential reluctance, sourcing data from underrepresented communities contributes to dataset inclusivity [ref]37 . Regarding disability, the American Community Survey  covers categories related to hearing, vision, cognitive, ambulatory, self-care, and independent living difficulties. Collect phenotypic and neutral performative features.\nCollecting phenotypic characteristics can serve as objective measures of diversity, i.e., attributes which, in evolutionary terms, contribute to individual-level recognition , e.g., skin color, eye color, hair type, hair color, height, and weight . These attributes have enabled finer-grained analysis of model performance and biases      . Additionally, considering a multiplicity of neutral performative features, e.g., facial hair, hairstyle, cosmetics, clothing, and accessories, is important to surface the perpetuation of social stereotypes and spurious relationships in trained models     . Record environment and instrument information.\n\nData should capture variations in environmental conditions and imaging devices, including factors such as image capture time, season, weather, ambient lighting, scene, geography, camera position, distance, lens, sensor, stabilization, use of flash, and post-processing software. Instrument-related factors may be easily captured, by restricting data collection to images with exchangeable image file format (Exif) metadata. The remaining factors, e.g., season and weather can be self-reported or coarsely estimated utilizing information such as image capture time and location. Recontextualize annotators as contributors.\nDataset creators should document the identities of annotators and their contributions to the dataset  , rather than treating them as anonymous entities responsible for data labeling alone 6 . While many datasets 6   neglect to report annotator demographics, assuming objectivity in annotation for visual categories is flawed  9 . Furthermore, using majority voting to reach the assumed ground truth, disregards minority opinions, treating them as noise . Annotator characteristics, including pronouns, age, and ancestry, should be recorded and reported to quantify and address annotator perspectives and bias in datasets  . Additionally, allowing annotators freedom in labeling helps to avoid replicating socially dominant viewpoints 9. Fair treatment and compensation for contributors.\nIn accordance with Australia’s National Health and Medical Research Council 1 and the WHO 6, dataset contributors should not only be guaranteed compensation above the minimum hourly wage of their country of residence , but also according to the complexity of tasks to be performed. However, alternative payment models, for example, based on the average hourly wage, may offer benefits in terms of promoting diversity by increasing the likelihood of higher socio-economic status contributors . Besides payment, the implementation of direct communication channels and feedback mechanisms, such as anonymized feedback forms , can help to address issues faced by annotators while providing a level of protection from retribution. Furthermore, the creation of plain language guides can ease task completion and reduce quality control overheads. Ideally, recruitment and compensation processes should be well-documented and undergo ethics review, which can help to further reduce the number of “glaring ethical lapses” .\n\nReference markers found: [309]\n\nContext windows for each [ref]:\n[ref]309: basis, acknowledging that identity is temporal and nonstatic. Specifically, for sensitive attributes, allowing the selection of multiple identity categories without limitations is preferable  [ref]309. This prevents oversimplification and marginalization. While we acknowledge the potential burden of self-identification on fluid and dynamic identities, an image captures a single moment.\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 309,\n            \"titles\": [\n                \"End-to-end people detection in crowded scenes\",\n                \"Announcing the NeurIPS Code of Ethics\",\n                \"OpenAI and Microsoft Sued for $3 Billion Over Alleged ChatGPT ’Privacy Violations’ — vice.com\",\n                \"Shared, but not up for grabs\",\n                \"What Else Can Fool Deep Learning? Addressing Color Constancy Errors on Deep Neural Network Performance\",\n                \"Data Readiness Report\",\n                \"Gendered Differences in Face Recognition Accuracy Explained by Hairstyles, Makeup, and Facial Morphology\",\n                \"Turning a Blind Eye: Explicit Removal of Biases and Variation from Deep Neural Network Embeddings\",\n                \"An own-age bias in face recognition for children and older adults\",\n                \"Evidence for an own-age bias in face recognition\",\n                \"The human in emotion recognition on social media: Attitudes, outcomes, risks\",\n                \"The hidden fingerprint inside your photos\",\n                \"A View From Somewhere: Human-Centric Face Representations\",\n                \"2d human pose estimation: New benchmark and state of the art analysis\",\n                \"Working to address algorithmic bias? don’t overlook the role of demographic data\",\n                \"”What We Can’t Measure, We Can’t Understand”: Challenges to Demographic Data Procurement in the Pursuit of Fairness\",\n                \"Pruning training sets for learning of object categories\",\n                \"Operationalising the collection of ethnicity data in studies of the sociology of health and illness\",\n                \"Towards causal benchmarking of bias in face analysis algorithms\",\n                \"Human phenotypic diversity\",\n                \"Students can adjust their pronouns and gender identity in bu’s updated data system\",\n                \"What’s Your Pronoun?: Beyond He and She\",\n                \"Google mistakenly tags Black people as ‘gorillas,’ showing limits of algorithms\",\n                \"Skin Deep: Investigating Subjectivity in Skin Tone Annotations for Computer Vision Benchmark Datasets\",\n                \"Principles of biomedical ethics: marking its fortieth anniversary\",\n                \"A survey on facial soft biometrics for video surveillance and forensic applications\",\n                \"Recognition in Terra Incognita\",\n                \"Data statements for natural language processing: Toward mitigating system bias and enabling better science\",\n                \"Racial categories in machine learning\",\n                \"Detecting discriminatory risk through data annotation based on Bayesian inferences\",\n                \"Representation in ai evaluations\",\n                \"Children and the data cycle: Rights and ethics in a big data world\",\n                \"Algorithmic colonization of africa\",\n                \"Automating ambiguity: Challenges and pitfalls of artificial intelligence\",\n                \"Large image datasets: A pyrrhic win for computer vision?\",\n                \"Multimodal datasets: misogyny, pornography, and malignant stereotypes\",\n                \"Why is data on disability so hard to collect and understand?\",\n                \"Making Intelligence: Ethical Values in IQ and ML Benchmarks\",\n                \"Picking on the same person: Does algorithmic monoculture lead to outcome homogenization?\",\n                \"Respondent burden: health survey research methods\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]309 based on the context and research area of Ethical Considerations for Responsible Data Curation. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}