{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Unsupervised Continual Learning in Streaming Environments\n\nPaper Abstract: \n\nPaper Section Text:\nExperimental Setup: ADCN capability in handling unsupervised continual learning problems is tested here where the number of tasks is greater than one (n​T>1𝑛𝑇1nT>1). We consider two continual learning scenarios in creating different tasks, i.e., new instances (NI) and new classes (NC) [ref]7. The former scenario is defined as a situation where the newly seen data of the same classes come into the picture in the following batches possessing different distribution, whereas the latter scenario defines a case where the newly seen data of different classes arrive in subsequent batches. Besides prequential accuracy, we also measure task accuracy (task acc.), positive backward transfer (BWT) and positive forward transfer (FWT) as suggested in 3. In a nutshell, those three metrics are commonly used in continual learning, and measure an algorithm’s capability in both handling catastrophic forgetting and utilizing the past knowledge to improve its prediction in the incoming task. Using them together satisfies to determine the efficacy of a continual learning algorithm. Note that BWT and FWT is a value within −∞-\\infty to +∞+\\infty, with a high positive value being the best performance in mitigating catastrophic forgetting problems and in exhibiting positive knowledge transfer. Unless otherwise stated, a similar setup as in the first simulation scenario is adopted. In each task, all consolidated algorithms only have access to (Ni​n​i​t/n​T)subscript𝑁𝑖𝑛𝑖𝑡𝑛𝑇(N_{init}/nT) initial unlabeled data of the current task for pre-training purpose. After that, all algorithms process streaming unlabeled samples batch-by-batch in a one-pass learning fashion. Several labeled samples per class (Nm/n​T)subscript𝑁𝑚𝑛𝑇(N_{m}/nT) are incrementally provided according to the task for performing classification. We simply consider [Ni​n​i​t,Nm]= subscript𝑁𝑖𝑛𝑖𝑡subscript𝑁𝑚5000500[N_{init},N_{m}]= . In each task, we also let a batch of data remain unseen for calculating task accuracy, BWT and FWT. That is, an algorithm is required to perform classification on all previously seen tasks at the end of every task. The simulation scenario of unsupervised continual learning is illustrated in Fig. S-2 of the supplemental document. Benchmark Datasets: Rotated MNIST (RMNIST) 3, Permuted MNIST (PMNIST) , Split MNIST (SMNIST)  are considered as benchmarks here which are created from the real-world handwritten digit dataset MNIST . In addition to the three-digit recognition problems, the Split CIFAR10 (SCIFAR10) problem  is included in our experiment. CIFAR10 is a popular dataset used to evaluate the performance of an image classification algorithm. It consists of 50K training images and 10K testing images incorporating 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck 6. Besides the classes are completely mutually exclusive 6, it has been demonstrated in  that the nearest neighbour cluster of CIFAR10 under the L2 distance metric is more unclear than that of MNIST. This causes CIFAR10 more difficult to classify than MNIST, thereby providing a more competitive benchmark for testing out ADCN. RMNIST and PMNIST problems are respectively generated via image rotation and image pixel permutation realizing the NI scenario. Four tasks are considered here (n​T=4𝑛𝑇4nT=4) generated by applying four sets of rotation angle, i.e., { , , , }0303160619091120\\{ , , , \\}, and four random permutations to images. SMNIST and SCIFAR10 are generated by splitting the MNIST dataset in sequence based on its classes (0/1, 2/3, 4/5, 6/7, 8/9) creating five tasks (n​T=5𝑛𝑇5nT=5). SMNIST and SCIFAR10 problems realize the NC scenario. Finally, we can have 15K samples (for RMNIST and PMNIST), 13K samples (for SMNIST) and 11K samples (for SCIFAR10) as streaming unlabeled data in each task. Algorithms and Parameters: we compare the proposed ADCN with DCN, AE+KMEANS and Self-Taught Associative Memory (STAM) . To make their learning policy fit in a continual learning environment, we arm DCN and AE+KMEANS with the state-of-the-art methods in the field, i.e., learning without forgetting (LwF)  and synaptic intelligence (SI) 8. In a nutshell, LwF and SI are capable of mitigating catastrophic forgetting problem respectively via controlling output stability and preventing the important parameters of the previous task to move away from the optimal solution. Note that they are originally operated in supervised learning. Here, those methods are used to update the autoencoder network in an unsupervised manner. On the other hand, STAM is an unsupervised continual learning algorithm consisting of a hierarchy of increasing receptive field, online clustering, novelty detection and a dual-memory that stores the prototype of data . It works in the similar manner as ADCN, with the exception that STAM uses a non-neural network model as the feature extractor. On RMNIST, SMNIST and SCIFAR10 problems, all consolidated algorithms utilize the same network structure as that on the MNIST and CIFAR10 problems in the first experiment scenario. A two-layered MLP is put forward as a feature extractor instead of CNN to deal with the PMNIST problem with  1000500  hidden nodes in each layer. It is reasonable since the PMNIST problem requires a network to take into account all image pixels without any exception which is unachievable by CNN. Unless otherwise noted, the ADCN and SGD hyperparameters in the second experiment adopt the same value as in the first simulation scenario. The maximum regularization strength is set as β=5𝛽5\\beta=5 which is also applied in LwF. The regularization strength of SI is set as 0.2 in the first task and 0.8 in the remaining tasks. These values are fixed during experiments. In the case of SCIFAR10, the learning process in streaming phase applies a small epoch of 10 times which is still applicable in streaming environments. Results:\nit is reported in Tables III that ADCN produces the highest task and prequential accuracy in RMNIST and SCIFAR10 problems. The t-test confirms that these results are statistically significant (P << 0.05). The rejection of the null hypothesis indicates that ADCN’s predictive accuracy is significantly better than other baselines. In terms of resolving the catastrophic forgetting problem, ADCN delivered a -13-point on average in BWT. This result is achievable since ADCN is capable of maintaining its output stability and storing the previous knowledge via latent-based regularization and self-clustering mechanism. Interestingly, the stored knowledge also helps to improve the predictive performance in incoming tasks indicated by an FWT of 18 on average, which is the highest value among the consolidated algorithms. This signifies that the ADCN learning policy is also suitable for addressing a transfer learning problem where the main objective is to obtain better predictive performance only in the target task after learning a source task. Separately, it is observed that the performance of ADCN on SMNIST is second only to that of STAM. This is understood since STAM adopts a hierarchy of increasing receptive fields as the feature extractor. This structure is more robust against catastrophic forgetting because each receptive field is able to store a specific knowledge. On the other hand, ADCN employs neural network architectures for feature extraction. One reason neural networks are prone to catastrophic forgetting is that the knowledge of all tasks is likely to be distributed across all nodes, rather than secluded to specific groups of nodes 9. Utilizing neural network structures, however, enables ADCN to perform the learning process on GPU and thus accelerates the learning process. For instance, the average execution time of ADCN on all cases to train and test a data batch is around 70 seconds, whereas STAM requires more than 240 seconds to complete both processes. This fact highlights that ADCN is more applicable for practical implementation in streaming environments. Also, it is noticed that ADCN’s numerical results are inferior to other methods on the PMNIST problem. We also notice that the performances of other baselines are unsatisfactory on this problem. This finding is likely attributed to the abrupt-change nature of the problem that occurred between tasks. The relatively low FWT on this problem supports our argument, signifying that there is almost no relevant knowledge to improve the performance in incoming tasks. It is understood that the latent representation learned by a DNN tend to be stable or less varying. When the task changes, the update forces the parameters to move to a point optimizing the performance on the new task resulting in changing representation. The implementation of LC​Lsubscript𝐿𝐶𝐿L_{CL}, LwF and SI try to consolidate the amount of update such that the network is capable of generating the stable latent representation. Changes that occurred on the PMNIST problem, however, are too severe to be addressed by these strategies in a single-pass learning fashion without any supervision. Another rationale behind low results in the PMNIST problem is attributed by the absence of any labeled samples for model updates. That is, the structural evolution is only guided by the reconstruction loss meaning that it only adapts to the virtual drift. The comparison results against all baselines demonstrate the efficacy of the ADCN self-organizing mechanism. Note that all consolidated algorithms possess the same network capacity at the beginning of the training process. Moreover, all baselines start with 500 clusters, whereas ADCN only consists of 2 clusters before the process runs. ADCN, however, is capable of increasing its network and learning capacity on demand. The uncovered latent representation can be immediately accommodated via a cluster growing mechanism. On the other hand, all baselines possess a static learning capacity requiring them to replace the stored knowledge in the cluster with a new one whenever there are new instances or classes. Because of this reason, their accuracy drastically suffers in an unsupervised continual learning scenario. This finding suggests that the evolving trait of ADCN took part in both delivering better predictive performance and preventing catastrophic forgetting.\n\nReference markers found: [7]\n\nContext windows for each [ref]:\n[ref]7: is tested here where the number of tasks is greater than one (n​T>1𝑛𝑇1nT>1). We consider two continual learning scenarios in creating different tasks, i.e., new instances (NI) and new classes (NC) [ref]7. The former scenario is defined as a situation where the newly seen data of the same classes come into the picture in the following batches possessing different distribution, whereas the\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 7,\n            \"titles\": [\n                \"Online Deep Learning: Learning Deep Neural Networks on the Fly\",\n                \"Extracting and composing robust features with denoising autoencoders\",\n                \"Knowledge Discovery from Data Streams\",\n                \"Learning without Forgetting\",\n                \"A generalized growing and pruning rbf (ggap-rbf) neural network for function approximation\",\n                \"Towards Compact ConvNets via Structure-Sparsity Regularized Filter Pruning\",\n                \"Online tool condition monitoring based on parsimonious ensemble+\",\n                \"Continuous Learning in Single-Incremental-Task Scenarios\",\n                \"Online incremental feature learning with denoising autoencoders\",\n                \"The Power of Depth for Feedforward Neural Networks\",\n                \"Autonomous Deep Learning: Continual Learning Approach for Dynamic Environments\",\n                \"Automatic construction of multi-layer perceptron network from streaming examples\",\n                \"Palm: An incremental construction of hyperplanes for data stream regression\",\n                \"Data stream classification guided by clustering on nonstationary environments and extreme verification latency\",\n                \"Continual multiview task learning via deep matrix factorization\",\n                \"Semi-supervised hashing for scalable image retrieval\",\n                \"Devdan: Deep evolving denoising autoencoder\",\n                \"Compose: A semisupervised learning framework for initially labeled nonstationary streaming data\",\n                \"A self-evolving mutually-operative recurrent network-based model for online tool condition monitoring in delay scenario\",\n                \"Weakly supervised deep learning approach in streaming environments\",\n                \"Unsupervised continual learning and self-taught associative memory hierarchies\",\n                \"Toward integrating feature selection algorithms for classification and clustering\",\n                \"Billion-scale similarity search with GPUs\",\n                \"Deep clustering for unsupervised learning of visual features\",\n                \"MNIST handwritten digit database\",\n                \"Deep Learning for Classical Japanese Literature\",\n                \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n                \"Progress & Compress: A scalable framework for continual learning\",\n                \"A streaming ensemble algorithm (sea) for large-scale classification\",\n                \"Moa: Massive online analysis\",\n                \"The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients\",\n                \"On the surprising behavior of distance metrics in high dimensional space\",\n                \"Gradient Episodic Memory for Continual Learning\",\n                \"Overcoming catastrophic forgetting in neural networks\",\n                \"Lifelong Learning with Dynamically Expandable Networks\",\n                \"Learning multiple layers of features from tiny images\",\n                \"t-SNE-CUDA: GPU-Accelerated t-SNE and its Applications to Modern Data\",\n                \"Continual learning through synaptic intelligence\",\n                \"Catastrophic forgetting in connectionist networks\",\n                \"The nature of statistical learning theory\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]7 based on the context and research area of Unsupervised Continual Learning in Streaming Environments. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}