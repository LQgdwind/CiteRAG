{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Quantum computational complexity of matrix functions\n\nPaper Abstract: \n\nPaper Section Text:\nWe now summarize our contributions. In this section we give informal versions of our results, quoted alongside prior results in the literature which also fall into our setting. We also point the reader to Table 1 which provides a further condensed visual summary. Full, formal statements along with proofs can be found in Sec. 4. As mentioned in Sec. 1.2, Problem I has already been considered for monomials\nfm​(x)=xmsubscript𝑓𝑚𝑥superscript𝑥𝑚f_{m}(x)=x^{m} in , where it was shown that  if A𝐴A is given through sparse access and satisfies ∥A∥≤1delimited-∥∥𝐴1\\left\\lVert A\\right\\rVert\\leq 1, the problem is BQP-complete.\nWe show an analogous result for the Pauli Access model, and even when A𝐴A is assumed to be Pauli-sparse.\nWe also show that these two results hold for the local measurement problem too.\nIn turn, when the norm condition ∥A∥≤1delimited-∥∥𝐴1\\left\\lVert A\\right\\rVert\\leq 1 is strengthened to ∥A∥≤1−ηdelimited-∥∥𝐴1𝜂\\left\\lVert A\\right\\rVert\\leq 1-\\eta, for any fixed η>0𝜂0\\eta>0,\nboth problems become classically easy for both access models given a sparsity assumption. The same has been known to be true in the absence of an additional sparsity assumption for the alternative norm assumptions ∥A∥1≤1subscriptdelimited-∥∥𝐴11\\left\\lVert A\\right\\rVert_{1}\\leq 1 or λA≤1subscript𝜆𝐴1\\lambda_{A}\\leq 1, which was shown in  and  respectively.\nFinally, we find the problem is classically easy to solve exactly if the matrix is made sparse enough in the Pauli basis. Instantiate Problems I and II with fm​(x)=xmsubscript𝑓𝑚𝑥superscript𝑥𝑚f_{m}(x)=x^{m}. Unless explicitly stated, set m𝑚m, 1/ε=𝒪​(poly⁡log⁡(N))1𝜀𝒪poly𝑁1/\\varepsilon=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)), ‖A‖≤1norm𝐴1\\|A\\|\\leq 1, and let A𝐴A be either sparse or Pauli-sparse (i.e., either s𝑠s or L,λA=𝒪​(poly⁡log⁡(N))𝐿subscript𝜆𝐴𝒪poly𝑁L,\\lambda_{A}=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right))) depending on the access model. Then: Problem I is BQP-complete when the input matrix A𝐴A is given through both the sparse access model (Thm. 21 6) or the Pauli access model (Prop. 23), as is Problem II in both access models (Prop. 24). For the sparse access model this holds even for a choice of s=𝒪​(1)𝑠𝒪1s=\\mathcal{O}(1). Moreover, in both cases, the result holds even if we add the condition that ∥A∥1≤2subscriptdelimited-∥∥𝐴12\\left\\lVert A\\right\\rVert_{1}\\leq 2. Both problems can be solved efficiently classically in time 𝒪​(poly⁡log⁡(N))𝒪poly𝑁\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)) whenever A𝐴A is given through the sparse access model and satisfies either s=1𝑠1s=1, or s=𝒪​(1)𝑠𝒪1s=\\mathcal{O}(1) and m=𝒪​(log⁡log⁡N)𝑚𝒪𝑁m=\\mathcal{O}(\\log\\log N) (exact algorithm, Lemma 17 and ), or ∥A∥≤1−ηdelimited-∥∥𝐴1𝜂\\left\\lVert A\\right\\rVert\\leq 1-\\eta with η=Ω​(1)𝜂Ω1\\eta=\\Omega(1), s=𝒪​(1)𝑠𝒪1s=\\mathcal{O}(1) (Props. 25 and 26), or ∥A∥1≤1subscriptdelimited-∥∥𝐴11\\left\\lVert A\\right\\rVert_{1}\\leq 1 (Prop. 27 ). Both problems can be solved efficiently classically in time 𝒪​(poly⁡log⁡(N))𝒪poly𝑁\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right))\nwhenever A𝐴A is given through the Pauli access model and satisfies either: ∥A∥≤1−ηdelimited-∥∥𝐴1𝜂\\left\\lVert A\\right\\rVert\\leq 1-\\eta, λA=𝒪​(1)subscript𝜆𝐴𝒪1\\lambda_{A}=\\mathcal{O}(1), and η=Ω​(1)𝜂Ω1\\eta=\\Omega(1)(Props. 25 and 26), or λA≤1subscript𝜆𝐴1\\lambda_{A}\\leq 1(Prop. 28 ) Both problems can be solved efficiently classically in time 𝒪​(poly⁡log⁡(N))𝒪poly𝑁\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)) if A𝐴A either Has at most 𝒪​(poly⁡log⁡(N))𝒪poly𝑁\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)) non-zero entries in the computational basis (Prop. 29), or Is given through the Pauli access model and L=𝒪​(log⁡log⁡N)𝐿𝒪𝑁L=\\mathcal{O}(\\log\\log N) (Thm. 30). The fact that a strengthening of the norm condition ∥A∥≤1delimited-∥∥𝐴1\\left\\lVert A\\right\\rVert\\leq 1 to ∥A∥≤1−ηdelimited-∥∥𝐴1𝜂\\left\\lVert A\\right\\rVert\\leq 1-\\eta allows one to develop efficient classical algorithms suggests that the quantum advantage is related to handling the higher end of the spectrum, i.e. the eigenvectors with eigenvalues close to one.\nWe note that the condition ∥A∥≤1−ηdelimited-∥∥𝐴1𝜂\\left\\lVert A\\right\\rVert\\leq 1-\\eta was also studied in  as a sufficient condition to construct a non-normalized quantum block encoding starting from sparse query access.444The standard way [2, Lemma 48] of preparing a block encoding of an s𝑠s-sparse matrix A𝐴A with largest matrix entry magnitude ≤1absent1\\leq 1 given through the sparse access model returns a subnormalized block encoding of A/s𝐴𝑠A/s. To the authors’ knowledge, there is not currently a known method to generically obtain a non-normalized block encoding when starting from sparse access. This indicates that for certain problems, specific use of a block encoding could shroud superpolynomial quantum advantage. We observe that the classical algorithm from M.2.2 cannot be extended to matrices with ‖A‖1=𝒪​(1)subscriptnorm𝐴1𝒪1\\|A\\|_{1}=\\mathcal{O}(1) or s=𝒪​(1)𝑠𝒪1s=\\mathcal{O}(1) since the hardness results holds even when ∥A∥1≤2subscriptdelimited-∥∥𝐴12\\left\\lVert A\\right\\rVert_{1}\\leq 2 and s=4𝑠4s=4 (Thm. 21 and Ref. 6), that is, under standard computational assumptions. This reflects a sharp transition in hardness with respect to the norm parameter. A first look at M.1 indicates that for a certain variation of the problem, the BQP-hardness is robust with respect to the choice of access model, namely the setting of . However, result M.4 shows a concrete difference in complexity between the Pauli and sparse access models in the regime when the sparsity is smaller than poly⁡log⁡(N)poly𝑁\\operatorname{poly}\\log\\!\\left(N\\right). As discussed, in the sparse access model constant row sparsity is in general BQP-hard. In contrast, here we see that if A𝐴A has structure in the Pauli basis with L=𝒪​(log⁡log⁡(N))𝐿𝒪𝑁L=\\mathcal{O}(\\log\\log(N)), implying super-constant sparsity s=𝒪​(log⁡log⁡(N))𝑠𝒪𝑁s=\\mathcal{O}(\\log\\log(N)) (and total number of non-zero computational-basis elements is 𝒪​(L​N)𝒪𝐿𝑁\\mathcal{O}(LN)), the problem is classically easy. This implies that Pauli structure does indeed make problems easier than other efficiently computable sparse accesses. The difference regarding the complexities between the access models for our classical algorithms (we demand poly⁡log⁡(N)poly𝑁\\operatorname{poly}\\log\\!\\left(N\\right) non-zero entries for the sparse access model but 𝒪​(log⁡log⁡N)𝒪𝑁\\mathcal{O}(\\log\\log N) for the Pauli one) is due to the fact that products between canonical projectors |i⟩​⟨j|ket𝑖bra𝑗|i\\rangle\\langle j| mostly vanish, while those between Pauli matrices do not. Result M.1 is obtained by observing that the reduction from  builds a matrix that is sparse also in the Pauli representation. It can also be seen that the matrix built in this reduction has 1-norm upper bounded by 2. Meanwhile, for M.2.2 and M.3.1, we develop an efficient classical\nalgorithm under the condition ∥A∥≤1−ηdelimited-∥∥𝐴1𝜂\\left\\lVert A\\right\\rVert\\leq 1-\\eta by observing\nthat Amsuperscript𝐴𝑚A^{m} tends to zero fast as m𝑚m increases.\nIn turn, to prove results M.2.3 and M.3.2, respectively based on the conditions ∥A∥1≤1subscriptdelimited-∥∥𝐴11\\left\\lVert A\\right\\rVert_{1}\\leq 1 and λA≤1subscript𝜆𝐴1\\lambda_{A}\\leq 1, we use classical algorithms that are particular cases of algorithms from  and ,\nwhich rely on Monte Carlo sampling.\nFinally, the results in M.4 are proven by observing that, under the given sparsity conditions,\nAmsuperscript𝐴𝑚A^{m} belongs to a low-dimensional subspace and can thus be efficiently represented explicitly for any m𝑚m. For Chebyshev polynomials we prove the following: Instantiate Problems I and II with fm​(x)=Tm​(x)subscript𝑓𝑚𝑥subscript𝑇𝑚𝑥f_{m}(x)=T_{m}(x), with Tmsubscript𝑇𝑚T_{m} the Chebyshev polynomial of the first kind and degree m∈ℕ𝑚ℕm\\in\\mathds{N}. Unless explicitly stated set m,1/ε=𝒪​(poly⁡log⁡(N)),‖A‖≤1formulae-sequence𝑚1𝜀𝒪poly𝑁norm𝐴1m,1/\\varepsilon=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)),\\|A\\|\\leq 1, and let A𝐴A be sparse or Pauli-sparse depending on the access model (that is, s𝑠s or L,λA=𝒪​(poly⁡log⁡(N))𝐿subscript𝜆𝐴𝒪poly𝑁L,\\lambda_{A}=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)). Then, The problems are BQP-complete whenever the matrix A𝐴A is given through either access model (Thm. 31 and Prop. 32).\nFor the sparse access model this holds even for a choice of s=𝒪​(1)𝑠𝒪1s=\\mathcal{O}(1). Moreover, in both cases, the result holds even if we add the conditions that ε=Ω​(1)𝜀Ω1\\varepsilon=\\Omega(1) and ∥A∥1≤2subscriptdelimited-∥∥𝐴12\\left\\lVert A\\right\\rVert_{1}\\leq 2. If BPP≠BQPBPPBQP\\textsc{BPP}{}\\neq\\textsc{BQP}{} Problem I\ncannot be solved classically in polynomial time (even for some fixed precision ε=Ω​(1)𝜀Ω1\\varepsilon=\\Omega(1))\nwhen the input matrix A𝐴A is either Given through the sparse access model and satisfies ∥A∥1=𝒪​(1/poly⁡log⁡(N))subscriptdelimited-∥∥𝐴1𝒪1poly𝑁\\left\\lVert A\\right\\rVert_{1}=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) (Prop. 33). Given through the Pauli access model, is Pauli-sparse and satisfies λA=𝒪​(1/poly⁡log⁡(N))subscript𝜆𝐴𝒪1poly𝑁\\lambda_{A}=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) (Prop. 33). Both problems can be solved classically in polynomial time via An exact algorithm in the sparse access model whenever s=𝒪​(1)𝑠𝒪1s=\\mathcal{O}(1) and m=𝒪​(log⁡log⁡N)𝑚𝒪𝑁m=\\mathcal{O}(\\log\\log N), a randomized algorithm in the sparse access model whenever ∥A∥1=𝒪​(1)subscriptdelimited-∥∥𝐴1𝒪1\\left\\lVert A\\right\\rVert_{1}=\\mathcal{O}(1) and m=𝒪​(log⁡log⁡N)𝑚𝒪𝑁m=\\mathcal{O}(\\log\\log N) or a randomized algorithm for the Pauli access model if λA=𝒪​(1)subscript𝜆𝐴𝒪1\\lambda_{A}=\\mathcal{O}(1) and m=𝒪​(log⁡log⁡N)𝑚𝒪𝑁m=\\mathcal{O}(\\log\\log N) (Prop. 34). An exact algorithm in the sparse access model when A𝐴A has at most poly⁡log⁡(N)poly𝑁\\operatorname{poly}\\log\\!\\left(N\\right) non-zero entries in the computational basis (consequence of Prop. 29) or an exact algorithm in the Pauli access model whenever L=𝒪​(log⁡log⁡N)𝐿𝒪𝑁L=\\mathcal{O}(\\log\\log N) (consequence of Thm. 30). A randomized algorithm in the Pauli access model for some value λA=𝒪​(1/(m2​log1.5⁡(N)))subscript𝜆𝐴𝒪1superscript𝑚2superscript1.5𝑁\\lambda_{A}=\\mathcal{O}(1/(m^{2}\\log^{1.5}(N))) and when the required precision is constant (Thm. 45). The results from Summary 5 show a sharp contrast between monomials and the Chebyshev polynomials. We first see indication of this as for the latter the problem remains BQP-hard even if we ask for a fixed precision ε≤13𝜀13\\varepsilon\\leq\\frac{1}{3}. Furthermore, strengthening the normalization condition beyond ∥A∥≤1delimited-∥∥𝐴1\\left\\lVert A\\right\\rVert\\leq 1 does not allow for polynomial-time classical algorithms (under the common assumption that BQP≠BPPBQPBPP\\textsc{BQP}{}\\neq\\textsc{BPP}{}), which is a concrete separation from monomials for which we showed an efficient algorithm. Result C.1 is obtained again by using the clock construction of , but noting that the Chebyshev polynomials enhance the argument from that reduction.\nSpecifically, denoting the clock matrix as H𝐻H, the remarkably convenient fact that the eigenvalues of H𝐻H happen to coincide precisely with the extrema of TMsubscript𝑇𝑀T_{M} allows us to show that the problem is BQP-hard to constant error. The intractability results C.2 are obtained by exploiting the relationship between Hamiltonian Simulation and the Chebyshev polynomials expressed through the Anger-Jacobi expansion (see Def. 46). This result is achieved through a polynomial-time Turing reduction (rather than a Karp reduction), and thus we do not claim BQP-completeness for the problem555The notion of BQP-completeness is based on Karp-reductions, see Def. 10 for definitions. Meanwhile, a polynomial-time Turing reduction from problem A𝐴A to B𝐵B consists of an algorithm that is able to decide A𝐴A in polynomial-time using an oracle able to solve problem B𝐵B. under the constraints ∥A∥1≤1subscriptdelimited-∥∥𝐴11\\left\\lVert A\\right\\rVert_{1}\\leq 1 or λA≤1subscript𝜆𝐴1\\lambda_{A}\\leq 1. The classical algorithm of Result C.3.1 is obtained by observing that computing monomials is easy under the given hypothesis, and the error propagation due to the coefficients of the Chebyshev polynomials can be controlled because they can be bounded as 𝒪​(4m)𝒪superscript4𝑚\\mathcal{O}(4^{m}) for the m𝑚m-th polynomial. Finally, the results in C.3.2 are direct consequences of Prop. 29 and Thm. 30 (which we further generalize in the next Summary), while C.3.3 is due to a general algorithm based on importance-sampling sketching on the Pauli coefficients, which we also elucidate in the next summary. The hardness results for monomials (and Chebyshev polynomials) are of course inherited by general polynomials. As for classical feasibility, for general polynomials, we can extend the ideas from Result M.4 and obtain the following classical algorithms: Instantiate Problems I and II with any degree-d𝑑d polynomial. If A𝐴A has 𝒪​(poly⁡log⁡(N))𝒪poly𝑁\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)) non-zero matrix elements\nin the\ncomputational basis both problems can be classically solved exactly in 𝒪​(d2⋅poly⁡log⁡(N))𝒪⋅superscript𝑑2poly𝑁\\mathcal{O}(d^{2}\\cdot\\operatorname{poly}\\log\\!\\left(N\\right)) time (Prop. 29). If A𝐴A has L=𝒪​(log⁡log⁡(N))𝐿𝒪𝑁L=\\mathcal{O}(\\log\\log(N)) non-zero\ncoefficients in the Pauli basis (implying that A𝐴A is\n𝒪​(log⁡log⁡(N))𝒪𝑁\\mathcal{O}(\\log\\log(N))-sparse) both problems can be classically solved exactly in 𝒪​(d2⋅poly⁡log⁡(N))𝒪⋅superscript𝑑2poly𝑁\\mathcal{O}(d^{2}\\cdot\\operatorname{poly}\\log\\!\\left(N\\right)) time. (Thm. 30) Further suppose the polynomial has magnitude at most 111 on the domain [−1,1]11[-1,1] and ‖A‖≤1norm𝐴1\\|A\\|\\leq 1. If A𝐴A has L=𝒪​(poly⁡log⁡(N))𝐿𝒪poly𝑁L=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)) non-zero\ncoefficients in the Pauli basis (or efficiently-representable structure in the Pauli basis), both problems can be classically solved to constant error in 𝒪​(d2⋅poly⁡log⁡(N))𝒪⋅superscript𝑑2poly𝑁\\mathcal{O}(d^{2}\\cdot\\operatorname{poly}\\log\\!\\left(N\\right)) time, for some value of λA=𝒪​(1/(d2​log1.5⁡(N)))subscript𝜆𝐴𝒪1superscript𝑑2superscript1.5𝑁\\lambda_{A}=\\mathcal{O}(1/(d^{2}\\log^{1.5}(N))) (Thm. 45). Results P.1 and P.2 are direct extensions of Result M.4. They provide classical algorithms for the eigenvalue transform for any polynomial, with runtimes that are polynomially equivalent to those of their corresponding quantum algorithms.\nImportantly, these techniques are also straightforwardly transferable to the singular value transform for even functions. They demonstrate that no superpolynomial quantum advantage in the problem size is possible when considering matrices that are super sparse, particularly when given in the Pauli basis. Observe that these results can be easily extended to general functions that can be efficiently approximated by polynomials, including the time evolution function and inverse function.\n Result P.3 comes from a two-stage algorithm. First, we perform importance sampling on Pauli coefficients to obtain a “sketched” description of A𝐴A in the Pauli basis. We then apply the algorithm of M.4. We see that under the standard condition d=poly⁡log⁡(N)𝑑poly𝑁d=\\operatorname{poly}\\log\\!\\left(N\\right), it would suffice to ask for λA≤csubscript𝜆𝐴𝑐\\lambda_{A}\\leq c for some c=𝒪​(1/poly⁡log⁡(N))𝑐𝒪1poly𝑁c=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) to guarantee an efficient classical algorithm. We saw in Result C.2 that we should not expect much more from a classical algorithm, as solving the Chebyshev problem to constant precision for some other λA=𝒪​(1/poly⁡log⁡(N))subscript𝜆𝐴𝒪1poly𝑁\\lambda_{A}=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) is hard under complexity-theoretic assumptions or. We will see in the following two summaries that for the inverse and time evolution functions this setting can even be shown to be BQP-complete. We now consider the paradigmatic problem of time evolution, defined through the complex exponential function. For this, we prove the following: Instantiate Problems I and II with ft​(x)=exp⁡(i​x​t)subscript𝑓𝑡𝑥𝑖𝑥𝑡f_{t}(x)=\\exp(ixt). Unless explicitly stated, set t,1/ε=𝒪​(poly⁡log⁡(N)),‖A‖≤1formulae-sequence𝑡1𝜀𝒪poly𝑁norm𝐴1t,1/\\varepsilon=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)),\\|A\\|\\leq 1, and let A𝐴A be sparse or Pauli-sparse depending on the access model (that is, s𝑠s or L=𝒪​(poly⁡log⁡(N))𝐿𝒪poly𝑁L=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)). Then, it holds that The problems are BQP-complete even for some fixed precision 1/ε=𝒪​(1)1𝜀𝒪11/\\varepsilon=\\mathcal{O}(1) (Props. 39 and 40) whenever the matrix A𝐴A: Is given through the sparse access model and satisfies ∥A∥1≤1subscriptdelimited-∥∥𝐴11\\left\\lVert A\\right\\rVert_{1}\\leq 1, or Is given through the Pauli Access model, satisfies λA≤1subscript𝜆𝐴1\\lambda_{A}\\leq 1 and is Pauli-sparse. Has even more strongly contracted norm ∥A∥1=𝒪​(1/poly⁡log⁡(N))subscriptdelimited-∥∥𝐴1𝒪1poly𝑁\\left\\lVert A\\right\\rVert_{1}=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) (hence\n∥A∥=𝒪​(1/poly⁡log⁡(N))delimited-∥∥𝐴𝒪1poly𝑁\\left\\lVert A\\right\\rVert=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) also) in sparse access or λA=𝒪​(1/poly⁡log⁡(N))subscript𝜆𝐴𝒪1poly𝑁\\lambda_{A}=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) in Pauli access (Prop. 41). The problems can be solved efficiently classically in 𝒪​(poly⁡log⁡(N))𝒪poly𝑁\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)) time via A randomized algorithm whenever ‖A‖1​t=𝒪​(log⁡log⁡N)subscriptnorm𝐴1𝑡𝒪𝑁\\|A\\|_{1}t=\\mathcal{O}(\\log\\log N) in the sparse access model or λA​t=𝒪​(log⁡log⁡N)subscript𝜆𝐴𝑡𝒪𝑁\\lambda_{A}t=\\mathcal{O}(\\log\\log N) in the Pauli access model (Prop. 42). An approximate algorithm in the Pauli access model whenever L=𝒪​(log⁡log⁡N)𝐿𝒪𝑁L=\\mathcal{O}(\\log\\log N) (Thm. 44). Like for Chebyshev polynomials, here hardness holds robustly in a variety of settings, even when matrix norms are small and precision is a constant. As discussed previously, measurement of time-evolved states can be considered the canonical BQP-complete problem, dating back to the landmark proposal of Feynman . To show BQP-completeness for the entry estimation variant of the problem for T.1, we use a Hamiltonian clock construction of . T.2 arises due to an application of the classical algorithms of  and  and our generalizations thereof to the local measurement problem (M.2.1 and M.3) applied to the truncated Taylor expansion strategy of . We also consider the inverse function. To frame it into the format of Problems I and II, we consider the family of functions given by The family invmsubscriptinv𝑚\\texttt{{inv}}_{m} coincides with the inverse function for any A𝐴A whose condition number κA=‖A‖​‖A−1‖subscript𝜅𝐴norm𝐴normsuperscript𝐴1\\kappa_{A}=\\|A\\|\\|A^{-1}\\| is upper-bounded by m𝑚m, and thus we will assume that the input matrix A𝐴A satisfies κA≤msubscript𝜅𝐴𝑚\\kappa_{A}\\leq m. Instantiate Problems I and II with fm​(x)=invm​(x)subscript𝑓𝑚𝑥subscriptinv𝑚𝑥f_{m}(x)=\\texttt{{inv}}_{m}(x). Unless explicitly stated, set m,1/ε=𝒪​(poly⁡log⁡(N)),‖A‖≤1formulae-sequence𝑚1𝜀𝒪poly𝑁norm𝐴1m,1/\\varepsilon=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)),\\|A\\|\\leq 1, and let A𝐴A be sparse or Pauli-sparse depending on the access model (that is, s𝑠s or L=𝒪​(poly⁡log⁡(N))𝐿𝒪poly𝑁L=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)). Then, it holds that The problems are BQP-complete (Thm. 36 and Prop. 37 [ref]17) for a fixed precision whenever the matrix A𝐴A is either Given through the sparse access model and satisfies ∥A∥1=𝒪​(1/poly⁡log⁡(N))subscriptdelimited-∥∥𝐴1𝒪1poly𝑁\\left\\lVert A\\right\\rVert_{1}=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) (hence\n∥A∥=𝒪​(1/poly⁡log⁡(N))delimited-∥∥𝐴𝒪1poly𝑁\\left\\lVert A\\right\\rVert=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) also), or Given through the Pauli access model, satisfies λA=𝒪​(1/poly⁡log⁡(N))subscript𝜆𝐴𝒪1poly𝑁\\lambda_{A}=\\mathcal{O}(1/\\operatorname{poly}\\log\\!\\left(N\\right)) and is Pauli-sparse. The problems can be solved classically in polynomial time For the sparse access model whenever s,m=𝒪​(1)𝑠𝑚𝒪1s,m=\\mathcal{O}(1) (exactly) or ∥A∥1≤1,m=𝒪​(1)formulae-sequencesubscriptdelimited-∥∥𝐴11𝑚𝒪1\\left\\lVert A\\right\\rVert_{1}\\leq 1,\\,m=\\mathcal{O}(1) (approximately) (Thm. 38) For the Pauli access model whenever λA,m=𝒪​(1)subscript𝜆𝐴𝑚𝒪1\\lambda_{A},m=\\mathcal{O}(1) (Thm. 38) The hardness part of Results I.1 are proven, once again, by exploiting the construction from  in the case of entry estimation, and by using the construction of [ref]17 for the local measurement problem with a small tweak to hone the hardness result to Hermitian (real symmetric) matrices.\nThese results are analogous to C.1 and T.1, since it shows that even a strong strengthening the condition ∥A∥≤1delimited-∥∥𝐴1\\left\\lVert A\\right\\rVert\\leq 1 does not lead to efficient classical algorithms for the case of the inverse function. This intractability result holds even for a constant precision level, but, unlike the case of Chebyshev polynomials, this is less surprising since we are considering additive precision and the inverse function commutes with scalar multiplication.666More precisely, given an algorithm that computes a (k​ε)𝑘𝜀(k\\varepsilon)-approximation of ⟨i|A−1|j⟩quantum-operator-product𝑖superscript𝐴1𝑗\\langle i|A^{-1}|j\\rangle,\nwe can obtain an ε𝜀\\varepsilon-approximation of the same value by using the same algorithm to compute a (k​ε)𝑘𝜀(k\\varepsilon)-approximation of ⟨i|(A/k)−1|j⟩=k​⟨i|A−1|j⟩quantum-operator-product𝑖superscript𝐴𝑘1𝑗𝑘quantum-operator-product𝑖superscript𝐴1𝑗\\langle i|\\left(A/k\\right)^{-1}|j\\rangle=k\\langle i|A^{-1}|j\\rangle and then dividing that approximation by k𝑘k. Result I.2 is deduced by employing a low-degree polynomial approximation of the inverse function in the range [−1,−1m]∪[1m,1]11𝑚1𝑚1\\left[-1,-\\frac{1}{m}\\right]\\cup\\left[\\frac{1}{m},1\\right], which was developed in , and by approximating that polynomimal with the classical algorithms in Results M.2 and M.3. We note that the classically solvable case is not immediately evident because, even when m𝑚m is fixed, the precision is still a parameter of the problem. Therefore, we cannot pick a fixed polynomial approximation of the inverse function (we need to pick an ε𝜀\\varepsilon-approximation of the inverse function). Meanwhile, for the case of monomials and the Chebyshev polynomials, whenever m𝑚m is fixed the resulting function is a polynomial, and those can be computed exactly and straightforwardly classically if the matrix is sparse or Pauli-sparse (Lemma 17).\n\nReference markers found: [17]\n\nContext windows for each [ref]:\n[ref]17: on the access model (that is, s𝑠s or L=𝒪​(poly⁡log⁡(N))𝐿𝒪poly𝑁L=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)). Then, it holds that The problems are BQP-complete (Thm. 36 and Prop. 37 [ref]17) for a fixed precision whenever the matrix A𝐴A is either Given through the sparse access model and satisfies ∥A∥1=𝒪​(1/poly⁡log⁡(N))subscriptdelimited-∥∥𝐴1𝒪1poly𝑁\\left\\lVert\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 17,\n            \"titles\": [\n                \"Quantum and classical query complexities of functions of matrices\",\n                \"Hamiltonian Simulation by Qubitization\",\n                \"Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics\",\n                \"Grand Unification of Quantum Algorithms\",\n                \"Product Decomposition of Periodic Functions in Quantum Signal Processing\",\n                \"Heisenberg-Limited Ground-State Energy Estimation for Early Fault-Tolerant Quantum Computers\",\n                \"Fourier-based quantum signal processing\",\n                \"Quantum algorithm for ground state energy estimation using circuit depth with exponentially improved dependence on precision\",\n                \"Faster ground state energy estimation on early fault-tolerant quantum computers via rejection sampling\",\n                \"Linear combination of Hamiltonian simulation for nonunitary dynamics with optimal state preparation cost\",\n                \"Quantum algorithm for linear non-unitary dynamics with near-optimal dependence on all parameters\",\n                \"Quantum eigenvalue processing\",\n                \"Circuit complexity of quantum access models for encoding classical data\",\n                \"Random Compiler for Fast Hamiltonian Simulation\",\n                \"A randomized quantum algorithm for statistical phase estimation\",\n                \"Qubit-efficient randomized quantum algorithms for linear algebra\",\n                \"qSWIFT: High-order randomized compiler for Hamiltonian simulation\",\n                \"Quantum algorithm for linear systems of equations\",\n                \"Dequantizing algorithms to understand quantum advantage in machine learning\",\n                \"Dequantizing the Quantum Singular Value Transformation: Hardness and Applications to Quantum Chemistry and the Quantum PCP Conjecture\",\n                \"Guest column: the quantum PCP conjecture\",\n                \"Faster Algorithms via Approximation Theory\",\n                \"Quantum Algorithm for Systems of Linear Equations with Exponentially Improved Dependence on Precision\",\n                \"Randomized semi-quantum matrix processing\",\n                \"Quantum walks, the discrete wave equation and Chebyshev polynomials\",\n                \"A simple PromiseBQP-complete matrix problem\",\n                \"A (simple) classical algorithm for estimating Betti numbers\",\n                \"Quantum Mechanical Computers\",\n                \"Fast universal quantum computation with railroad-switch local Hamiltonians\",\n                \"A quantum-inspired classical algorithm for recommendation systems\",\n                \"Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions\",\n                \"An improved quantum-inspired algorithm for linear regression\",\n                \"Sampling-Based Sublinear Low-Rank Matrix Arithmetic Framework for Dequantizing Quantum Machine Learning\",\n                \"Faster Quantum-Inspired Algorithms for Solving Linear Systems\",\n                \"Classical approximation schemes for the ground-state energy of quantum and classical ising spin hamiltonians on planar graphs\",\n                \"Logarithmic depth circuits for algebraic functions\",\n                \"Logical reversibility of computation\",\n                \"Arithmetic circuits: A survey of recent results and open questions\",\n                \"A Comprehensive Study of Quantum Arithmetic Circuits\",\n                \"Parallel Quantum Algorithm for Hamiltonian Simulation\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]17 based on the context and research area of Quantum computational complexity of matrix functions. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}