{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms\n\nPaper Abstract: \n\nPaper Section Text:\nEvaluation metrics. There are two key aspects throughout our evaluation: (1) How accurately can the poisoned samples be detected (upstream evaluation)? (2) After the suspicious points are removed, how would a downstream model learn from the remaining data perform (downstream evaluation)? For upstream evaluation, we utilize two metrics, namely, True Positive Rate (TPR), T‚ÄãP‚ÄãR=T‚ÄãP/(T‚ÄãP+F‚ÄãN)ùëáùëÉùëÖùëáùëÉùëáùëÉùêπùëÅTPR={TP}/{(TP+FN)},\nand False Positive Rate (FPR), F‚ÄãP‚ÄãR=F‚ÄãP/(F‚ÄãP+T‚ÄãN)ùêπùëÉùëÖùêπùëÉùêπùëÉùëáùëÅFPR={FP}/{(FP+TN)},\nwhere T‚ÄãPùëáùëÉTP, F‚ÄãPùêπùëÉFP, T‚ÄãNùëáùëÅTN, and F‚ÄãNùêπùëÅFN denote the number of true positives, false positives, true negatives, and false negatives, respectively444Note that poison is considered positive and clean is considered negative..\nTPR depicts how well a specific backdoor detection method filters out the backdoored samples. A higher TPR (closer to 100%percent\\%) denotes a stronger filtering ability.\nFPR depicts how precise the filtering is: when a specific method achieves TPR that is high enough, FPR helps us to understand the trade-off, i.e., how many clean samples are wasted and wrongly flagged as backdoored during the detection. A lower FPR shows that fewer clean samples are wasted, and more clean data shall be kept and available for downstream usage. One thing worth noting is that no detection method can reliably remove all the poisoned samples. However, the remained backdoor samples that go unnoticed by a successful defense should be small enough to deactivate attacks.\nThus, we evaluate the backdoor attacks‚Äô Attack Success Rate (ASR) on the downstream model trained using the filtered dataset to study whether the detection is good enough to stop attacks. ASR measures the proportion of backdoored test samples being classified into target classes. Additionally, we evaluate the downstream model‚Äôs Clean Accuracy (ACC). A high ACC means that the detection method is able to maintain a large enough clean set to support the model performance. blue red Dataset & models.\nWe incorporate three standard computer vision benchmark datasets into our evaluation: CIFAR-10  (main text), STL-10  (Appendix 6.3), and ImageNet [ref]55 (a randomly selected 100-class subset, Appendix 6.3). To ensure the effectiveness of the baselines and fair comparison, we set the base set size as 1000 for all the settings. We will later show that our method is robust to different choices of the base set size in the ablation study, Appendix 6.4. We obtain a 1000-size clean base set for each dataset by randomly selecting the samples from the test set and removing their label information.\nAll the upstream evaluation metrics (i.e., TPR and FPR) are evaluated on the respective training sets, i.e., the training set of Case-0, the fine-tuning set of Case-2, and the unlabeled pre-training set for Case-1.\nFor Case-0, we adopt all the remaining data from the test set for evaluation of the downstream metrics (i.e., ACC and ASR). For Case-1 and Case-2, we split the remaining test set into half being fine-tuning set and half being the downstream metric evaluation set.\nResNet-18 [ref]56 is adopted on the CIFAR-10.\nViT-Small/16  is adopted on STL-10 and ImageNet (Appendix 6.3).\nFor Case-1, we incorporate four state-of-the-art SSL training methods, i.e., SimCLR , MoCo V3 , BYOL , and the MAE 3, for evaluation. For Case-2, we consider the two most popular transfer learning cases, namely, FT-all and FT-last (detailed in Section¬†2).\nThe pre-trained model parameters for fine-tuning are loaded from the timm library555https://timm.fast.ai/. Baseline defenses.\nReferring to Table 1, we incorporate a wide range of existing backdoor detection for comparison, including both standard baselines used in prior work as well as state-of-the-art ones.\nIn particular, we consider Spectral\n, Spectre\n, and the Beatrix\n;\nwe include AC\n as a representative work that utilizes intermediate neural activation;\nABL\n, which was originally a robust training defense and repurposed as a detection method based on output losses;\nStrip\n\nas a representative detection approach based on model outputs;\nand CT\n, the most recent work reported achieving state-of-the-art performance on end-to-end SL settings based on confusion training.\nAll the implementations and hyperparameters follow the original papers. For methods that rely on or can be boosted by an additional base set, e.g., Spectre, Beatrix, Strip, CT, we use the same 1000-size base set as ours. We note that this comparison setting might not be fair, as compared to these baselines, our method relaxes the requirement on label information; in addition, AC and ABL cannot be adapted to use the base set.\nWe want to show that even without label information,\nour method can still achieve comparable or much better results with stronger robustness than the other baselines.\nDetailed explanations of the defense settings and how we adapted them to Case-1 and Case-2 are provided in Appendix 6.1. Backdoor attack settings.\nFor Case-0 we incorporate seven standard or state-of-the-art attacks, including four dirty-label and clean-label ones.\nFor dirty-label backdoor attacks, we incorporate localized backdoor attack BadNets , global-wised blended trigger Blended , wrapping-based invisible backdoor attack WaNet , and the state-of-the-art sample-specific invisible backdoor attack, ISSBA . For clean-label attacks, we include the standard Label Consistent (LC) attack , the state-of-the-art feature-collision-based hidden trigger backdoor, Sleeper Agent Attack (SAA) , and the state-of-the-art optimization-based Narcissus attack (Narci.) .\nFor Case-1, only limited existing work has explored the attack over SSL‚Äôs unlabeled training set. We incorporate\nthe Checkerboard trigger (C-brd) used in 9, the Colored Square trigger (C-squ) used in 0, and the state-of-the-art YCbCr frequency-based invisible trigger used in CTRL 1. In particular, CTRL has been shown to achieve a magnitude higher attacking efficacy than 0.\nFor Case-2, directly implementing some of the attacks from end-to-end SL may not lead to effective attacks, e.g., the Blended attack cannot achieve high ASR under the FT-all settings. Thus, we consider attacks that can maintain effectiveness for each TL setting.\nBadNets and the SAA are adopted for evaluation under the FT-all case. Blended and the hidden trigger backdoor attack (HTBA)  are adopted for the evaluation under the FT-last case. All the incorporated attacks‚Äô settings, such as trigger design and trigger strength, all follow their original papers.\nAppendix 6.2 details the specifics of these attacks‚Äô setups under each learning paradigm and visual examples of the poisoned samples we intend to detect. red\n\nReference markers found: [55]\n\nContext windows for each [ref]:\n[ref]55: the model performance. blue red Dataset & models.\nWe incorporate three standard computer vision benchmark datasets into our evaluation: CIFAR-10  (main text), STL-10  (Appendix 6.3), and ImageNet [ref]55 (a randomly selected 100-class subset, Appendix 6.3). To ensure the effectiveness of the baselines and fair comparison, we set the base set size as 1000 for all the settings. We will later\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 55,\n            \"titles\": [\n                \"Deep Residual Learning for Image Recognition\",\n                \"Badnets: Evaluating backdooring attacks on deep neural networks\",\n                \"Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information\",\n                \"Intriguing properties of neural networks\",\n                \"Backdoor Learning: A Survey\",\n                \"Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection\",\n                \"Strip: A defence against trojan attacks on deep neural networks\",\n                \"Spectral Signatures in Backdoor Attacks\",\n                \"Spectre: defending against backdoor attacks using robust statistics\",\n                \"The beatrix resurrections: Robust backdoor detection via gram matrices\",\n                \"Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering\",\n                \"Anti-Backdoor Learning: Training Clean Models on Poisoned Data\",\n                \"A Simple Framework for Contrastive Learning of Visual Representations\",\n                \"Masked autoencoders are scalable vision learners\",\n                \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\",\n                \"Beyond separability: Analyzing the linear transferability of contrastive representations to related subpopulations\",\n                \"Big Self-Supervised Models are Strong Semi-Supervised Learners\",\n                \"An Empirical Study of Training Self-Supervised Vision Transformers\",\n                \"Bootstrap your own latent-a new approach to self-supervised learning\",\n                \"Poisoning and backdooring contrastive learning\",\n                \"Backdoor Attacks on Self-Supervised Learning\",\n                \"Demystifying self-supervised trojan attacks\",\n                \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\",\n                \"Towards A Proactive ML Approach for Detecting Backdoor Poison Samples\",\n                \"Meta-Sift : How to Sift Out a Clean Subset in the Presence of Data Poisoning?\",\n                \"Stochastic gradient descent tricks\",\n                \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\",\n                \"Self-Supervised Learning with Swin Transformers\",\n                \"A survey of self-supervised learning from multiple perspectives: Algorithms, theory, applications and future trends\",\n                \"Targeted backdoor attacks on deep learning systems using data poisoning\",\n                \"Trojaning attack on neural networks\",\n                \"Blind Backdoors in Deep Learning Models\",\n                \"Invisible Backdoor Attack with Sample-Specific Triggers\",\n                \"Invisible Backdoor Attacks on Deep Neural Networks via Steganography and Regularization\",\n                \"Reflection Backdoor: A Natural Backdoor Attack on Deep Neural Networks\",\n                \"Wanet-imperceptible warping-based backdoor attack\",\n                \"Rethinking the Backdoor Attacks‚Äô Triggers: A Frequency Perspective\",\n                \"Check your other door! establishing backdoor attacks in the frequency domain\",\n                \"An invisible black-box backdoor attack through frequency domain\",\n                \"Label-Consistent Backdoor Attacks\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]55 based on the context and research area of ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep Learning Paradigms. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}