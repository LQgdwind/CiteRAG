{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\nPaper Abstract: \n\nPaper Section Text:\nIn vision applications, we often want a machine learning model to understand the semantic information of images, whereas the non-semantic factors such as the texture, background, viewpoints, lighting conditions and all kinds of noise can act as confounders that hurt the trustworthiness of vision models. Some application scenarios also suffer from the data scarcity and long-tail distribution problems.\nDifferent methods have been proposed to tackle the challenges in a variety of tasks\nincluding image classification\n            [ref]482,\nobject detection ,\nobject localization ,\nco-saliency detection [ref]270,\nfacial recognition ,\nemotion recognition ,\nsemantic segmentation  ,\nmeta-learning   ,\nsequential tasks\n    ,\ndataset preparation   [ref]270 ,\nknowledge distillation\n ,\nand\nmedical imaging          [ref]578   . Many works have employed data augmentation methods to extract causal features or remove confounders  [ref]270    . A subset of the literature approached the data scarcity problem by robust few-shot learning, intervening on features, normalizing them, or using synthetic images   .\nSeveral studies aimed to mitigate bias in sequential tasks, often through treatment effects    .\nFor knowledge distillation,\n\nused backdoor adjustment (Section 3.2.1)\nto eradicate the confounding effect of knowledge prior which determines the context or background features of the image.\nAdditionally,\n quantified the effect of an intervention, to eradicate the forgetfulness problem in student models\nby enforcing the same representation from the student model. Furthermore, several works        [ref]482 tried to enhance the interpretability of the models, mostly by generating an image that flips the label to emphasize the important features responsible for the original label. For example, [ref]482 aimed to measure robustness in robot control by quantifying the change required to generate a counterfactual image that has a ground-truth label but is predicted wrongly by the robot. Additionally, some studies have created vision datasets for training trustworthy models   [ref]270. For example,  provided a tool for constructing data with specified characteristics for use with self-driving cars. The tool offers a high-fidelity simulation environment that can be used for causal and temporal reasoning, providing control over variables such as environment characteristics, vehicles, and traffic lights. Machine learning applied to medical imaging holds great potential and societal value. By automatically recognizing the patterns in imaging data, machine learning models have the potential to greatly reduce the workload of radiologists and alleviate the strain in medical resources. They may also detect the subtle abnormalities reflecting the early stages of disease which may not be easily recognizable by humans . However, the high-stake nature of medical imaging places high demands on the trustworthiness of machine learning models, because a wrong prediction could bring severe outcome to the patient’s health. The model should be interpretable enough for medical experts to easily validate and adopt its predictions. Distribution shifts are common in imaging data due to different medical devices, imaging procedure and individual characteristics. High-quality labeled data are often scarce, due to privacy concerns and the expensive cost of annotation, which may lead to overfitting problems . Recent works have evaluated the performance of vision foundation models on medical imaging tasks.\n evaluated the SAM model on medical images in different applications including dermatology, ophthalmology, and radiology. The author discovers that SAM is not able to perform optimal for certain structured targets like continuous branch structures. However, fine-tuning the model on small amount of this data leads to several improvements.\nSimilarly,  evaluated the SAM model on medical imaging tasks using prompt learning. They discovered that prompt performance varies on datasets and does perform poorer on ambiguous segmentation tasks. Furthermore, the author discover that when prompts are provided iteratively their performance does not improve as much as the previous models.\nBesides numerical evaluation,  took a societal view and highlighted the marginalization of people with rare diseases in the dataset, which may cause unintentional discrimination. Different methods have been proposed to improve the trustworthiness of models for medical imaging.  discussed the importance of causal features to alleviate issues arising from domain-shift. Other studies such as   focused on delineating invariant features.  distinguished between causal and contrast features for COVID-19 CT scans, whereas  employed augmentation and pseudo-correlations to address domain shift issues in cross-modality (CT-MRI) abdominal image segmentation, cross-sequence (bSSFP-LGE) cardiac MRI segmentation, and cross-center prostate MRI segmentation.\nMoreover,  employed treatment effects (Section 3.3.2) to perturb various clustered units representing human-understandable concepts, aiming to identify units that serve as causal features. For interpretability, the study also trained a decision tree to map output to an explanation, thereby creating a rule-based explainer. Techniques of counterfactual image generation have been utilized by        [ref]578 to enhance the interpretability of medical models. Counterfactual images are generated to underscore causal features , and features contributing both negatively and positively are revealed .\nHowever, the task of image generation often results in poor quality. To mitigate this,   [ref]578 focused on improving the quality of generated images by emphasizing textural and structural information  for pneumonia classification from X-rays. Additionally,  evaluated the reconstruction quality of different segments of chest X-ray images, along with object retention.\nYet, focusing solely on intensified discriminatory pixels can compromise the interpretability of less-intensified pixels that nonetheless contribute significantly to prediction. To address this, [ref]578 proposed using a regression equation to quantify the contributions of different image segments rather than relying solely on visual appearance. This work also incorporated the factor of overdetermination to provide a broader view of the factors contributing to a label. Counterfactual explanations for medical images with high uncertainty occasionally produce blatantly incorrect explanations, but these can be improved  through reliable elucidation of the intricate relationships between image signatures and the target attribute. Nevertheless, all the aforementioned techniques might not perform well with medical images exhibiting high variability in data-shift. As a result,  sought to discover the statistical relationship between inter-species images, where the DL model fails due to its low generalizability properties. This work disentangled the information of medical images using a Directed Acyclic Graph to generate counterfactual images based on low-level and high-level features.\n\nReference markers found: [482]\n\nContext windows for each [ref]:\n[ref]482: also suffer from the data scarcity and long-tail distribution problems.\nDifferent methods have been proposed to tackle the challenges in a variety of tasks\nincluding image classification\n            [ref]482,\nobject detection ,\nobject localization ,\nco-saliency detection [ref]270,\nfacial recognition ,\nemotion recognition ,\nsemantic segmentation  ,\nmeta-learning   ,\nsequential tasks\n    ,\ndataset\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 482,\n            \"titles\": [\n                \"Offline RL for Natural Language Generation with Implicit Language Q Learning\",\n                \"Explaining individual predictions when features are dependent: More accurate approximations to shapley values\",\n                \"Deep Learning with Differential Privacy\",\n                \"Counterfactual vision and language learning\",\n                \"Gpt-3-driven pedagogical agents to train children’s curious question-asking skills\",\n                \"Persistent anti-muslim bias in large language models\",\n                \"Sanity checks for saliency maps\",\n                \"One-network adversarial fairness\",\n                \"Bias-resilient neural network\",\n                \"Learning optimal and fair decision trees for non-discriminative decision-making\",\n                \"Intrinsic dimensionality explains the effectiveness of language model fine-tuning\",\n                \"Vqa: Visual question answering\",\n                \"Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization\",\n                \"Domain-Adversarial Neural Networks\",\n                \"Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey\",\n                \"CX-ToM: Counterfactual Explanations with Theory-of-Mind for Enhancing Human Trust in Image Recognition Models\",\n                \"Adversarial invariant feature learning with accuracy constraint for domain generalization\",\n                \"What learning algorithm is in-context learning? Investigations with linear models\",\n                \"Flamingo: a visual language model for few-shot learning\",\n                \"Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning\",\n                \"Advanced econometrics\",\n                \"Uncovering and mitigating algorithmic bias through learned latent structure\",\n                \"Estimation of the parameters of a single equation in a complete system of stochastic equations\",\n                \"Square Attack: a query-efficient black-box adversarial attack via random search\",\n                \"Exploring Length Generalization in Large Language Models\",\n                \"PaLM 2 Technical Report\",\n                \"Invariant risk minimization\",\n                \"Logic-guided data augmentation and regularization for consistent question answering\",\n                \"A General Language Assistant as a Laboratory for Alignment\",\n                \"Craft: A benchmark for causal reasoning about forces and interactions\",\n                \"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\n                \"Understanding confounding and mediation\",\n                \"On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation\",\n                \"An Actor-Critic Algorithm for Sequence Prediction\",\n                \"Learning to Understand Goal Specifications by Modelling Reward\",\n                \"Learning de-biased representations with biased representations\",\n                \"Training a helpful and harmless assistant with reinforcement learning from human feedback, 2022\",\n                \"Instrumental variable methods for causal inference\",\n                \"Your fairness may vary: Pretrained language model fairness in toxic text classification\",\n                \"Adversarial transformation networks: Learning to generate adversarial examples\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]482 based on the context and research area of Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}