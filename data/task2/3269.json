{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Polyline Simplification under the Local FrÃ©chet Distance Has Almost-Quadratic Runtime in 2D\n\nPaper Abstract: \n\nPaper Section Text:\nThe most practically relevant setting for polyline simplification is to consider two-dimensional input curves in the Euclidean plane (i.e., under the L2 norm).\nHowever, the problem was also studied in higher dimensions d>2ğ‘‘2d>2 and under different norms. The ğ’ªâ€‹(n3)ğ’ªsuperscriptğ‘›3\\mathcal{O}(n^{3}) time algorithm by Imai, Iri, and GodauÂ  \nfor polyline simplification under the local Hausdorff and FrÃ©chet distance\nas well as the ğ’ªâ€‹(n3)ğ’ªsuperscriptğ‘›3\\mathcal{O}(n^{3}) time algorithm by Bringmann and ChaudhuryÂ \nfor the global FrÃ©chet distance can be generalized to work in\nâ„dâ‰¥2superscriptâ„ğ‘‘2\\mathbb{R}^{d\\geq 2} with the running time only increasing\nby a polynomial factor in dğ‘‘d.\nFor the local Hausdorff distance, Chan and Chin  showed\nthat the Imaiâ€“Iri algorithm can be improved to run in ğ’ªâ€‹(n2)ğ’ªsuperscriptğ‘›2\\mathcal{O}(n^{2}) time\nfor L1, L2 and Lâˆ (the concept can also be applied to any\nLpâˆˆ(1,âˆ) up to possible numerical issues that are further\ndiscussed in SectionÂ 4.3).\nFurthermore Barequet et al.Â  proposed\nan ğ’ªâ€‹(n2â€‹logâ¡n)ğ’ªsuperscriptğ‘›2ğ‘›\\mathcal{O}(n^{2}\\log n) time algorithm for the local Hausdorff distance\nunder the L2 norm in â„3superscriptâ„3\\mathbb{R}^{3}, as well as an ğ’ªâ€‹(dâ€‹2dâ€‹n2)ğ’ªğ‘‘superscript2ğ‘‘superscriptğ‘›2\\mathcal{O}(d2^{d}n^{2}) algorithm for L1 and an ğ’ªâ€‹(d2â€‹n2)ğ’ªsuperscriptğ‘‘2superscriptğ‘›2\\mathcal{O}(d^{2}n^{2}) algorithm for Lâˆ. Bringmann and ChaudhuryÂ  have also proven a conditional\nlower bound for simplification in â„dsuperscriptâ„ğ‘‘\\mathbb{R}^{d} under the local Hausdorff distance\nas well as under the local and global FrÃ©chet distance.\nMore precisely, for Lp with pâˆˆ[1,âˆ),pâ‰ 2formulae-sequenceğ‘1ğ‘2p\\in[1,\\infty),p\\neq 2, algorithms with\na running time subcubic in nğ‘›n and polynomial in dğ‘‘d were ruled out\n(unless the âˆ€âˆ€âˆƒfor-allfor-all\\forall\\forall\\exists-OV hypothesis fails).\nFor large dimensions dğ‘‘d, the algorithmic upper bounds of ğ’ªâ€‹(n3â‹…polyâ€‹(d))ğ’ªâ‹…superscriptğ‘›3polyğ‘‘\\mathcal{O}(n^{3}\\cdot\\mathrm{poly}(d))\nfor polyline simplification discussed above are hence tight.\nHowever, the lower bound still allows the existence of simplification algorithms\nwith a running time in ğ’ªâ€‹(nkâ‹…expâ¡(d))ğ’ªâ‹…superscriptğ‘›ğ‘˜ğ‘‘\\mathcal{O}(n^{k}\\cdot\\exp(d)) with k<3ğ‘˜3k<3.\nHence, for small values of dğ‘‘d (which are of high practical relevance),\nfaster algorithms are possible, as evidenced by the ğ’ªâ€‹(dâ€‹2dâ€‹n2)ğ’ªğ‘‘superscript2ğ‘‘superscriptğ‘›2\\mathcal{O}(d2^{d}n^{2}) time algorithm\nfor the local Hausdorff distance under the L1 norm .\nFor L2 and Lâˆ, the best currently known conditional lower bound for\nthe three similarity measures, local Hausdorff distance, local FrÃ©chet distance, and\nglobal FrÃ©chet distance, was proven by Buchin et al.Â 0.\nIt rules out algorithms with a subquadratic running time in nğ‘›n and polynomial\nrunning time in dğ‘‘d (unless SETH fails).\nHere again, better running times for simplification problems in a low-dimensional\nspace with dâˆˆoâ€‹(logâ¡n)ğ‘‘ğ‘œğ‘›d\\in o(\\log n) are still possible.\nTableÂ 1 provides an overview of known lower and\nupper bounds for optimal polyline simplification. As the cubic running time of the Imaiâ€“Iri algorithm\nand the quadratic running time of the Chanâ€“Chin algorithm\nmay be prohibitive for processing long polylines even for d=2ğ‘‘2d=2,\nheuristics and approximation algorithms have been investigated.\nThe Douglasâ€“Peucker algorithm ,\none of the most simple and widely used heuristics, computes a simplified\npolyline under the local Hausdorff distance in ğ’ªâ€‹(nâ€‹logâ¡n)ğ’ªğ‘›ğ‘›\\mathcal{O}(n\\log n) timeÂ \nand under the local FrÃ©chet distance in ğ’ªâ€‹(n2)ğ’ªsuperscriptğ‘›2\\mathcal{O}(n^{2}) timeÂ Â â€“\nbut without any guarantee regarding the solution size.\nAgarwal et al.Â  presented an approximation algorithm with a running time of\nğ’ªâ€‹(nâ€‹logâ¡n)ğ’ªğ‘›ğ‘›\\mathcal{O}(n\\log n) that works for any Lp norm and\ngeneralizes to â„dsuperscriptâ„ğ‘‘\\mathbb{R}^{d}.\nIt computes a simplification under the local FrÃ©chet distance for Î´ğ›¿\\delta,\nwhere the simplification size does not exceed\nthe optimal simplification size for Î´/2ğ›¿2\\delta/2.\nThere are other heuristics neither based on the Hausdorff nor the FrÃ©chet distance\nlike the algorithm by Visvalingam and WhyattÂ ,\nwhich measures the importance of a vertex by the triangular area it adds. There are also variants of the FrÃ©chet distance which allow for faster polyline simplification.\nFor example, polyline simplification under the discrete FrÃ©chet distance\n(where only the distance between the vertices but not the points on\nthe line segments in between matters) can be solved to optimality\nin ğ’ªâ€‹(n2)ğ’ªsuperscriptğ‘›2\\mathcal{O}(n^{2}) time [ref]6.\nHowever, the discrete FrÃ©chet distance heavily depends on the density of vertices on the polyline,\nand hence for many applications the\ncontinuous FrÃ©chet distance studied in this paper constitutes a more meaningful measure. The problem variant where the requirement is dropped that all vertices of the simplification must be vertices of the input polyline is called a weak simplification.\nGuibas et al.Â 9 showed that an optimal\nweak simplification under the (global) FrÃ©chet distance can be computed in ğ’ªâ€‹(n2â€‹log2â¡n)ğ’ªsuperscriptğ‘›2superscript2ğ‘›\\mathcal{O}(n^{2}\\log^{2}n) time.\nLater Agarwal et al.Â  gave an ğ’ªâ€‹(nâ€‹logâ¡n)ğ’ªğ‘›ğ‘›\\mathcal{O}(n\\log n)-time\napproximation algorithm for a weak simplification violating the distance thresholdÂ Î´ğ›¿\\delta\nby a factor of at mostÂ 8; see also an overview by Van de Kerkhof et al.Â . Regarding our techniques, we remark that the concept of a wavefront\nbeing comprised of (circular) arcs is well-established in computational geometry.\nMitchell,Â Mount,Â andÂ PapadimitriouÂ  have introduced\nthe continuous Dijkstra method in 1987, where a wavefront is expanded111This expansion is realized step-wise by discrete events.\nalong a surface of a polyhedron to allow shortest path computations.\nThis method was also used by Hershberger and SuriÂ \nto compute a shortest path in the plane given a set of polygonal obstacles.\nAlso, many sweep-line algorithms maintain a kind of a wavefront.\nFor example, the famous algorithm by FortuneÂ 6\nfor computing a Voronoi diagram maintains a wavefront made up\nof hyperbolic curves.\nAnother approach computes a (weighted) Voronoi diagram directly by\na wavefront expanding around the input pointsÂ .\nApart from a few similarities regarding the computation of\nintersection points of (circular) arcs, line segments, etc.,\nwe use a different type of wavefront.\nIn all of the aforementioned examples, the wavefront is a kinetic data structure\nwhere things move or expand continuously (although it suffices to consider a few discrete events).\nIn contrast, the structure by Melkman and Oâ€™RourkeÂ \nthat we call a wavefront is more static and simple:\nit is a collection of (circular) arcs that we\nupdate iteratively with a new unit circle.\nThere is no expansion of existing arcs or â€œtime in betweenâ€.\n\nReference markers found: [6]\n\nContext windows for each [ref]:\n[ref]6: FrÃ©chet distance\n(where only the distance between the vertices but not the points on\nthe line segments in between matters) can be solved to optimality\nin ğ’ªâ€‹(n2)ğ’ªsuperscriptğ‘›2\\mathcal{O}(n^{2}) time [ref]6.\nHowever, the discrete FrÃ©chet distance heavily depends on the density of vertices on the polyline,\nand hence for many applications the\ncontinuous FrÃ©chet distance studied in this paper\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 6,\n            \"titles\": [\n                \"Consistent Simplification of Polyline Tree Bundles\",\n                \"Near-linear time approximation algorithms for curve simplification\",\n                \"FrÃ©chet distance-based map construction algorithm\",\n                \"Constructing street networks from GPS trajectories\",\n                \"Computing the FrÃ©chet distance between two polygonal curves\",\n                \"Efficiently approximating polygonal paths in three and higher dimensions\",\n                \"Simplifying 3D polygonal chains under the discrete FrÃ©chet distance\",\n                \"(ğ‘˜,â„“)-Medians Clustering of Trajectories Using Continuous Dynamic Time Warping\",\n                \"Polyline Simplification has Cubic Complexity\",\n                \"Fine-grained analysis of problems on curves\",\n                \"Efficient FrÃ©chet distance queries for segments\",\n                \"Approximation of polygonal curves with minimum number of line segments or minimum error\",\n                \"Algorithms for the reduction of the number of points required to represent a digitized line or its caricature\",\n                \"Approximating the FrÃ©chet distance for realistic curves in near linear time\",\n                \"Pattern classification and scene analysis\",\n                \"A sweepline algorithm for Voronoi diagrams\",\n                \"A natural metric for curves â€“ computing the distance for polygonal chains and approximation algorithms\",\n                \"An efficient and topologically correct map generalization heuristic\",\n                \"Approximating polygons and subdivisions with minimum link paths\",\n                \"An Efficient, Practical Algorithm and Implementation for Computing Multiplicatively Weighted Voronoi Diagrams\",\n                \"Speeding up the Douglas-Peucker line-simplification algorithm\",\n                \"An optimal algorithm for euclidean shortest paths in the plane\",\n                \"Polygonal approximations of a curve â€“ formulations and algorithms\",\n                \"Visual abstraction and stylisation of maps\",\n                \"On polygonal chain approximation\",\n                \"Spatiotemporal compression techniques for moving point objects\",\n                \"SGM: Seed growing map-matching with trajectory fitting\",\n                \"The discrete geodesic problem\",\n                \"A comparison of line extraction algorithms using 2d range data for indoor mobile robotics\",\n                \"An iterative procedure for the polygonal approximation of plane curves\",\n                \"Global Curve Simplification\",\n                \"On Optimal Polyline Simplification Using the Hausdorff and FrÃ©chet Distance\",\n                \"The Douglas-Peucker algorithm for line simplification: Re-evaluation through visualization\",\n                \"Line generalisation by repeated elimination of points\",\n                \"A non-self-intersection Douglas-Peucker algorithm\",\n                \"Generated Reference Title 35 for [ref]6\",\n                \"Generated Reference Title 36 for [ref]6\",\n                \"Generated Reference Title 37 for [ref]6\",\n                \"Generated Reference Title 38 for [ref]6\",\n                \"Generated Reference Title 39 for [ref]6\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]6 based on the context and research area of Polyline Simplification under the Local FrÃ©chet Distance Has Almost-Quadratic Runtime in 2D. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}