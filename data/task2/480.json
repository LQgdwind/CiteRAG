{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: 1. Introduction\n\nPaper Abstract: \n\nPaper Section Text:\nConvergence tests in relative energy-norm error are carried out with three\ndifferent mesh refinement strategies. The first one is uniform hâ„h-refinements,\nin pursuance of both exposing the behaviour of AgFEM, in absence of hanging\nnode constraints, and the limited regularity of the Fichera corner problem. The\nremaining two are error-driven; they are distinguished by different optimality\ncriteria on the elemental error indicator Î³Tsubscriptğ›¾ğ‘‡\\gamma_{T}, for any Tâˆˆğ’¯hğ‘‡subscriptğ’¯â„T\\in{\\mathcal{T}}_{h}. It is not in the scope of this work to design a posteriori error\nestimation techniques for AgFEM, although there are some works with other\nunfitted FE methods that explore this questionÂ .\nHence, since the target problems have known analytical solution, Î³Tsubscriptğ›¾ğ‘‡\\gamma_{T}\nis taken as the energy norm of the local true error e=uâˆ’uhğ‘’ğ‘¢subscriptğ‘¢â„e=u-u_{h}, that is, Error-driven mesh adaptation seeks an optimal mesh with an iterative procedure.\nIn the examples below, optimality is declared when the global absolute\ndiscretisation error, measured in energy norm, â€–eâ€–asubscriptnormğ‘’ğ‘\\|e\\|_{a} is below a\nprescribed quantity Î³ğ›¾\\gamma, i.e. (8) is referred to as the\nacceptability criterion. The process starts with an initial guess of the optimal mesh. After finding the\napproximate solution and the exact cell-wise error distribution, a new mesh is\ndefined with a remeshing strategy. This step consists in comparing each\nÎ³Tsubscriptğ›¾ğ‘‡\\gamma_{T} to a given threshold, commonly known as the optimality\ncriterion, which is later defined. Depending on the result of the comparison, a\ndifferent remeshing flag is assigned to the cell. If Î³Tsubscriptğ›¾ğ‘‡\\gamma_{T} is above the\nthreshold, Tğ‘‡T is marked for refinement. Otherwise, Tğ‘‡T is left unmarked\nor, optionally, marked for coarsening, when Î³Tsubscriptğ›¾ğ‘‡\\gamma_{T} falls well below the\nthreshold. Following this, the mesh is transformed, according to the cell-wise\nremeshing flags, and partitioned. Next, a new FE space is created, by\ndistributing DOFs on top of the new mesh and computing the nonconforming\nDOF constraints and, if using ğ’±hagsuperscriptsubscriptğ’±â„ag{\\mathcal{V}}_{h}^{\\mathrm{ag}}, also the ill-posed DOF\nconstraints. After FE integration and assembly, the resulting linear system\nis solved and the cell-wise error distribution is updated. If the current mesh\ncomplies with the acceptability criterion of (8),\nthe process is stopped, otherwise it goes back to the application of the\noptimality criterion. As mentioned before, two different optimality criteria (thresholds for\nrefinement) are studiedThe first one, the LBÂ  \ncriterion, establishes that the error distribution in an optimal mesh (denoted\nwith *) is uniform, that is where Mâˆ—superscriptğ‘€M^{*} is the number of cells in the optimal mesh. At each mesh adaptation\nstep, this quantity is estimated as with dğ‘‘d the space dimension, mğ‘šm the degree of the interpolation (in\nsecond-order elliptic problems) and Mğ‘€M the number of cells of the current\niteration. On the other hand, the OBÂ  criterion\nconsiders that the distribution of error density in an optimal mesh is\nuniform, that is where Î©Î©\\Omega is the measure of the domain and Î©Tâˆ—âˆ©Î©subscriptÎ©superscriptğ‘‡Î©\\Omega_{T^{*}\\cap\\Omega} is\nthe measure of Tâˆ—âˆ©Î©superscriptğ‘‡Î©T^{*}\\cap\\Omega. While the former criterion has\nbeen provedÂ  to provide standard body-fitted FE meshes\nsatisfying (8) with the least number of\nelements, the latter scales the threshold in terms of the size of the\n(ill-posed) cell. One of the goals of the following experiments is to see how\nboth strategies perform in the context of unfitted FEs. Note that, with\nrespect to standard body-fitted FEM, both remeshing strategies are almost\napplied verbatim to an unfitted FE setting; the only difference being that\nthe local quantities in cut cells are computed in the interior part only, in the\nsame way as for the local integration of the weak form stated in\n(4). Convergence tests with uniform hâ„h-refinements follow the usual procedure,\nwhereas error-driven tests are controlled with a finite sequence of decreasing\nerror objectives Î³isubscriptğ›¾ğ‘–\\gamma_{i}, i>1ğ‘–1i>1. For each i>1ğ‘–1i>1, the iterative procedure\ndescribed above is carried out to find the mesh that complies with the\nacceptability criterion of (8) with\nÎ³=Î³iğ›¾subscriptğ›¾ğ‘–\\gamma=\\gamma_{i}. If subscript Î³isubscriptğ›¾ğ‘–\\gamma_{i} refers to the quantities obtained at the\nlast mesh iteration, at the end of the procedure we can extract the pair that is, a point of the convergence test curve. FigureÂ 7 depicts\nsome meshes found with this iterative procedure, using the LB\nacceptability criterion. We carry out all convergence tests for a fixed number of threads (MPI tasks). We\nemploy six MN-IV high-memory nodes and map each core to a different MPI task.\nTherefore, the experiments are launched in 6â‹…48=288â‹…6482886\\cdot 48=288 processors. The\npartition of the mesh considers 288288288 subdomains and is defined to seek an equal\ndistribution of the number of cells among processors (p4est default setting).\nThe well-posedness threshold for aggregation Î·0subscriptğœ‚0\\eta_{0} (see\nSectionÂ 2.2) is prescribed to 0.250.250.25 in what follows. Let us now start the discussion of the numerical results obtained with\nconvergence tests. As shown in FigureÂ 8 hâ„h-AgFEM\nbehaviour consistently mirrors the one of std.Â hâ„h-FEM. This includes that\n(1) hâ„h-AgFEM always produces more optimal meshes, in terms of the error,\nthan its non-adaptive version; and (2) optimal convergence rates are retained,\neven for the hâ„h-AgFEM Fichera problems, where convergence in the\nnon-adaptive version is limited by regularity. Although the std.Â method is slightly more accurate than its ag.Â counterpart\nfor the Fichera problems with uniform refinements, the usual behaviour is that\nthey are very similar in terms of accuracy. Another outcome observed is that the\nLB criterion is clearly more cost-efficient, in terms of mesh size, than\nthe OB one for both std.Â and ag.Â variants. This is also reported\ninÂ  with std.Â hâ„h-FEM. However, as expected, the linear solver does not manage to generate a solution\nin most of std.Â FE cases. Either the preconditioner cannot be generated or\nit is not positive definite (thus, incompatible with the conjugate gradient\nmethod). Both issues are directly related to the severe ill-conditioning of\nmatrices obtained with the std.Â method, as extensively reported in previous\nworksÂ  . On the other hand, when using the ag.Â method, GAMG is fully robust and converges towards the solution at the\n10âˆ’9superscript10910^{-9} tolerance. |uâˆ’uh|H1/|u|H1subscriptğ‘¢subscriptğ‘¢â„subscriptğ»1subscriptğ‘¢subscriptğ»1|u-u_{h}|_{H_{1}}/|u|_{H_{1}} |uâˆ’uh|H1/|u|H1subscriptğ‘¢subscriptğ‘¢â„subscriptğ»1subscriptğ‘¢subscriptğ»1|u-u_{h}|_{H_{1}}/|u|_{H_{1}} |uâˆ’uh|H1/|u|H1subscriptğ‘¢subscriptğ‘¢â„subscriptğ»1subscriptğ‘¢subscriptğ»1|u-u_{h}|_{H_{1}}/|u|_{H_{1}} |uâˆ’uh|H1/|u|H1subscriptğ‘¢subscriptğ‘¢â„subscriptğ»1subscriptğ‘¢subscriptğ»1|u-u_{h}|_{H_{1}}/|u|_{H_{1}} |uâˆ’uh|H1/|u|H1subscriptğ‘¢subscriptğ‘¢â„subscriptğ»1subscriptğ‘¢subscriptğ»1|u-u_{h}|_{H_{1}}/|u|_{H_{1}} Despite poor robustness of the solver with the std.Â method, available results\nin FigureÂ 9 are enough to clearly identify higher\ngrowth rates in number of iterations for std.Â matrices, than for ag.Â ones.\nThis exposes that, among the two methods, only hâ„h-AgFEM is potentially\nscalable, as the number of iterations mildly grows with the size of the problem;\neven for hâ„h-AgFEM points in FigureÂ 9 with the\nlargest number of DOFs, convergence is declared in almost twenty\niterations. We have verified that, in this context, the solver achieves\nsingle-digit reduction of the residual norm in 2-3 iterations, at most. Textbook\nmultigrid efficiency is attained when the solver uses a modest number of point\nsmoothing steps and convergence nearly advances at one digit in reduction of the\nresidual norm per iterationÂ . We have checked the former is\nsatisfied, by inspecting PETSc log data, whereas the latter is broadly\nfulfilled in AgFEM experiments. Therefore, GAMG on hâ„h-AgFEM\nmatrices is not only robust, but also efficient. Petsc gAMG iterations Petsc gAMG iterations Petsc gAMG iterations Petsc gAMG iterations Petsc gAMG iterations A final experiment with convergence tests looks at the sensitivity of AgFEM\nto the well-posedness threshold Î·0subscriptğœ‚0\\eta_{0}. As it is shown in\nFigureÂ 10, low values of Î·0subscriptğœ‚0\\eta_{0} may not bypass the\nsmall cut-cell problem and hinder GAMG solvability, as shown in the 3D\nparallel examples. Conversely, high values of Î·0subscriptğœ‚0\\eta_{0} do not affect robustness,\nbut increase solver iterations and reduce (local) accuracy. This is most likely\nan effect of excessive well-posed-to-ill-posed DOF extrapolation. As a\nresult, optimal Î·0subscriptğœ‚0\\eta_{0} values may be found in the middle of the  1 [ref]1 range.\nThis means that, while enforcing a minimum amount of aggregation is required to\nguarantee robustness, superfluous aggregation deteriorates solver efficiency.\nThis effect is particularly prominent in hâ„h-adaptivity; setting Î·0=1subscriptğœ‚01\\eta_{0}=1 on\nuniform meshes leads to decent results, as demonstrated in a previous\nworkÂ . |uâˆ’uh|H1/|u|H1subscriptğ‘¢subscriptğ‘¢â„subscriptğ»1subscriptğ‘¢subscriptğ»1|u-u_{h}|_{H_{1}}/|u|_{H_{1}} |uâˆ’uh|H1/|u|H1subscriptğ‘¢subscriptğ‘¢â„subscriptğ»1subscriptğ‘¢subscriptğ»1|u-u_{h}|_{H_{1}}/|u|_{H_{1}} |uâˆ’uh|H1/|u|H1subscriptğ‘¢subscriptğ‘¢â„subscriptğ»1subscriptğ‘¢subscriptğ»1|u-u_{h}|_{H_{1}}/|u|_{H_{1}} Petsc gAMG iterations Petsc gAMG iterations Petsc gAMG iterations\n\nReference markers found: [1]\n\nContext windows for each [ref]:\n[ref]1: reduce (local) accuracy. This is most likely\nan effect of excessive well-posed-to-ill-posed DOF extrapolation. As a\nresult, optimal Î·0subscriptğœ‚0\\eta_{0} values may be found in the middle of the  1 [ref]1 range.\nThis means that, while enforcing a minimum amount of aggregation is required to\nguarantee robustness, superfluous aggregation deteriorates solver efficiency.\nThis effect is particularly\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 1,\n            \"titles\": [\n                \"A tetrahedral space-filling curve for non-conforming adaptive meshes\",\n                \"Scalable Algorithms for Parallel Tree-based Adaptive Mesh Refinement with General Element Types\",\n                \"p4est: Scalable Algorithms for Parallel Adaptive Mesh Refinement on Forests of Octrees\",\n                \"Recursive Algorithms for Distributed Forests of Octrees\",\n                \"On a general implementation of $h$- and $p$-adaptive curl-conforming finite elements\",\n                \"An extreme-scale implicit solver for complex PDEs: highly heterogeneous flow in earthâ€™s mantle\",\n                \"Scalable adaptive mantle convection simulation on petascale supercomputers\",\n                \"A scalable parallel finite element framework for growing geometries. application to metal additive manufacturing.\",\n                \"A posteriori error estimation in finite element analysis\",\n                \"A posteriori error estimates with boundary correction for a cut finite element method\",\n                \"On a Data Structure for Adaptive Finite Element Mesh Refinements\",\n                \"Linear multipoint constraints applied via transformation as part of a direct stiffness assembly process\",\n                \"Algorithms and data structures for massively parallel generic adaptive finite element codes\",\n                \"A Generic Finite Element Framework on Parallel Tree-Based Adaptive Meshes\",\n                \"Condition number analysis and preconditioning of the finite cell method\",\n                \"CutFEM: Discretizing Geometry and Partial Differential Equations\",\n                \"The Finite Cell Method: A Review in the Context of Higher-Order Structural Analysis of CAD and Image-Based Geometric Models\",\n                \"The aggregated unfitted finite element method for elliptic problems\",\n                \"Modeling holes and inclusions by level sets in the extended finite-element method\",\n                \"Extended finite element method for three-dimensional crack modelling\",\n                \"A Nitsche-based cut finite element method for a fluid-structure interaction problem\",\n                \"The extended finite element method for two-phase and free-surface flows: A systematic study\",\n                \"Shape optimization using the cut finite element method\",\n                \"Phase-field boundary conditions for the voxel finite cell method: Surface-free stress analysis of CT-based bone structures\",\n                \"Robust and scalable domain decomposition solvers for unfitted finite element methods\",\n                \"Robust and parallel scalable iterative solutions for large-scale finite cell analyses\",\n                \"Distributed-memory parallelization of the aggregated unfitted finite element method\",\n                \"PETSc Users Manual\",\n                \"Mixed aggregated finite element methods for the unfitted discretization of the Stokes problem\",\n                \"FEMPAR: An Object-Oriented Parallel Finite Element Framework\",\n                \"Nonconforming Mesh Refinement for High-Order Finite Elements\",\n                \"Computing with hp-adaptive finite elements: Volume 1 one and two dimensional elliptic and maxwell problems\",\n                \"Theoretical formulations for adaptive finite element computations\",\n                \"A study of mesh optimality criteria in adaptive finite element analysis\",\n                \"Notes on mesh optimal criteria in adaptive finite element computations\",\n                \"A unified approach to remeshing strategies for finite element h-adaptivity\",\n                \"Finite elements and fast iterative solvers: with applications in incompressible fluid dynamics\",\n                \"Generated Reference Title 37 for [ref]1\",\n                \"Generated Reference Title 38 for [ref]1\",\n                \"Generated Reference Title 39 for [ref]1\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]1 based on the context and research area of 1. Introduction. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}