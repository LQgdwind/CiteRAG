{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Algorithmic Challenges in Ensuring Fairness at the Time of Decision\n\nPaper Abstract: \n\nPaper Section Text:\nFairness in static decision-making. Notions of fairness in static decision-making typically ensure that various stakeholders are treated equitably . Two broad varieties of notions have appeared in this regard. First is the popular notion of individual fairness [ref]15, which requires that similar individuals must receive similar treatments. Formally, if xisubscriptùë•ùëñx_{i} is the decision received by individual iùëñi, then individual fairness requires that |xi‚àíxj|‚â§K‚Äãd‚Äã(i,j)subscriptùë•ùëñsubscriptùë•ùëóùêæùëëùëñùëó|x_{i}-x_{j}|\\leq Kd(i,j) for any two individuals iùëñi and jùëój, where K>0ùêæ0K>0 is some constant, and d‚Äã(i,j)ùëëùëñùëód(i,j) is a similarity metric that captures some publicly acceptable notion of ‚Äúdistance\" between two individuals that dictates the allowable disparity between their decisions. The second notion is group fairness, also known as statistical parity  [ref]17, under which one demands parity in certain statistics of the decisions across multiple groups of people, e.g., requiring that two groups of populations in the same role have similar average salaries in an organization.\nSuch parity notions have been proposed in the context of multi-segment pricing recently by  and . For example, the notion of price fairness considered by  imposes bounds on the price disparity seen across segments, i.e., they require that |pi‚àípj|‚â§Ci‚Äãjsubscriptùëùùëñsubscriptùëùùëósubscriptùê∂ùëñùëó|p_{i}-p_{j}|\\leq C_{ij} for any two customer segments iùëñi and jùëój where Ci‚Äãj>0subscriptùê∂ùëñùëó0C_{ij}>0 is some constant. The common aspect of these two notions is that they impose bounds on the degree of envy felt by entities ‚Äì either individuals or groups ‚Äì when comparing their decision to others. In Section¬†2, we consider a generalization of such notions of fairness. Temporal notions of fairness in dynamic decision-making. Broadly, four different types of temporal notions of fairness have appeared in the literature on online decision-making. The first type of constraint is a time-independent fairness constraint in which a static fairness constraint must be satisfied independently in each period. For example,  and  consider a multi-segment dynamic pricing problem where the price fairness constraint of  must be satisfied in each time period. In contrast, the second type of fairness constraint is what we refer to as a time-dependent decision-adaptive fairness constraint. FTD is an example of this type of temporal constraint. Such constraint changes depending on the decisions taken in the past, but is agnostic to the outcomes of the decisions. Similar constraints have appeared in recent and parallel literature. For example,  requires that the price offered to a particular segment must be close to the prices offered to the same segment over the past kùëòk time periods (in addition to satisfying the price fairness constraint across segments every time period). Such a sliding-window fairness constraint was also considered by  in the context of adaptive supervised learning. In a similar vein, and the most related to our paper,  define the notion of individual fairness in hindsight in the context of contextual bandit problems. This is a temporal version of the static notion of individual fairness that guarantees individual fairness at the time of decision based on some underlying similarity metric. Our meta-objective of FTD is a significant generalization of this notion that goes beyond individual fairness objectives for static decision-making (e.g., unlike individual fairness, we can model additive as well as multiplicative notions of envy-freeness in our framework, with asymmetric allowable disparities across groups). Moreover, the technical analysis of  is restricted to a simple and abstract contextual bandit setup where the decision-maker tries to distinguish between a finite set of utility models. Our framework, on the other hand, allows us to consider a general stochastic convex optimization setup that is applicable in a broader variety of settings. The third type of temporal fairness constraint is what we refer to as a time-dependent outcome-adaptive fairness constraint, where the constraint can change as the outcomes from the decisions change. For example,  has introduced a fairness constraint in a contextual bandit setting requiring that preferential treatment be given to an arriving entity only if it is known with high enough certainty that such preferential treatment is justified by current estimates of the mean rewards resulting from the treatment. Thus, as entities are administered decisions over time, certainty in their reward distributions increases, and they can eventually be treated differently. A Bayesian version of this idea was proposed by  in the non-contextual bandit setting, in which decisions are constrained to be fair with respect to the posterior reward distributions of the arms at any time. In this way, as the posterior distributions converge to the true distributions, violations of the desired fairness constraint should diminish. In a similar vein,  consider a problem of ensuring group fairness in hiring, where uncertainty is modeled using a partial order and decisions are constrained to be consistent with the partial order at any time. The fourth type of temporal fairness constraint asks for fairness of certain decision statistics, either ex ante or ex post, across arriving entities over time. For example,  considers a sequential resource allocation setting where entities arrive over time with certain demands and the goal is to maximize the minimum fill rate.  similarly considers the problem of maximizing the minimum service rate across different groups in an online bipartite matching setting. The main difference from the other three types of constraints is that one doesn‚Äôt necessarily seek to guarantee comparative fairness for an entity arriving at a point in time, but rather one guarantees fair treatment of groups of entities across time. A general framework for satisfying such time-average fairness constraints in the context of kidney transplantation has been proposed by . Decision-constrained stochastic convex optimization. Our work makes fundamental contributions to decision-constrained stochastic convex optimization under bandit feedback.\nIn general, none of the existing algorithms from the convex optimization toolkit can be easily modified to satisfy FTD. For example, FTD may require that decisions are monotonically increasing in each dimension as we see in Section¬†5. Even this requirement cannot be met by simple modifications of existing algorithms. In the noiseless bandit feedback setting, Kiefer gave an ùí™‚Äã(1)ùí™1\\mathcal{O}(1)-regret algorithm, now well known as Golden-Section Search, for minimizing a one-dimensional convex function . This algorithm iteratively uses three-point function evaluations to ‚Äúzoom in‚Äù to the optimum, by eliminating a point and sampling a new point in each round. Its mechanics render it infeasible to implement it in a fashion that respects the monotonicity of decisions. For higher dimensions, a ùí™‚Äã(1)ùí™1\\mathcal{O}(1)-regret algorithm has been designed by . This algorithm is based on gradient-descent using a one-point gradient estimate constructed by sampling uniformly in a ball around the current point. This key idea recurringly appears in several works on convex optimization with bandit feedback (e.g., , , ). However, due to the randomness in the direction chosen to estimate the gradient, such an approach does not satisfy monotonicity. For the case of noisy bandit feedback,  has shown a lower bound of Œ©‚Äã(T)Œ©ùëá\\Omega(\\sqrt{T}) in the single-dimensional setting that holds for smooth and strongly convex functions and showed that an appropriately tuned version of the well-known Kiefer-Wolfowitz  stochastic approximation algorithm achieves this rate. This algorithm uses two-point function evaluations to construct gradient estimates, which are then utilized to perform gradient-descent. Our near-optimal algorithms in Section¬†5 are the most related to this approach, where we tackle the significant additional challenge that the two-point evaluations need to consistently satisfy monotonicity over time while attaining the same regret bounds (up to logarithmic factors). For the case of convex functions, Agrawal et al. designed an algorithm that achieves the ùí™~‚Äã(T)~ùí™ùëá\\widetilde{\\mathcal{O}}(\\sqrt{T}) bound under bandit feedback . In the one-dimensional case, their approach is the most related to the golden-section search procedure of , and as such, is infeasible to implement in a monotonic fashion. Though not motivated by fairness concerns, two recent parallel works have considered the problem of ensuring monotonicity of decisions in stochastic optimization under bandit feedback ([ref]36 and ).222It may be worth mentioning that the first public drafts of both these works appeared after the first public draft of an earlier version of our paper , although it is most likely that the research was conducted in parallel. Assuming that the functions are only known to be Lipschitz and unimodal they find that the optimal achievable regret is Œò~‚Äã(T3/4)~Œòsuperscriptùëá34\\widetilde{\\Theta}(T^{3/4}), which is higher than the Œò~‚Äã(T2/3)~Œòsuperscriptùëá23\\widetilde{\\Theta}(T^{2/3}) regret achievable without the monotonicity requirement. In contrast, Theorem¬†2 implies that under the assumption that the cost functions are smooth and strongly convex, the unconstrained optimal regret bound of ùí™~‚Äã(T)~ùí™ùëá\\widetilde{\\mathcal{O}}(\\sqrt{T}) is attainable while ensuring monotonicity of decisions (up to logarithmic terms). We also note that, because the settings considered by these other works are more pessimistic in their view of the possible cost functions, algorithm-design for optimizing the worst-case turns out to be simpler. In particular, both [ref]36 and  show that we cannot do better than the simple approach of sequentially traversing the decision space in a fixed direction and using a fixed step size until the utility keeps increasing (as determined by a sequence of two-point hypothesis tests). In contrast, the problem of leveraging gradient information while maintaining monotonicity, while also ensuring negligible impact on regret, results in several novel and non-trivial aspects of our algorithm design.\n\nReference markers found: [15]\n\nContext windows for each [ref]:\n[ref]15: decision-making typically ensure that various stakeholders are treated equitably . Two broad varieties of notions have appeared in this regard. First is the popular notion of individual fairness [ref]15, which requires that similar individuals must receive similar treatments. Formally, if xisubscriptùë•ùëñx_{i} is the decision received by individual iùëñi, then individual fairness requires that\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 15,\n            \"titles\": [\n                \"Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment\",\n                \"Topic modeling driven content based jobs recommendation engine for recruitment industry\",\n                \"Dynamic pricing with an unknown demand model: Asymptotically optimal semi-myopic policies\",\n                \"Resume screening using natural language processing and machine learning: A systematic review\",\n                \"Fairness and discounts: The subjective value of a bargain\",\n                \"Consumer perceptions of price (un) fairness\",\n                \"Perceptions of fair pricing\",\n                \"Dynamic pricing and consumer fairness perceptions\",\n                \"The price is unfair! a conceptual framework of price fairness perceptions\",\n                \"TITLE 1.81.5. California Consumer Privacy Act of 2018 (Title 1.81.5 added by Stats. 2018, Ch. 55, Sec. 3.)\",\n                \"Price discrimination with fairness constraints\",\n                \"Fair assortment planning\",\n                \"Individual fairness in kidney exchange programs\",\n                \"Regret and convergence bounds for a class of continuum-armed bandit problems\",\n                \"Equality of what?\",\n                \"Fairness through awareness\",\n                \"Building classifiers with independency constraints\",\n                \"Fairness, Welfare, and Equity in Personalized Pricing\",\n                \"Fairness-aware online price discrimination with nonparametric demand models\",\n                \"Dynamic pricing with fairness constraints\",\n                \"Preventing disparate treatment in sequential decision making\",\n                \"Individual fairness in hindsight\",\n                \"Fairness in learning: classic and contextual bandits\",\n                \"Calibrated Fairness in Bandits\",\n                \"Closing the gap: Group-aware parallelization for the secretary problem with biased evaluations\",\n                \"Fair dynamic rationing\",\n                \"Group-level fairness maximization in online bipartite matching\",\n                \"Fairness, efficiency, and flexibility in organ allocation for kidney transplantation\",\n                \"Sequential minimax search for a maximum\",\n                \"Random gradient-free minimization of convex functions\",\n                \"Multivariate stochastic approximation using a simultaneous perturbation gradient approximation\",\n                \"Online convex optimization in the bandit setting: gradient descent without a gradient\",\n                \"Bandit convex optimization: Towards tight bounds.\",\n                \"Stochastic estimation of the maximum of a regression function\",\n                \"Stochastic convex optimization with bandit feedback\",\n                \"Markdown pricing under unknown demand\",\n                \"Multi-armed Bandit Requiring Monotone Arm Sequences\",\n                \"Taming wild price fluctuations: Monotone stochastic convex optimization with bandit feedback\",\n                \"Resource allocation and the public sector\",\n                \"How to cut a cake fairly\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]15 based on the context and research area of Algorithmic Challenges in Ensuring Fairness at the Time of Decision. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}