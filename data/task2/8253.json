{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Disjoint Projected Enumeration for SAT and SMT without Blocking Clauses\n\nPaper Abstract: \n\nPaper Section Text:\nGiven a propositional formula Fğ¹F over a set of Boolean variables Vğ‘‰V, the All-Solution Satisfiability (AllSAT) problem consists of identifying all possible satisfying assignments for Fğ¹F. AllSAT has seen significant use across various fields, particularly in hardware and software verification. For example, it has been applied in the automatic generation of program test suites , as well as in both bounded and unbounded model checking . Additionally, AllSAT has been employed in data mining, specifically in solving the frequent itemset mining problem [ref]3. AllSAT can be extended to richer logical frameworks in the form of AllSMT (All Satisfiability Modulo Theories). Whereas AllSAT focuses on Boolean variables and propositional formulas, AllSMT expands to formulas Fğ¹F with variables from more complex domains, interpreted over one or multiple specific first-order logic theories ğ’¯ğ’¯\\mathcal{T} (e.g., linear integer arithmetic (â„’â€‹â„â€‹ğ’œâ„’â„ğ’œ\\mathcal{L}\\mathcal{I}\\mathcal{A}), linear real arithmetic (â„’â€‹â„›â€‹ğ’œâ„’â„›ğ’œ\\mathcal{L}\\mathcal{R}\\mathcal{A}) or bit-vectors (â„¬â€‹ğ’±â„¬ğ’±\\mathcal{B}\\mathcal{V})). The goal in AllSMT is to enumerate all satisfying assignments Î·ğœ‚\\eta for Fğ¹F under the constraints of the theory ğ’¯ğ’¯\\mathcal{T}. Recently, AllSMT has gained interest in artificial intelligence, which has been used for tasks such as probabilistic inference in hybrid domains via Weighted Model Integration (WMI) [ref]4 . Moreover, model counting over first-order theories (#SMT)  and the extraction of theory lemmas to generate canonical decision diagrams modulo theories  rely on enumeration strategies from AllSMT. In both AllSAT and AllSMT, the concept of projection plays an essential role. It involves restricting the enumeration to a specific subset Vrsubscriptğ‘‰ğ‘ŸV_{r} of the variables in Vğ‘‰V, thereby simplifying the search of satisfying models by ignoring the truth value of variables outside of Vrsubscriptğ‘‰ğ‘ŸV_{r}. Projection is particularly beneficial for the enumeration of non-CNF formulas. When formulas are transformed into CNFâ€”often via the Tseitin transformationâ€”projection is essential to exclude the newly introduced auxiliary variables. Projection has been applied in numerous domains other than enumeration, including predicate abstraction , image computation  0, quantifier elimination 1, and model checking 2. Enumerating all solutions for a given formula Fğ¹F is a significantly more computationally intensive task than solving a single SAT instance. When dealing with complex problems, several aspects must be carefully considered to make enumeration viable. One major challenge is the growth of the search space when dealing with complex instances. For a formula Fğ¹F with nğ‘›n variables, there are 2nsuperscript2ğ‘›2^{n} possible total assignments. Explicitly enumerating all of these would require exponential space, which is impractical for large values of nğ‘›n. To mitigate this issue, partial models can be utilized to provide more concise representations of the solution set. A partial model is an assignment that leaves some variables unspecified, implying that the truth value of these variables does not influence the satisfiability of the formula in that particular assignment. Consequently, a partial assignment with mğ‘šm specified variables represents 2nâˆ’msuperscript2ğ‘›ğ‘š2^{n-m} total assignments, effectively reducing the space needed to explore the solution space. Another critical aspect to consider in enumeration is the handling of repeated models. In some contexts, allowing the repetition of the same model in the enumeration might be acceptable or even desirable, such as in predicate abstraction applications. However, in other scenarios like Weighted Model Integration and #SMT, repeating the same model can lead to incorrect results or inefficiencies. In this paper, we focus on disjoint enumeration, where repetitions of the same assignment are strictly prohibited. SAT-based enumeration algorithms can be categorized into two main types: blocking solvers and non-blocking solvers. Blocking AllSAT solvers 3  4 are built on top of Conflict-Driven Clause Learning (CDCL) and non-chronological backtracking (NCB). These solvers work by adding blocking clauses to the formula each time a model is found. A blocking clause is designed to exclude the current satisfying assignment, ensuring that the solver does not find and return the same assignment in subsequent searches. This process is repeated until all possible satisfying assignments have been enumerated, effectively scanning the entire search space. Even though blocking solvers are relatively straightforward to implement and can be modified to retrieve partial assignments, they face significant efficiency challenges as the number of models increases. Specifically, an exponential number of blocking clauses might be required to cover the search space entirely. As more blocking clauses are added, unit propagationâ€”the process of deducing variable assignments from the existing clausesâ€”becomes increasingly difficult, leading to degraded performance. Non-blocking AllSAT solvers 0 5 address the inefficiencies associated with blocking clauses by avoiding their use altogether. Instead, these solvers employ chronological backtracking (CB) 6. In chronological backtracking, when a conflict arises during the search process, the solver backtracks to the most recently assigned variable, rather than jumping back non-chronologically as in CDCL. This method avoids covering the same model multiple times without the performance degradation caused by an excessive number of blocking clauses.\nHowever, non-blocking solvers have their limitations. They only generate total assignments, meaning all variables must be assigned a value in each satisfying assignment. Additionally, non-blocking solvers can struggle to efficiently escape regions of the search space that contain no solutions, which can lead to inefficiencies in certain scenarios. 7 introduces a formal calculus for disjunctive model counting that seeks to combine the strengths of both chronological backtracking and CDCL. This approach offers a promising direction, but the original work did not include an implementation or empirical results to demonstrate its effectiveness. Moreover, the calculus does not address how to effectively handle projected enumeration, and extending these methods to problems that include first-order logic theories. Another SAT-based approach for enumeration that is particularly useful for non-CNF formulas is based on the idea of entailment 8. Typically, when given a partial assignment Î¼ğœ‡\\mu, SAT solvers check whether Î¼ğœ‡\\mu satisfies Fğ¹F by substituting all the assigned variables in Fğ¹F with their corresponding truth values and recursively propagating these values through the formula. If this process results in âŠ¤top\\top, then Î¼ğœ‡\\mu is said to satisfy Fğ¹F, a concept known as â€evaluation to true.â€ Entailment, on the other hand, operates differently. A partial assignment Î¼ğœ‡\\mu entails Fğ¹F if every total assignment Î·ğœ‚\\eta that extends Î¼ğœ‡\\mu also satisfies Fğ¹F. In other words, after substituting the variables in Fğ¹F with the values from Î¼ğœ‡\\mu and propagating, the residual formula must be valid. Whereas determining whether a partial assignment entails a formula is computationally more expensive than simply checking if the formula evaluates to true given Î¼ğœ‡\\mu, it has been shown to be effective in generating compact partial models for enumeration 9. A few formal calculi have been developed to implement enumeration algorithms that leverage dual reasoning during enumeration 0 1. An alternative to SAT-based methods involves compiling a formula into a decomposable, deterministic negation normal form (d-DNNF). This structure allows for efficient retrieval of partial assignments that satisfy Fğ¹F. In a d-DNNF representation of a formula, every path from the root to a leaf node corresponds to a (possibly partial) assignment that satisfies Fğ¹F, and the properties of d-DNNF ensure that each assignment is mutually exclusive from the others. Building on this concept, a recently proposed tool leverages a depth-first traversal of the d-DNNF representation of a Boolean formula to enumerate models, ensuring that memory usage remains bounded by the size of Fğ¹F 2. It is important to note, however, that this approach is inherently designed for AllSAT and does not consider projection or first-order logic theories.\nRecently a new calculus to convert CNF formulae to d-DNNF using chronological backtracking has been presented 3. Based on the formal calculus in 7, in this paper we present TabularAllSAT and TabularAllSMT, respectively a projected AllSAT solver and a projected AllSMT solver that combine CDCL and chronological backtracking to avoid the introduction of blocking clauses. In particular, our main contributions can be summarized as follows: We discuss the AllSAT\nprocedure to perform disjoint partial enumeration of propositional\nformulae by combining the best of current All-\nSAT state-of-the-art literature: (iğ‘–i) CDCL, to escape search\nbranches where no satisfiable assignments can be found; (iâ€‹iğ‘–ğ‘–ii)\nchronological backtracking, to ensure no blocking clauses\nare introduced; (iâ€‹iâ€‹iğ‘–ğ‘–ğ‘–iii) efficient implicant shrinking, to reduce\nin size partial assignments, by exploiting the 2-literal watching\nscheme. We propose two implicant shrinking algorithms, intending to reduce the number of partial assignments retrived by the AllSAT procedure while making sure the calculus in 7 is not violated. We extend our procedure to deal with projected enumeration, showing how chronological backtracking and CDCL have been adapted to enumerate only a subset of important variables. We extend our procedure to deal with the enumeration of SMT formulae, showing how chronological backtracking and CDCL have been adapted to integrate theory reasoning. We perform an extensive experimental evaluation, showing the supremacy of our proposed techniques against the state-of-the-art algorithms. A preliminary and much shorter version of this paper was presented at the AAAI24 conference 4, presenting only the baseline algorithm to perform disjoint enumeration without introducing blocking clauses (ağ‘a) and the first of the two chronological implicant shrinking algorithm discussed in this work (b)b). We refer to this baseline algorithm in the manuscript as TabularAllSATAAAI24. This paper leverages the algorithm from 4 by proposing a novel implicant shrinking that allows the retrieval of shorter partial assignments without affecting computational times and is not heavily affected by variable ordering as the baseline algorithms (bğ‘b). Moreover, we extended the algorithm to deal with projected enumeration cğ‘c) and SMT enumeration (dğ‘‘d). Finally we provided an extensive and detailed experimental evaluation, to compare the implicant shrinking algorithms and the novel TabularAllSAT algorithm against the state-of-the-art solvers (eğ‘’e). The rest of the paper is organized as follows. InÂ Â§2 we introduce the background, focusing on the notation adopted, the CDCL algorithm, and chronological backtracking. InÂ Â§3 we briefly summarize the algorithm to perform AllSAT integrating CDCL and chronological backtracking with no need for blocking clauses, representing a summary of 4 and the baseline of extensions discussed in this work. InÂ Â§4 we discuss the novel implicant shrinking algorithm, to make it more effective. InÂ Â§5 and Â Â§6 we extend the baseline algorithm to address respectively projected SAT enumeration7 and SMT enumeration, showing the main difference and design choices that were required to make it compliant with the calculus in 7. At the end of sections Â§4, Â§5 and Â§6 an extensive experimental evaluation is presented, comparing our toolâ€™s latest version against the few publicly available state-of-the-art competitors.\n\nReference markers found: [3]\n\nContext windows for each [ref]:\n[ref]3: of program test suites , as well as in both bounded and unbounded model checking . Additionally, AllSAT has been employed in data mining, specifically in solving the frequent itemset mining problem [ref]3. AllSAT can be extended to richer logical frameworks in the form of AllSMT (All Satisfiability Modulo Theories). Whereas AllSAT focuses on Boolean variables and propositional formulas, AllSMT\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 3,\n            \"titles\": [\n                \"SMT-based Weighted Model Integration with Structure Awareness\",\n                \"A case for efficient solution enumeration\",\n                \"Efficient conflict analysis for finding all satisfying assignments of a Boolean circuit\",\n                \"A comparative study of SAT-based itemsets mining\",\n                \"Enhancing SMT-based Weighted Model Integration by Structure Awareness\",\n                \"Approximate Counting in SMT and Value Estimation for Probabilistic Programs\",\n                \"Canonical Decision Diagrams Modulo Theories\",\n                \"Smt techniques for fast predicate abstraction\",\n                \"Sat-based image computation with application in reachability analysis\",\n                \"Memory efficient all-solutions SAT solver and its application for reachability analysis\",\n                \"Existential quantification as incremental sat\",\n                \"Pruning techniques for the sat-based bounded model checking problem\",\n                \"Applying sat methods in unbounded symbolic model checking\",\n                \"All-SAT using minimal blocking clauses\",\n                \"A novel SAT all-solutions solver for efficient preimage computation\",\n                \"Chronological backtracking\",\n                \"Combining conflict-driven clause learning and chronological backtracking for propositional model counting.\",\n                \"Are You Satisfied by This Partial Assignment?\",\n                \"Entailing generalization boosts enumeration\",\n                \"Four flavors of entailment\",\n                \"On Enumerating Short Projected Models\",\n                \"Leveraging decision-dnnf compilation for enumerating disjoint partial models\",\n                \"An abstract cnf-to-d-dnnf compiler based on chronological cdcl\",\n                \"Disjoint Partial Enumeration without Blocking Clauses\",\n                \"On the Complexity of Derivation in Propositional Calculus\",\n                \"A Structure-preserving Clause Form Translation\",\n                \"On cnf conversion for disjoint sat enumeration\",\n                \"Chaff: Engineering an efficient SAT solver\",\n                \"GRASP: A search algorithm for propositional satisfiability\",\n                \"A machine program for theorem-proving\",\n                \"Counting models using connected components\",\n                \"Good learning and implicit model enumeration\",\n                \"Backing backtracking\",\n                \"Using DPLL for efficient OBDD construction\",\n                \"Implementing Efficient All Solutions SAT Solvers\",\n                \"Using CSP look-back techniques to solve real-world SAT instances\",\n                \"Backbone fragility and the local search cost peak\",\n                \"GANAK: A scalable probabilistic exact model counter\",\n                \"The MathSAT5 SMT solver\",\n                \"Accelerating all-sat computation with short blocking clauses\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]3 based on the context and research area of Disjoint Projected Enumeration for SAT and SMT without Blocking Clauses. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}