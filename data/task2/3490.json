{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Rule Mining over Knowledge Graphs via Reinforcement Learning\n\nPaper Abstract: \n\nPaper Section Text:\nWe conduct experiments to show our approach has better performance in terms of the quantity of mined high-quality rules in a certain time limit.\nAlthough it takes several hours to train the KG embedding and RL agent, they are offline procedures and negligible when amortized to several hundreds of predicates in KG.\nThus, we exclude the offline training time in this experiment. We compare the efficiency of our method with two rule miners AMIE+¬† and RLvLR¬†.\nThe former is a classic rule mining system and the latter is an improvement based on the former one.\nAlthough many optimizations have been proposed based on AMIE+¬†, these optimizations are scalable to all the top-down rule mining methods including ours.\nWe do not consider those optimizations in our experiments and use AMIE+ as the baseline because we only need to prove the superiority of our rule generation strategy guided by the RL agent.\nFor the reproduction reason, we re-implement the RLvLR with our trained embeddings and build a stronger baseline than the original paper¬†111Our implementation of RLvLR achieves a much better performance than the original paper in following link prediction experiments..\nOptimizations in AMIE 3 are also applicable in our rule mining framework.\nIn this experiment, we do not compare the efficiency of our method with rule miners such as RuDik¬†[ref]31 and AnyBURL¬† because they generate rules with different manners.\nFor example, AnyBURL generates rules by sampling paths in the KG, and the measures such as support and confidence are approximately calculated by sampling, which is not comparable with our accurate rule evaluation.\nIn addition, since we only evaluate the efficiency of rules in this experiment, we use the confidence based on closed-world assumption as the rule evaluation measure for all the methods. We selected all the predicates as head predicates for FB15K-237, and 30 popular predicates222We rank predicates in descend order of their number of instances in the KG, and choose the top 30 for our experiments. for Wikidata and DBpedia.\nWe set a 1 hour limit for each head predicate in FB15K-237 and 5 hour limit for each in Wikidata and DBpedia.\nTable¬†4 shows the average numbers of quality rules (#Rules, conf‚â•\\geq 0.1 and hc‚â•\\geq 0.01) and the average number of high-quality rules (#Q-Rules, conf‚â•\\geq 0.7) for selected head predicates. Results from Table¬†4 show that our method significantly outperforms baseline methods in terms of mining both the quality and high-quality rules.\nThe superiority of our method is more obvious in mining high-quality rules.\nThe numbers of quality rules mined by our method on DBpedia 3.8 and Wikidata are nearly 2 times larger than those mined by RLvLR.\nThe performance of our method is less prominent on the FB15K-237 dataset.\nAccording to our analysis, it is a subset of Freebase and has much fewer instances than a regular KG, which leads to less time cost for evaluating each rule.\nAs the time cost for rule evaluation drops, the amortized overheads of our rule search optimization are higher in the whole rule mining procedure.\nNevertheless, the superiority of our method is more highlighted as the KG size grows larger. Although we set time limits for all the comparative methods, we find our method stops early for many predicates within the pre-defined length L=5ùêø5L=5.\nThus, we plot the mined rule quantity with time for all comparative methods on the FB15K-237 dataset to further show the efficiency of our method.\nAs shown in Figure¬†5, our method spends around only 150 hours on the mining of 237 predicates in FB15K-237 and mines more rules than comparative methods in over 200 hours.\n We also conduct experiments to evaluate the predictive power of mined rules.\nThis evaluation is necessary because a method mining more rules does not mean those mined rules have more predictive power since they might just cover the existing facts.\nTo obtain the confidence degree (CD) of a fact inferred by rules, we adopt the score function from¬† , by aggregating the confidence of all the rules inferring the facts in a Noisy-OR manner.\nThe intuition is that facts inferred by more rules should have a higher confidence degree.\nFormally, for a fact k=(s,P,o)ùëòùë†ùëÉùëúk=(s,P,o) and the set of rules R‚Äãu‚Äãl‚Äãe‚ÄãsùëÖùë¢ùëôùëíùë†Rules that can infer kùëòk from the given KG, the CD of kùëòk is defined as follows: where S‚Äã(r)ùëÜùëüS(r) is the score function for rule rùëür. For the estimation of the predictive power of mined rules, we follow the setting of  and conduct experiments on DBpedia and Wikidata.\nWe eliminated from each dataset 30% of its facts involving the head predicates as the held-out sets and checked how many facts in the held-out sets can be predicted by applying mined rules on the remaining facts.\nUnlike , we only count the predicted facts in the held-out sets because the prediction of existing facts does not show the predictive power of rules.\nWe do not use FB15K-237 in this experiment because it is not a full-scale KG.\nTable¬†5 shows the numbers of predicted facts (#Facts) and those predictions with C‚ÄãD‚â•0.7ùê∂ùê∑0.7CD\\geq 0.7 (#QFacts).\nFrom the results, we can see that our method outperforms others in both datasets about the predictive power.\nIn our experimental settings, RLvLR mines more rules than AMIE+ on DBpedia while those rules have less predictive power.\nNote that, these two metrics only count the predicted facts that are in the held-out set, which can be regarded as the ‚Äúrecall‚Äù of the predicted facts.\nThus, the ratio of ‚Äú#QFacts‚Äù among ‚Äú#Facts‚Äù is not an evaluation metric for the performance of algorithms.\nFor the quality of predicted facts, we will evaluate in the next section with the precision metric. In addition, we also present the comparison of prediction time for the predictive experiment.\nSince the prediction procedure is shared among all the methods, the factor leading to the different prediction time is the number of mined rules.\nAs shown in the Table¬†5, our method requires large prediction time due to the large quantity of rules we mine.\nHowever, AMIE+ consumes significantly less prediction time, which is not proportional to the number of mined rules (our method mines around 5 times more rules than AMIE+ while requiring over 100 times more prediction time in Wikidata).\nThis is because AMIE+ mines rules from short to long, and it usually stops at short rules (L‚â§3ùêø3L\\leq 3) when the time limit is reached.\nOn the contrary, most rules our method mines are long rules (L‚â•4ùêø4L\\geq 4).\nSince the time complexity for applying a rule in KG is exponential to its length, the prediction time of our method is significantly larger than AMIE+.\nAs for RLvLR, it mines long rules as ours but ignores the sufficient discovery of short rules, thus it exhibit poor performance when predicting facts in large KG.\n\nReference markers found: [31]\n\nContext windows for each [ref]:\n[ref]31: prediction experiments..\nOptimizations in AMIE 3 are also applicable in our rule mining framework.\nIn this experiment, we do not compare the efficiency of our method with rule miners such as RuDik¬†[ref]31 and AnyBURL¬† because they generate rules with different manners.\nFor example, AnyBURL generates rules by sampling paths in the KG, and the measures such as support and confidence are\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 31,\n            \"titles\": [\n                \"Reinforced Anytime Bottom Up Rule Learning for Knowledge Graph Completion\",\n                \"Freebase: a collaboratively created graph database for structuring human knowledge\",\n                \"Dbpedia: A nucleus for a web of open data\",\n                \"Wikidata: a free collaborative knowledgebase\",\n                \"Adrl: An attention-based deep reinforcement learning framework for knowledge graph reasoning\",\n                \"Multi-modal knowledge-aware reinforcement learning network for explainable recommendation\",\n                \"Fast rule mining in ontological knowledge bases with amie+\",\n                \"Mining semantic association rules from rdf data\",\n                \"Arm‚Äìamo: An efficient association rule mining algorithm based on animal migration optimization\",\n                \"Scalable rule learning via learning representation.\",\n                \"Fast and exact rule mining with amie 3\",\n                \"Playing atari with deep reinforcement learning\",\n                \"Mastering the game of go without human knowledge\",\n                \"Deep reinforcement learning for transportation network combinatorial optimization: A survey\",\n                \"Translating embeddings for modeling multi-relational data\",\n                \"Reasoning with neural tensor networks for knowledge base completion\",\n                \"Embedding entities and relations for learning and inference in knowledge bases\",\n                \"Compositional vector space models for knowledge base completion\",\n                \"Learning rules from incomplete kgs using embeddings\",\n                \"Curriculum learning\",\n                \"Scalekb: scalable learning and inference over large knowledge bases\",\n                \"RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space\",\n                \"Long short-term memory\",\n                \"An introduction to mcmc for machine learning\",\n                \"Svm-boosting based on markov resampling: Theory and algorithm\",\n                \"Learning performance of weighted distributed learning with support vector machines\",\n                \"Reinforcement learning: An introduction\",\n                \"Deterministic policy gradient algorithms\",\n                \"Horizon: Facebook‚Äôs Open Source Applied Reinforcement Learning Platform\",\n                \"Amie: association rule mining under incomplete evidence in ontological knowledge bases\",\n                \"Yago: a core of semantic knowledge\",\n                \"Robust discovery of positive and negative rules in knowledge bases\",\n                \"An embedding-based approach to rule learning in knowledge graphs\",\n                \"Canonical Tensor Decomposition for Knowledge Base Completion\",\n                \"Tucker: Tensor factorization for knowledge graph completion\",\n                \"RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs\",\n                \"Rule-aware reinforcement learning for knowledge graph reasoning\",\n                \"Differentiable Learning of Logical Rules for Knowledge Base Reasoning\",\n                \"DRUM: End-To-End Differentiable Rule Mining On Knowledge Graphs\",\n                \"Learn to Explain Efficiently via Neural Logic Inductive Learning\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]31 based on the context and research area of Rule Mining over Knowledge Graphs via Reinforcement Learning. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}