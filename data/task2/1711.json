{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Quasi-structured quadrilateral meshing in Gmsh – a robust pipeline for complex CAD models\n\nPaper Abstract: \n\nPaper Section Text:\nGeometrical smoothing of a mesh is the process of finding good vertex\npositions given a fixed mesh topology. Ideally, we would like the positions\nto maximize some quality functional, but such formulation are usually\ntoo expensive to be solved globally and we have to resort to more efficient techniques.\nSmoothing of unstructured quadrilateral\nmeshes is still a challenging problem in our opinion. Simple and fast\ntechniques, such as Laplacian smoothing and its variants, often produce tangled elements\n(negative quality) while more advanced non-linear optimization techniques are\ncomputationally too expensive to be used on large sets of elements. For CAD\nsurfaces, an additional expensive operation is the projection of a 3D point on\nthe surface, which is typically performed many times during optimization. As an\napproximation, it is possible to project on a triangulated representation of\nthe geometry, but even this approximation is expensive when applied millions of\ntimes. In this work, we apply a great deal of topological remeshing (Sec. 6)\nand each time we use smoothing techniques to determine the geometry before\nvalidating or rejecting the remeshing. Concretely, this means that we are applying\nsmoothing all the time, on many more elements that there are in the initial or final\nmesh. For instance, if there are 100​k100𝑘100k vertices in the quadrilateral mesh, we will\nprobably smooth millions of vertex positions. While smoothing is always expensive\nin any mesher, the computational cost is particularly critical in our approach and\nwe have to employ fast techniques and fall-back to expensive ones only locally and\nin last resort. Before and after any smoothing operation, we compute the element\nqualities and we revert the vertex positions if the quality decreased. For consistency with other Gmsh algorithms, we use the Signed Inverse\nCondition Number (SICN) metric to evaluate the geometric quality of the quads.\nIt is the inverse of the condition number in Frobenius norm of the mapping from the\nquad to the regular square. This metric, which is also called shape quality\n, has a behavior similar to the scaled Jacobian: the range is\n[−1,1]11[-1,1] with negative values for invalid elements and a maximum value of 111\nfor squares (and rectangles for the scaled Jacobian). As with the Jacobian,\nthe SICN value is not constant inside a\nquad, so we use the minimum. In practice, most mesher sample the quad quality\nat the four corners and take the minimum. Assuming the\nquad corners are 𝐱i,i∈[ref]1 subscript𝐱𝑖𝑖14\\mathbf{x}_{i},i\\in[ref]1  and Nisubscript𝑁𝑖N_{i} are the CAD surface unit normals, the scaled Jacobian and SICN values at the i-th corner\nare respectively : When one edge length ∥𝐋i∥delimited-∥∥subscript𝐋𝑖\\left\\lVert\\mathbf{L}_{i}\\right\\rVert tends to zero (geometrical edge collapse),\nthe scaled Jacobian will not tend to zero but to the sine of the angle at the corner\n(as 𝐋i−1×𝐋i=∥𝐋i−1∥​∥𝐋i∥​sin⁡(θ)​𝐧subscript𝐋𝑖1subscript𝐋𝑖delimited-∥∥subscript𝐋𝑖1delimited-∥∥subscript𝐋𝑖𝜃𝐧\\mathbf{L}_{i-1}\\times\\mathbf{L}_{i}=\\left\\lVert\\mathbf{L}_{i-1}\\right\\rVert\\left\\lVert\\mathbf{L}_{i}\\right\\rVert\\sin(\\theta)\\ \\mathbf{n}).\nThis observation have very practical implications:\nwhen sampling the quality at the four corners, a quad mesh may have many almost-collapsed\nedges (e.g. 1​e−121superscript𝑒121e^{-12}) but still a high minimum scaled jacobian (e.g. 0.70.70.7).\nOn the other hand, the SICN quality metric, also sampled at the four corners, will\ntend to zero with edge collapse. In our experience, the discretized SICN\nshould be preferred to the scaled Jacobian when evaluating the quality of isotropic quadrilateral meshes. When we are dealing with\na parametrized CAD model, we have a valid u​v𝑢𝑣uv trimmed parametrization of each\nCAD face. To smooth the vertices inside a cavity C𝐶C, which can be a whole CAD\nface, we extract continuous 𝐮𝐯∈ℝ2𝐮𝐯superscriptℝ2\\mathbf{uv}\\in\\mathbb{R}^{2} values for each boundary 𝐱∈∂C𝐱𝐶\\mathbf{x}\\in\\partial C.\nOne must be careful with the parametrization jumps (e.g. periodic seam on a\ncylinder). Sometimes it is not possible to have a continuous boundary in the\nparameter domain (e.g. around the pole of a sphere parametrization), and we move\nto the next smoothing options. Once we have a continuous 𝐮𝐯𝐮𝐯\\mathbf{uv} on the boundary,\nwe simply solve the unweighted Laplacian equations Δ​u=0Δ𝑢0\\Delta u=0 and\nΔ​v=0Δ𝑣0\\Delta v=0,\nwhere each internal value is the arithmetic average of its edge-connected\nneighbors. It is important to use the arithmetic average and a direct linear\nsolver to respect the maximum principle and avoid inverted elements in the\nparameter domain. Depending on the distortions in the CAD parametrization,\nthis technique may both produce high-quality or poor elements.\nTo retrieve the 3D positions, we then apply the CAD face mapping\n𝐱=f​(𝐮𝐯)𝐱𝑓𝐮𝐯\\mathbf{x}=f(\\mathbf{uv}). Depending on the resulting element qualities, we keep or we reject\nthis smoothing.\nThe huge advantage of this approach is that there is no surface\nprojection and simply two linear solves, making it a very fast smoother.\nEven if the quality may be poor due to distortion in the CAD mapping, it is\nstill a good initial guess since all elements are usually untangled. Winslow smoothing 8 is the industry-standard technique used\nfor structured grid mesh generation 2. Given a fixed\nboundary, the idea is to solve the Winslow non-linear elliptic PDE Δx​𝐮=𝟎subscriptΔ𝑥𝐮0\\Delta_{x}\\mathbf{u}=\\mathbf{0}, where 𝐮​(𝐱)𝐮𝐱\\mathbf{u}(\\mathbf{x}) are the coordinates in a certain computational\nspace and 𝐱𝐱\\mathbf{x} are the coordinates in the physical space.\nThe advantage of this approach is that the two coordinate components are\ncoupled and the resulting quads are nicely shaped, with some orthogonality\nenforced even under large distortions. By applying a finite difference (FDM)\ndiscretization to the Winslow equation [ref]22, we can derive a local smoothing kernel for\nregular vertices in the quadrilateral mesh. Assuming that (𝐱1,…,𝐱8)subscript𝐱1…subscript𝐱8(\\mathbf{x}_{1},...,\\mathbf{x}_{8})\nare the ordered vertices of the stencil around the regular vertex 𝐱𝐱\\mathbf{x}, its\nnew position is given by: This smoothing is moving the vertex outside of the CAD surface.\nWe project back on it by finding the closest point\non a triangulated representation of the CAD surface (with a kd-tree for faster\nspatial queries). If we want a more accurate projection, such as in the last\nsteps of the smoothing, we ask the projection to the CAD geometric kernel,\nwhich in our case is OpenCASCADE. On irregular vertices,\nwe use the angle-based smoothing kernel of [ref]1, where the idea\nis to move the vertices on the bisector of the one-ring. As the above Winslow\nkernel, it works well in regions where the mesh is not too constrained but\nit may create inverted elements in complex configurations. An alternative\nfor irregular vertices is the unstructured Winslow FDM kernel [ref]22,\nbut it is more complicated and would suffer from the same issues. The smoothing kernels, followed by projection on the CAD,\nare applied iteratively to all vertices of\nthe current cavity, until the displacement is smaller than a criteria or the\nmaximal number of iterations is reached. This iterative process is slower than\nthe uv-Laplacian smoothing, because of the non-linearity of the kernel\nand of the surface projections, so we generally use it without waiting for\nconvergence. It should be notated that these kernels may produce tangled\nelements, especially close to concave CAD features or in very irregular\nregions. For this reason, we compare the element qualities before and after,\nand roll back if necessary. Some local configurations\nare difficult to untangle and smooth, or even impossible. This is generally due to a mix of constraining\nCAD features and mesh irregularity, such as for the disk quadrangulation remeshing\n(Sec. 6.3). In these tricky situations, we use the non-linear\nuntangler of Mesquite  on very small patches of quads. This\noptimization can fail or may convergence too slowly, so in practice we use\na time limit of 111s. Failure to untangle is not a big issue in our\npipeline because we start from a geometrically valid unstructured mesh by\nconstruction, so untangling is only encountered during remeshing and we\ncan simply rollback if the result is tangled.\n\nReference markers found: [1]\n\nContext windows for each [ref]:\n[ref]1: SICN value is not constant inside a\nquad, so we use the minimum. In practice, most mesher sample the quad quality\nat the four corners and take the minimum. Assuming the\nquad corners are 𝐱i,i∈[ref]1 subscript𝐱𝑖𝑖14\\mathbf{x}_{i},i\\in[ref]1  and Nisubscript𝑁𝑖N_{i} are the CAD surface unit normals, the scaled Jacobian and SICN values at the i-th corner\nare respectively : When one edge length\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 1,\n            \"titles\": [\n                \"Automatic feature-preserving size field for 3D mesh generation\",\n                \"An embedded polygon strategy for quality improvement of 2D quadrilateral meshes with boundaries\",\n                \"Computing cross fields: A PDE approach based on the Ginzburg-Landau theory\",\n                \"Conformal flattening by curvature prescription and metric scaling\",\n                \"Paving: A new approach to automated quadrilateral mesh generation\",\n                \"Mixed-integer quadrangulation\",\n                \"Global structure optimization of quadrilateral meshes\",\n                \"Integer-grid maps for reliable quad meshing\",\n                \"Adaptive triangular-quadrilateral mesh generation\",\n                \"The mesquite mesh quality improvement toolkit\",\n                \"Non-local topological clean-up\",\n                \"A continuum theory for unstructured mesh generation in two dimensions\",\n                \"Dual loops meshing\",\n                \"Quantized global parametrization\",\n                \"Quadrilateral mesh simplification\",\n                \"A regularization approach for automatic quad mesh generation\",\n                \"QEx\",\n                \"Gmsh: A 3-d finite element mesh generator with built-in pre- and post-processing facilities\",\n                \"Illustrating smooth surfaces\",\n                \"Instant field-aligned meshes\",\n                \"Quadcover-surface parameterization using branched coverings\",\n                \"Winslow smoothing on two-dimensional unstructured meshes\",\n                \"ABC: A Big CAD Model Dataset For Geometric Deep Learning\",\n                \"Mambo dataset\",\n                \"A new scheme for the generation of a graded quadrilateral mesh\",\n                \"Data-driven interactive quadrangulation\",\n                \"Advances in octree-based all-hexahedral mesh generation: Handling sharp features\",\n                \"Practical graph isomorphism, II\",\n                \"Robust field-aligned global parametrization\",\n                \"Q-morph: An indirect approach to advancing front quad meshing\",\n                \"Rotational symmetry field design on surfaces\",\n                \"Algebraic Representations for Volumetric Frame Fields\",\n                \"Tracing field-coherent quad layouts\",\n                \"Periodic global parameterization\",\n                \"N-symmetry direction field design\",\n                \"Efficient unstructured mesh generation by means of Delaunay triangulation and bowyer-Watson algorithm\",\n                \"Blossom-quad: A non-uniform quadrilateral mesh generator using a minimum-cost perfect-matching algorithm\",\n                \"A frontal Delaunay quad mesh generator using theL ∞\\\\infty norm\",\n                \"Chebyshev nets from commuting PolyVector fields\",\n                \"The verdict geometric quality library\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]1 based on the context and research area of Quasi-structured quadrilateral meshing in Gmsh – a robust pipeline for complex CAD models. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}