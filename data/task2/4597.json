{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: On the existence of strong proof complexity generators\n\nPaper Abstract: \n\nPaper Section Text:\nA propositional proof system\n(to be abbreviated pps) in the sense of Cook and Reckhow [ref]5\nis a polynomial time (p-time, shortly) binary relation P​(x,y)𝑃𝑥𝑦P(x,y) such that ∃x​P​(x,y)𝑥𝑃𝑥𝑦\\exists xP(x,y) defines exactly TAUT, the\nset of propositional tautologies (in the DeMorgan language for definiteness).\nThe efficiency of a\npps P𝑃P is measured by the lengths-of-proofs function sPsubscript𝑠𝑃s_{P}: for\nτ∈TAUT𝜏TAUT\\tau\\in\\mbox{TAUT} put A pps P𝑃P for which sP​(τ)subscript𝑠𝑃𝜏s_{P}(\\tau) is bounded above by |τ|csuperscript𝜏𝑐|\\tau|^{c} for some independent c≥1𝑐1c\\geq 1\nis called p-bounded.\nAs pointed out by Cook and Reckhow [ref]5,\nthe 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} vs. c​o​𝒩​𝒫𝑐𝑜𝒩𝒫co{\\cal N}{\\cal P} problem (asking whether the computational complexity class 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} is closed under\ncomplementation) can be equivalently restated as a question whether a p-bounded pps exists.\nThe existence of a p-bounded pps is thus a fundamental problem of proof complexity. A pps P𝑃P is not p-bounded iff there exists an\ninfinite subset H⊆TAUT𝐻TAUTH\\subseteq\\mbox{TAUT}\nsuch that for any c≥1𝑐1c\\geq 1, for only finitely many τ∈H𝜏𝐻\\tau\\in H\nit holds that sP​(τ)≤|τ|csubscript𝑠𝑃𝜏superscript𝜏𝑐s_{P}(\\tau)\\leq|\\tau|^{c}.\nAny such set H𝐻H will be said to be hard for P𝑃P. There are essentially only two classes of formulas known that make plausible candidates for being hard\nfor strong pps: reflection principles and τ𝜏\\tau-formulas coming from proof complexity generators.\nThe former class is a classic topic of proof complexity and its exposition can be found in [22, Sec.19.2]. The latter formulas are constructed as follows. Take a function g:{0,1}∗→{0,1}∗:𝑔→superscript01superscript01g:{\\{0,1\\}^{*}}\\rightarrow{\\{0,1\\}^{*}} that stretches\nall size n𝑛n inputs to size m=m​(n)>n𝑚𝑚𝑛𝑛m=m(n)>n (and hence the complement of its range r​n​g​(g)𝑟𝑛𝑔𝑔rng(g) is infinite) and\nsuch that its restriction gnsubscript𝑔𝑛g_{n} to {0,1}nsuperscript01𝑛{\\{0,1\\}^{n}} is computed by a size mO​(1)superscript𝑚𝑂1m^{O(1)} circuit Cnsubscript𝐶𝑛C_{n}.\nFor each b∈{0,1}m∖r​n​g​(gn)𝑏superscript01𝑚𝑟𝑛𝑔subscript𝑔𝑛b\\in{\\{0,1\\}^{m}}\\setminus rng(g_{n})\nencode naturally (as in the proof of the 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P}-completeness of SAT)\nthe statement by a size mO​(1)superscript𝑚𝑂1m^{O(1)} tautology τ​(g)b𝜏subscript𝑔𝑏\\tau(g)_{b}. Function g𝑔g\nis said to be hard for P𝑃P iff the set ⋃n≥1{τ​(g)b|b∈{0,1}m​(n)∖r​n​g​(gn)}subscript𝑛1conditional-set𝜏subscript𝑔𝑏𝑏superscript01𝑚𝑛𝑟𝑛𝑔subscript𝑔𝑛\\bigcup_{n\\geq 1}\\{\\tau(g)_{b}\\ |\\ b\\in\\{0,1\\}^{m(n)}\\setminus rng(g_{n})\\}\nis hard for P𝑃P, and we speak of function g𝑔g as of a proof complexity generator\nin this context. We shall actually restrict ourselves here111Note\nthat one can allow that the output bits of the generator g𝑔g are computed in non-uniform\nN​T​i​m​e​(mO​(1))∩c​o​N​T​i​m​e​(mO​(1))𝑁𝑇𝑖𝑚𝑒superscript𝑚𝑂1𝑐𝑜𝑁𝑇𝑖𝑚𝑒superscript𝑚𝑂1NTime(m^{O(1)})\\cap coNTime(m^{O(1)}) and still\nget tautologies of size polynomial in m𝑚m expressing that b∉r​n​g​(gn)𝑏𝑟𝑛𝑔subscript𝑔𝑛b\\notin rng(g_{n}), cf.\nRazborov [28, Conj.2], [21, Conj.1] and  .\nThere are quite a few facts known about such generators and the interested reader may start with   . \nto the rudimentary case of generators g𝑔g\ncomputed in time polynomial in n𝑛n (except the example of function\ntts,ksubscripttt𝑠𝑘{\\mbox{{\\bf tt}}}_{s,k} defined below that is computed in time polynomial in m𝑚m) and,\nin fact, Lemma 4.2 shows that non-uniformity of g𝑔g (i.e. g𝑔g is computed\nby a circuits that need not to come from a common algorithm)\nis to some extent irrelevant. The τ​(g)b𝜏subscript𝑔𝑏\\tau(g)_{b}-formulas were defined in \nmotivated by problems in bounded arithmetic\nand independently (and with an apparently different motivation)\nin Alekhnovich et al. . Unfortunately the authors of  did not pursue the topic222With the sole exception of  (although published in 2015 it was written in 2002/03). and\ndeveloping the theory was a rather lonely affair until recently.\nThe theory of proof complexity generators has now a number of facets and it is\nlinked\nnot only to bounded arithmetic and proof complexity but also to various topics in\ncomputational complexity theory. To give the reader an idea let us mention (just by\nkey words and phrases) some topics that have a non-trivial contact with the theory: lengths-of-proofs lower bounds, feasible interpolation, implicit proof systems, proof search, circuit complexity, the minimum circuit size problem, natural proofs, non-deterministic circuits, bounded arithmetic, Gödel’s incompleteness theorem, provability of upper and lower bounds,\nforcing with random variables, Nisan-Wigderson generators, structural complexity, 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} search problems, Kolmogorov complexity, learning theory, pseudo-randomness, one-way functions, indistinguishability obfuscation. A more detailed presentation of key points of the theory and of the necessary background\nrequires a text of a book-length but the interested reader may\nlook at [22, Sec.19.4-6] (or at older\n[19, Chpts.29-30]) for an overview and further references.\nThe introduction to Razborov’s  is an interesting presentation of\nhis ideas about the topic (including a formulation of a conjecture that stimulated some\nof my own work). Be it as it may, the theory as it is now\ngrew out of the motivation for the formulas in :\na logic question about the provability of the dual weak PHP principle (dWPHP) for p-time functions in a weak bounded arithmetic theory S21subscriptsuperscript𝑆12S^{1}_{2}, cf. [14, Problem 7.7].\nThe dWPHP​(f)dWPHP𝑓\\mbox{dWPHP}(f) says that function f𝑓f does not map any interval [0,a]0𝑎[0,a] onto [0,2​a]02𝑎[0,2a] (the term 2​a2𝑎2a can be altered\nto various other values, e.g. to a2superscript𝑎2a^{2} etc., without changing the logical strength of the principle over S21subscriptsuperscript𝑆12S^{1}_{2}). Denote the theory resulting from adding to S21subscriptsuperscript𝑆12S^{1}_{2} all instances\nof dWPHP​(f)dWPHP𝑓\\mbox{dWPHP}(f) for all (suitably defined) p-time functions f𝑓f by S21+dWPHP​(Δ1b)subscriptsuperscript𝑆12dWPHPsubscriptsuperscriptΔ𝑏1S^{1}_{2}+\\mbox{dWPHP}(\\Delta^{b}_{1}). The problem\n(cf. [14, Problem 7.7]) is: Is S21+dWPHP​(Δ1b)subscriptsuperscript𝑆12dWPHPsubscriptsuperscriptΔ𝑏1S^{1}_{2}+\\mbox{dWPHP}(\\Delta^{b}_{1}) equal to S21subscriptsuperscript𝑆12S^{1}_{2}?\nIf not, is it at least Σ1bsubscriptsuperscriptΣ𝑏1\\Sigma^{b}_{1}-conservative over it?\n This problem has a rather rich background and let me try to outline it in one paragraph.\nA task inherently difficult for bounded arithmetic (and for feasible algorithms) is to\ncount a number of elements of a finite set. It was discovered by A.Woods \nthat explicit counting may be replaced in many arguments\nin combinatorics or number theory by the pigeonhole\nprinciple PHP for bounded formulas, a statement that no bounded formula defines the graph\nof a function mapping [0,a+1]0𝑎1[0,a+1] injectively into [0,a]0𝑎[0,a]. It is still unknown whether this\nprinciple (denoted Δ0subscriptΔ0\\Delta_{0}-PHP) is provable in bounded arithmetic (the problem is due to\nMacIntyre). Then Paris, Wilkie and Woods  found out that the weak PHP\n(no bounded formula defines the graph of a function mapping [0,2​a]02𝑎[0,2a] injectively into [0,a]0𝑎[0,a]),\ndenoted Δ0subscriptΔ0\\Delta_{0}-WPHP, often suffices and that this principle is provable in\nbounded arithmetic (they used theory I​Δ0+Ω1𝐼subscriptΔ0subscriptΩ1I\\Delta_{0}+\\Omega_{1}, nowadays it is replaced\nby a more convenient Buss’s theory S2subscript𝑆2S_{2}). In a parallel development Buss\n defined a subtheory S21subscriptsuperscript𝑆12S^{1}_{2} of S2subscript𝑆2S_{2} and\nproved that functions with 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} graphs provably total in this\ntheory are exactly those that are p-time computable.\nA final twist before the formulation of our problem was\na theorem by A.Wilkie (unpublished but presented in [13, 7.3.7]) that functions with 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} graphs provably total in theory S21+dWPHP​(Δ1b)subscriptsuperscript𝑆12dWPHPsubscriptsuperscriptΔ𝑏1S^{1}_{2}+\\mbox{dWPHP}(\\Delta^{b}_{1}) are computable in randomized p-time.\nIt occurred to me that one may turn the table around and take the theory\nS21+dWPHP​(Δ1b)subscriptsuperscript𝑆12dWPHPsubscriptsuperscriptΔ𝑏1S^{1}_{2}+\\mbox{dWPHP}(\\Delta^{b}_{1}) as a basis for formalizing randomized algorithms\nand to establish its link with randomized p-time analogous to the link between S21subscriptsuperscript𝑆12S^{1}_{2} and\ndeterministic p-time.\nBecause randomized algorithms, and probabilistic constructions and arguments more generally,\nare ubiquitous in combinatorics and complexity theory I denoted in \nthe theory BT for ”basic theory”. The link was eventually established by Jeřábek\nin his PhD Thesis and in a subsequent series of papers  0 1 2.\nIn order not to interfere with his work I decided to focus on the provability/conservativity problem above and on the related propositional logic side of things, and this lead me to proof complexity generators. Right from the beginning there were two working conjectures: There are generators pseudo-surjective\nfor Extended Frege systems EF, cf. [14, Conj.7.9, Cor.7.10],[15, Conj.4.1,Cor.4.2]. This conjecture is related to the provability problem mentioned above\nand the notion of pseudo-surjectivity implies the hardness as defined earlier.\nWe shall touch upon it in Section 2, the reader can find details\nin 5 6. There is a generator hard for all proof systems, cf. [16, Sec.2]. We shall concentrate here on the second conjecture and we shall restrict our formulation to uniform generators (i.e. computed by algorithms not just by sequences of circuits)\nhaving the minimal required stretch m​(n)=n+1𝑚𝑛𝑛1m(n)=n+1.\nIt is easy to see that\ntruncating any p-time generator to output-size n+1𝑛1n+1 preserves the hardness over any pps simulating resolution (e.g. such a truncation can be applied to generators tts,ksubscripttt𝑠𝑘{\\mbox{{\\bf tt}}}_{s,k}\nand Utsuperscript𝑈𝑡U^{t} defined later).\nIt also allows for a particularly simple formulation of Conjecture 1.1:\nby [16, Sec.1] (or [22, L.19.4.1])\nthe second conjecture can be then restated without any reference\nto proof complexity notions as follows. There exists a p-time function g𝑔g stretching each input by one bit such that its range r​n​g​(g)𝑟𝑛𝑔𝑔rng(g)\nintersects all infinite 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} sets. That is, the complement of r​n​g​(g)𝑟𝑛𝑔𝑔rng(g) is 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P}-immune. A fundamental question of proof complexity is, in my view, whether the hardness of proving\na tautology can be traced back to the hardness of computing some computational task associated with the formula. A paradigm of such a reduction is the method of feasible interpolation that applies to a wide range of proof systems albeit not to strong ones (cf. [22, Chpts.17 and 18]). One can interpret Conjecture 1.1 as stating\na reduction of provability hardness to computational hardness for all proof systems in\nthe following sense: short proofs, here witnesses to the membership in an infinite 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} set A𝐴A, imply an upper bound on compression for some strings in A𝐴A, using g𝑔g as the decompressing algorithm. With a bit of imagination a direct parallel between the conjecture and\nfeasible interpolation may be seen when we restrict the conjecture.\nThe conjecture can be equivalently stated as asserting that all 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} sets disjoint\nwith r​n​g​(g)𝑟𝑛𝑔𝑔rng(g) are finite. A restriction of the conjecture may state the finiteness\njust for a subclass of all 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} sets.\nA natural restriction of Conjecture 1.1 in this sense,\ngiven a specific proof system P𝑃P, is the restriction to 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} sets A𝐴A\nfrom the class of those sets for which P𝑃P can prove in polynomial size\n(the tautologies expressing for all lengths n≥1𝑛1n\\geq 1) that A∩r​n​g​(g)=∅𝐴𝑟𝑛𝑔𝑔A\\cap rng(g)=\\emptyset.\nThis class of 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} set is the resultant R​e​sgP𝑅𝑒subscriptsuperscript𝑠𝑃𝑔Res^{P}_{g} of 6 and the reader\ncan find details there. Conjecture 1.1 restricted to P𝑃P\nthen says that R​e​sgP𝑅𝑒subscriptsuperscript𝑠𝑃𝑔Res^{P}_{g} contains only finite sets. This looks in form similar to\nfeasible interpolation: there we deduce feasible separability of two 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} sets\nwhose disjointness can be proved efficiently in P𝑃P, here we deduce the finiteness of\nan 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} set if it can be proved efficiently in P𝑃P that it is disjoint from a\nparticular 𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} set, namely r​n​g​(g)𝑟𝑛𝑔𝑔rng(g).\nNote also that the conjecture restricted to P𝑃P implies that\nP𝑃P is not p-bounded. Let us give two examples of potential generators (a third one will be discussed in\nSec. 4).\nAn illuminating example of a possibly strong generator is the truth-table function tts,ksubscripttt𝑠𝑘{\\mbox{{\\bf tt}}}_{s,k}\nsending a size s𝑠s circuit in k𝑘k inputs to its truth-table (a size 2ksuperscript2𝑘2^{k}\nstring), cf. 6 or [22, 19.5].\nCircuits of size s𝑠s can be coded by 10​s​log⁡s10𝑠𝑠10s\\log s bits and so to make the function\nstretching we assume that n:=10​s​log⁡s<m​(n):=2kassign𝑛10𝑠𝑠𝑚𝑛assignsuperscript2𝑘n:=10s\\log s<m(n):=2^{k}\n(hence size s𝑠s circuits are coded by n<m𝑛𝑚n<m bits). It is computed in (uniform) time\nO​(s​m)=2O​(k)𝑂𝑠𝑚superscript2𝑂𝑘O(sm)=2^{O(k)}, so it is p-time if s=2Ω​(k)𝑠superscript2Ω𝑘s=2^{\\Omega(k)}. The τ𝜏\\tau-formulas determined by this generator\nstate circuit lower bounds for particular Boolean functions: τ​(tts,k)b∈TAUT𝜏subscriptsubscripttt𝑠𝑘𝑏TAUT\\tau({\\mbox{{\\bf tt}}}_{s,k})_{b}\\in\\mbox{TAUT} iff\nthe function with truth-table b𝑏b has circuit complexity bigger than s𝑠s.\nThis makes the formulas attractive but also hard to approach as we\nknow very little about the size of general circuits. It is known that the first working conjecture\nabove implies that the τ𝜏\\tau-formulas determined by the truth table function\ntts,ksubscripttt𝑠𝑘{\\mbox{{\\bf tt}}}_{s,k} (with s=2ϵ​k𝑠superscript2italic-ϵ𝑘s=2^{\\epsilon k} for any 0<ϵ<10italic-ϵ10<\\epsilon<1)\nare hard for EF, cf. 6 or [19, Sec.30.1].\nOn the other hand,\nunless 𝒩​ℰ∩c​o​𝒩​ℰ𝒩ℰ𝑐𝑜𝒩ℰ{\\cal N}{\\cal E}\\cap co{\\cal N}{\\cal E} has size s​(k)𝑠𝑘s(k) circuits, the generator tts,ksubscripttt𝑠𝑘{\\mbox{{\\bf tt}}}_{s,k}\ncannot be hard for all proof systems333But to find a pps for which it is not hard\nwith any super-polynomial s​(k)𝑠𝑘s(k) is likely to be a hard task itself,\ncf. [19, L.29.2.2].\nand hence it is not a good candidate for Conjecture 1.1, cf. [19, p.198]. Our second example follows [24, Remark 6.1] and concerns time-bounded Kolmogorov complexity.\nRecall that the complexity measure Kt​(w)superscript𝐾𝑡𝑤K^{t}(w) is the minimal size of a program that\nprints w𝑤w in time at most t​(|w|)𝑡𝑤t(|w|), cf. Allender .\nThe point is that a proof complexity generator\nwith stretch m≥n+ω​(1)𝑚𝑛𝜔1m\\geq n+\\omega(1) produces strings w𝑤w of Ktsuperscript𝐾𝑡K^{t} complexity smaller than\nm=|w|𝑚𝑤m=|w|.\nFor example, if g𝑔g stretches n𝑛n bits to m=2​n𝑚2𝑛m=2n bits and runs in p-time t​(2​n)𝑡2𝑛t(2n)\nthen for all size m𝑚m strings w∈r​n​g​(gn)𝑤𝑟𝑛𝑔subscript𝑔𝑛w\\in rng(g_{n}) and n>>0much-greater-than𝑛0n>>0: In fact, as discussed in [24, 6.1],\nfor a fixed polynomial time t​(n)𝑡𝑛t(n) sufficient for the computation of g𝑔g\none can consider the universal Turing machine Utsuperscript𝑈𝑡U^{t} underlying the definition\nof Ktsuperscript𝐾𝑡K^{t} as a generator itself444A similar observation was made recently\nin Ren, Santhanam and Wang 9.. Then\nfor any pps P𝑃P simulating EF, if some τ​(Ut)𝜏superscript𝑈𝑡\\tau(U^{t})-formulas\nhave short P𝑃P-proofs\n(e.g. by proving tautologies expressing the lower bound\nKt​(w)≥2​m/3superscript𝐾𝑡𝑤2𝑚3K^{t}(w)\\geq 2m/3),\nso do some τ​(g)𝜏𝑔\\tau(g)-formulas. That is, if there is any\ng𝑔g computable in time t𝑡t and hard for P𝑃P then Utsuperscript𝑈𝑡U^{t} must be hard as well. The paper is organized as follows.\nIn Section 2 we consider the possibility of disproving\n(or at least of limiting possible g𝑔g in) Conjecture 1.1 by finding a feasible\nway to witness that the complement of r​n​g​(g)𝑟𝑛𝑔𝑔rng(g) is not empty. In Section 3 we discuss a\nnew definition of hardness, the ⋁\\bigvee-hardness, that strengthens (presumably) the hardness as defined above (but is weaker, also presumably, than\nthe notion of pseudo-surjectivity mentioned earlier).\nThe reason for introducing the new notion is that a particular generator from the class of\ngadget generators introduced in 8\nand recalled here in Section 4\nis the ⋁\\bigvee-hardest555Ren, Santhanam and Wang\n9 speak informally about the hardest proof complexity generator\nbut what they define is formally an infinite family of generators.\namong all generators but (presumably) not the hardest under\nthe definition of the hardness as given above: in 8\nwe used for this result the notion of iterability that\nis in strength between hardness and pseudosurjectivity mentioned in Section\n2,\nas it was at hand but that is not good for Conjecture 1.1.\nNamely, it is known (cf. 6) that if there is any iterable map for a given pps (containing resolution) then tts,ksubscripttt𝑠𝑘{\\mbox{{\\bf tt}}}_{s,k} is iterable for it\ntoo and hence hard. But by the remark above tts,ksubscripttt𝑠𝑘{\\mbox{{\\bf tt}}}_{s,k}\nis unlikely to be hard for all proof systems. This new notion of ⋁\\bigvee-hardness\nis equivalent to the hardness as defined above\nfor a class of pps satisfying the strong feasible disjunction property (Section 3). This class\nhas the property that all pps not in it are automatically not p-bounded. Section 2 is complemented\nin Section 5 where we link possible limitations to the stretch g𝑔g can have\nto the task of proving lower bounds on time-bounded Kolmogorov complexity.\nWe argue that known results imply that these approaches are not\nlikely to work without proving first super-polynomial lower bounds\nfor (uniform and non-uniform) computations. We also indicate in Section 6 how to modify the notion of a generator (and the conjecture and results in\nSections 2 and 5)\nto address the hardness of proof search instead of lengths-of-proofs. In Section 7 we discuss a way how to restrict Conjecture 1.1 and\nwe show, under a hypothesis, that the conjecture holds relative to all feasibly infinite\n𝒩​𝒫𝒩𝒫{\\cal N}{\\cal P} sets: sets for which there is a p-time function picking arbitrarily large elements of the set.\nThe paper is concluded by some remarks in Section 8. Basic proof complexity background can be found in [22, Chpt.1], the topic of hard formulas\n(including a brief introduction to the theory of proof complexity generators) is in [22, Chpt.19].\nWhen we use some proof complexity notions and facts in a formal statement we define them first (and give a reference). But\nwe also use proof complexity background in various informal remarks and there we only\nrefer to the original source and/or to\na place in 2 where it can be found.\n\nReference markers found: [5]\n\nContext windows for each [ref]:\n[ref]5: A propositional proof system\n(to be abbreviated pps) in the sense of Cook and Reckhow [ref]5\nis a polynomial time (p-time, shortly) binary relation P​(x,y)𝑃𝑥𝑦P(x,y) such that ∃x​P​(x,y)𝑥𝑃𝑥𝑦\\exists xP(x,y) defines exactly TAUT, the\nset of propositional tautologies (in the DeMorgan\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 5,\n            \"titles\": [\n                \"Failure of Feasible Disjunction Property for 𝑘-DNF Resolution and NP-hardness of Automating It\",\n                \"Pseudorandom generators in propositional proof complexity\",\n                \"Applications of Time-Bounded Kolmogorov Complexity in Complexity Theory\",\n                \"Bounded Arithmetic\",\n                \"An application of boolean complexity to separation problems in bounded arithmetic\",\n                \"The relative efficiency of propositional proof systems\",\n                \"Unexpected Hardness Results for Kolmogorov Complexity Under Uniform Reductions\",\n                \"Indistinguishability Obfuscation, Range Avoidance, and Bounded Arithmetic\",\n                \"Weak pigeonhole principle, and randomized computation\",\n                \"Dual weak pigeonhole principle, Boolean complexity, and derandomization\",\n                \"Approximate counting in bounded arithmetic\",\n                \"Approximate counting by hashing in bounded arithmetic\",\n                \"Bounded arithmetic, propositional logic, and complexity theory\",\n                \"On the weak pigeonhole principle\",\n                \"Tautologies from pseudo-random generators\",\n                \"Dual weak pigeonhole principle, pseudo-surjective functions, and provability of circuit lower bounds\",\n                \"Diagonalization in proof complexity\",\n                \"A proof complexity generator\",\n                \"Forcing with random variables and proof complexity\",\n                \"On the proof complexity of the Nisan-Wigderson generator based on a hard NP∩coNP function\",\n                \"On the computational complexity of finding hard tautologies\",\n                \"Proof complexity\",\n                \"Small circuits and dual weak PHP in the universal theory of p-time algorithms\",\n                \"Information in propositional proofs and algorithmic proof search\",\n                \"Interactive Computations of Optimal Solutions\",\n                \"Bounded arithmetic and the polynomial hierarchy\",\n                \"Provability of the Pigeonhole Principle and the Existence of Infinitely Many Primes\",\n                \"Pseudorandom generators hard for k𝑘k-DNF resolution polynomial calculus resolution\",\n                \"On the Range Avoidance Problem for Circuits\",\n                \"Introduction to the Theory of Computation\",\n                \"Some problems in logic and number theory, and their connections\",\n                \"Generated Reference Title 31 for [ref]5\",\n                \"Generated Reference Title 32 for [ref]5\",\n                \"Generated Reference Title 33 for [ref]5\",\n                \"Generated Reference Title 34 for [ref]5\",\n                \"Generated Reference Title 35 for [ref]5\",\n                \"Generated Reference Title 36 for [ref]5\",\n                \"Generated Reference Title 37 for [ref]5\",\n                \"Generated Reference Title 38 for [ref]5\",\n                \"Generated Reference Title 39 for [ref]5\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]5 based on the context and research area of On the existence of strong proof complexity generators. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}