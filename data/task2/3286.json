{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: An Adaptive Neuro-Fuzzy System with Integrated Feature Selection and Rule Extraction for High-Dimensional Classification Problems\n\nPaper Abstract: \n\nPaper Section Text:\nFuzzy systems have been successfully applied in many areas, such as control engineering     and pattern recognition     [ref]9 0. Takagi-Sugeno-Kang (TSK) fuzzy systems  , one of two classical fuzzy systems (the other one is Mamdani-Assilian (MA) fuzzy system ), have powerful ability to model nonlinear problems. To overcome the difficulties in identifying the fuzzy rules, various neural networks have been proposed based on their promising learning performance 1    [ref]9 0. As a consequence, back-propagation algorithm 2 has become a popular scheme to optimize TSK fuzzy systems. The computation of the firing strength of fuzzy rules is a necessary and important operation in fuzzy reasoning. The firing strength can be computed using any T-norm 3. In 4, two kinds of T-norms have been used which include minimum  and product 0 [ref]9  5. The product T-norm is differentiable and frequently used for solving low-dimensional problems. Since minimum is not differentiable, it is rarely considered when using gradient based algorithm for learning parameters of fuzzy systems. To remedy this drawback, different softer versions of minimum called softmin have been employed  6  although strictly speaking they are not T-norms. The softmin is differentiable and can be a good approximator to minimum. In 6, the authors adopted the product and softmin to compute the firing strength, separately. The simulation results revealed that these two T-norm based systems performed similarly on four regression datasets. For high-dimensional problem, one can easily deduce that the firing strength computed by the product T-norm would reduce almost to zero even when each antecedent component has a high membership value. Sometimes, this phenomenon is called ‚Äúnumeric underflow‚Äù 0, which means that the firing strength is too small to be correctly represented and used by the machine. The softmin is also prone to suffering from the same obstacle, ‚Äúnumeric underflow‚Äù. It also has another problem, which may be called as ‚Äúfake minimum‚Äù when the parameter of the softmin is not properly set. Thus, it is very important to investigate how we can design a novel adaptive version of softmin which can avoid these shortcomings to deal with high-dimensional problems. For solving high-dimensional classification problems, feature selection is of significant necessity because when the input dimension is high, it is very likely that the input feature set contains redundant and derogatory features, which are expected to negatively affect the final performance 7. In addition to improving the system performance, feature selection can also simplify the complexity, lower the computational cost, and enhance the interpretability of the system. Generally, feature selection methods are classified into three groups: filter methods 8, wrapper methods 9 0 1, and embedded methods  . A filter method selects features according to an evaluation criteria such as mutual information or correlation which is independent of the classifier or predictor, that will finally use these features. Although, filter methods are efficient in computation, they may result in unsatisfactory results because they ignore the feedback of the model 2 as well as the interaction between features. A wrapper method considers different feature subsets and then evaluates the goodness of them using classification or prediction accuracy. This results in good performance but costs more computational resource 3. Moreover, to get the best subset, we need evaluate all possible subsets of features, which is not feasible for high-dimensional datasets. An embedded method  has gradually been an attractive research topic. It simultaneously performs the feature selection and evaluation of the model and consequently, it promotes the effectiveness and reduces the computational burden. Additionally, some hybrid methods 4 5 which utilize two of these three feature selection approaches together have also been investigated. In 4, the Partial Mutual Information based filter approach was coupled with a firefly algorithm based wrapper method to deal with short-term load forecasting problem. And in 5, one hybrid wrapper-embedded feature selection method was proposed combining genetic algorithm and the embedded regularization approach. Basically, there are four kinds of features 6: essential features, redundant features, derogatory or bad features, and indifferent features. Essential features are of great importance to reach competitive performance, while derogatory or bad features have adverse effects. Indifferent features have neither positive nor negative influence on the tasks, and as for redundant features, they are useful but not all of them are needed. Feature selection method should select essential features, discard bad and indifferent features, and control the use of redundant features 7. In  and 7, features are selected using a fuzzy rule based framework and neural networks, respectively, and both of these works considered controlling the level of redundancy among selected features. In  and 8, the authors did not take into consideration redundant features and got comparable results as well. In 8, an unsupervised spectral feature selection method was designed by combining a kernel with a specific spectrum based on a feature evaluation metric. Compared with other filter methods, the experimental results demonstrated promising performance. Kabir et al. 1 integrated a wrapper approach into neural networks which automatically determined the architecture of the network model during the feature selection process. An embedded feature selection method was proposed in 8 7, which added the group lasso regularization to the loss function of neural networks to select useful features simultaneously with the training of the network. In   6 and 6, feature modulators were designed and used to modify the membership values in antecedent parts of fuzzy rules for feature selection. Note that the feature modulator was introduced as gate function in 6 which modified both antecedent and consequent parts, and finally picked up the required features. Actually, there are three commonly used gate functions to measure the magnitude of feature‚Äôs importance, 1‚àíe‚àíŒª21superscriptùëísuperscriptùúÜ21-e^{-\\lambda^{2}} ( ), 11+e‚àíŒª11superscriptùëíùúÜ\\frac{1}{1+e^{-\\lambda}} and e‚àíŒª2superscriptùëísuperscriptùúÜ2e^{-\\lambda^{2}} ( 7 ), where ŒªùúÜ\\lambda is the tuneable gate parameter. In the existing works, the gate values (the values of gate function) are generally initialized around zeros, and the corresponding derivatives are close to zeros as well. This leads to more training iterations to open the gates during feature selection. Thus, designing of a suitable gate function to overcome this drawback is another interesting task. How to generate or extract desirable fuzzy rules is an important part in constructing a fuzzy system. A variety of approaches have been introduced, such as heuristic approaches 9 0, genetic algorithms 1 2 3, and neuro-fuzzy techniques  6. In 9, an efficient method was proposed to extract fuzzy rules directly from input data through activation and inhibition hyperboxes. Ishibuchi et al. 0 used a distributed representation of fuzzy rules for classification of patterns. This approach used multiple fuzzy partitions simultaneously to generate rules for classification. The advantage of this method is that it does not need any iterative computations and complex procedures. In 2, Ishibuchi and Yamamoto proposed a two-phase method to select a small number of simple rules. In phase I, the candidate rules were generated using two metrics (confidence and support) and in phase II, the appropriate fuzzy rules were selected by a multi-objective genetic local search algorithm. In a neuro-fuzzy framework , all possible fuzzy rules were initially employed but after the training only an adequate set of rules involving a set of selected features was retained. Depending on the method of extraction, fuzzy rule bases can be divided into two categories, compactly combined fuzzy rule base (CoCo-FRB) and fully combined fuzzy rule base (FuCo-FRB). After the feature space is clustered or partitioned, CoCo-FRB converts each cluster into one fuzzy rule, in other words, the number of rules is equal to the number of clusters. While FuCo-FRB considers all possible rules. Here on the domain of each feature, a number of linguistic values are defined and all possible valid combinations that can define rules are considered. Hence, the number of rules in FuCo-FRB exponentially increases with the dimension. It is still a challenging task to address the issue of exponential increase in the number of rules when one employs FuCo-FRB especially for high-dimensional dataset. In [ref]9, a promising scheme was proposed to effectively address this problem. It first used principle component analysis (PCA) to reduce the original dimension to 555 and then the rule base was initialized to FuCo-FRB. Inspired by DropOut 4 and DropConnect 5, the so-called DropRule strategy was adopted in each iteration which randomly discarded the rules based on the drop rate. The simulation results demonstrate the superiority over its counterparts. Unfortunately, this scheme inevitably affect the interpretability of the constructed system. In this paper, we focus on TSK neuro-fuzzy systems to deal with high-dimensional classification problems. We introduce an adjustable-parameter-based softmin to compute the firing strength. Additionally, we propose a gate function to realize feature selection and rule extraction. As a result, we obtain a comprehensive feature selection and rule extraction-based system, that we call FSRE-AdaTSK. FSRE-AdaTSK consists of three sequential phases: (i) feature selection, (ii) rule extraction, and (iii) fine tuning. The main contributions in this work are summarized as follows: An adaptive softmin called as Ada-softmin is proposed whose index parameter is adjusted on the basis of current membership values. For every rule and every data point, depending on the present membership values of the antecedent clauses, the parameter of the Ada-softmin changes. It is adopted to compute the firing strength in the TSK fuzzy system which effectively avoids the two typical problems: ‚Äúnumeric underflow‚Äù and ‚Äúfake minimum‚Äù. An adaptive TSK (AdaTSK) neuro-fuzzy system is then derived which possesses the ability to deal with high-dimensional data. Inspired by the existing gate functions    7 , a novel gate function is designed. When the gate values are initialized around zeros, the derivatives of the proposed gate function are much greater than those of the existing ones. This enables the proposed TSK neuro-fuzzy system to efficiently accomplish the feature selection task. Based on CoCo-FRB, we obtain an enhanced fuzzy rule base (En-FRB). It collects more fuzzy rules than CoCo-FRB and avoids the exponential increase in the number of rules caused by FuCo-FRB. Finally, for the constructed En-FRB, we propose an efficient embedded rule extraction method using the above presented gate function. This results in a neuro-fuzzy classifier that can deal with even datasets having dimension greater than 7000. The proposed framework can be easily adapted to fuzzy rule based systems. The rest of this article is organized as follows. CoCo-FRB based TSK fuzzzy system is reviewed and the AdaTSK method is introduced in the next section. Section III elaborates the details of the proposed FSRE-AdaTSK system. Section IV demonstrates the effectiveness of the approach proposed in this paper. In Section V, our conclusions are provided and possible future research directions are also discussed.\n\nReference markers found: [9]\n\nContext windows for each [ref]:\n[ref]9: Fuzzy systems have been successfully applied in many areas, such as control engineering     and pattern recognition     [ref]9 0. Takagi-Sugeno-Kang (TSK) fuzzy systems  , one of two classical fuzzy systems (the other one is Mamdani-Assilian (MA) fuzzy system ), have powerful ability to model nonlinear problems. To\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 9,\n            \"titles\": [\n                \"Optimize TSK Fuzzy Systems for Classification Problems: Mini-Batch Gradient Descent with Uniform Regularization and Batch Normalization\",\n                \"An experiment in linguistic synthesis with a fuzzy logic controller\",\n                \"Fuzzy identification of systems and its applications to modeling and control\",\n                \"Fuzzy modelling and control of multilayer incinerator\",\n                \"Integrated feature analysis and fuzzy rule-based system identification in a neuro-fuzzy paradigm\",\n                \"A neuro-fuzzy scheme for simultaneous feature selection and fuzzy rule-based classification\",\n                \"An integrated mechanism for feature selection and fuzzy rule extraction for classification\",\n                \"Feature selection with controlled redundancy in a fuzzy rule based framework\",\n                \"Conjugate gradient-based takagi-sugeno fuzzy neural network parameter identification and its convergence analysis\",\n                \"Optimize TSK Fuzzy Systems for Regression Problems: Minibatch Gradient Descent With Regularization, DropRule, and AdaBound (MBGD-RDA)\",\n                \"On fuzzy modeling using fuzzy neural networks with the back-propagation algorithm\",\n                \"Learning representations by back-propagating errors\",\n                \"Fuzzy sets and fuzzy logic - theory and applications\",\n                \"Pictorial representations of fuzzy connectives, part I: Cases of t-norms, t-conorms and averaging operators\",\n                \"Fast training of adversarial deep fuzzy classifier by downsizing fuzzy rules with gradient guided learning\",\n                \"Simultaneous structure identification and fuzzy rule generation for takagi-sugeno models\",\n                \"Feature selection using a neural network with group lasso regularization and controlled redundancy\",\n                \"A new unsupervised spectral feature selection method for mixed data: A filter approach\",\n                \"Wrappers for feature subset selection\",\n                \"A wrapper method for feature selection using support vector machines\",\n                \"A new wrapper feature selection approach using neural network\",\n                \"Hybrid feature selection by combining filters and wrappers\",\n                \"An ensemble feature selection method for short-term electrical load forecasting\",\n                \"Hybrid filter-wrapper feature selection for short-term load forecasting\",\n                \"A hybrid genetic algorithm with wrapper-embedded approaches for feature selection\",\n                \"Selecting useful groups of features in a connectionist framework\",\n                \"Feature selection using a neural framework with controlled redundancy\",\n                \"Feature selection for neural networks using group lasso regularization\",\n                \"A method for fuzzy rules extraction directly from numerical data and its application to pattern classification\",\n                \"Distributed representation of fuzzy rules and its application to pattern classification\",\n                \"Selecting fuzzy if-then rules for classification problems using genetic algorithms\",\n                \"Fuzzy rule selection by multi-objective genetic local search algorithms and rule evaluation measures in data mining\",\n                \"Fuzzy data mining by heuristic rule extraction and multiobjective genetic rule selection\",\n                \"Dropout: A simple way to prevent neural networks from overfitting\",\n                \"Regularization of neural networks using dropconnect\",\n                \"Fuzzy broad learning system: A novel neuro-fuzzy model for regression and classification\",\n                \"A Novel Deep Fuzzy Classifier by Stacking Adversarial Interpretable TSK Fuzzy Sub-Classifiers With Smooth Gradient Information\",\n                \"Back-propagation fuzzy system as nonlinear dynamic system identifiers\",\n                \"Practical recommendations for gradient-based training of deep architectures\",\n                \"Fuzzy logic approaches to structure preserving dimensionality reduction\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]9 based on the context and research area of An Adaptive Neuro-Fuzzy System with Integrated Feature Selection and Rule Extraction for High-Dimensional Classification Problems. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}