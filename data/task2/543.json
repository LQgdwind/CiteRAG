{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Approximation of the Diagonal of a Laplacian’s Pseudoinverse for Complex Network Analysis\n\nPaper Abstract: \n\nPaper Section Text:\nMassive graph data sets are abundant these days in numerous applications.\nExtracting knowledge from these data thus requires fast algorithms.\nOne common matrix to represent a graph G=(V,E)𝐺𝑉𝐸G=(V,E) with n𝑛n vertices and m𝑚m edges\nin algebraic algorithms is its Laplacian 𝐋=𝐃−𝐀𝐋𝐃𝐀\\mathbf{L}=\\mathbf{D}-\\mathbf{A}.\nHere, 𝐃𝐃\\mathbf{D} is the diagonal degree matrix with 𝐃​[u,u]𝐃𝑢𝑢\\mathbf{D}[u,u] being the (possibly weighted) degree of vertex\nu∈V𝑢𝑉u\\in V.\nThe matrix 𝐀𝐀\\mathbf{A} is the (possibly weighted) adjacency matrix of G𝐺G.\nIt is well-known that 𝐋𝐋\\mathbf{L} does not have full rank and is thus not invertible.\nIts Moore-Penrose pseudoinverse  𝐋†superscript𝐋†\\mathbf{L}^{\\dagger}, in turn, has numerous\napplications in physics and engineering  as well as applied mathematics \nand graph (resp. matrix) algorithms [ref]40. We are motivated by one particular class of applications:\nelectrical centrality measures\nfor the analysis of small-world networks – i. e., graphs whose diameter is bounded by 𝒪​(log⁡n)𝒪𝑛\\mathcal{O}(\\log n).\nMany important real-world networks (social, epidemiological,\ninformation, biological, etc.) have the small-world feature .\nCentrality measures, in turn, belong to the most widely used network analysis concepts\nand indicate the importance of a vertex (or edge) in the network .\nNumerous measures exist, some based on shortest paths, others consider paths of arbitrary\nlengths. Electrical centrality measures fall into the latter category.\nThey exploit the perspective of graphs as electrical networks (see e. g., ).\nOne well-known of such measures is\nelectrical closeness centrality, a. k. a. current-flow closeness or information centrality , ce​l​(⋅)superscript𝑐𝑒𝑙⋅c^{el}(\\cdot).\nIt is the reciprocal of the average effective resistance 𝐫​(u,⋅)𝐫𝑢⋅\\mathbf{r}(u,\\cdot) between u𝑢u and all other vertices: In an electrical network corresponding to G𝐺G, 𝐫​(u,v)𝐫𝑢𝑣\\mathbf{r}(u,v) is the potential (voltage) difference\nacross terminals u𝑢u and v𝑣v when a unit current is applied between them .\nIt can be computed by solving 𝐋𝐱=𝐞u−𝐞v𝐋𝐱subscript𝐞𝑢subscript𝐞𝑣\\mathbf{L}\\mathbf{x}=\\mathbf{e}_{u}-\\mathbf{e}_{v} for 𝐱𝐱\\mathbf{x},\nwhere 𝐞zsubscript𝐞𝑧\\mathbf{e}_{z} is the canonical unit vector for vertex z𝑧z. Then, 𝐫​(u,v)=𝐱​[u]−𝐱​[v]𝐫𝑢𝑣𝐱delimited-[]𝑢𝐱delimited-[]𝑣\\mathbf{r}(u,v)=\\mathbf{x}[u]-\\mathbf{x}[v],\nalso see Section 2.1. Effective resistance also plays a major role in two other electrical measures we consider here,\nnormalized random-walk betweenness  and Kirchhoff index centrality .\nAlso note that effective resistance is a graph metric with numerous other applications, well beyond its usage\nin electrical centralities (cf. Refs.  ).\nA straightforward way to compute electrical closeness (or the other two measures) would be to compute 𝐋†superscript𝐋†\\mathbf{L}^{\\dagger}.\nWithout exploiting structure, this takes 𝒪​(nω)𝒪superscript𝑛𝜔\\mathcal{O}(n^{\\omega}) time,\nwhere ω<2.38𝜔2.38\\omega<2.38 is the exponent for fast matrix multiplication.\nThe standard tools in practice even require cubic time, cf. .\n𝐋†superscript𝐋†\\mathbf{L}^{\\dagger} is also in general a dense matrix (also for sparse 𝐋𝐋\\mathbf{L}).\nThus, full (pseudo)inversion is clearly limited to small inputs. Conceptually similar to inversion would be to solve Θ​(n)Θ𝑛\\Theta(n) Laplacian linear systems.\nIn situations with lower accuracy demands, fewer linear systems suffice:\nusing the Johnson-Lindenstrauss transform (JLT) in connection with a fast\nLaplacian solver such as Ref. 1,\none gets a relative approximation guarantee by solving 𝒪​(log⁡n/ϵ2)𝒪𝑛superscriptitalic-ϵ2\\mathcal{O}(\\log n/\\epsilon^{2}) systems \nin 𝒪~​(m​log1/2⁡n​log⁡(1/ϵ))~𝒪𝑚superscript12𝑛1italic-ϵ\\tilde{\\mathcal{O}}(m\\log^{1/2}n\\log(1/\\epsilon)) time each,\nwhere 𝒪~​(⋅)~𝒪⋅\\tilde{\\mathcal{O}}(\\cdot) hides a\n𝒪​((log⁡log⁡n)3+δ)𝒪superscript𝑛3𝛿\\mathcal{O}((\\log\\log n)^{3+\\delta}) factor for δ>0𝛿0\\delta>0. As pointed out previously , the (only) relevant part of 𝐋†superscript𝐋†\\mathbf{L}^{\\dagger}\nfor computing electrical closeness is its diagonal (we will see that this is true for other\nmeasures as well). Numerical methods for sampling-based approximation of the diagonal of implicitly\ngiven matrices do exist [ref]9. Yet, for our purpose, they solve\n𝒪​(log⁡n/ϵ2)𝒪𝑛superscriptitalic-ϵ2\\mathcal{O}(\\log{n}/\\epsilon^{2}) Laplacian linear systems as well\nto obtain an ϵitalic-ϵ\\epsilon-approximation with high probability, see Section 2.2 for more details. While this number of Laplacian linear systems can be\nsolved in parallel, their solution can still be time-consuming in practice, in part due to high constants hidden in the 𝒪𝒪\\mathcal{O}-notation. We propose a new algorithm for approximating diag⁡(𝐋†)diagsuperscript𝐋†\\operatorname{diag}(\\mathbf{L}^{\\dagger}) of\na Laplacian matrix 𝐋𝐋\\mathbf{L} that corresponds to weighted undirected graphs (Section 3).\nOur main technique is the approximation of effective resistances between\na pivot vertex u∈V𝑢𝑉u\\in V and all other vertices of G𝐺G. It is based on sampling uniform (= random) spanning\ntrees (USTs). The resulting algorithm is highly parallel and (almost)\npurely combinatorial – it relies on the connection between Laplacian linear systems, effective resistances, and USTs. For small-world graphs, our algorithm obtains an absolute ±ϵplus-or-minusitalic-ϵ\\pm\\epsilon-approximation guarantee\nwith high probability\nin (sequential) time 𝒪​(m​log4⁡n⋅ϵ−2)𝒪𝑚superscript4⋅𝑛superscriptitalic-ϵ2\\mathcal{O}(m\\log^{4}n\\cdot\\epsilon^{-2}).\nIn particular, compared to using the fastest theoretical Laplacian solvers\nin connection with JLT, our approach is off by only a polylogarithmic factor.\nProbably more importantly, after some algorithm\nengineering (Section 4), our algorithm performs\nmuch better than the state of the art, already in our sequential experiments (Section 5):\n(i) it is much faster and more memory-efficient,\n(ii) it yields a maximum absolute error that is one order\nof magnitude lower, and (iii) results in a more accurate complete\ncentrality ranking of elements of diag⁡(𝐋†)diagsuperscript𝐋†\\operatorname{diag}(\\mathbf{L}^{\\dagger}).\nDue to good parallel speedups, we can even compute a reasonably accurate diagonal of 𝐋†superscript𝐋†\\mathbf{L}^{\\dagger}\non a small-scale cluster with 16 compute nodes in less than 8 minutes for a graph with ≈13.6absent13.6\\approx 13.6M vertices\nand ≈334.6absent334.6\\approx 334.6M edges.\nMaterial omitted from the main part can be found in\nthe appendix.\n\nReference markers found: [40]\n\nContext windows for each [ref]:\n[ref]40: Moore-Penrose pseudoinverse  𝐋†superscript𝐋†\\mathbf{L}^{\\dagger}, in turn, has numerous\napplications in physics and engineering  as well as applied mathematics \nand graph (resp. matrix) algorithms [ref]40. We are motivated by one particular class of applications:\nelectrical centrality measures\nfor the analysis of small-world networks – i. e., graphs whose diameter is bounded by\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 40,\n            \"titles\": [\n                \"Kirchhoff Index As a Measure of Edge Centrality in Weighted Networks: Nearly Linear Time Algorithms\",\n                \"The random walk construction of uniform spanning trees and uniform labelled trees\",\n                \"Graph Clustering using Effective Resistance\",\n                \"Parallel computation of entries of a-1-1{}^{\\\\mbox{-1}}\",\n                \"Approximation of the diagonal of a laplacian’s pseudoinverse for complex network analysis, 2020\",\n                \"Guidelines for experimental algorithmics: A case study in network analysis\",\n                \"Randomized algorithms for estimating the trace of an implicit symmetric positive semi-definite matrix\",\n                \"On the architectural requirements for efficient execution of graph algorithms\",\n                \"Estimating the inverse trace using random forests on graphs, 2019\",\n                \"An estimator for the diagonal of a matrix\",\n                \"Computing top-𝑘 Closeness Centrality Faster in Unweighted Graphs\",\n                \"Estimating Current-Flow Closeness Centrality with a Multigrid Laplacian Solver\",\n                \"Near linear-work parallel sdd solvers, low-diameter decomposition, and low-stretch subgraphs, 2011\",\n                \"Axioms for centrality\",\n                \"Modern Graph Theory, volume 184 of Graduate Texts in Mathematics\",\n                \"Approximations of the generalized inverse of the graph laplacian matrix\",\n                \"Resistance distance, closeness, and betweenness\",\n                \"Centrality measures based on current flow\",\n                \"Generating random spanning trees\",\n                \"R-mat: A recursive model for graph mining\",\n                \"The electrical resistance of a graph captures its commute and cover times\",\n                \"Solving sdd linear systems in nearly mlog1/2n time\",\n                \"Effective graph resistance\",\n                \"Effective resistance on graphs and the epidemic quasimetric\",\n                \"A stochastic estimator of the trace of the influence matrix for laplacian smoothing splines\",\n                \"Minimizing effective resistance of a graph\",\n                \"Algebraic graph theory, volume 207\",\n                \"Matrix computations\",\n                \"Eigen v3\",\n                \"Efficient algorithms for spanning tree centrality\",\n                \"Pselinv – a distributed memory parallel algorithm for selected inversion: The non-symmetric case\",\n                \"Extensions of lipschitz mappings into a hilbert space\",\n                \"A simple, combinatorial algorithm for solving sdd systems in nearly-linear time\",\n                \"Resistance distance\",\n                \"A nearly-m log n time solver for SDD linear systems\",\n                \"Approaching optimality for solving SDD linear systems\",\n                \"Combinatorial preconditioners and multilevel solvers for problems in computer vision and image processing\",\n                \"KONECT: the koblenz network collection\",\n                \"Approximate Gaussian Elimination for Laplacians – Fast, Sparse, and Simple\",\n                \"Sparsified cholesky and multigrid solvers for connection laplacians\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]40 based on the context and research area of Approximation of the Diagonal of a Laplacian’s Pseudoinverse for Complex Network Analysis. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}