{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: TR2MTL: LLM based framework for Metric Temporal Logic Formalization of Traffic Rules\n\nPaper Abstract: \n\nPaper Section Text:\nSafety and liability concerns make traffic rule compliance important for the automated vehicles (AV) industry. Countries-specific traffic rulebooks such as German Road Traffic Regulation (StVO)111https://www.gesetze-im-internet.de/stvo_2013/ and general driving guides such as Vienna Convention on Road Traffic (VCoRT)222https://unece.org/DAM/trans/conventn/crt1968e.pdf govern the rights and obligation of road users. However, traffic rules are often written in natural language, which can be vague, inconsistent, or context-dependent. This makes it hard for AVs to interpret and follow traffic rules in different situations and locations. For example, the meaning of safe distance while driving can vary depending on the driver’s preference. A possible solution is to use formal logic, such as metric temporal logic (MTL), to represent traffic rules precisely and unambiguously. MTL can capture the temporal aspects of traffic rules  and enable various applications, such as verification, planning, monitoring, or prediction. MTL is a propositional bounded-operator logic that extends propositional logic with the temporal operator. This makes it especially suitable for safety and verification tasks [ref]2 due to its ability to consider time constraints on quantitative temporal operators, unlike linear temporal logic. In the planning module, formalized traffic rules can restrict AV maneuvers as per rules and contribute to rule-compliant behavior. MTL formalization of rules is not straightforward. It requires domain knowledge and expertise in both natural language and formal logic. It also involves complex reasoning and translation processes that could be more intuitive for humans. Moreover, it takes time and effort to manually formalize rules and specifications from different sources and domains. Therefore, an automated translator that translates natural language traffic rules into MTL specifications is desirable. Legal traffic rules to MTL can be considered a translation or semantic parsing task. We transform the semantic parsing as a “translation” problem. However, training such a semantic parser is difficult due to the large annotated dataset requirement of natural language traffic rules and temporal logic pairs, which is expensive to obtain due to the involvement of logic experts. Unlike the conventional “in-context learning”  approach which relies on prompting and language understanding of large language models (LLMs) to minimize the need for large datasets, our method addresses the limitations of prompting. Classical prompting  has performed poorly on complex reasoning tasks [ref]4, which is crucial for MTL formalization task. We propose TR2MTL, a framework that translates natural language traffic rules into MTL, as shown in Fig. 1. The translation module shown here leverages an LLM with a few examples of traffic rules and their corresponding MTL formulas, which are shown as “few-shot prompts”. The LLM also uses an MTL formula template (details in Fig. 3) to guide the translation process. The MTL output of the LLM is then filtered and parsed to generate the final MTL formula. Few-shot prompts shown here use a chain-of-thought (CoT) prompting [ref]4 variant, which divides the translation problem into subtasks, each requiring the LLM to generate an output that solves the current subtask and provides the context for the next one. Such a variant of prompting enables the model to have a more robust reasoning capability. This framework can serve as a valuable assistant, significantly reducing the effort required for rule formalization. It also offers the advantage of enabling users to select the appropriate answer or edit the automatically generated translation from the model rather than starting from scratch to create a new logical rule. We evaluate TR2MTL using various state-of-the-art and open-source LLMs as the backbone model on a challenging evaluation dataset of traffic rules from StVO and VCoRT. We achieved promising translation results even with relatively complex traffic rules having ambiguous and unstructured syntax and wordings. We also demonstrate the applicability of TR2MTL to various forms of temporal logic and other intelligent vehicle domains for generalization purposes. We provide our dataset of traffic rules and MTL pairs as a valuable resource for further research and development in traffic rule formalization and verification for autonomous vehicles. We envision it as a human-in-the-loop framework that facilitates the rapid formalization of rules and specifications for verification and testing purposes. We can summarize our main contribution as follows: We propose TR2MTL, a novel human-in-loop framework that leverages LLMs and an in-context learning approach to automate the translation of natural language traffic rules into MTL formulas without the need for large annotated datasets. We present a dataset for evaluating the quality of LLM-generated MTL traffic rules. Our dataset consists of unstructured traffic rules, which have varying linguistic complexity and ambiguity, in contrast to curated datasets , which are based on pre-processed rules with clear semantics and belong to the non-AV domain. We demonstrate that our framework can easily adapt to new traffic rules, different logic formalization, and other domains with minimal data requirements. Sec. II and III cover related work and theoretical backgrounds, respectively. Backbone language model choices and dataset are discussed in Sec. IV, followed by the results and discussion in Sec. V.\n\nReference markers found: [2]\n\nContext windows for each [ref]:\n[ref]2: or prediction. MTL is a propositional bounded-operator logic that extends propositional logic with the temporal operator. This makes it especially suitable for safety and verification tasks [ref]2 due to its ability to consider time constraints on quantitative temporal operators, unlike linear temporal logic. In the planning module, formalized traffic rules can restrict AV maneuvers as\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 2,\n            \"titles\": [\n                \"Language Models are Few-Shot Learners\",\n                \"Monitoring Algorithms for Metric Temporal Logic Specifications\",\n                \"Logics and models of real time: A survey\",\n                \"Chain-of-thought prompting elicits reasoning in large language models\",\n                \"Planning with State Abstractions for Non-Markovian Task Specifications\",\n                \"Formalization of intersection traffic rules in temporal logic\",\n                \"Formalization of interstate traffic rules in temporal logic\",\n                \"A formally verified checker of the safe distance traffic rules for autonomous vehicles\",\n                \"Formalizing traffic rules for uncontrolled intersections\",\n                \"Formalising and monitoring traffic rules for autonomous vehicles in isabelle/hol\",\n                \"Fast decision making using ontology-based knowledge base\",\n                \"A systematic framework to identify violations of scenario-dependent driving rules in autonomous vehicle software\",\n                \"Encoding and monitoring responsibility sensitive safety rules for automated vehicles in signal temporal logic\",\n                \"Specifying safety of autonomous vehicles in signal temporal logic\",\n                \"From Specifications to Behavior: Maneuver Verification in a Semantic State Space\",\n                \"Synthesis of controllers for co-safe linear temporal logic specifications using reinforcement learning\",\n                \"Intention-aware motion planning with road rules\",\n                \"Road Traffic Law Adaptive Decision-making for Self-Driving Vehicles\",\n                \"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents\",\n                \"ReAct: Synergizing reasoning and acting in language models\",\n                \"Semantic role assisted natural language rule formalization for intelligent vehicle\",\n                \"NL2LTL – a python package for converting natural language (NL) instructions to linear temporal logic (LTL) formulas\",\n                \"Formal Specifications from Natural Language\",\n                \"DeepSTL - From English Requirements to Signal Temporal Logic\",\n                \"Lang2LTL: Translating natural language commands to temporal specification with large language models\",\n                \"Attention Is All You Need\",\n                \"Differentiable logic layer for rule guided trajectory prediction\",\n                \"Legal compliance checking of autonomous driving with formalized traffic rule exceptions\",\n                \"Commonroad scenario designer: An open-source toolbox for map conversion and scenario creation for autonomous vehicles\",\n                \"Lanelet2: A high-definition map framework for the future of automated driving\",\n                \"StarCoder: may the source be with you!\",\n                \"Falcon-7b\",\n                \"Crosslingual Generalization through Multitask Finetuning\",\n                \"Temporal logic formalization of marine traffic rules\",\n                \"Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification\",\n                \"Parallel Context Windows for Large Language Models\",\n                \"Generated Reference Title 36 for [ref]2\",\n                \"Generated Reference Title 37 for [ref]2\",\n                \"Generated Reference Title 38 for [ref]2\",\n                \"Generated Reference Title 39 for [ref]2\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]2 based on the context and research area of TR2MTL: LLM based framework for Metric Temporal Logic Formalization of Traffic Rules. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}