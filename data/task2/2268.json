{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Effective Evaluation of Deep Active Learning on Image Classification Tasks\n\nPaper Abstract: \n\nPaper Section Text:\nSimilar to supervised learning, AL starts with a labeled seed set that is used to train an initial model. Unlike supervised learning, there is another set of unlabeled instances 𝒟𝒰​ℒsubscript𝒟𝒰ℒ\\mathcal{D_{UL}} from which AL periodically selects instances to label and add to the existing labeled set. The AL algorithm uses information from the model, from the unlabeled set, or from both when selecting these instances to yield the largest increase in test performance after the model is updated or retrained. To better understand the main approaches compared in this paper, we introduce some notation that we will use in our description of each algorithm. Let f𝑓f denote the deep neural network used in training, flsubscript𝑓𝑙f_{l} denote the output of f𝑓f at layer l𝑙l, and θlsubscript𝜃𝑙\\theta_{l} denote the parameters of layer l𝑙l. We use b𝑏b to denote the AL batch size and L𝐿L to denote the number of layers of f𝑓f. Uncertainty sampling selects instances from 𝒟𝒰​ℒsubscript𝒟𝒰ℒ\\mathcal{D_{UL}} that maximize a measure of uncertainty on the model’s prediction of the instance’s label. Common uncertainty-based sampling techniques are entropy, least confidence, and margin sampling techniques [ref]27. Using p​(x)=softmax​(fL​(x))𝑝𝑥softmaxsubscript𝑓𝐿𝑥p(x)=\\text{softmax}(f_{L}(x)), each computes the following for each x∈𝒟𝒰​ℒ𝑥subscript𝒟𝒰ℒx\\in\\mathcal{D_{UL}}: where σ1subscript𝜎1\\sigma_{1} and σ2subscript𝜎2\\sigma_{2} denote the indices of the largest and second-largest components of p​(x)𝑝𝑥p(x), respectively. Entropy sampling chooses x∈𝒟𝒰​ℒ𝑥subscript𝒟𝒰ℒx\\in\\mathcal{D_{UL}} associated with the b𝑏b largest H​(x)𝐻𝑥H(x) values. Least confidence sampling and margin sampling choose x∈𝒟𝒰​ℒ𝑥subscript𝒟𝒰ℒx\\in\\mathcal{D_{UL}} associated with the b𝑏b smallest C​(x)𝐶𝑥C(x) and M​(x)𝑀𝑥M(x) values, respectively. By selecting uncertain points, future training on f𝑓f can further refine the decision boundary, giving improved performance. Next, the CoreSet approach tries to find instances that represent or capture the structure of 𝒟𝒰​ℒsubscript𝒟𝒰ℒ\\mathcal{D_{UL}} by minimizing a core-set loss . The authors of  show that this can be achieved by solving the following: where ΔΔ\\Delta denotes some distance metric, 𝐬1superscript𝐬1\\mathbf{s}^{1} denotes the chosen AL batch, and 𝐬0superscript𝐬0\\mathbf{s}^{0} denotes the labeled set. The authors of  use a robust k𝑘k-center algorithm to solve this objective. The points selected in this fashion are thus diverse and representative of 𝒟𝒰​ℒsubscript𝒟𝒰ℒ\\mathcal{D_{UL}}, allowing for future training to produce f𝑓f that generalizes better on the domain. In our experiments, we choose to represent each x𝑥x by its penultimate layer embedding fL−1​(x)subscript𝑓𝐿1𝑥f_{L-1}(x) when calculating Δ​(xi,xj)Δsubscript𝑥𝑖subscript𝑥𝑗\\Delta(x_{i},x_{j}). FASS [ref]30 applies a two-step process of uncertainty sampling and submodular selection. Specifically, the top b×k𝑏𝑘b\\times k most uncertain x∈𝒟𝒰​ℒ𝑥subscript𝒟𝒰ℒx\\in\\mathcal{D_{UL}} are initially chosen and stored in 𝒰𝒰\\mathcal{U}, where k𝑘k is a configurable hyper-parameter. Next, a submodular 2 set function r:2𝒰→ℝ:𝑟→superscript2𝒰ℝr:2^{\\mathcal{U}}\\rightarrow\\mathbb{R} is instantiated on 𝒰𝒰\\mathcal{U}. Submodular function maximization subject to cardinality constraints is known to find diverse or representative subsets; thus, FASS [ref]30 selects 𝐬1⊆𝒰superscript𝐬1𝒰\\mathbf{s}^{1}\\subseteq\\mathcal{U} such that |𝐬1|=bsuperscript𝐬1𝑏|\\mathbf{s}^{1}|=b using submodular maximization with cardinality constraints on r𝑟r, thereby capturing both uncertainty (via 𝒰𝒰\\mathcal{U}) and diversity (via r𝑟r) in 𝒟𝒰​ℒsubscript𝒟𝒰ℒ\\mathcal{D_{UL}}. In our experiments, we use entropy sampling [ref]27 for the uncertainty measure and facility location 2 for r𝑟r. As before, we use penultimate layer embeddings given by fL−1​(x)subscript𝑓𝐿1𝑥f_{L-1}(x) for each x∈𝒰𝑥𝒰x\\in\\mathcal{U} when instantiating r𝑟r. Badge , a very recent approach free of hyper-parameter tuning, first computes the last linear layer gradients of the hypothesized loss on each of the instances in 𝒟𝒰​ℒsubscript𝒟𝒰ℒ\\mathcal{D_{UL}}. Specifically, if we denote y^​(x)=maxi⁡fL​(x)i^𝑦𝑥subscript𝑖subscript𝑓𝐿subscript𝑥𝑖\\hat{y}(x)=\\max_{i}f_{L}(x)_{i} and ℒℒ\\mathcal{L} as the loss used, then for each x∈𝒟𝒰​ℒ𝑥subscript𝒟𝒰ℒx\\in\\mathcal{D_{UL}}, we compute g​(x)=∇θL−1ℒ​(y^​(x),fL​(x))𝑔𝑥subscript∇subscript𝜃𝐿1ℒ^𝑦𝑥subscript𝑓𝐿𝑥g(x)=\\nabla_{\\theta_{L-1}}\\mathcal{L}(\\hat{y}(x),f_{L}(x)). Denoting 𝒢={g​(x)|x∈𝒟𝒰​ℒ}𝒢conditional-set𝑔𝑥𝑥subscript𝒟𝒰ℒ\\mathcal{G}=\\{g(x)|x\\in\\mathcal{D_{UL}}\\}, Badge  then runs the k-means++ initialization algorithm  on 𝒢𝒢\\mathcal{G} to obtain b𝑏b centers, which are likely to all have large loss gradient magnitudes (which captures uncertainty brought about by large changes to the loss) and diverse loss gradient directions (which captures diversity brought about by diverse parameter updates). The points corresponding to these b𝑏b centers are then chosen as the AL batch by Badge , which helps future training on f𝑓f better adapt to the domain. Lastly, GLISTER-ACTIVE 6 selects points by solving the following bi-level optimization problem: where L​L​(θ,S)𝐿𝐿𝜃𝑆LL(\\theta,S) denotes the log-likelihood on the set S𝑆S using f𝑓f parameterized by θ𝜃\\theta, P​(S)={(x,y^​(x))|x∈S}𝑃𝑆conditional-set𝑥^𝑦𝑥𝑥𝑆P(S)=\\{(x,\\hat{y}(x))|x\\in S\\}, and 𝒱𝒱\\mathcal{V} denotes a validation set of interest. In our experiments, we set 𝒱𝒱\\mathcal{V} as the union of the labeled set and 𝒟𝒰​ℒsubscript𝒟𝒰ℒ\\mathcal{D_{UL}} with hypothesized labels (e.g., the set P​(𝒟𝒰​ℒ)𝑃subscript𝒟𝒰ℒP(\\mathcal{D_{UL}})). Here, the inner optimization problem learns model parameters on the pseudo-labeled AL batch, and the outer optimization problem selects a set of unlabeled instances from 𝒟𝒰​ℒsubscript𝒟𝒰ℒ\\mathcal{D_{UL}} that maximizes the log-likelihood with respect to the validation set using the trained model parameters from the inner problem. The authors of 6 use an online meta approximation algorithm to carry out the bi-level optimization. Ultimately, GLISTER-ACTIVE 6 selects 𝐬1superscript𝐬1\\mathbf{s}^{1} that is representative of the domain (since we use our specific choice of 𝒱𝒱\\mathcal{V}), which aids in producing f𝑓f that generalizes better on the domain. Since the aim of deep AL methods is to reduce the labeling cost, AL is therefore most useful when considered in large data settings. Techniques such as BALD 0, adversarial-based AL techniques , and VAAL  are not as scalable; therefore, we do not consider them in most of our experiments in our main sections. For larger AL batch sizes, BALD requires intractably large collections of Monte Carlo samples for its Bayesian estimates, while VAAL  requires maintaining and training three models – the main supervised model, the VAE model, and the discriminator . Additionally, other adversarial methods such as those studied in  require expensive perturbations to perform AL selection. For completeness, we perform a few small-scale experiments to compare all AL baselines (including BALD, VAAL, and other adversarial methods) in Appendix B. Specifically, we contrast the running times, test performance, and labeling efficiencies of all these AL approaches.\n\nReference markers found: [27]\n\nContext windows for each [ref]:\n[ref]27: that maximize a measure of uncertainty on the model’s prediction of the instance’s label. Common uncertainty-based sampling techniques are entropy, least confidence, and margin sampling techniques [ref]27. Using p​(x)=softmax​(fL​(x))𝑝𝑥softmaxsubscript𝑓𝐿𝑥p(x)=\\text{softmax}(f_{L}(x)), each computes the following for each x∈𝒟𝒰​ℒ𝑥subscript𝒟𝒰ℒx\\in\\mathcal{D_{UL}}: where σ1subscript𝜎1\\sigma_{1}\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 27,\n            \"titles\": [\n                \"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\n                \"k-means++: the advantages of careful seeding\",\n                \"Deep active learning with badge\",\n                \"On Warm-Starting Neural Network Training\",\n                \"Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds\",\n                \"Autoaugment: Learning augmentation policies from data\",\n                \"Randaugment: Practical automated data augmentation with a reduced search space\",\n                \"Adversarial Active Learning for Deep Networks: a Margin Based Approach\",\n                \"Shake-Shake regularization\",\n                \"Deep Residual Learning for Image Recognition\",\n                \"Bayesian active learning for classification and preference learning\",\n                \"Deep active learning\",\n                \"Submodular Combinatorial Information Measures with Applications in Machine Learning\",\n                \"Averaging Weights Leads to Wider Optima and Better Generalization\",\n                \"Learning From Less Data: A Unified Data Subset Selection and Active Learning Framework for Computer Vision\",\n                \"Grad-match: A gradient matching based data subset selection for efficient learning\",\n                \"Glister: A generalization based data selection framework for efficient and robust learning\",\n                \"Adam: A method for stochastic optimization\",\n                \"Learning multiple layers of features from tiny images\",\n                \"Gradient-based learning applied to document recognition\",\n                \"DeepFool: a simple and accurate method to fool deep neural networks\",\n                \"Towards Robust and Reproducible Active Learning using Neural Networks\",\n                \"Reading digits in natural images with unsupervised feature learning\",\n                \"PyTorch: An Imperative Style, High-Performance Deep Learning Library\",\n                \"The Effectiveness of Data Augmentation in Image Classification using Deep Learning\",\n                \"apricot: Submodular selection for data summarization in Python\",\n                \"Active Learning for Convolutional Neural Networks: A Core-Set Approach\",\n                \"Active learning literature survey\",\n                \"Variational Adversarial Active Learning\",\n                \"Submodularity in data subset selection and active learning\",\n                \"The Marginal Value of Adaptive Gradient Methods in Machine Learning\",\n                \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\",\n                \"Deep Layer Aggregation\",\n                \"Wide Residual Networks\",\n                \"Towards Theoretically Understanding Why Sgd Generalizes Better Than Adam in Deep Learning\",\n                \"Generated Reference Title 35 for [ref]27\",\n                \"Generated Reference Title 36 for [ref]27\",\n                \"Generated Reference Title 37 for [ref]27\",\n                \"Generated Reference Title 38 for [ref]27\",\n                \"Generated Reference Title 39 for [ref]27\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]27 based on the context and research area of Effective Evaluation of Deep Active Learning on Image Classification Tasks. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}