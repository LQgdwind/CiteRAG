{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Fairness Maximization among Offline Agents in Online-Matching Markets\n\nPaper Abstract: \n\nPaper Section Text:\nA straight-forward analysis yields that the aforementioned non-adaptive sampling policy achieves 1−1/𝖾11𝖾1-1/\\mathsf{e} of the LP optimum, see e.g., [ref]18 .\nHowever, such a policy also achieves no better than 1−1/𝖾11𝖾1-1/\\mathsf{e}, even when the LP has been tightened by Constraint (6).555\nTo see this, consider a complete bipartite graph with T𝑇T nodes on each side.\nSetting xi​j=1/Tsubscript𝑥𝑖𝑗1𝑇x_{ij}=1/T for every edge (i,j)𝑖𝑗(i,j) is feasible in the tightened LP that leaves every offline node fractionally matched. However, the corresponding sampling policy would only leave each offline node matched with probability 1−1/𝖾11𝖾1-1/\\mathsf{e}.\nIn fact, it can be seen on this example that any non-adaptive sampling policy must leave some offline node matched with probability at most 1−1/𝖾11𝖾1-1/\\mathsf{e}. To go beyond the competitive ratio of 1−1/𝖾11𝖾1-1/\\mathsf{e}, we consider the following simple and natural idea. Boosting. Suppose we are at (the beginning of) time t𝑡t and an online agent j𝑗j arrives. Assume that by solving the benchmark LP, we learn a sampling distribution 𝐱j={xi​j|i∈𝒩j}subscript𝐱𝑗conditional-setsubscript𝑥𝑖𝑗𝑖subscript𝒩𝑗\\mathbf{x}_{j}=\\{x_{ij}|i\\in\\mathcal{N}_{j}\\} for online agent j𝑗j with ∑i∈𝒩jxi​j≤1subscript𝑖subscript𝒩𝑗subscript𝑥𝑖𝑗1\\sum_{i\\in\\mathcal{N}_{j}}x_{ij}\\leq 1 from the clairvoyant optimal. Let 𝒩j,t⊆𝒩jsubscript𝒩𝑗𝑡subscript𝒩𝑗\\mathcal{N}_{j,t}\\subseteq\\mathcal{N}_{j} be the set of available neighbors of j𝑗j at time t𝑡t. Instead of non-adaptively sticking on the distribution 𝐱jsubscript𝐱𝑗\\mathbf{x}_{j} over 𝒩jsubscript𝒩𝑗\\mathcal{N}_{j} throughout the online phase  , we try to sample a neighbor j𝑗j from 𝒩j,tsubscript𝒩𝑗𝑡\\mathcal{N}_{j,t} only following a boosted version of distribution 𝐱j′={xi​j/∑i∈𝒩j,txi​j}subscriptsuperscript𝐱′𝑗subscript𝑥𝑖𝑗subscript𝑖subscript𝒩𝑗𝑡subscript𝑥𝑖𝑗\\mathbf{x}^{\\prime}_{j}=\\{x_{ij}/\\sum_{i\\in\\mathcal{N}_{j,t}}x_{ij}\\}. In this way, we promote the chance of each available neighbor of j𝑗j at t𝑡t getting matched with j𝑗j. Also, we can guarantee that the offline neighbor we have sampled is available at the time and dismiss the case that we sample an unavailable neighbor and have to reject j𝑗j ultimately, which is also a desirable feature to have in practice. This is the key idea in the algorithm we will present for IFMIFM\\operatorname{IFM} (see Theorem 2.2). Note that our boosting idea has already been proposed and tested in several practical crowdsourcing applications  . Though it proved to be helpful in some scenarios, the boosted version of LP-based sampling is more challenging to analyze since one has to consider the adaptive behavior of the algorithm.\nWe are the first to show that it achieves an online competitive ratio of 0.7250.7250.725, exceeding 1−1/𝖾11𝖾1-1/\\mathsf{e}, for IFMIFM\\operatorname{IFM}, which matches the second-best ratio as shown in  for VOMVOM\\operatorname{VOM}. One can contrast this to  who studied unweighted online matching under KIID and also introduced a boosting strategy, which is more complex. The main idea there is to generate two negatively correlated sampling distributions from the original one, and sample two candidate neighbors for an online arriving agent. A critical element in our analysis of the simple boosting algorithm for IFMIFM\\operatorname{IFM}, however, is that an optimal LP solution places identical total mass xi:=∑j∼ixi​jassignsubscript𝑥𝑖subscriptsimilar-to𝑗𝑖subscript𝑥𝑖𝑗x_{i}:=\\sum_{j\\sim i}x_{ij} on each offline agent i𝑖i. By contrast, for GFMGFM\\operatorname{GFM}, an optimal LP solution may place higher mass on specific offline agents, e.g., those belonging in many groups.\nWe show that when there is heterogeneity in the mass placed across offline agents, the boosting algorithm matches high-mass offline agents i𝑖i with probability no better than (1−1/𝖾)⋅xi⋅11𝖾subscript𝑥𝑖(1-1/\\mathsf{e})\\cdot x_{i} (see Lemma 4), i.e., its competitive ratio achieved is no longer better than 1−1/𝖾11𝖾1-1/\\mathsf{e}. Uniform vs. Non-uniform Boosting.\nTo break this barrier of 1−1/𝖾11𝖾1-1/\\mathsf{e} for GFMGFM\\operatorname{GFM}, our idea is to use boosting in a non-uniform fashion. In the simple boosting algorithm above, for an incoming arrival, the probability of sampling unavailable neighbors was re-distributed evenly across its available neighbors.\nHowever, our algorithm for GFMGFM\\operatorname{GFM} is more likely to suffer from offline agents i𝑖i with high total mass xisubscript𝑥𝑖x_{i}, since as explained above those agents are more difficult to match relative to its total mass xisubscript𝑥𝑖x_{i}. To accomplish this, we add an attenuation factor to offline agents with small total mass in the LP solution, in an attempt to balance the probability of matching every offline agent i𝑖i relative to its total mass xisubscript𝑥𝑖x_{i}. Attenuation techniques have been used previously in several stochastic optimization problems, see, e.g., stochastic knapsack , stochastic matching  , and matching policy design in rideshare [ref]24 . Most similar to ours are the attenuation techniques used in   to overcome the barrier of 1−1/𝖾11𝖾1-1/\\mathsf{e} for VOMVOM\\operatorname{VOM} under KIID. However, our attenuation technique is different and novel in the following sense. Consider an online agent j𝑗j that arrives at time t𝑡t and let 𝐱j={xi​j|i∈𝒩j}subscript𝐱𝑗conditional-setsubscript𝑥𝑖𝑗𝑖subscript𝒩𝑗\\mathbf{x}_{j}=\\{x_{ij}|i\\in\\mathcal{N}_{j}\\} be the sampling distribution of j𝑗j before attenuation. The idea in   is to carefully design factors αi​jsubscript𝛼𝑖𝑗\\alpha_{ij} that are added directly to the sampling distribution 𝐱jsubscript𝐱𝑗\\mathbf{x}_{j} such that we finally sample an offline neighbor i∈𝒩j𝑖subscript𝒩𝑗i\\in\\mathcal{N}_{j} with an updated probability αi​j⋅xi​j⋅subscript𝛼𝑖𝑗subscript𝑥𝑖𝑗\\alpha_{ij}\\cdot x_{ij} upon the arrival of j𝑗j. In this way, they can both promote the performance of an offline agent i𝑖i with large mass by setting αi​j>1subscript𝛼𝑖𝑗1\\alpha_{ij}>1 and compress that of i𝑖i with small mass by setting αi​j<1subscript𝛼𝑖𝑗1\\alpha_{ij}<1. In contrast, our idea is to adaptively and randomly update the set of neighbors of j𝑗j subject to sampling. Recall that the idea of boosting is to sample a neighbor of j𝑗j only from the set of available neighbors at that time following a boosted version of distribution 𝐱j′={xi​j/∑i∈𝒩j,txi​j}subscriptsuperscript𝐱′𝑗subscript𝑥𝑖𝑗subscript𝑖subscript𝒩𝑗𝑡subscript𝑥𝑖𝑗\\mathbf{x}^{\\prime}_{j}=\\{x_{ij}/\\sum_{i\\in\\mathcal{N}_{j,t}}x_{ij}\\}. Our attenuation idea is to further enhance the power of boosting by randomly “muting” some available neighbors of j𝑗j at time t𝑡t with small mass (i.e., forcefully labeling them as unavailable) and then apply the boosting idea to the set of all available neighbors that survives the muting procedure. We expect our attenuation can help compress the performance of offline agents with small mass and promote that of offline agents with large mass as a result.\n\nReference markers found: [18]\n\nContext windows for each [ref]:\n[ref]18: A straight-forward analysis yields that the aforementioned non-adaptive sampling policy achieves 1−1/𝖾11𝖾1-1/\\mathsf{e} of the LP optimum, see e.g., [ref]18 .\nHowever, such a policy also achieves no better than 1−1/𝖾11𝖾1-1/\\mathsf{e}, even when the LP has been tightened by Constraint (6).555\nTo see this, consider a complete bipartite graph with\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 18,\n            \"titles\": [\n                \"Balancing Relevance and Diversity in Online Bipartite Matching via Submodularity\",\n                \"Spatial pricing in ride-sharing networks\",\n                \"Spatio-temporal pricing for ridesharing platforms\",\n                \"Avoiding the south side and the suburbs: The geography of mobile crowdsourcing markets\",\n                \"The gender earnings gap in the gig economy: Evidence from over a million rideshare drivers\",\n                \"Discriminating tastes: Customer ratings as vehicles for bias\",\n                \"Yes, there’s a wage gap for uber and lyft drivers based on age, gender and race\",\n                \"Preference-aware task assignment in on-demand taxi dispatching: An online stable matching approach\",\n                \"Assigning tasks to workers based on historical data: Online task assignment with two-sided arrivals\",\n                \"Multi-stage and multi-customer assortment optimization with inventory constraints\",\n                \"Online stochastic matching: New algorithms with better bounds\",\n                \"Online stochastic matching: New algorithms and bounds\",\n                \"Online stochastic matching: Online actions based on offline statistics\",\n                \"Online stochastic weighted matching: Improved approximation algorithms\",\n                \"Online stochastic matching: Beating 1-1/e\",\n                \"Online matching and ad allocation\",\n                \"Online Stochastic Matching, Poisson Arrivals, and the Natural Linear Program\",\n                \"Online prophet-inequality matching with applications to ad allocation\",\n                \"Online resource allocation with matching constraints\",\n                \"Improvements and generalizations of stochastic knapsack and multi-armed bandit approximation algorithms\",\n                \"Improved approximation algorithms for stochastic matching\",\n                \"Attenuate locally, win globally: An attenuation-based framework for online stochastic matching with timeouts\",\n                \"Linear programming based online policies for real-time assortment of reusable resources\",\n                \"Allocation Problems in Ride-Sharing Platforms: Online Matching with Offline Reusable Resources\",\n                \"Online budgeted matching in random input models with applications to adwords\",\n                \"An optimal algorithm for on-line bipartite matching\",\n                \"The network data repository with interactive graph analytics and visualization\",\n                \"Matching algorithms for blood donation\",\n                \"Online policies for efficient volunteer crowdsourcing\",\n                \"Incorporating compatible pairs in kidney exchange: A dynamic weighted matching model\",\n                \"Two-sided fairness for repeated matchings in two-sided markets: A case study of a ride-hailing platform\",\n                \"Balancing efficiency and fairness in on-demand ridesourcing\",\n                \"Matchings with group fairness constraints: Online and offline algorithms\",\n                \"Fair-by-design matching\",\n                \"Balancing the Tradeoff between Profit and Fairness in Rideshare Platforms During High-Demand Hours\",\n                \"Trade the system efficiency for the income equality of drivers in rideshare\",\n                \"Group-level fairness maximization in online bipartite matching\",\n                \"Fair dynamic rationing\",\n                \"Closing the gap: Group-aware parallelization for online selection of candidates with biased evaluations\",\n                \"Group-Fairness in Influence Maximization\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]18 based on the context and research area of Fairness Maximization among Offline Agents in Online-Matching Markets. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}