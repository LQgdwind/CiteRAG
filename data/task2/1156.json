{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Quantum Random Access Codes for Boolean Functions\n\nPaper Abstract: \n\nPaper Section Text:\nAn n‚Äã‚Ü¶ùëù‚Äãmùëõùëùmaps-toùëön\\overset{p}{\\mapsto}m (Q)RAC is an encoding of nùëõn bits into mùëöm (qu)bits such that any initial bit can be recovered with probability at least pùëùp. This probability is the worst case success probability over all possible pairs (x,i)ùë•ùëñ(x,i) of input string x‚àà{‚àí1,1}nùë•superscript11ùëõx\\in\\{-1,1\\}^{n} and recoverable bit i‚àà{1,‚Ä¶,n}ùëñ1‚Ä¶ùëõi\\in\\{1,\\dots,n\\}. Many different resources can be used during the encoding and decoding, e.g.¬†private randomness¬†(PR), shared randomness¬†(SR), shared entanglement, and even super-quantum correlations like Popescu-Rohrlich boxes¬†. Regarding the classical RAC, Ambainis et al.¬† proved that there is no 2‚Äã‚Ü¶ùëù‚Äã12ùëùmaps-to12\\overset{p}{\\mapsto}1 RAC (and 2m‚Äã‚Ü¶ùëù‚Äãmsuperscript2ùëöùëùmaps-toùëö2^{m}\\overset{p}{\\mapsto}m RAC by extension) with PR and worst case success probability p>1/2ùëù12p>1/2. On the other hand, Ambainis et al.¬†[ref]5 showed that RACs with SR can achieve success probability p>1/2ùëù12p>1/2. The optimal n‚Äã‚Ü¶ùëù‚Äã1ùëõùëùmaps-to1n\\overset{p}{\\mapsto}1 RAC with SR has success probability For a general number of encoded bits, Ambainis et al.¬† developed a RAC with PR using a specific code from¬† which matches their classical lower bound m‚â•(1‚àíH‚Äã(p))‚Äãnùëö1ùêªùëùùëõm\\geq(1-H(p))n up to an additive logarithmic term, where H‚Äã(p)=‚àíp‚Äãlog2‚Å°p‚àí(1‚àíp)‚Äãlog2‚Å°(1‚àíp)ùêªùëùùëùsubscript2ùëù1ùëùsubscript21ùëùH(p)=-p\\log_{2}{p}-(1-p)\\log_{2}(1-p) is the binary entropy function. There is an n‚Äã‚Ü¶ùëù‚Äãmùëõùëùmaps-toùëön\\overset{p}{\\mapsto}m RAC with PR and m‚â§(1‚àíH‚Äã(p))‚Äãn+7‚Äãlog2‚Å°nùëö1ùêªùëùùëõ7subscript2ùëõm\\leq(1-H(p))n+7\\log_{2}{n} for any p>12ùëù12p>\\frac{1}{2}. As for QRACs, Ambainis et al.¬† showed the existence of a 2‚Äã‚Ü¶ùëù‚Äã12ùëùmaps-to12\\overset{p}{\\mapsto}1 QRAC with PR111Usually private randomness is already assumed in QRACs under the encoding onto density matrices. and p=12+12‚Äã2‚âà0.85ùëù121220.85p=\\frac{1}{2}+\\frac{1}{2\\sqrt{2}}\\approx 0.85, and the existence of a 3‚Äã‚Ü¶ùëù‚Äã13ùëùmaps-to13\\overset{p}{\\mapsto}1 QRAC with PR and p=12+12‚Äã3‚âà0.79ùëù121230.79p=\\frac{1}{2}+\\frac{1}{2\\sqrt{3}}\\approx 0.79 (the second attributed to Chuang). Later Hayashi et al.¬† showed the impossibility of a 4‚Äã‚Ü¶ùëù‚Äã14ùëùmaps-to14\\overset{p}{\\mapsto}1 QRAC (and 4m‚Äã‚Ü¶ùëù‚Äãmsuperscript4ùëöùëùmaps-toùëö4^{m}\\overset{p}{\\mapsto}m QRAC by extension) with PR and success probability p>1/2ùëù12p>1/2. Similarly to the classical case, Ambainis et al.¬†[ref]5 showed that QRACs can also benefit from SR. There is an n‚Äã‚Ü¶ùëù‚Äã1ùëõùëùmaps-to1n\\overset{p}{\\mapsto}1 QRAC with SR and 222Ambainis et al.¬†[ref]5 do not give the high order terms, but these can be calculated by following their procedure together with¬†[30, Equation 2.198]. The specific case of m=2ùëö2m=2 encoding qubits was explored in¬†  . For the general case of m>1ùëö1m>1, Iwama et al.¬† constructed an (4m‚àí1)‚Äã‚Ü¶ùëù‚Äãmsuperscript4ùëö1ùëùmaps-toùëö(4^{m}-1)\\overset{p}{\\mapsto}m QRAC with PR and p=12+12‚Äã(2m‚àí1)‚Äã2m+1ùëù1212superscript2ùëö1superscript2ùëö1p=\\frac{1}{2}+\\frac{1}{2(2^{m}-1)\\sqrt{2^{m}+1}} (such construction also works for all n<4mùëõsuperscript4ùëön<4^{m}). On the other hand, Ambainis et al.¬† proved that if an n‚Äã‚Ü¶ùëù‚Äãmùëõùëùmaps-toùëön\\overset{p}{\\mapsto}m QRAC with PR and p>1/2ùëù12p>1/2 exists, then m=Œ©‚Äã(n/log‚Å°n)ùëöŒ©ùëõùëõm=\\Omega(n/\\log{n}), which was later improved to m‚â•(1‚àíH‚Äã(p))‚Äãnùëö1ùêªùëùùëõm\\geq(1-H(p))n by Nayak¬†3, thus matching the same classical lower bound from¬†. The idea of decoding a function of the initial bits instead of a single bit was already considered by Ben-Aroya, Regev and de Wolf¬† (who also considered recovering multiple bits rather than just one). More specifically, they defined an n‚Äã‚Ü¶ùëù‚Äãmùëõùëùmaps-toùëön\\overset{p}{\\mapsto}m XORksubscriptXORùëò\\operatorname{XOR}_{k}-QRAC, where nùëõn bits are encoded into mùëöm qubits such that the parity of any kùëòk initial bits can be recovered with success probability at least¬†pùëùp.333In their definition the success probability is the average over random kùëòk-subsets and random inputs, which, in our context, is equivalent to using SR. Using their hypercontractive inequality for matrix-valued functions, they proved the following upper bound on the success probability. For any Œ∑>2‚Äãln‚Å°2ùúÇ22\\eta>2\\ln{2} there is a constant CŒ∑subscriptùê∂ùúÇC_{\\eta} such that, for any n‚Äã‚Ü¶ùëù‚Äãmùëõùëùmaps-toùëön\\overset{p}{\\mapsto}m XORksubscriptXORùëò\\operatorname{XOR}_{k}-QRAC with SR and k=o‚Äã(n)ùëòùëúùëõk=o(n), They conjectured that the factor Œ∑>2‚Äãln‚Å°2ùúÇ22\\eta>2\\ln{2} can be dropped from the above bound, and thus extended to m/n>1/(2‚Äãln‚Å°2)‚âà0.72ùëöùëõ1220.72m/n>1/(2\\ln{2})\\approx 0.72, although it might require a strengthening of their hypercontractive inequality. The use of shared entanglement in random access codes was first considered by Klauck¬† . Here the encoding and decoding parties are allowed to use an arbitrary amount of shared entangled states (note that shared entanglement can be used to obtain both private and shared randomness). The figure of merit in this generalization is the relation between nùëõn, mùëöm and pùëùp, while the amount of shared entanglement is not taken into account. Klauck¬†  considered an n‚Äã‚Ü¶ùëù‚Äãmùëõùëùmaps-toùëön\\overset{p}{\\mapsto}m QRAC with shared entanglement and, by its equivalence to the quantum one-way communication complexity for the index function, proved the lower bound m‚â•(1‚àíH‚Äã(p))‚Äãn/2ùëö1ùêªùëùùëõ2m\\geq(1-H(p))n/2, similar to Nayak‚Äôs bound. Later Paw≈Çowski and ≈ªukowski¬†8 coined the term entanglement-assisted random access code (EARAC), which is a RAC with shared entanglement, and studied the case when m=1ùëö1m=1, giving protocols with better decoding probabilities compared to the usual n‚Äã‚Ü¶ùëù‚Äã1ùëõùëùmaps-to1n\\overset{p}{\\mapsto}1 QRAC with SR. Recently TƒÉnƒÉsescu et al.¬† expanded the idea of n‚Äã‚Ü¶ùëù‚Äã1ùëõùëùmaps-to1n\\overset{p}{\\mapsto}1 EARACs to recovering an initial bit under a specific request distribution. The optimal n‚Äã‚Ü¶ùëù‚Äã1ùëõùëùmaps-to1n\\overset{p}{\\mapsto}1 EARAC with SR has success probability The idea of (Q)RAC was generalized in other ways, e.g.¬†parity-oblivious¬†   and multiparty¬† versions, encoding on dùëëd-valued qubits (qudits)¬†[ref]6    , a wider range of information retrieval tasks¬† and a connection to Popescu-Rohrlich boxes. It was shown¬† that a Popescu-Rohrlich box can simulate a RAC by means of just one bit of communication, while in¬† the converse was proven. An object called racbox¬† was defined, which is a box that implements a RAC when supported with one bit of communication, and it was shown that a non-signaling racbox is equivalent to a Popescu-Rohrlich box. A quantum version of a racbox was later proposed in¬†. Finally, we mention that RACs were also studied within ‚Äútheories‚Äù that violate the uncertainty relation for anti-commuting observables and present stronger-than-quantum correlations¬†.\n\nReference markers found: [5]\n\nContext windows for each [ref]:\n[ref]5: RAC (and 2m‚Äã‚Ü¶ùëù‚Äãmsuperscript2ùëöùëùmaps-toùëö2^{m}\\overset{p}{\\mapsto}m RAC by extension) with PR and worst case success probability p>1/2ùëù12p>1/2. On the other hand, Ambainis et al.¬†[ref]5 showed that RACs with SR can achieve success probability p>1/2ùëù12p>1/2. The optimal n‚Äã‚Ü¶ùëù‚Äã1ùëõùëùmaps-to1n\\overset{p}{\\mapsto}1 RAC with SR has success probability For a general number of encoded\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 5,\n            \"titles\": [\n                \"Optimal Classical Random Access Codes Using Single ùëë-level Systems\",\n                \"The learnability of quantum states\",\n                \"Certifying an irreducible 1024-dimensional photonic state using refined dimension witnesses\",\n                \"Experimental tests of classical and quantum dimensionality\",\n                \"Dense quantum coding and a lower bound for 1-way quantum automata\",\n                \"Quantum random access codes with shared randomness\",\n                \"Parity Oblivious ùëë-Level Random Access Codes and Class of Noncontextuality Inequalities\",\n                \"A hypercontractive inequality for matrix-valued functions with applications to quantum computing and LDCs\",\n                \"Noise sensitivity of Boolean functions and applications to percolation\",\n                \"Communication complexity lower bounds by polynomials\",\n                \"The exponential complexity of satisfiability problems\",\n                \"Extrema of discrete Wigner functions and applications\",\n                \"Optimal bounds for parity-oblivious random access codes\",\n                \"A nonconstructive upper bound on covering radius\",\n                \"On Krawtchouk polynomials\",\n                \"Implausible consequences of superstrong nonlocality\",\n                \"Asymptotic analysis of the Krawtchouk polynomials by the WKB method\",\n                \"Quantum advantage in information retrieval\",\n                \"Self-testing mutually unbiased bases in the prepare-and-measure scenario\",\n                \"Self-testing mutually unbiased bases in higher dimensions with space-division multiplexing optical fiber technology\",\n                \"Experimental demonstration of sequential quantum random access codes\",\n                \"Bounded-error quantum state identification and exponential separations in communication complexity\",\n                \"When are Popescu-Rohrlich boxes and random access codes equivalent?\",\n                \"Nonsignaling quantum random access-code boxes\",\n                \"Complementarity between entanglement-assisted and quantum distributed random access code\",\n                \"(4, 1)-quantum random access coding does not exist‚Äîone qubit is not enough to recover one of four bits\",\n                \"Quantum network coding\",\n                \"Quantum detection and estimation theory, volume 3\",\n                \"Bounds for the quantity of information transmitted by a quantum communication channel\",\n                \"Random walks and random environments: random walks, volume 1\",\n                \"Constructions of quantum random access codes\",\n                \"Unbounded-error one-way classical and quantum communication complexity\",\n                \"Quantum encodings and applications to locally decodable codes and communication complexity\",\n                \"Exponential lower bound for 2-query locally decodable codes via a quantum argument\",\n                \"On quantum and probabilistic communication: Las Vegas and one-way protocols\",\n                \"One-way communication complexity and the Neƒçiporuk lower bound on formula size\",\n                \"Communication Complexity\",\n                \"Semi-device-independent random-number expansion without entanglement\",\n                \"Improved classical and quantum random access codes\",\n                \"The theory of error correcting codes, volume 16\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]5 based on the context and research area of Quantum Random Access Codes for Boolean Functions. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}