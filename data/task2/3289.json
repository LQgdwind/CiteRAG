{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Towards Group Robustness in the presence of Partial Group Labels\n\nPaper Abstract: \n\nPaper Section Text:\nNeural networks being overly biased to certain groups of the data is an increasing concern within the machine learning community .\nA primary cause for bias against specific groups is the presence of extraneous attributes in the datasets that wrongly direct the model responses .\nSuch extraneous attributes are features that need to be controlled for.\nFor example, in computer vision tasks such as image classification or object detection, an extraneous attribute could correspond to the background in an image or a co-occurring object irrelevant to the task, e.g. a person making a speech in a football field could be predicted as playing football [ref]6.\nThe presence of such extraneous attributes warrant a model to derive the predictions by making spurious correlations to extraneous features in an image rather than an actual object of interest.\nAn inevitable consequence of such correlations to extraneous attributes is disparities in performance across different groups within the dataset.\nSpecifically, if certain groups form a minority, a model can simply cheat by having a high overall aggregate accuracy but poor minority group accuracy 8. Existing works for this problem  [ref]35 operate in the regime where the number of groups, likely to be adversely impacted through spurious correlations, are known apriori.\nFurther, they assume a complete knowledge of the group membership of individual samples in the training dataset.\nWhile these methods have been proven effective, it is not realistic to assume access to the group labels for every sample.\nConsider the scenario where the minority / majority groups could be defined by demographic information such as gender or race.\nAn individual can simply choose not to reveal this information due to privacy considerations 6.\nAlternatively, in medical image settings a label class could contain unrecognized subgroups that demand significant burden on the data labelling efforts .\nAn example of such unrecognized subgroups could be a lung cancer detection problem, where the class label could comprise of groups such as solid/subsolid tumors and central/peripheral neoplasms 8, with many of these groups naturally forming a minority in the dataset.\nIn this work, we consider a setting where a significant portion of the training data is devoid of group labels.\nWe choose to fill a missing gap in the literature where several works bifurcate into methods that either are fully supervised or fully unsupervised in terms of the groups labels.\nKnowledge on the number of groups in the data makes it convenient to obtain group labels for a tiny portion of the data or take advantage of an existing labelled samples if available.\nHence, we address the following research question: Can we train a model that is invariant to group membership when partially labelled data is available? We answer the question using a framework of distributionally robust optimization (DRO)  7.\nDRO allows for a training routine that optimizes for the worst-case training loss over predefined set of groups closely connected to the Rawlsian fairness measure .\nWhen the group membership is fully known, the method simply upweights/downweights average training loss of different groups through the course of training [ref]35.\nThe application of DRO to the partial group label setting poses significant challenges: (1) the lack of group label makes it infeasible to compute the worst-off group loss; (2) optimizing only for the high-loss samples, by considering them as a worst-off group, discards considerable portion of the training data adversely impacting the overall accuracy; and (3) inferring missing group labels with pseudo-label based methods is a cause for ethical concerns especially when group labels are characteristic of sensitive information. The third challenge above alludes a straightforward way of handling partially labelled setting where we directly estimate the group label for each sample with pseudo-label based methods. However, this approach could be harmful in the context of fairness problems because the estimated labels could be misused by a wrongdoer. For example, when the groups are indicative of sensitive information such as age or gender, an incorrect group estimation would wrongly designate the demographics of an individual. Moreover, when it’s desirable and intended to conceal such sensitive information, a direct estimation of groups would be a violation of privacy. Thus we cautiously avoid building of utilizing pseudo-label based methods in this paper. In light of all these challenges, we make the following contributions. We propose a method that defines a constraint set of group assignments and optimizes over all possibles configurations of the assignments within the set. Such a constraint set can encompass the group labels of the unlabeled portion of the data with high probability. We observe that optimizing for the a worst-off soft group assignment from the constraint set upper bounds the DRO objective with true group membership. Since worst-off assignments do not directly estimate the ground-truth assignments, our approach is theoretically safe and does not violate privacy. As we shall see in the paper, our method assigns high loss samples to groups with a higher weight and lower marginal probability improving the worst-off group accuracies.\nFurther, the low loss samples are not discarded thus preserving the aggregate accuracy across groups.\nWe show experiments on three imaging datasets and one tabular dataset and contrast the performance against several baselines.\n\nReference markers found: [6]\n\nContext windows for each [ref]:\n[ref]6: attribute could correspond to the background in an image or a co-occurring object irrelevant to the task, e.g. a person making a speech in a football field could be predicted as playing football [ref]6.\nThe presence of such extraneous attributes warrant a model to derive the predictions by making spurious correlations to extraneous features in an image rather than an actual object of\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 6,\n            \"titles\": [\n                \"Environment Inference for Invariant Learning\",\n                \"A Reductions Approach to Fair Classification\",\n                \"Invariant risk minimization\",\n                \"Robust optimization\",\n                \"Robust solutions of optimization problems affected by uncertain probabilities\",\n                \"Server, server in the cloud. who is the fairest in the crowd?\",\n                \"Why Can’t I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\n                \"CVXPY: A Python-embedded modeling language for convex optimization\",\n                \"Empirical Risk Minimization Under Fairness Constraints\",\n                \"Uci machine learning repository\",\n                \"Statistics of robust optimization: A generalized empirical likelihood approach\",\n                \"Missing the missing values: The ugly duckling of fairness in machine learning\",\n                \"In Search of Lost Domain Generalization\",\n                \"Fairness Without Demographics in Repeated Loss Minimization\",\n                \"Does Distributionally Robust Supervised Learning Give Robust Classifiers?\",\n                \"Null-sampling for Interpretable and Fair Representations\",\n                \"Exponentiated gradient versus gradient descent for linear predictors\",\n                \"Fairness without demographics through adversarially reweighted learning\",\n                \"Gradient-based learning applied to document recognition\",\n                \"Large-Scale Methods for Distributionally Robust Optimization\",\n                \"Just Train Twice: Improving Group Robustness without Training Group Information\",\n                \"Deep learning face attributes in the wild\",\n                \"Domain Generalization using Causal Matching\",\n                \"Graphical models for recovering probabilistic and causal queries from missing data\",\n                \"Agnostic Federated Learning\",\n                \"Invariant Representations without Adversarial Training\",\n                \"Stochastic gradient methods for distributionally robust optimization with f-divergences\",\n                \"Hidden stratification causes clinically meaningful failures in machine learning for medical imaging\",\n                \"Distributionally Robust Language Modeling\",\n                \"PyTorch: An Imperative Style, High-Performance Deep Learning Library\",\n                \"Distributionally Robust Optimization: A Review\",\n                \"Justice as fairness: A restatement\",\n                \"Hodgelets: Localized Spectral Representations of Flows on Simplicial Complexes\",\n                \"Inference and missing data\",\n                \"Distributionally robust neural networks\",\n                \"An investigation of why overparameterization exacerbates spurious correlations\",\n                \"Lectures on stochastic programming: modeling and theory\",\n                \"No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classification Problems\",\n                \"The caltech-ucsd birds-200-2011 dataset\",\n                \"Robust Optimization for Fairness with Noisy Protected Groups\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]6 based on the context and research area of Towards Group Robustness in the presence of Partial Group Labels. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}