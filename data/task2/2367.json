{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Quantum Radon Transform and Its Application\n\nPaper Abstract: \n\nPaper Section Text:\nLet f𝑓f be an N×N𝑁𝑁N\\times N image, where N=2n𝑁superscript2𝑛N=2^{n}, and f​(i,j)≥0𝑓𝑖𝑗0f(i,j)\\geq 0 is the image intensity at point (i,j)𝑖𝑗(i,j), then its Real Ket representation is The NEQR representation of image f𝑓f is In this paper, we use the Real Ket representation of images in the quantum computation framework. The famous quantum Fourier transform  and HHL algorithm [ref]37 are both based on this amplitude encoding method. Unless otherwise specified, the term ‘quantum image’ refers to an image encoded with the Real Ket method. To show the connection between the above two representation methods, we need an efficient operation called conditional rotation [ref]37 [ref]38: Let a𝑎a be the k𝑘k-bit finite precision representation of a positive number that is smaller than 1. Then the following mapping can be performed in time O(k2.5superscript𝑘2.5k^{2.5}): Let a:=∑i∈[k]2−i−1​aiassign𝑎subscript𝑖delimited-[]𝑘superscript2𝑖1subscript𝑎𝑖a:=\\displaystyle\\sum_{i\\in[k]}2^{-i-1}a_{i}, where ai∈{0,1}subscript𝑎𝑖01a_{i}\\in\\{0,1\\}. Then |ai⟩ketsubscript𝑎𝑖|a_{i}\\rangle is the (i+1)𝑖1(i+1)-st qubit of |a⟩=|ak−1⟩​⋯​|a1⟩​|a0⟩ket𝑎ketsubscript𝑎𝑘1⋯ketsubscript𝑎1ketsubscript𝑎0|a\\rangle=|a_{k-1}\\rangle\\cdots|a_{1}\\rangle|a_{0}\\rangle counted from right. For s>0𝑠0s>0, define 1-qubit quantum gate Then it holds that By performing the following k𝑘k successive 1-bit conditional rotations: for each i∈[k]𝑖delimited-[]𝑘i\\in[k] the corresponding rotation is R2−(i+1)αisubscriptsuperscript𝑅subscript𝛼𝑖superscript2𝑖1R^{\\alpha_{i}}_{2^{-(i+1)}} where αj∈{0,1}subscript𝛼𝑗01\\alpha_{j}\\in\\{0,1\\} is the control bit, on the last qubit of |a⟩​|0⟩ket𝑎ket0|a\\rangle|0\\rangle, one gets By Lemma 484848 in , given |a⟩ket𝑎|a\\rangle where a∈(0,1)𝑎01a\\in(0,1), using Taylor series approximation allows to prepare the state |arccos⁡(a)⟩ket𝑎|\\arccos(a)\\rangle in time O(k2.5)superscript𝑘2.5(k^{2.5}), where arccos⁡(a)∈[0,π2)𝑎0𝜋2\\arccos(a)\\in[0,\\frac{\\pi}{2}). So with the help of ancilla qubits and (18), the following sequence of mappings can be implemented in time O(k2.5)superscript𝑘2.5(k^{2.5}): ∎ By the following proposition, a Real Ket image can be prepared from its NEQR version, and this preparation procedure is efficient if the condition number κ:=mini,j∈[N]⁡|f​(i,j)|maxi,j∈[N]⁡|f​(i,j)|assign𝜅subscript𝑖𝑗delimited-[]𝑁𝑓𝑖𝑗subscript𝑖𝑗delimited-[]𝑁𝑓𝑖𝑗\\kappa:=\\frac{\\min_{i,j\\in[N]}|f(i,j)|}{\\max_{i,j\\in[N]}|f(i,j)|}\nis large enough. Let a→→𝑎\\vec{a} be a real vector realized by a unitary operator U:|i⟩​|0⟩→|i⟩​|ai⟩:𝑈→ket𝑖ket0ket𝑖ketsubscript𝑎𝑖U:|i\\rangle|0\\rangle\\rightarrow|i\\rangle|a_{i}\\rangle, i∈[N]𝑖delimited-[]𝑁i\\in[N] where aisubscript𝑎𝑖a_{i} is the m𝑚m-bit finite precision representation of the vector entries, and U𝑈U can be performed in time O(TU)subscript𝑇𝑈(T_{U}). Given am​a​x=maxj⁡|aj|subscript𝑎𝑚𝑎𝑥subscript𝑗subscript𝑎𝑗a_{max}=\\max_{j}|a_{j}|, the state |a→⟩ket→𝑎|\\vec{a}\\rangle can be prepared in time O(TU+poly(m,logN))κ2)(\\frac{T_{U}+\\emph{poly}(m,\\log N))}{\\kappa^{2}}) by the following mapping: where 1) |a→⟩:=∑i∈[N]ai‖a→‖2​|i⟩assignket→𝑎subscript𝑖delimited-[]𝑁subscript𝑎𝑖subscriptnorm→𝑎2ket𝑖|\\vec{a}\\rangle:=\\displaystyle\\sum_{i\\in[N]}\\frac{a_{i}}{||\\vec{a}||_{2}}|i\\rangle; 2) a→⟂superscript→𝑎perpendicular-to\\vec{a}^{\\perp} denotes the vector of entries ai⟂:=1−|aiam​a​x|2assignsubscriptsuperscript𝑎perpendicular-to𝑖1superscriptsubscript𝑎𝑖subscript𝑎𝑚𝑎𝑥2a^{\\perp}_{i}:=\\sqrt{1-|\\frac{a_{i}}{a_{max}}|^{2}} for i∈[N]𝑖delimited-[]𝑁i\\in[N]; 3) the coefficient cos⁡θ=‖a→‖22N​amax2≥mini∈[N]⁡|ai|maxi∈[N]⁡|ai|:=κ𝜃subscriptsuperscriptnorm→𝑎22𝑁subscriptsuperscript𝑎2subscript𝑖delimited-[]𝑁subscript𝑎𝑖subscript𝑖delimited-[]𝑁subscript𝑎𝑖assign𝜅\\cos\\theta=\\sqrt{\\frac{||\\vec{a}||^{2}_{2}}{Na^{2}_{\\max}}}\\geq\\frac{\\min\\limits_{i\\in[N]}|a_{i}|}{\\max\\limits_{i\\in[N]}|a_{i}|}:=\\kappa, and κ𝜅\\kappa is called the condition number of vector |a⟩ket𝑎|a\\rangle. With the number am​a​xsubscript𝑎𝑚𝑎𝑥a_{max} and unitary operator U𝑈U at hand, we can implement the following transform [ref]37: We first perform the this transform on the input state ∑i∈[N]1N​|i⟩​|ai⟩subscript𝑖delimited-[]𝑁1𝑁ket𝑖ketsubscript𝑎𝑖\\displaystyle\\sum_{i\\in[N]}\\frac{1}{\\sqrt{N}}|i\\rangle|a_{i}\\rangle and then use the rotation conditioned on |aiam​a​x⟩ketsubscript𝑎𝑖subscript𝑎𝑚𝑎𝑥|\\frac{a_{i}}{a_{max}}\\rangle (cf. Proposition 3): and finally undo U𝑈U to clear the second register. After the above operations, we measure the last qubit. The running time of the above procedure is O(TU+poly​(m,log⁡N))subscript𝑇𝑈poly𝑚𝑁(T_{U}+\\text{poly}(m,\\log N)). The expected result |0⟩ket0|0\\rangle by measurement has probability ∑i∈[N]ai2N​am​a​x2≥am​i​n2am​a​x2=κ2subscript𝑖delimited-[]𝑁subscriptsuperscript𝑎2𝑖𝑁subscriptsuperscript𝑎2𝑚𝑎𝑥subscriptsuperscript𝑎2𝑚𝑖𝑛subscriptsuperscript𝑎2𝑚𝑎𝑥superscript𝜅2\\frac{\\sum_{i\\in[N]}a^{2}_{i}}{Na^{2}_{max}}\\geq\\frac{a^{2}_{min}}{a^{2}_{max}}=\\kappa^{2}, which indicates that we have successfully prepared the state |a→⟩:=∑i∈[N]ai‖a→‖2​|i⟩assignket→𝑎subscript𝑖delimited-[]𝑁subscript𝑎𝑖subscriptnorm→𝑎2ket𝑖|\\vec{a}\\rangle:=\\displaystyle\\sum_{i\\in[N]}\\frac{a_{i}}{||\\vec{a}||_{2}}|i\\rangle.\n∎ Remark: It is also possible to convert a Real Ket image to its NEQR version by applying phase estimations . The close connections between different image representations give researchers more confidence in developing quantum image processing tools based on a particular representation, as they are likely to become universal once quantum techniques are sufficiently developed. Quantum image preparation, also known as quantum (initial) state preparation, has been extensively studied over years, e.g.,   [ref]38.\nCurrent techniques allow to efficiently prepare the Real Ket (or NEQR) state of an N×N𝑁𝑁N\\times N image in time O​(polylog​N)𝑂polylog𝑁O(\\text{polylog}N) if the prepared image has some special structures111such as the corresponding quantum data structure [ref]38 is given or the quantum state to be prepared has a well condition number .. The time required to prepare an arbitrary quantum image is at most no more than the classical preparation time, up to a logarithmic factor. Specifically, a quantum image of form (13) or (14) can be prepared by applying at most N2superscript𝑁2N^{2} conditional operations, each of which has a time complexity polylog(N𝑁N). The following proposition will be used in Section V. It states that the inner products of quantum states can be estimated in parallel: . Given 2​N2𝑁2N quantum states |u→0⟩ketsubscript→𝑢0|\\vec{u}_{0}\\rangle, |v→0⟩​…​|u→N−1⟩ketsubscript→𝑣0…ketsubscript→𝑢𝑁1|\\vec{v}_{0}\\rangle...|\\vec{u}_{N-1}\\rangle, |v→N−1⟩ketsubscript→𝑣𝑁1|\\vec{v}_{N-1}\\rangle, and two state preparation unitaries: |k⟩​|0⟩→|k⟩​|u→k⟩→ket𝑘ket0ket𝑘ketsubscript→𝑢𝑘|k\\rangle|0\\rangle\\rightarrow|k\\rangle|\\vec{u}_{k}\\rangle and |k⟩​|0⟩→|k⟩​|v→k⟩→ket𝑘ket0ket𝑘ketsubscript→𝑣𝑘|k\\rangle|0\\rangle\\rightarrow|k\\rangle|\\vec{v}_{k}\\rangle (where k∈[N]𝑘delimited-[]𝑁k\\in[N]) that can be implemented in time O(Ti​n)subscript𝑇𝑖𝑛(T_{in}). There is a quantum algorithm with runtime O(Ti​nϵ)subscript𝑇𝑖𝑛italic-ϵ(\\frac{T_{in}}{\\epsilon}) to achieve\n|i⟩​|0⟩→|i⟩​|si⟩→ket𝑖ket0ket𝑖ketsubscript𝑠𝑖|i\\rangle|0\\rangle\\rightarrow|i\\rangle|s_{i}\\rangle for all i∈[N]𝑖delimited-[]𝑁i\\in[N], where |si−⟨u→i|v→i⟩|≤ϵsubscript𝑠𝑖inner-productsubscript→𝑢𝑖subscript→𝑣𝑖italic-ϵ|s_{i}-\\langle\\vec{u}_{i}|\\vec{v}_{i}\\rangle|\\leq\\epsilon. A detailed proof can be found in Theorem 1 in .\n\nReference markers found: [37]\n\nContext windows for each [ref]:\n[ref]37: is The NEQR representation of image f𝑓f is In this paper, we use the Real Ket representation of images in the quantum computation framework. The famous quantum Fourier transform  and HHL algorithm [ref]37 are both based on this amplitude encoding method. Unless otherwise specified, the term ‘quantum image’ refers to an image encoded with the Real Ket method. To show the connection between the\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 37,\n            \"titles\": [\n                \"Quantum Recommendation Systems\",\n                \"Über die bestimmung von funktionen durch ihre integralwerte längs gewisser mannigfaltigkeiten\",\n                \"The Radon transform and some of its applications\",\n                \"Image denoising using orthonormal finite ridgelet transform\",\n                \"Discrete Radon transform\",\n                \"The Radon transform-theory and implementation\",\n                \"The fast discrete Radon transform. i. theory\",\n                \"Discrete periodic radon transform based weighted nuclear norm minimization for image denoising\",\n                \"Fast and parallel computation of the discrete periodic radon transform on gpus, multicore cpus and fpgas\",\n                \"Image representation via a finite Radon transform\",\n                \"The discrete periodic Radon transform\",\n                \"Reconstruction of tomographic images using analog projections and the digital Radon transform\",\n                \"Projective transforms on periodic discrete image arrays\",\n                \"Computational complexity lower bounds of certain discrete Radon transform approximations\",\n                \"Quantum algorithm design: Techniques and applications\",\n                \"Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer\",\n                \"Grover’s quantum searching algorithm is optimal\",\n                \"Quantum Computation and Quantum Information\",\n                \"Advances in the quantum theoretical approach to image processing applications\",\n                \"Quantum image processing (quip)\",\n                \"A survey of quantum image representations\",\n                \"A flexible representation of quantum images for polynomial preparation, image compression, and processing operations\",\n                \"Multi-dimensional color image storage and retrieval for a normal arbitrary quantum superposition state\",\n                \"Storing, processing, and retrieving an image using quantum mechanics\",\n                \"Image compression and entanglement\",\n                \"NEQR: a novel enhanced quantum representation of digital images\",\n                \"Quantum wavelet transforms: Fast algorithms and complete circuits\",\n                \"Qsobel: a novel quantum image edge extraction algorithm\",\n                \"Quantum image processing and its application to edge detection: theory and experiment\",\n                \"Histogram-based segmentation of quantum images\",\n                \"A dynamic watermarking scheme for quantum images using quantum wavelet transform\",\n                \"A block-based quantum image scrambling for gneqr\",\n                \"The fast Fourier transform\",\n                \"Generalised finite Radon transform for n× n images\",\n                \"Orthogonal discrete Radon transform over pn×pn images\",\n                \"A review of image denoising algorithms, with a new one\",\n                \"Ideal spatial adaptation by wavelet shrinkage\",\n                \"Quantum algorithm for linear systems of equations\",\n                \"Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics\",\n                \"Quantum machine learning\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]37 based on the context and research area of Quantum Radon Transform and Its Application. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}