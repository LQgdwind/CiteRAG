{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Revealing Unfair Models by Mining Interpretable Evidence\n\nPaper Abstract: \n\nPaper Section Text:\nIn this subsection, we first define the RUMIE task. Then we propose a probabilistic framework to model the RUMIE task as a continuous optimization problem. Last, we discuss the key idea to incorporate some other group fairness measurements into our framework. Given a classification model gğ‘”g, a set of data instances ğ’Ÿğ’Ÿ\\mathcal{D}, and a set of sensitive attributes ğ’œğ’œ\\mathcal{A} that may be potentially related to the discrimination of gğ‘”g on groups of instances in ğ’Ÿğ’Ÿ\\mathcal{D}, the task of revealing unfair models by mining interpretable evidence (RUMIE) is to find the group of data instances, denoted by ğ’®âŠ‚ğ’Ÿğ’®ğ’Ÿ\\mathcal{S}\\subset\\mathcal{D}, that is the most discriminated by the model gğ‘”g; and interpret the discrimination on the data instances in ğ’®ğ’®\\mathcal{S} by finding a small set of key attributes, denoted by ğ’¬âŠ†ğ’œğ’¬ğ’œ\\mathcal{Q}\\subseteq\\mathcal{A}, such that the data instances in ğ’®ğ’®\\mathcal{S} are separated from those in ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S} in the feature space of ğ’¬ğ’¬\\mathcal{Q}. Here, the feature space of ğ’¬ğ’¬\\mathcal{Q}, denoted by ğš‚ğš™ğšŠğšŒğšğ’¬superscriptğš‚ğš™ğšŠğšŒğšğ’¬\\mathtt{Space}^{\\mathcal{Q}}, is the space where a data instance is represented by the attributes in ğ’¬ğ’¬\\mathcal{Q}.\nThe discriminated group ğ’®ğ’®\\mathcal{S} is said to be separated from ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S} in ğš‚ğš™ğšŠğšŒğšğ’¬superscriptğš‚ğš™ğšŠğšŒğšğ’¬\\mathtt{Space}^{\\mathcal{Q}} if ğ’®ğ’®\\mathcal{S} and ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S} are classified as two different classes by the classification boundary of a binary classifier in ğš‚ğš™ğšŠğšŒğšğ’¬superscriptğš‚ğš™ğšŠğšŒğšğ’¬\\mathtt{Space}^{\\mathcal{Q}}. To clearly explain to an end user why and how ğ’®ğ’®\\mathcal{S} is separated from ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S},\nwe also want the classification boundary separating ğ’®ğ’®\\mathcal{S} and ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S} to be simple.\nHere, a classification boundary is said to be simple if the partitions of data set ğ’Ÿğ’Ÿ\\mathcal{D} induced by the classification boundary have a small minimum description length.\nFor example, a linear classification boundary of a logistic regression classifier is said to be simpler than a non-linear classification boundary of a deep neural network. We refer to (ğ’®,ğ’¬)ğ’®ğ’¬(\\mathcal{S},\\mathcal{Q}) as the interpretable evidence to demonstrate the unfairness of gğ‘”g.\nThe discriminated group ğ’®ğ’®\\mathcal{S} is the evidence to demonstrate the unfairness of gğ‘”g because ğ’®ğ’®\\mathcal{S} is discriminated the most by gğ‘”g.\nA higher discrimination score on ğ’®ğ’®\\mathcal{S} means more unfairness exists in gğ‘”g.\nThe set of key attributes ğ’¬ğ’¬\\mathcal{Q} allows us to interpret the reason behind the discrimination of ğ’®ğ’®\\mathcal{S} because these attributes are used to separate the discriminated group ğ’®ğ’®\\mathcal{S} from the other group ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S}. A simpler classification boundary to separate ğ’®ğ’®\\mathcal{S} and ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S} in ğš‚ğš™ğšŠğšŒğšğ’¬superscriptğš‚ğš™ğšŠğšŒğšğ’¬\\mathtt{Space}^{\\mathcal{Q}} indicates the existence of the discriminated group is less possible by chance, and thus is more significant. Tackling the RUMIE task requires to\nfind the optimal set of ğ’®ğ’®\\mathcal{S} that maximizes the discrimination score Dâ€‹Sâ€‹câ€‹oâ€‹râ€‹eâ€‹(ğ’®)ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ’®DScore(\\mathcal{S}); and it also requires to find a small set of sensitive attributes denoted by ğ’¬ğ’¬\\mathcal{Q} such that ğ’®ğ’®\\mathcal{S} and ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S} are well separated by a simple decision boundary in ğš‚ğš™ğšŠğšŒğšğ’¬superscriptğš‚ğš™ğšŠğšŒğšğ’¬\\mathtt{Space}^{\\mathcal{Q}}.\nThis can be done by a brute-force search approach that enumerates all values of ğ’®ğ’®\\mathcal{S} and ğ’¬ğ’¬\\mathcal{Q} to find their optimal values.\nHowever, the brute-force search approach does not scale up well on large data sets, because the time cost grows exponentially with respect to the size of ğ’Ÿğ’Ÿ\\mathcal{D} and ğ’œğ’œ\\mathcal{A}. To efficiently tackle the RUMIE task, we propose a probabilistic framework to model it as a continuous optimization problem, which can be efficiently solved by a gradient-based optimization methodÂ . The key idea is to model the discrete variables ğ’®ğ’®\\mathcal{S} and ğ’¬ğ’¬\\mathcal{Q} by functions of continuous variables, and then formulate the optimization objective of RUMIE as a continuous function. First, we model ğ’®ğ’®\\mathcal{S} as a random set of data instances, where the probability of a data instance ğ±âˆˆğ’Ÿğ±ğ’Ÿ\\mathbf{x}\\in\\mathcal{D} belonging to ğ’®ğ’®\\mathcal{S} is modelled by\n Here, Ïƒğ’œâ€‹(ğ±)subscriptğœğ’œğ±\\sigma_{\\mathcal{A}}(\\mathbf{x}) is the projection of ğ±ğ±\\mathbf{x} to the feature space ğš‚ğš™ğšŠğšŒğšğ’œsuperscriptğš‚ğš™ğšŠğšŒğšğ’œ\\mathtt{Space}^{\\mathcal{A}} of the attributes in ğ’œğ’œ\\mathcal{A}, fğœ½:ğš‚ğš™ğšŠğšŒğšğ’œâ†’ :subscriptğ‘“ğœ½â†’superscriptğš‚ğš™ğšŠğšŒğšğ’œ01f_{\\bm{\\theta}}:\\mathtt{Space}^{\\mathcal{A}}\\rightarrow  is a continuous function parametrized by a vector ğœ½ğœ½\\bm{\\theta} with |ğ’œ|ğ’œ{|\\mathcal{A}|} entries, and |ğ’œ|ğ’œ|\\mathcal{A}| is the number of attributes in ğ’œğ’œ\\mathcal{A}. Every entry in ğœ½ğœ½\\bm{\\theta} is a continuous real-valued variable. For a given set of data instances ğ’Ÿğ’Ÿ\\mathcal{D}, the distribution of ğ’®ğ’®\\mathcal{S} is determined by ğœ½ğœ½\\bm{\\theta}.\nTherefore, ğ’®ğ’®\\mathcal{S} is a function of the continuous variables in ğœ½ğœ½\\bm{\\theta}. Second, we model ğ’¬ğ’¬\\mathcal{Q} as a function of continuous variables by formulating fğœ½subscriptğ‘“ğœ½f_{\\bm{\\theta}} as a logistic regression classifier, that is, where the none-zero entries in ğœ½ğœ½\\bm{\\theta} correspond to the set of key attributes ğ’¬âˆˆğ’œğ’¬ğ’œ\\mathcal{Q}\\in\\mathcal{A} because the data instances in ğ’®ğ’®\\mathcal{S} and ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S} are well separated by the simple linear decision boundary induced by fğœ½subscriptğ‘“ğœ½f_{\\bm{\\theta}} in ğš‚ğš™ğšŠğšŒğšğ’¬superscriptğš‚ğš™ğšŠğšŒğšğ’¬\\mathtt{Space}^{\\mathcal{Q}}.\nSince the value of ğ’¬ğ’¬\\mathcal{Q} is determined by ğœ½ğœ½\\bm{\\theta}, ğ’¬ğ’¬\\mathcal{Q} is a function of continuous variables. As illustrated later, we will enhance the interpretability of ğ’¬ğ’¬\\mathcal{Q} by reducing the size of ğ’¬ğ’¬\\mathcal{Q} with a sparsity constraint on ğœ½ğœ½{\\bm{\\theta}} and generate a set of more interpretable rules by distilling fğœ½subscriptğ‘“ğœ½f_{\\bm{\\theta}} into a simple decision tree. Third, we introduce how to formulate the optimization objective of the RUMIE task as a continuous function of ğœ½ğœ½\\bm{\\theta}. Since the RUMIE task requires to find the group of data instances that is the most discriminated by the model gğ‘”g, we need to find a discriminated group ğ’®ğ’®\\mathcal{S} that maximizes the discrimination score Dâ€‹Sâ€‹câ€‹oâ€‹râ€‹eâ€‹(ğ’®)ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ’®DScore(\\mathcal{S}) in EquationÂ (2). Since we model ğ’®ğ’®\\mathcal{S} as a random set of data instances parametrized by ğœ½ğœ½\\bm{\\theta}, the discrimination score Dâ€‹Sâ€‹câ€‹oâ€‹râ€‹eâ€‹(ğ’®)ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ’®DScore(\\mathcal{S}) is a real-valued random variable, which cannot be straight-forwardly maximized.\nTherefore, instead of directly maximizing the random variable Dâ€‹Sâ€‹câ€‹oâ€‹râ€‹eâ€‹(ğ’®)ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ’®DScore(\\mathcal{S}), we seek to maximize its expectation where ğ”¼â€‹[â„™â€‹(ğšğšŠğšŸâˆ£ğ’Ÿâˆ–ğ’®)]ğ”¼delimited-[]â„™conditionalğšğšŠğšŸğ’Ÿğ’®\\mathbb{E}[\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{D}\\setminus\\mathcal{S})] and ğ”¼â€‹[â„™â€‹(ğšğšŠğšŸâˆ£ğ’®)]ğ”¼delimited-[]â„™conditionalğšğšŠğšŸğ’®\\mathbb{E}[\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{S})] are the expectations of â„™â€‹(ğšğšŠğšŸâˆ£ğ’®)â„™conditionalğšğšŠğšŸğ’®\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{S}) and â„™â€‹(ğšğšŠğšŸâˆ£ğ’Ÿâˆ–ğ’®)â„™conditionalğšğšŠğšŸğ’Ÿğ’®\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{D}\\setminus\\mathcal{S}), respectively.\nHere, â„™â€‹(ğšğšŠğšŸâˆ£ğ’®)â„™conditionalğšğšŠğšŸğ’®\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{S}) and â„™â€‹(ğšğšŠğšŸâˆ£ğ’Ÿâˆ–ğ’®)â„™conditionalğšğšŠğšŸğ’Ÿğ’®\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{D}\\setminus\\mathcal{S}) are random variables because ğ’®ğ’®\\mathcal{S} is a random set of data instances. Recall that â„™â€‹(ğšğšŠğšŸâˆ£ğ’®)â„™conditionalğšğšŠğšŸğ’®\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{S}) is the probability of a data instance ğ±ğ±\\mathbf{x} receiving a favorable prediction from gğ‘”g when it is uniformly sampled from ğ’®ğ’®\\mathcal{S}. We write â„™â€‹(ğšğšŠğšŸâˆ£ğ’®)â„™conditionalğšğšŠğšŸğ’®\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{S}) as where ğŸ™ğšğšŠğšŸâ€‹(ğ±)âˆˆ{0,1}subscript1ğšğšŠğšŸğ±01\\mathbbm{1}_{\\mathtt{fav}}(\\mathbf{x})\\in\\{0,1\\} is an indicator function that is equal to 1 only if gğ‘”g makes a favorable prediction on ğ±ğ±\\mathbf{x}; and ğŸ™â€‹(ğ±âˆˆğ’®)âˆˆ{0,1}1ğ±ğ’®01\\mathbbm{1}(\\mathbf{x}\\in\\mathcal{S})\\in\\{0,1\\} is an indicator function that is equal to 1 only if ğ±âˆˆğ’®ğ±ğ’®\\mathbf{x}\\in\\mathcal{S}. Since every data instance ğ±ğ±\\mathbf{x} has a probability of â„™â€‹(ğ±âˆˆğ’®)â„™ğ±ğ’®\\mathbb{P}(\\mathbf{x}\\in\\mathcal{S}) to belong to ğ’®ğ’®\\mathcal{S}, the indicator function\nğŸ™â€‹(ğ±âˆˆğ’®)1ğ±ğ’®\\mathbbm{1}(\\mathbf{x}\\in\\mathcal{S}) is a random variable following a Bernoulli distribution, and its expectation is Since the numerator and denominator in EquationÂ (6) are conditionally independent given ğœ½ğœ½{\\bm{\\theta}}, we have Similarly, we can derive\n where â„™â€‹(ğ±âˆˆğ’Ÿâˆ–ğ’®)=1âˆ’â„™â€‹(ğ±âˆˆğ’®)â„™ğ±ğ’Ÿğ’®1â„™ğ±ğ’®\\mathbb{P}(\\mathbf{x}\\in\\mathcal{D}\\setminus\\mathcal{S})=1-\\mathbb{P}(\\mathbf{x}\\in\\mathcal{S}) is the probability of an instance ğ±ğ±\\mathbf{x} not belonging to ğ’®ğ’®\\mathcal{S}. Recall that â„™â€‹(ğ±âˆˆğ’®)=fğœ½â€‹(Ïƒğ’œâ€‹(ğ±))â„™ğ±ğ’®subscriptğ‘“ğœ½subscriptğœğ’œğ±\\mathbb{P}(\\mathbf{x}\\in\\mathcal{S})=f_{\\bm{\\theta}}(\\sigma_{\\mathcal{A}}(\\mathbf{x})) is a function of ğœ½ğœ½\\bm{\\theta}. Thus both ğ”¼â€‹[â„™â€‹(ğšğšŠğšŸâˆ£ğ’®)]ğ”¼delimited-[]â„™conditionalğšğšŠğšŸğ’®\\mathbb{E}[\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{S})] and ğ”¼â€‹[â„™â€‹(ğšğšŠğšŸâˆ£ğ’Ÿâˆ–ğ’®)]ğ”¼delimited-[]â„™conditionalğšğšŠğšŸğ’Ÿğ’®\\mathbb{E}[\\mathbb{P}(\\mathtt{fav}\\mid\\mathcal{D}\\setminus\\mathcal{S})] are real-valued functions of ğœ½ğœ½\\bm{\\theta}. Therefore, ğ”¼â€‹[Dâ€‹Sâ€‹câ€‹oâ€‹râ€‹eâ€‹(ğ’®)]ğ”¼delimited-[]ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ’®\\mathbb{E}[DScore(\\mathcal{S})] is a rea-valued function of ğœ½ğœ½\\bm{\\theta}, which can be maximized with respect to ğœ½ğœ½\\bm{\\theta}. Last, we model the RUMIE task as the following continuous optimization problem, which aims to maximize the expected discrimination score on ğ’®ğ’®\\mathcal{S}. where Î»>0ğœ†0\\lambda>0, Î±âˆˆ ğ›¼01\\alpha\\in  and Î²âˆˆ ğ›½01\\beta\\in , Î±â‰¤Î²ğ›¼ğ›½\\alpha\\leq\\beta, are positive real-valued hyper-parameters, ğ”¼â€‹[|ğ’®|]ğ”¼delimited-[]ğ’®\\mathbb{E}[|\\mathcal{S}|] is the expected size of ğ’®ğ’®\\mathcal{S} and |ğ’Ÿ|ğ’Ÿ|\\mathcal{D}| is the size of ğ’Ÿğ’Ÿ\\mathcal{D}. The second term Î»âˆ—ğ’â€‹(k,ğœ½)ğœ†ğ’ğ‘˜ğœ½\\lambda*\\mathcal{C}(k,\\bm{\\theta}) in the objective of the optimization problem is a regularization term that reduces the size of ğ’¬ğ’¬\\mathcal{Q} to enhance the interpretability of the discrimination evidence. Here kğ‘˜k refers to size of ğ’¬ğ’¬\\mathcal{Q} and implies the maximum number of sensitive attributes to be considered for distinguishing ğ’®ğ’®\\mathcal{S} from ğ’Ÿâˆ–ğ’®ğ’Ÿğ’®\\mathcal{D}\\setminus\\mathcal{S}. Choosing kğ‘˜k provides the user with the flexibility to adjust the interpretability as per their needs.\nThe term is the L-1 reduced penalization term adopted fromÂ    . The function sâ€‹mâ€‹aâ€‹lâ€‹lâ€‹eâ€‹sâ€‹tâ€‹(ğœ½,j)ğ‘ ğ‘šğ‘ğ‘™ğ‘™ğ‘’ğ‘ ğ‘¡ğœ½ğ‘—smallest(\\bm{\\theta},j) returns the jğ‘—j-th smallest absolute value of the entries in ğœ½ğœ½{\\bm{\\theta}}. Maximizing the objective minimizes the term ğ’â€‹(k,ğœ½)ğ’ğ‘˜ğœ½\\mathcal{C}(k,\\bm{\\theta}), which enforces the vector ğœ½ğœ½{\\bm{\\theta}} to contain kğ‘˜k effective non-zero entries while squeezing the rest of the entries to be very small or zeroÂ  .\nAfter finding a solution ğœ½âˆ—superscriptğœ½\\bm{\\theta}^{*} to the continuous optimization problem, we strictly enforce the maximum limit of kğ‘˜k sensitive attributes by keeping only the kğ‘˜k entries with the largest absolute values in ğœ½âˆ—superscriptğœ½\\bm{\\theta}^{*} and setting the other entries in ğœ½âˆ—superscriptğœ½\\bm{\\theta}^{*} to zero. Comparing to using the L1-norm of ğœ½ğœ½\\bm{\\theta} as a regularization term to induce the sparsity of ğœ½ğœ½\\bm{\\theta}, ğ’â€‹(k,ğœ½)ğ’ğ‘˜ğœ½\\mathcal{C}(k,\\bm{\\theta}) provides a better control on the number of non-zero entries in ğœ½ğœ½\\bm{\\theta}Â   .\nA small value of kğ‘˜k leads to a small set of ğ’¬ğ’¬\\mathcal{Q} thus produces a clear interpretation for the reason behind discrimination of a group. In the constraint of the optimization problem,\nÎ±ğ›¼\\alpha and Î²ğ›½\\beta constrain the expected proportion taken by ğ’®ğ’®\\mathcal{S} in ğ’Ÿğ’Ÿ\\mathcal{D}. Since different end users may be interested in different sizes of discriminated instance groups for different applications, the thresholds Î±ğ›¼\\alpha and Î²ğ›½\\beta provide a good flexibility to suit the needs of different end users.\nFor example, a bankâ€™s fairness policy may only be violated if at least 20% of its clients are being discriminated by a deployed AI lender model. Next, we discuss how to incorporate some other group fairness measurements, such as disparate impactÂ , difference of F1-scoresÂ , equal oddsÂ , and equal opportunitiesÂ  into the proposed framework. The key idea is to extend a fairness measurement into a discrimination score Dâ€‹Sâ€‹câ€‹oâ€‹râ€‹eâ€‹(ğ’®)ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ’®DScore(\\mathcal{S}), and then compute the expected discrimination score ğ”¼â€‹[Dâ€‹Sâ€‹câ€‹oâ€‹râ€‹eâ€‹(ğ’®)]ğ”¼delimited-[]ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ’®\\mathbb{E}[DScore(\\mathcal{S})] on the distribution of ğ’®ğ’®\\mathcal{S}.\nSince the distribution of ğ’®ğ’®\\mathcal{S} is parameterized by ğœ½ğœ½\\bm{\\theta}, ğ”¼â€‹[Dâ€‹Sâ€‹câ€‹oâ€‹râ€‹eâ€‹(ğ’®)]ğ”¼delimited-[]ğ·ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’ğ’®\\mathbb{E}[DScore(\\mathcal{S})] is a continuous function of ğœ½ğœ½\\bm{\\theta}, and it can be directly plugged in EquationÂ (11) to formulate a continuous optimization problem for the RUMIE task. It is straight-forward to extend a fairness measurement to a discrimination score.\nThe real-valued measurements such as difference of F1-scoresÂ  and disparate impactÂ  can be directly used as discrimination scores and can be optimized with respect to ğœ½ğœ½\\bm{\\theta}.\nThe boolean measurements such as equal oddsÂ , and equal opportunitiesÂ  can be extended to a real-valued discrimination score in a similar way as we extend demographic parityÂ  4 [ref]22.\nDeriving the expectation of a discriminated score on the distribution of ğ’®ğ’®\\mathcal{S} is straight-forward, thus we skip the details.\n\nReference markers found: [22]\n\nContext windows for each [ref]:\n[ref]22: to ğœ½ğœ½\\bm{\\theta}.\nThe boolean measurements such as equal oddsÂ , and equal opportunitiesÂ  can be extended to a real-valued discrimination score in a similar way as we extend demographic parityÂ  4 [ref]22.\nDeriving the expectation of a discriminated score on the distribution of ğ’®ğ’®\\mathcal{S} is straight-forward, thus we skip the details.\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 22,\n            \"titles\": [\n                \"Satisfying Real-world Goals with Dataset Constraints\",\n                \"Criminal justice forecasts of risk: A machine learning approach\",\n                \"Interpretable machine learning in healthcare\",\n                \"Applications of machine learning in drug discovery and development\",\n                \"Credit risk assessment using statistical and machine learning: basic methodology and risk modeling applications\",\n                \"Machine bias\",\n                \"Amazon just showed us that â€˜unbiasedâ€™ algorithms can be inadvertently racist.\",\n                \"Data preprocessing techniques for classification without discrimination\",\n                \"Bias in Machine Learning Software: Why? How? What to Do?\",\n                \"Fairness-aware classifier with prejudice remover regularizer\",\n                \"Exploiting reject option in classification for social discrimination control\",\n                \"Fair Decision Rules for Binary Classification\",\n                \"Machine learning interpretability: A survey on methods and metrics\",\n                \"Statistical hypothesis testing: theory and methods\",\n                \"Fairness through awareness\",\n                \"A multidisciplinary survey on discrimination analysis\",\n                \"k-nn as an implementation of situation testing for discrimination discovery and prevention\",\n                \"Situation testing-based discrimination discovery: A causal inference approach.\",\n                \"Data mining for discrimination discovery\",\n                \"Fair-db: Functional dependencies to discover data bias.\",\n                \"Fairness testing: testing software for discrimination\",\n                \"Three naive bayes approaches for discrimination-free classification\",\n                \"Fairness in criminal justice risk assessments: The state of the art\",\n                \"Weapons of math destruction: How big data increases inequality and threatens democracy\",\n                \"Automating inequality: How high-tech tools profile, police, and punish the poor\",\n                \"The Frontiers of Fairness in Machine Learning\",\n                \"A comparative study of fairness-enhancing interventions in machine learning\",\n                \"Fairness definitions explained\",\n                \"â€˜Itâ€™s Reducing a Human Being to a Percentageâ€™; Perceptions of Justice in Algorithmic Decisions\",\n                \"Inherent Trade-Offs in the Fair Determination of Risk Scores\",\n                \"Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment\",\n                \"Equality of Opportunity in Supervised Learning\",\n                \"Ai fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias\",\n                \"The What-If Tool: Interactive Probing of Machine Learning Models\",\n                \"Automated Directed Fairness Testing\",\n                \"Certifying and removing disparate impact\",\n                \"Building classifiers with independency constraints\",\n                \"FairFL: A fair federated learning approach to reducing demographic bias in privacy-sensitive classification models\",\n                \"Fairness in learning: Classic and contextual bandits\",\n                \"Empirical Risk Minimization Under Fairness Constraints\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]22 based on the context and research area of Revealing Unfair Models by Mining Interpretable Evidence. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}