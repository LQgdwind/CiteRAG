{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Provenance Graph Kernel\n\nPaper Abstract: \n\nPaper Section Text:\nFor each classification task, in order to ensure the robust evaluation of\nprovenance kernels‚Äô performance compared to that of existing graph kernels and\nthe PNA method, we carry out the following: balancing the input data set (if\nunbalanced), training classifiers with provenance kernels (PK), generic graph\nkernels, and provenance network metrics, measuring the performance of each\nclassifier, and comparing their performance. An overview of the full evaluation\npipeline, implemented in Python, is depicted in Fig.¬†4. Data balancing The MIMIC and CollabMap data sets are significantly\nskewed, being originated from real-world human activities. Therefore, for those\ndata sets, we balance the number of samples in each class by selecting all the\nsamples in the minority class and randomly under-sampling the majority class to\nproduce a balanced data set. Table¬†III shows the number of\nsamples used in each classification task after balancing. Classification methods In addition to building classifiers\nfor a classification task in question using provenance kernels,\nwe also build classifiers using existing graph kernels, implemented by\nthe Grakel library¬†[ref]41, and the provenance network metrics\nas proposed in the PNA method¬†3. Provenance Kernels: A provenance kernel is built on provenance types of\ndepth up to a specified level 0‚Äãp‚Äãt0ùëùùë°0pt which may include (1) only the\nPROV generic (application-agnostic) types, i.e. ent, act, and ag, or (2)\napplication-specific types (such as the mimic:Patient and\nmimic:Ward types shown in Fig.¬†1) in addition\nto the PROV generic types. We test both provenance kernels using only generic\ntypes and those including application types in our evaluation; we call the\nformer group PK-G and the latter PK-A. We also evaluate\nprovenance kernels for different levels of 0‚Äãp‚Äãt0ùëùùë°0pt, from 00 to 555.\nHence, the methods we test in these two groups are: G0,\nG1, ‚Ä¶, G5, A0, ‚Ä¶, A5;\nthe first letter in their names denotes whether they use only PROV generic types\n(G) or not (A) and the second denotes the specified\nlevel 0‚Äãp‚Äãt0ùëùùë°0pt; twelve PK-based methods are tested in total. Graph Kernels: The graph kernels we test are Shortest Path (SP)¬†, Vertex Histogram (VH)¬†, Edge\nHistogram (EH)¬†, Graphlet Sampling (GS)¬†, Weisfeiler-Lehman (WL)¬†, Weisfeiler-Lehman Optimal Assignment (WL-OA)¬†, Hadamard Code (HC)¬†, Ordered Dag Decomposition (ODD)¬†, Neighbourhood Hash (NH)¬†, Neighbourhood Subgraph Pairwise Distance\n(NSPD)¬†.333We also\ntested other kernels provided by the Grakel library. However, they\neither timed out or produced errors when processing graphs in our data sets and,\nhence, are not included in our evaluation. Similar to provenance\nkernels, Weisfeiler-Lehman and Hadamard Code kernels can be computed up to a\nspecified level 0‚Äãp‚Äãt0ùëùùë°0pt; we test those kernels with 0‚Äãp‚Äãt‚àà ùëùùë°150pt\\in [ref]5.\nHence, a total of 16 graph kernels are tested. As shown in Fig.¬†4,\nsupport-vector machines (SVM) are used to build classifiers from both provenance\nkernels and generic graph kernels.\nAmong the tested graph kernels, the SP, GS, ODD, NH, NSPD, WL-OA kernels take a\nsignificantly longer time to run compared to the rest. We, therefore, for\ncomparison purposes, put these methods in a group called GK-slow and\nthe remaining kernels in GK-fast. Provenance Network Analytics: The PNA method proposes calculating 22\nnetwork metrics for each provenance graph and using those as the feature vector\nfor that graph. Such feature vectors can be readily taken as inputs by a variety\nof ML algorithms. Since we are uncertain which algorithm works best with\nprovenance network metrics, we test the following classification algorithms over\nthe metrics: Decision Tree (DT), Random Forest (RF), K-Neighbour (KN), Gaussian\nNaive Bayes (NB), Multi-layer Perceptron neural network (NN), and Support Vector\nMachines (SVM). Hence, six methods are tested in total, all are implementations\nby the Scikit-learn library¬† using its default parameters\nfor them. This group of classifiers, which rely on provenance network metrics,\nis called PNA. For any of the above methods that rely on SVM, its Cùê∂C parameter was optimally\nchosen from a grid search (with an inner cross-validation process) over the\nfollowing values {10‚àí4,0.001,0.01,0.1,1.0,10,100,1000}superscript1040.0010.010.11.0101001000\\{10^{-4},0.001,0.01,0.1,1.0,10,100,1000\\} to give\nthe best accuracy. Performance metrics The performance of each method is measured\nby its accuracy in predicting the correct label of a provenance graph (i.e.¬†the\nnumber of correct prediction over the total number of samples), which is\nprovided with the above data sets.\nTo robustly measure the performance, 10-fold cross-validation is employed.\nIn particular, with all the available provenance graphs randomly split into 10\nequal subsets, we perform 10 rounds of\nlearning; on each round, a 1/10110\\nicefrac{{1}}{{10}} subset is held out as the test\nset and the remaining are used as training data.\nThis process is repeated 10 times; hence, 100 measures of accuracy are collected for each method per experiment.\nIn addition, to understand the computation cost of each method, we\nmeasure the time it takes to produce provenance kernels, graph kernels, and\nprovenance network metrics (the yellow step in Fig.¬†4) given the\nsame data set used in a classification task.\nThe time measurements do not include the time taken in training the classifiers nor the time preparing the input GraKeL graphs. Comparing performance Due to the large number of methods\nevaluated from the five groups (i.e.¬†PK-G, PK-A,\nGK-slow, GK-fast, PNA), we report here only\none best-performing method from each group, i.e.¬†the one with the highest mean\nclassification accuracy within its group. We then compare the mean accuracy of\nthe best-performing PK-based methods (i.e.¬†PK-G, PK-A)\nagainst those from the remaining three groups to establish whether PK-based\nmethods offer improved accuracy in the six classification tasks over existing\ngraph kernel and PNA methods. In order to ensure that our comparison results are\nstatistically significant, we carry out the Wilcoxon‚ÄìMann‚ÄìWhitney ranks\ntest¬†[45, Ch. 10], also known as the Wilcoxon rank-sum test, when\ncomparing the accuracy measurements of two methods. If the test produces a\np-value that is less than 0.05, we reject the null hypothesis that states\nthat the accuracy measurements are from the same distribution, i.e¬†one method\nperforms statistically better than the other. Otherwise, both methods are\nconsidered to have a similar level of performance. In addition, in real terms,\nwe disregard accuracy differences of less than 2% and consider the\ncorresponding methods to have a similar level of performance.\n\nReference markers found: [41]\n\nContext windows for each [ref]:\n[ref]41: methods In addition to building classifiers\nfor a classification task in question using provenance kernels,\nwe also build classifiers using existing graph kernels, implemented by\nthe Grakel library¬†[ref]41, and the provenance network metrics\nas proposed in the PNA method¬†3. Provenance Kernels: A provenance kernel is built on provenance types of\ndepth up to a specified level 0‚Äãp‚Äãt0ùëùùë°0pt which\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 41,\n            \"titles\": [\n                \"On Valid Optimal Assignment Kernels and Applications to Graph Classification\",\n                \"PROV-DM: The PROV data model\",\n                \"Enhancing and abstracting scientific workflow provenance for data publishing\",\n                \"Reprozip: Using provenance to support computational reproducibility\",\n                \"Capturing provenance of global change information\",\n                \"A disaster response system based on human-agent collectives\",\n                \"A Survey on Graph Kernels\",\n                \"Graph Kernels: A Survey\",\n                \"Graph Kernels State-of-the-Art and Future Challenges\",\n                \"Shortest-path kernels on graphs\",\n                \"Weisfeiler-Lehman graph kernels\",\n                \"Scalable kernels for graphs with continuous attributes\",\n                \"On graph kernels: Hardness results and efficient alternatives\",\n                \"Provenance Network Analytics\",\n                \"‚ÄúWhy Should I Trust You?‚Äù Explaining the Predictions of Any Classifier\",\n                \"Reproducing Kernel Hilbert Spaces in Probability and Statistics\",\n                \"Aggregation by provenance types: A technique for summarising provenance graphs\",\n                \"Incremental inference of provenance types\",\n                \"Workflow Provenance in the Lifecycle of Scientific Machine Learning\",\n                \"Towards unified data and lifecycle management for deep learning\",\n                \"struc2vec: Learning Node Representations from Structural Identity\",\n                \"Beyond triplets: Hyper-relational knowledge graph embedding for link prediction\",\n                \"Semantic web in data mining and knowledge discovery: A comprehensive survey\",\n                \"RDF2Vec: RDF graph embeddings for data mining\",\n                \"Graph kernels for rdf data\",\n                \"Substructure counting graph kernels for machine learning from rdf data\",\n                \"Nodesketch: Highly-efficient graph embeddings via recursive sketching\",\n                \"DeepWalk: Online Learning of Social Representations\",\n                \"node2vec: Scalable Feature Learning for Networks\",\n                \"A linear-time graph kernel\",\n                \"Fast neighborhood subgraph pairwise distance kernel\",\n                \"A fast approximation of the Weisfeiler-Lehman graph kernel for RDF data\",\n                \"Tree++: Truncated Tree Based Graph Kernels\",\n                \"Biological network comparison using graphlet degree distribution\",\n                \"Efficient graphlet kernels for large graph comparison\",\n                \"Halting in random walk kernels\",\n                \"Hadamard code graph kernels for classifying graphs\",\n                \"MIMIC-III, a freely accessible critical care database\",\n                \"CollabMap: Crowdsourcing maps for emergency planning\",\n                \"The pok√©mon go experience: A location-based augmented reality mobile game goes mainstream\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]41 based on the context and research area of Provenance Graph Kernel. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}