{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Neuro-symbolic Explainable Artificial Intelligence Twin for Zero-touch IoE in Wireless Network\n\nPaper Abstract: \n\nPaper Section Text:\nA tuple X≔(si​jphy,pi​jphy,qi​jphy,δi​jphy,ci​jphy)≔𝑋superscriptsubscript𝑠𝑖𝑗physuperscriptsubscript𝑝𝑖𝑗physuperscriptsubscript𝑞𝑖𝑗physuperscriptsubscript𝛿𝑖𝑗physuperscriptsubscript𝑐𝑖𝑗phyX\\coloneqq(s_{ij}^{\\textrm{phy}},p_{ij}^{\\textrm{phy}},q_{ij}^{\\textrm{phy}},\\delta_{ij}^{\\textrm{phy}},c_{ij}^{\\textrm{phy}}) of contextual metrics at a physical space (i.e., gNB) will play the key role for allocating uplink ui​jexesuperscriptsubscript𝑢𝑖𝑗exeu_{ij}^{\\textrm{exe}} and downlink di​jexesuperscriptsubscript𝑑𝑖𝑗exed_{ij}^{\\textrm{exe}} data transfer rates to each IoE user. Here, it is necessary to meet the IoE service requirements such as amount of upload αi​jreqsuperscriptsubscript𝛼𝑖𝑗req\\alpha_{ij}^{\\textrm{req}} (in (11b) and (11d)), download βi​jreqsuperscriptsubscript𝛽𝑖𝑗req\\beta_{ij}^{\\textrm{req}} data (in (11c) and (11e)), maintaining CQI (in (11f)), end to end communication and computational delay τi​jreqsuperscriptsubscript𝜏𝑖𝑗req\\tau_{ij}^{\\textrm{req}} (in (11g)), and utilization of computational capacity ωisubscript𝜔𝑖\\omega_{i} (in (11h)) become crucial on contextual metrics X𝑋X at the physical space.\nOn top of the proposed implicit learner, we can flexibly deploy numerous regression algorithms [ref]38 [ref]37 such as long short-term memory (LSTM), deep neural network-base regression, extra Trees, random forest, adaboost, and logistic regression based on the service provider requirements. However, the challenge is to determine a maximum likelihood estimation of 𝝃𝝃\\boldsymbol{\\xi} in (1). Thus, we design a least square estimator 𝝃^^𝝃\\hat{\\boldsymbol{\\xi}}    of (1) as follows: where ui​jexe,di​jexe∈𝒀superscriptsubscript𝑢𝑖𝑗exesuperscriptsubscript𝑑𝑖𝑗exe𝒀u_{ij}^{\\textrm{exe}},d_{ij}^{\\textrm{exe}}\\in\\boldsymbol{Y} and X∈𝑿𝑋𝑿X\\in\\boldsymbol{X}. Therefore, (𝒀−𝑿​𝝃^)T​(𝒀−𝑿​𝝃^)superscript𝒀𝑿^𝝃T𝒀𝑿^𝝃(\\boldsymbol{Y}-\\boldsymbol{X}\\hat{\\boldsymbol{\\xi}})^{\\textrm{T}}(\\boldsymbol{Y}-\\boldsymbol{X}\\hat{\\boldsymbol{\\xi}}) is a learning objective of (12).\nThe (12) becomes a least square minimization problem for an estimator 𝝃^^𝝃\\hat{\\boldsymbol{\\xi}}. However, the dynamics of each IoE user j∈𝒥i𝑗subscript𝒥𝑖j\\in\\mathcal{J}_{i} is heterogeneous in nature based on observed contextual metrics X𝑋X. As a result, the estimator 𝝃^^𝝃\\hat{\\boldsymbol{\\xi}} belongs to an biased decision. Thus, to eliminate the bias of the estimator 𝝃^^𝝃\\hat{\\boldsymbol{\\xi}}, utilization of a covariance matrix 𝛀𝛀\\boldsymbol{\\Omega} of ϵbold-italic-ϵ\\boldsymbol{\\epsilon} (in (1)) is more suitable. Therefore, an unbiased estimator 𝛀^^𝛀\\hat{\\boldsymbol{\\Omega}} can be defined as follows: where 𝛀=1(J−N−1)𝛀1𝐽𝑁1\\boldsymbol{\\Omega}=\\frac{1}{(J-N-1)} represents a covariance matrix with a zero mean. Then the implicit learner of XAI twin fits the for the unconscious decision as follows: where estimation error become ϵ^=𝒀−𝒀^^bold-italic-ϵ𝒀^𝒀\\hat{\\boldsymbol{\\epsilon}}=\\boldsymbol{Y}-\\hat{\\boldsymbol{Y}}. We illustrate the working procedure of the proposed implicit learner in Algorithm 1. Each gNB g∈𝒢𝑔𝒢g\\in\\mathcal{G} is responsible to execute the proposed implicit learner Algorithm 1. The role of the Algorithm 1 is to make an unconscious decisions ui​jexe,di​jexe,ai​jgsuperscriptsubscript𝑢𝑖𝑗exesuperscriptsubscript𝑑𝑖𝑗exesuperscriptsubscript𝑎𝑖𝑗𝑔u_{ij}^{\\textrm{exe}},d_{ij}^{\\textrm{exe}},a_{ij}^{g} based on current contextual metrics X≔(si​jphy,pi​jphy,qi​jphy,δi​jphy,ci​jphy)≔𝑋superscriptsubscript𝑠𝑖𝑗physuperscriptsubscript𝑝𝑖𝑗physuperscriptsubscript𝑞𝑖𝑗physuperscriptsubscript𝛿𝑖𝑗physuperscriptsubscript𝑐𝑖𝑗phyX\\coloneqq(s_{ij}^{\\textrm{phy}},p_{ij}^{\\textrm{phy}},q_{ij}^{\\textrm{phy}},\\delta_{ij}^{\\textrm{phy}},c_{ij}^{\\textrm{phy}}) and each IoE service requirements ui​jreqsuperscriptsubscript𝑢𝑖𝑗requ_{ij}^{\\textrm{req}}, di​jreqsuperscriptsubscript𝑑𝑖𝑗reqd_{ij}^{\\textrm{req}}, αi​jreqsuperscriptsubscript𝛼𝑖𝑗req\\alpha_{ij}^{\\textrm{req}}, βi​jreqsuperscriptsubscript𝛽𝑖𝑗req\\beta_{ij}^{\\textrm{req}}, τi​jreqsuperscriptsubscript𝜏𝑖𝑗req\\tau_{ij}^{\\textrm{req}} at each gNB g∈𝒢𝑔𝒢g\\in\\mathcal{G}. Lines from 111 to 888 in Algorithm 1 are responsible to execute a multivariate regression    scheme, where numerous regression process [ref]38 [ref]37 can be flexibly deployed based on the service provider demands.\nThus, we estimate 𝝃^^𝝃\\hat{\\boldsymbol{\\xi}} using the proposed unbiased least square minimization objective (14) at line 222 in the Algorithm 1. Lines 333 and 444 fit the estimator 𝝃^^𝝃\\hat{\\boldsymbol{\\xi}} to predict (ui​jexe,di​jexe)∈𝒀^superscriptsubscript𝑢𝑖𝑗exesuperscriptsubscript𝑑𝑖𝑗exe^𝒀(u_{ij}^{\\textrm{exe}},d_{ij}^{\\textrm{exe}})\\in\\hat{\\boldsymbol{Y}} and evaluate the prediction error ϵ^^bold-italic-ϵ\\hat{\\boldsymbol{\\epsilon}}, respectively. A termination decision of the regression process is made in line 555 of Algorithm 1 based on the required tolerable prediction error ν𝜈\\nu.\nThe convergence of regression process depends on the value of parameter ϵ^≤ν^bold-italic-ϵ𝜈\\hat{\\boldsymbol{\\epsilon}}\\leq\\nu    and number of iterations relies on parameter settings of specific regression algorithms [ref]38 [ref]37 such as long short-term memory (LSTM), deep neural network-base regression, extra Trees, random forest, adaboost, and logistic regression [ref]38 [ref]37. An expectation of total IoE service fulfillment delay 𝔼​[τi​jtot]𝔼delimited-[]superscriptsubscript𝜏𝑖𝑗tot\\mathbb{E}[\\tau_{ij}^{\\textrm{tot}}] is estimated in Algorithm 1 at line 161616. This delay is then combined with uplink duration 𝔼​[Ti​jup]𝔼delimited-[]subscriptsuperscript𝑇up𝑖𝑗\\mathbb{E}[T^{\\textrm{up}}_{ij}], waiting time duration 𝔼​[Ti​jqueue]𝔼delimited-[]subscriptsuperscript𝑇queue𝑖𝑗\\mathbb{E}[T^{\\textrm{queue}}_{ij}], computational duration 𝔼​[Ti​jexe]𝔼delimited-[]subscriptsuperscript𝑇exe𝑖𝑗\\mathbb{E}[T^{\\textrm{exe}}_{ij}], and downlink duration 𝔼​[Ti​jdown]𝔼delimited-[]subscriptsuperscript𝑇down𝑖𝑗\\mathbb{E}[T^{\\textrm{down}}_{ij}] that are calculated in lines 111111, 141414, 151515, and 161616 of Algorithm 1, respectively. Line 181818 in Algorithm 1 is responsible to evaluate constraints (11b), (11c), (11d), (11e), (11f), (11g), and (11h) based on the implicit decisions of ui​jexesuperscriptsubscript𝑢𝑖𝑗exeu_{ij}^{\\textrm{exe}}, and di​jexesuperscriptsubscript𝑑𝑖𝑗exed_{ij}^{\\textrm{exe}} at gNB g∈𝒢𝑔𝒢g\\in\\mathcal{G}. An decision indicator ai​jgsuperscriptsubscript𝑎𝑖𝑗𝑔a_{ij}^{g} is marked in lines 191919 or 212121 based on the constraints satisfaction of line 181818 in Algorithm 1. Finally, network dynamics and contextual metrics are preserved in line 232323 (in Algorithm 1) for reasoning and error correction by utilizing these findings in the virtual space of the XAI twin. The output of Algorithm 1 includes unconscious decisions ui​jexe,di​jexe,ai​jgsuperscriptsubscript𝑢𝑖𝑗exesuperscriptsubscript𝑑𝑖𝑗exesuperscriptsubscript𝑎𝑖𝑗𝑔u_{ij}^{\\textrm{exe}},d_{ij}^{\\textrm{exe}},a_{ij}^{g} based on current contextual metrics X≔(si​jphy,pi​jphy,qi​jphy,δi​jphy,ci​jphy)≔𝑋superscriptsubscript𝑠𝑖𝑗physuperscriptsubscript𝑝𝑖𝑗physuperscriptsubscript𝑞𝑖𝑗physuperscriptsubscript𝛿𝑖𝑗physuperscriptsubscript𝑐𝑖𝑗phyX\\coloneqq(s_{ij}^{\\textrm{phy}},p_{ij}^{\\textrm{phy}},q_{ij}^{\\textrm{phy}},\\delta_{ij}^{\\textrm{phy}},c_{ij}^{\\textrm{phy}}) for all IoE service ∀𝒥i,ℐfor-allsubscript𝒥𝑖ℐ\\forall\\mathcal{J}_{i},\\mathcal{I} at gNB g∈𝒢𝑔𝒢g\\in\\mathcal{G}. Thus, Algorithm 1 at physical space determines W=X+ui​jexe,di​jexe,ai​jg𝑊𝑋superscriptsubscript𝑢𝑖𝑗exesuperscriptsubscript𝑑𝑖𝑗exesuperscriptsubscript𝑎𝑖𝑗𝑔W=X+u_{ij}^{\\textrm{exe}},d_{ij}^{\\textrm{exe}},a_{ij}^{g} that will use for symbolic reasoning by a building Bayesian DAG. The complexity of the proposed implicit learner Algorithm 1 belongs to 𝒪​(|𝑿|+|ℐ|​|𝒥i|)𝒪𝑿ℐsubscript𝒥𝑖\\mathcal{O}(|\\boldsymbol{X}|+|\\mathcal{I}||\\mathcal{J}_{i}|), where |𝑿|𝑿|\\boldsymbol{X}|, |ℐ|ℐ|\\mathcal{I}|, and |𝒥i|subscript𝒥𝑖|\\mathcal{J}_{i}| are size of contextual metrics, number of IoE service by the service provider, and number of user for each IoE service j∈𝒥i𝑗subscript𝒥𝑖j\\in\\mathcal{J}_{i} respectively. However, the complexity of the multivariate regression 𝒪​(|𝑿|)𝒪𝑿\\mathcal{O}(|\\boldsymbol{X}|)    can vary depending on the algorithmic procedures of several schemes and neural network configurations [ref]38 [ref]37. In the following section, we present explicit learner of XAI twin for reasoning and error correction on implicit learners’ decisions for assuring ZSM.\n\nReference markers found: [38]\n\nContext windows for each [ref]:\n[ref]38: ωisubscript𝜔𝑖\\omega_{i} (in (11h)) become crucial on contextual metrics X𝑋X at the physical space.\nOn top of the proposed implicit learner, we can flexibly deploy numerous regression algorithms [ref]38 [ref]37 such as long short-term memory (LSTM), deep neural network-base regression, extra Trees, random forest, adaboost, and logistic regression based on the service provider requirements.\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning\",\n                \"Digital-Twin-Enabled 6G: Vision, Architectural Trends, and Future Directions\",\n                \"A Vision of 6G Wireless Systems: Applications, Trends, Technologies, and Open Research Problems\",\n                \"From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where\",\n                \"Explainable Artificial Intelligence for 6G: Improving Trust between Human and Machine\",\n                \"A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI\",\n                \"6G Wireless Systems: A Vision, Architectural Elements, and Future Directions\",\n                \"Neuro-Symbolic Artificial Intelligence (AI) for Intent based Semantic Communication\",\n                \"Zero-touch network and Service Management (ZSM); Reference Architecture\",\n                \"An Explainable Artificial Intelligence Framework for Quality-Aware IoE Service Delivery\",\n                \"Enforcing Intelligent Learning-Based Security in the Internet of Everything\",\n                \"Deep Learning-based Service Distribution Model for Wireless Network Assisted Internet of Everything\",\n                \"Cybertwin-Driven Resource Provisioning for IoE Applications at 6G-Enabled Edge Networks\",\n                \"Toward Zero-Touch Management and Orchestration of Massive Deployment of Network Slices in 6G\",\n                \"Smart Zero-Touch Management of UAV-Based Edge Network\",\n                \"Zero-Touch AI-Driven Distributed Management for Energy-Efficient 6G Massive Network Slicing\",\n                \"A Zero-Touch Network Service Management Approach Using AI-Enabled CDR Analysis\",\n                \"Actor-Critic-Based Learning for Zero-touch Joint Resource and Energy Control in Network Slicing\",\n                \"Introduction to multi-armed bandits\",\n                \"Beyond throughput, the next generation: a 5g dataset with channel and context metrics\",\n                \"Cybertwin Assisted Wireless Asynchronous Federated Learning Mechanism for Edge Computing\",\n                \"Cybertwin-driven Federated Learning based Personalized Service Provision for 6G-V2X\",\n                \"Edge Task Migration With 6G-Enabled Network in Box for Cybertwin-Based Internet of Vehicles\",\n                \"Edge Continual Learning for Dynamic Digital Twins over Wireless Networks\",\n                \"View on 5G Architecture\",\n                \"5G; NR; Physical layer procedures for data (3GPP TS 38.214 version 16.2.0 Release 16)\",\n                \"Statistical models: theory and practice\",\n                \"Multivariate regression\",\n                \"Introduction to multivariate regression analysis\",\n                \"Context Aware Medium Access Control for Buffer-Aided Multichannel Cognitive Networks\",\n                \"M/G/1 queue with multiple working vacations\",\n                \"Queueing Systems\",\n                \"Artificial Intelligence-based Service Aggregation for Mobile-Agent in Edge Computing\",\n                \"Bayesian logic programming: Theory and tool\",\n                \"First-Order Probabilistic Languages: Into the Unknown\",\n                \"Bayesian networks for interpretable machine learning and optimization\",\n                \"A effective SINR link to system mapping method for CQI feedback in TD-LTE system\",\n                \"Ensemble methods\",\n                \"LSTM: A Search Space Odyssey\",\n                \"PyBBN\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]38 based on the context and research area of Neuro-symbolic Explainable Artificial Intelligence Twin for Zero-touch IoE in Wireless Network. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}