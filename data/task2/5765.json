{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: A template for Arxiv Style Citation: Authors. Title. Pages…. DOI:000000/11111.\n\nPaper Abstract: \n\nPaper Section Text:\nMany of the remarkable advances of the past 5 years in deep learning have been driven by a continuous increase in the quantity of training compute used to develop cutting-edge models   .\nSuch large-scale training has been made possible through the concurrent use of hundreds or thousands of specialized accelerators with high inter-chip communication bandwidth (such as Google TPUs, NVIDIA A100 and H100 GPUs, or AMD MI250 GPUs), employed for a span of weeks or months to compute thousands or millions of gradient updates.\nWe refer to these specialized accelerators as ML chips, which we distinguish from consumer-oriented GPUs with lower interconnect bandwidth (e.g., the NVIDIA RTX 4090, used in gaming computers). This compute scaling trend has yielded models with ever more useful capabilities.\nHowever, these advanced capabilities also bring with them greater dangers from misuse .\nFor instance, it is increasingly plausible that criminals may soon be able to leverage heavily-trained code-generation-and-execution models to autonomously identify and exploit cyber-vulnerabilities, enabling ransomware attacks on an unprecedented scale.\n111The 2017 NotPetya worm was estimated to have caused $10B in damages, and was both far less capable and far more straightforward to disable .\nEven absent malicious intent, rival companies or countries trapped in an AI “race dynamic” may face substantial pressure to cut corners on testing and risk-mitigation, in order to deploy high-capability ML systems in the hopes of outmaneuvering their competitors economically or militarily.\nThe edge-case behaviors of deep learning models are notoriously difficult to debug [ref]20, and without thorough testing and mitigation, such bugs in increasingly capable systems may have increasingly severe consequences.\nEven when rival parties would all prefer to individually do more testing and risk-mitigation, or even forgo developing particularly dangerous types of ML models entirely , they may have no way to verify whether their competitors are matching their levels of caution. In the event that such risks do emerge, governments may wish to enforce limits on the large-scale development of ML models.\nWhile law-abiding companies will comply, criminal actors, negligent companies, and rival governments may not, especially if they believe their rule-violations will go unnoticed.\nIt would therefore be useful for governments to have methods for reliably verifying that large-scale ML training runs comply with agreed rules. These training runs’ current need for large quantities of specialized chips leaves a large physical and logistical footprint, meaning that such activities are generally undertaken by sizable organizations (e.g., corporate or governmental data-center operators) well-equipped to comply with potential regulations.\nYet even if the relevant facilities are known, there is no easily-observable difference between training a model for social benefit, and training a model for criminal misuse — they require the same hardware, and at most differ in the code and data they use.\nGiven the substantial promise of deep learning technologies to benefit society, it would be unfortunate if governments, in a reasonable attempt to curtail harmful use-cases but unable to distinguish the development of harmful ML models, ended up repressing the development of beneficial applications of ML as well.\nSuch dynamics are already appearing: the US Department of Commerce’s rationale for its October 2022 export controls denying the sale of high-performance chips to the People’s Republic of China, while not specific to ML, was based in part on concern that those chips might be used to develop weapons against the United States or commit human rights abuses [ref]5.\nIf the US and Chinese governments could reach an agreement on a set of permissible beneficial use-cases for export-controlled chips, and had a way to verify Chinese companies’ compliance with that agreement, it may be possible to prevent or reverse future restrictions. Such a system of verification-based checks and balances, distinguishing between “safe” and “dangerous” ML model training, might seem infeasible.\nYet a similar system has been created before.\nAt the dawn of the nuclear age, nations faced an analogous problem:\nreactor-grade uranium (used for energy) and weapons-grade uranium (used to build nuclear bombs) could be produced using the same types of centrifuges, just run for longer and in a different configuration.\nIn response, in 1970 the nations of the world adopted the Treaty on the Non-Proliferation of Nuclear Weapons (NPT) and empowered the International Atomic Energy Agency (IAEA) to verify countries’ commitments to limiting the spread of nuclear weapons, while still harnessing the benefits of nuclear power.\nThis verification framework has helped the world avoid nuclear conflict for over 50 years, and helped limit nuclear weapons proliferation to just 9 countries while spreading the benefits of safe nuclear power to 33 .\nIf future progress in machine learning creates the domestic or international political will for enacting rules on large-scale ML development, it is important that the ML community is ready with technical means for verifying such rules.\n\nReference markers found: [20]\n\nContext windows for each [ref]:\n[ref]20: to deploy high-capability ML systems in the hopes of outmaneuvering their competitors economically or militarily.\nThe edge-case behaviors of deep learning models are notoriously difficult to debug [ref]20, and without thorough testing and mitigation, such bugs in increasingly capable systems may have increasingly severe consequences.\nEven when rival parties would all prefer to individually do\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 20,\n            \"titles\": [\n                \"Training Compute-Optimal Large Language Models\",\n                \"Comparison Between Android and iOS Operating System in Terms of Security\",\n                \"Security Against Covert Adversaries: Efficient Protocols for Realistic Adversaries\",\n                \"Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback\",\n                \"Nuclear Arms Control Verification and Lessons for AI Treaties \",\n                \"BIS Press Release: Advanced Computing and Semiconductor Manufacturing Controls\",\n                \"Language Models are Few-Shot Learners\",\n                \"The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation\",\n                \"Federal Statistical Research Data Centers\",\n                \"Design of security enhanced TPM chip against invasive physical attacks\",\n                \"PaLM: Scaling Language Modeling with Pathways\",\n                \"Wyden, Booker and Clarke Introduce Algorithmic Accountability Act of 2022 to require new transparency and accountability for Automated Decision Systems\",\n                \"New Weapons, Proven Precedent: Elements of and Models for a Treaty on Killer Robots\",\n                \"Regulating Artificial Intelligence Proposal for a Global Solution\",\n                \"Algorithmic progress in computer vision\",\n                \"On the Fundamental Limits of Formally (Dis) Proving Robustness in Proof-of-Learning\",\n                \"Predictability and Surprise in Large Generative Models\",\n                \"NVIDIA Has Reinstated its RTX 3060 Ethereum Cryptocurrency Mining Limit\",\n                \"The Untold Story of NotPetya, the Most Devastating Cyberattack in History\",\n                \"IAEA Safeguards and Detection of Undeclared Nuclear Activities\",\n                \"Unsolved Problems in ML Safety\",\n                \"AI and International Stability: Risks and Confidence-Building Measures\",\n                \"Computational Power and the Social Impact of Artificial Intelligence\",\n                \"Proof-of-Learning: Definitions and Practice\",\n                \"Scaling Laws for Neural Language Models\",\n                \"Adam: A Method for Stochastic Optimization\",\n                \"Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems\",\n                \"US20140130151A1 - Methods for Providing Anti-Rollback Protection of a Firmware Version in a Device Which Has No Internal Non-Volatile Memory\",\n                \"Google Launches a 9 Exaflop Cluster of Cloud TPU V4 Pods Into Public Preview\",\n                \"VCNN: Verifiable convolutional neural network based on ZK-Snarks\",\n                \"Lightweight Threat Model: OpenTitan documentation\",\n                \"List of Semiconductor Fabrication Plants\",\n                \"On the Reproducibility and Replicability of Deep Learning in Software Engineering\",\n                \"Trojaning Attack on Neural Networks\",\n                \"Large Language Models Generate Functional Protein Sequences Across Diverse Families\",\n                \"Teaching Small Language Models to Reason\",\n                \"AI Verification-Mechanisms to Ensure AI Arms Control Compliance\",\n                \"NVIDIA Updates GeForce EULA to Prohibit Data Center Use\",\n                \"A Day in the Life of a Nuclear Safeguards Inspector\",\n                \"Nuclear Power by Country\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]20 based on the context and research area of A template for Arxiv Style Citation: Authors. Title. Pages…. DOI:000000/11111.. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}