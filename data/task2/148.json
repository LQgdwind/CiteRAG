{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Neural Lyapunov Model Predictive Control: Learning Safe Global Controllers from Sub-optimal Examples\n\nPaper Abstract: \n\nPaper Section Text:\nWe prove the following, extended version of the theorem. Stability and robustness\nAssume that V​(x)𝑉𝑥V(x) satisfies (5), with λ∈[0,1)𝜆01\\lambda\\in[0,1), 𝕏_​T={0}subscript𝕏_𝑇0\\mathbb{X}_{\\_}T=\\{0\\}. Then, for any horizon length N≥1𝑁1N\\geq 1 there exist a constant α¯≥0¯𝛼0\\bar{\\alpha}\\geq 0, a minimum discount factor γ¯∈(0,1]¯𝛾01\\bar{\\gamma}\\in(0,1], and a model error bound μ¯¯𝜇\\bar{\\mu} such that, if α≥α¯𝛼¯𝛼\\alpha\\geq\\bar{\\alpha}, μ≤μ¯𝜇¯𝜇\\mu\\leq\\bar{\\mu} and γ≥γ¯𝛾¯𝛾\\gamma\\geq\\bar{\\gamma}, then, ∀x​(0)∈𝒞​(𝕏_​s)for-all𝑥0𝒞subscript𝕏_𝑠\\forall x(0)\\in\\mathcal{C}(\\mathbb{X}_{\\_}s) If N=1𝑁1N=1, μ=0𝜇0\\mu=0, then the system is asymptotically stable for any γ>0𝛾0\\gamma>0, ∀x​(0)∈Υ_​N,γ,αfor-all𝑥0subscriptΥ_𝑁𝛾𝛼\\forall x(0)\\in\\Upsilon_{\\_}{N,\\gamma,\\alpha}. If N>1𝑁1N>1, μ=0𝜇0\\mu=0, then the system reaches a set 𝔹_​γsubscript𝔹_𝛾\\mathbb{B}_{\\_}{\\gamma} that is included in 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s. This set increases monotonically with decreasing discount factors, γ𝛾\\gamma, ∀x​(0)∈Υ_​N,γ,αfor-all𝑥0subscriptΥ_𝑁𝛾𝛼\\forall x(0)\\in\\Upsilon_{\\_}{N,\\gamma,\\alpha}. γ=1⇒𝔹_​γ={0}𝛾1⇒subscript𝔹_𝛾0\\gamma=1\\Rightarrow\\mathbb{B}_{\\_}{\\gamma}=\\{0\\}. If N>1𝑁1N>1, μ=0𝜇0\\mu=0, and once in 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s we switch to the expert policy, then the system is asymptotically stable, ∀x​(0)∈Υ_​N,γ,αfor-all𝑥0subscriptΥ_𝑁𝛾𝛼\\forall x(0)\\in\\Upsilon_{\\_}{N,\\gamma,\\alpha}. If α​V​(x)𝛼𝑉𝑥\\alpha V(x) is the optimal value function for the discounted problem, μ=0𝜇0\\mu=0, and if 𝒞​(𝕏_​s)=𝕏_​s𝒞subscript𝕏_𝑠subscript𝕏_𝑠\\mathcal{C}(\\mathbb{X}_{\\_}s)=\\mathbb{X}_{\\_}s, then the system is asymptotically stable, ∀x​(0)∈Υ_​N,γ,αfor-all𝑥0subscriptΥ_𝑁𝛾𝛼\\forall x(0)\\in\\Upsilon_{\\_}{N,\\gamma,\\alpha}. If α​V​(x)𝛼𝑉𝑥\\alpha V(x) is the optimal value function in 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s for the problem, μ=0𝜇0\\mu=0, and if 𝒞​(𝕏_​s)≠𝕏_​s𝒞subscript𝕏_𝑠subscript𝕏_𝑠\\mathcal{C}(\\mathbb{X}_{\\_}s)\\neq\\mathbb{X}_{\\_}s, then the system is asymptotically stable, ∀x​(0)∈Υ_​N,γ,αfor-all𝑥0subscriptΥ_𝑁𝛾𝛼\\forall x(0)\\in\\Upsilon_{\\_}{N,\\gamma,\\alpha}. The MPC has a stability margin. If the MPC uses a surrogate model satisfying (8), with one-step error bound ‖w‖_​22<μ¯2=1−λL_​V​L_​f^​x2​N​l_​ssubscriptnorm𝑤_superscript22superscript¯𝜇21𝜆subscript𝐿_𝑉subscript𝐿_^𝑓superscript𝑥2𝑁subscript𝑙_𝑠\\|w\\|_{\\_}2^{2}<\\bar{\\mu}^{2}=\\frac{1-\\lambda}{L_{\\_}VL_{\\_}{\\hat{f}x}^{2N}}l_{\\_}s, then the system is Input-to-State (practically) Stable (ISpS) and there exists a set 𝔹_​N,γ,μ:x​(t)→𝔹_​N,γ,μ:subscript𝔹_𝑁𝛾𝜇→𝑥𝑡subscript𝔹_𝑁𝛾𝜇\\mathbb{B}_{\\_}{N,{\\gamma},{\\mu}}:\\ x(t)\\rightarrow\\mathbb{B}_{\\_}{N,{\\gamma},{\\mu}}, ∀x​(0)∈β​Υ_​N,γ,αfor-all𝑥0𝛽subscriptΥ_𝑁𝛾𝛼\\forall x(0)\\in\\beta\\Upsilon_{\\_}{N,\\gamma,\\alpha}, β≤1𝛽1\\beta\\leq 1. If μ=0𝜇0\\mu=0, then α≥α¯𝛼¯𝛼\\alpha\\geq\\bar{\\alpha} implies that α​V​(x)≥V⋆​(x),∀x∈𝕏_​sformulae-sequence𝛼𝑉𝑥superscript𝑉⋆𝑥for-all𝑥subscript𝕏_𝑠\\alpha V(x)\\geq V^{\\star}(x),\\forall x\\in\\mathbb{X}_{\\_}s, where V⋆superscript𝑉⋆V^{\\star} is the optimal value function for the infinite horizon problem with cost (3) and subject to (2). In order to prove point 1 in the theorem, we first use the standard arguments for the MPC without terminal constraint  [ref]20 in the undiscounted case. We then extend the results to the discounted case. First, when an invariant set terminal constraint is used, which in our case corresponds to the condition V​(x​(N))≤l_​s𝑉𝑥𝑁subscript𝑙_𝑠V(x(N))\\leq l_{\\_}s with 𝕏_​s⊆𝕏subscript𝕏_𝑠𝕏\\mathbb{X}_{\\_}s\\subseteq\\mathbb{X}, then  have provided conditions to prove stability by demonstrating that J_⋆​MPC​(x)subscriptsuperscript𝐽⋆_MPC𝑥J^{\\star}_{\\_}{\\text{MPC}}(x) is a Lyapunov function. These require the terminal cost to be a Lyapunov function that satisfies Equation 5. Hence, we start by looking for values of α𝛼\\alpha such that α​V​(x)𝛼𝑉𝑥\\alpha V(x) satisfies Equation 5. In other words, we wish to find an α¯_​1≥1subscript¯𝛼_11\\bar{\\alpha}_{\\_}1\\geq 1 such that, for all α≥α¯_​1𝛼subscript¯𝛼_1\\alpha\\geq\\bar{\\alpha}_{\\_}1 and for some policy K_​0subscript𝐾_0K_{\\_}0 (in our case, the demonstrator for V𝑉V), the following condition holds: Let us denote x+=f​(x,K_​0​(x))superscript𝑥𝑓𝑥subscript𝐾_0𝑥x^{+}=f(x,K_{\\_}0(x)) for brevity. We have, by assumption, that: This implies that: Recall that the loss function satisfies l_​ℓ​‖x‖_​22≤ℓ​(x,u)subscript𝑙_ℓsubscriptnorm𝑥_superscript22ℓ𝑥𝑢l_{\\_}\\ell\\|x\\|_{\\_}2^{2}\\leq\\ell(x,u). Since the MPC is solved using a sequence of convex quadratic programs, it is also Lipschitz . Similarly, if K_​0subscript𝐾_0K_{\\_}0 is Lipschitz or (uniformly) continuous over the closed and bounded set 𝕌𝕌\\mathbb{U}, then since 𝕏𝕏\\mathbb{X} is also closed and bounded, there also exists a local upper bound for the loss function on this policy, namely, ℓ​(x,K_​0​(x))≤L_​ℓ​‖x‖_​22ℓ𝑥subscript𝐾_0𝑥subscript𝐿_ℓsubscriptnorm𝑥_superscript22\\ell(x,K_{\\_}0(x))\\leq L_{\\_}\\ell\\|x\\|_{\\_}2^{2}. Further, recall from Equation 4 that l_​ℓ​‖x‖_​22≤V​(x)subscript𝑙_ℓsubscriptnorm𝑥_superscript22𝑉𝑥l_{\\_}\\ell\\|x\\|_{\\_}2^{2}\\leq V(x). Using the above notions, we have: To satisfy the above condition, solving for a β≥1𝛽1\\beta\\geq 1 is sufficient. From Equations (40) and (41), it implies that: Now, the function α​V​(x)𝛼𝑉𝑥\\alpha V(x) satisfies all the sufficient conditions stated by  for the stability of an MPC under the terminal constraint x^​(N)∈𝕏_​s^𝑥𝑁subscript𝕏_𝑠\\hat{x}(N)\\in\\mathbb{X}_{\\_}s which is equivalent to V​(x^​(N))≤l_​s𝑉^𝑥𝑁subscript𝑙_𝑠V(\\hat{x}(N))\\leq l_{\\_}s, without discount (with γ=1𝛾1\\gamma=1). Since we do not wish to have such a terminal constraint, we wish for another lower bound α^_​2≥1subscript^𝛼_21\\hat{\\alpha}_{\\_}2\\geq 1 such that, if α≥α¯_​2𝛼subscript¯𝛼_2\\alpha\\geq\\bar{\\alpha}_{\\_}2, then V​(x^​(N))≤l_​s𝑉^𝑥𝑁subscript𝑙_𝑠V(\\hat{x}(N))\\leq l_{\\_}s at the optimal solution. The computation of this α¯_​2subscript¯𝛼_2\\bar{\\alpha}_{\\_}2 has been outlined by  for the undiscounted case. Since our constraints are closed, bounded and they contain the origin, our model and the MPC control law are both Lipschitz, we directly use the result from  to compute α¯_​2subscript¯𝛼_2\\bar{\\alpha}_{\\_}2: where x~​(i),u~​(i)~𝑥𝑖~𝑢𝑖\\tilde{x}(i),\\tilde{u}(i) represent a sub-optimal state-action sequence for which V​(x~​(N))≤ρ​l_​s𝑉~𝑥𝑁𝜌subscript𝑙_𝑠V(\\tilde{x}(N))\\leq\\rho l_{\\_}s with ρ∈[0,1)𝜌01\\rho\\in[0,1), and d𝑑d is a lower bound for the stage loss ℓℓ\\ell for all x outside 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s and all u𝑢u in 𝕌𝕌\\mathbb{U}. Then, one can take: to guarantee stability when γ=1𝛾1\\gamma=1. When the discount factor (γ<1𝛾1\\gamma<1) is used, condition (38) is still respected by the same range of α𝛼\\alpha since However, from the discussion in , for infinite horizon optimal control, it appears that Equation 38 is not sufficient for J_⋆​MPC​(x)subscriptsuperscript𝐽⋆_MPC𝑥J^{\\star}_{\\_}{\\text{MPC}}(x) to be a Lyapunov function, even when a terminal constraint is used. We wish to find a lower-bound γ¯¯𝛾\\bar{\\gamma} such that, given α𝛼\\alpha satisfying Equation 44, the MPC is stable for γ≥γ¯𝛾¯𝛾\\gamma\\geq\\bar{\\gamma}.\nFor infinite-horizon optimal control, this was done by . First, recall that: In , it shown that 1≤C<1/(1−γ)1𝐶11𝛾1\\leq C<1/(1-\\gamma) is sufficient for stability of an infinite-horizon discounted optimal control problem, when α​V​(x)𝛼𝑉𝑥\\alpha V(x) is its value function. This means that: which implies that: For MPC, we will instead present an additional condition to the above one that leads to at least convergence to the safe set. This results in a bounded and safe solution. Exact convergence to the origin will be then confirmed when V𝑉V is the actual value function, as in , or if we switch to the demonstrating policy, K_​0subscript𝐾_0K_{\\_}0, once in the terminal set. Finally, we will remove the terminal constraint as done for the undiscounted case with a final bound on α𝛼\\alpha and γ𝛾\\gamma. Recall that condition (38) applies.\nIf the terminal constraint was met at time t𝑡t, namely, if V​(x⋆​(N))≤l_​s𝑉superscript𝑥⋆𝑁subscript𝑙_𝑠V(x^{\\star}(N))\\leq l_{\\_}s, then at the next time step, t+1𝑡1t+1 we have that u​(N+1)=K_​0​(x⋆​(N))𝑢𝑁1subscript𝐾_0superscript𝑥⋆𝑁u(N+1)=K_{\\_}0(x^{\\star}(N)) is feasible. Hence, the optimal MPC solution can be upper-bounded by the shifted solution at the previous time t𝑡t, with the K_​0subscript𝐾_0K_{\\_}0 policy appended at the end of the horizon . Denote this policy as u¯~~¯𝑢\\tilde{\\underline{u}} and x~~𝑥\\tilde{x} as the predictions. We have that: Hence, where\nL_​N−1​(x)=∑_i=1N−1​γi−1​ℓ​(x~​(i),u~​(i))subscript𝐿_𝑁1𝑥subscript_𝑖superscript1𝑁1superscript𝛾𝑖1ℓ~𝑥𝑖~𝑢𝑖L_{\\_}{N-1}(x)=\\sum_{\\_}{i=1}^{N-1}\\gamma^{i-1}\\ell(\\tilde{x}(i),\\tilde{u}(i)) and we have taken α𝛼\\alpha such that γ​α≥α¯_​1𝛾𝛼subscript¯𝛼_1\\gamma\\alpha\\geq\\bar{\\alpha}_{\\_}1. Now, for γ=1𝛾1\\gamma=1, the effect of L_​N−1subscript𝐿_𝑁1L_{\\_}{N-1} disappears and the MPC optimal cost is a Lyapunov function as in the standard MPC stability result from . By inspection of L_​N−1subscript𝐿_𝑁1L_{\\_}{N-1}, since the cost is bounded over bounded sets, also a small enough γ𝛾\\gamma could be found such that L_​N−1​(x)<ℓ​(x,u~​(0))subscript𝐿_𝑁1𝑥ℓ𝑥~𝑢0L_{\\_}{N-1}(x)<\\ell(x,\\tilde{u}(0)). This γ𝛾\\gamma, however, depends on x𝑥x. Consider x∉𝕏_​s𝑥subscript𝕏_𝑠x\\not\\in\\mathbb{X}_{\\_}s, for which there exist a feasible solution, namely a solution providing x~​(N)∈𝕏_​s~𝑥𝑁subscript𝕏_𝑠\\tilde{x}(N)\\in\\mathbb{X}_{\\_}s. Then, since ℓℓ\\ell is strictly increasing, ℓ​(0,0)=0ℓ000\\ell(0,0)=0, 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s contains the origin and the constraints are bounded, we have that there exist a υ≥1𝜐1\\upsilon\\geq 1 such that for any feasbile x𝑥x: is an upper bound for L_​N−1​(x)subscript𝐿_𝑁1𝑥L_{\\_}{N-1}(x). For instance, is sufficient for any closed set of initial conditions x​(0)∈ϵ​𝕏⊃𝕏_​s𝑥0italic-ϵ𝕏superset-ofsubscript𝕏_𝑠x(0)\\in\\epsilon\\mathbb{X}\\supset\\mathbb{X}_{\\_}s, with ϵ>0italic-ϵ0\\epsilon>0.\nIn order to have stability, it suffices to have (1−γ)​L¯_​N−1−ℓ​(x,u~​(0))≤01𝛾subscript¯𝐿_𝑁1ℓ𝑥~𝑢00(1-\\gamma)\\bar{L}_{\\_}{N-1}-\\ell(x,\\tilde{u}(0))\\leq 0 which requires: In the above condition γ¯​(x)¯𝛾𝑥\\bar{\\gamma}(x) can be less than 111 only outside a neighborhood of origin. Consider again Then taking provides that the system trajectory will enter the safe set 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s, hence 𝔹_​γ⊆𝕏_​ssubscript𝔹_𝛾subscript𝕏_𝑠\\mathbb{B}_{\\_}\\gamma\\subseteq\\mathbb{X}_{\\_}s.\nFinally, once x∈𝕏_​s𝑥subscript𝕏_𝑠x\\in\\mathbb{X}_{\\_}s, we that\nthe policy K_​0​(x)subscript𝐾_0𝑥K_{\\_}0(x) is feasible and: Hence, we can use this policy to upper bound the MPC cost: If the above is true with equality, then we can proceed as in Theorem 3.1 of , with γ>γ¯_​1𝛾subscript¯𝛾_1\\gamma>\\bar{\\gamma}_{\\_}1. This would require α​V​(x)𝛼𝑉𝑥\\alpha V(x) to be also a value function for the discounted problem. From the above considerations, we can conclude that that: If N=1𝑁1N=1, then L¯_​N−1=0subscript¯𝐿_𝑁10\\bar{L}_{\\_}{N-1}=0 and the system is asymptotically stable for any γ>0𝛾0\\gamma>0. If N>1𝑁1N>1, γ≥γ_​2¯𝛾¯subscript𝛾_2\\gamma\\geq\\bar{\\gamma_{\\_}2}, then the system reaches an bound 𝔹_​γsubscript𝔹_𝛾\\mathbb{B}_{\\_}\\gamma that is included in 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s. If N>1𝑁1N>1 γ≥γ_​2¯𝛾¯subscript𝛾_2\\gamma\\geq\\bar{\\gamma_{\\_}2} and once in 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s we switch to the policy K_​0​(x)subscript𝐾_0𝑥K_{\\_}0(x) then the system is asymptotically stable. If α​V​(x)𝛼𝑉𝑥\\alpha V(x) is the global value function for the discounted problem and if ℛ​(𝕏_​s)=𝕏_​sℛsubscript𝕏_𝑠subscript𝕏_𝑠\\mathcal{R}(\\mathbb{X}_{\\_}s)=\\mathbb{X}_{\\_}s, then γ>γ¯_​1𝛾subscript¯𝛾_1\\gamma>\\bar{\\gamma}_{\\_}1 provides that the system is Asymptotically stable. If α​V​(x)𝛼𝑉𝑥\\alpha V(x) is only the value function in 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s for the discounted problem, and if ℛ​(𝕏_​s)≠𝕏_​sℛsubscript𝕏_𝑠subscript𝕏_𝑠\\mathcal{R}(\\mathbb{X}_{\\_}s)\\neq\\mathbb{X}_{\\_}s, then γ>max⁡(γ¯_​1,γ_​2¯)𝛾subscript¯𝛾_1¯subscript𝛾_2\\gamma>\\max(\\bar{\\gamma}_{\\_}1,\\bar{\\gamma_{\\_}2}) provides that the system is Asymptotically stable. Finally, following Theorem 3 from [ref]20, the terminal constraint can be removed for all points x∈ℛN​(ρ​𝕏_​s)𝑥superscriptℛ𝑁𝜌subscript𝕏_𝑠x\\in\\mathcal{R}^{N}(\\rho\\mathbb{X}_{\\_}s), with ρ∈[0,1)𝜌01\\rho\\in[0,1), by setting: In fact, by the same argument of [ref]20, for any states for which it exists a feasible sequence u¯~~¯𝑢\\tilde{\\underline{u}} taking x^​(N)^𝑥𝑁\\hat{x}(N) to ρ​𝕏_​s𝜌subscript𝕏_𝑠\\rho\\mathbb{X}_{\\_}s we have that: If α𝛼\\alpha satisfies (52), then we also have that: from which we can directly verify that the set defined in (III-B) is a ROA (for either asymptotic or practical stability): For point 6, the stability margins of nominal MPC have been studied in . In particular, in a setup without terminal constraint, under nominal stabilising conditions, with a uniformly continuous model (in our case even Lipschitz), cost functions being also uniformly continuous, then the optimal MPC cost is also uniformly continuous [24, Proposition 1]. In other words, from [24, Theorem 1], there is a 𝒦_​∞subscript𝒦_\\mathcal{K}_{\\_}\\infty-function, σ𝜎\\sigma, such that at the optimal solution, u¯⋆superscript¯𝑢⋆\\underline{u}^{\\star}, we have: Using the above identity, one wish to bound the increase in the MPC cost due to uncertainty. At the same time, we wish the MPC to remain feasible and perform a contraction, namely, to have a stability margin. Since we are using soft constraints, then the MPC remains always feasible, however, we need the predictions at the end of the horizon to be in an invariant set 𝕏_​ssubscript𝕏_𝑠\\mathbb{X}_{\\_}s even under the effect of uncertainty. In particular, we will use V​(x)𝑉𝑥V(x) and its contraction factor λ𝜆\\lambda to compute a smaller level set ζ​𝕏_​s𝜁subscript𝕏_𝑠\\zeta\\mathbb{X}_{\\_}s, for some ζ∈(0,1)𝜁01\\zeta\\in(0,1) which is invariant under the uncertainty. Once this is found then we can compute a new α𝛼\\alpha for this set according to (52).\nIn particular, under the policy K_​0subscript𝐾_0K_{\\_}0, we have that: We wish this quantity to be non-positive for x∉ζ​𝕏_​s𝑥𝜁subscript𝕏_𝑠x\\not\\in\\zeta\\mathbb{X}_{\\_}s, which means that V​(x)≥ζ​l_​s𝑉𝑥𝜁subscript𝑙_𝑠V(x)\\geq\\zeta l_{\\_}s. For this it is sufficient to have: Since we apply the function V𝑉V to the prediction at time N𝑁N, and at the next step the measured state (prediction at index 00) differs from the previous MPC prediction of a quantity w𝑤w, for the MPC this condition translates into: Therefore, given the model error w𝑤w, if the MPC remains feasible and if α𝛼\\alpha and γ𝛾\\gamma exceed their lower bounds given the restricted set ζ​𝕏_​s𝜁subscript𝕏_𝑠\\zeta\\mathbb{X}_{\\_}s, we have that ‖w‖_​2<μ¯subscriptnorm𝑤_2¯𝜇\\|w\\|_{\\_}2<\\bar{\\mu} implies that: which is the definition of Input-to-State practical Stability  , where we have defined d¯​(N)=(1−γ)​L¯_​N−1¯𝑑𝑁1𝛾subscript¯𝐿_𝑁1\\bar{d}(N)=(1-\\gamma)\\bar{L}_{\\_}{N-1}. The trajectory of the system is therefore bounded by the level-set of J_⋆​M​P​C​(x)subscriptsuperscript𝐽⋆_𝑀𝑃𝐶𝑥J^{\\star}_{\\_}{MPC}(x) outside which σ​(μ)+d¯​(N)≤l_​ℓ​‖x‖_​22.𝜎𝜇¯𝑑𝑁subscript𝑙_ℓsubscriptnorm𝑥_superscript22\\sigma(\\mu)+\\bar{d}(N)\\leq l_{\\_}\\ell\\|x\\|_{\\_}2^{2}.\nSince σ𝜎\\sigma is strictly increasing and d¯¯𝑑\\bar{d} is strictly decreasing, we can also conclude that the size of this bound increases with increasing model error μ𝜇\\mu and with the horizon length N𝑁N. Note that the term d¯¯𝑑\\bar{d} vanishes if γ=1𝛾1\\gamma=1 but the term σ𝜎\\sigma will also increase with N𝑁N if L¯_​f>1subscript¯𝐿_𝑓1\\bar{L}_{\\_}f>1. From the restriction of the terminal set, it also follows that the ROA defined in Equation III-B will also be restricted unless we recompute a larger α𝛼\\alpha for this new set. Denote V^​(x)=α​V​(x)^𝑉𝑥𝛼𝑉𝑥\\hat{V}(x)=\\alpha V(x). Recall that, if α≥α_​1𝛼subscript𝛼_1\\alpha\\geq\\alpha_{\\_}1, as defined in Equation 42, and if ‖w​(t)‖=0​∀tnorm𝑤𝑡0for-all𝑡\\|w(t)\\|=0\\ \\forall t, then we have that, ∀x​(t)∈𝕏_​sfor-all𝑥𝑡subscript𝕏_𝑠\\forall x(t)\\in\\mathbb{X}_{\\_}s: which in turn implies that, by means of γ≤1𝛾1\\gamma\\leq 1 and of induction: which is the value of the policy K_​0subscript𝐾_0K_{\\_}0. This is, by definition, an upper bound of the optimal value function, V⋆​(x)superscript𝑉⋆𝑥V^{\\star}(x). Hence α​V​(x)≥V⋆​(x),∀x∈𝕏_​sformulae-sequence𝛼𝑉𝑥superscript𝑉⋆𝑥for-all𝑥subscript𝕏_𝑠\\alpha V(x)\\geq V^{\\star}(x),\\forall x\\in\\mathbb{X}_{\\_}s. ∎ In practice, the ISS bound σ​(μ)𝜎𝜇\\sigma(\\mu) from Theorem 2 has a form similar to the one discussed for the constraint penalty in the proof of Theorem 3, see Equation 37. Its explicit computation is omitted for brevity; however, in general, we can expect the bound to become worse for systems that are open-loop unstable as the horizon length increases.\n\nReference markers found: [20]\n\nContext windows for each [ref]:\n[ref]20: function for the infinite horizon problem with cost (3) and subject to (2). In order to prove point 1 in the theorem, we first use the standard arguments for the MPC without terminal constraint  [ref]20 in the undiscounted case. We then extend the results to the discounted case. First, when an invariant set terminal constraint is used, which in our case corresponds to the condition\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 20,\n            \"titles\": [\n                \"The Lyapunov Neural Network: Adaptive Stability Certification for Safe Learning of Dynamical Systems\",\n                \"Concrete Problems in AI Safety\",\n                \"Model-based reinforcement learning: A survey\",\n                \"Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control\",\n                \"Nonlinear Control\",\n                \"Sampling driven stability domains computation and predictive control of constrained nonlinear systems\",\n                \"Sampling–based verification of Lyapunov’s inequality for piecewise continuous nonlinear systems\",\n                \"Safe Model-based Reinforcement Learning with Stability Guarantees\",\n                \"Safe Interactive Model-Based Learning\",\n                \"Neural Lyapunov Control\",\n                \"Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning\",\n                \"Set-Theoretic Methods in Control (Systems & Control: Foundations & Applications)\",\n                \"Robust constraint satisfaction: Invariant sets and predictive control\",\n                \"Formal Synthesis of Lyapunov Neural Networks\",\n                \"dreach: δ𝛿\\\\delta-reachability analysis for hybrid systems\",\n                \"Echo State Networks: analysis, training and predictive control\",\n                \"Physics-informed echo state networks for chaotic systems forecasting\",\n                \"Using machine learning to replicate chaotic attractors and calculate lyapunov exponents from data\",\n                \"NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations\",\n                \"Constrained model predictive control: Stability and optimality\",\n                \"Stable constrained MPC without terminal constraint\",\n                \"Reinforcement learning: An introduction\",\n                \"Soft constraints and exact penalty functions in model predictive control\",\n                \"Input-to-State Stability: A Unifying Framework for Robust Model Predictive Control\",\n                \"LASSO-MPC – Predictive Control with ℓ_​1subscriptℓ_1\\\\ell_{\\\\_}1-Regularised Least Squares\",\n                \"Lipschitz Continuity in Model-based Reinforcement Learning\",\n                \"Differentiable convex optimization layers\",\n                \"Differentiable MPC for End-to-end Planning and Control\",\n                \"Adam: A method for stochastic optimization\",\n                \"Constrained Policy Optimization\",\n                \"Benchmarking Safe Exploration in Deep Reinforcement Learning\",\n                \"Proximal policy optimization algorithms\",\n                \"Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor\",\n                \"When to trust your model: Model-based policy optimization\",\n                \"Model Predictive Control Theory and Design\",\n                \"Homothetic tube model predictive control\",\n                \"Stabilization with discounted optimal control\",\n                \"Synthesis and stabilization of complex behaviors through online trajectory optimization\",\n                \"Numerical optimization\",\n                \"SNODE: Spectral Discretization of Neural ODEs for System Identification\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]20 based on the context and research area of Neural Lyapunov Model Predictive Control: Learning Safe Global Controllers from Sub-optimal Examples. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}