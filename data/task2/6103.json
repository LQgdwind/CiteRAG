{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Set-Type Belief Propagation with Applications to Poisson Multi-Bernoulli SLAM\n\nPaper Abstract: \n\nPaper Section Text:\nWe investigate the performance gain of the proposed set-type BP MB and PMB-SLAM filters, compared to the vector-type BP-SLAM method¬† .\nWe consider KùêæK time steps with two scenarios as follows: one with an uninformative birth model, and the other with an informative birth model in modeling of undetected landmarks.\nIn realistic environments, the uninformative birth model represents cases where we lack prior map knowledge, whereas the informative birth models the assumption that we have a previously available map.\nIn both birth models, the landmarks are observable starting from k=5ùëò5k=5, and additional landmarks can be observable at each subsequent time step.\nFor sensor localization in both scenarios, multipath is employed from k=5ùëò5k=5, whereas for k<5ùëò5k<5 the measurement for BS-sensor path is exploited.333By the ellipsoidal gating method , the measurement for BS-sensor path is determined as ùê≥^=minùê≥kj‚ààùíµk(ùê≥kj‚àíùê±BS)‚ä§ùêë‚àí1(ùê≥kj‚àíùê±BS)\\hat{\\mathbf{z}}=\\min_{\\mathbf{z}_{k}^{j}\\in\\mathcal{Z}_{k}}(\\mathbf{z}_{k}^{j}-\\mathbf{x}_{\\mathrm{BS}})^{\\top}\\mathbf{R}^{-1}(\\mathbf{z}_{k}^{j}-\\mathbf{x}_{\\mathrm{BS}}). For set-type BP PMB-SLAM, undetected landmarks and the birth are modeled by the PPP process, implemented by the intensity functions. The intensities for undetected targets and the birth are\nrepresented by\nŒª‚Äã(ùê±)=‚àëqŒ∑q‚Äãùñ≠‚Äã(ùê±;ùê±q,ùêîq)ùúÜùê±subscriptùëûsuperscriptùúÇùëûùñ≠ùê±superscriptùê±ùëûsuperscriptùêîùëû\\lambda(\\mathbf{x})=\\sum_{q}\\eta^{q}\\mathsf{N}(\\mathbf{x};\\mathbf{x}^{q},\\mathbf{U}^{q}) and ŒªB‚Äã(ùê±)=‚àëqŒ∑B,q‚Äãùñ≠‚Äã(ùê±;ùê±B,q,ùêîB,q)superscriptùúÜBùê±subscriptùëûsuperscriptùúÇBùëûùñ≠ùê±superscriptùê±BùëûsuperscriptùêîBùëû\\lambda^{\\mathrm{B}}(\\mathbf{x})=\\sum_{q}\\eta^{\\mathrm{B},q}\\mathsf{N}(\\mathbf{x};\\mathbf{x}^{\\mathrm{B},q},\\mathbf{U}^{\\mathrm{B},q}),\nwhere ùñ≠‚Äã(ùê±;ùê±,ùêî)ùñ≠ùê±ùê±ùêî\\mathsf{N}(\\mathbf{x};\\mathbf{x},\\mathbf{U}) is the Gaussian density, and Œ∑ùúÇ\\eta is the Gaussian weight.\nFor set-type BP MB-SLAM, the birth is modeled by the MB process. The MB birth density is the form of¬†(11), where the qùëûq-th Bernoulli has an existence probability rB,qsuperscriptùëüBùëûr^{\\text{B},q} and Gaussian density ùñ≠‚Äã(ùê±;ùê±B,q,ùêîB,q)ùñ≠ùê±superscriptùê±BùëûsuperscriptùêîBùëû\\mathsf{N}(\\mathbf{x};\\mathbf{x}^{\\text{B},q},\\mathbf{U}^{\\text{B},q}).\nFor both birth cases, we set ùê±B,q‚àºùñ≠‚Äã(ùê±;ùê±SP,ùêîB,q)similar-tosuperscriptùê±Bùëûùñ≠ùê±subscriptùê±SPsuperscriptùêîBùëû\\mathbf{x}^{\\text{B},q}\\sim\\mathsf{N}(\\mathbf{x};\\mathbf{x}_{\\text{SP}},\\mathbf{U}^{\\text{B},q}); for the informative birth case, Œ∑B,q=1superscriptùúÇBùëû1\\eta^{\\text{B},q}=1 and ùêîB,q=0.01‚Äãùêà2√ó2superscriptùêîBùëû0.01subscriptùêà22\\mathbf{U}^{\\text{B},q}=0.01\\mathbf{I}_{2\\times 2}; and for the uninformative birth case, Œ∑B,q=10‚àí3superscriptùúÇBùëûsuperscript103\\eta^{\\text{B},q}=10^{-3} and ùêîB,q=106√óùêà2√ó2superscriptùêîBùëûsuperscript106subscriptùêà22\\mathbf{U}^{\\text{B},q}=10^{6}\\times\\mathbf{I}_{2\\times 2}.\nUsing the Kalman filter¬†, we implement the messages and beliefs corresponding to landmarks and data associations.\nThe belief of the sensor state of 27 is intractable by the Kalman filter, and thus implemented by the particle filter¬†7  with NPsubscriptùëÅPN_{\\mathrm{P}} samples.\nAfter the belief computation at each time step, we declare that a landmark is detected when rk|ki>ŒìDsuperscriptsubscriptùëüconditionalùëòùëòùëñsubscriptŒìDr_{k|k}^{i}>\\Gamma_{\\mathrm{D}}. The previously detected landmarks with rk|ki<ŒìBersuperscriptsubscriptùëüconditionalùëòùëòùëñsubscriptŒìBerr_{k|k}^{i}<\\Gamma_{\\mathrm{Ber}} for i=1,‚Ä¶,Ik‚àí1+Jkùëñ1‚Ä¶subscriptùêºùëò1subscriptùêΩùëòi=1,\\dots,I_{k-1}+J_{k} are removed, and the Gaussians in the PPP with Œ∑k|kq<ŒìPoisuperscriptsubscriptùúÇconditionalùëòùëòùëûsubscriptŒìPoi\\eta_{k|k}^{q}<\\Gamma_{\\mathrm{Poi}} are eliminated. We set the prior density of the sensor state to f‚Äã(ùê¨0)=ùñ≠‚Äã(ùê¨0;ùê¨0|0,ùêè0|0)ùëìsubscriptùê¨0ùñ≠subscriptùê¨0subscriptùê¨conditional00subscriptùêèconditional00f(\\mathbf{s}_{0})=\\mathsf{N}(\\mathbf{s}_{0};\\mathbf{s}_{0|0},\\mathbf{P}_{0|0}), where ùê¨0|0subscriptùê¨conditional00\\mathbf{s}_{0|0} is sampled from ùñ≠‚Äã(ùê¨¬Ø0,ùêè0|0)ùñ≠subscript¬Øùê¨0subscriptùêèconditional00\\mathsf{N}(\\bar{\\mathbf{s}}_{0},\\mathbf{P}_{0|0}) for each simulation run. Here ùê¨¬Ø0=[15,‚àí420,0,20]‚ä§subscript¬Øùê¨0superscript15420020top\\bar{\\mathbf{s}}_{0}=[15,-420,0,20]^{\\top} is the ground truth of the initial sensor state, with the units of m, m, m/s, and m/s, and ùêè0|0=blkdiag‚Äã[0.5‚Äãùêà2√ó2,0.005‚Äãùêà2√ó2]subscriptùêèconditional00blkdiag0.5subscriptùêà220.005subscriptùêà22\\mathbf{P}_{0|0}=\\mathrm{blkdiag}[0.5\\mathbf{I}_{2\\times 2},0.005\\mathbf{I}_{2\\times 2}], and the units of the diagonal term of ùêèùêè\\mathbf{P} are\nm2, m2, m2/s2, and m2/s2.\nThe BS location is set to ùê±BS= ‚ä§subscriptùê±BSsuperscript00top\\mathbf{x}_{\\mathrm{BS}}= ^{\\top}, and 150 SPs are uniformly distributed in   ¬†m √ó absent55805\\times ¬†m.\nThe radius of the field-of-view of the sensor is 20¬†m, and the landmarks begin to be observable at time k=5ùëò5k=5.\nTo investigate the influence of newly detected landmarks on sensor state updates, we set up the map environment so that an average of two landmarks are newly detected at every single time step.\nThe number of clutter measurements, which are observed by the sensor, is modeled by the Poisson distribution with mean Œºcsubscriptùúác\\mu_{\\mathrm{c}}¬†1, and\nthe clutter intensity is denoted by c‚Äã(ùê≥)ùëêùê≥c(\\mathbf{z}).\nFor both informative and uninformative births, Œºc=1subscriptùúác1\\mu_{\\mathrm{c}}=1, c‚Äã(ùê≥)=1.6‚ãÖ10‚àí4ùëêùê≥‚ãÖ1.6superscript104c(\\mathbf{z})=1.6\\cdot 10^{-4} in the area of interest.\nThe rest of the simulation parameters are set as follows:\nK=80ùêæ80K=80; œÉw=0.1subscriptùúéùë§0.1\\sigma_{w}=0.1 m/s2;\nœÉr=0.707subscriptùúéùëü0.707\\sigma_{r}=0.707 m;\nŒî‚Äãt=0.5Œîùë°0.5\\Delta t=0.5 s;\nNp=104subscriptùëÅùëùsuperscript104N_{p}=10^{4},\nŒìD=0.4subscriptŒìD0.4\\Gamma_{\\mathrm{D}}=0.4;\nŒìBer=10‚àí5subscriptŒìBersuperscript105\\Gamma_{\\mathrm{Ber}}=10^{-5};\nŒìPoi=5‚ãÖ10‚àí10subscriptŒìPoi‚ãÖ5superscript1010\\Gamma_{\\mathrm{Poi}}=5\\cdot 10^{-10}.\nFor simplicity, we set the detection probability and survival probability to constant values¬† [ref]26: pD‚Äã(‚ãÖ)=pD=0.95subscriptùëùD‚ãÖsubscriptùëùD0.95p_{\\mathrm{D}}(\\cdot)=p_{\\mathrm{D}}=0.95 and pS‚Äã(‚ãÖ)=pS=0.99subscriptùëùS‚ãÖsubscriptùëùS0.99p_{\\mathrm{S}}(\\cdot)=p_{\\mathrm{S}}=0.99.\nThe simulation results are averaged over 500 Monte Carlo trials. The performance of sensor localization and landmark mapping are evaluated by  root mean square error (RMSE) and  generalized optimal subpattern assignment (GOSPA)¬†[48, eq.¬†(1)] with parameters Gp=1subscriptGùëù1\\mathrm{G}_{p}=1, Gc=2subscriptGùëê2\\mathrm{G}_{c}=2, and GŒ±=2subscriptGùõº2\\mathrm{G}_{\\alpha}=2, respectively.\n\nReference markers found: [26]\n\nContext windows for each [ref]:\n[ref]26: 10^{-10}.\nFor simplicity, we set the detection probability and survival probability to constant values¬† [ref]26: pD‚Äã(‚ãÖ)=pD=0.95subscriptùëùD‚ãÖsubscriptùëùD0.95p_{\\mathrm{D}}(\\cdot)=p_{\\mathrm{D}}=0.95 and pS‚Äã(‚ãÖ)=pS=0.99subscriptùëùS‚ãÖsubscriptùëùS0.99p_{\\mathrm{S}}(\\cdot)=p_{\\mathrm{S}}=0.99.\nThe simulation\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 26,\n            \"titles\": [\n                \"Poisson multi-Bernoulli mixture filter: direct derivation and implementation\",\n                \"Factor graphs and the sum-product algorithm\",\n                \"An introduction to factor graphs\",\n                \"Constructing free-energy approximations and generalized belief propagation algorithms\",\n                \"Iterative Receiver Design\",\n                \"Nonparametric belief propagation for sensor network self-calibration\",\n                \"Cooperative localization in wireless networks\",\n                \"Scalable probabilistic gas distribution mapping using gaussian belief propagation\",\n                \"A scalable algorithm for tracking an unknown number of targets using multiple sensors\",\n                \"Message passing algorithms for scalable multitarget tracking\",\n                \"5G mmWave downlink vehicular positioning\",\n                \"5G mmWave vehicular tracking\",\n                \"A Belief Propagation Algorithm for Multipath-Based SLAM\",\n                \"Multipath-based SLAM exploiting AoA and amplitude information\",\n                \"Data fusion for multipath-based slam: Combining information from multiple propagation paths\",\n                \"Distributed localization and tracking of mobile networks including noncooperative objects\",\n                \"FastSLAM: A factored solution to the simultaneous localization and mapping problem\",\n                \"A tutorial on graph-based SLAM\",\n                \"Simultaneous localization and mapping: Part I\",\n                \"Simultaneous localization and mapping (SLAM): Part II\",\n                \"On the representation and estimation of spatial uncertainty\",\n                \"Statistical Multisource-Multitarget Information Fusion\",\n                \"Advances Statistical Multisource-Multitarget Information Fusion\",\n                \"Multitarget Bayes filtering via first-order multi target moments\",\n                \"5G mmWave cooperative positioning and mapping using multi-model PHD\",\n                \"Derivation of the PHD and CPHD filters based on direct Kullback-Leibler divergence minimization\",\n                \"Marginal multi-Bernoulli filters: RFS derivation of MHT, JIPDA, and association-based MeMBer\",\n                \"PMBM-based SLAM filters in 5G mmWave vehicular networks\",\n                \"Multisensor Poisson Multi-Bernoulli Filter for Joint Target-Sensor State Tracking\",\n                \"Œ¥ùõø\\\\delta-generalised labelled multi-Bernoulli simultaneous localisation and mapping\",\n                \"Œ¥ùõø\\\\delta-generalized labeled multi-Bernoulli simultaneous localization and mapping with an optimal kernel-based particle filtering approach\",\n                \"Random finite set-based localization and SLAM for highly automated vehicles\",\n                \"The labeled multi-Bernoulli SLAM filter\",\n                \"Labeled random finite sets and multi-object conjugate priors\",\n                \"A computationally efficient EK-PMBM filter for bistatic mmWave radio SLAM\",\n                \"Using a probabilistic hypothesis density filter to confirm tracks in a multi-target environment.\",\n                \"Hybrid Poisson and multi-Bernoulli filters\",\n                \"If a tree falls in the woods, it does make a sound: multiple-hypothesis tracking with undetected target births\",\n                \"Trajectory PMB filters for extended object tracking using belief propagation\",\n                \"Basic topology\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]26 based on the context and research area of Set-Type Belief Propagation with Applications to Poisson Multi-Bernoulli SLAM. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}