{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: On performance bounds for topology optimization\n\nPaper Abstract: \n\nPaper Section Text:\nTo obtain a mode converter with higher transmittance, i.e. one that produces the target mode output but also maximizes the output magnitude, we next choose the maximum mode overlap magnitude objective in (37). Again, the input mode on the left hand side is the first-order mode, whereas the output target on the right hand side is the second-order mode including its amplitude, i.e. m=2𝑚2m=2, cf. (37). In this example, we vary the size of the design domain Ld∈{0.1667,0.2381,0.3333,0.4286,0.5000}subscript𝐿𝑑0.16670.23810.33330.42860.5000L_{d}\\in\\{0.1667,0.2381,0.3333,0.4286,0.5000\\} μ𝜇\\mum to investigate how this influences the design and bounds. The topology optimized designs and corresponding field distributions are depicted in Fig. 5. Since the objective is posed such that we still aim to match the target output mode profile, we plot the normalized output and target mode profiles at the right-hand side boundary for the smallest and largest Ldsubscript𝐿𝑑L_{d} designs in Fig. 6. The larger design domain clearly matches the target waveform profile better than the smaller design domain, as we expected based on our basic understanding of the physical system and previous numerical results. In Fig. 7 we plot both the topology optimization and bound objective values and transmittance versus the range of Ldsubscript𝐿𝑑L_{d}. As expected, the objective function plateaus when the design domain is sufficiently large since the transmittance approaches unity. We also emphasize that for the largest design domain, the topology optimization is able to design a \\sayperfect mode converter starting from a single initial guess; the gap between the bound and topology optimization objective values is as small as 0.33%percent0.330.33\\% for the largest design domain. For the smaller design domains, it is noted that the topology optimization does not generate perfect mode converters, but by comparing to the bound we realize that this should not be possible either. This illustrates the power of the bounds, both as a predictive tool a priori telling the designer what is possible, and as a tool explaining why a particular design is not performing better despite being optimized. We further tried to recompute the bounds without the cross-correlation constraints in (6). However, this always resulted in less tight bounds; even unbounded results could be obtained, illustrating the importance of including (6) in the bounds formulation. In Fig. 8, we plot the CPU time usage for the topology and bound optimization problems versus the design region size Ldsubscript𝐿𝑑L_{d}, which directly translates to the design variable space size. The topology optimization problems for Ld∈{0.1667,0.2381}subscript𝐿𝑑0.16670.2381L_{d}\\in\\{0.1667,0.2381\\} μ𝜇\\mum terminated earlier than the rest; at 235 and 684 design iterations respectively. The remaining topology optimization runs terminated at 1000 design iterations and have similar time usage. This is expected since the number of degrees-of-freedom is constant for all choices of Ldsubscript𝐿𝑑L_{d}; it is not the MMA optimizer that poses the greatest bottleneck in the topology optimization problem; it is the solution of the state problem. Fig. 8 illustrates a key challenge with the bound problem; its time usage scales poorly with the number of design variables. Already at Ld=0.5subscript𝐿𝑑0.5L_{d}=0.5 μ𝜇\\mum, which corresponds to 1849 design variables, the time to solve the bound optimization problem passes the time to solve the topology optimization problem. The graph clearly illustrates the exponential time usage of the bound problem. We estimated the time dependency to scale with ∼nθf3∼absentsuperscriptsubscript𝑛subscript𝜃𝑓3\\thicksim n_{\\theta_{f}}^{3}, where θfsubscript𝜃𝑓\\theta_{f} is the number of designable degrees-of-freedom. The bound optimization problem for Ld=0.2381subscript𝐿𝑑0.2381L_{d}=0.2381 μ𝜇\\mum yields a solution with rank(𝑿)≈3𝑿3(\\text{\\boldmath$X$})\\approx 3. In Fig. 9 we plot the rank-1 and rank-3 approximations of the density design field, i.e. when we approximate 𝒙≈∑j=1rλj​𝝍j𝒙superscriptsubscript𝑗1𝑟subscript𝜆𝑗subscript𝝍𝑗\\text{\\boldmath$x$}\\approx\\sum_{j=1}^{r}\\sqrt{\\lambda_{j}}\\text{\\boldmath$\\psi$}_{j} using r=1𝑟1r=1 or r=3𝑟3r=3, respectively. We emphasize that the cross-correlation constraints in (6) enforce θn+j′=θj′superscriptsubscript𝜃𝑛𝑗′superscriptsubscript𝜃𝑗′\\theta_{n+j}^{\\prime}=\\theta_{j}^{\\prime}, j=1,2,…,n𝑗12…𝑛j=1,2,...,n, i.e. the first and second half’s of 𝜽′∈ℝ2​nsuperscript𝜽′superscriptℝ2𝑛\\text{\\boldmath$\\theta$}^{\\prime}\\in\\mathbb{R}^{2n} must equal. However, as long as rank(𝑿)≠1𝑿1(\\text{\\boldmath$X$})\\neq 1, the rank approximations must not fulfill these constraints, since the constraint is explicitly enforced on the matrix 𝑿𝑿X via (26), not on the sum of the vectors 𝝍jsubscript𝝍𝑗\\text{\\boldmath$\\psi$}_{j}, j=1,…,r𝑗1…𝑟j=1,...,r, from which the approximations of 𝜽′superscript𝜽′\\text{\\boldmath$\\theta$}^{\\prime} can be computed, cf. (34). Therefore, Fig. 9 depicts two designs for each rank approximation corresponding to the first and second half’s of 𝜽′superscript𝜽′\\text{\\boldmath$\\theta$}^{\\prime}. Clearly, the two rank-1 approximative designs have no resemblance to the topology optimized design at all, which exposes the non-convexity of the primal optimization problem. These designs are dysfunctional, with post-processing objective function values of ≈0absent0\\approx 0. Indeed, this is not very surprising since the structures in Fig. 9 are symmetric with respect to the middle x𝑥x-plane, which clearly suppresses the ability to transform the symmetric first-order excitation mode to the asymmetric second-order target mode (Fig. 4 bottom). The two rank-3 approximative designs are not symmetric with respect to the middle x𝑥x-plane, wherefore their post-processing objective function values are greatly improved compared to the rank-1 approximative designs. We also tried to use these designs as initial guesses for the topology optimization to see whether it could improve the design, but the same local minima as depicted in Fig. 5 was found. We believe this can be caused by the relatively low rank of 𝑿𝑿X. The solution to the bound optimization problem and thus the bound value will depend on the discretization of the physics. To illustrate this, we plot the objective function of the topology and bound optimization problems versus the number of free design variables when using Ld=0.3333subscript𝐿𝑑0.3333L_{d}=0.3333 μ𝜇\\mum in Fig. 10. In this case, the objective function values are normalized by the number of degrees-of-freedom in the y𝑦y-direction. In the same figure, we also plot the topology optimization objective function calculated for the increasingly refined designs evaluated on the finest mesh. While the bound (black curve) is respected for each topology optimized design when evaluated on the meshes that they where optimized on (red curve), it is seen that the coarse topology optimized designs evaluated on the fine mesh (blue curve) actually surpass the predicted bound, which at a first glance should not be possible. This is however not surprising, yet a key point, when considering that the bounds have been computed for a particular problem size (mesh resolution), and thus are only guaranteed to be valid for said mesh resolutions. This example illustrates that one must exercise great care when computing bounds for a particular problem; the bounds are mathematical/computational in nature and thus relates to the particular optimization problem being solved and only make physical sense if the physics is sufficiently resolved. Although the design in the bottom panel of Fig. 5 exhibits almost perfect mode conversion and transmittance (T≈0.9996𝑇0.9996T\\approx 0.9996), it consists of large intermediate density regions wherein θ∈(−1,1)𝜃11\\theta\\in(-1,1). This hinders the physical realization of the design as it is challenging if not impossible to realize intermediate εrsubscript𝜀𝑟\\varepsilon_{r} values at such small length scales. Therefore, to end this section, we implement a \\sayconventional topology optimization approach with penalization, filtration and thresholding, such that intermediate density regions are penalized. The filtering is a traditional convolution filter (Bruns and Tortorelli , Bourdin ) with a cone shaped kernel such that Hj​k=max​(0,r−Δj​k)subscript𝐻𝑗𝑘max0𝑟subscriptΔ𝑗𝑘H_{jk}=\\text{max}(0,r-\\Delta_{jk}), where Njsubscript𝑁𝑗N_{j} is the set of nodes k𝑘k for which the node-to-node distance Δj​ksubscriptΔ𝑗𝑘\\Delta_{jk} to node j𝑗j is smaller than r𝑟r. The thresholding is performed via an approximate Heaviside projection around zero (Wang et al. [ref]52) The penalization follows a so-called pamping scheme (Jensen and Sigmund ), wherein intermediate density regions are penalized by introducing a density dependent attenuation, i.e. where η=1𝜂1\\eta=1 is a scaling parameter. In this way, intermediate densities θ∈(−1,1)𝜃11\\theta\\in(-1,1) are penalized since the objective is to maximize the output field magnitude, i.e. the optimizer will tend to avoid attenuating materials. We use a filter radius r𝑟r of three times the element length. The Heaviside projection slope parameter β𝛽\\beta is initially β=1𝛽1\\beta=1 and increased β←2​β←𝛽2𝛽\\beta\\leftarrow 2\\beta every 50th iteration until β=8𝛽8\\beta=8. The topology optimized design obtained using the conventional framework is depicted in Fig. 11. In a post-processing evaluation without pamping (η=0𝜂0\\eta=0 in (43)), the Fig. 11 design has a transmittance of T≈0.9685𝑇0.9685T\\approx 0.9685, i.e. by obtaining a realizable design we only drop approximately 3%percent33\\% in performance. We note that this performance drop can be reduced significantly by allowing added design freedom using a finer finite-element discretization (Christiansen ) and possibly continuation in η𝜂\\eta.\n\nReference markers found: [52]\n\nContext windows for each [ref]:\n[ref]52: k𝑘k for which the node-to-node distance Δj​ksubscriptΔ𝑗𝑘\\Delta_{jk} to node j𝑗j is smaller than r𝑟r. The thresholding is performed via an approximate Heaviside projection around zero (Wang et al. [ref]52) The penalization follows a so-called pamping scheme (Jensen and Sigmund ), wherein intermediate density regions are penalized by introducing a density dependent attenuation, i.e. where\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 52,\n            \"titles\": [\n                \"Architecting materials for extremal stiffness, yield and buckling strength\",\n                \"Giga-voxel computational morphogenesis for structural design\",\n                \"Large scale three-dimensional topology optimisation of heat sinks cooled by natural convection\",\n                \"Design of manufacturable 3d extremal elastic microstructure\",\n                \"A note on generalizing power bounds for physical design\",\n                \"Bounds on efficiency metrics in photonics\",\n                \"Heuristic methods and performance bounds for photonic design\",\n                \"Computational bounds for photonic design\",\n                \"Finite element procedures\",\n                \"Optimal shape design as a material distribution problem\",\n                \"Generating optimal topologies in structural design using a homogenization method\",\n                \"Internal contact modeling for finite strain topology optimization\",\n                \"Principles of optics: electromagnetic theory of propagation, interference and diffraction of light\",\n                \"Topology optimization of fluids in stokes flow\",\n                \"Filters in topology optimization\",\n                \"Convex optimization\",\n                \"Topology optimization of non-linear elastic structures and compliant mechanisms\",\n                \"Inverse design of optical mode converters by topology optimization: tutorial\",\n                \"Topological insulators by topology optimization\",\n                \"Topology optimization of transient vibroacoustic problems for broadband filter design using cut elements\",\n                \"Acoustic design by topology optimization\",\n                \"Introduction to finite element methods\",\n                \"Systematic design of high-q prestressed micro membrane resonators\",\n                \"Many physical design problems are sparse QCQPs\",\n                \"CVX: Matlab software for disciplined convex programming, version 2.1.\",\n                \"Graph implementations for nonsmooth convex programs\",\n                \"Optimizing multifunctional materials: design of microstructures for maximized stiffness and fluid permeability\",\n                \"A variational approach to the theory of the elastic behaviour of multiphase materials\",\n                \"Topology optimization of photonic crystal structures: a high-bandwidth low-loss t-junction waveguide\",\n                \"Topology optimization for nano-photonics\",\n                \"Exploiting sparsity in linear and nonlinear matrix inequalities via positive semidefinite matrix completion\",\n                \"Fundamental Limits of Nanophotonic Design\",\n                \"Computational bounds to light–matter interactions via local conservation laws\",\n                \"Narrow-band topology optimization on a sparsely populated grid\",\n                \"Semidefinite relaxation of quadratic optimization problems\",\n                \"Adaptive topology optimization of elastoplastic structures\",\n                \"Fundamental limits to optical response in absorptive systems\",\n                \"Hierarchical mean-field t operator bounds on electromagnetic scattering: Upper bounds on near-field radiative purcell enhancement\",\n                \"Mosek optimization toolbox for matlab\",\n                \"Effective thermal expansion coefficients and specific heats of composite materials\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]52 based on the context and research area of On performance bounds for topology optimization. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}