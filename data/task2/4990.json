{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: DynamicISP: Dynamically Controlled Image Signal Processor for Image Recognition\n\nPaper Abstract: \n\nPaper Section Text:\nVarious ablation studies are performed using the human detection RAW\ndataset [ref]48. We evaluate with the following\nsetting if not specified. TTFNet [ref]22 with ResNet18\n backbone is used as the detector. The entire pipeline\nis trained for 24 epochs with Adam optimizer \nfrom randomly initialized weights using a cosine decay learning rate\nschedule (0.001 magnitudes) whose maximum and minimum learning rates\nare 1e-3 and 1e-6 with a linear warmup for the first 1,000 iterations\n. The controller's learning rate is multiplied\nby 0.1 from the base learning rate. After that, the model is additionally\ntrained for 24 epochs with the same learning rate scheduling, but\nthe ISP and controller are frozen the samely with NeuralAE [ref]32.\nThis procedure slightly improves the accuracy from simple 48-epoch\ntraining. The input size is set to (576,‚Äâ352,‚Äâ3)5763523\\left(576,\\,352,\\,3\\right),\nand Rawgment [ref]48 is applied to bridge the\ndomain gap between the training data and challenging test data. During\nthe training phase, the identical frame is input twice instead of\nusing the continuous frame as described in Section 3.2\ndue to the rough frame rate of about 1 fps. In the evaluation phase,\non the other hand, we try both sequential input and identical input.\nWe set the channel size of the latent variable in the proposed controller\nas 256. The accuracy is evaluated with the average AP@0.5:0.95 \nscores of four-time experiments with different random seeds. We add each proposed component one by one to the NeuralAE controller\n[ref]32 to control two ISPs. One consisting of only\nGM and the other consisting of DN, SN, GM, and CS. The reason we do\nnot use AG is that we tried to control AG, but for some reason, it\nfailed on this dataset. The result is shown in Table 1. Even when controlling only the GM, the complexity of the GM function\nmakes it difficult to control with the NeuralAE method. The parameter\ninitializer (PI) contributes significantly to alleviate the difficulty;\nwithout PI, the detector's backbone has to deal with the pixel distributions\nbefore and after ISP, degrading detection performance. A detailed\nablation study of the PI is shown in Table 2.\nWe compare three types of PIs. One is a uniform sampling from (pl,n,m‚Äãi‚Äãn,pl,n,m‚Äãa‚Äãx)subscriptùëùùëôùëõùëöùëñùëõsubscriptùëùùëôùëõùëöùëéùë•\\left(p_{l,n,min},\\,p_{l,n,max}\\right);\nit learns how to control from all possible parameters. Another adds\nGaussian noise to the running mean of the previously used parameters\nby tracking the running mean and running variance of used parameters\nin the second frame. The last approach is our best method, which memorizes\nthe parameters for the 500 most recent data in a buffer and randomly\nadopts the value in the first frame. It takes into account correlations\nbetween parameters and does not approximate a Gaussian distribution,\nthus covering more necessary and sufficient parameter regions. Our\nbuffer memory automatically fits the search space to the minimum required,\nalthough it can still make the controller stable to the drastic environmental\nchange. The buffer memory creates a situation where the environment\nis changed from day to night in a one-time step. The residual output format of parameters (RO) further eases\nthe difficulty of controlling complex functions by making the controller\noutput the difference from the averaging good parameters for the entire\ndataset. For the normal RO, the static ISP parameter obtained by differentiable\ntuning in Table 3 is used as a constant\npl,n^^subscriptùëùùëôùëõ\\hat{p_{l,n}}. On the other hand, pl,n^^subscriptùëùùëôùëõ\\hat{p_{l,n}} in RO+ is jointly\noptimized with the dynamic ISP control from scratch. The gain from\nRO to RO+ is thought to be because the averaging good parameters for\nthe static ISP and DynamicISP is different. RO+ is practical as the\nparameters are tuned automatically. For multi-layer control, the latent update style controller\n(LU) further improves the accuracy. All-at-one estimation of all the\nparameters in the multi-layers is difficult and the proposed LU successfully\ndisentangles the problem setting. The proposed dynamic control is compared to static tuning approaches.\nIn this comparison, we use an ISP containing only a GM tone mapping\nfunction because tone mapping is known to have the biggest impact\non machine vision . One of the static tuning\napproaches for comparison is a grid search [ref]48.\nIn this approach, the detector is trained per searched parameters.\nSince it takes a huge time to train the detector per parameter set\nof large search space, it searches for one parameter of the simplest\ngamma function y=x1ùë¶superscriptùë•1y=x^{\\frac{1}{\\text{}}}. The other\nis a differentiable tuning approach to train the ISP and detector\nend-to-end [ref]48. Table 3\nshows the effectiveness of our dynamic control. Although both static\nISPs are optimized for machine vision, they are just optimal for the\nentire dataset and not optimal for each image. The experiments above are conducted by inputting identical images\ntwice instead of sequential input. We now check the availability of\nsequential inference without twice input. In this setting, optimal\nparameters for the previous frame are used, resulting in possibly\nsuboptimal. The result is shown in Table 4.\nContrary to expectations, a slight improvement is observed, and it\nmight come from the fact that the twice input case is evaluated under\nsevere settings. The initial parameters are set as the moving average\nof the parameters in the training phase and are far from the optimal\nparameters per image. On the other hand, in the sequential settings,\nthe previous parameters can be already decent values since consecutive\nframes are similar. From this experiment, efficient inference without\ninput twice is proved to be possible. Additionally, since the dataset\nis captured at about 1 fps, and about half of it is taken with a shaken\ncamera, consecutive frames may have some disparities. Inference at\nhigher frame rates might further improve the performance of sequential\ninference. The computational efficiency is evaluated by profiling the FLOPS of\neach component. As listed in Table 5,\nthe computational cost of our ISP controller is lightweight enough\nto be ignored compared with the detector despite our choice of a lightweight\nTTFNet detector with a ResNet18 backbone. Although our proposed LU\nhas a complicated computational graph as shown in Fig. 2,\nthe computational cost does not change very much (an increase of about\n4e-5 GFLOPS per each ISP function) thanks to the lightweight design\nwith 1-D latent variable manipulations. The computational cost of\nthe detector in the input twice setting is not doubled from other\nsettings because the whole part of the calculation for the first input\nis not needed. If ISP functions are lightweight classical functions,\nthe dynamic ISP control can be efficient even as a single image detector\nwith the inputting twice setting. ‚ô£‚ô£\\clubsuit: The original augmentation in stead of Rawgment[ref]48\nis used. ‚Ä†‚Ä†\\dagger: Full version of NeuralAE including Global Feature\nBranch, which is a histgram-based encoder to support Semantic\nFeature Branch. ‚ô†‚ô†\\spadesuit: Our implementations of DN and SN have a lot of duplicate\ncalculations and are not optimized. Various evaluations are performed against the state-of-the-art. The\nlatency is measured on an RTX2080 GPU. The result is shown in Table\n6. One category for comparison is DNN-based encoder-decoder ISPs. The\nproblem with the DNN ISP is that there are no input and ground truth\npairs to train them. As pointed out in ,\ncreating clean ground truth for challenging noisy/blurry environment\ndata is difficult. So, three kinds of DNN ISPs are tried. One is UNet(s);\nan UNet  based ISP , and the ISP and detector\nare trained end-to-end from scratch. It means that the ISP is trained\nonly with the detection loss. The second is AW+sGM+UNet(f); a fixed\nstate-of-ther-art UNet ISP trained for dark environments \nis used following auto-white balance (AWB) and simple gamma (sGM).\nThe AWB and sGM are identical to the preprocessing pipeline of the\ntrained UNet. In this setting, the UNet ISP is trained with paired\ndata for dark environments proposed in .\nThe third is AW+sGM+UNet(p); end-to-end training is performed from\nthe pre-trained UNet ISP's weight to tune it to the target sensor\nand downstream detector. The other category is classical function-based ISPs. As for NeuralAE,\nwe do not convert the images to those taken with lower-quality sensors\nas the original paper did to make a fair comparison and use our ISP\nfunctions because the details are missing. Comparing DNN ISP and classical\nISPs, the tuned classical ISPs outperform the existing state-of-the-art\nDNN ISPs in challenging environments despite the low computational\ncost. One of the reasons should be the lack of paired data for the\ntarget dataset to train the DNN ISPs, but it is difficult to create\nground truth images for challenging RAW data. ISPs that do not require\npaired data and can be optimized with downstream task loss must be\nuseful. As to NeuralAE [ref]32, we try two of its\nproposed encoders, Semantic Feature Branch and Global\nFeature Branch. Our Global Feature Branch implementation uses\nthe histc() function implemented in Pytroch \nto generate multiple histograms of the image, but it is time-consuming.\nSo we only use Semantic Feature Branch in our method. We also\ntried further tuning from the well-trained diff. tuning (GM) [ref]32\nweight using Hardware-in-the-loop [ref]48, but\nit did not improve accuracy due to overfitting the training data.\nAlthough we use vanilla CMA-ES in the Hardware-in-the-loop due to\nthe missing information about the modifications, it should be no problem\nsince only three parameters in the GM function are the target for\nthe optimization. Comparing ours with both categories, our method achieves the best\naccuracy in spite of the low computational cost. Especially, compared\nwith diff. tuning, ours further improved detection accuracy with a\nlittle computational gain. While our computational cost and inference\nspeed are almost unchanged compared to static ISP (diff. tuning),\nthe number of parameters is increased. This is because the fully connected\nlayers whose channel sizes are 1024 in the Semantic Feature\nBranch have many parameters despite a few computational costs. If\nthe target device is constrained by the number of parameters, we can\nreduce their channel sizes. It is not a bottleneck, but an enough\nlarge value of 256 is also set for the channel size for latent variable\nin LU since the computational cost hardly increases. Although NeuralAE\nalso controls the exposure function, it is a simple function. Instead,\nours enables the control of complicated functions and yields more\nsuitable images for the downstream detector like Fig. 4.\n\nReference markers found: [48]\n\nContext windows for each [ref]:\n[ref]48: Various ablation studies are performed using the human detection RAW\ndataset [ref]48. We evaluate with the following\nsetting if not specified. TTFNet [ref]22 with ResNet18\n backbone is used as the detector. The entire pipeline\nis trained for 24 epochs with Adam optimizer\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 48,\n            \"titles\": [\n                \"ReconfigISP: Reconfigurable Camera Image Processing Pipeline\",\n                \"Cross-camera convolutional color constancy\",\n                \"Unprocessing Images for Learned Raw Denoising\",\n                \"Reconfiguring the imaging pipeline for computer vision\",\n                \"Learning to see in the dark\",\n                \"Hinet: Half instance normalization network for image restoration\",\n                \"Dynamic Convolution: Attention over Convolution Kernels\",\n                \"Dynamic ReLU\",\n                \"Model-Based Image Signal Processors via Learnable Dictionaries\",\n                \"Dirty pixels: Towards end-to-end image processing and perception\",\n                \"Zero-Reference Deep Curve Estimation for Low-Light Image Enhancement\",\n                \"Isp4ml: The role of image signal processing in efficient deep learning vision systems\",\n                \"Delving deep into rectifiers: Surpassing human-level performance on imagenet classification\",\n                \"Deep Residual Learning for Image Recognition\",\n                \"Optimization of the isp parameters of a camera through differential evolution\",\n                \"Crafting object detection in very low light\",\n                \"Enlightengan: Deep light enhancement without paired supervision\",\n                \"Adam: A method for stochastic optimization\",\n                \"Restoring extremely dark images in real time\",\n                \"Microsoft COCO: Common Objects in Context\",\n                \"Darts: Differentiable architecture search\",\n                \"Deep-flexisp: A three-stage framework for night photography rendering\",\n                \"Training-time-friendly network for real-time object detection\",\n                \"SGDR: Stochastic Gradient Descent with Warm Restarts\",\n                \"Mbllen: Low-light image/video enhancement using cnns\",\n                \"Toward Fast, Flexible, and Robust Low-Light Image Enhancement\",\n                \"Theory of edge detection\",\n                \"Dancing under the stars: video denoising in starlight\",\n                \"GenISP: Neural ISP for Low-Light Machine Cognition\",\n                \"Hardware-in-the-loop end-to-end optimization of camera image processing pipelines\",\n                \"Automatic isp image quality tuning using nonlinear optimization\",\n                \"Degree-of-linear-polarization-based color constancy\",\n                \"Neural auto-exposure for high-dynamic range object detection\",\n                \"PyTorch: An Imperative Style, High-Performance Deep Learning Library\",\n                \"Automatic image quality tuning framework for optimization of isp parameters based on multi-stage optimization approach\",\n                \"Day-to-Night Image Synthesis for Training Nighttime Neural ISPs\",\n                \"High dynamic range imaging: acquisition, display, and image-based lighting\",\n                \"End-to-end high dynamic range camera pipeline optimization\",\n                \"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\n                \"ISP Distillation\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]48 based on the context and research area of DynamicISP: Dynamically Controlled Image Signal Processor for Image Recognition. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}