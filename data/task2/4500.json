{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Analyzing social media with crowdsourcing in Crowd4SDG This work was supported European Commission H2020 project Crowd4SDG “Citizen Science for Monitoring Climate Impacts and Achieving Climate Resilience”, No. 872944. Corresponding author: Barbara Pernici, ORCID: 0000-0002-2034-9774.\n\nPaper Abstract: \n\nPaper Section Text:\nThe following case studies are presented to illustrate the different contexts of data analysis and their challenges and results. 2019 Albania earthquake:\nIn this case study, we aimed to provide a working example of how we fit the conceptual and mathematical framework behind Crowdnalysis to real-world data, and demonstrate how we could benefit from our software library in an emergency scenario, where we refer to crowdsourcing. We have published the framework and case study results in . The imagery dataset we worked with was the courtesy of the Qatar Computing Research Institute, which contains social media images posted for the 2019 Albanian earthquake filtered by their Artificial Intelligence for Disaster Response (AIDR) platform . The AIDR collected Twitter posts for four days after November 26th, 2019, when the earthquake had occurred, which was the strongest for the country in the last 40 years.\nThe AIDR automatically classified 907907907 images as relevant out of 9,24192419,241 collected. As mentioned in Section 3.5, crowdsourcing was performed using three different groups of citizens to annotate the relevant images and the severity of damage seen in the photos by humans compared to the AIDR. Specifically, to obtain a ground truth for the labels, we first worked with ten disaster experts and configured a redundancy of 333 for annotations on the Crowd4EMS platform , a precursor of CSPB.\nWe then referred to a group of 50 volunteers on Crowd4EMS with a redundancy of 333. Finally, 171 paid workers annotated the same dataset on the Amazon Mechanical Turk (MTurk) platform171717https://www.mturk.com with a redundancy of 101010. Using Crowdnalysis, we first computed the experts’ consensus as the ground truth and, successively, calculated the error rates—in labeling—of the three crowds. We also carried out a prospective analysis of the communities designed in Section 3.5 of this article.\nThis case study is related to the use case C in Fig. 3. Subsequently, we extended our analysis with this dataset incorporating VisualCit for further filtering the AIDR dataset for relevant images; hence, we adopted the use case D in the same figure.\nWe provide the confusion matrix for VisualCit in Table 1, which shows a 0.830.830.83 precision, a 0.900.900.90 recall and a 0.820.820.82 overall accuracy of VisualCit, with respect to the experts’ consensus on relevance. Moreover, we conducted a hypothetical experiment to determine whether the results would be accurate if the experts and the MTurk crowd annotated the subset of the AIDR dataset filtered by VisualCit. Specifically, after removing the annotation data for the 253253253 tasks excluded by VisualCit, we calculated the new experts’ consensus and error rates of the experts and MTurk crowd by Crowdnalysis. We observed that the error rates for both communities remained almost the same (e.g., +0.010.010.01 in experts’ recall, -0.040.040.04 in MTurk crowd’s specificity). Our extended analysis suggests that when we can trade crowdsourcing efforts for higher recall, we can safely bring VisualCit to automatically filter relevant images, thus; reducing the number of irrelevant tasks to be processed by crowd workers. COVID-19 social distancing case study: This case study, developed in 2020 during the initial phases of the pandemic, aimed to derive indicators of social distancing behavior and face mask usage in different countries\n.\nThis case study is related to use case\nF shown in Fig. 3. Selected raw data were captured from social media from May to August 2020, crawling Twitter with generic COVID-related keywords. Filtering posts with VisualCit, selecting only images that are classified as photos (excluding memes, maps, drawings, etc.), in outdoor spaces, and containing at least two persons. When a native geolocation was not present in the tweet, the posts were geolocated using the CIME algorithm . Crowdsourcing performed with the CS Project Builder was used to confirm the relevance according to the above-mentioned criteria and the automatic geolocation of the images, and to assess whether face masks were correctly used and social distancing rules followed.\nThe majority vote was used to compute the consensus on the crowd annotations. The resulting images were aggregated to build behavioral indicators on a national basis. Thailand flood alerting case study: In this case study, a large-scale flood event in Thailand was evaluated. Tropical storm Dianmu181818https://floodlist.com/asia/thailand-tropical-storm-dianmu-floods-september-2021 hit Thailand in late September and October 2021. According to the UNOSAT Thailand flood monitoring dashboard191919https://unosat-geodrr.cern.ch/portal/apps/opsdashboard/index.html#/4f878691713a40f3b8ef3140e63c9f6d, as a preliminary assessment around 1.4 million people were affected by flooding. The goal of this case study was to assess the ability to capture the onset of large scale emergencies, while enabling a spatial description of the event. This case study refers to the use of Cases G and H in Fig. 3. An overall description of this approach can be found in [ref]6. Tweets corresponding to event onset were crawled using a small set of flood-related Thai keywords, provided by the UNOSAT office in Bangkok. The time series corresponding to keywords’ usage during event onset is shown in Fig. 13. After detecting the onset trend, a VisualCit pipeline was executed to remove near-duplicates, non-photos, and NSFW images, to exclude irrelevant content. The filtered posts were then geolocated with CIME, focusing on locations within Thailand’s national borders. The results were then aggregated by administrative region and normalized using the population count. The aggregate descriptions of the results and insights from the case studies are represented in Table 2. We present here the main results and outcomes of the case studies presented above and, discuss their validation procedure. These three case studies were aimed at a range of goals. In the Albania case study, the focus was on analyzing images from posts assessing damage to buildings, while in the COVID and Thailand case studies, the goal was to generate thematic maps providing evidence about ongoing situations. The case studies were characterized using different types of source data. In most cases, social media data are obtained through the crawling of Twitter, while in one case (the Albania case study), the initial dataset is available as the result of previous analyses. Consequently, the volume of posts to be analyzed was significantly different. In addition to the volume aspect, the three case studies were characterized by different velocity characteristics, and timeliness requirements. In particular, the Thailand flood case study has a large number of posts to be analyzed rapidly to provide a rapid assessment of the situation, while in the COVID case study, the volume is high, while timeliness is less stringent, as the analysis is performed on a weekly basis.\nThe VisualCit results are validated in different ways, according to the tasks to be performed. In the Albania case study, VisualCit was used to further pinpoint relevant images from the initial dataset, and a significant improvement in accuracy was obtained.\nIn the COVID case study, filtering resulted in only 0.5% of the images being considered relevant for the task to be performed. A detailed evaluation of precision and recall for different filters was published in , and the accuracy of geolocation measured on a country basis was 84%. In the Thailand case study, low recall was compensated by analyzing the text of the tweets, thus improving completeness in the data for the considered regions.\nCrowdsourcing was only applied to the first two case studies. In Albania case study, crowdsourcing was performed using three different communities: a group of experts, a group of volunteers, and a group of paid workers on Amazon Turk, as detailed above. In the COVID case study, characterized by a high volume even notwithstanding the high VisualCit selectivity, the CS Project Builder was used with redundancy 3 and majority vote. The main problem encountered in this case was related to the size of the data and the availability of a crowd of sufficient size for performing the analysis, and the costs of the analysis when a paid crowd is employed.\nIn the Albania case study, the performance of the crowd was analyzed using Crowdnalysis, based on comparisons with expert evaluations, as illustrated in Section 3.5. However, the size of the COVID case study did not allow extensive data validation of the results, so an indirect validation procedure was adopted, comparing the results with similar analyses conducted at the same time with surveys, highlighting a significant correlation of the results .\nIn addition, in the case of the Thailand flood case study, validation was performed by comparing the obtained data with data collected in the field, showing good qualitative results of the method [ref]6. The selected case studies represent various goals and conditions.\nIn general, the volume of data is high, and timeliness may be a constraint, whereas the number of relevant tweets for a given goal is usually small. Fast automatic filtering tools, such as VisualCit can be successfully employed to speed up the analysis and reduce the number of irrelevant elements to be examined. When timeliness poses constraints of less than 24h to analyze a situation, acceptable results can be obtained with completely automated tools, while better accuracy can be obtained by adding crowdsourcing if time is available for the analysis.\nIn general, while citizen scientists for crowdsourcing activities are difficult or costly to recruit, better results can be obtained with a selected crowd or experts, thus showing the importance of crowd analysis.\n\nReference markers found: [6]\n\nContext windows for each [ref]:\n[ref]6: of large scale emergencies, while enabling a spatial description of the event. This case study refers to the use of Cases G and H in Fig. 3. An overall description of this approach can be found in [ref]6. Tweets corresponding to event onset were crawled using a small set of flood-related Thai keywords, provided by the UNOSAT office in Bangkok. The time series corresponding to keywords’ usage\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 6,\n            \"titles\": [\n                \"A first approach to closeness distributions\",\n                \"Using social media data in emergency management: a proposal for a socio-technical framework and a systematic literature review\",\n                \"Processing social media images by combining human and machine computing during crises\",\n                \"Exploring the use of deep learning with crowdsourcing to annotate images\",\n                \"Truth Is a Lie: Crowd Truth and the Seven Myths of Human Annotation\",\n                \"Automatic analysis of social media images to identify disaster type and infer appropriate emergency response\",\n                \"TriggerCit: Early Flood Alerting using Twitter and Geolocation–a comparison with alternative sources\",\n                \"crowdnalysis: A software library to help analyze crowdsourcing results\",\n                \"A conceptual probabilistic framework for annotation aggregation of citizen science data\",\n                \"Data democracy–increased supply of geospatial information and expanded participatory processes in the production of data\",\n                \"Maximum Likelihood Estimation of Observer Error-Rates Using the EM Algorithm\",\n                \"CrowdTruth 2.0: Quality Metrics for Crowdsourcing with Disagreement\",\n                \"Measuring nominal scale agreement among many raters\",\n                \"Social media as an information source for rapid flood inundation mapping\",\n                \"Crowds, citizens, and science: a multi-dimensional framework and agenda for future research\",\n                \"Citizen science and the united nations sustainable development goals\",\n                \"Codified hashtags for weather warning on twitter: an italian case study\",\n                \"The age of citizen cyberscience\",\n                \"Handbook of Inter-Rater Reliability: The Definitive Guide to Measuring the Extent of Agreement Among Raters\",\n                \"OpenStreetMap: User-generated street maps\",\n                \"E2mc: Improving emergency management service practice through social media and crowdsourcing analysis in near real time\",\n                \"Processing Social Media Messages in Mass Emergency: A Survey\",\n                \"AIDR: Artificial intelligence for disaster response\",\n                \"Using AI and Social Media Multimodal Content for Disaster Response and Management: Opportunities, Challenges, and Future Directions\",\n                \"ISCRAM 2022 Conference Proceedings - 19th International Conference on Information Systems for Crisis Response and Management\",\n                \"Theoretical Analysis and Efficient Algorithms for Crowdsourcing\",\n                \"Integrating social media into a pan-european flood awareness system: a multilingual approach\",\n                \"Citizen science: An information quality research frontier\",\n                \"Real-time crisis mapping of natural disasters using social media\",\n                \"Image-based Social Sensing: Combining AI and the Crowd to Mine Policy-Adherence Indicators from Twitter\",\n                \"Automatic image filtering on social networks using deep learning and perceptual hashing during crises\",\n                \"A Real-time System for Detecting Landslide Reports on Social Media using Artificial Intelligence\",\n                \"The Benefits of a Model of Annotation\",\n                \"Comparing Bayesian Models of Annotation\",\n                \"A near-real-time global landslide incident reporting tool demonstrator using social media and artificial intelligence\",\n                \"Crowd4SDG Deliverable 5.1 - Initial report on relevance and quality-related considerations of citizen-science generated data\",\n                \"Crowd4SDG Deliverable 5.2 - Data usability assessment and recommendations for SDGs GEAR cycle 1\",\n                \"Citizen science data to track SDG progress: Low-hanging fruit for Governments and National Statistical Offices\",\n                \"Crowd4Ems: A crowdsourcing platform for gathering and geolocating social media content in disaster response\",\n                \"Tweet analysis for real-time event detection and earthquake reporting system development\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]6 based on the context and research area of Analyzing social media with crowdsourcing in Crowd4SDG This work was supported European Commission H2020 project Crowd4SDG “Citizen Science for Monitoring Climate Impacts and Achieving Climate Resilience”, No. 872944. Corresponding author: Barbara Pernici, ORCID: 0000-0002-2034-9774.. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}