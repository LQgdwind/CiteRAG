{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Quantum computational complexity of matrix functions\n\nPaper Abstract: \n\nPaper Section Text:\nIn which problems\nfrom matrix algebra can we expect strong\n(i.e. super-polynomial) quantum speedups?\nRecently, powerful abstract frameworks for approximating matrix functions via matrix polynomials have been established [ref]1 , with polylogarithmic runtime in the dimension of the matrix for a broad class of instances. This provides a unified perspective on synthesizing many quantum algorithms, as matrix polynomials can now be thought of as building blocks to construct other interesting matrix functions on a quantum computer  . However, not all efficient quantum algorithms for matrix polynomials lead to a super-polynomial quantum speedup; indeed, some have classically efficient counterparts. In this work, we aim to characterize this dividing line in terms of computational complexity. Apart from matrix polynomials, we also\ndiscuss the hardness of two more concrete problems: matrix inversion and time evolution, which themselves can also be considered building blocks for synthesizing other matrix functions     [ref]8 [ref]9  . We study two primitive problems for matrix algebra. First, given a Hermitian matrix A𝐴A and function f𝑓f, we ask for one matrix element [f​(A)]i​jsubscriptdelimited-[]𝑓𝐴𝑖𝑗[f(A)]_{ij}. We refer to this as the matrix element problem, which can be considered as an elemental matrix algebra task. Second, we consider a task, which we refer to as the local measurement problem, that at first sight may appear more native to quantum approaches than the previous one: Performing a local measurement on a state acted on by f​(A)𝑓𝐴f(A) without normalization. That is, we ask for the value ⟨0|⊗n​f​(A)†​(|0⟩​⟨0|⊗𝟙N/2)​f​(A)​|0⟩⊗nsuperscriptbra0tensor-productabsent𝑛𝑓superscript𝐴†tensor-productket0bra0subscript1𝑁2𝑓𝐴superscriptket0tensor-productabsent𝑛\\langle 0|^{\\otimes n}f(A)^{\\dagger}\\left(|\\hskip 0.5pt0\\rangle\\!\\langle 0\\hskip 0.5pt|\\otimes\\mathds{1}_{N/2}\\right)f(A)|0\\rangle^{\\otimes n}, where |0⟩​⟨0|ket0bra0|\\hskip 0.5pt0\\rangle\\!\\langle 0\\hskip 0.5pt| is a projector acting on the first qubit and 𝟙N/2subscript1𝑁2\\mathds{1}_{N/2} is the identity matrix on the remaining n−1𝑛1n-1 qubits, for a total system dimension N=2n𝑁superscript2𝑛N=2^{n}. Immediate questions arise: how do the complexities of these two problems relate to each other? And how do they depend on the input models assumed? For both these problems, we derive hardness results for several different settings and problem-parameter regimes (see Fig. 1). The complexity of matrix function problems can depend on various factors, which we tune individually to investigate their effect on the hardness of the problems. The concrete properties that we study are: The access model to the matrix The matrix normalization The matrix sparsity The desired precision The type of function Let us now briefly discuss and motivate each of these. Access model. A standard matrix access model that we investigate is the so-called sparse access model (Def. 2), where the non-zero matrix entries of A𝐴A in the computational basis are accessible via an efficiently computable function. This is commonly studied both constructively for quantum algorithms as well as for computational complexity analysis. Without an efficient structure for matrix entries, a generic quantum data structure of size Ω​(N)Ω𝑁\\Omega(N) would be required, even for row- and column-sparse matrices. That is,\nΩ​(N)Ω𝑁\\Omega(N)\ngates are required to instantiate the access model for a generic N×N𝑁𝑁N\\times N row- or column-sparse matrix .\nSparse access should then be seen as one way of imposing efficient access to large matrices. By “efficient,” we mean that there is a polylogarithmic-sized circuit in both depth and width able to provide access to the entries. Another reasonable type of access one might ask for, particularly in physically-motivated problems, is classical\naccess to the non-zero coefficients of A𝐴A\nin the Pauli basis (Def. 3).\nThis access model can be considered as a concrete special case of sparse access, and it can only be efficient generically if there are polylogarithmically many non-zero coefficients. This condition is commonly encountered in chemistry, material science, or many-body physics applications. Alternatively, the non-zero Pauli coefficients can often have some underlying structure enabling efficient description, as has been recently considered in a line of work on randomized quantum algorithms    . The main question we ask concerning these access models is: does providing a matrix in Pauli access change the complexity of these problems compared to sparse\naccess in the computational basis? Answering this question should shed light on whether hardness results for matrix algebra problems in one model hold any relevancy for hardness in the other one. For instance, if a problem’s complexity is unchanged by the access model, this suggests a form of complexity robustness with respect to the matrix representation.\n Sparsity. To a certain extent, the sparser the matrix, the easier it is to perform matrix algebra — both for deterministic and randomized classical algorithms. Moreover, as discussed above, it is common to ask for efficient sparse access models to allow for scalable quantum algorithms.\nThus, it is pertinent to ask whether quantum algorithms become classically simulatable at some sparsity level (both in the sparse and Pauli access models).\nHowever, in the absence of further conditions, we cannot expect efficient classical algorithms for general matrix functions even for 𝒪​(1)𝒪1\\mathcal{O}(1)-row-sparse matrices (in the computational basis) without further constraints — for example, the problem of computing a local measurement for f​(A)=A−1𝑓𝐴superscript𝐴1f(A)=A^{-1} is well-known to be BQP-complete for 𝒪​(1)𝒪1\\mathcal{O}(1)-sparse matrices .\nIn our work we start with the case of 𝒪​(poly⁡log⁡(N))𝒪poly𝑁\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)) many non-zero coefficients per row or 𝒪​(poly⁡log⁡(N))𝒪poly𝑁\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)) non-zero coefficients in the Pauli basis (the maximal amounts that still allow efficient representation of matrices with generic coefficients), and investigate the change in complexity when we tune the sparsity down with additional constraints. Matrix normalization. For many problems, the complexity of the classical algorithms solving them depends on norms different from the operator norm  , and thus considering different normalization conditions for A𝐴A can affect such dequantization results. Here, we consider normalization conditions based mostly on three different matrix norms: the operator norm ‖A‖norm𝐴\\|A\\|; the larger induced 111-norm ‖A‖1subscriptnorm𝐴1\\|A\\|_{1} (for the sparse access model) and the vector ℓ1subscriptℓ1\\ell_{1}-norm of the Pauli coefficients (for the Pauli access model). We consider the classes of problems where each of these norms is upper-bounded by 111 and also investigate how the complexity changes when stronger bounds are put on these norms. Error parameter.\nFor each function of interest, we consider two regimes of additive precision for the desired estimations: 1/ε=𝒪​(poly⁡log⁡(N))1𝜀𝒪poly𝑁1/\\varepsilon=\\mathcal{O}(\\operatorname{poly}\\log\\!\\left(N\\right)) and 1/ε=𝒪​(1)1𝜀𝒪11/\\varepsilon=\\mathcal{O}(1). Recent work 0 shows that\nchanging from the former to the latter can make certain BQP-complete problems turn classically efficiently solvable, under access assumptions.\nMoreover, understanding the impact of the precision parameter in a problem’s complexity is a central question regarding the Quantum PCP Conjecture 1. Type of function. We study two classes of polynomials. First, we study monomials. This is arguably the simplest instance of a polynomial,\nand thus potentially the most amenable one to classical approaches. Second, we study Chebyshev polynomials. This is a powerful class of polynomials in numerical approximation theory 2 and has been widely studied in the context of quantum algorithms 3 [ref]1  4 5.\nFinally, we also consider time evolution, also known as\nHamiltonian simulation (i.e. ft​(A)=e−i​A​tsubscript𝑓𝑡𝐴superscript𝑒𝑖𝐴𝑡f_{t}(A)=e^{-iAt}), and the inverse function.\nMoreover, for each function family, we characterize the complexity of sub-classes given by restricted regimes of relevant parameters (the polynomial degree, evolution time, or matrix condition number). The rest of our manuscript is structured as follows: we discuss related work in Section 1.2, we present a condensed form of our results in Section 2 along with a summary in Table 1 and Figure 1, and the remainder of the manuscript is dedicated to elucidating our results in full detail with proofs.\n\nReference markers found: [1]\n\nContext windows for each [ref]:\n[ref]1: matrix algebra can we expect strong\n(i.e. super-polynomial) quantum speedups?\nRecently, powerful abstract frameworks for approximating matrix functions via matrix polynomials have been established [ref]1 , with polylogarithmic runtime in the dimension of the matrix for a broad class of instances. This provides a unified perspective on synthesizing many quantum algorithms, as matrix polynomials\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 1,\n            \"titles\": [\n                \"Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics\",\n                \"Hamiltonian Simulation by Qubitization\",\n                \"Grand Unification of Quantum Algorithms\",\n                \"Product Decomposition of Periodic Functions in Quantum Signal Processing\",\n                \"Heisenberg-Limited Ground-State Energy Estimation for Early Fault-Tolerant Quantum Computers\",\n                \"Fourier-based quantum signal processing\",\n                \"Quantum algorithm for ground state energy estimation using circuit depth with exponentially improved dependence on precision\",\n                \"Faster ground state energy estimation on early fault-tolerant quantum computers via rejection sampling\",\n                \"Linear combination of Hamiltonian simulation for nonunitary dynamics with optimal state preparation cost\",\n                \"Quantum algorithm for linear non-unitary dynamics with near-optimal dependence on all parameters\",\n                \"Quantum eigenvalue processing\",\n                \"Circuit complexity of quantum access models for encoding classical data\",\n                \"Random Compiler for Fast Hamiltonian Simulation\",\n                \"A randomized quantum algorithm for statistical phase estimation\",\n                \"Qubit-efficient randomized quantum algorithms for linear algebra\",\n                \"qSWIFT: High-order randomized compiler for Hamiltonian simulation\",\n                \"Quantum algorithm for linear systems of equations\",\n                \"Quantum and classical query complexities of functions of matrices\",\n                \"Dequantizing algorithms to understand quantum advantage in machine learning\",\n                \"Dequantizing the Quantum Singular Value Transformation: Hardness and Applications to Quantum Chemistry and the Quantum PCP Conjecture\",\n                \"Guest column: the quantum PCP conjecture\",\n                \"Faster Algorithms via Approximation Theory\",\n                \"Quantum Algorithm for Systems of Linear Equations with Exponentially Improved Dependence on Precision\",\n                \"Randomized semi-quantum matrix processing\",\n                \"Quantum walks, the discrete wave equation and Chebyshev polynomials\",\n                \"A simple PromiseBQP-complete matrix problem\",\n                \"A (simple) classical algorithm for estimating Betti numbers\",\n                \"Quantum Mechanical Computers\",\n                \"Fast universal quantum computation with railroad-switch local Hamiltonians\",\n                \"A quantum-inspired classical algorithm for recommendation systems\",\n                \"Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions\",\n                \"An improved quantum-inspired algorithm for linear regression\",\n                \"Sampling-Based Sublinear Low-Rank Matrix Arithmetic Framework for Dequantizing Quantum Machine Learning\",\n                \"Faster Quantum-Inspired Algorithms for Solving Linear Systems\",\n                \"Classical approximation schemes for the ground-state energy of quantum and classical ising spin hamiltonians on planar graphs\",\n                \"Logarithmic depth circuits for algebraic functions\",\n                \"Logical reversibility of computation\",\n                \"Arithmetic circuits: A survey of recent results and open questions\",\n                \"A Comprehensive Study of Quantum Arithmetic Circuits\",\n                \"Parallel Quantum Algorithm for Hamiltonian Simulation\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]1 based on the context and research area of Quantum computational complexity of matrix functions. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}