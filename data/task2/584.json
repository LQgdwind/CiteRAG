{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Fast Hybrid Network Algorithms for Shortest Paths in Sparse Graphs\n\nPaper Abstract: \n\nPaper Section Text:\nAs theoretical models for hybrid networks have only been proposed recently, only few results for such models are known at this point  [ref]7 .\nComputing an exact solution for SSSP in arbitrary graphs can be done in O~​(SPD)~𝑂SPD\\widetilde{O}(\\sqrt{\\textsf{SPD}}) rounds , where SPD is the so-called shortest path diameter of G𝐺G.\nFor large SPD, this bound has recently been improved to O~​(n2/5)~𝑂superscript𝑛25\\widetilde{O}(n^{2/5}) .\nThe authors of  also present several approximation algorithms for SSSP: A (1+ε)1𝜀(1+\\varepsilon)-approximation with runtime O~​(n1/3/ε6)~𝑂superscript𝑛13superscript𝜀6\\widetilde{O}(n^{1/3}/\\varepsilon^{6}), a (1/ε)O​(1/ε)superscript1𝜀𝑂1𝜀(1/\\varepsilon)^{O(1/\\varepsilon)}-approximation running in O~​(nε)~𝑂superscript𝑛𝜀\\widetilde{O}(n^{\\varepsilon}) rounds and a 2O​(log⁡n​log⁡log⁡n)superscript2𝑂𝑛𝑛2^{O(\\sqrt{\\log n\\log\\log n})}-approximation with runtime 2O​(log⁡n​log⁡log⁡n)superscript2𝑂𝑛𝑛2^{O(\\sqrt{\\log n\\log\\log n})}.\nFor APSP there is an exact algorithm that runs in O~​(n2/3)~𝑂superscript𝑛23\\widetilde{O}(n^{2/3}) rounds, a (1+ε)1𝜀(1+\\varepsilon)-approximation running in O~​(n/ε)~𝑂𝑛𝜀\\widetilde{O}(\\sqrt{n/\\varepsilon}) rounds (only for unweighted graphs) and a 333-approximation with runtime O~​(n)~𝑂𝑛\\widetilde{O}(\\sqrt{n}) .\nIn , the authors give a lower bound of Ω~​(n1/3)~Ωsuperscript𝑛13\\widetilde{\\Omega}(n^{1/3}) rounds for computing the diameter in arbitrary graphs in our model.\nThey also give approximation algorithms with approximation factors (3/2+ε)32𝜀(3/2+\\varepsilon) and (1+ε)1𝜀(1+\\varepsilon) that run in time O~​(n1/3/ε)~𝑂superscript𝑛13𝜀\\widetilde{O}(n^{1/3}/\\varepsilon) and O~​(n0.397/ε)~𝑂superscript𝑛0.397𝜀\\widetilde{O}(n^{0.397}/\\varepsilon), respectively.\nEven though APSP and the diameter problem are closely related, we demonstrate that the diameter can be computed much faster in our hybrid network model for certain graphs classes. As already pointed out, the global network in our model has a close connection to overlay networks.\nThe NCC model, which has been introduced in [ref]7, mainly focuses on the impact of node capacities, especially when the nodes have a high degree.\nSince, intuitively, for many graph problems the existence of each edge is relevant for the output, most algorithms in [ref]7 depend on the arboricity a𝑎a of G𝐺G (which is, roughly speaking, the time needed to efficiently distribute the load of all edges over the network).\nThe authors present O~​(a)~𝑂𝑎\\widetilde{O}(a) algorithms for local problems such as MIS, matching, or coloring, an O~​(D+a)~𝑂𝐷𝑎\\widetilde{O}(D+a) algorithm for BFS tree, and an O~​(1)~𝑂1\\widetilde{O}(1) algorithm to compute a minimum spanning tree (MST).\nRecently, O~​(Δ)~𝑂Δ\\widetilde{O}(\\Delta)-time algorithms for graph realization problems have been presented [ref]6, where ΔΔ\\Delta is the maximum node degree; notably, most of the algorithms work in the NCC0 variant.\nFurthermore, Robinson  investigates the information the nodes need to learn to jointly solve graph problems and derives a lower bound for constructing spanners in the NCC.\nFor example, his result implies that spanners with constant stretch require polynomial time in the NCC, and are therefore harder to compute than MSTs.\nSince our global network behaves like an overlay network, we can make efficient use of the so-called shortest-path diameter reduction technique .\nBy adding shortcuts between nodes in the global network, we can bridge large distances quickly throughout our computations. Our work also relates to the literature concerned with overlay construction     4 5, where the goal is to transform a low-degree weakly-connected graph into a low-depth overlay network such as a binary tree using node introductions.\nRecently, 5 showed a randomized O​(log⁡n)𝑂𝑛O(\\log n) time overlay construction algorithm for the NCC0 model, if the initial degree is constant.\nOur algorithms directly yield a deterministic O​(log⁡n)𝑂𝑛O(\\log n) time alternative for pseudotrees.\nIt may be interesting to see whether our results can be used to compute deterministic overlay construction algorithms for sparse graphs. A problem closely related to SSSP is the computation of short routing paths between any given nodes.\nThe problem has, for example, been studied in mobile ad-hoc networks 9, in which constant-competitive routing paths can be computed in O​(log2⁡n)𝑂superscript2𝑛O(\\log^{2}n) rounds 5.\nThe authors consider a hybrid network model similar to , where nodes can communicate using either their WiFi-interface (similar to the local edges) or the cellular infrastructure (similar to global edges). In the classical CONGEST model there is a lower bound of Ω~​(n+D)~Ω𝑛𝐷\\widetilde{\\Omega}(\\sqrt{n}+D) rounds to approximate SSSP with a constant factor .\nThis bound is tight, as there is a (1+ε)1𝜀(1+\\varepsilon)-approximation algorithm by Becker et al. that runs in O~​(n+D)~𝑂𝑛𝐷\\widetilde{O}(\\sqrt{n}+D) rounds .\nThe best known algorithms for computing exact SSSP in the CONGEST model are the ones by Ghaffari and Li 1 and by Forster and Nanongkai  which have runtimes of O~​(n⋅D)~𝑂⋅𝑛𝐷\\widetilde{O}(\\sqrt{n\\cdot D}) and O~​(n​D1/4+n3/5+D)~𝑂𝑛superscript𝐷14superscript𝑛35𝐷\\widetilde{O}(\\sqrt{n}D^{1/4}+n^{3/5}+D), respectively.\nComputing the diameter can be done in O​(n)𝑂𝑛O(n) rounds in the CONGEST model , which is also tight to the lower bound .\nThis lower bound even holds for very sparse graphs .\nIn addition to that, the obvious lower bound of Ω​(D)Ω𝐷\\Omega(D) for shortest paths problems also always holds if the graph is sparse.\nTherefore, algorithms for sparse graphs have been proposed mainly for local problems such as vertex coloring, maximal matching or maximal independent set.\nThere exists an abundance of literature that studies such problems, for example, in graphs with bounded arboricity 2 0 2, planar graphs  8 9 0 or degree-bounded graphs . Somewhat related to the NCC model, although much more powerful, is the congested clique model, which has received quite some attention in recent years.\nA (1+ε)1𝜀(1+\\varepsilon)-approximation for SSSP can be computed in O​(polylog​(n))𝑂polylog𝑛O(\\text{polylog}(n)) rounds in this model 6.\nIn 7, techniques for faster matrix multiplication in the congested clique model are presented, resulting in a O​(n1−2/ω)𝑂superscript𝑛12𝜔O(n^{1-2/\\omega})-round algorithm, where ω<2.3728639𝜔2.3728639\\omega<2.3728639 is the exponent of matrix multiplication.\nOur algorithm for sparse graphs also uses matrix multiplication in order to compute APSP between O​(n1/3)𝑂superscript𝑛13O(n^{1/3}) nodes in the network in O​(log2⁡n)𝑂superscript2𝑛O(\\log^{2}n) rounds.\nIn general, the results in the congested clique model are of no help in our setting because due to the restriction that a node can only send or receive O​(log⁡n)𝑂𝑛O(\\log n) messages per round via global edges, we cannot effectively emulate congested clique algorithms in the NCC model. As argued before, we could apply some of the algorithms for PRAMs to our model instead of using native distributed solutions by using Lemma A.1 in Appendix A for PRAM simulations.\nFor example, we are able to use the algorithms of 4 to solve SSSP and diameter in trees in time O​(log⁡n)𝑂𝑛O(\\log n), w.h.p.\nFurthermore, we can compute the distance between any pair s𝑠s and t𝑡t in outerplanar graphs in time O​(log3⁡n)𝑂superscript3𝑛O(\\log^{3}n) by simulating a CREW PRAM.\nFor planar graphs, the distance between s𝑠s and t𝑡t can be computed in time O​(log3⁡n​(1+M​(q))/n)𝑂superscript3𝑛1𝑀𝑞𝑛O(\\log^{3}n(1+M(q))/n), w.h.p., where the nodes know a set of q𝑞q faces of a planar embedding that covers all vertices, and M​(q)𝑀𝑞M(q) is the number of processors required to multiply two q×q𝑞𝑞q\\times q matrices in O​(log⁡q)𝑂𝑞O(\\log q) time in the CREW PRAM. For graphs with polylogarithmic arboricity, a (1+ε)1𝜀(1+\\varepsilon)-approximation of SSSP can be computed in polylog time using 6 and our simulation framework (with huge polylogarithmic terms).\nFor general graphs, the algorithm can be combined with well-known spanner algorithms for the CONGEST model (e.g., 1) to achieve constant approximations for SSSP in time O~​(nε)~𝑂superscript𝑛𝜀\\widetilde{O}(n^{\\varepsilon}) time in our hybrid model.\nThis yields an alternative to the SSSP approximation of , which also requires time O~​(nε)~𝑂superscript𝑛𝜀\\widetilde{O}(n^{\\varepsilon}) but has much smaller polylogarithmic factors.\n\nReference markers found: [7]\n\nContext windows for each [ref]:\n[ref]7: As theoretical models for hybrid networks have only been proposed recently, only few results for such models are known at this point  [ref]7 .\nComputing an exact solution for SSSP in arbitrary graphs can be done in O~​(SPD)~𝑂SPD\\widetilde{O}(\\sqrt{\\textsf{SPD}}) rounds , where SPD is the so-called shortest path diameter of G𝐺G.\nFor\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 7,\n            \"titles\": [\n                \"Shortest Paths in a Hybrid Network Model\",\n                \"Near-Linear Lower Bounds for Distributed Distance Computations, Even in Sparse Networks\",\n                \"Distributed coloring in sparse graphs with fewer colors\",\n                \"Fast Construction of Overlay Networks\",\n                \"o​(log⁡n)𝑜𝑛o(\\\\log n)-time overlay network construction from graphs with out-degree 1\",\n                \"Finding euler tours in parallel\",\n                \"Distributed graph realizations, 2020\",\n                \"Distributed Computation in Node-Capacitated Networks\",\n                \"Spartan: A framework for sparse robust addressable networks\",\n                \"Sublogarithmic distributed MIS algorithm for sparse graphs using Nash-Williams decomposition\",\n                \"A simple and linear time randomized algorithm for computing sparse spanners in weighted graphs\",\n                \"Near-optimal approximate shortest paths and transshipment in distributed and streaming models\",\n                \"Centdian computation in cactus graphs\",\n                \"Memory efficient algorithms for cactus graphs and block graphs\",\n                \"A bounding box overlay for competitive routing in hybrid communication networks\",\n                \"Fast Approximate Shortest Paths in the Congested Clique\",\n                \"Algebraic Methods in the Congested Clique\",\n                \"Optimal Distributed Coloring Algorithms for Planar Graphs in the LOCAL model\",\n                \"The features, hardware, and architectures of data center networks: A survey\",\n                \"Channel allocation in wireless data center networks\",\n                \"Data centers as software defined networks: Traffic redundancy elimination with wireless cards at routers\",\n                \"Some algorithms on cactus graphs\",\n                \"An Optimal Algorithm to Find Maximum and Minimum Height Spanning Trees on Cactus Graphs\",\n                \"Computing shortest paths and distances in planar graphs\",\n                \"Helios: a hybrid electrical/optical switch architecture for modular data centers\",\n                \"A faster distributed single-source shortest paths algorithm\",\n                \"Networks cannot compute their diameter in sublinear time\",\n                \"Well-separated pair decomposition for the unit-disk graph metric and its applications\",\n                \"Distributed algorithms for planar networks I: planar embedding\",\n                \"Distributed algorithms for planar networks II: low-congestion shortcuts, mst, and min-cut\",\n                \"Improved Distributed Algorithms for Exact Shortest Paths\",\n                \"Simple and near-optimal distributed coloring for sparse graphs\",\n                \"Distributed monitoring of network properties: The power of hybrid networks\",\n                \"Faster construction of overlay networks\",\n                \"Time-optimal construction of overlay networks, 2020\",\n                \"Augmenting data center networks with multi-gigabit wireless links\",\n                \"An Introduction to Parallel Algorithms, volume 17\",\n                \"A Parallel Algorithm for Computing Minimum Spanning Trees\",\n                \"Competitive routing in hybrid communication networks\",\n                \"Routing in unit disk graphs\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]7 based on the context and research area of Fast Hybrid Network Algorithms for Shortest Paths in Sparse Graphs. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}