{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Weighted Automata and Logics Meet Computational Complexity\n\nPaper Abstract: \n\nPaper Section Text:\nLet ℳ=(Q,Γ,Δ,σ,q0,F,□)ℳ𝑄ΓΔ𝜎subscript𝑞0𝐹□\\mathcal{M}=(Q,\\Gamma,\\Delta,\\sigma,q_{0},F,\\square) be a weighted Turing machine over S𝑆S and ΣΣ\\Sigma.\nGiven a word w∈Σ∗𝑤superscriptΣw\\in\\Sigma^{*}, we write 𝖳𝖨𝖬𝖤​(ℳ,w)𝖳𝖨𝖬𝖤ℳ𝑤\\mathsf{TIME}(\\mathcal{M},w) for the maximal length of a computation of ℳℳ\\mathcal{M} on w𝑤w: note that the maximum is well-defined, as all weighted Turing machines are assumed to be halting. Moreover, given n∈ℕ𝑛ℕn\\in\\mathbb{N}, we write When f:ℕ→ℕ:𝑓→ℕℕf\\colon\\mathbb{N}\\to\\mathbb{N} is a function, we write 𝟣​𝖭​𝖳​𝖨​𝖬​𝖤​[S,Σ]​(f​(n))1𝖭𝖳𝖨𝖬𝖤𝑆Σ𝑓𝑛\\mathsf{1NTIME}[S,\\Sigma](f(n)) for the set of all power series r∈S​\\llangle​Σ∗​\\rrangle𝑟𝑆\\llanglesuperscriptΣ\\rrangler\\in S\\llangle\\Sigma^{*}\\rrangle\nsuch that r=‖ℳ‖𝑟normℳr=\\|\\mathcal{M}\\| for some weighted Turing machine ℳℳ\\mathcal{M} over S𝑆S and ΣΣ\\Sigma satisfying 𝖳𝖨𝖬𝖤​(ℳ,n)=O​(f​(n))𝖳𝖨𝖬𝖤ℳ𝑛𝑂𝑓𝑛\\mathsf{TIME}(\\mathcal{M},n)=O(f(n)).\nThe “𝟣1\\mathsf{1}” stands for single-tape machines in this notation. Moreover, let us define the complexity class 𝟣​𝖭​𝖳​𝖨​𝖬​𝖤​[S]​(f​(n))1𝖭𝖳𝖨𝖬𝖤delimited-[]𝑆𝑓𝑛\\mathsf{1NTIME}[S](f(n)) by The class 𝐍𝐏​[S]𝐍𝐏delimited-[]𝑆\\mathbf{NP}[S], which is a counterpart of 𝐍𝐏𝐍𝐏\\mathbf{NP} for formal power series over a semiring S𝑆S, can now be defined in an expectable way;\nC. Damm, M. Holzer, and P. McKenzie  denote this class by S−#​𝐏𝑆#𝐏S\\mathchar 45\\relax\\#\\mathbf{P}. Let S𝑆S be a semiring. The class 𝐍𝐏​[S]𝐍𝐏delimited-[]𝑆\\mathbf{NP}[S] is given by It turns out that weighted Turing machines and the classes 𝐍𝐏​[S]𝐍𝐏delimited-[]𝑆\\mathbf{NP}[S] can be used to capture a large variety of well-known complexity-theoretic settings, providing a natural framework for their consistent study.\nThe first five of the following examples were already observed by C. Damm, M. Holzer, and P. McKenzie . Weighted Turing machines over the Boolean semiring 𝔹=(𝔹,∨,∧,0,1)𝔹𝔹01\\mathbb{B}=(\\mathbb{B},\\lor,\\land,0,1) can obviously be identified with ordinary nondeterministic Turing machines without weights.\nHence, 𝐍𝐏​[𝔹]𝐍𝐏delimited-[]𝔹\\mathbf{NP}[\\mathbb{B}] can be identified with the usual complexity class 𝐍𝐏𝐍𝐏\\mathbf{NP}. Let ℳ=(Q,Γ,Δ,σ,q0,F,□)ℳ𝑄ΓΔ𝜎subscript𝑞0𝐹□\\mathcal{M}=(Q,\\Gamma,\\Delta,\\sigma,q_{0},F,\\square) be a weighted Turing machine over the semiring of natural numbers ℕ=(ℕ,+,⋅,0,1)ℕℕ⋅01\\mathbb{N}=(\\mathbb{N},+,\\cdot,0,1) and over some alphabet ΣΣ\\Sigma.\nWhen each transition is weighted by 111 – i.e., σ​(e)=1𝜎𝑒1\\sigma(e)=1 for all e∈Δ𝑒Δe\\in\\Delta – the coefficient of each w∈Σ∗𝑤superscriptΣw\\in\\Sigma^{*} in ‖ℳ‖normℳ\\|\\mathcal{M}\\|\nis the number of accepting computations of ℳℳ\\mathcal{M} on w𝑤w. Moreover, each weighted Turing machine ℳℳ\\mathcal{M} over ℕℕ\\mathbb{N} is equivalent to some other weighted Turing machine ℳ′superscriptℳ′\\mathcal{M}^{\\prime}\nsuch that all transitions of ℳ′superscriptℳ′\\mathcal{M}^{\\prime} are weighted by 111 and ℳ′superscriptℳ′\\mathcal{M}^{\\prime} runs in polynomial time if and only if ℳℳ\\mathcal{M} does.\nTo construct ℳ′superscriptℳ′\\mathcal{M}^{\\prime} from ℳℳ\\mathcal{M}, it is enough to replace each transition e=(p,c,q,d,s)𝑒𝑝𝑐𝑞𝑑𝑠e=(p,c,q,d,s) of ℳℳ\\mathcal{M} by transitions (p,c,[e,1],c,0),…,(p,c,[e,σ​(e)],c,0)𝑝𝑐𝑒1𝑐0…𝑝𝑐𝑒𝜎𝑒𝑐0\\left(p,c,[e,1],c,0\\right),\\ldots,\\left(p,c,[e,\\sigma(e)],c,0\\right)\nand ([e,1],c,q,d,s),…,([e,σ​(e)],c,q,d,s)𝑒1𝑐𝑞𝑑𝑠…𝑒𝜎𝑒𝑐𝑞𝑑𝑠\\left([e,1],c,q,d,s\\right),\\ldots,\\left([e,\\sigma(e)],c,q,d,s\\right), where [e,1],…,[e,σ​(e)]𝑒1…𝑒𝜎𝑒[e,1],\\ldots,[e,\\sigma(e)] are new states.\nIt follows that 𝐍𝐏​[ℕ]𝐍𝐏delimited-[]ℕ\\mathbf{NP}[\\mathbb{N}] can be identified with the counting class #​𝐏#𝐏\\#\\mathbf{P} . A weighted Turing machine ℳℳ\\mathcal{M} over the finite field 𝔽2=ℤ/2​ℤsubscript𝔽2ℤ2ℤ\\mathbb{F}_{2}=\\mathbb{Z}/2\\mathbb{Z} and over an alphabet ΣΣ\\Sigma\ncan only contain transitions weighted by 111. It is then immediate that ‖ℳ‖normℳ\\|\\mathcal{M}\\| is a power series in 𝔽2​\\llangle​Σ∗​\\rranglesubscript𝔽2\\llanglesuperscriptΣ\\rrangle\\mathbb{F}_{2}\\llangle\\Sigma^{*}\\rrangle such that\n(‖ℳ‖,w)normℳ𝑤(\\|\\mathcal{M}\\|,w) is, for each w∈Σ∗𝑤superscriptΣw\\in\\Sigma^{*}, the parity of the number of accepting computations of ℳℳ\\mathcal{M} on w𝑤w. As a result, 𝐍𝐏​[ℤ2]𝐍𝐏delimited-[]subscriptℤ2\\mathbf{NP}[\\mathbb{Z}_{2}] can be identified\nwith the complexity class ⊕𝐏direct-sum𝐏\\oplus\\mathbf{P} – i.e., “parity-𝐏𝐏\\mathbf{P}” . Let k≥2𝑘2k\\geq 2 be a natural number. Then similarly as above, a weighted Turing machine ℳℳ\\mathcal{M} over the ring ℤ/k​ℤℤ𝑘ℤ\\mathbb{Z}/k\\mathbb{Z} with all transitions weighted by 111\nrealises a power series ‖ℳ‖normℳ\\|\\mathcal{M}\\| such that (‖ℳ‖,w)normℳ𝑤(\\|\\mathcal{M}\\|,w) is, for each w∈Σ∗𝑤superscriptΣw\\in\\Sigma^{*}, the congruence class of the number of accepting computations of ℳℳ\\mathcal{M} on w𝑤w modulo k𝑘k.\nMoreover, the same reasoning as in Example 4.3 can be used to observe that every weighted Turing machine over ℤ/k​ℤℤ𝑘ℤ\\mathbb{Z}/k\\mathbb{Z} is equivalent to some machine with all transitions\nweighted by 111. It follows that 𝐍𝐏​[ℤ/k​ℤ]𝐍𝐏delimited-[]ℤ𝑘ℤ\\mathbf{NP}[\\mathbb{Z}/k\\mathbb{Z}] is precisely the class of all series over ℤ/k​ℤℤ𝑘ℤ\\mathbb{Z}/k\\mathbb{Z} with support in 𝐌𝐎𝐃𝐤​𝐏subscript𝐌𝐎𝐃𝐤𝐏\\mathbf{MOD_{k}P}  . The class 𝐆𝐚𝐩𝐏𝐆𝐚𝐩𝐏\\mathbf{GapP}, introduced in   as ℤ​#​𝐏ℤ#𝐏\\mathbb{Z}\\#\\mathbf{P}, and independently in , is\na closure of #​𝐏#𝐏\\#\\mathbf{P} under subtraction. It can be equivalently described as the class consisting of all functions gapℳ:Σ∗→ℤ:subscriptgapℳ→superscriptΣℤ\\mathrm{gap}_{\\mathcal{M}}\\colon\\Sigma^{*}\\to\\mathbb{Z}, for some alphabet ΣΣ\\Sigma,\nsuch that gapℳ​(w)subscriptgapℳ𝑤\\mathrm{gap}_{\\mathcal{M}}(w) is the difference between the number of accepting and rejecting computations of some polynomial-time nondeterministic Turing machine ℳℳ\\mathcal{M} on w∈Σ∗𝑤superscriptΣw\\in\\Sigma^{*} .\nGiven any polynomial-time nondeterministic Turing machine ℳℳ\\mathcal{M}, one can construct a polynomial-time weighted Turing machine ℳ′superscriptℳ′\\mathcal{M}^{\\prime} over the ring of integers ℤℤ\\mathbb{Z}\nthat first simulates ℳℳ\\mathcal{M} using transitions weighted by 111. If ℳℳ\\mathcal{M} accepts, ℳ′superscriptℳ′\\mathcal{M}^{\\prime} makes a single step using a transition weighted by 111 and accepts;\nif ℳℳ\\mathcal{M} rejects, ℳ′superscriptℳ′\\mathcal{M}^{\\prime} makes a single step using a transition weighted by −11-1 and accepts as well. Clearly (‖ℳ′‖,w)=gapℳ​(w)normsuperscriptℳ′𝑤subscriptgapℳ𝑤(\\|\\mathcal{M}^{\\prime}\\|,w)=\\mathrm{gap}_{\\mathcal{M}}(w) for all w∈Σ∗𝑤superscriptΣw\\in\\Sigma^{*}.\nConversely, a reasoning similar to the one of Example 4.3 shows that every weighted Turing machine ℳℳ\\mathcal{M} over ℤℤ\\mathbb{Z} can be assumed to\nonly contain transitions weighted by 111 or −11-1. Given ℳℳ\\mathcal{M} like this, one can construct a nondeterministic Turing machine ℳ′superscriptℳ′\\mathcal{M}^{\\prime} that simulates\nℳℳ\\mathcal{M} and maintains in state the product of weights of the transitions used in the computation so far – which is always either 111, or −11-1.\nIf the computation of ℳℳ\\mathcal{M} accepts with value 111, then ℳ′superscriptℳ′\\mathcal{M}^{\\prime} accepts; if it accepts with value −11-1, ℳ′superscriptℳ′\\mathcal{M}^{\\prime} rejects; if it rejects,\nℳ′superscriptℳ′\\mathcal{M}^{\\prime} nondeterministically branches into two states such that one of them is accepting and the other one is rejecting. Clearly gapℳ′​(w)=(‖ℳ‖,w)subscriptgapsuperscriptℳ′𝑤normℳ𝑤\\mathrm{gap}_{\\mathcal{M}^{\\prime}}(w)=(\\|\\mathcal{M}\\|,w)\nfor all w∈Σ∗𝑤superscriptΣw\\in\\Sigma^{*}, so that 𝐍𝐏​[ℤ]𝐍𝐏delimited-[]ℤ\\mathbf{NP}[\\mathbb{Z}] can be identified with 𝐆𝐚𝐩𝐏𝐆𝐚𝐩𝐏\\mathbf{GapP}. We now identify several new examples of known complexity classes that can be described as 𝐍𝐏​[S]𝐍𝐏delimited-[]𝑆\\mathbf{NP}[S] for a suitable semiring S𝑆S. Fuzzy Turing machines in the sense of  can be viewed as weighted Turing machines over a semiring as well.\nA triangular norm (or t-norm, for short) is an associative and commutative binary operation ∗∗\\ast on the real interval   [ref]1 that is nondecreasing – i.e., x1∗y≤x2∗y∗subscript𝑥1𝑦∗subscript𝑥2𝑦x_{1}\\ast y\\leq x_{2}\\ast y whenever x1,x2,y∈ [ref]1subscript𝑥1subscript𝑥2𝑦01x_{1},x_{2},y\\in [ref]1 are such that x1≤x2subscript𝑥1subscript𝑥2x_{1}\\leq x_{2} –\nand the equality 1∗x=x∗1𝑥𝑥1\\ast x=x is satisfied for all x𝑥x from the interval in consideration . It follows that ∗∗\\ast distributes over maxmax\\operatorname*{max} and 0∗x=0∗0𝑥00\\ast x=0 holds for all x∈ [ref]1𝑥01x\\in [ref]1. Thus, F∗=( [ref]1,max,∗,0,1)subscript𝐹∗01max∗01F_{\\ast}=( [ref]1,\\operatorname*{max},\\ast,0,1) is a semiring for each t-norm ∗∗\\ast.\nEvery fuzzy Turing machine ℳℳ\\mathcal{M}, as understood in , can then be viewed as a weighted Turing machine over the semiring F∗subscript𝐹∗F_{\\ast} for some t-norm ∗∗\\ast.\nCoefficients of particular words in ‖ℳ‖normℳ\\|\\mathcal{M}\\| represent their degrees of membership to the fuzzy language realised by ℳℳ\\mathcal{M}.\nThe class 𝐍𝐏​[F∗]𝐍𝐏delimited-[]subscript𝐹∗\\mathbf{NP}[F_{\\ast}] can thus be interpreted as the class of all fuzzy languages realisable by fuzzy Turing machines with t-norm ∗∗\\ast in polynomial time.\n(Note that fuzzy machines can also be seen as acceptors for “ordinary” languages .) Let Σ1subscriptΣ1\\Sigma_{1} and Σ2subscriptΣ2\\Sigma_{2} be alphabets, and ℳℳ\\mathcal{M} a weighted Turing machine with input alphabet Σ1subscriptΣ1\\Sigma_{1} over the semiring of finite languages 2𝑓𝑖𝑛Σ2∗=(2𝑓𝑖𝑛Σ2∗,∪,⋅,∅,{ε})superscriptsubscript2𝑓𝑖𝑛superscriptsubscriptΣ2superscriptsubscript2𝑓𝑖𝑛superscriptsubscriptΣ2⋅𝜀2_{\\mathit{fin}}^{\\Sigma_{2}^{*}}=(2_{\\mathit{fin}}^{\\Sigma_{2}^{*}},\\cup,\\cdot,\\emptyset,\\{\\varepsilon\\}).\nThen ‖ℳ‖normℳ\\|\\mathcal{M}\\| can be viewed as a multivalued function assigning a finite subset of Σ2∗superscriptsubscriptΣ2\\Sigma_{2}^{*} to each w∈Σ1∗𝑤superscriptsubscriptΣ1w\\in\\Sigma_{1}^{*}.\nIt is easy to see that ℳℳ\\mathcal{M} can be turned into a nondeterministic transducer machine – in the sense of  – such that there is\nan accepting computation on u∈Σ1∗𝑢superscriptsubscriptΣ1u\\in\\Sigma_{1}^{*} with the output tape containing a word v∈Σ2∗𝑣superscriptsubscriptΣ2v\\in\\Sigma_{2}^{*} at its end if and only if v∈(‖ℳ‖,u)𝑣normℳ𝑢v\\in(\\|\\mathcal{M}\\|,u).\nConversely, given a nondeterministic transducer machine realising some multivalued function, it is possible to construct an “equivalent” weighted Turing machine\nover 2𝑓𝑖𝑛Σ2∗superscriptsubscript2𝑓𝑖𝑛superscriptsubscriptΣ22_{\\mathit{fin}}^{\\Sigma_{2}^{*}}. What needs to be done is to first simulate the transducer on a single tape of a weighted Turing machine with polynomial overhead, while\nthe transitions responsible for this simulation are weighted by {ε}𝜀\\{\\varepsilon\\}. After the simulation finally reaches an accepting state of the original transducer,\nthe simulating weighted machine just goes over the output from left to right using a transition weighted by {c}𝑐\\{c\\} whenever c∈Σ2𝑐subscriptΣ2c\\in\\Sigma_{2} is being read; only then the simulating machine accepts.\nThis in particular implies that there is a weighted Turing machine realising a series r∈2𝑓𝑖𝑛Σ2∗​\\llangle​Σ1∗​\\rrangle𝑟superscriptsubscript2𝑓𝑖𝑛superscriptsubscriptΣ2\\llanglesuperscriptsubscriptΣ1\\rrangler\\in 2_{\\mathit{fin}}^{\\Sigma_{2}^{*}}\\llangle\\Sigma_{1}^{*}\\rrangle in polynomial time if and only\nif there is a polynomial-time nondeterministic transducer machine realising r𝑟r interpreted as a multivalued function. As a result, the union of 𝐍𝐏​[2𝑓𝑖𝑛Σ∗]𝐍𝐏delimited-[]superscriptsubscript2𝑓𝑖𝑛superscriptΣ\\mathbf{NP}[2_{\\mathit{fin}}^{\\Sigma^{*}}] over all alphabets ΣΣ\\Sigma can be interpreted\nas the class 𝐍𝐏𝐌𝐕𝐍𝐏𝐌𝐕\\mathbf{NPMV} of all multivalued functions realised by nondeterministic polynomial-time transducer machines . Multivalued functions of the previous example are, in principle, set-valued functions.\nIn case the free semiring ℕ​⟨Σ2∗⟩=(ℕ​⟨Σ2∗⟩,+,⋅,0,1)ℕdelimited-⟨⟩superscriptsubscriptΣ2ℕdelimited-⟨⟩superscriptsubscriptΣ2⋅01\\mathbb{N}\\langle\\Sigma_{2}^{*}\\rangle=(\\mathbb{N}\\langle\\Sigma_{2}^{*}\\rangle,+,\\cdot,0,1) is used instead of 2𝑓𝑖𝑛Σ2∗superscriptsubscript2𝑓𝑖𝑛superscriptsubscriptΣ22_{\\mathit{fin}}^{\\Sigma_{2}^{*}}, then\nthe setting is changed from set-valued functions to “multiset-valued” functions computed by “nondeterministic transducer machines with counting”,\ni.e., transducer machines in which each accepting computation with input u∈Σ1∗𝑢superscriptsubscriptΣ1u\\in\\Sigma_{1}^{*} and output v∈Σ2∗𝑣superscriptsubscriptΣ2v\\in\\Sigma_{2}^{*} adds 111 to the multiplicity of v𝑣v in the finite multiset corresponding to u𝑢u.\nThe union of 𝐍𝐏​[ℕ​⟨Σ∗⟩]𝐍𝐏delimited-[]ℕdelimited-⟨⟩superscriptΣ\\mathbf{NP}[\\mathbb{N}\\langle\\Sigma^{*}\\rangle] over all alphabets ΣΣ\\Sigma then corresponds to the class of all multiset-valued functions computed\nby “nondeterministic polynomial-time transducer machines with counting”. As we observe later in this article, weighted computation over free semirings\ncan be described as “hardest” among all semirings (cf. Proposition 7.2). The radix order ⪯precedes-or-equals\\preceq on {0,1}∗superscript01\\{0,1\\}^{*} is defined for all x,y∈{0,1}∗𝑥𝑦superscript01x,y\\in\\{0,1\\}^{*} by x⪯yprecedes-or-equals𝑥𝑦x\\preceq y if and only if either |x|<|y|𝑥𝑦\\lvert x\\rvert<\\lvert y\\rvert, or |x|=|y|𝑥𝑦\\lvert x\\rvert=\\lvert y\\rvert and x𝑥x is smaller than or equal to y𝑦y according to the lexicographic order.\nLet us consider the semiring Smax=({0,1}∗∪{−∞},max,⋅,−∞,ε)subscript𝑆maxsuperscript01max⋅𝜀S_{\\operatorname*{max}}=(\\{0,1\\}^{*}\\cup\\{-\\infty\\},\\operatorname*{max},\\cdot,-\\infty,\\varepsilon) such that the restriction of maxmax\\operatorname*{max} to {0,1}∗superscript01\\{0,1\\}^{*} is the maximum according\nto the radix order ⪯precedes-or-equals\\preceq,\nmax(x,−∞)=max(−∞,x)=xmax𝑥max𝑥𝑥\\operatorname*{max}(x,-\\infty)=\\operatorname*{max}(-\\infty,x)=x for all x∈Smax𝑥subscript𝑆maxx\\in S_{\\operatorname*{max}}, the restriction of ⋅⋅\\cdot to {0,1}∗superscript01\\{0,1\\}^{*} is the usual concatenation operation,\nand x⋅(−∞)=(−∞)⋅x=−∞⋅𝑥⋅𝑥x\\cdot(-\\infty)=(-\\infty)\\cdot x=-\\infty for all x∈Smax𝑥subscript𝑆maxx\\in S_{\\operatorname*{max}}. If num​(x)num𝑥\\mathrm{num}(x) denotes a number with binary representation x∈{0,1}∗𝑥superscript01x\\in\\{0,1\\}^{*}, then\nφ:{0,1}∗→ℕ:𝜑→superscript01ℕ\\varphi\\colon\\{0,1\\}^{*}\\to\\mathbb{N}, defined by φ:x↦num​(1​x)−1:𝜑maps-to𝑥num1𝑥1\\varphi\\colon x\\mapsto\\mathrm{num}(1x)-1, is clearly an isomorphism of linearly ordered sets ({0,1}∗,⪯)superscript01precedes-or-equals(\\{0,1\\}^{*},\\preceq) and (ℕ,≤)ℕ(\\mathbb{N},\\leq). Given a weighted Turing machine ℳℳ\\mathcal{M} over Smaxsubscript𝑆maxS_{\\operatorname*{max}} with input alphabet ΣΣ\\Sigma, it is straightforward to construct\na nondeterministic Turing machine ℳ′superscriptℳ′\\mathcal{M}^{\\prime} with binary encoded nonnegative integer output such that\nan accepting configuration with output φ​(x)𝜑𝑥\\varphi(x) for x∈{0,1}∗𝑥superscript01x\\in\\{0,1\\}^{*} is reachable in ℳ′superscriptℳ′\\mathcal{M}^{\\prime} upon an input word w𝑤w\nif and only if there is an accepting computation γ𝛾\\gamma of the weighted Turing machine ℳℳ\\mathcal{M} such that λ​(γ)=w𝜆𝛾𝑤\\lambda(\\gamma)=w and σ​(γ)=x𝜎𝛾𝑥\\sigma(\\gamma)=x. A converse construction can be done similarly as in Example 4.8.\nMoreover, it is easy to see that both constructions result in at most polynomial overhead. Hence, as the maximum is used as an additive operation of the semiring Smaxsubscript𝑆maxS_{\\operatorname*{max}}, the class 𝐍𝐏​[Smax]𝐍𝐏delimited-[]subscript𝑆max\\mathbf{NP}[S_{\\operatorname*{max}}] corresponds in principle\nto maximisation problems in the class 𝐎𝐩𝐭𝐏𝐎𝐩𝐭𝐏\\mathbf{OptP} of :\nthe class 𝐎𝐩𝐭𝐏𝐎𝐩𝐭𝐏\\mathbf{OptP} consists of all problems, in which the objective is to compute the value of an optimal solution to\na given instance of an optimisation problem in 𝐍𝐏𝐎𝐍𝐏𝐎\\mathbf{NPO}   ;\na minor difference between this class and the Smaxsubscript𝑆maxS_{\\operatorname*{max}}-weighted setting is that the value −∞-\\infty is not permitted for problems in 𝐎𝐩𝐭𝐏𝐎𝐩𝐭𝐏\\mathbf{OptP}. In addition, one can also describe the class of minimisation problems in 𝐎𝐩𝐭𝐏𝐎𝐩𝐭𝐏\\mathbf{OptP} using the semiring Smin=({0,1}∗∪{∞},min,⋅,∞,ε)subscript𝑆minsuperscript01min⋅𝜀S_{\\operatorname*{min}}=(\\{0,1\\}^{*}\\cup\\{\\infty\\},\\operatorname*{min},\\cdot,\\infty,\\varepsilon), for which the operations are defined in a similar way as for Smaxsubscript𝑆maxS_{\\operatorname*{max}}. Considering the max-plus – or arctic  – semiring ℕmax=(ℕ∪{−∞},max,+,−∞,0)subscriptℕmaxℕmax0\\mathbb{N}_{\\operatorname*{max}}=(\\mathbb{N}\\cup\\{-\\infty\\},\\operatorname*{max},+,-\\infty,0) of natural numbers instead of Smaxsubscript𝑆maxS_{\\operatorname*{max}}\nhas an effect of requiring unary outputs in the corresponding nondeterministic Turing machine instead of binary outputs. The complexity class 𝐍𝐏​[ℕmax]𝐍𝐏delimited-[]subscriptℕmax\\mathbf{NP}[\\mathbb{N}_{\\operatorname*{max}}]\nthus roughly corresponds to maximisation problems from the class 𝐎𝐩𝐭𝐏​[O​(log⁡n)]𝐎𝐩𝐭𝐏delimited-[]𝑂𝑛\\mathbf{OptP}[O(\\log n)] of , which is the same to 𝐍𝐏𝐎​𝐏𝐁𝐍𝐏𝐎𝐏𝐁\\mathbf{NPO\\leavevmode\\nobreak\\ PB}   \nas 𝐎𝐩𝐭𝐏𝐎𝐩𝐭𝐏\\mathbf{OptP} is to 𝐍𝐏𝐎𝐍𝐏𝐎\\mathbf{NPO}. Moreover, the class of minimisation problems from 𝐎𝐩𝐭𝐏​[O​(log⁡n)]𝐎𝐩𝐭𝐏delimited-[]𝑂𝑛\\mathbf{OptP}[O(\\log n)] can be captured via the tropical semiring ℕmin=(ℕ∪{∞},min,+,∞,0)subscriptℕminℕmin0\\mathbb{N}_{\\operatorname*{min}}=(\\mathbb{N}\\cup\\{\\infty\\},\\operatorname*{min},+,\\infty,0). In addition to 𝐍𝐏​[S]𝐍𝐏delimited-[]𝑆\\mathbf{NP}[S], other time complexity classes of power series can be introduced as well by generalising the usual definition of a nondeterministic time complexity class to weighted Turing machines –\nfor instance, Similarly, weighted space complexity classes can be defined using weighted multitape Turing machines with a read-only input tape.\n\nReference markers found: [1]\n\nContext windows for each [ref]:\n[ref]1: sense of  can be viewed as weighted Turing machines over a semiring as well.\nA triangular norm (or t-norm, for short) is an associative and commutative binary operation ∗∗\\ast on the real interval   [ref]1 that is nondecreasing – i.e., x1∗y≤x2∗y∗subscript𝑥1𝑦∗subscript𝑥2𝑦x_{1}\\ast y\\leq x_{2}\\ast y whenever x1,x2,y∈ [ref]1subscript𝑥1subscript𝑥2𝑦01x_{1},x_{2},y\\in [ref]1 are such that\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 1,\n            \"titles\": [\n                \"Descriptive Complexity for Counting Complexity Classes\",\n                \"Finite Semigroups and Universal Algebra\",\n                \"Computational Complexity\",\n                \"The complexity of tensor circuit evaluation\",\n                \"On the computing power of fuzzy Turing machines\",\n                \"Counting classes: Tresholds, parity, mods, and fewness\",\n                \"Universal Algebra: Fundamentals and Selected Topics\",\n                \"Noncommutative Rational Series with Applications\",\n                \"Qualitative relativizations of complexity classes\",\n                \"Weak second-order arithmetic and finite automata\",\n                \"Cooperative combinatorial optimization: Evolutionary computation case study\",\n                \"On the power of parity polynomial time\",\n                \"Determinization of weighted finite automata over strong bimonoids\",\n                \"Structure in approximation classes\",\n                \"The complexity of tensor calculus\",\n                \"Weighted automata and logics on graphs\",\n                \"Weighted automata and weighted logics\",\n                \"Aperiodic Weighted Automata and Weighted First-Order Logic\",\n                \"Semirings and formal power series\",\n                \"Handbook of Weighted Automata\",\n                \"Weighted automata\",\n                \"Weighted automata and weighted logics with discounting\",\n                \"Weighted finite automata over strong bimonoids\",\n                \"Weighted tree automata and weighted logics\",\n                \"Weighted logics for unranked tree automata\",\n                \"The Chomsky-Schützenberger theorem for quantitative context-free languages\",\n                \"Descriptive complexity of #​P#𝑃\\\\#P functions: A new perspective\",\n                \"Automata, Languages, and Machines, Vol. A\",\n                \"On the complexity of sum-of-products problems over semirings\",\n                \"Semiring reasoning frameworks in AI and their computational complexity\",\n                \"Gap-definable counting classes\",\n                \"Semirings and their Applications\",\n                \"Finite model theory and descriptive complexity\",\n                \"The power of witness reduction\",\n                \"Closure properties and witness reduction\",\n                \"Semirings\",\n                \"Weighted automata with storage\",\n                \"Lindenmayer systems\",\n                \"Introduction to Automata Theory, Languages, and Computation\",\n                \"Descriptive Complexity\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]1 based on the context and research area of Weighted Automata and Logics Meet Computational Complexity. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}