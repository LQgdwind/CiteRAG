{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic citation prediction expert. Your task is to predict the most likely citations for [ref] markers in academic paper sections based on the paper content and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract + section text with [ref] markers\n- Output: top {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nTASK DESCRIPTION:\n- Input: Paper section text with [ref] markers + retrieved relevant papers\n- Output: top 40 predicted reference titles for each [ref] marker with reasoning\n- Format: JSON object with \"citations\" array containing objects with \"ref_index\", \"titles\", and \"reasoning\" fields\n\nREQUIREMENTS:\n1. Analyze the context around each [ref] marker to understand what reference is needed\n2. Consider the retrieved papers as potential references (when available)\n3. Consider the surrounding text, research area, and topic\n4. Generate realistic and relevant reference titles that would fit the context\n5. Provide detailed reasoning for each prediction to prevent hallucination\n6. Output format: JSON object with \"citations\" array\n7. Generate exactly 40 most relevant reference titles for each [ref]\n8. Ensure titles are realistic and appropriate for the research area\n9. Include reasoning that explains why each title is relevant to the specific [ref] context\n10. Use proper JSON escaping for special characters (escape quotes with \\\")\n11. Ensure all strings are properly quoted and escaped\n\nEXAMPLE:\nInput:\n\"Federated Learning aims to train models in massively distributed networks [ref]38 at a large scale [ref]5, over multiple sources of heterogeneous data [ref]30.\"\n\nRetrieved papers (top {top_r}):\n1. Title: Communication-efficient learning of deep networks from decentralized data\n   Abstract: We report on a series of experiments with federated learning systems for decentralized data training.\n\n2. Title: Federated Learning: Challenges, Methods, and Future Directions\n   Abstract: A comprehensive survey of federated learning approaches and challenges in distributed settings.\n\nOutput:\n{\n  \"citations\": [\n    {\n      \"ref_index\": 38,\n      \"titles\": [\n        \"Communication-efficient learning of deep networks from decentralized data\",\n        \"Federated Learning: Challenges, Methods, and Future Directions\",\n        \"Federated optimization in heterogeneous networks\",\n        \"Towards federated learning at scale: System design\",\n        \"A performance evaluation of federated learning algorithms\",\n        \"Distributed machine learning: A survey\",\n        \"Communication protocols for distributed learning\",\n        \"Scalable federated learning systems\",\n        \"Efficient distributed training algorithms\",\n        \"Large-scale distributed learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]38 appears in the context of 'massively distributed networks' for federated learning, so it likely refers to foundational papers on federated learning systems, distributed training, and communication-efficient methods in distributed networks.\"\n    },\n    {\n      \"ref_index\": 5,\n      \"titles\": [\n        \"Bagging predictors\",\n        \"Ensemble methods in machine learning\",\n        \"Random forests for classification\",\n        \"Bootstrap methods and their application\",\n        \"Combining multiple classifiers\",\n        \"Large-scale machine learning systems\",\n        \"Distributed ensemble methods\",\n        \"Scalable classification algorithms\",\n        \"Massive data processing techniques\",\n        \"High-performance machine learning frameworks\"\n      ],\n      \"reasoning\": \"This [ref]5 appears in the context of 'at a large scale', suggesting it refers to papers on scaling machine learning methods, ensemble techniques, or methods that can handle large-scale data and distributed settings.\"\n    },\n    {\n      \"ref_index\": 30,\n      \"titles\": [\n        \"Learning fair representations\",\n        \"Fair machine learning: A survey\",\n        \"Bias in machine learning systems\",\n        \"Addressing fairness in AI systems\",\n        \"Fair representation learning\",\n        \"Heterogeneous data handling methods\",\n        \"Multi-source learning algorithms\",\n        \"Cross-domain representation learning\",\n        \"Fair learning from diverse data\",\n        \"Bias mitigation in heterogeneous datasets\"\n      ],\n      \"reasoning\": \"This [ref]30 appears in the context of 'heterogeneous data' and 'fair representation learning', indicating it likely refers to papers on heterogenous data handling, bias mitigation, and learning representations that are fair across different data distributions.\"\n    }\n  ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped.\n\nIMPORTANT NOTES ON REASONING:\n- The reasoning field is crucial for preventing hallucination\n- Each reasoning should be specific to the context around the [ref] marker\n- Explain the connection between the predicted titles and the research topic\n- This helps validate that predictions are grounded in the actual content\n- Reasoning should be concise but informative (2-3 sentences)\n- Consider retrieved papers when available to improve prediction accuracy"
    },
    {
      "role": "user",
      "content": "Paper Title: Learning Large Neighborhood Search for Vehicle Routing in Airport Ground Handling\n\nPaper Abstract: \n\nPaper Section Text:\nInstance Generation. Our experiments are conducted on a well-known international airport in Singapore, i.e., CHANGI airport, whose topology is shown in Fig.¬†4. It contains 3 terminals with 90 gates where the operations are executed. We load the map111https://www.changiairport.com/en/maps.html into SUMO¬†, by which the distances between gates and the depot are calculated automatically. On top of the map, we first generate AGH instances of 20, 50 and 100 flights which are referred as AGH20, AGH50 and AGH100, respectively. Particularly, the instances are generated based on statistics of the real scenario in CHANGI airport. For the flight density, we follow the scheduling table in one day222https://www.changiairport.com/en/flights.html, and randomly generate the number of hourly aircraft arrivals from  , where 5 and 25 correspond to the flight quantities in the idlest and busiest periods, respectively. The duration of a turnaround for each aircraft is sampled from [ref]30  minutes. We consider three types of aircraft with respective precedence relations according to their manufacturers  , the first one of which has been shown in Fig. 1. The others are similar to the first type yet much harder, i.e., the priority of catering could be 1 or 2 for the second type; the cleaning could be prioritized as 1 or 2 and catering can be executed anytime before pushback for the third type. The three aircraft types are uniformly across all the flights, which are also uniformly assigned to the gates. For the 10 operations to be scheduled, their service durations, time windows and vehicle speeds are set individually following  . The number of vehicles in each fleet is randomly sampled from  . We randomly generate the flight demands for each operation from  , and set the ratio of demand to capacity to a random value in [0.7, 0.9] following . Baselines. We compare our learning based LNS with the state-of-the-art exact solver for MILP, and various conventional LNS heuristics. In specific, the baselines include, 1) the exact solver CPLEX¬† (we also use OR-Tools¬†1 instead to verify the versatility of our method), which is also the repair operator in the LNS methods; 2) Random, which destroys the current solution by randomly picking a subset of integer decision variables to reoptimize; 3) Vehicle-random, which is used to collect demos for imitation learning as described in section¬†4.2; 4) Vehicle-worst, which sorts all used vehicles according to their travelling distance in the current solution, and selects the variables related to those vehicles with the longest distances; 5) Vehicle-worst-random, which selects ùíüd/2subscriptùíüùëë2\\mathcal{D}_{d}/2 of variables with Vehicle-random and ùíüd/2subscriptùíüùëë2\\mathcal{D}_{d}/2 of variables with Vehicle-worst, given a destroy degree ùíüdsubscriptùíüùëë\\mathcal{D}_{d}; 6) Decomposition, which tackled a similar problem to ours and reported favorable performance by first decomposing it into sub-problems for each fleet using constraint programming (CP) and then applying LNS heuristic to solve them¬†4. We adapted it to solve the same problem as ours. Note that the work in 4 is the recent one for solving AGH problems whose settings are most similar to ours ; 7) GA, which solved the AGH problem by a genetic algorithm¬†. While its original work only considers one type of aircraft, we adapt the GA method to our setting with heterogeneous aircraft. Other specialized approaches for VRPs with individual operations are not considered as baselines, since they are less relevant to the studied problem in this paper. For LNS heuristics and our method, we generate initial solutions with a simple heuristic based on nearest neighbor insertion¬†, which is commonly used to initialize the solutions for routing problems¬†  . Specifically, each route, starting from the depot, is iteratively extended with the nearest unserved flight (which also satisfies the basic constraints), until no such flights exist and then a new route starts. Meanwhile, the routes are constructed for each fleet following the precedence relation among each other. We note that the above insertion heuristic basically picks the nearest aircraft which satisfies all constraints and it scarcely needs domain knowledge for the problem. Alternatively, we can also simply run a solver (e.g. CPLEX) with a time limit to attain initial solutions. Hyperparameters in LNS Heuristics. We use CPLEX 12.10 as the solver in baseline 1, and as the repair operators in baselines 2-5 and our method. We set two parameters in CPLEX (i.e., mipgap333The relative gap between the lower and upper objective bound. and timelimit) as stopping conditions in each LNS iteration. The current LNS iteration stops when either of the two conditions is met. In particular, we set mipgap to 0.1 for AGH20 and AGH50, 0.2 for AGH100. The timelimit is set to 10s, 1m and 10m respectively, though they could be longer than the real runtime in iterations. The acceptance criterion is that in each iteration, we only accept the solution whose objective value is smaller or at most 1%percent11\\% larger than that of the incumbent. Typically, we find that all LNS heuristics considerably improve solutions between 5 and 10 iterations, so we empirically set the total runtime to 1m, 5m and 30m for AGH20, AGH50 and AGH100, respectively. Since the destroy degree cannot be too large or small (as analyzed in Section 4.2), we have tried 0.3, 0.4, 0.5 and 0.6 in our experiment. We observe that when it equals to 0.4, all LNS heuristics (including Vehicle-random LNS that generates demos for the policy network) perform relatively well on the validation set. Therefore, we set it to 0.4 for all LNS heuristics on AGH20, AGH50 and AGH100. Hyperparameters in Learning based LNS. We train the model only on instances of AGH20 to learn the policy (which consumes about five days), and test it on instances of AGH20, AGH50 and AGH100 to evaluate its performance. Regarding AGH20, we generate 70 instances for training, 30 instances for validation and 50 instances for testing. For each of other sizes, we also generate 50 instances for testing. During the training, we set the epoch number to 10 according to the convergence of the training curve. In each epoch, we set the iteration number of LNS ni=5subscriptùëõùëñ5n_{i}=5, since we observe its performance cannot be significantly improved afterwards. In each iteration of the forward training algorithm (i.e., each LNS iteration), we run Vehicle-random LNS ns=10subscriptùëõùë†10n_{s}=10 times for each instance in the training set, and keep the best one as a demo. Accordingly, the stopping condition, acceptance criterion and destroy degree are set following the hyperparameters of Vehicle-random LNS, as mentioned above. After the demos are collected, we train the neural network by the stochastic gradient descent (SGD) optimizer 0, with the learning rate equals to 10‚àí4superscript10410^{-4} and the batch size equals to 16 due to GPU memory limit. For validation, we set the iteration number ni=10subscriptùëõùëñ10n_{i}=10 and the destroy degree ùíüd=0.4subscriptùíüùëë0.4\\mathcal{D}_{d}=0.4. For testing, we keep the destroy degree same as the training, and run the learned LNS with the same time as other baselines.\nAll experiments are conducted on a machine with 32 AMD EPYC 7601 32-Core Processors.\n\nReference markers found: [30]\n\nContext windows for each [ref]:\n[ref]30: of hourly aircraft arrivals from  , where 5 and 25 correspond to the flight quantities in the idlest and busiest periods, respectively. The duration of a turnaround for each aircraft is sampled from [ref]30  minutes. We consider three types of aircraft with respective precedence relations according to their manufacturers  , the first one of which has been shown in Fig. 1. The others are similar\n\n{retrieved_text}\n\nGenerate exactly 40 most likely reference titles for each [ref] marker. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL REQUIREMENTS:\n1. For each [ref] marker, provide detailed reasoning explaining why the predicted titles are relevant\n2. The reasoning should analyze the specific context around each [ref] marker\n3. Explain how each title connects to the research topic, methodology, or problem being discussed\n4. This reasoning helps prevent hallucination by grounding predictions in the actual context\n5. Consider retrieved papers when available to improve prediction accuracy\n\nCRITICAL FORMAT REQUIREMENT: You must respond with ONLY valid JSON. Do not include any explanatory text, markdown formatting, or other content outside the JSON structure.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"citations\": [\n        {\n            \"ref_index\": 38,\n            \"titles\": [\n                \"Reference Title 1\",\n                \"Reference Title 2\",\n                \"Reference Title 3\",\n                \"Reference Title 4\",\n                \"Reference Title 40\"\n            ],\n            \"reasoning\": \"Detailed explanation of why these titles are relevant to [ref]38 based on the surrounding context, research area, and specific topic being discussed.\"\n        }\n    ]\n}\n\nCRITICAL: Return ONLY the JSON object. Do not include any text before or after the JSON. Do not use markdown formatting. Ensure all quotes and special characters are properly escaped. Do not include authors, venues, or years - only the paper titles. Generate exactly 40 titles for each [ref] marker with reasoning."
    },
    {
      "role": "assistant",
      "content": "{\n    \"citations\": [\n        {\n            \"ref_index\": 30,\n            \"titles\": [\n                \"Learn to Design the Heuristics for Vehicle Routing Problem\",\n                \"Cplex\",\n                \"Gurobi Optimizer Reference Manual\",\n                \"Scheduling de-icing vehicles within airport logistics: a heuristic algorithm and performance evaluation\",\n                \"Planning towing processes at airports more efficiently\",\n                \"Solving a manpower scheduling problem for airline catering using metaheuristics\",\n                \"Aco-ih: An improved ant colony optimization algorithm for airport ground service scheduling\",\n                \"Research on airport trailer emergency scheduling model based on genetic simulation annealing algorithm\",\n                \"Scheduling for airport baggage transport vehicles based on diversity enhancement genetic algorithm\",\n                \"A bi-objective approach for scheduling ground-handling vehicles in airports\",\n                \"Scheduling optimisation of multi-type special vehicles in an airport\",\n                \"Or-tools\",\n                \"Integrating optimization and simulation to gain more efficient airport logistics\",\n                \"A bi-objective optimization of airport ferry vehicle scheduling based on heuristic algorithm: A real data case study\",\n                \"An improved method for scheduling aircraft ground handling operations from a global perspective\",\n                \"Optimization of apron support vehicle operation scheduling based on multi-layer coding genetic algorithm\",\n                \"A turnaround control system to automatically detect and monitor the time stamps of ground service actions in airports: a deep learning and computer vision based approach\",\n                \"Optimization of ground vehicles movement on the aerodrome\",\n                \"Analysis of accidents resulting from the interaction of air and ground vehicles at airports\",\n                \"Ensuring safety and security in employing drones at airports\",\n                \"Robust resource planning for aircraft ground operations\",\n                \"A simheuristic approach for robust scheduling of airport turnaround teams\",\n                \"Efficiency and robustness in a support platform for intelligent airport ground handling\",\n                \"Review on meta-heuristics approaches for airside operation research\",\n                \"Using constraint programming and local search methods to solve vehicle routing problems\",\n                \"An adaptive large neighborhood search heuristic for the pickup and delivery problem with time windows\",\n                \"Large neighborhood search for dial-a-ride problems\",\n                \"An adaptive large neighborhood search heuristic for the cumulative capacitated vehicle routing problem\",\n                \"An adaptive large neighborhood search metaheuristic for the vehicle routing problem with drones\",\n                \"An evolutionary multiobjective route grouping-based heuristic algorithm for large-scale capacitated vehicle routing problems\",\n                \"Neural Large Neighborhood Search for the Capacitated Vehicle Routing Problem\",\n                \"A General Large Neighborhood Search Framework for Solving Integer Linear Programs\",\n                \"Model-based automatic neighborhood design by unsupervised learning\",\n                \"A learn-and-construct framework for general mixed-integer programming problems\",\n                \"Explicit evolutionary multitasking for combinatorial optimization: A case study on capacitated vehicle routing problem\",\n                \"Robust multiobjective optimization for vehicle routing problem with time windows\",\n                \"Record breaking optimization results using the ruin and recreate principle\",\n                \"An autonomous land vehicle in a neural network\",\n                \"Efficient reductions for imitation learning\",\n                \"Microscopic traffic simulation using sumo\"\n            ],\n            \"reasoning\": \"Selected these 40 citations for [ref]30 based on the context and research area of Learning Large Neighborhood Search for Vehicle Routing in Airport Ground Handling. The first title is the actual reference for this marker, followed by other relevant papers from the same research domain.\"\n        }\n    ]\n}"
    }
  ],
  "format": "chatml"
}