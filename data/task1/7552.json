{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 55 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Truthful Meta-Explanations for Local Interpretability of Machine Learning Models\n\nPaper Abstract: Abstract Automated Machine Learning-based systems’ integration into a wide range of tasks has expanded as a result of their performance and speed. Although there are numerous advantages to employing ML-based systems, if they are not interpretable, they should not be used in critical, high-risk applications where human lives are at risk. To address this issue, researchers and businesses have been focusing on finding ways to improve the interpretability of complex ML systems, and several such methods have been developed. Indeed, there are so many developed techniques that it is difficult for practitioners to choose the best among them for their applications, even when using evaluation metrics. As a result, the demand for a selection tool, a meta-explanation technique based on a high-quality evaluation metric, is apparent. In this paper, we present a local meta-explanation technique which builds on top of the truthfulness metric, which is a faithfulness-based metric. We demonstrate the effectiveness of both the technique and the metric by concretely defining all the concepts and through experimentation.\n\n{retrieved_text}\n\nGenerate exactly 55 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 55\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A systematic literature review of machine learning methods applied to predictive maintenance\",\n        \"Visiored: A visualisation tool for interpretable predictive maintenance\",\n        \"Statistical and machine learning models in credit scoring: A systematic literature survey\",\n        \"Machine learning for credit scoring: Improving logistic regression with non-linear decision-tree effects\",\n        \"Machine learning in banking risk management: A literature review\",\n        \"Detecting insurance claims fraud using machine learning techniques\",\n        \"Moderate automobile accident claim process automation using machine learning\",\n        \"Big data and machine learning algorithms for health-care delivery\",\n        \"Machine learning for improved diagnosis and prognosis in healthcare\",\n        \"Systematic review of machine learning for diagnosis and prognosis in dermatology\",\n        \"Machine learning with applications in breast cancer diagnosis and prognosis\",\n        \"The coming war on the hidden algorithms that trap people in poverty\",\n        \"An insurance startup bragged it uses ai to detect fraud. it didn’t go well\",\n        \"Ibm’s watson gave unsafe recommendations for treating cancer\",\n        \"In scramble to respond to covid-19, hospitals turned to models with high risk of bias\",\n        \"Regulation (eu) 2016/679 of the european parliament and of the council of 27 april 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing directive 95/46\",\n        \"Explainable artificial intelligence: A survey\",\n        \"Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)\",\n        \"Interpretable machine learning: definitions, methods, and applications\",\n        \"Explainable AI: A Review of Machine Learning Interpretability Methods\",\n        \"Towards robust interpretability with self-explaining neural networks\",\n        \"On attribution of recurrent neural network predictions via additive decomposition\",\n        \"On the (in)fidelity and sensitivity of explanations\",\n        \"Altruist: Argumentative explanations through local interpretations of predictive models\",\n        \"Evaluating and aggregating feature-based model explanations\",\n        \"A survey of methods for explaining black box models\",\n        \"Factual and counterfactual explanations for black box decision making\",\n        \"On the stability of interpretable models\",\n        \"Argumentation in artificial intelligence, volume 47\",\n        \"Combining explanation and argumentation in dialogue\",\n        \"Predictive learning via rule ensembles\",\n        \"Why should i trust you?: Explaining the predictions of any classifier\",\n        \"Conclusive local interpretation rules for random forests\",\n        \"Anchors: High-Precision Model-Agnostic Explanations\",\n        \"A unified approach to interpreting model predictions\",\n        \"Random forests\",\n        \"On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation\",\n        \"Axiomatic attribution for deep networks\",\n        \"Explanation in ai and law: Past, present and future\",\n        \"Argumentation and explainable artificial intelligence: a survey\",\n        \"Argumentation based on classical logic\",\n        \"A comparative study of faithfulness metrics for model interpretability methods\",\n        \"Improving the faithfulness of attention-based explanations with task-specific information for text classification\",\n        \"Is attention interpretable?\",\n        \"ERASER: A benchmark to evaluate rationalized NLP models\",\n        \"Leveraging latent features for local explanations\",\n        \"Rethinking attention-model explainability through faithfulness violation test\",\n        \"On the diversity and limits of human explanations\",\n        \"Towards model-agnostic ensemble explanations\",\n        \"Model-agnostic ensemble-based explanation correction leveraging rashomon effect\",\n        \"Turbofan engine degradation simulation data set\",\n        \"Damage propagation modeling for aircraft engine run-to-failure simulation\",\n        \"Detecting damaged buildings on post-hurricane satellite imagery based on customized convolutional neural networks\",\n        \"Natural language processing and machine learning algorithm to identify brain MRI reports with acute ischemic stroke\",\n        \"Biobert: a pre-trained biomedical language representation model for biomedical text mining\"\n    ],\n    \"reasoning\": \"Selected these 55 references because they represent foundational work and recent advances in Truthful Meta-Explanations for Local Interpretability of Machine Learning Models, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}