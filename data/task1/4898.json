{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 167 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Energy-Efficient Deflection-based On-chip Networks: Topology, Routing, Flow Control\n\nPaper Abstract: Abstract As the number of cores scales to tens and hundreds, the energy consumption of routers across various types of on-chip networks in chip muiltiprocessors (CMPs) increases significantly. A major source of this energy consumption comes from the input buffers inside Network-on-Chip (NoC) routers, which are traditionally designed to maximize performance. To mitigate this high energy cost, many works propose bufferless router designs that utilize deflection routing to resolve port contention. While this approach is able to maintain high performance relative to its buffered counterparts at low network traffic, the bufferless router design suffers performance degradation under high network load. In order to maintain high performance and energy efficiency under both low and high network loads, this chapter discusses critical drawbacks of traditional bufferless designs and describes recent research works focusing on two major modifications to improve the overall performance of the traditional bufferless network-on-chip design. The first modification is a minimally-buffered design that introduces limited buffering inside critical parts of the on-chip network in order to reduce the number of deflections. The second modification is a hierarchical bufferless interconnect design that aims to further improve performance by limiting the number of hops each packet needs to travel while in the network. In both approaches, we discuss design tradeoffs and provide evaluation results based on common CMP configurations with various network topologies to show the effectiveness of each proposal.\n\n{retrieved_text}\n\nGenerate exactly 167 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 167\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Principles and Practices of Interconnection Networks\",\n        \"A case for bufferless routing in on-chip networks\",\n        \"MinBD: Minimally-buffered deflection routing for energy-efficient interconnect\",\n        \"CHIPPER: A low-complexity bufferless deflection router\",\n        \"HAT: Heterogeneous Adaptive Throttling for On-Chip Networks\",\n        \"Carpool: A Bufferless on-Chip Network Supporting Adaptive Multicast and Hotspot Alleviation\",\n        \"A model for Application Slowdown Estimation in on-chip networks and its use for improving system fairness and performance\",\n        \"Next generation on-chip networks: What kind of congestion control do we need?\",\n        \"On-chip networks from a networking perspective: Congestion and scalability in many-core interconnects\",\n        \"Express cube topologies for on-chip interconnects\",\n        \"Preemptive Virtual Clock: A Flexible, Efficient, and Cost-effective QOS Scheme for Networks-on-Chip\",\n        \"Topology-aware quality-of-service support in highly integrated chip multiprocessors\",\n        \"Kilo-NOC: A heterogeneous network-on-chip architecture for scalability and service guarantees\",\n        \"ViChaR: A dynamic virtual channel regulator for on-chip networks\",\n        \"Application-aware prioritization mechanisms for on-chip networks\",\n        \"Aérgia: exploiting packet latency slack in on-chip networks\",\n        \"Application-to-core mapping policies to reduce memory system interference in multi-core systems\",\n        \"Flattened butterfly: A cost-efficient topology for high-radix networks\",\n        \"The Tera computer system\",\n        \"The raw microprocessor: A computational fabric for software circuits and general-purpose programs\",\n        \"Single-chip cloud computer\",\n        \"R. Ausavarungnirun\",\n        \"Design and evaluation of hierarchical rings with deflection routing\",\n        \"A Case for Hierarchical Rings with Deflection Routing\",\n        \"Implementation and Evaluation of On-Chip Network Architectures\",\n        \"Evaluating bufferless flow-control for on-chip networks\",\n        \"Power-driven design of router microarchitectures in on-chip networks\",\n        \"On distributed communications networks\",\n        \"NoCs: What’s the point?\",\n        \"A 5-GHz mesh interconnect for a teraflops processor\",\n        \"On-chip interconnection architecture of the tile processor\",\n        \"Tilera announces the world’s first 100-core processor with the new TILE-Gx family\",\n        \"6th Generation Intel Core Processor Family Datasheet\",\n        \"Second Generation Intel Xeon Scalable Datasheet\",\n        \"10th Generation Intel Core Processor Families Datasheet\",\n        \"Larrabee: a many-core x86 architecture for visual computing\",\n        \"Overview of the architecture\",\n        \"Intel details 2011 processor features\",\n        \"8th and 9th Generation Intel Core Processor Family and Intel Xeon E Processor Families Datasheet\",\n        \"NVIDIA DGX-1 With Tesla V100 System Architecture\",\n        \"Router microarchitecture and scalability of ring topology in on-chip networks\",\n        \"Cache Consistency in Hierarchical-Ring-Based Multiprocessors\",\n        \"Hector: A Hierarchically Structured Shared-Memory Multiprocessor\",\n        \"A performance comparison of hierarchical ring- and mesh-connected multiprocessor networks\",\n        \"Comparative modeling and evaluation of CC-NUMA and COMA on hierarchical ring architectures\",\n        \"Hierarchical ring network configuration and performance modeling\",\n        \"On topology and bisection bandwidth for hierarchical-ring networks for shared memory multiprocessors\",\n        \"The NUMAchine multiprocessor\",\n        \"Performance Evaluation of Hierarchical Ring-based Shared Memory Multiprocessors\",\n        \"Improving energy efficiency of hierarchical rings via deflection routing\",\n        \"The Connection Machine\",\n        \"Architecture and applications of the HEP multiprocessor computer system\",\n        \"SCARAB: A single cycle adaptive routing and bufferless network\",\n        \"Reducing packet dropping in a bufferless NoC\",\n        \"Implementation analysis of NoC: a MPSoC trace-driven approach\",\n        \"Evaluation of on-chip networks using deflection routing\",\n        \"Comparative evaluation of FPGA and ASIC implementations of bufferless and buffered routing algorithms for on-chip networks\",\n        \"Unslotted deflection routing: a practical and efficient protocol for multihop optical networks\",\n        \"Deflection routing in hypercube networks\",\n        \"Fast deflection routing for packets and worms\",\n        \"M. Magdon-Ismail\",\n        \"Clumsy flow control for high-throughput bufferless on-chip networks\",\n        \"BPS: a bufferless switching technique for NoCs\",\n        \"Hard-potato routing\",\n        \"Chaos router: architecture and performance\",\n        \"Lockup-Free Instruction Fetch/Prefetch Cache Organization\",\n        \"Complexity/Performance Tradeoffs with Non-Blocking Loads\",\n        \"Scalable Cache Miss Handling for High Memory-Level Parallelism\",\n        \"Adaptive flow control for robust performance and energy\",\n        \"Bufferless and Minimally-Buffered Deflection Routing\",\n        \"Towards scalable\",\n        \"Design and evaluation of hierarchical on-chip network topologies for next generation CMPs\",\n        \"DSENT - a tool connecting emerging photonics with electronics for opto-electronic networks-on-chip modeling\",\n        \"Avoiding message-dependent deadlock in network-based systems-on-chip\",\n        \"Low-cost router microarchitecture for on-chip networks\",\n        \"The SGI Origin: a ccNUMA highly scalable server\",\n        \"A flow control mechanism to avoid message deadlock in k-ary n-cube networks\",\n        \"in: https://github.com/CMU-SAFARI/NOCulator\",\n        \"Pin: building customized program analysis tools with dynamic instrumentation\",\n        \"Cloudcache: Expanding and shrinking private caches\",\n        \"Investigating the viability of bufferless NoCs in modern chip multi-processor systems\",\n        \"GraphChi: Large-scale graph computation on just a PC\",\n        \"GraphLab: A new parallel framework for machine learning\",\n        \"a social network or a news media?\",\n        \"Symbiotic jobscheduling for a simultaneous multithreaded processor\",\n        \"System-level performance metrics for multiprogram workloads\",\n        \"ATLAS: a scalable and high-performance scheduling algorithm for multiple memory controllers\",\n        \"Thread cluster memory scheduling: Exploiting differences in memory access behavior\",\n        \"Fairness metrics for multi-threaded processors\",\n        \"Fairness via source throttling: a configurable and high-performance fairness substrate for multi-core memory systems\",\n        \"Prefetch-aware shared resource management for multi-core systems\",\n        \"Coordinated control of multiple prefetchers in multi-core systems\",\n        \"Reducing memory interference in multicore systems via application-aware memory channel partitioning\",\n        \"The application slowdown model: Quantifying and controlling the impact of inter-application interference at shared caches and main memory\",\n        \"MISE: Providing performance predictability and improving fairness in shared main memory systems\",\n        \"DASH: Deadline-Aware High-Performance Memory Scheduler for Heterogeneous Systems with Hardware Accelerators\",\n        \"Staged Memory Scheduling: Achieving High Performance and Scalability in Heterogeneous Systems\",\n        \"The blacklisting memory scheduler: Achieving high performance and fairness at low cost\",\n        \"The blacklisting memory scheduler: Balancing performance\",\n        \"Self-tuned congestion control for multiprocessor networks\",\n        \"A family of mechanisms for congestion control in wormhole networks\",\n        \"Transportation-network-inspired network-on-chip\",\n        \"The scalable coherent interface and related standards projects\",\n        \"Kendall square multiprocessor: Early experiences and performance\",\n        \"The Gemini System Interconnect\",\n        \"Design tradeoffs for tiled CMP on-chip networks\",\n        \"A QoS-Enabled On-Die Interconnect Fabric for Kilo-Node Chips\",\n        \"HyperX: topology\",\n        \"Slim Fly: A Cost Effective Low-Diameter Network Topology\",\n        \"The Turn Model for Adaptive Routing\",\n        \"Retrospective: The Turn Model for Adaptive Routing\",\n        \"Low-latency virtual-channel routers for on-chip networks\",\n        \"Rotary router: an efficient architecture for CMP interconnection networks\",\n        \"iDEAL: Inter-router dual-function energy and area-efficient links for network-on-chip (NoC) architectures\",\n        \"M. Shoaib Bin Altaf\",\n        \"Centaur: A Chiplet-Based\",\n        \"String Figure: A Scalable and Elastic Memory Network Architecture\",\n        \"Beyond the Memory Wall: A Case for Memory-centric HPC System for Deep Learning\",\n        \"A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing\",\n        \"GraphP: Reducing Communication for PIM-Based Graph Processing with Efficient Data Partition\",\n        \"Processing Data Where It Makes Sense: Enabling In-Memory Computation\",\n        \"Accelerating Sparse Matrix-Matrix Multiplication with 3D-Stacked Logic-in-Memory Hardware\",\n        \"R. Balasubramonian\",\n        \"TOP-PIM: Throughput-Oriented Programmable Processing in Memory\",\n        \"NDA: Near-DRAM acceleration architecture leveraging commodity DRAM devices and standard memory modules\",\n        \"PIM-Enabled Instructions: A Low-Overhead\",\n        \"A Processing in Memory Taxonomy and a Case for Studying Fixed-Function PIM\",\n        \"Transparent Offloading and Mapping (TOM): Enabling Programmer-Transparent Near-Data Processing in GPU Systems\",\n        \"Accelerating Pointer Chasing in 3D-Stacked Memory: Challenges\",\n        \"JAFAR: Near-Data Processing for Databases\",\n        \"BSSync: Processing Near Memory for Machine Learning Workloads with Bounded Staleness Consistency Models\",\n        \"HRL: Efficient and Flexible Reconfigurable Logic for Near-Data Processing\",\n        \"PRIME: A Novel Processing-In-Memory Architecture for Neural Network Computation In ReRAM-Based Main Memory\",\n        \"Biscuit: A Framework for Near-Data Processing of Big Data Workloads\",\n        \"Neurocube: A Programmable Digital Neuromorphic Architecture with High-Density 3D Memory\",\n        \"Chameleon: Versatile and Practical Near-DRAM Acceleration Architecture for Large Memory Systems\",\n        \"LazyPIM: An Efficient Cache Coherence Mechanism for Processing-in-Memory\",\n        \"Accelerating Dependent Cache Misses with an Enhanced Memory Controller\",\n        \"Practical Near-Data Processing for In-Memory Analytics Frameworks\",\n        \"3D-Stacked Memory-Side Acceleration: Accelerator and System Design\",\n        \"Data Access Optimization in a Processing-in-Memory System\",\n        \"GP-SIMD Processing-in-Memory\",\n        \"Near Data Processing: Impact and Optimization of 3D Memory System Architecture on the Uncore\",\n        \"Pinatubo: A Processing-in-Memory Architecture for Bulk Bitwise Operations in Emerging Non-Volatile Memories\",\n        \"An Energy-Efficient VLSI Architecture for Pattern Recognition via Deep Embedding of Computation in SRAM\",\n        \"N. Muralimanohar\",\n        \"GraphPIM: Enabling Instruction-Level PIM Offloading in Graph Computing Frameworks\",\n        \"GRIM-Filter: Fast Seed Filtering in Read Mapping Using Emerging Memory Technologies\",\n        \"GRIM-Filter: Fast Seed Location Filtering in DNA Read Mapping Using Processing-in-Memory Technologies\",\n        \"DRISA: A DRAM-Based Reconfigurable In-Situ Accelerator\",\n        \"Toward Standardized Near-Data Processing with Unrestricted Data Placement for GPUs\",\n        \"NATSA: A Near-Data Processing Accelerator for Time Series Analysis\",\n        \"NAPEL: Near-memory Computing Application Performance Prediction via Ensemble Learning\",\n        \"D. Diamantopoulos\",\n        \"FIGARO: Improving System Performance via Fine-Grained In-DRAM Data Relocation and Caching\",\n        \"SynCron: Efficient Synchronization Support for Near-Data-Processing Architectures\",\n        \"Benchmarking a new paradigm: An experimental analysis of a real processing-in-memory architecture (2021)\",\n        \"R. Narayanaswami\",\n        \"DAMOV: A New Methodology and Benchmark Suite for Evaluating Data Movement Bottlenecks\",\n        \"Intelligent Architectures for Intelligent Computing Systems\",\n        \"25.4 A 20nm 6GB Function-In-Memory DRAM\",\n        \"Hardware Architecture and Software Stack for PIM Based on Commercial DRAM Technology : Industrial Product\",\n        \"Understanding a Modern Processing-in-Memory Architecture: Benchmarking and Experimental Characterization\",\n        \"J. a. D. Ferreira\",\n        \"Fast Bulk Bitwise AND and OR in DRAM\",\n        \"Low-Cost Inter-Linked Subarrays (LISA): Enabling Fast Inter-Subarray Data Movement in DRAM\",\n        \"Ambit: In-Memory Accelerator for Bulk Bitwise Operations Using Commodity DRAM Technology\"\n    ],\n    \"reasoning\": \"Selected these 167 references because they represent foundational work and recent advances in Energy-Efficient Deflection-based On-chip Networks: Topology, Routing, Flow Control, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}