{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 59 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: MetaCon: Unified Predictive Segments System with Trillion Concept Meta-Learning\n\nPaper Abstract: Abstract. Accurate understanding of users in terms of predicative segments play an essential role in the day to day operation of modern internet enterprises. Nevertheless, there are significant challenges that limit the quality of data, especially on long tail predictive tasks. In this work, we present MetaCon, our unified predicative segments system with scalable, trillion concepts meta learning that addresses these challenges. It builds on top of a flat concept representation (li2021hadoop, ) that summarizes entitiesâ€™ heterogeneous digital footprint, jointly considers the entire spectrum of predicative tasks as a single learning task, and leverages principled meta learning approach with efficient first order meta-optimization procedure under a provable performance guarantee in order to solve the learning task. Experiments on both proprietary production datasets and public structured learning tasks demonstrate that MetaCon can lead to substantial improvements over state of the art recommendation and ranking approaches.\n\n{retrieved_text}\n\nGenerate exactly 59 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 59\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Hadoop-mta: a system for multi data-center trillion concepts auto-ml atop hadoop\",\n        \"Driving big data with hadoop tools and technologies\",\n        \"Target marketing and segmentation: valid and useful tools for marketing\",\n        \"The eu general data protection regulation (gdpr)\",\n        \"https://blog.chromium.org/2019/05/improving-privacy-and-security-on-web.html\",\n        \"Towards a privacy-preserving web\",\n        \"Recommending what video to watch next: a multitask ranking system\",\n        \"Ad click prediction: a view from the trenches\",\n        \"Related pins at pinterest: The evolution of a real-world recommender system\",\n        \"Practical lessons from predicting clicks on ads at facebook\",\n        \"Visual discovery at pinterest\",\n        \"Practical lessons from developing a large-scale recommender system at zalando\",\n        \"Deep neural networks for youtube recommendations\",\n        \"Why i like it: multi-task learning for recommendation and explanation\",\n        \"Localized factor models for multi-context recommendation\",\n        \"Multi-objective optimization for long tail recommendation\",\n        \"Entire space multi-task model: An effective approach for estimating post-click conversion rate\",\n        \"Progressive layered extraction (ple): A novel multi-task learning (mtl) model for personalized recommendations\",\n        \"The psychological nature of concepts\",\n        \"Mining and analyzing technical knowledge based on concepts\",\n        \"Concept expansion using web tables\",\n        \"On social event organization\",\n        \"Discovering enterprise concepts using spreadsheet tables\",\n        \"Fts: Faceted taxonomy construction and search for scientific publications\",\n        \"Poqaa: Text mining and knowledge sharing for scientific publications\",\n        \"Mining algorithm roadmap in scientific publications\",\n        \"Hiercon: Hierarchical organization of technical documents based on concepts\",\n        \"Unsupervised neural categorization for scientific publications\",\n        \"Concept mining via embedding\",\n        \"Learning to learn: Introduction and overview\",\n        \"Improving generalization in meta reinforcement learning using learned objectives\",\n        \"Meta-learning in reinforcement learning\",\n        \"Bilevel programming for hyperparameter optimization and meta-learning\",\n        \"Autoaugment: Learning augmentation policies from data\",\n        \"Online meta-critic learning for off-policy actor-critic methods\",\n        \"Meta learning via learned loss\",\n        \"Darts: Differentiable architecture search\",\n        \"Model-agnostic meta-learning for fast adaptation of deep networks\",\n        \"Learning a synaptic learning rule\",\n        \"Automl: From methodology to application\",\n        \"Heterogeneous network representation learning: A unified framework with survey and benchmark\",\n        \"Evolving memory cell structures for sequence learning\",\n        \"Neural architecture search with reinforcement learning\",\n        \"Meta-learning update rules for unsupervised representation learning\",\n        \"Evolution strategies as a scalable alternative to reinforcement learning\",\n        \"Optimization as a model for few-shot learning\",\n        \"Prototypical networks for few-shot learning\",\n        \"A relational model of data for large shared data banks\",\n        \"Adaptive mixtures of local experts\",\n        \"Modeling task relationships in multi-task learning with multi-gate mixture-of-experts\",\n        \"Overcoming negative transfer: A survey\",\n        \"Meta-learning with implicit gradients\",\n        \"Tnt: Text normalization based pre-training of transformers for content moderation\",\n        \"Predicting pre-click quality for native advertisements\",\n        \"Result analysis of the nips 2003 feature selection challenge\",\n        \"Sequential minimal optimization: A fast algorithm for training support vector machines\",\n        \"Wide & deep learning for recommender systems\",\n        \"Deep & cross network for ad click predictions\",\n        \"Dcn v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems\"\n    ],\n    \"reasoning\": \"Selected these 59 references because they represent foundational work and recent advances in MetaCon: Unified Predictive Segments System with Trillion Concept Meta-Learning, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}