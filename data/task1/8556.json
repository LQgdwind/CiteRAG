{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 59 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Data-driven Knowledge Fusion for Deep Multi-instance Learning\n\nPaper Abstract: Abstract Multi-instance learning (MIL) is a widely-applied technique in practical applications that involve complex data structures. MIL can be broadly categorized into two types: traditional methods and those based on deep learning. These approaches have yielded significant results, especially with regards to their problem-solving strategies and experimental validation, providing valuable insights for researchers in the MIL field. However, a considerable amount of knowledge is often trapped within the algorithm, leading to subsequent MIL algorithms that solely rely on the model’s data fitting to predict unlabeled samples. This results in a significant loss of knowledge and impedes the development of more intelligent models. In this paper, we propose a novel data-driven knowledge fusion for deep multi-instance learning (DKMIL) algorithm. DKMIL adopts a completely different idea from existing deep MIL methods by analyzing the decision-making of key samples in the data set (referred to as the data-driven) and using the knowledge fusion module designed to extract valuable information from these samples to assist the model’s training. In other words, this module serves as a new interface between data and the model, providing strong scalability and enabling the use of prior knowledge from existing algorithms to enhance the learning ability of the model. Furthermore, to adapt the downstream modules of the model to more knowledge-enriched features extracted from the data-driven knowledge fusion module, we propose a two-level attention module that gradually learns shallow- and deep-level features of the samples to achieve more effective classification. We will prove the scalability of the knowledge fusion module while also verifying the efficacy of the proposed architecture by conducting experiments on 38 data sets across 6 categories.\n\n{retrieved_text}\n\nGenerate exactly 59 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 59\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Evolutionary computation: Comments on the history and current state\",\n        \"Evolutionary computation: A unified approach\",\n        \"A review: Knowledge reasoning over knowledge graph\",\n        \"Knowledge graphs\",\n        \"Reinforcement learning: A survey\",\n        \"Deep reinforcement learning: A brief survey\",\n        \"Abductive learning: Towards bridging machine learning and logical reasoning\",\n        \"Abductive learning with ground knowledge base.\",\n        \"Solving the multiple instance problem with axis-parallel rectangles\",\n        \"Multi-instance learning with discriminative bag mapping\",\n        \"Multi-instance ensemble learning with discriminative bags\",\n        \"Keyword-based diverse image retrieval with variational multiple instance graph\",\n        \"Multi-instance learning based web mining\",\n        \"Multiple instance learning with emerging novel class\",\n        \"Bag dissimilarity regularized multi-instance learning\",\n        \"Real-world anomaly detection in surveillance videos\",\n        \"Weakly-supervised video anomaly detection with robust temporal feature magnitude learning\",\n        \"Self-training multi-sequence learning with transformer for weakly supervised video anomaly detection\",\n        \"Interventional multi-instance learning with deconfounded instance-level prediction\",\n        \"MuRCL: Multi-instance reinforcement contrastive learning for whole slide image classification\",\n        \"TransMIL: Transformer based correlated multiple instance learning for whole slide image classification\",\n        \"Scalable algorithms for multi-instance learning\",\n        \"Attention-based deep multiple instance learning\",\n        \"Multi-attention multiple instance learning\",\n        \"Multi-instance clustering with applications to multi-instance prediction\",\n        \"Robust multi-instance learning with stable instances\",\n        \"MILIS: Multiple instance learning with instance selection\",\n        \"Multi instance neural networks\",\n        \"Neural networks for multi-instance learning\",\n        \"Improve multi-instance neural networks through feature selection\",\n        \"Revisiting multiple instance neural networks\",\n        \"Loss-based attention for deep multiple instance learning\",\n        \"Dual-stream multiple instance learning network for whole slide image classification with self-supervised contrastive learning\",\n        \"Childhood leukemia classification via information bottleneck enhanced hierarchical multi-instance learning\",\n        \"Clustering by fast search and find of density peaks\",\n        \"Multi-embedding space set-kernel and its application to multi-instance learning\",\n        \"Understanding of a convolutional neural network\",\n        \"FlowNet 2.0: Evolution of optical flow estimation with deep networks\",\n        \"Image super-resolution using dense skip connections\",\n        \"Uctransnet: Rethinking the skip connections in u-net from a channel-wise perspective with transformer\",\n        \"Robust bag classification approach for multi-instance learning via subspace fuzzy clustering\",\n        \"Multi-instance learning by treating instances as non-I.I.D. samples\",\n        \"Mask R-CNN\",\n        \"Mask-CNN: Localizing parts and selecting descriptors for fine-grained bird species categorization\",\n        \"Multi-instance embedding learning through high-level instance selection\",\n        \"Attention is all you need\",\n        \"Multiscale structural similarity for image quality assessment\",\n        \"An empirical study on image bag generators for multi-instance learning\",\n        \"Attention-to-embedding framework for multi-instance learning\",\n        \"Interpreting vulnerabilities of multi-instance learning to adversarial perturbations\",\n        \"Support vector machines for multiple-instance learning\",\n        \"Real-time computerized annotation of pictures\",\n        \"The MNIST database of handwritten digits\",\n        \"Learning multiple layers of features from tiny images\",\n        \"An analysis of single-layer networks in unsupervised feature learning\",\n        \"Future frame prediction for anomaly detection–a new baseline\",\n        \"Graph convolutional label noise cleaner: Train a plug-and-play action classifier for anomaly detection\",\n        \"The kinetics human action video dataset\",\n        \"Enhanced performance of brain tumor classification via tumor region augmentation and partition\"\n    ],\n    \"reasoning\": \"Selected these 59 references because they represent foundational work and recent advances in Data-driven Knowledge Fusion for Deep Multi-instance Learning, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}