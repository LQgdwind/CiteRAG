{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 54 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Explicit and Implicit Pattern Relation Analysis for Discovering Actionable Negative Sequences\n\nPaper Abstract: Abstract Real-life events, behaviors and interactions produce sequential data. An important but rarely explored problem is to analyze those nonoccurring (also called negative) yet important sequences, forming negative sequence analysis (NSA). A typical NSA area is to discover negative sequential patterns (NSPs) consisting of important non-occurring and occurring elements and patterns. The limited existing work on NSP mining relies on frequentist and downward closure property-based pattern selection, producing large and highly redundant NSPs, nonactionable for business decision-making. This work makes the first attempt for actionable NSP discovery. It builds an NSP graph representation, quantify both explicit occurrence and implicit non-occurrence-based element and pattern relations, and then discover significant, diverse and informative NSPs in the NSP graph to represent the entire NSP set for discovering actionable NSPs. A DPP-based NSP representation and actionable NSP discovery method EINSP introduces novel and significant contributions for NSA and sequence analysis: (1) it represents NSPs by a determinantal point process (DPP) based graph; (2) it quantifies actionable NSPs in terms of their statistical significance, diversity, and strength of explicit/implicit element/pattern relations; and (3) it models and measures both explicit and implicit element/pattern relations in the DPP-based NSP graph to represent direct and indirect couplings between NSP items, elements and patterns. We substantially analyze the effectiveness of EINSP in terms of various theoretical and empirical aspects including complexity, item/pattern coverage, pattern size and diversity, implicit pattern relation strength, and data factors.\n\n{retrieved_text}\n\nGenerate exactly 54 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 54\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Negative sequence analysis: A review\",\n        \"Nonoccurring behavior analytics: A new area\",\n        \"eNSP: Efficient negative sequential pattern mining\",\n        \"Mining negative sequential patterns\",\n        \"Mining negative sequential patterns for e-commerce recommendations\",\n        \"Mining impact-targeted activity patterns in imbalanced data\",\n        \"Mining approximate multi-relational patterns\",\n        \"Mining sequential patterns\",\n        \"Discovering maximal periodic-frequent patterns in very large temporal databases\",\n        \"Fixed point for set-valued mappings satisfying an implicit relation in partially ordered metric spaces\",\n        \"Coupled behavior analysis with applications\",\n        \"Negative-GSP: An efficient method for mining negative sequential patterns\",\n        \"An efficient GA-based algorithm for mining negative sequential patterns\",\n        \"Research on typical algorithms in negative sequential pattern mining\",\n        \"Debt detection in social security by sequence classification using both positive and negative patterns\",\n        \"Mining both positive and negative impact-oriented sequential rules from transactional data\",\n        \"An effective contrast sequential pattern mining approach to taxpayer behavior analysis\",\n        \"Campus data analysis based on positive and negative sequential patterns\",\n        \"Combined mining: Analyzing object and pattern relations for discovering and constructing complex yet actionable patterns\",\n        \"Select actionable positive or negative sequential patterns\",\n        \"Unsupervised video summarization with adversarial lstm networks\",\n        \"Coupling learning of complex interactions\",\n        \"P-n-rminer: a generic framework for mining interesting structured relational patterns\",\n        \"Learning determinantal point processes\",\n        \"Expectation-maximization for learning determinantal point processes\",\n        \"Towards a theory of negative dependence\",\n        \"Negative dependence and the geometry of polynomials\",\n        \"Determinantal point processes for machine learning\",\n        \"Determinantal point processes\",\n        \"Learning the parameters of determinantal point process kernels\",\n        \"Determinantal thinning of point processes with network learning applications\",\n        \"Fixed-point algorithms for learning determinantal point processes\",\n        \"Inferring implicit rules by learning explicit and hidden item dependency\",\n        \"Discovering diverse subset for unsupervised hyperspectral band selection\",\n        \"Cohesion based co-location pattern mining\",\n        \"Short sequence classification through discriminable linear dynamical system\",\n        \"Bfspminer: an effective and efficient batch-free algorithm for mining sequential patterns over data streams\",\n        \"An incremental technique for mining coverage patterns in large databases\",\n        \"Mining behavioral sequence constraints for classification\",\n        \"Negpspan: Efficient extraction of negative sequential patterns with embedding constraints\",\n        \"e-nspfi: Efficient mining negative sequential pattern from both frequent and infrequent positive sequential patterns\",\n        \"F-NSP+: A fast negative sequential patterns mining method with self-adaptive data storage\",\n        \"Mining top-k useful negative sequential patterns via learning\",\n        \"e-rnsp: An efficient method for mining repetition negative sequential patterns\",\n        \"On mining progressive positive and negative sequential patterns simultaneously\",\n        \"Diverse sequential subset selection for supervised video summarization\",\n        \"Improving the estimation of word importance for news multi-document summarization\",\n        \"Discovering diverse and salient threads in document collections\",\n        \"Fast greedy map inference for determinantal point process to improve recommendation diversity\",\n        \"k-dpps: Fixed-size determinantal point processes\",\n        \"Structured determinantal point processes\",\n        \"Normalized (pointwise) mutual information in collocation extraction\",\n        \"First-and second-order expectation semirings with applications to minimum-risk training on translation forests\",\n        \"Nu-minebench version 2.0 data set and technical report\"\n    ],\n    \"reasoning\": \"Selected these 54 references because they represent foundational work and recent advances in Explicit and Implicit Pattern Relation Analysis for Discovering Actionable Negative Sequences, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}