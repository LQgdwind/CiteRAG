{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 59 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: RHS-TRNG: A Resilient High-Speed True Random Number Generator Based on STT-MTJ Device\n\nPaper Abstract: Abstract High-quality random numbers are very critical to many fields such as cryptography, finance, and scientific simulation, which calls for the design of reliable true random number generators (TRNGs). Limited by entropy source, throughput, reliability, and system integration, existing TRNG designs are difficult to be deployed in real computing systems to greatly accelerate target applications. This study proposes a TRNG circuit named RHS-TRNG based on spin-transfer torque magnetic tunnel junction (STT-MTJ). RHS-TRNG generates resilient and high-speed random bit sequences exploiting the stochastic switching characteristics of STT-MTJ. By circuit/system co-design, we integrate RHS-TRNG into a RISC-V processor as an acceleration component, which is driven by customized random number generation instructions. Our experimental results show that a single cell of RHS-TRNG has a random bit generation speed of up to 303 Mb/s, which is the highest among existing MTJ-based TRNGs. Higher throughput can be achieved by exploiting cell-level parallelism. RHS-TRNG also shows strong resilience against PVT variations thanks to our designs using bidirectional switching currents and dual generator units. In addition, our system evaluation results using gem5 simulator suggest that the system equipped with RHS-TRNG can achieve 3.4–12x higher performance in speeding up option pricing programs than software implementations of random number generation.\n\n{retrieved_text}\n\nGenerate exactly 59 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 59\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Encryption by heart (EbH)-using ECG for time-invariant symmetric key generation\",\n        \"The surprising power of graph neural networks with random node initialization\",\n        \"SPINBIS: Spintronics-based Bayesian inference system with stochastic computing\",\n        \"Inferring a sequence generated by a linear congruence\",\n        \"A robust authentication methodology using physically unclonable functions in DRAM arrays\",\n        \"D-PUF: An intrinsically reconfigurable DRAM PUF for device authentication and random number generation\",\n        \"DRNG: DRAM-based random number generation using its startup value behavior\",\n        \"DRAM as source of randomness\",\n        \"D-RaNGe: Using commodity DRAM devices to generate true random numbers with low latency and high throughput\",\n        \"8.2 8Mb/s 28Mb/mJ robust true-random-number generator in 65nm CMOS based on differential ring oscillator with feedback resistors\",\n        \"Analysis of ring-oscillator-based true random number generator on FPGAs\",\n        \"Robust metastability-based TRNG design in nanometer CMOS with sub-vdd pre-charge and hybrid self-calibration\",\n        \"A metastability-based true random number generator on FPGA\",\n        \"A true random number generator using time-dependent dielectric breakdown\",\n        \"Magnetism\",\n        \"A novel circuit design of true random number generator using magnetic tunnel junction\",\n        \"True random number generator for reliable hardware security modules based on a neuromorphic variation-tolerant spintronic structure\",\n        \"An asynchronous and low-power true random number generator using STT-MTJ\",\n        \"High-entropy STT-MTJ-based TRNG\",\n        \"A true random number generator based on parallel STT-MTJs\",\n        \"Variation-resilient true random number generators based on multiple STT-MTJs\",\n        \"A process variation resilient spintronic true random number generator for highly reliable hardware security applications\",\n        \"A scaling roadmap and performance evaluation of in-plane and perpendicular MTJ based STT-MRAMs for high-density cache memory\",\n        \"Development of the magnetic tunnel junction MRAM at IBM: From first junctions to a 16-Mb MRAM demonstrator chip\",\n        \"Tunable linear magnetoresistance in MgO magnetic tunnel junction sensors using two pinned CoFeB electrodes\",\n        \"Yoke-shaped MgO-barrier magnetic tunnel junction sensors\",\n        \"Magnetic tunnel junctions for spintronic memories and beyond\",\n        \"Materials for spin-transfer-torque magnetoresistive random-access memory\",\n        \"Theory of tunneling magnetoresistance of an epitaxial Fe/MgO/Fe (001) junction\",\n        \"Systematic optimization of 1 Gbit perpendicular magnetic tunnel junction arrays for 28 nm embedded STT-MRAM and beyond\",\n        \"Defect and fault modeling framework for STT-MRAM testing\",\n        \"Commercialization of 1Gb standalone spin-transfer torque MRAM\",\n        \"13.3 A 22nm 32Mb embedded STT-MRAM with 10ns read speed, 1M cycle write endurance, 10 years retention at 150 °C and high immunity to magnetic field interference\",\n        \"Embedded STT-MRAM in 28-nm FDSOI logic process for industrial MCU/IoT application\",\n        \"Manufacturable 22nm FD-SOI embedded MRAM technology for industrial-grade MCU and IOT applications\",\n        \"A 4-Mb toggle MRAM based on a novel bit and switching method\",\n        \"22nm STT-MRAM for reflow and automotive uses with high yield, reliability, and magnetic immunity and with performance and shielding options\",\n        \"CMOS compatible process integration of SOT-MRAM with heavy-metal bi-layer bottom electrode and 10ns field-free SOT switching with STT assist\",\n        \"Basic principles of STT-MRAM cell operation in memory arrays\",\n        \"Survey on STT-MRAM testing: Failure mechanisms, fault models, and tests\",\n        \"Switching-probability distribution of spin-torque switching in MgO-based magnetic tunnel junctions\",\n        \"Physically transient true random number generators based on paired threshold switches enabling Monte Carlo method applications\",\n        \"Fast cpu-based monte carlo simulation for radiotherapy dose calculation\",\n        \"Reconfigurable and dynamically transformable in-cache-MPUF system with true randomness based on the SOT-MRAM\",\n        \"QUAC-TRNG: High-throughput true random number generation using quadruple row activation in commodity DRAM chips\",\n        \"A study of dielectric breakdown mechanism in CoFeB/MgO/CoFeB magnetic tunnel junction\",\n        \"Characterization, modeling, and test of intermediate state defects in STT-MRAMs\",\n        \"STT-RAM cell design considering CMOS and MTJ temperature dependence\",\n        \"A magnetic tunnel junction based true random number generator with conditional perturb and real-time output probability tracking\",\n        \"Design of an STT-MTJ based true random number generator using digitally controlled probability-locked loop\",\n        \"High speed, high stability and low power sensing amplifier for MTJ/CMOS hybrid logic circuits\",\n        \"Testing STT-MRAM: Manufacturing defects, fault models, and test solutions\",\n        \"Compact model of magnetic tunnel junction with stochastic spin transfer torque switching for reliability analyses\",\n        \"Sp 800-22 rev. 1a. a statistical test suite for random and pseudorandom number generators for cryptographic applications\",\n        \"Analytical macrospin modeling of the stochastic switching time of spin-transfer torque devices\",\n        \"Use of the Monte Carlo simulation in valuation of european and american call options\",\n        \"Python for Finance: Analyze big financial data\",\n        \"The boost C++ libraries\",\n        \"Low-energy truly random number generation with superparamagnetic tunnel junctions for unconventional computing\"\n    ],\n    \"reasoning\": \"Selected these 59 references because they represent foundational work and recent advances in RHS-TRNG: A Resilient High-Speed True Random Number Generator Based on STT-MTJ Device, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}