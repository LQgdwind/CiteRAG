{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 52 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation\n\nPaper Abstract: Abstract Recently, deep learning based methods have revolutionized remote sensing image segmentation. However, these methods usually rely on a predefined semantic class set, thus needing additional image annotation and model training when adapting to new classes. More importantly, they are unable to segment arbitrary semantic classes. In this work, we introduce Open-Vocabulary Remote Sensing Image Semantic Segmentation (OVRSISS), which aims to segment arbitrary semantic classes in remote sensing images. To address the lack of OVRSISS datasets, we develop LandDiscover50K, a comprehensive dataset of 51,846 images covering 40 diverse semantic classes. In addition, we propose a novel framework named GSNet that integrates domain priors from special remote sensing models and versatile capabilities of general vision-language models. Technically, GSNet consists of a Dual-Stream Image Encoder (DSIE), a Query-Guided Feature Fusion (QGFF), and a Residual Information Preservation Decoder (RIPD). DSIE first captures comprehensive features from both special models and general models in dual streams. Then, with the guidance of variable vocabularies, QGFF integrates specialist and generalist features, enabling them to complement each other. Finally, RIPD is proposed to aggregate multi-source features for more accurate mask predictions. Experiments show that our method outperforms other methods by a large margin, and our proposed LandDiscover50K improves the performance of OVRSISS methods. The proposed dataset and method will be made publicly available at https://github.com/yecy749/GSNet.\n\n{retrieved_text}\n\nGenerate exactly 52 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 52\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Synthesizing optical and SAR imagery from land cover maps and auxiliary raster data\",\n        \"LandCover. ai: Dataset for automatic mapping of buildings, woodlands, water and roads from aerial imagery\",\n        \"Coco-stuff: Thing and stuff classes in context\",\n        \"Emerging properties in self-supervised vision transformers\",\n        \"TEMPORARY REMOVAL: Aerial imagery for roof segmentation: A large-scale dataset towards automatic mapping of buildings\",\n        \"Cat-seg: Cost aggregation for open-vocabulary semantic segmentation\",\n        \"Deepglobe 2018: A challenge to parse the earth through satellite images\",\n        \"An image is worth 16x16 words: Transformers for image recognition at scale\",\n        \"Guidelines on the Use of Remote Sensing Products to Improve Agricultural Crop Production Forecast Statistics in Sub-Saharan African Countries\",\n        \"FLAIR: a country-scale land cover semantic segmentation dataset from multi-source optical imagery\",\n        \"Scaling open-vocabulary image segmentation with image-level labels\",\n        \"Creating xBD: A dataset for assessing building damage from satellite imagery\",\n        \"Semantic segmentation of remote sensing images with sparse annotations\",\n        \"2D Semantic Labeling Potsdam Dataset\",\n        \"2D Semantic Labeling Vaihingen Dataset\",\n        \"Few-Shot Segmentation of Remote Sensing Images Using Deep Metric Learning\",\n        \"Language-driven Semantic Segmentation\",\n        \"Semisupervised semantic segmentation of remote sensing images with consistency self-training\",\n        \"Object detection in optical remote sensing images: A survey and a new benchmark\",\n        \"Open-vocabulary semantic segmentation with mask-adapted clip\",\n        \"Remoteclip: A vision language foundation model for remote sensing\",\n        \"Open-vocabulary segmentation with semantic-assisted calibration\",\n        \"Fully convolutional networks for semantic segmentation\",\n        \"Decoupled weight decay regularization\",\n        \"UAVid: A semantic segmentation dataset for UAV imagery\",\n        \"Can semantic labeling methods generalize to any city? the inria aerial image labeling benchmark\",\n        \"Open Cities AI Competition: Segmenting Buildings for Disaster Resilience\",\n        \"Pytorch: An imperative style, high-performance deep learning library\",\n        \"Learning transferable visual models from natural language supervision\",\n        \"Floodnet: A high resolution aerial imagery dataset for post flood scene understanding\",\n        \"U-net: Convolutional networks for biomedical image segmentation\",\n        \"Open-Vocabulary Semantic Segmentation with Image Embedding Balancing\",\n        \"SUNet: Change detection for heterogeneous remote sensing images from satellite and UAV using a dual-channel fully convolution network\",\n        \"Large-scale land cover classification in Gaofen-2 satellite imagery\",\n        \"Spacenet: A remote sensing dataset and challenge series\",\n        \"Remote sensing for natural disaster management\",\n        \"Semantic segmentation of urban scenes by learning local class interactions\",\n        \"Samrs: Scaling-up remote sensing segmentation dataset with segment anything model\",\n        \"LoveDA: A remote sensing land-cover dataset for domain adaptive semantic segmentation\",\n        \"isaid: A large-scale dataset for instance segmentation in aerial images\",\n        \"Detectron2\",\n        \"DOTA: A large-scale dataset for object detection in aerial images\",\n        \"Openearthmap: A benchmark dataset for global high-resolution land cover mapping\",\n        \"Sed: A simple encoder-decoder for open-vocabulary semantic segmentation\",\n        \"Side adapter network for open-vocabulary semantic segmentation\",\n        \"A simple baseline for open-vocabulary semantic segmentation with pre-trained vision-language model\",\n        \"AerialFormer: Multi-resolution Transformer for Aerial Image Segmentation\",\n        \"Fully transformer network for change detection of remote sensing images\",\n        \"Transy-net: Learning fully transformer networks for change detection of remote sensing images\",\n        \"Semantic annotation of high-resolution satellite images via weakly supervised learning\",\n        \"Foreground-aware relation network for geospatial object segmentation in high spatial resolution remote sensing imagery\",\n        \"Unsupervised domain adaptation semantic segmentation of high-resolution remote sensing imagery with invariant domain-level prototype memory\"\n    ],\n    \"reasoning\": \"Selected these 52 references because they represent foundational work and recent advances in Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}