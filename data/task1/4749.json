{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 53 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Training Generative Adversarial Networks with Adaptive Composite Gradient\n\nPaper Abstract: Abstract The wide applications of Generative adversarial networks benefit from the successful training methods, guaranteeing that an object function converges to the local minima. Nevertheless, designing an efficient and competitive training method is still a challenging task due to the cyclic behaviors of some gradient-based ways and the expensive computational cost of these methods based on the Hessian matrix. This paper proposed the adaptive Composite Gradients (ACG) method, linearly convergent in bilinear games under suitable settings. Theory and toy-function experiments suggest that our approach can alleviate the cyclic behaviors and converge faster than recently proposed algorithms. Significantly, the ACG method is not only used to find stable fixed points in bilinear games as well as in general games. The ACG method is a novel semi-gradient-free algorithm since it does not need to calculate the gradient of each step, reducing the computational cost of gradient and Hessian by utilizing the predictive information in future iterations. We conducted two mixture of Gaussians experiments by integrating ACG to existing algorithms with Linear GANs. Results show ACG is competitive with the previous algorithms. Realistic experiments on four prevalent data sets (MNIST, Fashion-MNIST, CIFAR-10, and CelebA) with DCGANs show that our ACG method outperforms several baselines, which illustrates the superiority and efficacy of our method.\n\n{retrieved_text}\n\nGenerate exactly 53 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 53\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"The mechanics of n-player differentiable games\",\n        \"Convex analysis and monotone operator theory in Hilbert spaces, volume 408\",\n        \"On the weak convergence of an ergodic iteration for the solution of variational inequalities for monotone operators in hilbert space\",\n        \"Taming gans with lookahead-minmax\",\n        \"GAN-BERT: Generative adversarial learning for robust text classification with a bunch of labeled examples\",\n        \"Scan: Structure correcting adversarial network for organ segmentation in chest x-rays\",\n        \"A variational inequality perspective on generative adversarial networks\",\n        \"Polyphonic music generation with sequence generative adversarial networks\",\n        \"Nips 2016 tutorial: Generative adversarial networks\",\n        \"Generative adversarial networks\",\n        \"Objective-reinforced generative adversarial networks (organ) for sequence generation models\",\n        \"Textkd-gan: Text generation using knowledgedistillation and generative adversarial networks\",\n        \"How generative adversarial networks and their variants work\",\n        \"Voice conversion from unaligned corpora using variational autoencoding wasserstein generative adversarial networks\",\n        \"Training gans with predictive projection centripetal acceleration\",\n        \"Learning to discover cross-domain relations with generative adversarial networks\",\n        \"Learning multiple layers of features from tiny images\",\n        \"Deblurgan: Blind motion deblurring using conditional adversarial networks\",\n        \"Gradient-based learning applied to document recognition\",\n        \"Photo-realistic single image super-resolution using a generative adversarial network\",\n        \"First-order methods almost always avoid saddle points\",\n        \"Deep reinforcement learning for multiobjective optimization\",\n        \"Interaction matters: A note on non-asymptotic local convergence of generative adversarial networks\",\n        \"Adversarial ranking for language generation\",\n        \"Deep learning face attributes in the wild\",\n        \"Deep generative adversarial neural networks for compressive sensing mri\",\n        \"The numerics of gans\",\n        \"Revisiting stochastic extragradient\",\n        \"A unified analysis of extra-gradient and optimistic gradient methods for saddle point problems: Proximal point approach\",\n        \"Subgradient methods for saddle-point problems\",\n        \"A method for solving the convex programming problem with convergence rate o‚Äã(1/k2)ùëú1superscriptùëò2o(1/k^{2})\",\n        \"Stabilizing gan training with multiple random projections\",\n        \"f-gan: Training generative neural samplers using variational divergence minimization\",\n        \"Open questions about generative adversarial networks\",\n        \"Training gans with centripetal acceleration\",\n        \"Trajectory of Alternating Direction Method of Multipliers and Adaptive Acceleration\",\n        \"Training generative adversarial networks by solving ordinary differential equations\",\n        \"Unsupervised representation learning with deep convolutional generative adversarial networks\",\n        \"Mocogan: Decomposing motion and content for video generation\",\n        \"Feudal networks for hierarchical reinforcement learning\",\n        \"Generating videos with scene dynamics\",\n        \"The pose knows: Video forecasting by generating pose futures\",\n        \"Perceptual adversarial networks for image-to-image transformation\",\n        \"Lookahead converges to stationary points of smooth non-convex functions\",\n        \"A mathematical introduction to generative adversarial nets (gan)\",\n        \"Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling\",\n        \"Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms\",\n        \"Automatic vertebra labeling in large-scale 3d ct using deep image-to-image network with message passing and sparsity regularization\",\n        \"Unified convergence analysis of stochastic momentum methods for convex and non-convex optimization\",\n        \"Dualgan: Unsupervised dual learning for image-to-image translation\",\n        \"Seqgan: Sequence generative adversarial nets with policy gradient\",\n        \"Dual adversarial network: Toward real-world noise removal and noise generation\",\n        \"Convergence of gradient methods on bilinear zero-sum games\"\n    ],\n    \"reasoning\": \"Selected these 53 references because they represent foundational work and recent advances in Training Generative Adversarial Networks with Adaptive Composite Gradient, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}