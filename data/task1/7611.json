{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 56 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Contextually Enhanced ES-dRNN with Dynamic Attention for Short-Term Load Forecasting\n\nPaper Abstract: Abstract In this paper, we propose a new short-term load forecasting (STLF) model based on contextually enhanced hybrid and hierarchical architecture combining exponential smoothing (ES) and a recurrent neural network (RNN). The model is composed of two simultaneously trained tracks: the context track and the main track. The context track introduces additional information to the main track. It is extracted from representative series and dynamically modulated to adjust to the individual series forecasted by the main track. The RNN architecture consists of multiple recurrent layers stacked with hierarchical dilations and equipped with recently proposed attentive dilated recurrent cells. These cells enable the model to capture short-term, long-term and seasonal dependencies across time series as well as to weight dynamically the input information. The model produces both point forecasts and predictive intervals. The experimental part of the work performed on 35 forecasting problems shows that the proposed model outperforms in terms of accuracy its predecessor as well as standard statistical models and state-of-the-art machine learning models.\n\n{retrieved_text}\n\nGenerate exactly 56 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 56\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"ES-dRNN: A Hybrid Exponential Smoothing and Dilated Recurrent Neural Network Model for Short-Term Load Forecasting\",\n        \"Rule-based autoregressive moving average models for forecasting load on special days: A case study for France\",\n        \"Short-term load forecasting with exponentially weighted methods\",\n        \"A refined parametric model for short term load forecasting\",\n        \"Using the ensemble Kalman filter for electricity load forecasting and analysis\",\n        \"Neural networks for pattern-based short-term load forecasting: A comparative study\",\n        \"Statistical load forecasting using optimal quantile regression random forest and risk assessment index\",\n        \"A hybrid forecasting model for short-term power load based on sample entropy, two-phase decomposition and whale algorithm optimized support vector regression\",\n        \"ReNFuzz-LF: A Recurrent Neurofuzzy System for Short-Term Load Forecasting\",\n        \"A deep learning method for short-term residential load forecasting in smart grid\",\n        \"Short-term residential load forecasting based on LSTM recurrent neural network\",\n        \"Short-term load forecasting for industrial customers based on TCN-LightGBM\",\n        \"A novel stacked generalization ensemble-based hybrid LGBM-XGB-MLP model for short-term load forecasting\",\n        \"Ultra-short-term industrial power demand forecasting using LSTM based hybrid ensemble learning\",\n        \"Kaggle forecasting competitions: An overlooked learning opportunity\",\n        \"Convolutional and recurrent neural network based model for short-term load forecasting\",\n        \"Deep learning for household load forecasting—A novel pooling deep RNN\",\n        \"Recurrent inception convolution neural network for multi short-term load forecasting\",\n        \"Bi-directional long short-term memory method based on attention mechanism and rolling update for short-term load forecasting\",\n        \"Short-term load forecasting with deep residual networks\",\n        \"Residential Electric Load Forecasting via Attentive Transfer of Graph Neural Networks.\",\n        \"A Hybrid Residual Dilated LSTM and Exponential Smoothing Model for Midterm Electric Load Forecasting\",\n        \"An interval decomposition-ensemble approach with data-characteristic-driven reconstruction for short-term load forecasting\",\n        \"Random vector functional link neural network based ensemble deep learning for short-term load forecasting\",\n        \"Advanced Ensemble Methods Using Machine Learning and Deep Learning for One-Day-Ahead Forecasts of Electric Energy Production in Wind Farms\",\n        \"Investigating Causal Relations by Econometric Models and Cross-spectral Methods\",\n        \"Multivariate time series forecasting with latent graph inference\",\n        \"Think globally, act locally: A deep neural network approach to high-dimensional time series forecasting\",\n        \"Deep factors for forecasting\",\n        \"Factor-based framework for multivariate and multi-step-ahead forecasting of large scale time series\",\n        \"Graph neural networks: A review of methods and applications\",\n        \"Connecting the dots: Multivariate time series forecasting with graph neural networks\",\n        \"Adaptive graph convolutional neural networks\",\n        \"Radflow: A recurrent, aggregated, and decomposable model for networks of time series\",\n        \"A dual-stage attention-based recurrent neural network for time series prediction\",\n        \"A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting\",\n        \"ES-dRNN with Dynamic Attention for Short-Term Load Forecasting\",\n        \"cES-adRNN code and data: https://github.com/slaweks17/ES-adRNN-with-Context.\",\n        \"Long short-term memory\",\n        \"Learning phrase representations using RNN encoder-decoder for statistical machine translation\",\n        \"Sequence modeling using a memory controller extension for LSTM\",\n        \"Deep residual learning for image recognition\",\n        \"Don’t decay the learning rate, increase the batch size\",\n        \"Pattern similarity-based methods for short-term load forecasting – part 2: Models\",\n        \"Forecasting at scale\",\n        \"Pattern-based forecasting of monthly electricity demand using support vector machine\",\n        \"Pattern-based long short-term memory for mid-term electrical load forecasting\",\n        \"Neuro-fuzzy system for medium-term electric energy demand forecasting\",\n        \"DeepAR: Probabilistic forecasting with autoregressive recurrent networks\",\n        \"WaveNet: A generative model for raw audio\",\n        \"N-BEATS: Neural basis expansion analysis for interpretable time series forecasting\",\n        \"LightGBM: A highly efficient gradient boosting decision tree\",\n        \"XGBoost: A scalable tree boosting system\",\n        \"Tests of conditional predictive ability\",\n        \"Criteria for classifying forecasting methods\",\n        \"Multitask learning\"\n    ],\n    \"reasoning\": \"Selected these 56 references because they represent foundational work and recent advances in Contextually Enhanced ES-dRNN with Dynamic Attention for Short-Term Load Forecasting, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}