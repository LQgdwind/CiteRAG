{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 441 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Computation-efficient Deep Learning for Computer Vision: A Survey\n\nPaper Abstract: Abstract\\\\ Over the past decade, deep learning models have exhibited considerable advancements, reaching or even exceeding human-level performance in a range of visual perception tasks. This remarkable progress has sparked interest in applying deep networks to real-world applications, such as autonomous vehicles, mobile devices, robotics, and edge computing. However, the challenge remains that state-of-the-art models usually demand significant computational resources, leading to impractical power consumption, latency, or carbon emissions in real-world scenarios. This trade-off between effectiveness and efficiency has catalyzed the emergence of a new research focus: computationally efficient deep learning, which strives to achieve satisfactory performance while minimizing the computational cost during inference. This review offers an extensive analysis of this rapidly evolving field by examining four key areas: 1) the development of static or dynamic light-weighted backbone models for the efficient extraction of discriminative deep representations; 2) the specialized network architectures or algorithms tailored for specific computer vision tasks; 3) the techniques employed for compressing deep learning models; and 4) the strategies for deploying efficient deep networks on hardware platforms. Additionally, we provide a systematic discussion on the critical challenges faced in this domain, such as network architecture design, training schemes, practical efficiency, and more realistic model compression approaches, as well as potential future research directions.\n\n{retrieved_text}\n\nGenerate exactly 441 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 441\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Imagenet classification with deep convolutional neural networks\",\n        \"Very deep convolutional networks for large-scale image recognition\",\n        \"Going deeper with convolutions\",\n        \"Deep residual learning for image recognition\",\n        \"Convolutional networks with dense connectivity\",\n        \"An image is worth 16x16 words: Transformers for image recognition at scale\",\n        \"Swin transformer: Hierarchical vision transformer using shifted windows\",\n        \"Object detection in 20 years: A survey\",\n        \"Image segmentation using deep learning: A survey\",\n        \"A survey on deep learning technique for video segmentation\",\n        \"Human action recognition and prediction: A survey\",\n        \"Human action recognition from various data modalities: A review\",\n        \"Deep learning for 3d point clouds: A survey\",\n        \"Deep learning with edge computing: A review\",\n        \"Deep learning on mobile devices: a review\",\n        \"Deep learning on computational-resource-limited platforms: a survey\",\n        \"Deep learning for safe autonomous driving: Current challenges and future directions\",\n        \"End to end learning for self-driving cars\",\n        \"A survey of deep learning techniques for autonomous driving\",\n        \"Deep learning in mobile and wireless networking: A survey\",\n        \"Deep learning for iot big data and streaming analytics: A survey\",\n        \"Learning iot in edge: Deep learning for the internet of things with edge computing\",\n        \"A review of deep learning methods and applications for unmanned aerial vehicles\",\n        \"Once-for-all: Train one network and specialize it for efficient deployment\",\n        \"A survey on green deep learning\",\n        \"Mobilenets: Efficient convolutional neural networks for mobile vision applications\",\n        \"Mobilenetv2: Inverted residuals and linear bottlenecks\",\n        \"Searching for mobilenetv3\",\n        \"Efficientnet: Rethinking model scaling for convolutional neural networks\",\n        \"Designing network design spaces\",\n        \"Neural architecture search with reinforcement learning\",\n        \"Darts: Differentiable architecture search\",\n        \"Dynamic neural networks: A survey\",\n        \"Multi-scale dense networks for resource efficient image classification\",\n        \"Runtime neural pruning\",\n        \"Hd-cnn: hierarchical deep convolutional neural networks for large scale visual recognition\",\n        \"Adaframe: Adaptive frame selection for fast video recognition\",\n        \"Adaptive focus for efficient video recognition\",\n        \"Latency-aware spatial-wise dynamic networks\",\n        \"You only look once: Unified, real-time object detection\",\n        \"Ssd: Single shot multibox detector\",\n        \"Fcos: Fully convolutional one-stage object detection\",\n        \"Yolov7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors\",\n        \"Bisenet: Bilateral segmentation network for real-time semantic segmentation\",\n        \"Solo: Segmenting objects by locations\",\n        \"Solov2: Dynamic and fast instance segmentation\",\n        \"Learning efficient convolutional networks through network slimming\",\n        \"The lottery ticket hypothesis: Finding sparse, trainable neural networks\",\n        \"Binaryconnect: Training deep neural networks with binary weights during propagations\",\n        \"Xnor-net: Imagenet classification using binary convolutional neural networks\",\n        \"Distilling the knowledge in a neural network\",\n        \"Knowledge distillation: A survey\",\n        \"Mnasnet: Platform-aware neural architecture search for mobile\",\n        \"Proxylessnas: Direct neural architecture search on target task and hardware\",\n        \"Fpga/dnn co-design: An efficient design methodology for iot intelligence on the edge\",\n        \"Hardware/software co-exploration of neural architectures\",\n        \"Efficient inference with tensorrt\",\n        \"Introduction to core ml framework\",\n        \"Tvm: end-to-end optimization stack for deep learning\",\n        \"Deep learning on mobile and embedded devices: State-of-the-art, challenges, and future directions\",\n        \"Aggregated residual transformations for deep neural networks\",\n        \"Res2net: A new multi-scale backbone architecture\",\n        \"Shufflenet: An extremely efficient convolutional neural network for mobile devices\",\n        \"Shufflenet v2: Practical guidelines for efficient cnn architecture design\",\n        \"Training data-efficient image transformers & distillation through attention\",\n        \"Selective kernel networks\",\n        \"Resnest: Split-attention networks\",\n        \"Interleaved group convolutions\",\n        \"Interleaved structured sparse convolutional neural networks\",\n        \"Igcv3: Interleaved low-rank group convolutions for efficient deep neural networks\",\n        \"Attention is all you need\",\n        \"Xception: Deep learning with depthwise separable convolutions\",\n        \"Espnetv2: A light-weight, power efficient, and general purpose convolutional neural network\",\n        \"A convnet for the 2020s\",\n        \"Cvt: Introducing convolutions to vision transformers\",\n        \"Cmt: Convolutional neural networks meet vision transformers\",\n        \"Batch normalization: Accelerating deep network training by reducing internal covariate shift\",\n        \"Rethinking the inception architecture for computer vision\",\n        \"Inception-v4, inception-resnet and the impact of residual connections on learning\",\n        \"Inception transformer\",\n        \"Hornet: Efficient high-order spatial interactions with recursive gated convolutions\",\n        \"Efficientnetv2: Smaller models and faster training\",\n        \"Rethinking bottleneck structure for efficient mobile network design\",\n        \"Training very deep networks\",\n        \"Densely connected convolutional networks\",\n        \"Condensenet: An efficient densenet using learned group convolutions\",\n        \"Condensenet v2: Sparse feature reactivation for deep networks\",\n        \"Ghostnets on heterogeneous devices via cheap operations\",\n        \"Ghostnet: More features from cheap operations\",\n        \"Ghostnetv2: Enhance cheap operation with long-range attention\",\n        \"Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution\",\n        \"Fast vision transformers with hilo attention\",\n        \"Deep high-resolution representation learning for human pose estimation\",\n        \"Deep high-resolution representation learning for visual recognition\",\n        \"Hrformer: High-resolution vision transformer for dense predict\",\n        \"Pyramid vision transformer: A versatile backbone for dense prediction without convolutions\",\n        \"Pvt v2: Improved baselines with pyramid vision transformer\",\n        \"Shunted self-attention via multi-scale token aggregation\",\n        \"Twins: Revisiting the design of spatial attention in vision transformers\",\n        \"Swin transformer v2: Scaling up capacity and resolution\",\n        \"Scaling local self-attention for parameter efficient visual backbones\",\n        \"Focal self-attention for local-global interactions in vision transformers\",\n        \"Cswin transformer: A general vision transformer backbone with cross-shaped windows\",\n        \"Volo: Vision outlooker for visual recognition\",\n        \"V2x-vit: Vehicle-to-everything cooperative perception with vision transformer\",\n        \"Maxvit: Multi-axis vision transformer\",\n        \"Convit: Improving vision transformers with soft convolutional inductive biases\",\n        \"Locality guidance for improving vision transformers on tiny datasets\",\n        \"Msg-transformer: Exchanging local spatial information by manipulating messenger tokens\",\n        \"Tokens-to-token vit: Training vision transformers from scratch on imagenet\",\n        \"Transformer in transformer\",\n        \"Transformers are rnns: Fast autoregressive transformers with linear attention\",\n        \"Rethinking attention with performers\",\n        \"Nyströmformer: A nyström-based algorithm for approximating self-attention\",\n        \"Soft: Softmax-free transformer with linear complexity\",\n        \"Castling-vit: Compressing self-attention via switching towards linear-angular attention during vision transformer inference\",\n        \"Efficient architecture search by network transformation\",\n        \"Flatten transformer: Vision transformer using focused linear attention\",\n        \"Co-scale conv-attentional image transformers\",\n        \"Mpvit: Multi-path vision transformer for dense prediction\",\n        \"Glance-and-gaze vision transformer\",\n        \"Incorporating convolution designs into visual transformers\",\n        \"Localvit: Bringing locality to vision transformers\",\n        \"Coatnet: Marrying convolution and attention for all data sizes\",\n        \"Early convolutions help transformers see better\",\n        \"Levit: a vision transformer in convnet’s clothing for faster inference\",\n        \"Mobilevit: Light-weight, general-purpose, and mobile-friendly vision transformer\",\n        \"Visformer: The vision-friendly transformer\",\n        \"Rethinking spatial dimensions of vision transformers\",\n        \"Vitae: Vision transformer advanced by exploring intrinsic inductive bias\",\n        \"Vitaev2: Vision transformer advanced by exploring inductive bias for image recognition and beyond\",\n        \"Mobile-former: Bridging mobilenet and transformer\",\n        \"Mixformer: Mixing features across windows and dimensions\",\n        \"Conformer: Local features coupling global representations for recognition and detection\",\n        \"Conformer: Local features coupling global representations for visual recognition\",\n        \"On network design spaces for visual recognition\",\n        \"Fast and accurate model scaling\",\n        \"Model rubik’s cube: Twisting resolution, depth and width for tinynets\",\n        \"Designing neural network architectures using reinforcement learning\",\n        \"Learning transferable architectures for scalable image recognition\",\n        \"Large-scale evolution of image classifiers\",\n        \"Genetic cnn\",\n        \"Regularized evolution for image classifier architecture search\",\n        \"Simple and efficient architecture search for convolutional neural networks\",\n        \"Path-level network transformation for efficient architecture search\",\n        \"Hierarchical representations for efficient architecture search\",\n        \"Efficient neural architecture search via parameters sharing\",\n        \"Understanding and simplifying one-shot architecture search\",\n        \"Snas: stochastic neural architecture search\",\n        \"Searching for a robust neural architecture in four gpu hours\",\n        \"Understanding and robustifying differentiable architecture search\",\n        \"Network adjustment: Channel and block search guided by resource utilization ratio\",\n        \"Progressive differentiable architecture search: Bridging the depth gap between search and evaluation\",\n        \"Greedynas: Towards fast one-shot nas with greedy supernet\",\n        \"Smash: One-shot model architecture search through hypernetworks\",\n        \"Graph hypernetworks for neural architecture search\",\n        \"Single path one-shot neural architecture search with uniform sampling\",\n        \"Bignas: Scaling up neural architecture search with big single-stage models\",\n        \"Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search\",\n        \"Learning spatiotemporal features with 3d convolutional networks\",\n        \"Quo vadis, action recognition? a new model and the kinetics dataset\",\n        \"Eco: Efficient convolutional network for online video understanding\",\n        \"Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification\",\n        \"Video classification with channel-separated convolutional networks\",\n        \"X3d: Expanding architectures for efficient video recognition\",\n        \"A closer look at spatiotemporal convolutions for action recognition\",\n        \"Human action recognition using factorized spatio-temporal convolutional networks\",\n        \"Learning spatio-temporal representation with pseudo-3d residual networks\",\n        \"Tam: Temporal adaptive module for video recognition\",\n        \"Temporal relational reasoning in videos\",\n        \"Stm: Spatiotemporal and motion encoding for action recognition\",\n        \"Tea: Temporal excitation and aggregation for action recognition\",\n        \"Tsm: Temporal shift module for efficient video understanding\",\n        \"Token shift transformer for video classification\",\n        \"Gate-shift networks for video action recognition\",\n        \"Slowfast networks for video recognition\",\n        \"Tdn: Temporal difference networks for efficient action recognition\",\n        \"Vivit: A video vision transformer\",\n        \"Space-time mixing attention for video transformer\",\n        \"Video swin transformer\",\n        \"Uniformer: Unified transformer for efficient spatial-temporal representation learning\",\n        \"Multiview transformers for video recognition\",\n        \"Keeping your eye on the ball: Trajectory attention in video transformers\",\n        \"Is space-time attention all you need for video understanding?\",\n        \"Video transformer network\",\n        \"Pointnet: Deep learning on point sets for 3d classification and segmentation\",\n        \"Pointnet++: Deep hierarchical feature learning on point sets in a metric space\",\n        \"Graph attention convolution for point cloud semantic segmentation\",\n        \"Dynamic graph cnn for learning on point clouds\",\n        \"Spidercnn: Deep learning on point sets with parameterized convolutional filters\",\n        \"Tangent convolutions for dense prediction in 3d\",\n        \"Kpconv: Flexible and deformable convolution for point clouds\",\n        \"Pointcnn: Convolution on x-transformed points\",\n        \"Relation-shape convolutional neural network for point cloud analysis\",\n        \"Pointconv: Deep convolutional networks on 3d point clouds\",\n        \"A closer look at local aggregation operators in point cloud analysis\",\n        \"Stratified transformer for 3d point cloud segmentation\",\n        \"Point transformer\",\n        \"Pointnext: Revisiting pointnet++ with improved training and scaling strategies\",\n        \"Voxnet: A 3d convolutional neural network for real-time object recognition\",\n        \"3d semantic segmentation with submanifold sparse convolutional networks\",\n        \"4d spatio-temporal convnets: Minkowski convolutional neural networks\",\n        \"Focal sparse convolutional networks for 3d object detection\",\n        \"Pv-rcnn: Point-voxel feature set abstraction for 3d object detection\",\n        \"Pv-rcnn++: Point-voxel feature set abstraction with local vector representation for 3d object detection\",\n        \"Class-balanced grouping and sampling for point cloud 3d object detection\",\n        \"Point-voxel cnn for efficient 3d deep learning\",\n        \"Searching efficient 3d architectures with sparse point-voxel convolution\",\n        \"Multi-view convolutional neural networks for 3d shape recognition\",\n        \"View-gcn: View-based graph convolutional network for 3d shape analysis\",\n        \"Mvtn: Multi-view transformation network for 3d shape recognition\",\n        \"Gift: A real-time and scalable 3d shape search engine\",\n        \"Mlvcnn: Multi-loop-view convolutional neural network for 3d shape retrieval\",\n        \"Rotationnet: Joint object categorization and pose estimation using multiviews from unsupervised viewpoints\",\n        \"Branchynet: Fast inference via early exiting from deep neural networks\",\n        \"Adaptive neural networks for efficient inference\",\n        \"Resolution adaptive networks for efficient inference\",\n        \"Not all images are worth 16x16 words: Dynamic transformers for efficient image recognition\",\n        \"Dynamic perceiver for efficient visual recognition\",\n        \"Improved techniques for training adaptive deep networks\",\n        \"Learning to weight samples for dynamic early-exiting networks\",\n        \"Skipnet: Learning dynamic routing in convolutional networks\",\n        \"Convolutional networks with adaptive inference graphs\",\n        \"Adavit: Adaptive vision transformers for efficient image recognition\",\n        \"Batch-shaping for learning conditional channel gated networks\",\n        \"Channel selection using gumbel softmax\",\n        \"Dynamic slimmable network\",\n        \"Adaptive neural trees\",\n        \"The tree ensemble layer: Differentiability meets conditional computation\",\n        \"Condconv: Conditionally parameterized convolutions for efficient inference\",\n        \"Adaptive rotated convolution for rotated object detection\",\n        \"Instanas: Instance-aware neural architecture search\",\n        \"Learning dynamic routing for semantic segmentation\",\n        \"Learning deep features for discriminative localization\",\n        \"More is less: A more complicated network with less inference complexity\",\n        \"Dynamic convolutions: Exploiting spatial sparsity for faster inference\",\n        \"Spatially adaptive inference with stochastic feature sampling and interpolation\",\n        \"Spatially adaptive feature refinement for efficient inference\",\n        \"Deformable convolutional networks\",\n        \"Deformable convnets v2: More deformable, better results\",\n        \"Internimage: Exploring large-scale vision foundation models with deformable convolutions\",\n        \"Vision transformer with deformable attention\",\n        \"Recurrent models of visual attention\",\n        \"Dynamic computational time for visual attention\",\n        \"Look closer to see better: Recurrent attention convolutional neural network for fine-grained image recognition\",\n        \"Glance and focus: a dynamic approach to reducing spatial redundancy in image classification\",\n        \"Glance and focus networks for dynamic visual recognition\",\n        \"Reinforcement learning: A survey\",\n        \"Scale-aware face detection\",\n        \"Dynamic resolution network\",\n        \"Liteeval: A coarse-to-fine framework for resource efficient video recognition\",\n        \"Long short-term memory\",\n        \"Adafuse: Adaptive temporal fusion network for efficient action recognition\",\n        \"Dynamic network quantization for efficient video inference\",\n        \"Ar-net: Adaptive frame resolution for efficient action recognition\",\n        \"End-to-end learning of action detection from frame glimpses in videos\",\n        \"Action search: Spotting actions in videos and its application to temporal action localization\",\n        \"Watching a small portion could be as good as watching all: Towards efficient video classification\",\n        \"Dynamic inference: A new approach toward efficient video action recognition\",\n        \"Frameexit: Conditional early exiting for efficient video recognition\",\n        \"Deep progressive reinforcement learning for skeleton-based action recognition\",\n        \"Multi-agent reinforcement learning based frame sampling for effective untrimmed video recognition\",\n        \"Dynamic sampling networks for efficient action recognition in videos\",\n        \"Adafocus v2: End-to-end training of spatial dynamic networks for video recognition\",\n        \"Adafocusv3: On unified spatial-temporal dynamic video recognition\",\n        \"Dynamic spatial focus for efficient compressed video action recognition\",\n        \"2d or not 2d? adaptive 3d convolution selection for efficient video recognition\",\n        \"Rich feature hierarchies for accurate object detection and semantic segmentation\",\n        \"Region-based convolutional networks for accurate object detection and segmentation\",\n        \"Spatial pyramid pooling in deep convolutional networks for visual recognition\",\n        \"Fast r-cnn\",\n        \"Faster r-cnn: Towards real-time object detection with region proposal networks\",\n        \"R-fcn: Object detection via region-based fully convolutional networks\",\n        \"Light-head r-cnn: In defense of two-stage object detector\",\n        \"Feature pyramid networks for object detection\",\n        \"Yolov3: An incremental improvement\",\n        \"Yolov4: Optimal speed and accuracy of object detection\",\n        \"Yolo9000: better, faster, stronger\",\n        \"You only learn one representation: Unified network for multiple tasks\",\n        \"Focal loss for dense object detection\",\n        \"Cornernet: Detecting objects as paired keypoints\",\n        \"Bottom-up object detection by grouping extreme and center points\",\n        \"Objects as points\",\n        \"End-to-end object detection with transformers\",\n        \"Deformable detr: Deformable transformers for end-to-end object detection\",\n        \"On efficient real-time semantic segmentation: a survey\",\n        \"Pyramid scene parsing network\",\n        \"Segnet: A deep convolutional encoder-decoder architecture for image segmentation\",\n        \"Enet: A deep neural network architecture for real-time semantic segmentation\",\n        \"Linknet: Exploiting encoder representations for efficient semantic segmentation\",\n        \"Espnet: Efficient spatial pyramid of dilated convolutions for semantic segmentation\",\n        \"Segnext: Rethinking convolutional attention design for semantic segmentation\",\n        \"Erfnet: Efficient residual factorized convnet for real-time semantic segmentation\",\n        \"Dabnet: Depth-wise asymmetric bottleneck for real-time semantic segmentation\",\n        \"Efficient dense modules of asymmetric convolution for real-time semantic segmentation\",\n        \"Efficient ladder-style densenets for semantic segmentation of large images\",\n        \"Encoder-decoder with atrous separable convolution for semantic image segmentation\",\n        \"Fast-scnn: Fast semantic segmentation network\",\n        \"Shelfnet for fast semantic segmentation\",\n        \"Contextnet: Exploring context and detail for semantic segmentation in real-time\",\n        \"Bisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation\",\n        \"Rethinking bisenet for real-time semantic segmentation\",\n        \"Icnet for real-time semantic segmentation on high-resolution images\",\n        \"Lednet: A lightweight encoder-decoder network for real-time semantic segmentation\",\n        \"Dfanet: Deep feature aggregation for real-time semantic segmentation\",\n        \"Real-time semantic segmentation with fast attention\",\n        \"Squeezenas: Fast neural architecture search for faster semantic segmentation\",\n        \"Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation\",\n        \"Fasterseg: Searching for faster real-time semantic segmentation\",\n        \"Per-pixel classification is not all you need for semantic segmentation\",\n        \"Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers\",\n        \"Segformer: Simple and efficient design for semantic segmentation with transformers\",\n        \"Semantic segmentation by early region proxy\",\n        \"Masked-attention mask transformer for universal image segmentation\",\n        \"A survey on instance segmentation: Recent advances and challenges\",\n        \"Mask r-cnn\",\n        \"Masklab: Instance segmentation by refining object detection with semantic and direction features\",\n        \"Mask scoring r-cnn\",\n        \"Path aggregation network for instance segmentation\",\n        \"Hybrid task cascade for instance segmentation\",\n        \"Yolact: Real-time instance segmentation\",\n        \"Blendmask: Top-down meets bottom-up for instance segmentation\",\n        \"Tensormask: A foundation for dense object segmentation\",\n        \"Smart, secure, yet energy-efficient, internet-of-things sensors\",\n        \"A survey on deep neural network compression: Challenges, overview, and solutions\",\n        \"A survey of model compression and acceleration for deep neural networks\",\n        \"Convolutional neural network pruning: A survey\",\n        \"Pruning and quantization for deep neural network acceleration: A survey\",\n        \"A survey of quantization methods for efficient neural network inference\",\n        \"Exploiting linear structure within convolutional networks for efficient evaluation\",\n        \"Speeding up convolutional neural networks with low rank expansions\",\n        \"Fitnets: Hints for thin deep nets\",\n        \"Correlation congruence for knowledge distillation\",\n        \"Weight sharing and deep learning for spectral data\",\n        \"Pvanet: Deep but lightweight neural networks for real-time object detection\",\n        \"Channel pruning for accelerating very deep neural networks\",\n        \"Variational convolutional neural network pruning\",\n        \"Thinet: A filter level pruning method for deep neural network compression\",\n        \"Deepmon: Mobile gpu-based deep learning framework for continuous vision applications\",\n        \"Eie: Efficient inference engine on compressed deep neural network\",\n        \"Bayesian compression for deep learning\",\n        \"Scnn: An accelerator for compressed-sparse convolutional neural networks\",\n        \"Multi-task zipping via layer-wise neuron sharing\",\n        \"Deep learning with limited numerical precision\",\n        \"Hardware-oriented approximation of convolutional neural networks\",\n        \"Sparse, quantized, full frame cnn for low power embedded devices\",\n        \"Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1\",\n        \"Compressing deep convolutional networks using vector quantization\",\n        \"Quantized convolutional neural networks for mobile devices\",\n        \"Compressing neural networks with the hashing trick\",\n        \"Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding\",\n        \"Learning efficient object detection models with knowledge distillation\",\n        \"Fast human pose estimation\",\n        \"Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer\",\n        \"Learning to specialize with knowledge distillation for visual question answering\",\n        \"Paraphrasing complex network: Network compression via factor transfer\",\n        \"Knowledge distillation via route constrained optimization\",\n        \"Feature normalized knowledge distillation for image classification\",\n        \"Exclusivity-consistency regularized knowledge distillation for face recognition\",\n        \"Towards learning spatially discriminative feature representations\",\n        \"Learn from the past: Experience ensemble knowledge distillation\",\n        \"A gift from knowledge distillation: Fast optimization, network minimization and transfer learning\",\n        \"Self-supervised knowledge distillation using singular value decomposition\",\n        \"Heterogeneous knowledge distillation using information flow modeling\",\n        \"Knowledge distillation via instance relationship graph\",\n        \"Similarity-preserving knowledge distillation\",\n        \"Relational knowledge distillation\",\n        \"Deep mutual learning\",\n        \"Knowledge distillation by on-the-fly native ensemble\",\n        \"Online knowledge distillation via collaborative learning\",\n        \"Online ensemble model compression using knowledge distillation\",\n        \"Online knowledge distillation with diverse peers\",\n        \"Be your own teacher: Improve the performance of convolutional neural networks via self distillation\",\n        \"Learning lightweight lane detection cnns by self attention distillation\",\n        \"Snapshot distillation: Teacher-student optimization in one generation\",\n        \"Few-shot image recognition with knowledge transfer\",\n        \"Efficient knowledge distillation from model checkpoints\",\n        \"Tc3kd: Knowledge distillation via teacher-student cooperative curriculum customization\",\n        \"Triplet distillation for deep face recognition\",\n        \"Modality distillation with multiple stream networks for action recognition\",\n        \"D3d: Distilled 3d networks for video action recognition\",\n        \"Relation distillation networks for video object detection\",\n        \"General instance distillation for object detection\",\n        \"Structured knowledge distillation for semantic segmentation\",\n        \"Geometry-aware distillation for indoor semantic segmentation\",\n        \"Intra-class feature variation distillation for semantic segmentation\",\n        \"Inter-region affinity distillation for road marking segmentation\",\n        \"Learning monocular depth by distilling cross-domain stereo networks\",\n        \"Pad-net: Multi-tasks guided prediction-and-distillation network for simultaneous depth estimation and scene parsing\",\n        \"Learning monocular depth estimation infusing traditional stereo knowledge\",\n        \"Refine and distill: Exploiting cycle-inconsistency and knowledge distillation for unsupervised monocular depth estimation\",\n        \"Depth distillation: unsupervised metric depth estimation for uavs by finding consensus between kinematics, optical flow and deep learning\",\n        \"Knowledge distillation for fast and accurate monocular depth estimation on mobile devices\",\n        \"Feature estimations based correlation distillation for incremental image retrieval\",\n        \"Deep hash distillation for image retrieval\",\n        \"Object relational graph with teacher-recommended learning for video captioning\",\n        \"Spatio-temporal graph for video captioning with knowledge distillation\",\n        \"Revisiting knowledge distillation for image captioning\",\n        \"Better and faster: Knowledge transfer from multiple self-supervised learning tasks via graph distillation for video classification\",\n        \"Efficient video classification using fewer frames\",\n        \"Revisit knowledge distillation: a teacher-free framework\",\n        \"Understanding and improving knowledge distillation\",\n        \"Explaining knowledge distillation by quantifying the knowledge\",\n        \"Speeding-up convolutional neural networks using fine-tuned cp-decomposition\",\n        \"Convolutional neural networks with low-rank regularization\",\n        \"Predicting parameters in deep learning\",\n        \"A tucker deep computation model for mobile multimedia feature learning\",\n        \"Fully-adaptive feature sharing in multi-task networks with applications in person attribute classification\",\n        \"Low-rank matrix factorization for deep neural network training with high-dimensional output targets\",\n        \"Clip-q: Deep network compression learning by in-parallel pruning-quantization\",\n        \"Model compression via distillation and quantization\",\n        \"Fbnetv2: Differentiable neural architecture search for spatial and channel dimensions\",\n        \"Neural architecture search survey: A hardware perspective\",\n        \"Mcunet: Tiny deep learning on iot devices\",\n        \"Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning\",\n        \"Roofline: an insightful visual performance model for multicore architectures\",\n        \"Cnvlutin: Ineffectual-neuron-free deep neural network computing\",\n        \"An efficient hardware accelerator for sparse convolutional neural networks on fpgas\",\n        \"When neural architecture search meets hardware implementation: from hardware awareness to co-design\",\n        \"Standing on the shoulders of giants: Hardware and neural architecture co-search with hot start\",\n        \"Best of both worlds: Automl codesign of a cnn and its hardware accelerator\",\n        \"Mcunetv2: Memory-efficient patch-based inference for tiny deep learning\",\n        \"On-device training under 256kb memory\",\n        \"Boosting the performance of cnn accelerators with dynamic fine-grained channel gating\",\n        \"Drq: dynamic region-based quantization for deep neural network acceleration\",\n        \"Processor architecture optimization for spatially dynamic neural networks\",\n        \"Energon: Toward efficient acceleration of transformers using dynamic sparse attention\",\n        \"Image as set of points\",\n        \"Sequencer: Deep LSTM for image classification\",\n        \"Vision GNN: An image is worth graph of nodes\",\n        \"Image as a foreign language: Beit pretraining for all vision and vision-language tasks\",\n        \"Florence: A new foundation model for computer vision\",\n        \"Nas-fpn: Learning scalable feature pyramid architecture for object detection\",\n        \"A unified sequence interface for vision tasks\",\n        \"Deep learning in spiking neural networks\",\n        \"Momentum contrast for unsupervised visual representation learning\",\n        \"Masked autoencoders are scalable vision learners\",\n        \"Revisiting locally supervised learning: an alternative to end-to-end training\",\n        \"Automated progressive learning for efficient training of vision transformers\",\n        \"Deep incubation: Training large models by divide-and-conquering\",\n        \"Efficienttrain: Exploring generalized curriculum learning for training visual backbones\"\n    ],\n    \"reasoning\": \"Selected these 441 references because they represent foundational work and recent advances in Computation-efficient Deep Learning for Computer Vision: A Survey, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}