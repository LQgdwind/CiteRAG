{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 59 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Assessing Safety-Critical Systems from Operational Testing: A Study on Autonomous Vehicles\n\nPaper Abstract: Abstract Context: Demonstrating high reliability and safety for safety-critical systems (SCSs) remains a hard problem. Diverse evidence needs to be combined in a rigorous way: in particular, results of operational testing with other evidence from design and verification. Growing use of machine learning in SCSs, by precluding most established methods for gaining assurance, makes evidence from operational testing even more important for supporting safety and reliability claims. Objective: We revisit the problem of using operational testing to demonstrate high reliability. We use Autonomous Vehicles (AVs) as a current example. AVs are making their debut on public roads: methods for assessing whether an AV is safe enough are urgently needed. We demonstrate how to answer 5 questions that would arise in assessing an AV type, starting with those proposed by a highly-cited study. Method: We apply new theorems extending our Conservative Bayesian Inference (CBI) approach, which exploit the rigour of Bayesian methods while reducing the risk of involuntary misuse associated (we argue) with now-common applications of Bayesian inference; we define additional conditions needed for applying these methods to AVs. Results: Prior knowledge can bring substantial advantages if the AV design allows strong expectations of safety before road testing. We also show how naive attempts at conservative assessment may lead to over-optimism instead; why extrapolating the trend of disengagements (take-overs by human drivers) is not suitable for safety claims; use of knowledge that an AV has moved to a “less stressful” environment. Conclusion: While some reliability targets will remain too high to be practically verifiable, our CBI approach removes a major source of doubt: it allows use of prior knowledge without inducing dangerously optimistic biases. For certain ranges of required reliability and prior beliefs, CBI thus supports feasible, sound arguments. Useful conservative claims can be derived from limited prior knowledge.\n\n{retrieved_text}\n\nGenerate exactly 59 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 59\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Validation of ultra-high dependability for software-based systems\",\n        \"The infeasibility of quantifying the reliability of life-critical real-time software\",\n        \"Disruptive innovations and disruptive assurance: Assuring machine learning and autonomy\",\n        \"Considerations in assuring safety of increasingly autonomous systems\",\n        \"Mind the gaps: Assuring the safety of autonomous systems from an engineering, ethical, and legal perspective\",\n        \"Hands off: The future of self-driving cars\",\n        \"Hands off the wheel in autonomous vehicles?: A systems perspective on over a million miles of field data\",\n        \"Driving to safety: How many miles of driving would it take to demonstrate autonomous vehicle reliability?\",\n        \"Autonomous vehicles’ disengagements: Trends, triggers, and regulatory limitations\",\n        \"Autonomous vehicles: Disengagements, accidents and reaction times\",\n        \"Analysis of autopilot disengagements occurring during autonomous vehicle testing\",\n        \"Autonomous vehicle technology: A guide for policymakers\",\n        \"Safety first for automated driving\",\n        \"Waymo safety report: On the road to fully self-driving\",\n        \"A plan to develop safe autonomous vehicles. And prove it\",\n        \"DeepTest: Automated testing of deep-neural-network-driven autonomous cars\",\n        \"Safety verification of deep neural networks\",\n        \"Verifying autonomous systems\",\n        \"Verifiable self-certifying autonomous systems\",\n        \"Credible autonomy safety argumentation\",\n        \"Assessing the Safety and Reliability of Autonomous Vehicles from Road Testing\",\n        \"Toward a formalism for conservative claims about the dependability of software-based systems\",\n        \"Software fault-freeness and reliability predictions\",\n        \"Modeling the probability of failure on demand (pfd) of a 1-out-of-2 system in which one channel is “quasi-perfect”\",\n        \"Conservative claims about the probability of perfection of software-based systems\",\n        \"Conservative claims for the probability of perfection of a software-based system using operational experience of previous similar systems\",\n        \"Exponential order statistic models of software reliability growth\",\n        \"IEC61508, Functional Safety of Electrical/ Electronic/Programmable Electronic Safety Related Systems\",\n        \"EN 50129:2018: Railway applications - Communication, signalling and processing systems - Safety related electronic systems for signalling\",\n        \"Handbook of parameter estimation for probabilistic risk assessment\",\n        \"Guidelines for Statistical Testing\",\n        \"Reliability estimation from appropriate testing of plant protection software\",\n        \"Bayesian nonparametric system reliability using sets of priors\",\n        \"Deriving a frequentist conservative confidence bound for probability of failure per demand for systems with different operational and test profiles\",\n        \"Imprecise probabilistic inference for software run reliability growth models.\",\n        \"Assessing asymmetric fault-tolerant software\",\n        \"Examining accident reports involving autonomous vehicles in California\",\n        \"How safe is safe enough for self-driving vehicles?\",\n        \"Assessing the risk due to software faults: Estimates of failure rate vs evidence of perfection\",\n        \"Reasoning about the reliability of diverse two-channel systems in which one channel is ‘possibly perfect’\",\n        \"Could Fisher, Jeffreys and Neyman have agreed on testing?\",\n        \"Bounds on survival probability given mean probability of failure per demand; and the paradoxical advantages of uncertainty\",\n        \"Techniques for prediction analysis and recalibration\",\n        \"Recalibrating software reliability models\",\n        \"Safety argument considerations for public road testing of autonomous vehicles\",\n        \"Systems with human monitors: A signal detection analysis\",\n        \"Human-Machine diversity in the use of computerised advisory systems: A case study\",\n        \"On reliability assessment when a software-based system is replaced by a thought-to-be-better one\",\n        \"Verification and repair of control policies for safe reinforcement learning\",\n        \"Probabilistic model checking of robots deployed in extreme environments\",\n        \"A safety framework for critical systems utilising deep neural networks\",\n        \"Autonomous vehicle safety: An interdisciplinary challenge\",\n        \"Bayesian framework for reliability assurance of a deployed safety critical system\",\n        \"Software reliability corroboration\",\n        \"The increasing risks of risk assessment: On the rise of artificial intelligence and non-determinism in safety-critical systems\",\n        \"‘Validation of ultra-high dependability…’ – 20 years on\",\n        \"On testing process control software for reliability assessment: the effects of correlation between successive failures\",\n        \"Failure correlation in software reliability models\",\n        \"Modeling correlation in software recovery blocks\"\n    ],\n    \"reasoning\": \"Selected these 59 references because they represent foundational work and recent advances in Assessing Safety-Critical Systems from Operational Testing: A Study on Autonomous Vehicles, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}