{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 53 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Towards Homogeneous Modality Learning and Multi-Granularity Information Exploration for Visible-Infrared Person Re-Identification\n\nPaper Abstract: Abstract Visible-infrared person re-identification (VI-ReID) is a challenging and essential task, which aims to retrieve a set of person images over visible and infrared camera views. In order to mitigate the impact of large modality discrepancy existing in heterogeneous images, previous methods attempt to apply generative adversarial network (GAN) to generate the modality-consisitent data. However, due to severe color variations between the visible domain and infrared domain, the generated fake cross-modality samples often fail to possess good qualities to fill the modality gap between synthesized scenarios and target real ones, which leads to sub-optimal feature representations. In this work, we address cross-modality matching problem with Aligned Grayscale Modality (AGM), an unified dark-line spectrum that reformulates visible-infrared dual-mode learning as a gray-gray single-mode learning problem. Specifically, we generate the grasycale modality from the homogeneous visible images. Then, we train a style tranfer model to transfer infrared images into homogeneous grayscale images. In this way, the modality discrepancy is significantly reduced in the image space. In order to reduce the remaining appearance discrepancy, we further introduce a multi-granularity feature extraction network to conduct feature-level alignment. Rather than relying on the global information, we propose to exploit local (head-shoulder) features to assist person Re-ID, which complements each other to form a stronger feature descriptor. Comprehensive experiments implemented on the mainstream evaluation datasets include SYSU-MM01 and RegDB indicate that our method can significantly boost cross-modality retrieval performance against the state of the art methods.\n\n{retrieved_text}\n\nGenerate exactly 53 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 53\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Neural feature search for rgb-infrared person re-identification\",\n        \"Cross-modality person re-identification with generative adversarial training.\",\n        \"Spherereid: Deep hypersphere manifold embedding for person re-identification\",\n        \"Llm: Learning cross-modality person re-identification via low-rank local matching\",\n        \"Learning modality-specific representations for visible-infrared person re-identification\",\n        \"Generative adversarial nets\",\n        \"Cross-modality person re-identification via modality confusion and center aggregation\",\n        \"In defense of the triplet loss for person re-identification\",\n        \"A survey of open-world person re-identification\",\n        \"Infrared-visible cross-modal person re-identification with an x modality\",\n        \"Multi-pose learning based head-shoulder re-identification\",\n        \"The casia nir-vis 2.0 face database\",\n        \"Illumination invariant face recognition using near-infrared images\",\n        \"Collaborative attention network for person re-identification\",\n        \"Improving person re-identification by attribute and identity learning\",\n        \"A multi-constraint similarity learning with adaptive weighting for visible-thermal person re-identification\",\n        \"Parameter sharing exploration and hetero-center triplet loss for visible-thermal person re-identification\",\n        \"Domain adaptation with structural knowledge transfer learning for person re-identification\",\n        \"Sfanet: A spectrum-aware feature augmentation network for visible-infrared person reidentification\",\n        \"Pose transferrable person re-identification\",\n        \"Cross-modality person re-identification with shared-specific feature transfer\",\n        \"Spectral feature transformation for person re-identification\",\n        \"Pose-guided feature alignment for occluded person re-identification\",\n        \"Person recognition system based on a combination of body images from visible light and thermal cameras\",\n        \"Facenet: A unified embedding for face recognition and clustering\",\n        \"Learning part-based convolutional features for person re-identification\",\n        \"Farewell to mutual information: Variational distillation for cross-modal person re-identification\",\n        \"Gated siamese convolutional neural network architecture for human re-identification\",\n        \"Cross-modality paired-images generation and augmentation for rgb-infrared person re-identification\",\n        \"Rgb-infrared cross-modality person re-identification via joint pixel and feature alignment\",\n        \"Learning discriminative features with multiple granularities for person re-identification\",\n        \"Learning to reduce dual-level discrepancy for infrared-visible person re-identification\",\n        \"Flexible body partition-based adversarial learning for visible infrared person re-identification\",\n        \"Rgb-infrared cross-modality person re-identification\",\n        \"Discover cross-modality nuances for visible-infrared person re-identification\",\n        \"Visible-infrared person re-identification with data augmentation via cycle-consistent adversarial network\",\n        \"Cross-modality person re-identification via modality-aware collaborative ensemble learning\",\n        \"Hierarchical discriminative learning for visible thermal person re-identification\",\n        \"Bi-directional center-constrained top-ranking for visible thermal person re-identification\",\n        \"Channel augmented joint learning for visible-infrared recognition\",\n        \"Dynamic dual-attentive aggregation learning for visible-infrared person re-identification\",\n        \"Deep learning for person re-identification: A survey and outlook\",\n        \"Visible-infrared person re-identification via homogeneous augmented tri-modal learning\",\n        \"Visible thermal person re-identification via dual-constrained top-ranking\",\n        \"Global-local multiple granularity learning for cross-modality visible-infrared person reidentification\",\n        \"Towards a unified middle modality learning for visible-infrared person re-identification\",\n        \"Relation-aware global attention for person re-identification\",\n        \"Person re-identification: Past, present and future\",\n        \"Grayscale enhancement colorization network for visible-infrared person re-identification\",\n        \"Visible-infrared person re-identification via colorization-based siamese generative adversarial network\",\n        \"Unpaired image-to-image translation using cycle-consistent adversarial networks\",\n        \"Viewpoint-aware loss with angular regularization for person re-identification\",\n        \"Syncretic modality collaborative learning for visible infrared person re-identification\"\n    ],\n    \"reasoning\": \"Selected these 53 references because they represent foundational work and recent advances in Towards Homogeneous Modality Learning and Multi-Granularity Information Exploration for Visible-Infrared Person Re-Identification, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}