{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 52 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Saliency-Based diversity and fairness Metric and FaceKeepOriginalAugment: A Novel Approach for Enhancing Fairness and Diversity\n\nPaper Abstract: Abstract Data augmentation has become a pivotal tool in enhancing the performance of computer vision tasks, with the KeepOriginalAugment method emerging as a standout technique for its intelligent incorporation of salient regions within less prominent areas, enabling augmentation in both regions. Despite its success in image classification, its potential in addressing biases remains unexplored. In this study, we introduce an extension of the KeepOriginalAugment method, termed FaceKeepOriginalAugment, which explores various debiasing aspects—geographical, gender, and stereotypical biases—in computer vision models. By maintaining a delicate balance between data diversity and information preservation, our approach empowers models to exploit both diverse salient and non-salient regions, thereby fostering increased diversity and debiasing effects. We investigate multiple strategies for determining the placement of the salient region and swapping perspectives to decide which part undergoes augmentation. Leveraging the Image Similarity Score (ISS), we quantify dataset diversity across a range of datasets, including Flickr Faces HQ (FFHQ), WIKI, IMDB, Labelled Faces in the Wild (LFW), UTK Faces, and Diverse Dataset. We evaluate the effectiveness of FaceKeepOriginalAugment in mitigating gender bias across CEO, Engineer, Nurse, and School Teacher datasets, utilizing the Image-Image Association Score (IIAS) in convolutional neural networks (CNNs) and vision transformers (ViTs). Our findings shows the efficacy of FaceKeepOriginalAugment in promoting fairness and inclusivity within computer vision models, demonstrated by reduced gender bias and enhanced overall fairness. Additionally, we introduce a novel metric, Saliency-Based Diversity and Fairness Metric, which quantifies both diversity and fairness while handling data imbalance across various datasets.\n\n{retrieved_text}\n\nGenerate exactly 52 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 52\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Random data augmentation based enhancement: a generalized enhancement approach for medical datasets\",\n        \"Class specific autoencoders enhance sample diversity\",\n        \"Multimodal datasets: misogyny, pornography, and malignant stereotypes\",\n        \"Gender shades: Intersectional accuracy disparities in commercial gender classification\",\n        \"Precise single-stage detector. arxiv 2022.\",\n        \"Audd: audio urdu digits dataset for automatic audio urdu digit recognition\",\n        \"Gridmask data augmentation\",\n        \"Salfmix: a novel single image-based data augmentation technique using a saliency map\",\n        \"Randaugment: Practical automated data augmentation with a reduced search space\",\n        \"Towards a holistic view of bias in machine learning: bridging algorithmic fairness and imbalanced learning\",\n        \"Improved regularization of convolutional neural networks with cutout\",\n        \"Keepaugment: A simple information-preserving data augmentation approach\",\n        \"Fairface: Face attribute dataset for balanced race, gender, and age for bias measurement and mitigation\",\n        \"Nvlabs/ffhq-dataset\",\n        \"Sql and nosql database software architecture performance analysis and assessments—a systematic literature review\",\n        \"Introducing urdu digits dataset with demonstration of an efficient and robust noisy decoder-based pseudo example generator\",\n        \"Biaswap: Removing dataset bias with bias-tailored swapping augmentation\",\n        \"Navigating complexity: A tailored question-answering approach for pdfs in finance, bio-medicine, and science\",\n        \"Image data augmentation approaches: A comprehensive survey and future directions\",\n        \"Keeporiginalaugment: Single image-based better information-preserving data augmentation approach\",\n        \"Advanced data augmentation approaches: A comprehensive survey and future directions\",\n        \"Intra-class random erasing (icre) augmentation for audio classification\",\n        \"Audrandaug: Random image augmentations for audio classification\",\n        \"Forged character detection datasets: Passports, driving licences and visa stickers\",\n        \"Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy\",\n        \"Labeled faces in the wild: A survey\",\n        \"Learning debiased representation via disentangled feature augmentation\",\n        \"Dataset diversity: measuring and mitigating geographical bias in image search and retrieval\",\n        \"Biased attention: Do vision transformers amplify gender bias more than convolutional neural networks?\",\n        \"Multimodal composite association score: Measuring gender bias in generative multimodal models\",\n        \"Gender bias in multimodal models: A transnational feminist approach considering geographical region and culture\",\n        \"Human detection using a mobile platform and novel features derived from a visual saliency mechanism\",\n        \"Search for optimal data augmentation policy for environmental sound classification with deep neural networks\",\n        \"Oxml challenge 2023: Carcinoma classification using data augmentation\",\n        \"Understanding eeg signals for subject-wise definition of armoni activities\",\n        \"Me-ccnn: Multi-encoded images and a cascade convolutional neural network for breast tumor segmentation and recognition\",\n        \"Dex: Deep expectation of apparent age from a single image\",\n        \"A computer vision-based object localization model for endangered wildlife detection\",\n        \"Wildect-yolo: An efficient and robust computer vision-based accurate object localization model for automated endangered wildlife detection\",\n        \"Very deep convolutional networks for large-scale image recognition\",\n        \"Deep learning-based cost-effective and responsive robot for autism treatment\",\n        \"Efficient paddy grain quality assessment approach utilizing affordable sensors\",\n        \"Hide-and-seek: A data augmentation technique for weakly-supervised localization and beyond\",\n        \"Understanding and mitigating bias in imaging artificial intelligence\",\n        \"Investigating multi-feature selection and ensembling for audio classification. arxiv 2022.\",\n        \"Investigating multi-feature selection and ensembling for audio classification\",\n        \"Saliencymix: A saliency guided data augmentation strategy for better regularization\",\n        \"Cardiacnet: A neural networks based heartbeat classifications using ecg signals\",\n        \"Towards accuracy-fairness paradox: Adversarial example-based data augmentation for visual debiasing\",\n        \"Age progression/regression by conditional adversarial autoencoder\",\n        \"Position: Measure dataset diversity, don’t just claim it\",\n        \"Random erasing data augmentation\"\n    ],\n    \"reasoning\": \"Selected these 52 references because they represent foundational work and recent advances in Saliency-Based diversity and fairness Metric and FaceKeepOriginalAugment: A Novel Approach for Enhancing Fairness and Diversity, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}