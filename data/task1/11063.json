{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 51 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: An upper bound of the mutation probability in the genetic algorithm for general 0-1 knapsack problem\n\nPaper Abstract: Abstract As an important part of genetic algorithms (GAs), mutation operators is widely used in evolutionary algorithms to solve ùí©‚Äãùí´ùí©ùí´\\mathcal{NP}-hard problems because it can increase the population diversity of individual. Due to limitations in mathematical tools, the mutation probability of the mutation operator is primarily empirically set in practical applications. In this paper, we propose a novel reduction method for the 0-1 knapsack problem(0-1 KP) and an improved mutation operator (IMO) based on the assumption ùí©‚Äãùí´‚â†ùí´ùí©ùí´ùí´\\mathcal{NP}\\neq\\mathcal{P}, along with the utilization of linear relaxation techniques and a recent result by Dey et al. (Math. Prog., pp 569-587, 2022). We employ this method to calculate an upper bound of the mutation probability in general instances of the 0-1 KP, and construct an instance where the mutation probability does not tend towards 0 as the problem size increases. Finally, we prove that the probability of the IMO hitting the optimal solution within only a single iteration in large-scale instances is superior to that of the traditional mutation operator.\n\n{retrieved_text}\n\nGenerate exactly 51 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 51\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Knapsack Problems: Algorithms and Computer Implementations\",\n        \"Knapsack Problems\",\n        \"Knapsack problems- An overview of recent advances. Part I: Single knapsack problems\",\n        \"Knapsack problems-An overview of recent advances. Part II: Multiple, multidimensional, and quadratic knapsack problems\",\n        \"The complexity of theorem-proving procedures\",\n        \"Reducibility among Combinatorial Problems\",\n        \"Computer and Intractablility: A Guide to the Theory of NP-Completeness\",\n        \"Dynamic programming\",\n        \"Dynamic programming algorithms for the Zero-One Knapsack Problem\",\n        \"Computing Partitions with Applications to the Knapsack Problem\",\n        \"A T=O‚Äã(2n/2)ùëáùëÇsuperscript2ùëõ2T=O(2^{n/2}), S=O‚Äã(2n/4)ùëÜùëÇsuperscript2ùëõ4S=O(2^{n/4}) algorithm for certain NP-complete problems\",\n        \"Isoperimetric and isodiametric functions of groups\",\n        \"On the hardness of approximating vertex cover\",\n        \"Adaptation in Natural and Artificial Systems\",\n        \"A hybrid adaptively genetic algorithm for task scheduling problem in the phased array radar\",\n        \"A Powerful Genetic Algorithm Using Edge Assembly Crossover for the Traveling Salesman Problem\",\n        \"A Hybrid Genetic Algorithm for Multidepot and Periodic Vehicle Routing Problems\",\n        \"A Runtime Analysis of Evolutionary Algorithms for Constrained Optimization Problems\",\n        \"Running Time Analysis of the (1 + 1)-EA for OneMax and LeadingOnes Under Bit-Wise Noise\",\n        \"Analysis of Evolutionary Algorithms on Fitness Function with Time-linkage Property\",\n        \"Global convergence of genetic algorithms: A markov chain analysis\",\n        \"Convergence analysis of canonical genetic algorithms\",\n        \"Finite Markov Chain Results in Evolutionary Computation: A Tour d‚ÄôHorizon\",\n        \"Parameter Control in Evolutionary Algorithms: Trends and Challenges\",\n        \"Towards an optimal mutation probability for genetic algorithms\",\n        \"Parameter Setting in Evolutionary Algorithms\",\n        \"Genetic Algorithm Essentials\",\n        \"Ubiquity symposium: Evolutionary computation and the processes of life: the emperor is naked: evolutionary algorithms for real-world applications\",\n        \"Quo Vadis, Evolutionary Computation?\",\n        \"Metaheuristics-the metaphor exposed\",\n        \"No free lunch theorems for optimization\",\n        \"On the futility of blind search: An algorithmic view of ‚ÄôNo Free Lunch‚Äô\",\n        \"The No Free Lunch Theorems: Complexity and Security\",\n        \"Conditions that Obviate the No-Free-Lunch Theorems for Optimization\",\n        \"An automatic method of solving discrete programming problem\",\n        \"Branch-and-bound solves random binary IPs in poly(nùëõn)-time\",\n        \"Introductory Combinatorics\",\n        \"Symmetric generating functions and Euler-Stirling statistics on permutations\",\n        \"An expanding-core algorithm for the exact 0-1 Knapsack Problem\",\n        \"Convex Optimization\",\n        \"Discrete-Variable Extremum Problems\",\n        \"An Algorithm for the Large Zero-One Knapsack Problems\",\n        \"A Minimal Algorithm for the 0-1 Knapsack Problem\",\n        \"Dynamic programming and strong bounds for the 0-1 knapsack problem\",\n        \"New trends in exact algorithms for the 0-1 knapsack problem\",\n        \"Evolutionary Algorithms for Knapsack Problems\",\n        \"Theory of genetic algorithms\",\n        \"An Introduction to Genetic Algorithms\",\n        \"Parameter Control in Evolutionary Algorithms\",\n        \"An Introduction to Metaheuristics for Optimization\",\n        \"Handbook of Metaheuristics\"\n    ],\n    \"reasoning\": \"Selected these 51 references because they represent foundational work and recent advances in An upper bound of the mutation probability in the genetic algorithm for general 0-1 knapsack problem, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}