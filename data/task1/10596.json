{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 47 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Enabling performance portability of data-parallel OpenMP applications on asymmetric multicore processors\n\nPaper Abstract: Abstract. Asymmetric multicore processors (AMPs) couple high-performance big cores and low-power small cores with the same instruction-set architecture but different features, such as clock frequency or microarchitecture. Previous work has shown that asymmetric designs may deliver higher energy efficiency than symmetric multicores for diverse workloads. Despite their benefits, AMPs pose significant challenges to runtime systems of parallel programming models. While previous work has mainly explored how to efficiently execute task-based parallel applications on AMPs, via enhancements in the runtime system, improving the performance of unmodified data-parallel applications on these architectures is still a big challenge. In this work we analyze the particular case of loop-based OpenMP applications, which are widely used today in scientific and engineering domains, and constitute the dominant application type in many parallel benchmark suites used for performance evaluation on multicore systems. We observed that conventional loop-scheduling OpenMP approaches are unable to efficiently cope with the load imbalance that naturally stems from the different performance delivered by big and small cores. To address this shortcoming, we propose Asymmetric Iteration Distribution (AID), a set of novel loop-scheduling methods for AMPs that distribute iterations unevenly across worker threads to efficiently deal with performance asymmetry. We implemented AID in libgomp –the GNU OpenMP runtime system–, and evaluated it on two different asymmetric multicore platforms. Our analysis reveals that the AID methods constitute effective replacements of the static and dynamic methods on AMPs, and are capable of improving performance over these conventional strategies by up to 56% and 16.8%, respectively.\n\n{retrieved_text}\n\nGenerate exactly 47 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 47\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"SPEC CPU 2017 Overview. What’s New?\",\n        \"Benefits of the big.LITTLE Architecture\",\n        \"Is the schedule clause really necessary in OpenMP?\",\n        \"Optimized Execution of Parallel Loops via User-Defined Scheduling Policies\",\n        \"The PARSEC benchmark suite: characterization and architectural implications\",\n        \"Paraver: a flexible performance analysis tool\",\n        \"Position Paper: OpenMP scheduling on ARM big.LITTLE architecture\",\n        \"Efficient Programming for Multicore Processor Heterogeneity: OpenMP versus OmpS\",\n        \"A cloud-scale acceleration architecture\",\n        \"Rodinia: A benchmark suite for heterogeneous computing\",\n        \"Maximizing System Utilization via Parallelism Management for Co-Located Parallel Applications\",\n        \"Criticality-Aware Dynamic Task Scheduling for Heterogeneous Architectures\",\n        \"On the maturity of parallel applications for asymmetric multi-core processors\",\n        \"OpenMP Loop Scheduling Revisited: Making a Case for More Schedules\",\n        \"Accelerator-Rich Architectures: Opportunities and Progresses\",\n        \"Hybrid Static/Dynamic Scheduling for Already Optimized Dense Matrix Factorization\",\n        \"Report on the Sunway TaihuLight System\",\n        \"Contention-Aware Fair Scheduling for Asymmetric Single-ISA Multicore Systems\",\n        \"Odroid XU4 board\",\n        \"A New Golden Age for Computer Architecture\",\n        \"Load-Sharing in Heterogeneous Systems via Weighted Factoring\",\n        \"The OpenMP implementation of NAS parallel benchmarks and its performance\",\n        \"Utility-based acceleration of multithreaded applications on asymmetric CMPs\",\n        \"Introduction to the Cell Broadband Engine Architecture\",\n        \"A Domain-specific Architecture for Deep Neural Networks\",\n        \"Adaptive Loop Scheduling with Charm++ to Improve Performance of Scientific Applications\",\n        \"Locality-Optimized Mixed Static/Dynamic Scheduling for Improving Load Balancing on SMPs\",\n        \"Lakefield: Hybrid Cores in 3D Package\",\n        \"Twenty years of the OpenMP API\",\n        \"Bias Scheduling in Heterogeneous Multi-core Architectures\",\n        \"Single-ISA Heterogeneous Multi-Core Architectures for Multithreaded Workload Performance\",\n        \"Operating system support for overlapping-ISA heterogeneous multi-core architectures\",\n        \"A Survey of Techniques for Architecting and Managing Asymmetric Multicore Processors\",\n        \"SPEC OMP2012 – an Application Benchmark Suite for Parallel Systems Using OpenMP\",\n        \"Energy-Aware Scheduling of Malleable Fork-Join Tasks under a Deadline Constraint on Heterogeneous Multicores\",\n        \"OpenMP Application Programming Interface (Version 4.5)\",\n        \"CellSs: Making it easier to program the Cell Broadband Engine processor\",\n        \"Compiler Enhanced Scheduling for OpenMP for Heterogeneous Multiprocessors\",\n        \"Operating System Support for Mitigating Software Scalability Bottlenecks on Asymmetric Multicore Processors\",\n        \"Run-Time Parallelization and Scheduling of Loops\",\n        \"Accelerating Critical Section Execution with Asymmetric Multi-Core Architectures\",\n        \"Efficient Execution of Multiple CUDA Applications Using Transparent Suspend, Resume and Migration\",\n        \"Processor self-scheduling for multiple-nested parallel loops\",\n        \"Automatic OpenMP Loop Scheduling: A Combined Compiler and Runtime Approach\",\n        \"Asymmetry-Aware Work-Stealing Runtimes\",\n        \"Trapezoid Self-Scheduling: A Practical Scheduling Scheme for Parallel Compilers\",\n        \"COLAB: A Collaborative Multi-Factor Scheduler for Asymmetric Multicore Processors\"\n    ],\n    \"reasoning\": \"Selected these 47 references because they represent foundational work and recent advances in Enabling performance portability of data-parallel OpenMP applications on asymmetric multicore processors, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}