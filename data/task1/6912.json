{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 62 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Automatic Analysis of Available Source Code of Top Artificial Intelligence Conference Papers\n\nPaper Abstract: Abstract Source code is essential for researchers to reproduce the methods and replicate the results of artificial intelligence (AI) papers. Some organizations and researchers manually collect AI papers with available source code to contribute to the AI community. However, manual collection is a labor-intensive and time-consuming task. To address this issue, we propose a method to automatically identify papers with available source code and extract their source code repository URLs. With this method, we find that 20.5% of regular papers of 10 top AI conferences published from 2010 to 2019 are identified as papers with available source code and that 8.1% of these source code repositories are no longer accessible. We also create the XMU NLP Lab README Dataset, the largest dataset of labeled README files for source code document research. Through this dataset, we have discovered that quite a few README files have no installation instructions or usage tutorials provided. Further, a large-scale comprehensive statistical analysis is made for a general picture of the source code of AI conference papers. The proposed solution can also go beyond AI conference papers to analyze other scientific papers from both journals and conferences to shed light on more domains.\n\n{retrieved_text}\n\nGenerate exactly 62 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 62\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Face recognition: Past, present and future (a review)\",\n        \"Intelligent personal assistants: A systematic literature review\",\n        \"Deep learning based recommender system: A survey and new perspectives\",\n        \"Introduction to “This is Watson”\",\n        \"Mastering the game of Go without human knowledge\",\n        \"Superhuman AI for multiplayer poker\",\n        \"Detecting and analyzing missing citations to published scientific entities\",\n        \"A framework for assessing the peer review duration of journals: Case study in computer science\",\n        \"Adam: A method for stochastic optimization\",\n        \"Deep residual learning for image recognition\",\n        \"Attention is all you need\",\n        \"Universal language model fine-tuning for text classification\",\n        \"BERT: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Conferences versus journals in computer science\",\n        \"Artificial intelligence faces reproducibility crisis\",\n        \"A step toward quantifying independently reproducible machine learning research\",\n        \"How many preprints have actually been printed and why: A case study of computer science preprints on arXiv\",\n        \"Winners and losers in the global research village\",\n        \"Code replicability in computer graphics\",\n        \"GROBID: Combining automatic bibliographic data recognition and term extraction for scholarship publications\",\n        \"How to fine-tune BERT for text classification?\",\n        \"SciBERT: A pretrained language model for scientific text\",\n        \"Theano: A CPU and GPU math compiler in Python\",\n        \"Caffe: Convolutional architecture for fast feature embedding\",\n        \"TensorFlow: A system for large-scale machine learning\",\n        \"PyTorch: An imperative style, high-performance deep learning library\",\n        \"An omnibus test of normality for moderate and large size samples\",\n        \"Tests for departure from normality: Comparison of powers\",\n        \"Use of ranks in one-criterion variance analysis\",\n        \"On a test of whether one of two random variables is stochastically larger than the other\",\n        \"The proof and measurement of association between two things\",\n        \"Simple unsupervised keyphrase extraction using sentence embeddings\",\n        \"Unifying holistic and parts-based deformable model fitting\",\n        \"A 3D morphable model learnt from 10,000 faces\",\n        \"Improving representation learning in autoencoders via multidimensional interpolation and dual regularizations\",\n        \"Open-domain targeted sentiment analysis via span-based extraction and classification\",\n        \"Categorizing the content of GitHub README files\",\n        \"A coefficient of agreement for nominal scales\",\n        \"Two BERTs are better than one (2nd place solution), report\",\n        \"Siamese and dual BERT for multi text classification, report\",\n        \"SciBERT multi label classification - dual input, report\",\n        \"Code sharing is associated with research impact in image processing\",\n        \"Code availability for image processing papers: A status update\",\n        \"A large-scale analysis of bioinformatics code on GitHub\",\n        \"Analyzing the GitHub repositories of research papers\",\n        \"An overview of Microsoft Academic Service (MAS) and applications\",\n        \"A large scale study of programming languages and code quality in GitHub\",\n        \"Findings from GitHub: Methods, datasets and limitations\",\n        \"Identifying unmaintained projects in Github\",\n        \"Understanding the working habits of GH-SO users on GitHub commit activity and Stack Overflow post activity\",\n        \"GitHub repositories with links to academic papers: Public access, traceability, and evolution\",\n        \"Recurrent neural network for text classification with multi-task learning\",\n        \"Very deep convolutional networks for text classification\",\n        \"Graph convolutional networks for text classification\",\n        \"A novel reasoning mechanism for multi-label text classification\",\n        \"Deep learning–based text classification: A comprehensive review\",\n        \"An empirical study of software release notes\",\n        \"Mining readme files to support automatic building of Java projects in software repositories\",\n        \"Detecting similar repositories on GitHub\",\n        \"To do or not to do: Distill crowdsourced negative caveats to augment API documentation\",\n        \"Usability requirements extraction method from software document\",\n        \"Automatically generating release notes with content classification models\"\n    ],\n    \"reasoning\": \"Selected these 62 references because they represent foundational work and recent advances in Automatic Analysis of Available Source Code of Top Artificial Intelligence Conference Papers, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}