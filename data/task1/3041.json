{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 47 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx\n\nPaper Abstract: Abstract We extend the neural basis expansion analysis (NBEATS) to incorporate exogenous factors. The resulting method, called NBEATSx, improves on a well performing deep learning model, extending its capabilities by including exogenous variables and allowing it to integrate multiple sources of useful information. To showcase the utility of the NBEATSx model, we conduct a comprehensive study of its application to electricity price forecasting (EPF) tasks across a broad range of years and markets. We observe state-of-the-art performance, significantly improving the forecast accuracy by nearly 20% over the original NBEATS model, and by up to 5% over other well established statistical and machine learning methods specialized for these tasks. Additionally, the proposed neural network has an interpretable configuration that can structurally decompose time series, visualizing the relative impact of trend and seasonal components and revealing the modeled processes’ interactions with exogenous factors. To assist related work we made the code available in a dedicated repository.\n\n{retrieved_text}\n\nGenerate exactly 47 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 47\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Why does forecast combination work so well?\",\n        \"An empirical evaluation of generic convolutional and recurrent networks for sequence modeling\",\n        \"Neural forecasting: Introduction and literature overview\",\n        \"Algorithms for hyper-parameter optimization\",\n        \"Bagging predictors\",\n        \"Dilated recurrent neural networks\",\n        \"Electricity price forecasting for operational scheduling of behind-the-meter storage systems\",\n        \"Comparing predictive accuracy\",\n        \"Finding structure in time\",\n        \"Tests of conditional predictive ability\",\n        \"Comparing the forecasting performances of linear models for electricity prices with high RES penetration\",\n        \"Generating sequences with recurrent neural networks\",\n        \"A note on averaging day-ahead electricity price forecasts across calibration windows\",\n        \"Another look at measures of forecast accuracy\",\n        \"On large-batch training for deep learning: Generalization gap and sharp minima\",\n        \"ADAM: A method for stochastic optimization\",\n        \"The spectral analysis of time series\",\n        \"Forecasting spot electricity prices: Deep learning approaches and empirical comparison of traditional algorithms\",\n        \"Forecasting day-ahead electricity prices in Europe: The importance of considering market integration\",\n        \"Forecasting day-ahead electricity prices: A review of state-of-the-art algorithms, best practices and an open-access benchmark\",\n        \"Erratum to ’Forecasting day-ahead electricity prices: A review of state-of-the-art algorithms, best practices and an open-access benchmark’ [Appl. Energy 293 (2021) 116983]\",\n        \"Efficient backprop\",\n        \"Day-ahead electricity price prediction applying hybrid models of lstm-based deep learning methods and feature selection algorithms under consideration of market coupling\",\n        \"Forecasting time series with complex seasonal patterns using exponential smoothing\",\n        \"Statistical and machine learning forecasting methods: Concerns and ways forward\",\n        \"The M4 competition: 100,000 time series and 61 forecasting methods\",\n        \"Forecasting electricity prices using deep neural networks: A robust hyper-parameter selection scheme\",\n        \"Electricity markets around the world\",\n        \"Econometric modelling and forecasting of intraday electricity prices\",\n        \"Hybrid model using three-stage algorithm for simultaneous load and price forecasting\",\n        \"An empirical comparison of alternative schemes for combining electricity spot price forecasts\",\n        \"Recent advances in electricity price forecasting: A review of probabilistic forecasting\",\n        \"Wavenet: A generative model for raw audio\",\n        \"N-BEATS: neural basis expansion analysis for interpretable time series forecasting\",\n        \"Pytorch: An imperative style, high-performance Deep Learning library\",\n        \"Principles of neurodynamics. perceptrons and the theory of brain mechanisms\",\n        \"A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting\",\n        \"Sequence to Sequence learning with neural networks\",\n        \"The information bottleneck method\",\n        \"Automated variable selection and shrinkage for day-ahead electricity price forecasting\",\n        \"Regularized quantile regression averaging for probabilistic electricity price forecasting\",\n        \"Variance stabilizing transformations for electricity spot price forecasting\",\n        \"Short-term electricity price forecasting with stacked denoising autoencoders\",\n        \"A Multi-horizon Quantile Recurrent Forecaster\",\n        \"Electricity price forecasting: A review of the state-of-the-art with a look into the future\",\n        \"On early stopping in gradient descent learning\",\n        \"Probabilistic mid- and long-term electricity price forecasting\"\n    ],\n    \"reasoning\": \"Selected these 47 references because they represent foundational work and recent advances in Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}