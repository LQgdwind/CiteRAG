{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 59 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: DRL: Deep Reinforcement Learning for Intelligent Robot Control– Concept, Literature, and Future\n\nPaper Abstract: Abstract Combination of machine learning (for generating machine intelligence), computer vision (for better environment perception), and robotic systems (for controlled environment interaction) motivates this work toward proposing a vision-based learning framework for intelligent robot control as the ultimate goal (vision-based learning robot). This work specifically introduces deep reinforcement learning as the the learning framework, a General-purpose framework for AI (AGI) meaning application-independent and platform-independent. In terms of robot control, this framework is proposing specifically a high-level control architecture independent of the low-level control, meaning these two required level of control can be developed separately from each other. In this aspect, the high-level control creates the required intelligence for the control of the platform using the recorded low-level controlling data from that same platform generated by a trainer. The recorded low-level controlling data is simply indicating the successful and failed experiences or sequences of experiments conducted by a trainer using the same robotic platform. The sequences of the recorded data are composed of observation data (input sensor), generated reward (feedback value) and action data (output controller). For experimental platform and experiments, vision sensors are used for perception of the environment, different kinematic controllers create the required motion commands based on the platform application, deep learning approaches generate the required intelligence, and finally reinforcement learning techniques incrementally improve the generated intelligence until the mission is accomplished by the robot. For deep reinforcement learning, deep Q networks (DQN) [1] using Convolutional Neural Network (CNN) [2] will be used for learning the Q network. Deep Q Network approach is applied to the images acquired from our vision devices as input sensors to select the maximum rewarded action (best possible move based on our experiences) for our output controller to generate the required kinematics motion. keywords Advanced Cognitive Robotics, Control Architectures, Computer Vision, Deep Learning, Reinforcement Learning and Machine Learning.\n\n{retrieved_text}\n\nGenerate exactly 59 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 59\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Human-level control through deep reinforcement learning\",\n        \"Gradient-based learning applied to document recognition\",\n        \"Stanley: The robot that won the darpa grand challenge\",\n        \"Probabilistic robotics\",\n        \"Junior: The stanford entry in the urban challenge\",\n        \"Deep learning\",\n        \"The learning machines\",\n        \"Learning representations by back-propagating errors\",\n        \"How to do backpropagation in a brain\",\n        \"Parallel distributed processing\",\n        \"A learning algorithm for boltzmann machines\",\n        \"Learning and relearning in boltzmann machines\",\n        \"Reducing the dimensionality of data with neural networks\",\n        \"A fast learning algorithm for deep belief nets\",\n        \"Imagenet classification with deep convolutional neural networks\",\n        \"Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups\",\n        \"Convolutional networks for images, speech, and time series\",\n        \"Learning deep architectures for AI\",\n        \"Long short-term memory\",\n        \"Multi-column deep neural networks for image classification\",\n        \"Deep, big, simple neural nets for handwritten digit recognition\",\n        \"Deep learning in neural networks: An overview\",\n        \"Ros: an open-source robot operating system\",\n        \"Large scale distributed deep networks\",\n        \"An invitation to imitation\",\n        \"Introduction to reinforcement learning\",\n        \"Reinforcement learning improves behaviour from evaluative feedback\",\n        \"Reinforcement learning in robotics: A survey\",\n        \"On learning navigation behaviors for small mobile robots with reservoir computing architectures\",\n        \"Learning navigation attractors for mobile robots with reinforcement learning and reservoir computing\",\n        \"Reservoir computing architectures for modeling robot navigation systems\",\n        \"Mastering the game of go with deep neural networks and tree search\",\n        \"Artificial intelligence: Learning to see and act\",\n        \"Deep reinforcement learning from self-play in imperfect-information games\",\n        \"Deep reinforcement learning\",\n        \"Deep reinforcement learning discovers internal models\",\n        \"Learning to communicate with deep multi-agent reinforcement learning\",\n        \"Benchmarking deep reinforcement learning for continuous control\",\n        \"Terrain-adaptive locomotion skills using deep reinforcement learning\",\n        \"Stereo-based terrain traversability estimation using surface normals\",\n        \"Towards end-to-end learning for dialog state tracking and management using deep reinforcement learning\",\n        \"Deep reinforcement learning with macro-actions\",\n        \"Negative learning rates and p-learning\",\n        \"Progressive neural networks\",\n        \"Vizdoom: A doom-based AI research platform for visual reinforcement learning\",\n        \"A deep hierarchical approach to lifelong learning in minecraft\",\n        \"Towards vision-based deep reinforcement learning for robotic motion control\",\n        \"Intelligent laser welding through representation, prediction, and control learning: An architecture with deep neural networks and reinforcement learning\",\n        \"First steps towards an intelligent laser welding architecture using deep neural networks and reinforcement learning\",\n        \"Weld appearance prediction with {BP} neural network improved by genetic algorithm during disk laser welding\",\n        \"Unsupervised energy prediction in a smart grid context using reinforcement cross-building transfer learning\",\n        \"Deep direct reinforcement learning for financial signal representation and trading\",\n        \"Convolutional neural networks for automatic state-time feature extraction in reinforcement learning applied to residential load control\",\n        \"Simpleds: A simple deep reinforcement learning dialogue system\",\n        \"Using goal-driven deep learning models to understand sensory cortex\",\n        \"Deep Learning a Grasp Function for Grasping under Gripper Pose Uncertainty\",\n        \"Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection\",\n        \"Unsupervised learning for physical interaction through video prediction\",\n        \"End-to-end training of deep visuomotor policies\"\n    ],\n    \"reasoning\": \"Selected these 59 references because they represent foundational work and recent advances in DRL: Deep Reinforcement Learning for Intelligent Robot Control– Concept, Literature, and Future, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}