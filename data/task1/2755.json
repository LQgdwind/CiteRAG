{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 50 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: A Bioinspired Retinal Neural Network for Accurately Extracting Small-Target Motion Information in Cluttered Backgrounds\n\nPaper Abstract: Abstract Robust and accurate detection of small moving targets in cluttered moving backgrounds is a significant and challenging problem for robotic visual systems to perform search and tracking tasks. Inspired by the neural circuitry of elementary motion vision in the mammalian retina, this paper proposes a bioinspired retinal neural network based on a new neurodynamics-based temporal filtering and multiform 2-D spatial Gabor filtering. This model can estimate motion direction accurately via only two perpendicular spatiotemporal filtering signals, and respond to small targets of different sizes and velocities through adjusting the dendrite field size of spatial filter. Meanwhile, an algorithm of directionally selective inhibition is proposed to suppress the target-like features in the moving background, which can reduce the influence of background motion effectively. Extensive synthetic and real-data experiments show that the proposed model works stably for small targets of a wider size and velocity range, and has better detection performance than other bioinspired models. Additionally, it can also extract the information of motion direction and motion energy accurately and rapidly.\n\n{retrieved_text}\n\nGenerate exactly 50 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 50\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Radial basis function based neural network for motion detection in dynamic scenes\",\n        \"Robust online matrix factorization for dynamic background subtraction\",\n        \"Rotation feature extraction for moving targets based on temporal differencing and image edge detection\",\n        \"Motion detection based on temporal difference method and optical flow field\",\n        \"Independent component analysis-based background subtraction for indoor surveillance\",\n        \"Environmentally robust motion detection for video surveillance\",\n        \"Optical flow modeling and computation\",\n        \"Motion detection based on optical flow and self-adaptive threshold segmentation\",\n        \"Region-based convolutional networks for accurate object detection and segmentation\",\n        \"Fast r-cnn\",\n        \"Faster r-cnn: Towards real-time object detection with region proposal networks\",\n        \"Ssd: Single shot multibox detector\",\n        \"Yolov3: An incremental improvement\",\n        \"Yolo9000: better, faster, stronger\",\n        \"You only look once: Unified, real-time object detection\",\n        \"Infrared patch-image model for small target detection in a single image\",\n        \"Derivative entropy-based contrast measure for infrared small-target detection\",\n        \"A novel infrared small moving target detection method based on tracking interest points under complicated background\",\n        \"Using deep learning to detect small targets in infrared oversampling images\",\n        \"Sg-fcn: A motion and memory-based deep learning model for video saliency detection\",\n        \"Moving object detection based on background compensation and deep learning\",\n        \"Small object detection neurons in female hoverflies\",\n        \"Retinotopic organization of small-field-target-detecting neurons in the insect visual system\",\n        \"A model for the detection of moving targets in visual clutter inspired by insect physiology\",\n        \"An autonomous robot inspired by insect neurophysiology pursues moving features in natural environments\",\n        \"Performance of an insect-inspired target tracker in natural conditions\",\n        \"Properties of neuronal facilitation that improve target tracking in natural pursuit simulations\",\n        \"A directionally selective small target motion detecting visual neural network in cluttered backgrounds\",\n        \"A robust visual system for small target motion detection against cluttered moving backgrounds\",\n        \"A bio-inspired sighted robot chases like a hoverfly\",\n        \"Visual acuity and the evolution of signals\",\n        \"Ultra-rapid vision in birds\",\n        \"Common circuit design in fly and mammalian motion vision\",\n        \"Parallel computations in insect and mammalian visual motion processing\",\n        \"Spatiotemporal energy models for the perception of motion\",\n        \"Optical flow using spatiotemporal filters\",\n        \"A neural model of how the brain computes heading from optic flow in realistic scenes.\",\n        \"Cortical dynamics of navigation and steering in natural scenes: Motion-based object segmentation, heading, and obstacle avoidance\",\n        \"The fundamental plan of the retina\",\n        \"Principles of Neural Science\",\n        \"Retinal bipolar cells: elementary building blocks of vision\",\n        \"Temporal filtering in retinal bipolar cells. elements of an optimal computation?\",\n        \"Retinal bipolar cells : Temporal filtering of signals from cone photoreceptors\",\n        \"Specific wiring of distinct amacrine cells in the directionally selective retinal circuit permits independent coding of direction and size\",\n        \"Contributions of retinal ganglion cells to subcortical visual processing and behaviors\",\n        \"Shaping the collision selectivity in a looming sensitive neuron model with parallel on and off pathways and spike frequency adaptation\",\n        \"Autocorrelation, a principle for the evaluation of sensory information by the central nervous system\",\n        \"A density-based algorithm for discovering clusters in large spatial databases with noise.\",\n        \"Dbscan revisited, revisited: why and how you should (still) use dbscan\",\n        \"Directionally sensitive ganglion cells in the rabbit retina: specificity for stimulus direction, size, and speed\"\n    ],\n    \"reasoning\": \"Selected these 50 references because they represent foundational work and recent advances in A Bioinspired Retinal Neural Network for Accurately Extracting Small-Target Motion Information in Cluttered Backgrounds, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}