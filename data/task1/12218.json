{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 47 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: An Adaptive Balance Search Based Complementary Heterogeneous Particle Swarm Optimization Architecture\n\nPaper Abstract: Abstract A series of modified cognitive-only particle swarm optimization (PSO) algorithms effectively mitigate premature convergence by constructing distinct vectors for different particles. However, the underutilization of these constructed vectors hampers convergence accuracy. In this paper, an adaptive balance search based complementary heterogeneous PSO architecture is proposed, which consists of a complementary heterogeneous PSO (CHxPSO) framework and an adaptive balance search (ABS) strategy. The CHxPSO framework mainly includes two update channels and two subswarms. Two channels exhibit nearly heterogeneous properties while sharing a common constructed vector. This ensures that one constructed vector is utilized across both heterogeneous update mechanisms. The two subswarms work within their respective channels during the evolutionary process, preventing interference between the two channels. The ABS strategy precisely controls the proportion of particles involved in the evolution in the two channels, and thereby guarantees the flexible utilization of the constructed vectors, based on the evolutionary process and the interactions with the problem’s fitness landscape. Together, our architecture ensures the effective utilization of the constructed vectors by emphasizing exploration in the early evolutionary process while exploitation in the later, enhancing the performance of a series of modified cognitive-only PSOs. Extensive experimental results demonstrate the generalization performance of our architecture.\n\n{retrieved_text}\n\nGenerate exactly 47 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 47\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A stochastic simulation optimization based range gate pull-off jamming method\",\n        \"Persistence of serum and saliva antibody responses to sars-cov-2 spike antigens in covid-19 patients\",\n        \"A survey of particle swarm optimization applications in electric power systems\",\n        \"A micro-ga embedded pso feature selection approach to intelligent facial emotion recognition\",\n        \"Particle swarm optimization\",\n        \"Adaptive multimodal continuous ant colony optimization\",\n        \"A review on genetic algorithm: past, present, and future\",\n        \"Particle swarm optimiser with neighbourhood operator\",\n        \"A modified particle swarm optimizer\",\n        \"A hybrid particle swarm optimization–back-propagation algorithm for feedforward neural network training\",\n        \"A comparative study on particle swarm optimization for optimal steady-state performance of power systems\",\n        \"An adaptive particle swarm optimizer with decoupled exploration and exploitation for large scale optimization\",\n        \"A promotive particle swarm optimizer with double hierarchical structures\",\n        \"A new initialization approach in particle swarm optimization for global optimization problems\",\n        \"The particle swarm: social adaptation of knowledge\",\n        \"The fully informed particle swarm: simpler, maybe better\",\n        \"Impact of communication topology in particle swarm optimization\",\n        \"Comprehensive learning particle swarm optimizer for global optimization of multimodal functions\",\n        \"Genetic learning particle swarm optimization\",\n        \"Orthogonal learning particle swarm optimization\",\n        \"Composite particle swarm optimizer with historical memory for function optimization\",\n        \"A scatter learning particle swarm optimization algorithm for multimodal problems\",\n        \"A distance-based locally informed particle swarm model for multimodal optimization\",\n        \"Exploration and exploitation in evolutionary algorithms: A survey\",\n        \"Heterogeneous strategy particle swarm optimization\",\n        \"Heterogeneous particle swarm optimizers\",\n        \"Ahps2: An optimizer using adaptive heterogeneous particle swarms\",\n        \"Network-based heterogeneous particle swarm optimization and its application in uav communication coverage\",\n        \"A hybrid pso-ga method for composing heterogeneous groups in collaborative learning\",\n        \"Heterogeneous differential evolution particle swarm optimization with local search\",\n        \"Heterogeneous comprehensive learning and dynamic multi-swarm particle swarm optimizer with two mutation operators\",\n        \"Heterogeneous comprehensive learning particle swarm optimization with enhanced exploration and exploitation\",\n        \"Self-organizing hierarchical particle swarm optimizer with time-varying acceleration coefficients\",\n        \"Heterogeneous particle swarm optimization\",\n        \"An adaptive particle swarm optimization with multiple adaptive methods\",\n        \"Dynamic multi-swarm differential learning particle swarm optimizer\",\n        \"Adaptive multistrategy ensemble particle swarm optimization with signal-to-noise ratio distance metric\",\n        \"Particle swarm optimization with a new update mechanism\",\n        \"Pso-elpm: Pso with elite learning, enhanced parameter updating, and exponential mutation operator\",\n        \"Problem definitions and evaluation criteria for the cec 2013 special session on real-parameter optimization\",\n        \"Problem definitions and evaluation criteria for the cec 2017 competition on constrained real-parameter optimization\",\n        \"Ensemble particle swarm optimizer\",\n        \"A novel sigmoid-function-based adaptive weighted particle swarm optimizer\",\n        \"Multiple adaptive strategies based particle swarm optimization algorithm\",\n        \"Measuring exploration/exploitation in particle swarms using swarm diversity\",\n        \"Comprehensive learning particle swarm optimization algorithm with local search for multimodal functions\",\n        \"No free lunch theorems for optimization\"\n    ],\n    \"reasoning\": \"Selected these 47 references because they represent foundational work and recent advances in An Adaptive Balance Search Based Complementary Heterogeneous Particle Swarm Optimization Architecture, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}