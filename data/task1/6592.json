{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 46 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Detecting Multivariate Time Series Anomalies with Zero Known Label\n\nPaper Abstract: Abstract Multivariate time series anomaly detection has been extensively studied under the one-class classification setting, where a training dataset with all normal instances is required. However, preparing such a dataset is very laborious since each single data instance should be fully guaranteed to be normal. It is, therefore, desired to explore multivariate time series anomaly detection methods based on the dataset without any label knowledge. In this paper, we propose MTGFlow, an unsupervised anomaly detection approach for Multivariate Time series anomaly detection via dynamic Graph and entity-aware normalizing Flow, leaning only on a widely accepted hypothesis that abnormal instances exhibit sparse densities than the normal. However, the complex interdependencies among entities and the diverse inherent characteristics of each entity pose significant challenges to density estimation, let alone to detect anomalies based on the estimated possibility distribution. To tackle these problems, we propose to learn the mutual and dynamic relations among entities via a graph structure learning model, which helps to model the accurate distribution of multivariate time series. Moreover, taking account of distinct characteristics of the individual entities, an entity-aware normalizing flow is developed to describe each entity into a parameterized normal distribution, thereby producing fine-grained density estimation. Incorporating these two strategies, MTGFlow achieves superior anomaly detection performance. Experiments on five public datasets with seven baselines are conducted, MTGFlow outperforms the SOTA methods by up to 5.0 AUROC%.\n\n{retrieved_text}\n\nGenerate exactly 46 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 46\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Practical approach to asynchronous multivariate time series anomaly detection and localization\",\n        \"WADI: a water distribution testbed for research in the design of secure cyber physical systems\",\n        \"Guided image generation with conditional invertible neural networks\",\n        \"USAD: unsupervised anomaly detection on multivariate time series\",\n        \"Deep learning for anomaly detection: A survey\",\n        \"DAEMON: Unsupervised Anomaly Detection and Interpretation for Multivariate Time Series\",\n        \"Learning phrase representations using RNN encoder-decoder for statistical machine translation\",\n        \"Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series\",\n        \"Graph neural network-based anomaly detection in multivariate time series\",\n        \"Density estimation using real nvp\",\n        \"Multi-scale Attention Flow for Probabilistic Time Series Forecasting\",\n        \"A dataset to support research in the design of secure water treatment systems\",\n        \"LUNAR: Unifying Local Outlier Detection Methods via Graph Neural Networks\",\n        \"DROCC: Deep robust one-class classification\",\n        \"Cflow-ad: Real-time unsupervised anomaly detection with localization via conditional normalizing flows\",\n        \"Outlier detection for temporal data: A survey\",\n        \"Long short-term memory\",\n        \"Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding\",\n        \"Unsupervised outlier detection using memory and contrastive learning\",\n        \"Semi-supervised learning with normalizing flows\",\n        \"Semi-supervised classification with graph convolutional networks\",\n        \"LSTM-based encoder-decoder for multi-sensor anomaly detection\",\n        \"Deep Learning for Anomaly Detection: Challenges, Methods, and Opportunities\",\n        \"Masked autoregressive flow for density estimation\",\n        \"Latent Outlier Exposure for Anomaly Detection with Contaminated Data\",\n        \"Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting\",\n        \"Multivariate probabilistic time series forecasting via conditioned normalizing flows\",\n        \"Same same but differnet: Semi-supervised defect detection with normalizing flows\",\n        \"A unifying review of deep and shallow anomaly detection\",\n        \"Deep one-class classification\",\n        \"Deep semi-supervised anomaly detection\",\n        \"Deep end-to-end one-class classifier\",\n        \"DeepAR: Probabilistic forecasting with autoregressive recurrent networks\",\n        \"Support vector method for novelty detection\",\n        \"Robust anomaly detection for multivariate time series through stochastic recurrent neural network\",\n        \"TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate Time Series Data\",\n        \"Attention is all you need\",\n        \"Graph attention networks\",\n        \"Deep Learning for Anomaly Detection\",\n        \"Effective end-to-end unsupervised outlier detection via inlier priority of discriminative network\",\n        \"Current time series anomaly detection benchmarks are flawed and are creating the illusion of progress\",\n        \"Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy\",\n        \"Understanding deep learning (still) requires rethinking generalization\",\n        \"A deep neural network for unsupervised anomaly detection and diagnosis in multivariate time series data\",\n        \"Online and unsupervised anomaly detection for streaming data using an array of sliding windows and PDDs\",\n        \"Deep autoencoding gaussian mixture model for unsupervised anomaly detection\"\n    ],\n    \"reasoning\": \"Selected these 46 references because they represent foundational work and recent advances in Detecting Multivariate Time Series Anomalies with Zero Known Label, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}