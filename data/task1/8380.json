{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 58 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Q-Learning Based System for Path Planning with UAV Swarms in Obstacle Environments\n\nPaper Abstract: Abstract Path Planning methods for autonomous control of Unmanned Aerial Vehicle (UAV) swarms are on the rise because of all the advantages they bring. There are more and more scenarios where autonomous control of multiple UAVs is required. Most of these scenarios present a large number of obstacles, such as power lines or trees. If all UAVs can be operated autonomously, personnel expenses can be decreased. In addition, if their flight paths are optimal, energy consumption is reduced. This ensures that more battery time is left for other operations. In this paper, a Reinforcement Learning based system is proposed for solving this problem in environments with obstacles by making use of Q-Learning. This method allows a model, in this particular case an Artificial Neural Network, to self-adjust by learning from its mistakes and achievements. Regardless of the size of the map or the number of UAVs in the swarm, the goal of these paths is to ensure complete coverage of an area with fixed obstacles for tasks, like field prospecting. Setting goals or having any prior information aside from the provided map is not required. For experimentation, five maps of different sizes with different obstacles were used. The experiments were performed with different number of UAVs. For the calculation of the results, the number of actions taken by all UAVs to complete the task in each experiment is taken into account. The lower the number of actions, the shorter the path and the lower the energy consumption. The results are satisfactory, showing that the system obtains solutions in fewer movements the more UAVs there are. For a better presentation, these results have been compared to another state-of-the-art approach.\n\n{retrieved_text}\n\nGenerate exactly 58 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 58\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Monitoring and mapping with robot swarms for agricultural applications\",\n        \"Soil sampling with drones and augmented reality in precision agriculture\",\n        \"Forest inventory with high-density uav-lidar: Machine learning approaches for predicting individual tree attributes\",\n        \"F prime: an open-source framework for small-scale flight software systems\",\n        \"Scaling sediment mobilization beneath rotorcraft for titan and mars\",\n        \"A motif-based rescue mission planning method for uav swarms usingan improved picea\",\n        \"Virtual air power: a case for complementing ADF air operations with uninhabited aerial vehicles\",\n        \"Remote sensing uav/drones and its applications for urban areas: A review\",\n        \"Unmanned aircraft systems: UAVS design, development and deployment\",\n        \"Special issue on swarm robotics\",\n        \"Survey on computational-intelligence-based uav path planning\",\n        \"A review and future directions of uav swarm communication architectures\",\n        \"Path planning techniques for unmanned aerial vehicles: A review, solutions, and challenges\",\n        \"Swarm intelligence\",\n        \"Swarm intelligence: A whole new way to think about business\",\n        \"Optimal and efficient path planning for partially known environments\",\n        \"A review of artificial intelligence applied to path planning in uav swarms\",\n        \"Reinforcement learning: An introduction\",\n        \"Reinforcement learning\",\n        \"A data-driven packet routing algorithm for an un-manned aerial vehicle swarm: A multi-agent rein-forcement learning approach\",\n        \"High-performance uav crowdsensing: A deep reinforcement learning approach\",\n        \"Deep reinforcement learning for flocking control of uavs in complex environments\",\n        \"Q-learning\",\n        \"Inter-uav collision avoidance using deep-q-learning in flocking environment\",\n        \"Uav swarm path planning with reinforcement learning for field prospecting\",\n        \"Handbook of genetic algorithms\",\n        \"Adaptation in natural and artificial systems\",\n        \"An improved ga-based approach for uav swarm formation transformation\",\n        \"An improved genetic algorithm for rapid uav path planning\",\n        \"A task allocation strategy of the uav swarm based on multi-discrete wolf pack algorithm\",\n        \"Collision free 4d path planning for multiple uavs based on spatial refined voting mechanism and pso approach\",\n        \"Pso-based minimum-time motion planning for multiple vehicles under acceleration and velocity limitations\",\n        \"Mvo-based path planning scheme with coordination of uavs in 3-d environment\",\n        \"Swarm intelligence based algorithms: a critical analysis\",\n        \"A novel hybrid particle swarm optimization for multi-uav cooperate path planning\",\n        \"Reinforcement learning: A survey\",\n        \"States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning\",\n        \"Hybrid combinatorial remanufacturing strategy for medical equipment in the pandemic\",\n        \"A study on overfitting in deep reinforcement learning\",\n        \"Machine learning\",\n        \"Deep learning\",\n        \"A theoretical analysis of deep q-learning\",\n        \"What are artificial neural networks?\",\n        \"Understanding of a convolutional neural network\",\n        \"Densely connected convolutional networks\",\n        \"Reinforcement learning by stochastic hill climbing on discounted reward\",\n        \"Stabilising experience replay for deep multi-agent reinforcement learning\",\n        \"The effects of memory replay in reinforcement learning\",\n        \"Introduction to autonomous robots. kinematics, perception, localization and planning\",\n        \"Random search for hyper-parameter optimization\",\n        \"Introduction to neural networks with Java\",\n        \"Deep learning using rectified linear units (relu)\",\n        \"On the properties of the softmax function with application in game theory and reinforcement learning\",\n        \"On the importance of initialization and momentum in deep learning\",\n        \"A dissection of overfitting and generalization in continuous reinforcement learning\",\n        \"Power comparisons of shapiro-wilk, kolmogorov-smirnov, lilliefors and anderson-darling tests\",\n        \"Kruskal-wallis test\",\n        \"Comparing individual means in the analysis of variance\"\n    ],\n    \"reasoning\": \"Selected these 58 references because they represent foundational work and recent advances in Q-Learning Based System for Path Planning with UAV Swarms in Obstacle Environments, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}