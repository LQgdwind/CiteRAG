{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 44 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: CiFlow: Dataflow Analysis and Optimization of Key Switching for Homomorphic Encryption\n\nPaper Abstract: Abstract Homomorphic encryption (HE) is a privacy-preserving computation technique that enables computation on encrypted data. Today, the potential of HE remains largely unrealized as it is impractically slow, preventing it from being used in real applications. A major computational bottleneck in HE is the key-switching operation, accounting for approximately 70% of the overall HE execution time and involving a large amount of data for inputs, intermediates, and keys. Prior research has focused on hardware accelerators to improve HE performance, typically featuring large on-chip SRAMs and high off-chip bandwidth to deal with large scale data. In this paper, we present a novel approach to improve key-switching performance by rigorously analyzing its dataflow. Our primary goal is to optimize data reuse with limited on-chip memory to minimize off-chip data movement. We introduce three distinct dataflows: Max-Parallel (MP), Digit-Centric (DC), and Output-Centric (OC), each with unique scheduling approaches for key-switching computations. Through our analysis, we show how our proposed Output-Centric technique can effectively reuse data by significantly lowering the intermediate key-switching working set and alleviating the need for massive off-chip bandwidth. We thoroughly evaluate the three dataflows using the RPU, a recently published vector processor tailored for ring processing algorithms, which includes HE. This evaluation considers sweeps of bandwidth and computational throughput, and whether keys are buffered on-chip or streamed. With OC, we demonstrate up to 4.16×\\times speedup over the MP dataflow and show how OC can save 16×\\times on-chip SRAM by streaming keys for minimal performance penalty.\n\n{retrieved_text}\n\nGenerate exactly 44 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 44\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Fully homomorphic encryption using ideal lattices\",\n        \"(leveled) fully homomorphic encryption without bootstrapping\",\n        \"Fully homomorphic encryption without modulus switching from classical gapsvp\",\n        \"Somewhat practical fully homomorphic encryption\",\n        \"Homomorphic encryption for arithmetic of approximate numbers\",\n        \"Openfhe: Open-source fully homomorphic encryption library.\",\n        \"Lattigo 1.3.0.\",\n        \"Microsoft SEAL (release 4.1).\",\n        \"Cheetah: Optimizing and accelerating homomorphic encryption for private inference\",\n        \"F1: A fast and programmable accelerator for fully homomorphic encryption\",\n        \"Reed: Chiplet-based scalable hardware accelerator for fully homomorphic encryption\",\n        \"Tensorfhe: Achieving practical computation on encrypted data using gpgpu\",\n        \"Craterlake: a hardware accelerator for efficient unbounded computation on encrypted data\",\n        \"Rpu: The ring processing unit\",\n        \"Bts: An accelerator for bootstrappable fully homomorphic encryption\",\n        \"Ark: Fully homomorphic encryption accelerator with runtime data generation and inter-operation key reuse\",\n        \"Better bootstrapping for approximate homomorphic encryption\",\n        \"Low-complexity deep convolutional neural networks on fully homomorphic encryption using multiplexed parallel convolutions\",\n        \"Does fully homomorphic encryption need compute acceleration?\",\n        \"Fab: An fpga-based accelerator for bootstrappable fully homomorphic encryption\",\n        \"A full rns variant of approximate homomorphic encryption\",\n        \"Sharp: A short-word hierarchical accelerator for robust and practical fully homomorphic encryption\",\n        \"Lattigo: A multiparty homomorphic encryption library in go\",\n        \"Mad: Memory-aware design techniques for accelerating fully homomorphic encryption\",\n        \"Palladium Emulation.\",\n        \"A hybrid of dual and meet-in-the-middle attack on sparse and ternary secret lwe\",\n        \"Efficient bootstrapping for approximate homomorphic encryption with non-sparse keys\",\n        \"DARPA DPRIVE Broad Agency Announcement (BAA), HR001120S0032.\",\n        \"Over 100x faster bootstrapping in fully homomorphic encryption through memory-centric optimization with gpus\",\n        \"Hyphen: A hybrid packing method and optimizations for homomorphic encryption-based neural networks\",\n        \"Optimized privacy-preserving cnn inference with fully homomorphic encryption\",\n        \"Characterizing and optimizing end-to-end systems for private inference\",\n        \"Towards Fast and Scalable Private Inference\",\n        \"Chet: compiler and runtime for homomorphic evaluation of tensor programs\",\n        \"Eva: An encrypted vector arithmetic language and compiler for efficient homomorphic computation\",\n        \"Orion: A fully homomorphic encryption compiler for private deep neural network inference\",\n        \"Efficient bootstrapping for approximate homomorphic encryption with non-sparse keys.\",\n        \"High-performance fv somewhat homomorphic encryption on gpus: An implementation using cuda\",\n        \"Accelerating number theoretic transformations for bootstrappable homomorphic encryption on GPUs\",\n        \"Gme: Gpu-based microarchitectural extensions to accelerate homomorphic encryption\",\n        \"Accelerating polynomial multiplication for homomorphic encryption on gpus\",\n        \"Poseidon: Practical homomorphic encryption accelerator\",\n        \"An fpga-based programmable vector engine for fast fully homomorphic encryption over the torus\",\n        \"Fxhenn: Fpga-based acceleration framework for homomorphic encrypted cnn inference\"\n    ],\n    \"reasoning\": \"Selected these 44 references because they represent foundational work and recent advances in CiFlow: Dataflow Analysis and Optimization of Key Switching for Homomorphic Encryption, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}