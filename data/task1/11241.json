{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 50 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Hilbert Functions and Low-Degree Randomness Extractors\n\nPaper Abstract: Abstract For S⊆𝔽n𝑆superscript𝔽𝑛S\\subseteq\\mathbb{F}^{n}, consider the linear space of restrictions of degree-d𝑑d polynomials to S𝑆S. The Hilbert function of S𝑆S, denoted hS​(d,𝔽)subscripth𝑆𝑑𝔽\\mathrm{h}_{S}(d,\\mathbb{F}), is the dimension of this space. We obtain a tight lower bound on the smallest value of the Hilbert function of subsets S𝑆S of arbitrary finite grids in 𝔽nsuperscript𝔽𝑛\\mathbb{F}^{n} with a fixed size |S|𝑆|S|. We achieve this by proving that this value coincides with a combinatorial quantity, namely the smallest number of low Hamming weight points in a down-closed set of size |S|𝑆|S|. Understanding the smallest values of Hilbert functions is closely related to the study of degree-d𝑑d closure of sets, a notion introduced by Nie and Wang (Journal of Combinatorial Theory, Series A, 2015). We use bounds on the Hilbert function to obtain a tight bound on the size of degree-d𝑑d closures of subsets of 𝔽qnsuperscriptsubscript𝔽𝑞𝑛\\mathbb{F}_{q}^{n}, which answers a question posed by Doron, Ta-Shma, and Tell (Computational Complexity, 2022). We use the bounds on the Hilbert function and degree-d𝑑d closure of sets to prove that a random low-degree polynomial is an extractor for samplable randomness sources. Most notably, we prove the existence of low-degree extractors and dispersers for sources generated by constant-degree polynomials and polynomial-size circuits. Until recently, even the existence of arbitrary deterministic extractors for such sources was not known.\n\n{retrieved_text}\n\nGenerate exactly 50 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 50\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Low-degree polynomials extract from local sources\",\n        \"Low-degree polynomials are good extractors\",\n        \"Generalized Hamming weights of affine Cartesian codes\",\n        \"Random low-degree polynomials are hard to approximate\",\n        \"Sparse extractor families for all the entropy\",\n        \"On the bias of Reed–Muller codes over odd prime fields\",\n        \"Independent unbiased coin flips from a correlated biased source—a finite state Markov chain\",\n        \"What can be computed in algebraic geometry?\",\n        \"Unbiased bits from sources of weak randomness and probabilistic communication complexity\",\n        \"Extractors for polynomial sources over 𝔽2subscript𝔽2\\\\mathbb{F}_{2}\",\n        \"Randomness extraction in AC0superscriptAC0\\\\textrm{AC}^{0} and with small locality\",\n        \"Ideals, varieties, and algorithms: an introduction to computational algebraic geometry and commutative algebra\",\n        \"Two structural results for low degree polynomials and applications\",\n        \"On the (im)possibility of cryptography with imperfect randomness\",\n        \"On hitting-set generators for polynomials that vanish rarely\",\n        \"Extractors and lower bounds for locally samplable sources\",\n        \"Doubly-affine extractors, and their applications\",\n        \"Gröbner theory of zero dimensional ideals with a view toward combinatorics\",\n        \"On randomness extraction in AC0superscriptAC0\\\\text{AC}^{0}\",\n        \"Some classes of linear codes: observations about their structure, construction, (non-)existence and decoding\",\n        \"Affine extractors and AC0superscriptAC0\\\\text{AC}^{0}-parity\",\n        \"Probability inequalities for sums of bounded random variables\",\n        \"Generalized Hamming weights of q𝑞q-ary Reed-Muller codes\",\n        \"Uncertainty principles, extractors, and explicit embeddings of L2 into L1\",\n        \"Weight distribution and list-decoding size of Reed–Muller codes\",\n        \"Set systems with restricted cross-intersections and the minimum rank ofinclusion matrices\",\n        \"Certifying polynomials for AC0​[⊕]superscriptAC0delimited-[]direct-sum\\\\mathrm{AC}^{0}[\\\\oplus] circuits, with applications to lower bounds and circuit compression\",\n        \"Two source extractors for asymptotically optimal entropy, and (many) more\",\n        \"3.1​n−o​(n)3.1𝑛𝑜𝑛3.1n-o(n) circuit lower bounds for explicit functions\",\n        \"Shattered sets and the Hilbert function\",\n        \"Probability and Computing: Randomization and Probabilistic Techniques in Algorithms and Data Analysis\",\n        \"Hilbert functions and the finite degree Zariski closure in finite field combinatorial geometry\",\n        \"Randomness is linear in space\",\n        \"Parity helps to compute majority\",\n        \"Lower bounds on the size of bounded depth circuits over a complete basis with logical addition\",\n        \"The Hilbert function, algebraic extractors, and recursive Fourier sampling\",\n        \"Algebraic methods in the theory of lower bounds for Boolean circuit complexity\",\n        \"On representations by low-degree polynomials\",\n        \"A robust version of Hegedűs’s lemma, with applications\",\n        \"Generating quasi-random sequences from semi-random sources\",\n        \"Extractor codes\",\n        \"Extracting randomness from samplable distributions\",\n        \"Constructing locally computable extractors and cryptosystems in the bounded-storage model\",\n        \"The complexity of constructing pseudorandom generators from hard functions\",\n        \"The complexity of distributions\",\n        \"Extractors for circuit sources\",\n        \"Quadratic maps are hard to sample\",\n        \"Generalized Hamming weights for linear codes\",\n        \"Expanders that beat the eigenvalue bound: Explicit construction and applications\",\n        \"Linear degree extractors and the inapproximability of max clique and chromatic number\"\n    ],\n    \"reasoning\": \"Selected these 50 references because they represent foundational work and recent advances in Hilbert Functions and Low-Degree Randomness Extractors, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}