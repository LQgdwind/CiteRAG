{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 53 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: PronounFlow: A Hybrid Approach for Calibrating Pronouns in Sentences\n\nPaper Abstract: Abstract Flip through any book or listen to any song lyrics, and you will come across pronouns that, in certain cases, can hinder meaning comprehension, especially for machines. As the role of having cognitive machines becomes pervasive in our lives, numerous systems have been developed to resolve pronouns under various challenges. Commensurate with this, it is believed that having systems able to disambiguate pronouns in sentences will help towards the endowment of machines with commonsense and reasoning abilities like those found in humans. However, one problem these systems face with modern English is the lack of gender pronouns, where people try to alternate by using masculine, feminine, or plural to avoid the whole issue. Since humanity aims to the building of systems in the full-bodied sense we usually reserve for people, what happens when pronouns in written text, like plural or epicene ones, refer to unspecified entities whose gender is not necessarily known? Wouldn’t that put extra barriers to existing coreference resolution systems? Towards answering those questions, through the implementation of a neural-symbolic system that utilizes the best of both worlds, we are employing PronounFlow, a system that reads any English sentence with pronouns and entities, identifies which of them are not tied to each other, and makes suggestions on which to use to avoid biases. Undertaken experiments show that PronounFlow not only alternates pronouns in sentences based on the collective human knowledge around us but also considerably helps coreference resolution systems with the pronoun disambiguation process.\n\n{retrieved_text}\n\nGenerate exactly 53 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 53\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Language unlimited: The science behind our most creative power\",\n        \"The influence of technology on english language and literature\",\n        \"Establishing a human baseline for the winograd schema challenge\",\n        \"How conservative are language models? adapting to the introduction of gender-neutral pronouns\",\n        \"Comprehension of anaphoric pronouns\",\n        \"Speak, memory: An archaeology of books known to chatgpt/gpt-4.\",\n        \"It depends: Dependency parser comparison using a web-based evaluation tool\",\n        \"Pronoun disambiguation: Accessing potential antecedents\",\n        \"The stanford typed dependencies representation\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Back to square one: Artifact detection, training and commonsense disentanglement in the winograd schema\",\n        \"A knowledge hunting framework for common sense reasoning\",\n        \"A marker passing approach to winograd schemas\",\n        \"Investigating differences in general comprehension skill\",\n        \"Masked autoencoders are scalable vision learners\",\n        \"A hybrid neural network model for commonsense reasoning\",\n        \"Resolving pronoun references\",\n        \"Tackling domain-specific winograd schemas with knowledge-based reasoning and machine learning\",\n        \"Universal language model fine-tuning for text classification.\",\n        \"Blending dependency parsers with language models\",\n        \"A neural-symbolic approach towards identifying grammatically correct sentences.\",\n        \"Tackling the Winograd Schema Challenge Through Machine Logical Inferences\",\n        \"Winventor: A machine-driven approach for the development of winograd schemas\",\n        \"Blending nlp and machine learning for the development of winograd schemas\",\n        \"Attention is (not) all you need for commonsense reasoning\",\n        \"A Surprisingly Robust Trick for Winograd Schema Challenge\",\n        \"The defeat of the winograd schema challenge\",\n        \"Welcome to the modern world of pronouns: Identity-inclusive natural language processing beyond gender.\",\n        \"The Winograd Schema Challenge\",\n        \"On Our Best behaviour\",\n        \"Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.\",\n        \"Reducing a male bias in language? establishing the efficiency of three different gender-fair language strategies.\",\n        \"Roberta: A robustly optimized bert pretraining approach\",\n        \"Readers’ perceptions of four alternatives to masculine generic pronouns\",\n        \"Alternating between masculine and feminine pronouns: Does essay topic affect readers’ perceptions?\",\n        \"The stanford corenlp natural language processing toolkit\",\n        \"A guide to neopronouns\",\n        \"Rebooting AI: Building artificial intelligence we can trust\",\n        \"A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, August 31, 1955\",\n        \"Inference during reading\",\n        \"Gender and ethnicity attributions to a gender-and ethnicity-unspecified individual: Is there a people= white male bias?\",\n        \"Reading between the lines\",\n        \"Robust Pronoun Resolution with Limited Knowledge\",\n        \"Dependency grammar and dependency parsing\",\n        \"Improving language understanding by generative pre-training.\",\n        \"Exploring the limits of transfer learning with a unified text-to-text transformer\",\n        \"Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge\",\n        \"Winogrande: An adversarial winograd schema challenge at scale.\",\n        \"Neural machine translation doesn’t translate gender coreference right unless you make it.\",\n        \"Tackling winograd schemas by formalizing relevance theory in knowledge graphs\",\n        \"Towards Addressing the Winograd Schema Challenge - Building and Using a Semantic Parser and a Knowledge Hunting Module\",\n        \"Perceptions of technology use and its effects on student writing.\",\n        \"A simple method for commonsense reasoning.\"\n    ],\n    \"reasoning\": \"Selected these 53 references because they represent foundational work and recent advances in PronounFlow: A Hybrid Approach for Calibrating Pronouns in Sentences, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}