{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 51 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Deep intrinsic decomposition trained on surreal scenes yet with realistic light effects\n\nPaper Abstract: Abstract Estimation of intrinsic images still remains a challenging task due to weaknesses of ground-truth datasets, which either are too small, or present non-realistic issues. On the other hand, end-to-end deep learning architectures start to achieve interesting results that we believe could be improved if important physical hints were not ignored. In this work we present a twofold framework: (a) a flexible generation of images overcoming some classical dataset problems like larger size jointly with coherent lighting appearance; and (b) a flexible architecture tying physical properties through intrinsic losses. Our proposal is versatile, presents low computation time and achieves state-of-art results.\n\n{retrieved_text}\n\nGenerate exactly 51 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 51\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Recovering intrinsic scene characteristics\",\n        \"Ground-truth dataset and baseline evaluations for intrinsic image algorithms\",\n        \"Intrinsic images in the wild\",\n        \"A naturalistic open source movie for optical flow evaluation\",\n        \"Learning non-lambertian object intrinsics across shapenet categories\",\n        \"CNN based learning using reflection and retinex models for intrinsic image decomposition\",\n        \"Joint learning of intrinsic images and semantic segmentation\",\n        \"Cgintrinsics: Better intrinsic image decomposition through physically-based rendering\",\n        \"Shapenet: An information-rich 3d model repository\",\n        \"Lightness and retinex theory\",\n        \"Determining lightness from an image\",\n        \"Deriving intrinsic images from image sequences\",\n        \"Recovering intrinsic images from a single image\",\n        \"Estimating intrinsic component images using non-linear regression\",\n        \"Recovering shading from color images\",\n        \"Recovering intrinsic images with a global sparsity prior on reflectance\",\n        \"Intrinsic image decomposition using a sparse representation of reflectance\",\n        \"Shape, illumination, and reflectance from shading\",\n        \"Names and shades of color for intrinsic image estimation\",\n        \"Intrinsic scene properties from a single rgb-d image\",\n        \"Estimation of intrinsic image sequences from image depth video\",\n        \"A simple model for intrinsic image decomposition with depth cues\",\n        \"Intrinsic image decomposition using structure-texture separation and surface normals\",\n        \"Estimating intrinsic images from image sequences with biased illumination\",\n        \"Intrinsic decomposition of image sequences from local temporal variations\",\n        \"Direct intrinsics: Learning albedo-shading decomposition by convolutional regression\",\n        \"Depth map prediction from a single image using a multi-scale deep network\",\n        \"Learning data-driven reflectance priors for intrinsic image decomposition\",\n        \"Scene intrinsics and depth from a single image\",\n        \"Deep convolutional neural fields for depth estimation from a single image\",\n        \"Unified depth prediction and intrinsic image decomposition from a single image via joint convolutional neural fields\",\n        \"Reflectance adaptive filtering improves intrinsic image estimation\",\n        \"Generative adversarial nets\",\n        \"Darn: A deep adversarial residual network for intrinsic image decomposition\",\n        \"Single image intrinsic decomposition without a single intrinsic image\",\n        \"Signature verification using a siamese time delay neural network\",\n        \"Learning intrinsic image decomposition from watching the world\",\n        \"Revisiting deep intrinsic image decompositions\",\n        \"Multi-view multi-illuminant intrinsic dataset\",\n        \"Semantic scene completion from a single depth image\",\n        \"Interiornet: Mega-scale multi-sensor photo-realistic indoor scenes dataset\",\n        \"Color-based data augmentation for reflectance estimation\",\n        \"Corel datasets\",\n        \"Rethinking the inception architecture for computer vision\",\n        \"Keras\",\n        \"Deep residual learning for image recognition\",\n        \"Adam: A method for stochastic optimization.\",\n        \"Intrinsic images decomposition using a local and global sparse representation of reflectance\",\n        \"Intrinsic images by clustering\",\n        \"A closed-form solution to retinex with nonlocal texture constraints\",\n        \"An l1 image transform for edge-preserving smoothing and scene-level intrinsic decomposition\"\n    ],\n    \"reasoning\": \"Selected these 51 references because they represent foundational work and recent advances in Deep intrinsic decomposition trained on surreal scenes yet with realistic light effects, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}