{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 49 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: 1 Introduction\n\nPaper Abstract: Abstract Speaker embeddings represent a means to extract representative vectorial representations from a speech signal such that the representation pertains to the speaker identity alone. The embeddings are commonly used to classify and discriminate between different speakers. However, there is no objective measure to evaluate the ability of a speaker embedding to disentangle the speaker identity from the other speech characteristics. This means that the embeddings are far from ideal, highly dependent on the training corpus and still include a degree of residual information pertaining to factors such as linguistic content, recording conditions or speaking style of the utterance. This paper introduces an analysis over six sets of speaker embeddings extracted with some of the most recent and high-performing deep neural network (DNN) architectures, and in particular, the degree to which they are able to truly disentangle the speaker identity from the speech signal. To correctly evaluate the architectures, a large multi-speaker parallel speech dataset is used. The dataset includes 46 speakers uttering the same set of prompts, recorded in either a professional studio or their home environments. The analysis looks into the intra- and inter-speaker similarity measures computed over the different embedding sets, as well as if simple classification and regression methods are able to extract several residual information factors from the speaker embeddings. The results show that the discriminative power of the analyzed embeddings is very high, yet across all the analyzed architectures, residual information is still present in the representations in the form of a high correlation to the recording conditions, linguistic contents and utterance duration. However, we show that this correlation, although not ideal, could still be useful in downstream tasks. The low-dimensional projections of the speaker embeddings show similar behavior patterns across the embedding sets with respect to intra-speaker data clustering and utterance outlier detection.\n\n{retrieved_text}\n\nGenerate exactly 49 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 49\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis\",\n        \"Speaker Generation\",\n        \"Automatic speaker verification using cepstral measurements\",\n        \"Cepstral analysis technique for automatic speaker verification\",\n        \"Experimental Study on GMM-Based Speaker Recognition\",\n        \"Spectral-Subtraction Based Features for Speaker Identification\",\n        \"Improving speaker identification robustness to highly channel-degraded speech through multiple system fusion\",\n        \"Developing a speaker identification system for the DARPA RATS project\",\n        \"A Gaussian Mixture Modeling Approach to Text-Independent Speaker Identification\",\n        \"Robust text-independent speaker identification using Gaussian mixture speaker models\",\n        \"Speaker Verification Using Adapted Gaussian Mixture Models\",\n        \"Support vector machines using GMM supervectors for speaker verification\",\n        \"Exploiting PCA classifiers to speaker recognition\",\n        \"Front-End Factor Analysis for Speaker Verification\",\n        \"Learning Speaker-Specific Characteristics With a Deep Neural Architecture\",\n        \"Reducing the Dimensionality of Data with Neural Networks\",\n        \"X-Vectors: Robust DNN Embeddings for Speaker Recognition\",\n        \"x-Vector DNN Refinement with Full-Length Recordings for Speaker Recognition\",\n        \"Multi-Task Learning with High-Order Statistics for x-Vector Based Text-Independent Speaker Verification\",\n        \"RawNet: Advanced End-to-End Deep Neural Network Using Raw Waveforms for Text-Independent Speaker Verification\",\n        \"Improved RawNet with Feature Map Scaling for Text-Independent Speaker Verification Using Raw Waveforms\",\n        \"In defence of metric learning for speaker recognition\",\n        \"The ins and outs of speaker recognition: Lessons from VoxSRC 2020\",\n        \"The IDLAB VoxCeleb Speaker Recognition Challenge 2020 System Description\",\n        \"Fine-Tuning Wav2Vec2 for Speaker Recognition\",\n        \"Speaker recognition based on deep learning: An overview\",\n        \"Deep Speaker Recognition: Process, Progress, and Challenges\",\n        \"ID R&D System Description to VoxCeleb Speaker Recognition Challenge 2022\",\n        \"The Kriston AI System for the VoxCeleb Speaker Recognition Challenge 2022\",\n        \"The ReturnZero System for VoxCeleb Speaker Recognition Challenge 2022\",\n        \"The HCCL system for VoxCeleb Speaker Recognition Challenge 2022\",\n        \"SC-GlowTTS: An Efficient Zero-Shot Multi-Speaker Text-To-Speech Model\",\n        \"Zero-Shot Multi-Speaker Text-To-Speech with State-Of-The-Art Neural Speaker Embeddings\",\n        \"Language Agnostic Speaker Embedding for Cross-Lingual Personalized Speech Generation\",\n        \"Whispered and Lombard Neural Speech Synthesis\",\n        \"Transfer Learning From Speech Synthesis to Voice Conversion With Non-Parallel Training Data\",\n        \"The SWARA Speech Corpus: A Large Parallel Romanian Read Speech Dataset\",\n        \"Pyannote.audio: Neural building blocks for speaker diarization\",\n        \"End-to-end speaker segmentation for overlap-aware resegmentation\",\n        \"Speaker Recognition from Raw Waveform with SincNet\",\n        \"SpeechBrain: A General-Purpose Speech Toolkit\",\n        \"ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification\",\n        \"TitaNet: Neural Model for speaker representation with 1D Depth-wise separable convolutions and global context\",\n        \"ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context\",\n        \"SpeakerNet: 1D Depth-wise Separable Convolutional Network for Text-Independent Speaker Recognition and Verification\",\n        \"ECAPA-TDNN Embeddings for Speaker Diarization\",\n        \"LightGBM: A Highly Efficient Gradient Boosting Decision Tree\",\n        \"Robust signal-to-noise ratio estimation based on waveform amplitude distribution analysis\",\n        \"Visualizing High-Dimensional Data Using t-SNE\"\n    ],\n    \"reasoning\": \"Selected these 49 references because they represent foundational work and recent advances in 1 Introduction, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}