{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 65 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Analyzing the relationship between text features and grants productivity\n\nPaper Abstract: Abstract Predicting the output of research grants is of considerable relevance to research funding bodies, scientific entities and government agencies. In this study, we investigate whether text features extracted from projects title and abstracts are able to identify productive grants. Our analysis was conducted in three distinct areas, namely Medicine, Dentistry and Veterinary Medicine. Topical and complexity text features were used to identify predictors of productivity. The results indicate that there is a statistically significant relationship between text features and grants productivity, however such a dependence is weak. A feature relevance analysis revealed that the abstract text length and metrics derived from lexical diversity are among the most discriminative features. We also found that the prediction accuracy has a dependence on the considered project language and that topical features are more discriminative than text complexity measurements. Our findings suggest that text features should be used in combination with other features to assist the identification of relevant research ideas.\n\n{retrieved_text}\n\nGenerate exactly 65 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 65\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Predicting scientific success\",\n        \"Comparing the topological properties of real and artificially generated scientific manuscripts\",\n        \"Probing the topological properties of complex networks modeling short written texts\",\n        \"Complex networks analysis of language complexity\",\n        \"Three-feature model to reproduce the topology of citation networks and the effects from authors’ visibility on their h-index\",\n        \"A systematic comparison of supervised classifiers\",\n        \"Concentric network symmetry grasps authors’ styles in word adjacency networks\",\n        \"Strong correlations between text quality and complex networks features\",\n        \"Using complex networks for text classification: Discriminating informative and imaginative documents\",\n        \"Toward predicting research proposal success\",\n        \"Random forests\",\n        \"Le vocabulaire de Jean Giraudoux. Structure et évolution.\",\n        \"Reviewers’ ratings and bibliometric indicators: Hand in hand when assessing over research proposals?\",\n        \"Introduction to algorithms\",\n        \"Patterns of authors contribution in scientific manuscripts\",\n        \"Word sense disambiguation: A complex network approach\",\n        \"Using machine learning techniques for rising star prediction in co-author network\",\n        \"Statistical comparisons of classifiers over multiple data sets\",\n        \"Which factors help authors produce the highest impact research? collaboration, journal and document properties\",\n        \"Effective dissemination requires effective talk: a comparison of behavior-analytic journals\",\n        \"Scientific collaboration and endorsement: Network analysis of coauthorship and citation networks\",\n        \"Pattern classification\",\n        \"Characterizing and modeling citation dynamics\",\n        \"Nih peer review percentile scores are poorly predictive of grant productivity\",\n        \"Science of science\",\n        \"Learning scikit-learn: machine learning in python\",\n        \"Healing the nih-funded biomedical research enterprise\",\n        \"Coh-metrix: Analysis of text on cohesion and language\",\n        \"Fundamentals of artificial neural networks\",\n        \"A concept for inferring ‘frontier research’ in grant proposals\",\n        \"Social media-based sleeping beauties: Defining, identifying and features\",\n        \"Peer review: crude and understudied, but indispensable\",\n        \"Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel\",\n        \"Peer to peer lending: The relationship between language features, trustworthiness, and persuasion success\",\n        \"Deep learning\",\n        \"The advantage of short paper titles\",\n        \"The advantage of simple paper abstracts\",\n        \"Indicators of the interdisciplinarity of journals: Diversity, centrality, and citations\",\n        \"Interdisciplinarity as diversity in citation patterns among journals: Rao-stirling diversity, relative variety, and the gini coefficient\",\n        \"Big names or big ideas: Do peer-review panels select the best science proposals?\",\n        \"A learning method for the class imbalance problem with medical data sets\",\n        \"Introduction to information retrieval\",\n        \"The writing style of predatory publishers\",\n        \"What words are worth: National science foundation grant abstracts indicate award funding\",\n        \"Predicting the impact of scientific concepts using full-text features\",\n        \"A survey of named entity recognition and classification\",\n        \"The revival of the gini importance?\",\n        \"Factors affecting citation rates of research articles\",\n        \"Articles with short titles describing the results are cited more often\",\n        \"When small words foretell academic success: The case of college admissions essays\",\n        \"A macro analysis of productivity differences across fields: Challenges in the measurement of scientific publishing\",\n        \"Statistical and methodological problems with concreteness and other semantic variables: A list memory experiment case study\",\n        \"Predicting the citation counts of individual papers via a bp neural network\",\n        \"Coh-metrix-port: a readability assessment tool for texts in brazilian portuguese\",\n        \"Using network science and text analytics to produce surveys in a scientific topic\",\n        \"Word sense disambiguation via high order of learning in complex networks\",\n        \"Modelling early word acquisition through multiplex lexical networks and machine learning\",\n        \"Forma mentis networks map how nursing and engineering students enhance their mindsets about innovation and health during professional growth\",\n        \"Forma mentis networks quantify crucial differences in stem perception between students and experts\",\n        \"Could scientists use altmetric. com scores to predict longer term citation counts?\",\n        \"Do declarative titles affect readers’ perceptions of research findings? a randomized trial\",\n        \"Quantifying long-term scientific impact\",\n        \"Measuring the preferential attachment mechanism in citation networks\",\n        \"Modeling the citation network by network cosmology\",\n        \"The science of science: From the perspective of complex systems\"\n    ],\n    \"reasoning\": \"Selected these 65 references because they represent foundational work and recent advances in Analyzing the relationship between text features and grants productivity, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}