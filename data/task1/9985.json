{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 45 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: AIM: Accelerating Arbitrary-precision Integer Multiplication on Heterogeneous Reconfigurable Computing Platform Versal ACAP\n\nPaper Abstract: Abstract Arbitrary-precision integer multiplication is the core kernel of many applications including scientific computing, cryptographic algorithms, etc. Existing acceleration of arbitrary-precision integer multiplication includes CPUs, GPUs, FPGAs, and ASICs. To leverage the hardware intrinsics low-bit function units (32/64-bit), arbitrary-precision integer multiplication can be calculated using Karatsuba decomposition, and Schoolbook decomposition by decomposing the two large operands into several small operands, generating a set of low-bit multiplications that can be processed either in a spatial or sequential manner on the low-bit function units, e.g., CPU vector instructions, GPU CUDA cores, FPGA digital signal processing (DSP) blocks. Among these accelerators, reconfigurable computing, e.g., FPGA accelerators are promised to provide both good energy efficiency and flexibility. We implement the state-of-the-art (SOTA) FPGA accelerator and compare it with the SOTA libraries on CPUs and GPUs. Surprisingly, in terms of energy efficiency, we find that the FPGA has the lowest energy efficiency, i.e., 0.29x of the CPU and 0.17x of the GPU with the same generation fabrication. Therefore, key questions arise: Where do the energy efficiency gains of CPUs and GPUs come from? Can reconfigurable computing do better? If can, how to achieve that? We first identify that the biggest energy efficiency gains of the CPUs and GPUs come from the dedicated vector units, i.e., vector instruction units in CPUs and CUDA cores in GPUs. FPGA uses DSPs and lookup tables (LUTs) to compose the needed computation, which incurs overhead when compared to using vector units directly. New reconfigurable computing, e.g., “FPGA+vector units” is a novel and feasible solution to improve energy efficiency. In this paper, we propose to map arbitrary-precision integer multiplication onto such a “FPGA+vector units” platform, i.e., AMD/Xilinx Versal ACAP architecture, a heterogeneous reconfigurable computing platform that features 400 AI engine tensor cores (AIE) running at 1 GHz, FPGA programmable logic (PL), and a general-purpose CPU in the system fabricated with the TSMC 7nm technology. Designing on Versal ACAP incurs several challenges and we propose AIM: Arbitrary-precision Integer Multiplication on Versal ACAP to automate and optimize the design. AIM accelerator is composed of AIEs, PL, and CPU. AIM framework includes analytical models to guide design space exploration and AIM automatic code generation to facilitate the system design and on-board design verification. We deploy the AIM framework on three different applications, including large integer multiplication (LIM), RSA, and Mandelbrot, on the AMD/Xilinx Versal ACAP VCK190 evaluation board. Our experimental results show that compared to existing accelerators, AIM achieves up to 12.6x, and 2.1x energy efficiency gains over the Intel Xeon Ice Lake 6346 CPU, and NVidia A5000 GPU respectively, which brings reconfigurable computing the most energy-efficient platform among CPUs and GPUs.\n\n{retrieved_text}\n\nGenerate exactly 45 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 45\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"High-precision computation: Mathematical physics and dynamics\",\n        \"A method for obtaining digital signatures and public-key cryptosystems\",\n        \"Recommendation for Key Management, Part 1: General.\",\n        \"Elliptic curve cryptography point multiplication core for hardware security module\",\n        \"Generalizations of the karatsuba algorithm for efficient implementations\",\n        \"IMpress: Large Integer Multiplication Expression Rewriting for FPGA HLS\",\n        \"Time-memory trade-off in toom-cook multiplication: an application to module-lattice based cryptography\",\n        \"Customizable domain-specific computing\",\n        \"FPGA HLS today: successes, challenges, and opportunities\",\n        \"Caffeine: Toward uniformed representation and acceleration for deep convolutional neural networks\",\n        \"Democratizing domain-specific computing\",\n        \"Alveo U250 Data Center Accelerator Card .\",\n        \"Intel Software Development Emulator (Intel SDE) .\",\n        \"Get Started with Intel VTune Profiler .\",\n        \"Intel Core i9-10900X X-series Processor .\",\n        \"Intel 64 and IA-32 Architectures Optimization Reference Manual.\",\n        \"Intel Xeon Gold 6346 Processor .\",\n        \"New 3rd gen intel xeon scalable processor (codename: Ice lake-sp).\",\n        \"NVIDIA TESLA V100 GPU ARCHITECTURE.\",\n        \"NVIDIA AMPERE GA102 GPU ARCHITECTURE.\",\n        \"Xilinx Versal: The First Adaptive Compute Acceleration Platform (ACAP).\",\n        \"Cambricon-p: A bitflow architecture for arbitrary precision computing\",\n        \"On the minimum computation time of functions\",\n        \"Acceleration of large integer multiplication with intel avx-512 instructions\",\n        \"Accelerating big integer arithmetic using intel ifma extensions\",\n        \"Fast modular squaring with avx512ifma\",\n        \"NVlabs/CGBN: CGBN: CUDA Accelerated Multiple Precision Arithmetic (Big Num) using Cooperative Groups.\",\n        \"Efficient high-precision integer multiplication on the gpu\",\n        \"Accelerating number theoretic transform in gpu platform for fully homomorphic encryption\",\n        \"Vitis Security HLS.\",\n        \"Folded integer multiplication for fpgas\",\n        \"Vitis HLS.\",\n        \"Parametric throughput oriented large integer multipliers for high level synthesis\",\n        \"Low-latency asic algorithms of modular squaring of large integers for vdf evaluation\",\n        \"CHARM: Composing Heterogeneous AcceleRators for Matrix Multiply on Versal ACAP Architecture\",\n        \"High Performance, Low Power Matrix Multiply Design on ACAP: from Architecture, Design Challenges and DSE Perspectives\",\n        \"H-gcn: A graph convolutional network accelerator on versal acap architecture\",\n        \"Sparta: Spatial acceleration for efficient and scalable horizontal diffusion weather stencil computation\",\n        \"Exploring the versal ai engines for accelerating stencil-based atmospheric advection simulation\",\n        \"AMD Vivado.\",\n        \"AMD AI Engine Tools and Flows User Guide (UG1076).\",\n        \"Versal AI Core Series.\",\n        \"AMD BEAM Tool,\",\n        \"System Management Interface SMI — NVIDIA Developer.\",\n        \"Semiconductor design and manufacturing: Achieving leading-edge capabilities.\"\n    ],\n    \"reasoning\": \"Selected these 45 references because they represent foundational work and recent advances in AIM: Accelerating Arbitrary-precision Integer Multiplication on Heterogeneous Reconfigurable Computing Platform Versal ACAP, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}