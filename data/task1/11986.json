{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 46 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction\n\nPaper Abstract: Abstract There are two issues in news-driven multi-stock movement prediction tasks that are not well solved in the existing works. On the one hand, “relation discovery” is a pivotal part when leveraging the price information of other stocks to achieve accurate stock movement prediction. Given that stock relations are often unidirectional, such as the “supplier-consumer” relationship, causal relations are more appropriate to capture the impact between stocks. On the other hand, there is substantial noise existing in the news data leading to extracting effective information with difficulty. With these two issues in mind, we propose a novel framework called CausalStock for news-driven multi-stock movement prediction, which discovers the temporal causal relations between stocks. We design a lag-dependent temporal causal discovery mechanism to model the temporal causal graph distribution. Then a Functional Causal Model is employed to encapsulate the discovered causal relations and predict the stock movements. Additionally, we propose a Denoised News Encoder by taking advantage of the excellent text evaluation ability of large language models (LLMs) to extract useful information from massive news data. The experiment results show that CausalStock outperforms the strong baselines for both news-driven multi-stock movement prediction and multi-stock movement prediction tasks on six real-world datasets collected from the US, China, Japan, and UK markets. Moreover, getting benefit from the causal relations, CausalStock could offer a clear prediction mechanism with good explainability.\n\n{retrieved_text}\n\nGenerate exactly 46 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 46\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Finbert: Financial sentiment analysis with pre-trained language models\",\n        \"Neural graphical modelling in continuous-time: consistency guarantees and algorithms\",\n        \"Variational inference: A review for statisticians\",\n        \"Sparks of artificial general intelligence: Early experiments with gpt-4\",\n        \"Causaltime: Realistically generated time-series for benchmarking of causal discovery\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"News or noise?\",\n        \"Enhancing stock movement prediction with adversarial training\",\n        \"Deep end-to-end causal inference\",\n        \"High-recall causal discovery for autocorrelated time series with latent confounders\",\n        \"Understanding the difficulty of training deep feedforward neural networks\",\n        \"Review of causal discovery methods based on graphical models\",\n        \"Multi-stage hybrid attentive networks for knowledge-driven stock movement prediction\",\n        \"Rhino: Deep causal temporal relationship learning with history-dependent noise\",\n        \"Listening to chaotic whispers: A deep learning framework for news-oriented stock trend prediction\",\n        \"Categorical reparameterization with gumbel-softmax\",\n        \"Applications of deep learning in stock market prediction: recent progress\",\n        \"Causal autoregressive flows\",\n        \"Hats: A hierarchical graph attention network for stock movement prediction\",\n        \"Adam: A method for stochastic optimization\",\n        \"Pen: Prediction-explanation network to forecast stock price movement with better explainability\",\n        \"Roberta: A robustly optimized bert pretraining approach\",\n        \"Causality-guided multi-memory interaction network for multivariate stock price movement prediction\",\n        \"The concrete distribution: A continuous relaxation of discrete random variables\",\n        \"Stock market’s price movement prediction with lstm neural networks\",\n        \"Dynotears: Structure learning from time-series data\",\n        \"Causal inference in statistics: An overview\",\n        \"A dual-stage attention-based recurrent neural network for time series prediction\",\n        \"Solving general arithmetic word problems\",\n        \"Discovering contemporaneous and lagged causal relations in autocorrelated nonlinear time series datasets\",\n        \"Detecting and quantifying causal associations in large nonlinear time series datasets\",\n        \"Deep attentive learning for stock movement prediction from social media text and company correlations\",\n        \"Textual analysis of stock market prediction using breaking financial news: The azfin text system\",\n        \"Temporal pattern attention for multivariate time series forecasting\",\n        \"Exploiting topic based twitter sentiment for stock prediction\",\n        \"The proof and measurement of association between two things\",\n        \"News or noise? using twitter to identify and understand company-specific news flow\",\n        \"News or noise? the stock market reaction to different types of company-specific news events\",\n        \"Llama: Open and efficient foundation language models\",\n        \"Coupling macro-sector-micro financial indicators for learning stock representations with less uncertainty\",\n        \"Natural language based financial forecasting: a survey\",\n        \"Stock movement prediction from tweets and historical prices\",\n        \"Fingpt: Open-source financial large language models\",\n        \"Accurate multivariate stock movement prediction via data-axis transformer with multi-level contexts\",\n        \"Stock price prediction via discovering multi-frequency trading patterns\",\n        \"Dags with no tears: Continuous optimization for structure learning\"\n    ],\n    \"reasoning\": \"Selected these 46 references because they represent foundational work and recent advances in CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}