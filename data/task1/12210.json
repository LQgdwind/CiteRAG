{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 48 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Flex-PE: Flexible and SIMD Multi-Precision Processing Element for AI Workloads\n\nPaper Abstract: Abstract The rapid adaptation of data-driven AI models, such as deep learning inference, training, Vision Transformers (ViTs), and other HPC applications, drives a strong need for run-time precision configurable different non-linear activation functions (AF) hardware support. Existing solutions support diverse precision or run-time AF reconfigurability but fail to address both simultaneously. This work proposes a flexible and SIMD multi-precision processing element (Flex-PE), which supports diverse run-time configurable AFs, including sigmoid, tanh, ReLU and softmax, in addition to MAC operation. The proposed design achieves an improved throughput of up to 16×\\times FxP4, 8×\\times FxP8, 4×\\times FxP16 and 1×\\times FxP32 in pipeline mode with 100% time-multiplexed hardware. This work proposes an area-efficient multi-precision iterative mode in the SIMD systolic arrays for edge-AI use cases. The design delivers superior performance with up to 62× and 371× reductions in DMA reads for input feature maps and weight filters in VGG-16, with an energy efficiency of 8.42 GOPS / W within the accuracy loss of 2%. The proposed architecture supports emerging 4-bit computations for DL inference while enhancing throughput in FxP8/16 modes for transformers and other HPC applications. The proposed approach enables a way for future energy-efficient AI accelerators in both edge and cloud environments.\n\n{retrieved_text}\n\nGenerate exactly 48 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 48\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A Reconfigurable Processing Element for Multiple-Precision Floating/Fixed-Point HPC\",\n        \"A Multi-Mode 8k-MAC HW-Utilization-Aware Neural Processing Unit With a Unified Multi-Precision Datapath in 4-nm Flagship Mobile SoC\",\n        \"Approximating activation function in a neural network with look-up table having hybrid architecture\",\n        \"Approximating activation functions with Taylor series\",\n        \"Accuracy-based approximation of activation functions with programmable look-up table having area budget\",\n        \"Efficient softmax computation\",\n        \"SoftAct: A High-Precision Softmax Architecture for Transformers Supporting Nonlinear Functions\",\n        \"Efficient CORDIC-Based Activation Functions for RNN Acceleration on FPGAs\",\n        \"Exploring Hardware Activation Function Design: CORDIC Architecture in Diverse Floating Formats\",\n        \"High-Precision Method and Architecture for Base-2 Softmax Function in DNN Training\",\n        \"ReAFM: A Reconfigurable Nonlinear Activation Function Module for Neural Networks\",\n        \"An Empirical Evaluation of Enhanced Performance Softmax Function in Deep Learning\",\n        \"A Unified Parallel CORDIC-Based Hardware Architecture for LSTM Network Acceleration\",\n        \"A CORDIC Based Configurable Activation Function for ANN Applications\",\n        \"Design Space Exploration of Neural Network Activation Function Circuits\",\n        \"Efficient Precision-Adjustable Architecture for Softmax Function in Deep Learning\",\n        \"A High-Speed and Low-Complexity Architecture for Softmax Function in Deep Learning\",\n        \"NullHop: A Flexible Convolutional Neural Network Accelerator Based on Sparse Representations of Feature Maps\",\n        \"An Efficient Hardware Accelerator for Structured Sparse Convolutional Neural Networks on FPGAs\",\n        \"An Efficient and Flexible Accelerator Design for Sparse Convolutional Neural Networks\",\n        \"Data multiplexed and hardware reused architecture for deep neural network accelerator\",\n        \"An Efficient Unstructured Sparse Convolutional Neural Network Accelerator for Wearable ECG Classification Device\",\n        \"An Empirical Approach to Enhance Performance for Scalable CORDIC-Based Deep Neural Networks\",\n        \"An Efficient Hardware Accelerator for Block Sparse Convolutional Neural Networks on FPGA\",\n        \"RAMAN: A Reconfigurable and Sparse tinyML Accelerator for Inference on Edge\",\n        \"Edge-Side Fine-Grained Sparse CNN Accelerator With Efficient Dynamic Pruning Scheme\",\n        \"A Data Flow Scheduler for Multi-precision SIMD Processing Engine Systolic Array CNN Accelerators\",\n        \"Enhancing Utilization of SIMD-Like Accelerator for Sparse Convolutional Neural Networks\",\n        \"Supporting compressed-sparse activations and weights on SIMD-like accelerator for sparse convolutional neural networks\",\n        \"Energy-Efficient and High-Throughput CNN Inference Engine Based on Memory-Sharing and Data-Reusing for Edge Applications\",\n        \"RECON: Resource-Efficient CORDIC-Based Neuron Architecture\",\n        \"A SIMD Dynamic Fixed Point Processing Engine for DNN Accelerators\",\n        \"Comparing vertical and horizontal SIMD vector processor architectures for accelerated image feature extraction\",\n        \"AI and Memory Wall\",\n        \"A Unified Programmable Edge Matrix Processor for Deep Neural Networks and Matrix Algebra\",\n        \"Activation functions in deep learning: A comprehensive survey and benchmark\",\n        \"UNPU: An Energy-Efficient Deep Neural Network Accelerator With Fully Variable Weight Bit Precision\",\n        \"50 Years of CORDIC: Algorithms, Architectures, and Applications\",\n        \"Design of Synthesis-time Vectorized Arithmetic Hardware for Tapered Floating-point Addition and Subtraction\",\n        \"A reconfigurable multi-precision quantization-aware nonlinear activation function hardware module for DNNs\",\n        \"Slimmer CNNs Through Feature Approximation and Kernel Size Reduction\",\n        \"Embedded Deep Learning Accelerators: A Survey on Recent Advances\",\n        \"Deep Learning Approaches Based on Transformer Architectures for Image Captioning Tasks\",\n        \"A Mixed-Precision Transformer Accelerator With Vector Tiling Systolic Array for License Plate Recognition in Unconstrained Scenarios\",\n        \"A Twofold Lookup Table Architecture for Efficient Approximation of Activation Functions\",\n        \"Approximate Softmax Functions for Energy-Efficient Deep Neural Networks\",\n        \"RASHT: A Partially Reconfigurable Architecture for Efficient Implementation of CNNs\",\n        \"Cheshire: A Lightweight, Linux-Capable RISC-V Host Platform for Domain-Specific Accelerator Plug-In\"\n    ],\n    \"reasoning\": \"Selected these 48 references because they represent foundational work and recent advances in Flex-PE: Flexible and SIMD Multi-Precision Processing Element for AI Workloads, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}