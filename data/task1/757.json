{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 48 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Challenges in Emotion Style Transfer: An Exploration with a Lexical Substitution Pipeline\n\nPaper Abstract: Abstract We propose the task of emotion style transfer, which is particularly challenging, as emotions (here: anger, disgust, fear, joy, sadness, surprise) are on the fence between content and style. To understand the particular difficulties of this task, we design a transparent emotion style transfer pipeline based on three steps: (1) select the words that are promising to be substituted to change the emotion (with a brute-force approach and selection based on the attention mechanism of an emotion classifier), (2) find sets of words as candidates for substituting the words (based on lexical and distributional semantics), and (3) select the most promising combination of substitutions with an objective function which consists of components for content (based on BERT sentence embeddings), emotion (based on an emotion classifier), and fluency (based on a neural language model). This comparably straight-forward setup enables us to explore the task and understand in what cases lexical substitution can vary the emotional load of texts, how changes in content and style interact and if they are at odds. We further evaluate our pipeline quantitatively in an automated and an annotation study based on Tweets and find, indeed, that simultaneous adjustments of content and emotion are conflicting objectives: as we show in a qualitative analysis motivated by Scherer’s emotion component model, this is particularly the case for implicit emotion expressions based on cognitive appraisal or descriptions of bodily reactions.\n\n{retrieved_text}\n\nGenerate exactly 48 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 48\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Emotions from text: Machine learning for text-based emotion prediction\",\n        \"NTUA-SLP at SemEval-2018 task 1: Predicting affective content in tweets with deep attentive RNNs and transfer learning\",\n        \"Creating a system for lexical substitutions from scratch using crowdsourcing\",\n        \"An analysis of annotated corpora for emotion classification in text\",\n        \"Direct word sense matching for lexical substitution\",\n        \"Style transformer: Unpaired text style transfer without disentangled latent representation\",\n        \"BERT: Pre-training of deep bidirectional transformers for language understanding\",\n        \"An argument for basic emotions\",\n        \"WordNet: an electronic lexical database\",\n        \"Style transfer in text: Exploration and evaluation\",\n        \"Affect-LM: A neural language model for customizable affective text generation\",\n        \"Reinforcement learning based text style transfer without parallel training corpus\",\n        \"Valentino: A tool for valence shifting of natural language texts\",\n        \"UNT: SubFinder: Combining knowledge sources for automatic lexical substitution\",\n        \"Toward controlled generation of text\",\n        \"Automatic dialogue generation with expressed emotions\",\n        \"Shakespearizing modern language using copy-enriched sequence to sequence models\",\n        \"Investigating the relationship between literary genres and emotional plot development\",\n        \"IEST: WASSA-2018 implicit emotions shared task\",\n        \"What substitutes tell us - analysis of an “all-words” lexical substitution corpus\",\n        \"Neural text style transfer via denoising and reranking\",\n        \"Delete, Retrieve, Generate: a simple approach to sentiment and style transfer\",\n        \"Best-worst scaling: theory, methods and applications\",\n        \"MELB-MKB: Lexical substitution system based on relatives in context\",\n        \"SemEval-2007 task 10: English lexical substitution task\",\n        \"A simple word embedding model for lexical substitution\",\n        \"#emotional tweets\",\n        \"SemEval-2018 task 1: Affect in tweets\",\n        \"Stance and sentiment in tweets\",\n        \"Crowdsourcing a word-emotion association lexicon\",\n        \"The nature of emotions: Human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice\",\n        \"The circumplex model of affect: an integrative approach to affective neuroscience, cognitive development, and psychopathology\",\n        \"Style transfer through back-translation\",\n        \"Improving language understandingby generative pre-training\",\n        \"Fighting offensive language on social media with unsupervised text style transfer\",\n        \"What are emotions? And how can they be measured?\",\n        \"Controlling politeness in neural machine translation via side constraints\",\n        \"Style transfer from non-parallel text by cross-alignment\",\n        \"Explorations in lexical sample and all-words lexical substitution\",\n        \"Zero-shot fine-grained style transfer: Leveraging distributed continuous style representations to transfer to unseen styles\",\n        \"A comparison of context-sensitive models for lexical substitution\",\n        \"Generating responses with a specific emotion in dialog\",\n        \"Harnessing pre-trained neural networks with rules for formality style transfer\",\n        \"Generating Shifting Sentiment for a Conversational Agent\",\n        \"HuggingFace’s transformers: State-of-the-art natural language processing\",\n        \"Unpaired sentiment-to-sentiment translation: A cycled reinforcement learning approach\",\n        \"Adversarially regularized autoencoders\",\n        \"HIT: Web based scoring method for English lexical substitution\"\n    ],\n    \"reasoning\": \"Selected these 48 references because they represent foundational work and recent advances in Challenges in Emotion Style Transfer: An Exploration with a Lexical Substitution Pipeline, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}