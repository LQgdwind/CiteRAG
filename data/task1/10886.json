{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 52 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Never-Ending Embodied Robot Learning\n\nPaper Abstract: Abstract Relying on large language models (LLMs), embodied robots could perform complex multi-modal robot manipulation tasks from visual observations with powerful generalization ability. However, most visual behavior-cloning agents suffer from manipulation performance degradation and skill knowledge forgetting when adapting into a series of challenging unseen tasks. We here investigate the above challenge with NBCagent in embodied robots, a pioneering language-conditioned Never-ending Behavior-Cloning agent, which can continually learn observation knowledge of novel robot manipulation skills from skill-specific and skill-shared attributes. Specifically, we establish a skill-specific evolving planner to perform knowledge decoupling, which can continually embed novel skill-specific knowledge in our NBCagent agent from latent and low-rank space. Meanwhile, we propose a skill-shared semantics rendering module and a skill-shared representation distillation module to effectively transfer anti-forgetting skill-shared knowledge, further tackling catastrophic forgetting on old skills from semantics and representation aspects. Finally, we design a continual embodied robot manipulation benchmark, and several expensive experiments demonstrate the significant performance of our method. Visual results, code, and dataset are provided at: https://neragent.github.io.\n\n{retrieved_text}\n\nGenerate exactly 52 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 52\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Few-shot continual active learning by a robot\",\n        \"Cbcl-pr: A cognitively inspired model for class-incremental learning in robotics\",\n        \"Continual learning through human-robot interactionâ€“human perceptions of a continual learning robot in repeated interactions\",\n        \"Rainbow memory: Continual learning with a memory of diverse samples\",\n        \"Rt-1: Robotics transformer for real-world control at scale\",\n        \"Do as i can, not as i say: Grounding language in robotic affordances\",\n        \"On tiny episodic memories in continual learning\",\n        \"Palm: Scaling language modeling with pathways\",\n        \"Kernel continual learning\",\n        \"Heterogeneous forgetting compensation for class-incremental learning\",\n        \"Podnet: Pooled outputs distillation for small-tasks incremental learning\",\n        \"Reinforcement learning with neural radiance fields\",\n        \"Palm-e: An embodied multimodal language model\",\n        \"Cril: Continual robot imitation learning via generative and prediction model\",\n        \"Ifor: Iterative flow minimization for robotic object rearrangement\",\n        \"Rvt: Robotic view transformer for 3d object manipulation\",\n        \"Continual robot learning using self-supervised task inference\",\n        \"Lora: Low-rank adaptation of large language models\",\n        \"Inner monologue: Embodied reasoning through planning with language models\",\n        \"Perceiver io: A general architecture for structured inputs & outputs\",\n        \"Rlbench: The robot learning benchmark & learning environment\",\n        \"Coarse-to-fine q-attention: Efficient learning for visual robotic manipulation via discretisation\",\n        \"Vima: General robot manipulation with multimodal prompts\",\n        \"Continual learning with node-importance based adaptive group sparse regularization\",\n        \"Crafting papers on machine learning\",\n        \"Your diffusion model is secretly a zero-shot classifier\",\n        \"Continual few-shot intent detection\",\n        \"Learning without forgetting\",\n        \"Nerf: Representing scenes as neural radiance fields for view synthesis\",\n        \"Learning transferable visual models from natural language supervision\",\n        \"icarl: Incremental classifier and representation learning\",\n        \"V-rep: A versatile and scalable robot simulation framework\",\n        \"High-resolution image synthesis with latent diffusion models\",\n        \"Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action\",\n        \"Snerl: Semantic-aware neural radiance fields for reinforcement learning\",\n        \"Cliport: What and where pathways for robotic manipulation\",\n        \"Perceiver-actor: A multi-task transformer for robotic manipulation\",\n        \"Create your world: Lifelong text-to-image diffusion\",\n        \"Exploring example influence in continual learning\",\n        \"Gcr: Gradient coreset based replay buffer selection for continual learning\",\n        \"Bring evanescent representations to life in lifelong class incremental learning\",\n        \"Lotus: Continual imitation learning for robot manipulation through unsupervised skill discovery\",\n        \"Coscl: Cooperation of small continual learners is stronger than a big one\",\n        \"A comprehensive survey of continual learning: Theory, method and application\",\n        \"Incremental learning via rate reduction\",\n        \"Incremental learning using conditional adversarial networks\",\n        \"Open-vocabulary panoptic segmentation with text-to-image diffusion models\",\n        \"Continual object detection via prototypical task correlation guided gating mechanism\",\n        \"Large batch optimization for deep learning: Training bert in 76 minutes\",\n        \"pixelnerf: Neural radiance fields from one or few images\",\n        \"Gnfactor: Multi-task real robot learning with generalizable neural feature fields\",\n        \"Rt-2: Vision-language-action models transfer web knowledge to robotic control\"\n    ],\n    \"reasoning\": \"Selected these 52 references because they represent foundational work and recent advances in Never-Ending Embodied Robot Learning, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}