{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 237 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Enabling High-Performance and Energy-Efficient Hybrid Transactional/Analytical Databases with Hardware/Software Cooperation\n\nPaper Abstract: Abstract A growth in data volume, combined with increasing demand for real-time analysis (using the most recent data), has resulted in the emergence of database systems that concurrently support transactions and data analytics. These hybrid transactional and analytical processing (HTAP) database systems can support real-time data analysis without the high costs of synchronizing across separate single-purpose databases. Unfortunately, for many applications that perform a high rate of data updates, state-of-the-art HTAP systems incur significant losses in transactional (up to 74.6%) and/or analytical (up to 49.8%) throughput compared to performing only transactional or only analytical queries in isolation, due to (1) data movement between the CPU and memory, (2) data update propagation from transactional to analytical workloads, and (3) the cost to maintain a consistent view of data across the system. \\Copy CR1/1AWe propose Polynesia, a hardware–software co-designed system for in-memory HTAP databases that avoids the large throughput losses of traditional HTAP systems. Polynesia (1) divides the HTAP system into transactional and analytical processing islands, (2) implements new custom hardware that unlocks software optimizations to reduce the costs of update propagation and consistency, and (3) exploits processing-in-memory for the analytical islands to alleviate data movement overheads. Our evaluation shows that Polynesia outperforms three state-of-the-art HTAP systems, with average transactional/analytical throughput improvements of 1.7×\\times/3.7×\\times, and reduces energy consumption by 48% over the prior lowest-energy HTAP system.\n\n{retrieved_text}\n\nGenerate exactly 237 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 237\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Cisco Global Cloud Index: Forecast and Methodology, 2016-2021\",\n        \"TitAnt: Online Real-Time Transaction Fraud Detection in Ant Financial\",\n        \"Real-Time Constrained Cycle Detection in Large Dynamic Graphs\",\n        \"Real-Time Credit Card Fraud Detection Using Computational Intelligence\",\n        \"Real-Time Analytical Processing with SQL Server\",\n        \"SnappyData: Streaming, Transactions, and Interactive Analytics in a Unified Engine\",\n        \"Real Time Business Intelligence in Supply Chain Analytics\",\n        \"Adopting Medical Technologies and Diagnostics Recommended by NICE: The Health Technologies Adoption Programme\",\n        \"Big Data Stream Computing in Healthcare Real-Time Analytics\",\n        \"WiSer: A Highly Available HTAP DBMS for IoT Applications\",\n        \"Kunpeng: Parameter Server Based Distributed Learning Systems and Its Applications in Alibaba and Ant Financial\",\n        \"TiDB: A Raft-Based HTAP Database\",\n        \"Hybrid Transaction/Analytical Processing Will Foster Opportunities for Dramatic Business Innovation\",\n        \"SAP HANA: The Evolution from a Modern Main-Memory Data Platform to an Enterprise Application Platform\",\n        \"Hybrid OLTP and OLAP\",\n        \"Bridging the Archipelago Between Row-Stores and Column-Stores for Hybrid Workloads\",\n        \"BatchDB: Efficient Isolated Execution of Hybrid OLTP+OLAP Workloads for Interactive Applications\",\n        \"Hybrid Transactional/Analytical Processing: A Survey\",\n        \"CoNDA: Efficient Cache Coherence Support for Near-Data Accelerators\",\n        \"LazyPIM: An Efficient Cache Coherence Mechanism for Processing-in-Memory\",\n        \"Practical Mechanisms for Reducing Processor-Memory Data Movement in Modern Workloads\",\n        \"A Modern Primer on Processing in Memory\",\n        \"Processing Data Where It Makes Sense: Enabling In-Memory Computation\",\n        \"Processing-in-Memory: A Workload-Driven Perspective\",\n        \"Cellular Logic-in-Memory Arrays\",\n        \"A Logic-in-Memory Computer\",\n        \"EXECUBE: A New Architecture for Scaleable MPPs\",\n        \"Processing in Memory: The Terasys Massively Parallel PIM Array\",\n        \"A Case for Intelligent RAM\",\n        \"Active Pages: A Computation Model for Intelligent Memory\",\n        \"The Architecture of the DIVA Processing-in-Memory Chip\",\n        \"Ambit: In-Memory Accelerator for Bulk Bitwise Operations Using Commodity DRAM Technology\",\n        \"Buddy-RAM: Improving the Performance and Efficiency of Bulk Bitwise Operations Using DRAM\",\n        \"RowClone: Fast and Energy-Efficient In-DRAM Bulk Data Copy and Initialization\",\n        \"RowClone: Accelerating Data Movement and Initialization Using DRAM\",\n        \"GraphidDe: A Graph Processing Accelerator Leveraging In-DRAM-Computing\",\n        \"The DRAM Latency PUF: Quickly Evaluating Physical Unclonable Functions by Exploiting the Latency–Reliability Tradeoff in Modern DRAM Devices\",\n        \"D-RaNGe: Using Commodity DRAM Devices to Generate True Random Numbers with Low Latency and High Throughput\",\n        \"Low-Cost Inter-Linked Subarrays (LISA): Enabling Fast Inter-Subarray Data Movement in DRAM\",\n        \"SIMDRAM: A Framework for Bit-Serial SIMD Processing Using DRAM\",\n        \"NoM: Network-on-Memory for Inter-Bank Data Transfer in Highly-Banked Memories\",\n        \"FIGARO: Improving System Performance via Fine-Grained In-DRAM Data Relocation and Caching\",\n        \"SynCron: Efficient Synchronization Support for Near-Data-Processing Architectures\",\n        \"NATSA: A Near-Data Processing Accelerator for Time Series Analysis\",\n        \"Accelerating Genome Analysis: A Primer on an Ongoing Journey\",\n        \"GenASM: A High-Performance, Low-Power Approximate String Matching Acceleration Framework for Genome Sequence Analysis\",\n        \"GRIM-Filter: Fast Seed Filtering in Read Mapping Using Emerging Memory Technologies\",\n        \"GRIM-Filter: Fast Seed Location Filtering in DNA Read Mapping Using Processing-in-Memory Technologies\",\n        \"PIM-Enabled Instructions: A Low-Overhead, Locality-Aware Processing-in-Memory Architecture\",\n        \"A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing\",\n        \"“Google Workloads for Consumer Devices: Mitigating Data Movement Bottlenecks\",\n        \"“LazyPIM: Efficient Support for Cache Coherence in Processing-in-Memory Architectures\",\n        \"“NAPEL: Near-Memory Computing Application Performance Prediction via Ensemble Learning\",\n        \"“JAFAR: Near-Data Processing for Databases\",\n        \"“NDA: Near-DRAM Acceleration Architecture Leveraging Commodity DRAM Devices and Standard Memory Modules\",\n        \"“Practical Near-Data Processing for In-Memory Analytics Frameworks\",\n        \"“HRL: Efficient and Flexible Reconfigurable Logic for Near-Data Processing\",\n        \"“Biscuit: A Framework for Near-Data Processing of Big Data Workloads\",\n        \"“3D-Stacked Memory-Side Acceleration: Accelerator and System Design\",\n        \"“Accelerating Dependent Cache Misses with an Enhanced Memory Controller\",\n        \"“Continuous Runahead: Transparent Hardware Acceleration for Memory Intensive Workloads\",\n        \"“Transparent Offloading and Mapping (TOM): Enabling Programmer-Transparent Near-Data Processing in GPU Systems\",\n        \"“NeuroCube: A Programmable Digital Neuromorphic Architecture with High-Density 3D Memory\",\n        \"“Toward Standardized Near-Data Processing with Unrestricted Data Placement for GPUs\",\n        \"“BSSync: Processing Near Memory for Machine Learning Workloads with Bounded Staleness Consistency Models\",\n        \"“Concurrent Data Structures for Near-Memory Computing\",\n        \"“GP-SIMD Processing-in-Memory\",\n        \"“GraphPIM: Enabling Instruction-Level PIM Offloading in Graph Computing Frameworks\",\n        \"“Scheduling Techniques for GPU Architectures with Processing-in-Memory Capabilities\",\n        \"“NDC: Analyzing the Impact of 3D-Stacked Memory+Logic Devices on MapReduce Workloads\",\n        \"“TOP-PIM: Throughput-Oriented Programmable Processing in Memory\",\n        \"“Accelerating Sparse Matrix-Matrix Multiplication with 3D-Stacked Logic-in-Memory Hardware\",\n        \"“Data Reorganization in Memory Using 3D-Stacked DRAM\",\n        \"“TETRIS: Scalable and Efficient Neural Network Acceleration with 3D Memory\",\n        \"“The Mondrian Data Engine\",\n        \"“GraphH: A Processing-in-Memory Architecture for Large-Scale Graph Processing\",\n        \"“GraphP: Reducing Communication for PIM-Based Graph Processing with Efficient Data Partition\",\n        \"“A Heterogeneous PIM Hardware-Software Co-Design for Energy-Efficient Graph Processing\",\n        \"“GraphQ: Scalable PIM-Based Graph Processing\",\n        \"“Operand Size Reconfiguration for Big Data Processing in Memory\",\n        \"“A Workload and Programming Ease Driven Perspective of Processing-in-Memory\",\n        \"“SISA: Set-Centric Instruction Set Architecture for Graph Mining on Processing-in-Memory Systems\",\n        \"“pLUTo: In-DRAM Lookup Tables to Enable Massively Parallel General-Purpose Computation\",\n        \"“QUAC-TRNG: High-Throughput True Random Number Generation Using Quadruple Row Activation in Commodity DRAMs\",\n        \"“In-Memory Data Rearrangement for Irregular\",\n        \"“Computational RAM: Implementing Processors in Memory\",\n        \"“Combining Emulation and Simulation to Evaluate a Near Memory Key/Value Lookup Accelerator\",\n        \"“Towards a Scatter-Gather Architecture: Hardware and Software Issues\",\n        \"“Near Memory Key/Value Lookup Acceleration\",\n        \"“Near Memory Data Structure Rearrangement\",\n        \"“Active Memory Cube: A Processing-in-Memory Architecture for Exascale Systems\",\n        \"“Exploring the Processing-in-Memory Paradigm for Future Computing Systems (Fall 2021)\",\n        \"“PiDRAM: A Holistic End-to-End FPGA-Based Framework for Processing-in-DRAM\",\n        \"16Gb/s/Pin GDDR6-Based Accelerator-in-Memory Supporting 1TFLOPS MAC Operation and Various Activation Functions for Deep-Learning Applications\",\n        \"“Near-Memory Processing in Action: Accelerating Personalized Recommendation with AxDIMM\",\n        \"“25.4 A 20nm 6GB Function-In-Memory DRAM\",\n        \"“Hardware Architecture and Software Stack for PIM Based on Commercial DRAM Technology: Industrial Product\",\n        \"“Enabling Fast and Energy-Efficient FM-Index Exact Matching Using Processing-Near-Memory\",\n        \"“FPGA-Based Near-Memory Acceleration of Modern Data-Intensive Applications\",\n        \"“Accelerating Weather Prediction Using Near-Memory Reconfigurable Fabric\",\n        \"“DAMOV: A New Methodology and Benchmark Suite for Evaluating Data Movement Bottlenecks\",\n        \"“Google Neural Network Models for Edge Devices: Analyzing and Mitigating Machine Learning Inference Bottlenecks\",\n        \"“Casper: Accelerating Stencil Computation Using Near-Cache Processing\",\n        \"“GenStore: A High-Performance and Energy-Efficient In-Storage Computing System for Genome Sequence Analysis\",\n        \"“NIM: An HMC-Based Machine for Neuron Computation\",\n        \"“184QPS/W 64Mb/m​m2𝑚superscript𝑚2mm^{2} 3D Logic-to-DRAM Hybrid Bonding with Process-Near-Memory Engine for Recommendation System\",\n        \"“The True Processing in Memory Accelerator\",\n        \"“Benchmarking a New Paradigm: An Experimental Analysis of a Real Processing-in-Memory Architecture\",\n        \"“Benchmarking Memory-Centric Computing Systems: Analysis of Real Processing-in-Memory Hardware\",\n        \"“Mythic — Power-Efficient AI Acceleration for the Edge\",\n        \"“HMC Specification 2.0\",\n        \"“Simultaneous Multi-Layer Access: Improving 3D-Stacked Memory Bandwidth at Low Cost\",\n        \"“HyPer: A Hybrid OLTP&OLAP Main Memory Database System Based on Virtual Memory Snapshots\",\n        \"“Accelerating Analytical Processing in MVCC Using Fine-Granular High-Frequency Virtual Snapshotting\",\n        \"“Polynesia — GitHub Repository\",\n        \"“The SAP HANA Database – An Architecture Overview\",\n        \"“Oracle Database In-Memory: A Dual Format In-Memory Database\",\n        \"“Towards Scalable Real-Time Analytics: An Architecture for Scale-Out of OLxP Workloads\",\n        \"“HYRISE: A Main Memory Hybrid Storage Engine\",\n        \"“The Case For Heterogeneous HTAP\",\n        \"“L-Store: A Real-Time OLTP and OLAP System\",\n        \"“ScyPer: A Hybrid OLTP and OLAP Distributed Main Memory Database System for Scalable Real-Time Analytics\",\n        \"“Janus: A Hybrid Scalable Multi-Representation Cloud Datastore\",\n        \"“Janus: Transaction Processing of Navigation and Analytic Graph Queries on Many-Core Servers\",\n        \"“Parallel Replication across Formats in SAP HANA for Scaling Out Mixed OLTP/OLAP Workloads\",\n        \"The Relational Model for Database Management: Version 2. Addison-Wesley\",\n        \"“The Notions of Consistency and Predicate Locks in a Database System\",\n        \"“Virtual Lightweight Snapshots for Consistent Analytics in NoSQL Stores\",\n        \"“Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems\",\n        \"“A Critique of ANSI SQL Isolation Levels\",\n        \"“Serializable Isolation for Snapshot Databases\",\n        \"“A Comparison of the Use of Virtual Versus Physical Snapshots for Supporting Update-Intensive Workloads\",\n        \"“H-Store: A High-Performance\",\n        \"“A Decomposition Storage Model\",\n        \"“C-Store: A Column-oriented DBMS\",\n        \"“MISE: Providing Performance Predictability and Improving Fairness in Shared Main Memory Systems\",\n        \"“Application-to-Core Mapping Policies to Reduce Memory System Interference in Multi-Core Systems\",\n        \"“Stall-Time Fair Memory Access Scheduling for Chip Multiprocessors\",\n        \"“Parallelism-Aware Batch Scheduling: Enhancing Both Performance and Fairness of Shared DRAM Systems\",\n        \"“Reducing Memory Interference in Multicore Systems via Application-Aware Memory Channel Partitioning\",\n        \"“Fairness via Source Throttling: A Configurable and High-Performance Fairness Substrate for Multi-Core Memory Systems\",\n        \"“Memory Scaling: A Systems Architecture Perspective\",\n        \"“Research Problems and Opportunities in Memory Systems\",\n        \"“Main Memory Scaling: Challenges and Solution Directions\",\n        \"“The Application Slowdown Model: Quantifying and Controlling the Impact of Inter-Application Interference at Shared Caches and Main Memory\",\n        \"“Providing High and Controllable Performance in Multicore Systems Through Shared Resource Management\",\n        \"“ATLAS: A Scalable and High-Performance Scheduling Algorithm for Multiple Memory Controllers\",\n        \"“Thread Cluster Memory Scheduling: Exploiting Differences in Memory Access Behavior\",\n        \"“Memory Performance Attacks: Denial of Memory Service in Multi-Core Systems\",\n        \"“DASH: Deadline-Aware High-Performance Memory Scheduler for Heterogeneous Systems With Hardware Accelerators\",\n        \"“BLISS: Balancing Performance\",\n        \"“Decoupled Direct Memory Access: Isolating CPU and IO Traffic by Leveraging a Dual-Data-Port DRAM\",\n        \"“Staged Memory Scheduling: Achieving High Performance and Scalability in Heterogeneous Systems\",\n        \"“Kilo-NOC: A Heterogeneous Network-on-Chip Architecture for Scalability and Service Guarantees\",\n        \"“Fair Queuing Memory Systems\",\n        \"“Multicore Resource Management\",\n        \"“Multiversion Concurrency Control—Theory and Algorithms\",\n        \"“Scaling Up Concurrent Main-Memory Column-Store Scans: Towards Adaptive NUMA-Aware Data and Task Placement\",\n        \"“Dictionary-Based Order-Preserving String Compression for Main Memory Column Stores\",\n        \"“Speeding Up Queries in Column Stores: A Case for Compression\",\n        \"“Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores\",\n        \"“Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age\",\n        \"“Fast Updates on Read-Optimized Databases Using Multi-Core CPUs\",\n        \"“Database Compression on Graphics Processors\",\n        \"“Fixed-Function Hardware Sorting Accelerators for Near Data MapReduce Execution\",\n        \"“Q100: The Architecture and Design of a Database Processing Unit\",\n        \"“Materialization Strategies in a Column-Oriented DBMS\",\n        \"“Hardware Acceleration for Memory to Memory Copies\",\n        \"“ComputeDRAM: In-Memory Compute Using Off-the-Shelf DRAMs\",\n        \"“In-DRAM Bulk Bitwise Execution Engine\",\n        \"“Encapsulation of Parallelism in the Volcano Query Processing System\",\n        \"“Efficiently Compiling Efficient Query Plans for Modern Hardware\",\n        \"“QTM: Modelling Query Execution With Tasks\",\n        \"“Beyond the Wall: Near-Data Processing for Databases\",\n        \"“JESD235B: High Bandwidth Memory (HBM) DRAM\",\n        \"“A Logic-Base Interconnect for Supporting Near Memory Computation in the Hybrid Memory Cube\",\n        \"“Performance Implications of NoCs on 3D-Stacked Memories: Insights from the Hybrid Memory Cube\",\n        \"“There and Back Again: Optimizing the Interconnect in Networks of Memory Cubes\",\n        \"“Logic-Base Interconnect Design for Near Memory Computing in the Smart Memory Cube\",\n        \"“High Performance AXI-4.0 Based Interconnect for Extensible Smart Memory Cubes\",\n        \"“A Comparison of Receiver-Initiated and Sender-Initiated Adaptive Load Sharing\",\n        \"” https://cloud.google.com/tpu\",\n        \"“Ten Lessons from Three Generations Shaped Google’s TPUv4i: Industrial Product\",\n        \"“Habana Labs Purpose-Built AI Inference and Training Processor Architectures: Scaling AI Training Systems Using Standard Ethernet with Gaudi Processor\",\n        \"“AWS Trainium - Amazon Web Services (AWS)\",\n        \"“Warehouse-Scale Video Acceleration: Co-Design and Deployment in the Wild\",\n        \"“Improved Cloud Service Performance Through ASIC Acceleration\",\n        \"“Aquabolt-XL: Samsung HBM2-PIM with In-Memory Processing for ML Accelerators and Beyond\",\n        \"“ASIC Clouds: Specializing the Datacenter\",\n        \"” https://github.com/yxymit/DBx1000\",\n        \"“The gem5 Simulator\",\n        \"” https://developer.arm.com/ip-products/processors/cortex-a/cortex-a7\",\n        \"“Near-Memory Address Translation\",\n        \"“A Low-Overhead Coherence Solution for Multiprocessors with Private Cache Memories\",\n        \"“A New Solution to Coherence Problems in Multicache Systems\",\n        \"“MEG: A RISCV-Based System Emulation Infrastructure for Near-Data Processing Using FPGAs and High-Bandwidth Memory\",\n        \"“Task Scheduling for Highly Concurrent Analytical and Transactional Main-Memory Workloads\",\n        \"“Scaling Up Mixed Workloads: A Battle of Data Freshness\",\n        \"“Adaptive HTAP Through Elastic Resource Scheduling\",\n        \"“Hekaton: SQL Server’s Memory-Optimized OLTP Engine\",\n        \"“TicToc: Time Traveling Optimistic Concurrency Control\",\n        \"“Taurus: Lightweight Parallel Logging for In-Memory Database Management Systems\",\n        \"“Sundial: Harmonizing Concurrency Control and Caching in a Distributed OLTP Database Management System\",\n        \"“Accelerating Pointer Chasing in 3D-Stacked Memory: Challenges\",\n        \"“The Volcano Optimizer Generator: Extensibility and Efficient Search\",\n        \"“MonetDB/X100: Hyper-Pipelining Query Execution\",\n        \"“Compiling Database Queries into Machine Code\",\n        \"“Lecture Notes for Data Processing On Modern Hardware – Lecture 3: Cache Awareness for Query Execution Models\",\n        \"“TPC-C Benchmark\",\n        \"“TPC-H Benchmark\",\n        \"“TPC-H Analyzed: Hidden Messages and Lessons Learned from an Influential Benchmark\",\n        \"“Runahead Execution: An Alternative to Very Large Instruction Windows for Out-of-Order Processors\",\n        \"“A Case for MLP-Aware Cache Replacement\",\n        \"“Efficient Runahead Execution: Power-Efficient Memory Latency Tolerance\",\n        \"“Techniques for Efficient Processing in Runahead Execution Engines\",\n        \"“Microarchitecture Optimizations for Exploiting Memory-Level Parallelism\",\n        \"“Scalable Cache Miss Handling for High Memory-Level Parallelism\",\n        \"“Improving Memory Bank-Level Parallelism in the Presence of Prefetching\",\n        \"“Memory-Centric System Interconnect Design with Hybrid Memory Cubes\",\n        \"“Hybrid Memory Cube New DRAM Architecture Increases Density and Performance\",\n        \"“Optimizing NUCA Organizations and Wiring Alternatives for Large Caches with CACTI 6.0\",\n        \"“Catapult High-Level Synthesis\",\n        \"“A Comparison of Intel’s 32nm and 22nm Core i5 CPUs: Power\",\n        \"“Performance Characterization of HTAP Workloads\",\n        \"“Oracle GoldenGate 12c: Real-Time Access to Real-Time Information\",\n        \"“Meet the Walkers: Accelerating Index Traversals for In-Memory Databases\",\n        \"“Navigating Big Data with High-Throughput\",\n        \"“Sort vs. Hash Join Revisited for Near-Memory Execution\",\n        \"“Processing-in-Memory Enabled Graphics Processors for 3D Rendering\",\n        \"“CAIRO: A Compiler-Assisted Technique for Enabling Instruction-Level Offloading of Processing-in-Memory\",\n        \"“Adaptive Scheduling for Systems with Asymmetric Memory Hierarchies\",\n        \"“3D-Stacked Many-Core Architecture for Biological Sequence Analysis Problems\",\n        \"“Processing in 3D Memories to Speed Up Operations on Complex Data Structures\",\n        \"“Near-Data Processing: Insights from a MICRO-46 Workshop\",\n        \"“HAMLeT: Hardware Accelerated Memory Layout Transform within 3D-Stacked DRAM\",\n        \"“3D-Stacked Memory Architectures for Multi-Core Processors\",\n        \"“HIPE: HMC Instruction Predication Extension Applied on Database Processing\"\n    ],\n    \"reasoning\": \"Selected these 237 references because they represent foundational work and recent advances in Enabling High-Performance and Energy-Efficient Hybrid Transactional/Analytical Databases with Hardware/Software Cooperation, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}