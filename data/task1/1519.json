{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 51 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Smoothness Sensor: Adaptive Smoothness-Transition Graph Convolutions for Attributed Graph Clustering\n\nPaper Abstract: Abstract Clustering techniques attempt to group objects with similar properties into a cluster. Clustering the nodes of an attributed graph, in which each node is associated with a set of feature attributes, has attracted significant attention. Graph convolutional networks (GCNs) represent an effective approach for integrating the two complementary factors of node attributes and structural information for attributed graph clustering. However, oversmoothing of GCNs produces indistinguishable representations of nodes, such that the nodes in a graph tend to be grouped into fewer clusters, and poses a challenge due to the resulting performance drop. In this study, we propose a smoothness sensor for attributed graph clustering based on adaptive smoothness-transition graph convolutions, which senses the smoothness of a graph and adaptively terminates the current convolution once the smoothness is saturated to prevent oversmoothing. Furthermore, as an alternative to graph-level smoothness, a novel fine-gained node-wise level assessment of smoothness is proposed, in which smoothness is computed in accordance with the neighborhood conditions of a given node at a certain order of graph convolution. In addition, a self-supervision criterion is designed considering both the tightness within clusters and the separation between clusters to guide the whole neural network training process. Experiments show that the proposed methods significantly outperform 12 other state-of-the-art baselines in terms of three different metrics across four benchmark datasets. In addition, an extensive study reveals the reasons for their effectiveness and efficiency.\n\n{retrieved_text}\n\nGenerate exactly 51 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 51\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Algorithm as 136: A k-means clustering algorithm\",\n        \"On spectral clustering: Analysis and an algorithm\",\n        \"A survey of text clustering algorithms\",\n        \"Image clustering using local discriminant models and global integration\",\n        \"Finding statistically significant communities in networks\",\n        \"An information flow model for conflict and fission in small groups\",\n        \"Graph polish: A novel graph generation paradigm for molecular optimization\",\n        \"Dynamic cluster formation game for attributed graph clustering\",\n        \"Discrete optimal graph clustering\",\n        \"Detecting criminal organizations in mobile phone networks\",\n        \"Contextual correlation preserving multiview featured graph clustering\",\n        \"Multiobjective optimization and local merge for clustering attributed graphs\",\n        \"A tutorial on spectral clustering\",\n        \"Finding community structure in networks using the eigenvectors of matrices\",\n        \"Structural deep network embedding\",\n        \"Non-negative matrix factorization on manifold\",\n        \"Co-clustering on manifolds\",\n        \"A comprehensive survey on graph neural networks\",\n        \"Mgae: Marginalized graph autoencoder for graph clustering\",\n        \"Learning deep representations for graph clustering\",\n        \"Semi-supervised classification with graph convolutional networks\",\n        \"Structural deep clustering network\",\n        \"Attributed graph clustering via adaptive graph convolution\",\n        \"Deeper insights into graph convolutional networks for semi-supervised learning\",\n        \"A comprehensive survey of graph embedding: Problems, techniques, and applications\",\n        \"Combining link and content for community detection: a discriminative approach\",\n        \"Locally weighted fusion of structural and attribute information in graph clustering\",\n        \"Modularity and community structure in networks\",\n        \"Community structure in social and biological networks\",\n        \"Low-density parity-check codes\",\n        \"Community detection as an inference problem\",\n        \"Network representation learning with rich text information\",\n        \"Robust multi-view spectral clustering via low-rank and sparse decomposition\",\n        \"Deep network embedding for graph representation learning in signed networks\",\n        \"Hopgat: Hop-aware supervision graph attention networks for sparsely labeled graphs\",\n        \"Learning graph embedding with adversarial training methods\",\n        \"Deep neural networks for learning graph representations\",\n        \"Variational graph auto-encoders\",\n        \"Attributed graph clustering: A deep attentional embedding approach\",\n        \"The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains\",\n        \"Spectral graph theory\",\n        \"Adaptive computation time for recurrent neural networks\",\n        \"Long short-term memory\",\n        \"Learning phrase representations using RNN encoderâ€“decoder for statistical machine translation\",\n        \"Matching node embeddings for graph similarity\",\n        \"A graphical aid to the interpretation and validation of cluster analysis\",\n        \"Deepwalk: Online learning of social representations\",\n        \"Adversarially regularized graph autoencoder for graph embedding\",\n        \"Data clustering: Algorithms and applications\",\n        \"Adam: a method for stochastic optimization\",\n        \"Visualizing data using t-sne\"\n    ],\n    \"reasoning\": \"Selected these 51 references because they represent foundational work and recent advances in Smoothness Sensor: Adaptive Smoothness-Transition Graph Convolutions for Attributed Graph Clustering, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}