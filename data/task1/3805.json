{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 250 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: A Survey on Deep Learning Event Extraction: Approaches and Applications\n\nPaper Abstract: Abstract Event extraction is a crucial research task for promptly apprehending event information from massive textual data. With the rapid development of deep learning, event extraction based on deep learning technology has become a research hotspot. Numerous methods, datasets, and evaluation metrics have been proposed in the literature, raising the need for a comprehensive and updated survey. This paper fills the research gap by reviewing the state-of-the-art approaches, especially focusing on the general domain event extraction based on deep learning models. We introduce a new literature classification of current general domain event extraction research according to the task definition. Afterwards, we summarize the paradigm and models of event extraction approaches, and then discuss each of them in detail. As an important aspect, we summarize the benchmarks that support tests of predictions and evaluation metrics. A comprehensive comparison among different approaches is also provided in this survey. Finally, we conclude by summarizing future research directions facing the research area.\n\n{retrieved_text}\n\nGenerate exactly 250 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 250\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"The automatic content extraction (ACE) program - tasks, data, and evaluation\",\n        \"DRL4IR: 2nd workshop on deep reinforcement learning for information retrieval\",\n        \"Reinforcement learning for information retrieval\",\n        \"CPMF: A collective pairwise matrix factorization model for upcoming event recommendation\",\n        \"Collaborative social group influence for event recommendation\",\n        \"What question answering can learn from trivia nerds\",\n        \"Deformer: Decomposing pre-trained transformers for faster question answering\",\n        \"Automatic knowledge graph construction: A report on the 2019 ICDM/ICBK contest\",\n        \"Dynamic neuro-symbolic knowledge graph construction for zero-shot commonsense question answering\",\n        \"A comprehensive survey on community detection with deep learning\",\n        \"Deep learning for community detection: Progress, challenges and opportunities\",\n        \"A comprehensive survey on graph anomaly detection with deep learning\",\n        \"Joint extraction of events and entities within a document context\",\n        \"Semi-supervised event extraction with paraphrase clusters\",\n        \"Casee: A joint learning framework with cascade decoding for overlapping event extraction\",\n        \"Open-domain event extraction and embedding for natural gas market prediction\",\n        \"Open domain event extraction using neural latent variable models\",\n        \"A survey of textual event extraction from social networks\",\n        \"Grounding visual concepts for zero-shot event detection and event captioning\",\n        \"Learning discriminative neural representations for event detection\",\n        \"“Cost-sensitive regularization for label confusion-aware event detection\",\n        \"“Knowledge-preserving incremental social event detection via heterogeneous gnns\",\n        \"“Hierarchical multi-label classification of text with capsule networks\",\n        \"“Large-scale multi-label text classification on EU legislation\",\n        \"“Taming pretrained transformers for extreme multi-label text classification\",\n        \"“A unified MRC framework for named entity recognition\",\n        \"“Named entity recognition as dependency parsing\",\n        \"“Triggerner: Learning with entity triggers as explanations for named entity recognition\",\n        \"“Unsupervised dual paraphrasing for two-stage semantic parsing\",\n        \"“Universal decompositional semantic parsing\",\n        \"“A semantic parsing and reasoning-based approach to knowledge base question answering\",\n        \"“Empower distantly supervised relation extraction with collaborative adversarial training\",\n        \"“GATE: graph attention transformer encoder for cross-lingual relation and event extraction\",\n        \"“Progressive multi-task learning with controlled information flow for joint entity and relation extraction\",\n        \"“A survey of event extraction methods from text for decision support systems\",\n        \"“A survey of event extraction from text\",\n        \"“Exploring pre-trained language models for event extraction and generation\",\n        \"“Joint event extraction via structured prediction with global features\",\n        \"“Event extraction via dynamic multi-pooling convolutional neural networks\",\n        \"“Joint event extraction via recurrent neural networks\",\n        \"“Event extraction by answering (almost) natural questions\",\n        \"“Event extraction as multi-turn question answering\",\n        \"“Text2event: Controllable sequence-to-structure generation for end-to-end event extraction\",\n        \"“Degree: A data-efficient generative event extraction model\",\n        \"“Contextualized weak supervision for text classification\",\n        \"“Label confusion learning to enhance text classification models\",\n        \"“A frame-based sentence representation for machine reading comprehension\",\n        \"“Document modeling with graph attention networks for multi-grained machine reading comprehension\",\n        \"“Bidirectional machine reading comprehension for aspect sentiment triplet extraction\",\n        \"“Improving neural question generation using deep linguistic representation\",\n        \"“Seqvat: Virtual adversarial training for semi-supervised sequence labeling\",\n        \"“Uncertainty-aware label refinement for sequence labeling\",\n        \"“Biomedical event extraction as sequence labeling\",\n        \"“Lightxml: Transformer with dynamic negative sampling for high-performance extreme multi-label text classification\",\n        \"“Does head label help for long-tailed multi-label text classification\",\n        \"“F-HMTC: detecting financial events for investment decisions based on neural hierarchical multi-label text classification\",\n        \"“Cross-lingual structure transfer for relation and event extraction\",\n        \"“Extracting entities and events as a single task using a transition-based neural model\",\n        \"“Biomedical event extraction based on knowledge-driven tree-lstm\",\n        \"“A joint learning framework for the CCKS-2020 financial event extraction task\",\n        \"“Zero-shot transfer learning for event extraction\",\n        \"“Pipelined query processing in coprocessor environments\",\n        \"“R-node: New pipelined approach for an effective reconfigurable wireless sensor node\",\n        \"“BERT: pre-training of deep bidirectional transformers for language understanding\",\n        \"“A joint neural model for information extraction with global features\",\n        \"“Cross-task instance representation interactions and label dependencies for joint information extraction with graph convolutional networks\",\n        \"“Abstract meaning representation guided graph encoding and decoding for joint information extraction\",\n        \"“Bilingual event extraction: a case study on trigger type determination\",\n        \"“Leveraging framenet to improve automatic event detection\",\n        \"“Automatically labeled data generation for large scale event extraction\",\n        \"“Cleve: Contrastive pre-training for event extraction\",\n        \"“Trigger is not sufficient: Exploiting frame-aware knowledge for implicit event argument extraction\",\n        \"“Document-level event extraction via heterogeneous graph-based interaction model with a tracker\",\n        \"“Revisiting the evaluation of end-to-end event extraction\",\n        \"“What the role is vs. what plays the role: Semi-supervised event argument extraction via dual question answering\",\n        \"“GRIT: generative role-filler transformers for document-level event entity extraction\",\n        \"“Event time extraction and propagation via graph attention networks\",\n        \"“Joint event extraction with hierarchical policy network\",\n        \"“Cross-media structured common space for multimedia event extraction\",\n        \"“Towards few-shot event mention retrieval: An evaluation framework and A siamese network approach\",\n        \"“Reading the manual: Event extraction as definition comprehension\",\n        \"“Edge-enhanced graph convolution networks for event detection with syntactic relation\",\n        \"“Doc2edag: An end-to-end document-level framework for chinese financial event extraction\",\n        \"“Joint entity and event extraction with generative adversarial imitation learning\",\n        \"and event extraction with contextualized span representations\",\n        \"“HMEAE: hierarchical modular event argument extraction\",\n        \"“Joint event and temporal relation extraction with shared representations and structured prediction\",\n        \"“One for all: Neural joint modeling of entities and events\",\n        \"“Rapid customization for event extraction\",\n        \"“Entity-relation extraction as multi-turn question answering\",\n        \"“DCFEE: A document-level chinese financial event extraction system based on automatically labeled training data\",\n        \"“Scale up event extraction learning via automatic training data generation\",\n        \"“Document embedding enhanced event detection with hierarchical and supervised attention\",\n        \"“Self-regulation: Employing a generative adversarial network to improve event detection\",\n        \"“Jointly extracting event triggers and arguments by dependency-bridge RNN and tensor-based argument interaction\",\n        \"“Jointly multiple events extraction via attention-based graph information aggregation\",\n        \"“Exploiting argument information to improve event detection via supervised attention mechanisms\",\n        \"“RBPB: regularization-based pattern balancing method for event extraction\",\n        \"“A convolution bilstm neural network model for chinese event extraction\",\n        \"“Event extraction via bidirectional long short-term memory tensor neural networks\",\n        \"“Joint event extraction based on skip-window convolutional neural networks\",\n        \"“Modeling skip-grams for event detection with convolutional neural networks\",\n        \"“HAWK: rapid android malware detection through heterogeneous graph attention networks\",\n        \"“SUGAR: subgraph neural network with reinforcement pooling and self-supervised mutual information mechanism\",\n        \"“Graph structure learning with variational information bottleneck\",\n        \"“Event extraction as machine reading comprehension\",\n        \"“Event extraction by associating event types and argument roles\",\n        \"“Event detection and domain adaptation with convolutional neural networks\",\n        \"“A language-independent neural network for event detection\",\n        \"“Graph convolutional networks with argument-aware pooling for event detection\",\n        \"“Graph convolutional networks for text classification\",\n        \"“Deep contextualized word representations\",\n        \"“Document-level event role filler extraction using multi-granularity contextualized encoding\",\n        \"Fourth Message Uunderstanding Conference (MUC-4): Proceedings of a Conference Held in McLean\",\n        \"“Multi-sentence argument linking\",\n        \"“A two-step approach for implicit event argument detection\",\n        \"“Document-level event extraction with efficient end-to-end learning of cross-event dependencies\",\n        \"“Document-level event argument extraction by conditional generation\",\n        \"“Document-level event extraction via parallel prediction networks\",\n        \"“Exploring sentence community for document-level event extraction\",\n        \"“Template filling with generative transformers\",\n        \"“Semi-supervised new event type induction and event detection\",\n        \"“Matching networks for one shot learning\",\n        \"“Model-agnostic meta-learning for fast adaptation of deep networks\",\n        \"“Adaptive attentional network for few-shot knowledge graph completion\",\n        \"“Multi-level matching and aggregation network for few-shot relation classification\",\n        \"“Exploiting the matching information in the support set for few shot event classification\",\n        \"“Extensively matching for few-shot learning event detection\",\n        \"“Adaptive knowledge-enhanced bayesian meta-learning for few-shot event detection\",\n        \"“Learning prototype representations across few-shot tasks for event detection\",\n        \"“Taxonomy-aware learning for few-shot event detection\",\n        \"“Graph learning regularization and transfer learning for few-shot event detection\",\n        \"“Meta-learning with dynamic-memory-based prototypical network for few-shot event detection\",\n        \"“Few-shot event detection with prototypical amortized conditional random field\",\n        \"“Honey or poison? solving the trigger curse in few-shot event detection via causal intervention\",\n        \"“Zero-shot event extraction via transfer learning: Challenges and insights\",\n        \"“Continual learning in reinforcement environments\",\n        \"“Lifelong learning algorithms\",\n        \"“Incremental event detection via knowledge consolidation networks\",\n        \"“Leveraging multilingual training for limited resource event extraction\",\n        \"“Event detection via gated multilingual attention mechanism\",\n        \"“Language specific issue and feature exploration in Chinese event extraction\",\n        \"“Employing compositional semantics and discourse consistency in Chinese event extraction\",\n        \"“Event type recognition based on trigger expansion\",\n        \"“Employing morphological structures and sememes for Chinese event extraction\",\n        \"“A novel joint framework for multiple Chinese events extraction\",\n        \"“Nugget proposal networks for Chinese event detection\",\n        \"“Event detection with trigger-aware lattice neural network\",\n        \"“Chinese NER using lattice LSTM\",\n        \"“Label enhanced event detection with heterogeneous graph attention networks\",\n        \"“Can twitter replace newswire for breaking news?\",\n        \"“Event extraction from historical texts: A new dataset for black rebellions\",\n        \"“Liberal event extraction and event schema induction\",\n        \"G. Portillo-Wightman\",\n        \"“Maven: A massive general domain event detection dataset\",\n        \"“Refining event extraction through cross-document inference\",\n        \"“Using document level cross-event inference to improve event extraction\",\n        \"“Using cross-entity inference to improve event extraction\",\n        \"“Neural cross-lingual event detection with minimal parallel resources\",\n        \"“Joint event extraction based on hierarchical event schemas from framenet\",\n        \"“Attention is all you need\",\n        \"“Extracting events and their relations from texts: A survey on recent research progress and challenges\",\n        \"“ELG: an event logic graph\",\n        \"“An overview of event extraction and its applications\",\n        \"“Event-qa: A dataset for event-centric question answering over knowledge graphs\",\n        \"“Answering event-related questions over long-term news article archives\",\n        \"“ESTER: A machine reading comprehension dataset for reasoning about event semantic relations\",\n        \"“Uncertain local-to-global networks for document-level event factuality identification\",\n        \"“A factuality profiler for eventualities in text\",\n        \"“Are you sure that this happened? assessing the factuality degree of events in text\",\n        \"“Did it happen? the pragmatic complexity of veridicality assessment\",\n        \"“Neural models of factuality\",\n        \"“Graph based neural networks for event factuality prediction using syntactic and semantic structures\",\n        \"“Computing relative polarity for textual inference\",\n        \"“Truthteller: Annotating predicate truth\",\n        \"“Committed belief annotation and tagging\",\n        \"“Automatic committed belief tagging\",\n        \"“Event detection and factuality assessment with non-expert supervision\",\n        \"“A two-step approach for event factuality identification\",\n        \"“Event factuality identification via generative adversarial networks with auxiliary classification\",\n        \"“Chinese event factuality detection\",\n        \"“Event factuality detection in discourse\",\n        \"J. Pouget-Abadie\",\n        \"“Semi-supervised classification with graph convolutional networks\",\n        \"“Document-level event factuality identification via adversarial neural network\",\n        \"“Translating granularity of event slots into features for event coreference resolution\",\n        \"“Learning antecedent structures for event coreference resolution\",\n        \"“Unsupervised event coreference resolution with rich linguistic features\",\n        \"“Improving event coreference resolution by modeling correlations between event coreference chains and document topic structures\",\n        \"“Improving event coreference resolution by learning argument compatibility from unlabeled data\",\n        \"“A pairwise event coreference model\",\n        \"“Graph-based event coreference resolution\",\n        \"“Event coreference resolution by iteratively unfolding inter-dependencies among events\",\n        \"“Joint inference over a lightly supervised information extraction pipeline: Towards event coreference resolution for resource-scarce languages\",\n        \"“Joint inference for event coreference resolution\",\n        \"“Joint learning for event coreference resolution\",\n        \"“Joint event trigger identification and event coreference resolution with structured perceptron\",\n        \"“Revisiting joint modeling of cross-document entity and event coreference resolution\",\n        \"“Extracting temporal and causal relations between events\",\n        \"“Another look at causality: Discovering scenario-specific contingency relationships with no supervision\",\n        \"“Toward a better understanding of causality between verbal events: Extraction and analysis of the causal power of verb-verb associations\",\n        \"“Toward future scenario generation: Extracting event causality exploiting semantic relation\",\n        \"“An analysis of causality between events and its relation to temporal information\",\n        \"“Catena: Causal and temporal relation extraction from natural language texts\",\n        \"“Inferring narrative causality between event pairs in films\",\n        \"“Modeling document-level causal structures for event causal relation identification\",\n        \"“Event causality recognition exploiting multiple annotators’ judgments and background knowledge\",\n        \"“Event2mind: Commonsense inference on events\",\n        \"“Glucose: Generalized and contextualized story explanations\",\n        \"“Knowledge enhanced event causality identification with mention masking generalizations\",\n        \"“Knowledge-enriched event causality identification via latent structure induction networks\",\n        \"“Recognizing causality in verb-noun pairs via noun and verb semantics\",\n        \"“KnowDis: Knowledge enhanced data augmentation for event causality detection via distant supervision\",\n        \"“Timeml: Robust specification of event and temporal expressions in text\",\n        \"“Xrce-t: Xip temporal module for tempeval campaign\",\n        \"“Sutime: Evaluation in tempeval-3\",\n        \"“Dense event ordering with a multi-pass architecture\",\n        \"“Machine learning of temporal relations\",\n        \"“A structured learning approach to temporal relation extraction\",\n        \"“Neural temporal relation extraction\",\n        \"“Neural architecture for temporal relation extraction: A bi-lstm approach for detecting narrative containers\",\n        \"“Classifying temporal relations by bidirectional lstm over dependency paths\",\n        \"“Domain knowledge empowered structured neural net for end-to-end event temporal relation extraction\",\n        \"“Exploring contextualized neural language models for temporal dependency parsing\",\n        \"“Unsupervised learning of contextual role knowledge for coreference resolution\",\n        \"“Story comprehension for predicting what happens next\",\n        \"“Using external knowledge for financial event prediction based on graph neural networks\",\n        \"“What happens next? event prediction using a compositional neural network model\",\n        \"“Graff david and christopher cieri\",\n        \"“Unsupervised learning of narrative event chains\",\n        \"“Skip n-grams and ranking functions for predicting script events\",\n        \"“Statistical script learning with multi-argument events\",\n        \"“Script induction as language modeling\",\n        \"“Sam-net: Integrating event-level and chain-level attentions to predict what happens next\",\n        \"“Learning statistical scripts with lstm recurrent neural networks\",\n        \"“Integrating order information and event relation for script event prediction\",\n        \"“Multi-level connection enhanced representation learning for script event prediction\",\n        \"“Heterogeneous graph neural networks to predict what happen next\",\n        \"“Event representation learning enhanced with external commonsense knowledge\",\n        \"“Atomic: An atlas of machine commonsense for if-then reasoning\",\n        \"“Integrating external event knowledge for script learning\",\n        \"“Aser: A large-scale eventuality knowledge graph\",\n        \"“Biomedical event extraction on graph edge-conditioned attention networks with hierarchical knowledge graphs\",\n        \"“An overview of biomolecular event extraction from scientific documents\",\n        \"“Generalizing biomedical event extraction\",\n        \"“Biomedical event extraction using convolutional neural networks and dependency parsing\",\n        \"“Extracting biomedical events with parallel multi-pooling convolutional neural networks\",\n        \"“Deepeventmine: end-to-end neural nested event extraction from biomedical texts\",\n        \"“Exploring interpretability in event extraction: Multitask learning of a neural event classifier and an explanation decoder\",\n        \"“A survey on event extraction for natural language understanding: Riding the biomedical literature wave\"\n    ],\n    \"reasoning\": \"Selected these 250 references because they represent foundational work and recent advances in A Survey on Deep Learning Event Extraction: Approaches and Applications, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}