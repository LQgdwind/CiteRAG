{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 286 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Transformers in Action Recognition: A Review on Temporal Modeling\n\nPaper Abstract: Abstract In vision-based action recognition, spatio-temporal features from different modalities are used for recognizing activities. Temporal modeling is a long challenge of action recognition. However, there are limited methods such as pre-computed motion features, three-dimensional (3D) filters, and recurrent neural networks (RNN) for modeling motion information in deep-based approaches. Recently, transformers’ success in modeling long-range dependencies in natural language processing (NLP) tasks has gotten great attention from other domains; including speech, image, and video, to rely entirely on self-attention without using sequence-aligned RNNs or convolutions. Although the application of transformers to action recognition is relatively new, the amount of research proposed on this topic within the last few years is astounding. This paper especially reviews recent progress in deep learning methods for modeling temporal variations. It focuses on action recognition methods that use transformers for temporal modeling, discussing their main features, used modalities, and identifying opportunities and challenges for future research.\n\n{retrieved_text}\n\nGenerate exactly 286 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 286\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A review of human activity recognition methods\",\n        \"Human activity analysis: A review\",\n        \"A survey on still image based human action recognition\",\n        \"Driving behaviour recognition from still images by using multi-stream fusion cnn\",\n        \"Deep ensemble learning for human action recognition in still images\",\n        \"A survey on deep learning based approaches for action and gesture recognition in image sequences\",\n        \"Sensor-based and vision-based human activity recognition: A comprehensive survey\",\n        \"Human action recognition and prediction: A survey\",\n        \"Rgb-d sensing based human action and interaction analysis: A survey\",\n        \"3d skeleton-based human action classification: A survey\",\n        \"A survey on 3d skeleton-based action recognition using learning method\",\n        \"Rgb-d-based human motion recognition with deep learning: A survey\",\n        \"A survey of context-aware middleware designs for human activity recognition\",\n        \"A comprehensive survey of vision-based human action recognition methods\",\n        \"Rgb-d-based action recognition datasets: A survey\",\n        \"From handcrafted to learned representations for human action recognition: A survey\",\n        \"Learning spatiotemporal features with 3d convolutional networks\",\n        \"3d convolutional neural networks for human action recognition\",\n        \"Two-stream convolutional networks for action recognition in videos\",\n        \"Long-term recurrent convolutional networks for visual recognition and description\",\n        \"Review of dynamic gesture recognition\",\n        \"A survey of deep learning based models for human activity recognition\",\n        \"Deep learning in sport video analysis: a review\",\n        \"A comprehensive study of deep video action recognition\",\n        \"Attention is all you need\",\n        \"An image is worth 16x16 words: Transformers for image recognition at scale\",\n        \"Transformers in vision: A survey\",\n        \"A survey on vision transformer\",\n        \"Video transformer network\",\n        \"Semi-supervised action recognition with temporal contrastive learning\",\n        \"Spatio-temporal contrastive domain adaptation for action recognition\",\n        \"Sensors, vision and networks: From video surveillance to activity recognition and health monitoring\",\n        \"Vision-based action understanding for assistive healthcare: A short review.\",\n        \"Video benchmarks of human action datasets: a review\",\n        \"Human activity recognition in video benchmarks: A survey\",\n        \"Rgb-d datasets using microsoft kinect or similar sensors: a survey\",\n        \"Deep learning for sensor-based human activity recognition: Overview, challenges, and opportunities\",\n        \"Trends in human activity recognition with focus on machine learning and power requirements\",\n        \"A review and categorization of techniques on device-free human activity recognition\",\n        \"Vision-based human activity recognition: a survey\",\n        \"A review on computer vision-based methods for human action recognition\",\n        \"A comparative review of recent kinect-based action recognition algorithms\",\n        \"A review of real-time human action recognition involving vision sensing\",\n        \"A review of multimodal human activity recognition with special emphasis on classification, applications, challenges and future directions\",\n        \"Human action recognition from various data modalities: A review\",\n        \"Vision and inertial sensing fusion for human action recognition: A review\",\n        \"Multi-user activity recognition: Challenges and opportunities\",\n        \"Analysis of deep fusion strategies for multi-modal gesture recognition\",\n        \"Deep learning-based action recognition with 3d skeleton: a survey\",\n        \"A survey on video-based human action recognition: recent updates, datasets, challenges, and applications\",\n        \"Vision-based human action recognition: An overview and real world challenges\",\n        \"A review of state-of-the-art techniques for abnormal human activity recognition\",\n        \"Zero-shot action recognition in videos: A survey\",\n        \"A review of convolutional-neural-network-based action recognition\",\n        \"Intelligent video surveillance: a review through deep learning techniques for crowd analysis\",\n        \"Vision transformers for action recognition: A survey\",\n        \"Extended histogram: probabilistic modelling of video content temporal evolutions\",\n        \"A comprehensive survey of human action recognition with spatio-temporal interest point (stip) detector\",\n        \"A 3-dimensional sift descriptor and its application to action recognition\",\n        \"An efficient dense and scale-invariant spatio-temporal interest point detector\",\n        \"A spatio-temporal descriptor based on 3d-gradients\",\n        \"Learning realistic human actions from movies\",\n        \"Video action detection with relational dynamic-poselets\",\n        \"Motionlets: Mid-level 3d parts for human motion recognition\",\n        \"Action bank: A high-level representation of activity in video\",\n        \"Mining motion atoms and phrases for complex action recognition\",\n        \"Action recognition with actons\",\n        \"View invariant human action recognition using histograms of 3d joints\",\n        \"Human activity recognition process using 3-d posture data\",\n        \"Learning spatio-temporal structure from rgb-d videos for human activity detection and anticipation\",\n        \"Learning human activities and object affordances from rgb-d videos\",\n        \"Action recognition using rate-invariant analysis of skeletal shape trajectories\",\n        \"A weighting scheme for mining key skeletal joints for human action recognition\",\n        \"Deep multimodal learning: A survey on recent advances and trends\",\n        \"Score normalization in multimodal biometric systems\",\n        \"Human interaction prediction using deep temporal features\",\n        \"Action recognition with trajectory-pooled deep-convolutional descriptors\",\n        \"Deep temporal linear encoding networks\",\n        \"Actionvlad: Learning spatio-temporal aggregation for action classification\",\n        \"Spatiotemporal multiplier networks for video action recognition\",\n        \"Action recognition for depth video using multi-view dynamic images\",\n        \"Depth pooling based large-scale 3-d action recognition with convolutional neural networks\",\n        \"Action recognition from depth maps using deep convolutional neural networks\",\n        \"Action recognition from depth sequence using depth motion maps-based local ternary patterns and cnn\",\n        \"Action recognition based on joint trajectory maps with convolutional neural networks\",\n        \"Action recognition based on joint trajectory maps using convolutional neural networks\",\n        \"Skelemotion: A new representation of skeleton joint sequences based on motion information for 3d action recognition\",\n        \"Skeleton image representation for 3d action recognition based on tree structure and reference joints\",\n        \"Skeleton optical spectra-based action recognition using convolutional neural networks\",\n        \"Joint distance maps based action recognition with convolutional neural networks\",\n        \"Exploiting deep residual networks for human action recognition from skeletal data\",\n        \"Action recognition from rgb-d data: Comparison and fusion of spatio-temporal handcrafted features and deep strategies\",\n        \"Dynamic image networks for action recognition\",\n        \"Very deep convolutional networks for large-scale image recognition\",\n        \"Aggregated residual transformations for deep neural networks\",\n        \"Human activity recognition in rgb-d videos by dynamic images\",\n        \"Combining cnn streams of dynamic image and depth data for action recognition\",\n        \"Privacy-preserving human action recognition as a remote cloud service using rgb-d sensors and deep cnn\",\n        \"Human action recognition using rgb-d sensor and deep convolutional neural networks\",\n        \"Multi-stream deep architecture for surgical phase recognition on multi-view rgbd videos\",\n        \"Imagenet classification with deep convolutional neural networks\",\n        \"Scene flow to action map: A new representation for rgb-d based action recognition with convolutional neural networks\",\n        \"Deep multimodal feature analysis for action recognition in rgb+ d videos\",\n        \"Joint deep learning for rgb-d action recognition\",\n        \"Multi-stream deep neural networks for rgb-d egocentric action recognition\",\n        \"Cross-modality compensation convolutional neural networks for rgb-d action recognition\",\n        \"Cooperative training of deep aggregation networks for rgb-d action recognition\",\n        \"Multi-modality learning for human action recognition\",\n        \"Segment spatial-temporal representation and cooperative learning of convolution neural networks for multimodal-based action recognition\",\n        \"Modality distillation with multiple stream networks for action recognition\",\n        \"Deep learning-based multi-modal approach using rgb and skeleton sequences for human activity recognition\",\n        \"Human activity recognition using combined deep architectures\",\n        \"Deep convolutional neural networks for human action recognition using depth maps and postures\",\n        \"Structured images for rgb-d action recognition\",\n        \"Cnn-based action recognition using adaptive multiscale depth motion maps and stable joint distance maps\",\n        \"A deep multimodal network based on bottleneck layer features fusion for action recognition\",\n        \"Human activity recognition by fusion of rgb\",\n        \"Information fusion for human action recognition via biset/multiset globality locality preserving canonical correlation analysis\",\n        \"Multimodal human action recognition based on a fusion of dynamic images using cnn descriptors\",\n        \"P.-J. Kindermans\",\n        \"Vision-based multi-modal framework for action recognition\",\n        \"A closer look at spatiotemporal convolutions for action recognition\",\n        \"Spatio-temporal fast 3d convolutions for human action recognition\",\n        \"action recognition? a new model and the kinetics dataset\",\n        \"Learning spatio-temporal representation with pseudo-3d residual networks\",\n        \"Long-term temporal convolutions for action recognition\",\n        \"D. Fuentes-Jimenez\",\n        \"Channel-wise topology refinement graph convolution for skeleton-based action recognition\",\n        \"Disentangling and unifying graph convolutions for skeleton-based action recognition\",\n        \"Infrared and 3d skeleton feature fusion for rgb-d action recognition\",\n        \"Large-scale gesture recognition with a fusion of rgb-d data based on the c3d model\",\n        \"Large-scale isolated gesture recognition using pyramidal 3d convolutional networks\",\n        \"Rgb-d based action recognition with light-weight 3d convolutional networks\",\n        \"Two-stream network with 3d common-specific framework for rgb-d action recognition\",\n        \"Adaptive cross-fusion learning for multi-modal gesture recognition\",\n        \"Regional attention with architecture-rebuilt 3d network for rgb-d gesture recognition\",\n        \"3d-based deep convolutional neural network for action recognition with depth sequences\",\n        \"What makes training multi-modal classification networks hard?\",\n        \"Finding structure in time\",\n        \"B. Van Merriënboer\",\n        \"Learning precise timing with lstm recurrent networks\",\n        \"S. Vijayanarasimhan\",\n        \"Conflux lstms network: A novel approach for multi-view action recognition\",\n        \"Action recognition in real homes using low resolution depth video data\",\n        \"Multi-view hierarchical bidirectional recurrent neural network for depth video sequence based action recognition\",\n        \"Hierarchical recurrent neural network for skeleton based action recognition\",\n        \"Fusing geometric features for skeleton-based action recognition using multilayer lstm networks\",\n        \"On geometric features for skeleton-based action recognition using multilayer lstm networks\",\n        \"Differential recurrent neural networks for action recognition\",\n        \"Co-occurrence feature learning for skeleton based action recognition using regularized deep lstm networks\",\n        \"Ntu rgb+ d: A large scale dataset for 3d human activity analysis\",\n        \"Spatio-temporal lstm with trust gates for 3d human action recognition\",\n        \"Modeling temporal dynamics and spatial configurations of actions using two-stream recurrent neural networks\",\n        \"Ensemble deep learning for skeleton-based action recognition using temporal sliding lstm networks\",\n        \"Deep independently recurrent neural network (indrnn)\",\n        \"Relational network for skeleton-based action recognition\",\n        \"M. Van Herreweghe\",\n        \"Two streams recurrent neural networks for large-scale continuous gesture recognition\",\n        \"A deep-learning–based multimodal depth-aware dynamic hand gesture recognition system\",\n        \"Cnn+ rnn depth and skeleton based dynamic hand gesture recognition\",\n        \"Learning and refining of privileged information-based rnns for action recognition from depth sequences\",\n        \"Deep bilinear learning for rgb-d action recognition\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Improving language understanding by generative pre-training (2018)\",\n        \"Roberta: A robustly optimized bert pretraining approach\",\n        \"Exploring the limits of transfer learning with a unified text-to-text transformer\",\n        \"Scaling neural machine translation\",\n        \"Training data-efficient image transformers & distillation through attention\",\n        \"End-to-end object detection with transformers\",\n        \"End-to-end video instance segmentation with transformers\",\n        \"Mm-vit: Multi-modal video transformer for compressed video action recognition\",\n        \"“reading pictures instead of looking”: Rgb-d image-based action recognition via capsule network and kalman filter\",\n        \"Tbsn: Sparse-transformer based siamese network for few-shot action recognition\",\n        \"G. Tzimiropoulos\",\n        \"R. Salakhutdinov\",\n        \"Hierarchical attention network for action recognition in videos\",\n        \"Attentional pooling for action recognition\",\n        \"Videolstm convolves\",\n        \"Recurrent spatial-temporal attention network for action recognition in videos\",\n        \"Part-aligned pose-guided recurrent network for action recognition\",\n        \"Spatial transformer networks\",\n        \"An attention mechanism based convolutional lstm network for video action recognition\",\n        \"Going deeper with convolutions\",\n        \"Video action transformer network\",\n        \"Faster r-cnn: Towards real-time object detection with region proposal networks\",\n        \"Late temporal modeling in 3d cnn architectures with bert for action recognition\",\n        \"Lightweight network architecture for real-time action recognition\",\n        \"Deep residual learning for image recognition\",\n        \"Action transformer: A self-attention model for short-time human action recognition\",\n        \"Video swin transformer\",\n        \"Swin transformer: Hierarchical vision transformer using shifted windows\",\n        \"Two-pathway transformer network for video action recognition\",\n        \"Is space-time attention all you need for video understanding\",\n        \"C. Feichtenhofer\",\n        \"Vivit: A video vision transformer\",\n        \"Skeleton-based human action recognition with global context-aware attention lstm networks\",\n        \"Global context-aware attention lstm networks for 3d action recognition\",\n        \"An end-to-end spatio-temporal attention model for human action recognition from skeleton data\",\n        \"Gcst: Graph convolutional skeleton transformer for action recognition\",\n        \"Hierarchical transformer: Unsupervised representation learning for skeleton-based human action recognition\",\n        \"Motion-transformer: self-supervised pre-training for skeleton-based action recognition\",\n        \"Msst-rt: Multi-stream spatial-temporal relative transformer for skeleton-based action recognition\",\n        \"Skeleton-based action recognition via spatial and temporal transformer networks\",\n        \"Spatial temporal transformer network for skeleton-based action recognition\",\n        \"Skeleton-based action recognition with synchronous local and non-local spatio-temporal learning and frequency attention\",\n        \"Stst: Spatial-temporal specialized transformer for skeleton-based action recognition\",\n        \"Star: Sparse transformer-based action recognition\",\n        \"Human action recognition: Pose-based attention draws focus to hands\",\n        \"Human activity recognition with pose-driven attention to rgb\",\n        \"Where to focus on for human action recognition?\",\n        \"Attention-driven body pose encoding for human activity recognition\",\n        \"Trear: Transformer-based rgb-d egocentric action recognition\",\n        \"Ts-lstm and temporal-inception: Exploiting spatiotemporal dynamics for activity recognition\",\n        \"3d-cnn-based fused feature maps with lstm applied to action recognition\",\n        \"3dv: 3d dynamic voxel for action recognition in depth video\",\n        \"Pointnet++: Deep hierarchical feature learning on point sets in a metric space\",\n        \"Adaptive feature selection with reinforcement learning for skeleton-based action recognition\",\n        \"Skeleton-based action recognition using lstm and cnn\",\n        \"Dynamic gcn: Context-enriched topology learning for skeleton-based action recognition\",\n        \"Two-stream 3d convolutional neural network for skeleton-based action recognition\",\n        \"Skeleton-based human action recognition using spatial temporal 3d convolutional neural networks\",\n        \"Srnet: Structured relevance feature learning network from skeleton data for human action recognition\",\n        \"A hybrid network for large-scale action recognition from rgb and depth modalities\",\n        \"Learning spatiotemporal features using 3dcnn and convolutional lstm for gesture recognition\",\n        \"Online detection and classification of dynamic hand gestures with recurrent 3d convolutional neural network\",\n        \"View-invariant deep architecture for human action recognition using two-stream motion and shape temporal dynamics\",\n        \"A spatiotemporal attention-based resc3d model for large-scale gesture recognition\",\n        \"Multimodal gesture recognition based on the resc3d network\",\n        \"Multi-modality fusion based on consensus-voting and 3d convolution for isolated gesture recognition\",\n        \"Multi-view region-adaptive multi-temporal dmm and rgb action recognition\",\n        \"Spatiotemporal multimodal learning with 3d cnns for video action recognition\",\n        \"Multid-cnn: A multi-dimensional feature learning approach based on deep convolutional networks for gesture recognition in rgb-d image sequences\",\n        \"Multimodal gesture recognition using 3-d convolution and convolutional lstm\",\n        \"Skeleton-indexed deep multi-modal feature learning for high performance human action recognition\",\n        \"3d behavior recognition based on multi-modal deep space-time learning\",\n        \"Skeleton-based action recognition with multi-stream adaptive graph convolutional networks\",\n        \"Vpn: Learning video-pose embedding for activities of daily living\",\n        \"Vpn++: Rethinking video-pose embeddings for understanding activities of daily living\",\n        \"Toyota smarthome: Real-world activities of daily living\",\n        \"Improved dense trajectory with cross streams\",\n        \"Action machine: Rethinking action recognition in trimmed videos\",\n        \"Recognizing actions in videos from unseen viewpoints\",\n        \"X3d: Expanding architectures for efficient video recognition\",\n        \"Slowfast networks for video recognition\",\n        \"Vertex feature encoding and hierarchical temporal modeling in a spatial-temporal graph convolutional network for action recognition\",\n        \"Temporal extension module for skeleton-based action recognition\",\n        \"Learning multi-granular spatio-temporal graph network for skeleton-based action recognition\",\n        \"Revisiting skeleton-based action recognition\",\n        \"Hierarchical action classification with network pruning\",\n        \"Regularizing long short term memory with 3d human-skeleton sequences for action recognition\",\n        \"Multiview transformers for video recognition\",\n        \"Co-training transformer with videos and images improves action recognition\",\n        \"Florence: A new foundation model for computer vision\",\n        \"Swin transformer v2: Scaling up capacity and resolution\",\n        \"Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training\",\n        \"Tokenlearner: What can 8 learned tokens do for images and videos?\",\n        \"Non-local neural networks\",\n        \"Unik: A unified framework for real-world skeleton-based action recognition\",\n        \"Assemblenet++: Assembling modality representations via attention connections\",\n        \"Adaptive intermediate representations for video understanding\",\n        \"Centrality graph convolutional networks for skeleton-based action recognition\",\n        \"Ntu rgb+ d 120: A large-scale benchmark for 3d human activity understanding\",\n        \"A. Banki-Horvath\",\n        \"S. Ebrahimi Kahou\",\n        \"Ucf101: A dataset of 101 human actions classes from videos in the wild\",\n        \"Resound: Towards action recognition without representation bias\",\n        \"Etri-activity3d: A large-scale rgb-d dataset for robots to recognize daily activities of the elderly\",\n        \"Lcr-net++: Multi-person 2d and 3d pose detection in natural images\",\n        \"A short note on the kinetics-700-2020 human action dataset\",\n        \"Spatial temporal graph convolutional networks for skeleton-based action recognition\",\n        \"Realtime multi-person 2d pose estimation using part affinity fields\",\n        \"Recognizing human actions as the evolution of pose estimation maps\",\n        \"Albert: A lite bert for self-supervised learning of language representations\",\n        \"Are sixteen heads really better than one?\",\n        \"Tinybert: Distilling bert for natural language understanding\",\n        \"Q-bert: Hessian based ultra low precision quantization of bert\",\n        \"Bert-of-theseus: Compressing bert by progressive module replacing\",\n        \"Language models are few-shot learners\",\n        \"Pre-trained image processing transformer\",\n        \"Perceiver: General perception with iterative attention\",\n        \"Perceiver io: A general architecture for structured inputs & outputs\",\n        \"Recurring the transformer for video action recognition\",\n        \"A non-local algorithm for image denoising\",\n        \"On the turing completeness of modern neural network architectures\",\n        \"On the relationship between self-attention and convolutional layers\",\n        \"Layer normalization\"\n    ],\n    \"reasoning\": \"Selected these 286 references because they represent foundational work and recent advances in Transformers in Action Recognition: A Review on Temporal Modeling, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}