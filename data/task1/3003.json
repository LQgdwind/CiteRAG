{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 60 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Learning Triadic Belief Dynamics in Nonverbal Communication from Videos\n\nPaper Abstract: Abstract Humans possess a unique social cognition capability [43, 20]; nonverbal communication can convey rich social information among agents. In contrast, such crucial social characteristics are mostly missing in the existing scene understanding literature. In this paper, we incorporate different nonverbal communication cues (\\eg, gaze, human poses, and gestures) to represent, model, learn, and infer agents’ mental states from pure visual inputs. Crucially, such a mental representation takes the agent’s belief into account so that it represents what the true world state is and infers the beliefs in each agent’s mental state, which may differ from the true world states. By aggregating different beliefs and true world states, our model essentially forms “five minds” during the interactions between two agents. This “five minds” model differs from prior works that infer beliefs in an infinite recursion; instead, agents’ beliefs are converged into a “common mind” [31, 47]. Based on this representation, we further devise a hierarchical energy-based model that jointly tracks and predicts all five minds. From this new perspective, a social event is interpreted by a series of nonverbal communication and belief dynamics, which transcends the classic keyframe video summary. In the experiments, we demonstrate that using such a social account provides a better video summary on videos with rich social interactions compared with state-of-the-art keyframe video summary methods.\n\n{retrieved_text}\n\nGenerate exactly 60 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 60\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Social eye gaze in human-robot interaction: a review\",\n        \"Bayesian theory of mind: Modeling joint belief-desire attribution\",\n        \"Action understanding as inverse planning\",\n        \"Are children with autism blind to the mentalistic significance of the eyes?\",\n        \"A cognitive hierarchy model of games\",\n        \"Histograms of oriented gradients for human detection\",\n        \"Estimating the use of higher-order theory of mind using computational agents\",\n        \"How much does it help to know what she knows you know? an agent-based simulation study\",\n        \"Modeling recursive reasoning by humans using empirically informed interactive pomdps\",\n        \"Who is mistaken?\",\n        \"Inferring shared attention in social scene videos\",\n        \"Understanding human gaze communication by spatio-temporal graph reasoning\",\n        \"On social facts\",\n        \"Collaborative plans for complex group action\",\n        \"The dynamics of intention in collaborative activity\",\n        \"Creating summaries from user videos\",\n        \"Learning others’ intentional models in multi-agent settings using interactive pomdps\",\n        \"Deep residual learning for image recognition\",\n        \"An experimental study of apparent behavior\",\n        \"Biological bases of human social behaviour\",\n        \"Feature-based joint planning and norm learning in collaborative games\",\n        \"Long short-term memory\",\n        \"Review essay: From cognitive science to folk psychology: Computation, mental representation, and belief\",\n        \"An Abstract of a Treatise of Human Nature, 1740\",\n        \"Lemma: A multi-view dataset for learning multi-agent multi-task activities\",\n        \"Towards social artificial intelligence: Nonverbal social signal prediction in a triadic interaction\",\n        \"Gaze360: Physically unconstrained gaze estimation in the wild\",\n        \"Adam: A method for stochastic optimization\",\n        \"Coordinate to cooperate or compete: abstract goals and joint intentions in social interaction\",\n        \"Video summarization from spatio-temporal features\",\n        \"On acting together\",\n        \"Philosophical investigations. Philosophische Untersuchungen\",\n        \"Unsupervised video summarization with adversarial lstm networks\",\n        \"A framework for endowing an interactive robot with reasoning capabilities about perspective-taking and belief management\",\n        \"Gesture recognition: Focus on the hands\",\n        \"Evaluating theory of mind in question answering\",\n        \"Interactive pomdps with finite-state models of other agents\",\n        \"Mental representation\",\n        \"Does the chimpanzee have a theory of mind?\",\n        \"Wavelet statistics for human motion classification\",\n        \"Machine theory of mind\",\n        \"Video summarization using fully convolutional sequence networks\",\n        \"Uniquely human social cognition\",\n        \"Tvsum: Summarizing web videos using titles\",\n        \"Intuitive signaling through an “imagined we”\",\n        \"Bootstrapping an imagined we for cooperation\",\n        \"Origins of human communication\",\n        \"Efficiently scaling up crowdsourced video annotation\",\n        \"Ideas about causation in philosophy and psychology\",\n        \"Deep cosine metric learning for person re-identification\",\n        \"Detectron2\",\n        \"Using iterated reasoning to predict opponent strategies\",\n        \"Gaze prediction in dynamic 360 immersive videos\",\n        \"Semantic video indexing and summarization using subtitles\",\n        \"Joint inference of states, robot knowledge, and human (false-) beliefs\",\n        \"Multi-agent filtering with infinitely nested beliefs\",\n        \"Video summarization with long short-term memory\",\n        \"Deep reinforcement learning for unsupervised video summarization with diversity-representativeness reward\",\n        \"A stochastic grammar of images\",\n        \"Dark, beyond deep: A paradigm shift to cognitive ai with humanlike common sense\"\n    ],\n    \"reasoning\": \"Selected these 60 references because they represent foundational work and recent advances in Learning Triadic Belief Dynamics in Nonverbal Communication from Videos, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}