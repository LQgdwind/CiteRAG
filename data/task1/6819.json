{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 198 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Explainable AI for clinical and remote health applications: a survey on tabular and time series data\n\nPaper Abstract: Abstract Nowadays Artificial Intelligence (AI) has become a fundamental component of healthcare applications, both clinical and remote, but the best performing AI systems are often too complex to be self-explaining. Explainable AI (XAI) techniques are defined to unveil the reasoning behind the system’s predictions and decisions, and they become even more critical when dealing with sensitive and personal health data. It is worth noting that XAI has not gathered the same attention across different research areas and data types, especially in healthcare. In particular, many clinical and remote health applications are based on tabular and time series data, respectively, and XAI is not commonly analysed on these data types, while computer vision and Natural Language Processing (NLP) are the reference applications. To provide an overview of XAI methods that are most suitable for tabular and time series data in the healthcare domain, this paper provides a review of the literature in the last 555 years, illustrating the type of generated explanations and the efforts provided to evaluate their relevance and quality. Specifically, we identify clinical validation, consistency assessment, objective and standardised quality evaluation, and human-centered quality assessment as key features to ensure effective explanations for the end users. Finally, we highlight the main research challenges in the field as well as the limitations of existing XAI methods.\n\n{retrieved_text}\n\nGenerate exactly 198 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 198\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"High-performance medicine: the convergence of human and artificial intelligence\",\n        \"Opportunities and challenges in explainable artificial intelligence (xai): A survey\",\n        \"Why we do need explainable ai for healthcare\",\n        \"A survey on explainable artificial intelligence (xai): Toward medical xai\",\n        \"A review of explainable deep learning cancer detection models in medical imaging\",\n        \"xvitcos: Explainable vision transformer based covid-19 screening using radiography\",\n        \"Residualcovid-net: An interpretable deep network to screen covid-19 utilizing chest ct images\",\n        \"Explainable artificial intelligence models using real-world electronic health record data: a systematic scoping review\",\n        \"Explainable artificial intelligence (xai) for internet of things: A survey\",\n        \"Explainable artificial intelligence for tabular data: A survey\",\n        \"Explainable artificial intelligence (xai) on timeseries data: A survey\",\n        \"The role of explainability in creating trustworthy artificial intelligence for health care: a comprehensive survey of the terminology, design choices, and evaluation strategies\",\n        \"Explainability for artificial intelligence in healthcare: a multidisciplinary perspective\",\n        \"Explainable ai: A review of machine learning interpretability methods\",\n        \"Local rule-based explanations of black box decision systems\",\n        \"Towards a rigorous science of interpretable machine learning\",\n        \"Explainable artificial intelligence (xai): Concepts, taxonomies, opportunities and challenges toward responsible ai\",\n        \"A unified approach to interpreting model predictions\",\n        \"” why should i trust you?” explaining the predictions of any classifier\",\n        \"Alime: Autoencoder based approach for local interpretability\",\n        \"Dlime: A deterministic local interpretable model-agnostic explanations approach for computer-aided diagnosis systems\",\n        \"Ilime: Local and global interpretable model-agnostic explainer of black-box decision\",\n        \"Anchors: High-precision model-agnostic explanations\",\n        \"Counterfactual explanations without opening the black box: Automated decisions and the gdpr\",\n        \"Interpretable counterfactual explanations guided by prototypes\",\n        \"Factorial sampling plans for preliminary computational experiments\",\n        \"Variance based sensitivity analysis of model output. design and estimator for the total sensitivity index\",\n        \"Greedy function approximation: a gradient boosting machine\",\n        \"Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation\",\n        \"Visualizing the effects of predictor variables in black box supervised learning models\",\n        \"Interpreting tree ensembles with intrees\",\n        \"Beyond sparsity: Tree regularization of deep models for interpretability\",\n        \"Rule extraction from support vector machines: A sequential covering approach\",\n        \"Deep inside convolutional networks: Visualising image classification models and saliency maps\",\n        \"Axiomatic attribution for deep networks\",\n        \"Learning important features through propagating activation differences\",\n        \"Visualizing and understanding convolutional networks\",\n        \"Adaptive deconvolutional networks for mid and high level feature learning\",\n        \"Striving for simplicity: The all convolutional net\",\n        \"Learning deep features for discriminative localization\",\n        \"Grad-cam: Visual explanations from deep networks via gradient-based localization\",\n        \"On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation\",\n        \"Neural machine translation by jointly learning to align and translate\",\n        \"Attention is all you need\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Improving language understanding by generative pre-training\",\n        \"A symbolic representation of time series, with implications for streaming algorithms\",\n        \"Time series shapelets: a new primitive for data mining\",\n        \"Techniques for interpretable machine learning\",\n        \"Efficient and explainable risk assessments for imminent dementia in an aging cohort study\",\n        \"R.: Overview and findings from the rush memory and aging project. Current Alzheimer Research 9(6)\",\n        \"T.: Smile: systems metabolomics using interpretable learning and evolution. BMC bioinformatics 22(1)\",\n        \"et al.: Plasma metabolite profiles of alzheimer’s disease and mild cognitive impairment. Journal of Proteome Research 13(5)\",\n        \": Interpretable machine learning for early neurological deterioration prediction in atrial fibrillation-related stroke\",\n        \": Long-term outcomes of real-world korean patients with atrial-fibrillation-related stroke and severely decreased ejection fraction\",\n        \": Clinically applicable machine learning approaches to identify attributes of chronic kidney disease (ckd) for use in low-cost diagnostic screening\",\n        \"Univ. California\",\n        \": Understanding early childhood obesity via interpretation of machine learning model predictions\",\n        \"H.: Explainable machine-learning predictions for complications after pediatric congenital heart surgery. Scientific reports 11(1)\",\n        \": An explainable supervised machine learning predictor of acute kidney injury after adult deceased donor liver transplantation\",\n        \"S.: Deepaise–an interpretable and recurrent neural survival model for early prediction of sepsis. Artificial Intelligence in Medicine 113\",\n        \": Regression models and life-tables\",\n        \"a freely accessible critical care database. Scientific data 3(1)\",\n        \"Z.: Attention-based deep recurrent model for survival prediction. ACM Transactions on Computing for Healthcare 2(4)\",\n        \"D.W.: Applied Survival Analysis: Regression Modeling of Time-to-Event Data. John Wiley & Sons\",\n        \"et al.: The support prognostic model: Objective estimates of survival for seriously ill hospitalized adults. Annals of internal medicine 122(3)\",\n        \"et al.: The genomic and transcriptomic architecture of 2\",\n        \": Tracer: A framework for facilitating accurate and interpretable analytics for high stakes applications\",\n        \"A.: Film: Visual reasoning with a general conditioning layer. In: Proceedings of the AAAI Conference on Artificial Intelligence\",\n        \": Retainvis: Visual analytics with interpretable and interactive recurrent neural networks on electronic medical records\",\n        \": Retain: An interpretable predictive model for healthcare using reverse time attention mechanism\",\n        \"S.: A guide for the utilization of health insurance review and assessment service national patient samples. Epidemiology and health 36 (2014)\",\n        \"M.S.: An explainable system for diagnosis and prognosis of covid-19. IEEE Internet of Things Journal 8(21)\",\n        \"et al.: An interpretable mortality prediction model for covid-19 patients. Nature machine intelligence 2(5)\",\n        \"T.: Fundamentals of predictive text mining: Springer science & business media (2010)\",\n        \": Interpretable ai model-based predictions of ecg changes in covid-recovered patients\",\n        \"S.: Targeting the cholinergic anti-inflammatory pathway with vagus nerve stimulation in patients with covid-19? Bioelectronic medicine 6(1)\",\n        \": Pay attention to the cough: Early diagnosis of covid-19 using interpretable symptoms embeddings with cough sound signal processing\",\n        \"T.: Tabnet: Attentive interpretable tabular learning. In: AAAI\",\n        \"G.: Visualizing data using t-sne. Journal of machine learning research 9(11) (2008)\",\n        \"G.: A comprehensive explanation framework for biomedical time series classification. IEEE Journal of Biomedical and Health Informatics 25(7)\",\n        \"H.: Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861 (2017)\",\n        \": Af classification from a short single lead ecg recording: The physionet/computing in cardiology challenge 2017\",\n        \"U.R.: Han-ecg: An interpretable atrial fibrillation detection model using hierarchical attention networks. Computers in biology and medicine 127\",\n        \": A robust interpretable deep learning classifier for heart anomaly detection without segmentation\",\n        \"R.G.: Recent advances in heart sound analysis. Physiological measurement 38\",\n        \"H.E.: Physiobank\",\n        \"C.: Dexar: Deep explainable sensor-based activity recognition in smart-home environments. Proceedings of the ACM on Interactive\",\n        \"A.: Healthxai: Collaborative and explainable ai for supporting early diagnosis of cognitive decline. Future Generation Computer Systems 116\",\n        \": Modelling and identification of characteristic kinematic features preceding freezing of gait with convolutional neural networks and layer-wise relevance propagation\",\n        \"A.: Freezing of gait in parkinson’s disease: the impact of dual-tasking and turning. Movement Disorders 25(15)\",\n        \"E.: Explainable artificial intelligence for covid-19 diagnosis through blood test variables. Journal of Control\",\n        \"R.: Interpretml: A unified framework for machine learning interpretability. arXiv preprint arXiv:1909.09223 (2019)\",\n        \": Explaining machine learning based diagnosis of covid-19 from routine blood tests with decision trees and criteria graphs\",\n        \"J.: Explainable data analytics for disease and healthcare informatics. In: 25th International Database Engineering & Applications Symposium\",\n        \"S.: Interpretable machine learning: A case study of healthcare. In: 2021 International Symposium on Networks\",\n        \": Interpretable prediction of diabetes from tabular health screening records using an attentional neural network\",\n        \"S.: On the interpretability of machine learning-based model for predicting hypertension. BMC medical informatics and decision making 19(1)\",\n        \": Using machine learning on cardiorespiratory fitness data for predicting hypertension: The henry ford exercise testing (fit) project\",\n        \"B.E.: Predictive learning via rule ensembles. The annals of applied statistics\",\n        \": Automated and interpretable m-health discrimination of vocal cord pathology enabled by machine learning\",\n        \": Exmed: An ai tool for experimenting explainable ai techniques on medical data analytics\",\n        \": A comparison of explanations given by explainable artificial intelligence methods on analysing electronic health records\",\n        \"G.: Explainable machine learning can outperform cox regression predictions and provide insights in breast cancer survival. Scientific reports 11(1)\",\n        \"M.S.: Random survival forests. The annals of applied statistics 2(3)\",\n        \"A.: An efficient training algorithm for kernel survival support vector machines. arXiv preprint arXiv:1611.07054 (2016)\",\n        \"In: 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\",\n        \"M.: Cross-site transportability of an explainable artificial intelligence model for acute kidney injury prediction. Nature communications 11(1)\",\n        \"J.R.: The greater plains collaborative: a pcornet clinical research data network. Journal of the American Medical Informatics Association 21(4)\",\n        \"Q.: Domain adaptation via transfer component analysis. IEEE transactions on neural networks 22(2)\",\n        \": Using explainable machine learning to characterise data drift and detect emergent health risks for emergency department admissions during covid-19\",\n        \": An interpretable deep learning framework for health monitoring systems: A case study of eye state detection using eeg signals\",\n        \"C.: Prediction of caregiver quality of life in amyotrophic lateral sclerosis using explainable machine learning. Scientific Reports 11(1)\",\n        \": Explainable artificial intelligence for pharmacovigilance: What features are important when predicting adverse outcomes? Computer Methods and Programs in Biomedicine 212\",\n        \": Vbridge: Connecting the dots between features and data to explain healthcare models\",\n        \"a paediatric-specific intensive care database. Scientific data 7(1)\",\n        \": Evaluating local interpretable model-agnostic explanations on clinical machine learning classification models\",\n        \"G.D.: Early prediction of sepsis from clinical data: the physionet/computing in cardiology challenge 2019. In: 2019 Computing in Cardiology (CinC)\",\n        \": Towards an empirically determined scale of trust in computerized systems: distinguishing concepts and types of trust\",\n        \": A qualitative research framework for the design of user-centered displays of explanations for machine learning model predictions in healthcare\",\n        \"J.A.: Predicting stroke risk with an interpretable classifier. IEEE Access 9\",\n        \"G.: Dempster’s rule of combination. International Journal of Approximate Reasoning 79\",\n        \"R.M.: Ada-whips: explaining adaboost classification with applications in the health sciences. BMC Medical Informatics and Decision Making 20(1)\",\n        \"X.: Explainability metrics of deep convolutional networks for photoplethysmography quality assessment. IEEE Access 9\",\n        \"J.: Deep residual learning for image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\n        \": Insights into the problem of alarm fatigue with physiologic monitor devices: a comprehensive observational study of consecutive intensive care unit patients\",\n        \"X.: Deep learning approaches for plethysmography signal quality assessment in the presence of atrial fibrillation. Physiological measurement 40(12)\",\n        \": Uncertainty-aware deep ensembles for reliable and explainable predictions of clinical time series\",\n        \"E.: The ucr time series archive. IEEE/CAA Journal of Automatica Sinica 6(6)\",\n        \"R.: Learning similarities between irregularly sampled short multivariate time series from ehrs (2016)\",\n        \"M.: Explaining machine learning models for clinical gait analysis. ACM Transactions on Computing for Healthcare (HEALTH) 3(2)\",\n        \"a large-scale ground reaction force dataset of healthy and impaired gait. Scientific Data 7(1)\",\n        \"T.C.: Generalized n-dimensional biomechanical field analysis using statistical parametric mapping. Journal of biomechanics 43(10)\",\n        \": Explainable multivariate time series classification: A deep neural network which learns to attend to important variables as well as time intervals\",\n        \"J.R.: Bci2000: a general-purpose brain-computer interface (bci) system. IEEE Transactions on biomedical engineering 51(6)\",\n        \"S.-I.: From local explanations to global understanding with explainable ai for trees. Nature Machine Intelligence 2(1)\",\n        \"D.: A survey on the robustness of feature importance and counterfactual explanations. arXiv preprint arXiv:2111.00358 (2021)\",\n        \"B.: The (un) reliability of saliency methods. In: Explainable AI: Interpreting\",\n        \": On the robustness of interpretability methods\",\n        \"S.: Tsviz: Demystification of deep learning models for time-series analysis. IEEE Access 7\",\n        \"In: 2020 IEEE Sixth International Conference on Big Data Computing Service and Applications (BigDataService)\",\n        \"T.: Towards robust interpretability with self-explaining neural networks. Advances in neural information processing systems 31 (2018)\",\n        \": A human-grounded evaluation benchmark for local explanations of machine learning\",\n        \": Current challenges and future opportunities for xai in machine learning-based clinical decision support systems: a systematic review\",\n        \"R.: Physician understanding\",\n        \"Y.: Analyzing description\",\n        \"B.Y.: Designing theory-driven user-centric explainable ai. In: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems\",\n        \"D.A.: Three-stage intelligent support of clinical decision making for higher trust\",\n        \"J.: The what-if tool: Interactive probing of machine learning models. IEEE transactions on visualization and computer graphics 26(1)\",\n        \"In: International Conference on Machine Learning\",\n        \"B.: Towards automatic concept-based explanations. Advances in Neural Information Processing Systems 32 (2019)\",\n        \"B.: Explaining classifiers with causal concept effect (cace). arXiv preprint arXiv:1907.07165 (2019)\",\n        \"P.: On completeness-aware concept-based explanations in deep neural networks. Advances in Neural Information Processing Systems 33\",\n        \": Fast and interpretable classification of small x-ray diffraction datasets using data augmentation and deep neural networks\",\n        \": Network dissection: Quantifying interpretability of deep visual representations\",\n        \"J.: Interpretation of deep temporal representations by selective visualization of internally activated nodes. arXiv preprint arXiv:2004.12538 (2020)\",\n        \"U.: The next generation of medical decision support: A roadmap toward transparent expert companions. Frontiers in artificial intelligence 3\",\n        \"H.: Toward human–ai interfaces to support explainability and causability in medical ai. Computer 54(10)\",\n        \"H.: Measuring the quality of explanations: the system causability scale (scs). KI-Künstliche Intelligenz 34(2)\",\n        \"Y.: Toward causal representation learning. Proceedings of the IEEE 109(5)\",\n        \"A.: The ten commandments of ethical medical ai. Computer 54(07)\",\n        \"N.: Equality of opportunity in supervised learning. Advances in neural information processing systems 29 (2016)\",\n        \"J.: Artificial intelligence and patient-centered decision-making. Philosophy & Technology 34(2)\",\n        \"K.H.: Explainable artificial intelligence based framework for non-communicable diseases prediction. IEEE Access 9\",\n        \": Integrating machine learning with symbolic reasoning to build an explainable ai model for stroke prediction\",\n        \"et al.: Asymptomatic internal carotid artery stenosis and cerebrovascular risk stratification. Journal of vascular surgery 52(6)\",\n        \": Explaining the neural network: A case study to model the incidence of cervical cancer\",\n        \": Parkinson’s disease diagnosis: towards grammar-based explainable artificial intelligence\",\n        \"In: 2015 IEEE 28th International Symposium on Computer-based Medical Systems\",\n        \"M.A.: Explainable prediction of acute myocardial infarction using machine learning and shapley values. IEEE Access 8\",\n        \": Automated identification of myocardial infarction using harmonic phase distribution pattern of ecg data\",\n        \": Towards interpretable and maintainable supervised learning using shapley values in arrhythmia\",\n        \"A.: A supervised machine learning algorithm for arrhythmia analysis. In: Computers in Cardiology 1997\",\n        \": Development of an explainable prediction model of heart failure survival by using ensemble trees\",\n        \"M.A.: Survival analysis of heart failure patients: A case study. PloS one 12(7)\",\n        \"M.: Using explainable machine learning to identify patients at risk of reattendance at discharge from emergency departments. Scientific reports 11(1)\",\n        \"Z.: Interpretable clinical prediction via attention-based neural network. BMC Medical Informatics and Decision Making 20(3)\",\n        \": Hospital admission location prediction via deep interpretable networks for the year-round improvement of emergency patient care\",\n        \"T.: Medical recommender systems based on continuous-valued logic and multi-criteria decision operators\",\n        \"N.: Predicting the evolution of pain relief: Ensemble learning by diversifying model explanations. ACM Transactions on Computing for Healthcare 2(4)\",\n        \"Computers and Artificial Intelligence (ECAI)\",\n        \"Y.: Making sense of sleep: Multimodal sleep stage classification in a large\",\n        \"S.: The national sleep research resource: towards a sleep data commons. Journal of the American Medical Informatics Association 25(10)\",\n        \"T.: Opitrack: A wearable-based clinical opioid use tracker with temporal convolutional attention networks. Proceedings of the ACM on Interactive\",\n        \"H.: Interpretable time-aware and co-occurrence-aware network for medical prediction. BMC medical informatics and decision making 21(1)\",\n        \": Dynamic and explainable machine learning prediction of mortality in patients in the intensive care unit: a retrospective study of high-frequency data in electronic patient records\",\n        \"D.A.: Deep interpretable early warning system for the detection of clinical deterioration. IEEE journal of biomedical and health informatics 24(2)\",\n        \"B.: Explainable artificial intelligence model to predict acute critical illness from electronic health records. Nature communications 11(1)\",\n        \": Explainable deep learning for readmission prediction with tree-glove embedding\",\n        \": Hitanet: Hierarchical time-aware attention networks for risk prediction on electronic health records\",\n        \"B.: Cefes: A cnn explainable framework for ecg signals. Artificial Intelligence in Medicine 115\",\n        \"P.: Ecg signals (1000 fragments). Mendeley Data\",\n        \"Z.: Interpretable multivariate time series classification based on prototype learning. In: International Conference on Green\",\n        \": Interpreting deep glucose predictive models for diabetic people using retain\",\n        \": Adversarial representation learning for robust patient-independent epileptic seizure detection\",\n        \"J.: The temple university hospital eeg data corpus. Frontiers in neuroscience 10\",\n        \"A.: Extraction and interpretation of deep autoencoder-based temporal features from wearables for forecasting personalized mood\",\n        \": A multi-attention collaborative deep learning approach for blood pressure prediction\"\n    ],\n    \"reasoning\": \"Selected these 198 references because they represent foundational work and recent advances in Explainable AI for clinical and remote health applications: a survey on tabular and time series data, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}