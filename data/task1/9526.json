{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 203 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Approximate Computing Survey, Part II: Application-Specific & Architectural Approximation Techniques and Applications\n\nPaper Abstract: Abstract. The challenging deployment of compute-intensive applications from domains such Artificial Intelligence (AI) and Digital Signal Processing (DSP), forces the community of computing systems to explore new design approaches. Approximate Computing appears as an emerging solution, allowing to tune the quality of results in the design of a system in order to improve the energy efficiency and/or performance. This radical paradigm shift has attracted interest from both academia and industry, resulting in significant research on approximation techniques and methodologies at different design layers (from system down to integrated circuits). Motivated by the wide appeal of Approximate Computing over the last 10 years, we conduct a two-part survey to cover key aspects (e.g., terminology and applications) and review the state-of-the art approximation techniques from all layers of the traditional computing stack. In Part II of our survey, we classify and present the technical details of application-specific and architectural approximation techniques, which both target the design of resource-efficient processors/accelerators & systems. Moreover, we present a detailed analysis of the application spectrum of Approximate Computing and discuss open challenges and future directions.\n\n{retrieved_text}\n\nGenerate exactly 203 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 203\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Approximate Computation with Outlier Detection in Topaz\",\n        \"Approximate Restoring Dividers Using Inexact Cells and Estimation From Partial Remainders\",\n        \"X-NVDLA: Runtime Accuracy Configurable NVDLA Based on Applying Voltage Overscaling to Computing and Memory Units\",\n        \"BlinkDB: Queries with Bounded Errors and Bounded Response Times on Very Large Data\",\n        \"9.1 A 7nm 4-Core AI Chip with 25.6TFLOPS Hybrid FP8 Training, 102.4TOPS INT4 Inference and Workload-Aware Throttling\",\n        \"Approximate Computing: Challenges and Opportunities\",\n        \"Dual-Quality 4:2 Compressors for Utilizing in Dynamic Accuracy Configurable Multipliers\",\n        \"RAP-CLA: A Reconfigurable Approximate Carry Look-Ahead Adder\",\n        \"SnaPEA: Predictive Early Activation for Reducing Computation in Deep Convolutional Neural Networks\",\n        \"Fuzzy Memoization for Floating-Point Multimedia Applications\",\n        \"General-Purpose Code Acceleration with Limited-Precision Analog Computation\",\n        \"Input Selection for Fast Feature Engineering\",\n        \"An Improved Logarithmic Multiplier for Energy-Efficient Neural Computing\",\n        \"Language and Compiler Support for Auto-Tuning Variable-Accuracy Algorithms\",\n        \"A Review of Approximate Computing Techniques Towards Fault Mitigation in HW/SW Systems\",\n        \"Hardware Approximate Techniques for Deep Neural Network Accelerators: A Survey\",\n        \"Cross-Layer Approximation For Printed Machine Learning Circuits\",\n        \"Co-Design of Approximate Multilayer Perceptron for Ultra-Resource Constrained Printed Circuits\",\n        \"Model-to-Circuit Cross-Approximation For Printed Machine Learning Classifiers\",\n        \"Green: A Framework for Supporting Energy-Conscious Programming Using Controlled Approximation\",\n        \"Woongki Baek and Trishul M\",\n        \"LEXACT: Low Energy N-Modular Redundancy Using Approximate Computing for Real-Time Multicore Processors\",\n        \"Trends in Data Centre Energy Consumption under the European Code of Conduct for Data Centre Energy Efficiency\",\n        \"Jaswinder Pal Singh\",\n        \"Anand Raghunathan\",\n        \"Toward a Systematic Survey for Carbon Neutral Data Centers\",\n        \"Juli√°n Mateus-Vargas\",\n        \"Chakradhar and Anand Raghunathan\",\n        \"A Priority-Based 6T/8T Hybrid SRAM Architecture for Aggressive Voltage Scaling in Video Applications\",\n        \"Energy-Efficient Digital Signal Processing via Voltage-Overscaling-Based Residue Number System\",\n        \"Efficient Implementations of Reduced Precision Redundancy (RPR) Multiply and Accumulate (MAC)\",\n        \"On the Design of Approximate Restoring Dividers for Error-Tolerant Applications\",\n        \"Algorithm and Design of a Fully Parallel Approximate Coordinate Rotation Digital Computer (CORDIC)\",\n        \"Design, Evaluation and Application of Approximate High-Radix Dividers\",\n        \"Only Train Once: A One-Shot Neural Network Training And Pruning Framework\",\n        \"Ganesh Gopalakrishnan\",\n        \"Scalable Effort Hardware Design\",\n        \"ERSA: Error Resilient System Architecture for Probabilistic Applications\",\n        \"A Lightweight Posit Processing Unit for RISC-V Processors in Deep Neural Network Applications\",\n        \"Approximation Opportunities in Edge Computing Hardware: A Systematic Literature Review\",\n        \"Towards a Compiler for Reals\",\n        \"and Karthikeyan Sankaralingam\",\n        \"Block-Based Carry Speculative Approximate Adder for Energy-Efficient Applications\",\n        \"Approximate Multipliers Based on New Approximate Compressors\",\n        \"Risk-5: Controlled Approximations for RISC-V\",\n        \"Verifying Safety and Accuracy of Approximate Parallel Programs via Canonical Sequentialization\",\n        \"Approximate SRAMs With Dynamic Energy-Quality Management\",\n        \"Approximate Multipliers With Dynamic Truncation for Energy Reduction via Graceful Quality Degradation\",\n        \"DyVEDeep: Dynamic Variable Effort Deep Neural Networks\",\n        \"Acceleration Techniques and Evaluation on Multi-Core CPU, GPU and FPGA for Image Processing and Super-Resolution\",\n        \"Ricardo Bianchini\",\n        \"ApproxTrain: Fast Simulation of Approximate Multipliers for DNN Training and Inference\",\n        \"ARA: Cross-Layer Approximate Computing Framework based Reconfigurable Architecture for CNNs\",\n        \"Hui Guo and Cindy Rubio-Gonz√°lez\",\n        \"Low-Power Digital Signal Processing Using Approximate Adders\",\n        \"Jie Han and Michael Orshansky\",\n        \"EIE: Efficient Inference Engine on Compressed Deep Neural Network\",\n        \"Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding\",\n        \"Learning both Weights and Connections for Efficient Neural Networks\",\n        \"Giuseppe Maria Sarda\",\n        \"A Cross-Layer Approach Towards Developing Efficient Embedded Deep Learning Systems\",\n        \"Francesco Buttafuoco\",\n        \"Using Code Perforation to Improve Performance, Reduce Energy Consumption, and Respond to Failures\",\n        \"Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures\",\n        \"Binarized Neural Networks\",\n        \"State of IoT 2023\",\n        \"Skirmantas Kligys\",\n        \"Swagath Venkataramani\",\n        \"An Error Compensation Technique for Low-Voltage DNN Accelerators\",\n        \"Approximate Radix-8 Booth Multipliers for Low-Power and High-Performance Operation\",\n        \"Low-Power Unsigned Divider and Square Root Circuit Designs Using Adaptive Approximation\",\n        \"LEVAX: An Input-Aware Learning-Based Error Model of Voltage-Scaled Functional Units\",\n        \"Matthias Herrmann\",\n        \"Aleksandar Vitorovic\",\n        \"Cristiana Bolchini\",\n        \"Architecture-Aware Approximate Computing\",\n        \"Efficient Mitchell‚Äôs Approximate Log Multipliers for Convolutional Neural Networks\",\n        \"Data Access Skipping for Recursive Partitioning Methods\",\n        \"A Giray Yaƒülƒ±k√ßƒ±\",\n        \"Quantizing Deep Convolutional Networks for Efficient Inference: A Whitepaper\",\n        \"Low-Power Multimedia System Design by Aggressive Voltage Scaling\",\n        \"George Plastiras\",\n        \"Fine-Grained Floating-Point Precision Analysis\",\n        \"Bronis R. de Supinski\",\n        \"Early Accurate Results for Advanced Analytics on MapReduce\",\n        \"Vadim Lebedev and Victor Lempitsky\",\n        \"Miodrag Potkonjak\",\n        \"George Chatzitsompanis\",\n        \"Approximate Computing Survey, Part I: Terminology and Software & Hardware Approximation Techniques\",\n        \"Kiamal Pekmestzi\",\n        \"Improving Power of DSP and CNN Hardware Accelerators Using Approximate Floating-Point Multipliers\",\n        \"Ioannis Stratakos\",\n        \"Approximate Hybrid High Radix Encoding for Energy-Efficient Inexact Multipliers\",\n        \"Walking through the Energy-Error Pareto Frontier of Approximate Multipliers\",\n        \"Pruning Filters for Efficient ConvNets\",\n        \"Karthik Pattabiraman\",\n        \"Design of Approximate Radix-4 Booth Multipliers for Error-Tolerant Computing\",\n        \"Design and Evaluation of Approximate Logarithmic Multipliers for Low Power Error-Tolerant Applications\",\n        \"Computation Error Analysis in Digital Signal Processing Systems With Overscaled Supply Voltage\",\n        \"Amir Yazdanbakhsh\",\n        \"DEVoT: Dynamic Delay Modeling of Functional Units Under Voltage and Temperature Variations\",\n        \"Amir Yazdanbaksh\",\n        \"Design of Approximate Booth Squarer for Error-Tolerant Computing\",\n        \"Srimat Chakradhar\",\n        \"Daniel Osei-Kuffuor\",\n        \"Natalie Enright Jerger\",\n        \"Andreas Moshovos\",\n        \"and Natalie Enright Jerger\",\n        \"Parallelizing Sequential Programs with Statistical Accuracy Tests\",\n        \"Stelios Sidiroglou\",\n        \"Rajkishore Barik\",\n        \"A Survey of Techniques for Approximate Computing\",\n        \"A Survey of CPU-GPU Heterogeneous Computing Techniques\",\n        \"Design and Analysis of Approximate Compressors for Multiplication\",\n        \"A Taxonomy of General Purpose Approximate Computing Techniques\",\n        \"Hadi Esmaeilzadeh\",\n        \"Syed Shakib Sarwar\",\n        \"Libraries of Approximate Circuits: Automated Design and Application in CNN Accelerators\",\n        \"Muhammad Abdullah Hanif\",\n        \"Nathaniel Bleier\",\n        \"Berkin Ozisikyilmaz\",\n        \"Tiago Trevisan Jost\",\n        \"Automated High-Level Generation of Low-Power Approximate Computing Circuits\",\n        \"Giuseppe Tagliavini\",\n        \"Energy-Efficient and Improved Image Recognition with Conditional Deep Learning\",\n        \"Abhronil Sengupta\",\n        \"Energy-Efficient Object Detection Using Semantic Decomposition\",\n        \"Koushik Chakraborty\",\n        \"SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks\",\n        \"ExpAX: A Framework for Automating Approximate Programming\",\n        \"Approximate Reverse Carry Propagate Adder for Energy-Efficient DSP Applications\",\n        \"A Two-Stage Operand Trimming Approximate Logarithmic Multiplier\",\n        \"and Theocharis Theocharides\",\n        \"Roldan Pozo and Bruce Miller\",\n        \"Arnab Raha and Vijay Raghunathan\",\n        \"Approximating Beyond the Processor: Exploring Full-System Energy-Accuracy Tradeoffs in a Smart Camera System\",\n        \"Spatial Memoization: Concurrent Instruction Reuse to Correct Timing Errors in SIMD Architectures\",\n        \"Approximate Memory Compression\",\n        \"Vijayalakshmi Srinivasan\",\n        \"Computing the Similarity Estimate Using Approximate Memory\",\n        \"Hong Diep Nguyen\",\n        \"Minimally Biased Multipliers for Approximate Integer and Floating-Point Multiplication\",\n        \"Aleksandar Ignjatovic\",\n        \"A Majority-Based Imprecise Multiplier for Ultra-Efficient Approximate Image Multiplication\",\n        \"Davoud Anoushe Jamshidi\",\n        \"D. Anoushe Jamshidi\",\n        \"Muhammad Shafique\",\n        \"ACCEPT: A Programmer-Guided Compiler Framework for Practical Approximate Computing\",\n        \"Danushen Gnanapragasam\",\n        \"Approximate Storage in Solid-State Memories\",\n        \"John Sartori and Rakesh Kumar\",\n        \"Design and Applications of Approximate Circuits by Gate-Level Pruning\",\n        \"Walaa El-Harouni\",\n        \"A Cross-Layer Multicore Architecture to Tradeoff Program Accuracy and Resilience Overheads\",\n        \"Sensitivity-Based Error Resilient Techniques With Heterogeneous Multiply‚ÄìAccumulate Unit for Voltage Scalable Deep Neural Network Accelerators\",\n        \"Stelios Sidiroglou-Douskos\",\n        \"DAISM: Digital Approximate In-SRAM Multiplier-based Accelerator for DNN Training and Inference\",\n        \"Eon: A Language and Runtime System for Perpetual Systems\",\n        \"History ‚Äì RISC-V International\",\n        \"Georgios Zervakis\",\n        \"Jaswanth Sreeram and Santosh Pande\",\n        \"Exploiting Errors for Efficiency: A Survey from Circuits to Applications\",\n        \"PANDORA: An Architecture-Independent Parallelizing Approximation-Discovery Framework\",\n        \"Comparison and Extension of Approximate 4-2 Compressors for Low-Power Approximate Multipliers\",\n        \"CHIP: CHannel Independence-based Pruning for Compact Neural Networks\",\n        \"DeepAxe: A Framework for Exploration of Approximation and Reliability Trade-offs in DNN Accelerators\",\n        \"Thannirmalai Somu Muthukaruppan\",\n        \"Chong Min John Tan and Mehul Motani\",\n        \"Jan-Willem van de Meent\",\n        \"Temporal Approximate Function Memoization\",\n        \"Sanjeev Sripadraj Murthy\",\n        \"TOSAM: An Energy-Efficient Truncation- and Rounding-Based Scalable Approximate Multiplier\",\n        \"Ali Afzali-Kusha\",\n        \"Evolutionary Approach to Approximate Digital Circuits Design\",\n        \"Konstantinos Parasyris\",\n        \"Design and Analysis of Area and Power Efficient Approximate Booth Multipliers\",\n        \"Efficient AI System Design With Cross-Layer Approximate Computing\",\n        \"Matthai Phillipose\",\n        \"Vivek Kozhikkottu\",\n        \"Neural Pruning via Growing Regularization\",\n        \"Enabling Energy-Efficient and Reliable Neural Network via Neuron-Level Voltage Scaling\",\n        \"Resilience-Aware Frequency Tuning for Neural-Network-Based Approximate Computing Chips\",\n        \"Hybrid Low Radix Encoding-Based Approximate Booth Multipliers\",\n        \"AxBMs: Approximate Radix-8 Booth Multipliers for High-Performance FPGA-Based Accelerators\",\n        \"Learning Structured Sparsity in Deep Neural Networks\",\n        \"Approximate Computing: A Survey\",\n        \"AxBench: A Multiplatform Benchmark Suite for Approximate Computing\",\n        \"AxBench: A Benchmark Suite for Approximate Computing Across the System Stack\",\n        \"Bradley Thwaites\",\n        \"Pejman Lotfi-Kamran\",\n        \"Toward Dynamic Precision Scaling\",\n        \"Scalpel: Customizing DNN Pruning to the Underlying Hardware Parallelism\",\n        \"RED : Looking for Redundancies for Data-Free Structured Compression of Deep Neural Networks\",\n        \"RED++ : Data-Free Pruning of Deep Neural Networks via Input Splitting and Output Merging\",\n        \"Progressive Scaled STT-RAM for Approximate Computing in Multimedia Applications\",\n        \"RoBA Multiplier: A Rounding-Based Approximate Multiplier for High-Speed yet Energy-Efficient Digital Signal Processing\",\n        \"VOSsim: A Framework for Enabling Fast Voltage Overscaling Simulation for Approximate Computing Circuits\",\n        \"Multi-Level Approximate Accelerator Synthesis Under Voltage Island Constraints\",\n        \"Leveraging Hardware Caches for Memoization\",\n        \"Kartheek Rangineni\",\n        \"Sapprox: Enabling Efficient and Accurate Approximations on Sub-Datasets with Distribution-Aware Online Sampling\",\n        \"DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients\",\n        \"Design of Approximate Radix-256 Booth Encoding for Error-Tolerant Computing\"\n    ],\n    \"reasoning\": \"Selected these 203 references because they represent foundational work and recent advances in Approximate Computing Survey, Part II: Application-Specific & Architectural Approximation Techniques and Applications, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}