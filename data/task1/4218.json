{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 49 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: How do I update my model? On the resilience of Predictive Process Monitoring models to change\n\nPaper Abstract: Abstract Existing well investigated Predictive Process Monitoring techniques typically construct a predictive model based on past process executions, and then use this model to predict the future of new ongoing cases, without the possibility of updating it with new cases when they complete their execution. This can make Predictive Process Monitoring too rigid to deal with the variability of processes working in real environments that continuously evolve and/or exhibit new variant behaviours over time. As a solution to this problem, we evaluate the use of three different strategies that allow the periodic rediscovery or incremental construction of the predictive model so as to exploit new available data. The evaluation focuses on the performance of the new learned predictive models, in terms of accuracy and time, against the original one, and uses a number of real and synthetic datasets with and without explicit Concept Drift. The results provide an evidence of the potential of incremental learning algorithms for predicting process monitoring in real environments.\n\n{retrieved_text}\n\nGenerate exactly 49 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 49\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"BPI Challenge 2011 Event Log\",\n        \"Entropy as a measure of log variability\",\n        \"Algorithms for hyper-parameter optimization\",\n        \"Random search for hyper-parameter optimization\",\n        \"Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures\",\n        \"Dealing with concept drifts in process mining\",\n        \"Exploring the effect of context information on deep learning business process predictions\",\n        \"Artificial intelligence, the next digital frontier?\",\n        \"Learning accurate LSTM models of business processes\",\n        \"Online techniques for dealing with concept drift in process mining\",\n        \"Genetic algorithms for hyperparameter optimization in predictive business process monitoring\",\n        \"Clustering-based predictive process monitoring\",\n        \"Predictive process monitoring methods: Which one suits me best?\",\n        \"An eye into the future: Leveraging a-priori knowledge in predictive business process monitoring\",\n        \"Predicting process behaviour using deep learning\",\n        \"Discovering context-aware models for predicting business process performances\",\n        \"Learning with drift detection\",\n        \"A survey on concept drift adaptation\",\n        \"Incremental learning algorithms and applications\",\n        \"Random decision forests\",\n        \"Nirdizati: A web-based tool for predictive process monitoring\",\n        \"Complex symbolic sequence encodings for predictive monitoring of business processes\",\n        \"Fast and accurate business process drift detection\",\n        \"Online process discovery to detect concept drifts in ltl-based declarative process models\",\n        \"Predictive monitoring of business processes\",\n        \"Handling concept drift in predictive process monitoring\",\n        \"Predictive monitoring of heterogeneous service-oriented business networks: The transport and logistics case\",\n        \"Comparing and combining predictive business process monitoring techniques\",\n        \"Perceptrons: An introduction to computational geometry\",\n        \"Process mining for healthcare: Characteristics and challenges\",\n        \"Incremental predictive process monitoring: The next activity case\",\n        \"The temporal logic of programs\",\n        \"Induction of decision trees\",\n        \"Nirdizati 2.0: New features and redesigned backend\",\n        \"Prediction of remaining service execution time using stochastic petri nets with arbitrary firing delays\",\n        \"Process mining in healthcare: A literature review\",\n        \"Incremental learning from noisy data\",\n        \"Predictive business process monitoring with LSTM neural networks\",\n        \"Predictive business process monitoring via generative adversarial nets: The case of next event prediction\",\n        \"Outcome-oriented predictive process monitoring: Review and benchmark\",\n        \"Temporal stability in predictive process monitoring\",\n        \"Netdata\",\n        \"Time prediction based on process mining\",\n        \"Process mining manifesto\",\n        \"Bpi challenge 2012\",\n        \"BPIC 2015\",\n        \"Bpi challenge 2018\",\n        \"Change patterns and change support features - enhancing flexibility in process-aware information systems\",\n        \"Learning in the presence of concept drift and hidden contexts\"\n    ],\n    \"reasoning\": \"Selected these 49 references because they represent foundational work and recent advances in How do I update my model? On the resilience of Predictive Process Monitoring models to change, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}