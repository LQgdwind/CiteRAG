{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 58 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Efficient Conformance Checking using Approximate Alignment Computation with Tandem Repeats\n\nPaper Abstract: Abstract Conformance checking encompasses a body of process mining techniques which aim to find and describe the differences between a process model capturing the expected process behavior and a corresponding event log recording the observed behavior. Alignments are an established technique to compute the distance between a trace in the event log and the closest execution trace of a corresponding process model. Given a cost function, an alignment is optimal when it contains the least number of mismatches between a log trace and a model trace. Determining optimal alignments, however, is computationally expensive, especially in light of the growing size and complexity of event logs from practice, which can easily exceed one million events with traces of several hundred activities. A common limitation of existing alignment techniques is the inability to exploit repetitions in the log. By exploiting a specific form of sequential pattern in traces, namely tandem repeats, we propose a novel approximate technique that uses pre- and post-processing steps to compress the length of a trace and recomputes the alignment cost while guaranteeing that the cost result never under-approximates the optimal cost. In an extensive empirical evaluation with 50 real-life model-log pairs and against six state-of-the-art alignment techniques, we show that the proposed compression approach systematically outperforms the baselines by up to an order of magnitude in the presence of traces with repetitions, and that the cost over-approximation, when it occurs, is negligible.\n\n{retrieved_text}\n\nGenerate exactly 58 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 58\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Fundamentals of Business Process Management\",\n        \"Process Mining - Data Science in Action, Second Edition\",\n        \"Conformance checking using cost-based fitness analysis\",\n        \"Efficiently computing alignments: using the extended marking equation\",\n        \"Bpi challenge 2018\",\n        \"Automated discovery of process models from event logs: Review and benchmark\",\n        \"Linear time algorithms for finding and representing all the tandem repeats in a string\",\n        \"Abstractions in process mining: A taxonomy of patterns\",\n        \"Scalable alignment of process models and event logs: An approach based on automata and s-components\",\n        \"Conformance checking of processes based on monitoring real behavior\",\n        \"Genetic process mining\",\n        \"Scalable process discovery and conformance checking\",\n        \"Complete and interpretable conformance checking of business processes\",\n        \"Aligning observed and modeled behavior\",\n        \"Scalable conformance checking of business processes\",\n        \"Aligning real process executions and prescriptive process models through automated planning\",\n        \"Petri nets, event structures and domains, part I\",\n        \"Aligning modeled and observed behavior: a compromise between complexity and quality\",\n        \"Computing alignments of well-formed process models using local search\",\n        \"An evolutionary technique to approximate multiple optimal alignments\",\n        \"Estimating process conformance by trace sampling and result approximation\",\n        \"Online conformance checking using behavioural patterns\",\n        \"Decomposing petri nets for process mining: A generic approach\",\n        \"Single-entry single-exit decomposed conformance checking\",\n        \"Aligning observed and modelled behaviour based on workflow decomposition\",\n        \"Merging alignments for decomposed replay\",\n        \"Recomposing conformance: Closing the circle on decomposed alignment-based conformance checking in process mining\",\n        \"Efficient alignment between event logs and process models\",\n        \"A comparative study of text compression algorithms\",\n        \"A universal algorithm for sequential data compression\",\n        \"Compression of individual sequences via variable-rate coding\",\n        \"Data compression via textual substitution\",\n        \"A technique for high-performance data compression\",\n        \"Data compression with finite windows\",\n        \"Periodic pattern miningâ€“algorithms and applications\",\n        \"The application of petri nets to workflow management\",\n        \"Free choice Petri nets\",\n        \"Soundness and separability of workflow nets in the stepwise refinement approach\",\n        \"An algorithm for the general petri net reachability problem\",\n        \"Incremental construction of minimal acyclic finite-state automata\",\n        \"Replacing suffix trees with enhanced suffix arrays\",\n        \"Diagnosing behavioral differences between business process models: An approach based on event structures\",\n        \"APROMORE: an advanced process model repository\",\n        \"Bpi challenge 2012\",\n        \"Bpi challenge 2013, closed problems\",\n        \"Bpi challenge 2013, incidents\",\n        \"Bpi challenge 2014\",\n        \"Bpi challenge 2015\",\n        \"Bpi challenge 2017\",\n        \"Road traffic fine management process\",\n        \"Sepsis cases - event log\",\n        \"Filtering out infrequent behavior from business process event logs\",\n        \"Discovering block-structured process models from event logs-a constructive approach\",\n        \"Split miner: Discovering accurate and simple business process models from event logs\",\n        \"Automated discovery of structured process models from event logs: The discover-and-structure approach\",\n        \"Fodina: A robust and flexible heuristic process discovery technique\",\n        \"Conformance checking in the large (dataset)\",\n        \"The imprecisions of precision measures in process mining\"\n    ],\n    \"reasoning\": \"Selected these 58 references because they represent foundational work and recent advances in Efficient Conformance Checking using Approximate Alignment Computation with Tandem Repeats, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}