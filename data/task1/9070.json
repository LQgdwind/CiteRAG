{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 64 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning\n\nPaper Abstract: Abstract Online tuning of real-world plants is a complex optimisation problem that continues to require manual intervention by experienced human operators. Autonomous tuning is a rapidly expanding field of research, where learning-based methods, such as Reinforcement Learning-trained Optimisation (RLO) and Bayesian optimisation (BO), hold great promise for achieving outstanding plant performance and reducing tuning times. Which algorithm to choose in different scenarios, however, remains an open question. Here we present a comparative study using a routine task in a real particle accelerator as an example, showing that RLO generally outperforms BO, but is not always the best choice. Based on the study’s results, we provide a clear set of criteria to guide the choice of algorithm for a given tuning task. These can ease the adoption of learning-based autonomous tuning solutions to the operation of complex real-world plants, ultimately improving the availability and pushing the limits of operability of these facilities, thereby enabling scientific and engineering advancements.\n\n{retrieved_text}\n\nGenerate exactly 64 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 64\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Online storage ring optimization using dimension-reduction and genetic algorithms\",\n        \"An algorithm for online optimization of accelerators\",\n        \"Dynamic Programming\",\n        \"Taking the human out of the loop: A review of bayesian optimization\",\n        \"Learning to learn by gradient descent by gradient descent\",\n        \"Learning to optimize: A primer and a benchmark\",\n        \"Learning to optimize\",\n        \"Learning to optimize neural nets\",\n        \"Feedback design for control of the micro-bunching instability based on reinforcement learning\",\n        \"Basic Reinforcement Learning Techniques to Control the Intensity of a Seeded Free-Electron Laser\",\n        \"Bayesian Optimization of a Free-Electron Laser\",\n        \"Online tuning and light source control using a physics-informed Gaussian process\",\n        \"Bayesian optimization of a laser-plasma accelerator\",\n        \"Sample-efficient reinforcement learning for CERN accelerator control\",\n        \"Learning-based optimisation of particle accelerators under partial observability without real-world training\",\n        \"Automated intensity optimisation using reinforcement learning at LEIR\",\n        \"Bayesian Optimization of FEL Performance at LCLS\",\n        \"Policy gradient methods for free-electron laser and terahertz source optimization and stabilization at the FERMI free-electron laser at Elettra\",\n        \"Autonomous control of a particle accelerator using deep reinforcement learning\",\n        \"Automation and control of laser wakefield accelerators using Bayesian optimization\",\n        \"Real-time artificial intelligence for accelerator control: A study at the Fermilab Booster\",\n        \"Bayesian optimization of the beam injection process into a storage ring\",\n        \"Magnetic control of tokamak plasmas through deep reinforcement learning\",\n        \"Feedforward beta control in the KSTAR tokamak by deep reinforcement learning\",\n        \"Development of an operation trajectory design algorithm for control of multiple 0D parameters using deep reinforcement learning in KSTAR\",\n        \"Towards piston fine tuning of segmented mirrors through reinforcement learning\",\n        \"Toward on-sky adaptive optics control using reinforcement learning: Model-based policy optimization for adaptive optics\",\n        \"Deep reinforcement learning for smart calibration of radio telescopes\",\n        \"Optimizing chemical reactions with deep reinforcement learning\",\n        \"Toward autonomous additive manufacturing: Bayesian optimization on a 3D printer\",\n        \"Bayesian optimization for maximum power point tracking in photovoltaic power plants\",\n        \"Intelligent thermal control strategy based on reinforcement learning for space telescope\",\n        \"Application of deep reinforcement learning to thermal control of space telescope\",\n        \"Real-time control using Bayesian optimization: A case study in airborne wind energy systems\",\n        \"Bayesian optimization for radio resource management: Open loop power control\",\n        \"MB2C: Model-based deep reinforcement learning for multi-zone building control\",\n        \"Real-world challenges for multi-agent reinforcement learning in grid-interactive buildings\",\n        \"Commissioning results and electron beam characterization with the S-band photoinjector at SINBAD-ARES\",\n        \"The ARES Linac at DESY\",\n        \"Gaussian Processes for Machine Learning\",\n        \"A simplex method for function minimization\",\n        \"Challenges of real-world reinforcement learning\",\n        \"Domain randomization for transferring deep neural networks from simulation to the real world\",\n        \"Solving Rubik’s cube with a robot hand\",\n        \"Accelerated deep reinforcement learning for fast feedback of beam dynamics at KARA\",\n        \"KINGFISHER: A Framework for Fast Machine Learning Inference for Autonomous Accelerator Systems\",\n        \"Bayesian optimization for dynamic problems\",\n        \"Contextual Gaussian process bandit optimization\",\n        \"OpenAI Gym\",\n        \"Accelerating linear beam dynamics simulations for machine learning applications\",\n        \"Addressing function approximation error in actor-critic methods\",\n        \"Stable Baselines3\",\n        \"BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization\",\n        \"Spatial Variation\",\n        \"Efficient global optimization of expensive black-box functions\",\n        \"SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python\",\n        \"First steps toward an autonomous accelerator, a common project between DESY and KIT\",\n        \"Development and application of online optimization algorithms\",\n        \"Online optimisation of the MAX-IV 3 GeV ring dynamic aperture\",\n        \"Multi-objective particle swarm and genetic algorithm for the optimization of the LANSCE linac operation\",\n        \"Machine based optimization using genetic algorithms in a storage ring\",\n        \"Progress in automatic software-based optimization of accelerator performance\",\n        \"Badger: The Ocelot Optimizer rebirth\",\n        \"Badger: The missing optimizer in ACR\"\n    ],\n    \"reasoning\": \"Selected these 64 references because they represent foundational work and recent advances in Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}