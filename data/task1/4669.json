{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 64 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Conical Classification For Computationally Efficient One-Class Topic Determination\n\nPaper Abstract: Abstract As the Internet grows in size, so does the amount of text based information that exists. For many application spaces it is paramount to isolate and identify texts that relate to a particular topic. While one-class classification would be ideal for such analysis, there is a relative lack of research regarding efficient approaches with high predictive power. By noting that the range of documents we wish to identify can be represented as positive linear combinations of the Vector Space Model representing our text, we propose Conical classification, an approach that allows us to identify if a document is of a particular topic in a computationally efficient manner. We also propose Normal Exclusion, a modified version of Bi-Normal Separation that makes it more suitable within the one-class classification context. We show in our analysis that our approach not only has higher predictive power on our datasets, but is also faster to compute.\n\n{retrieved_text}\n\nGenerate exactly 64 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 64\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Statistical analysis on e-commerce reviews, with sentiment classification using bidirectional recurrent neural network (rnn)\",\n        \"Detection of online fake news using n-gram analysis and machine learning techniques\",\n        \"Detecting opinion spams and fake news using text classification\",\n        \"An intelligent model for online recruitment fraud detection\",\n        \"Detection of text quality flaws as a one-class classification problem\",\n        \"Ontology based similarity for information technology skills\",\n        \"Separation of metallothionein isoforms by micellar electrokinetic capillary chromatography\",\n        \"1t 5-gram version 1.0\",\n        \"Aggregating filter feature selection methods to enhance multiclass text classification\",\n        \"Scenario-based insider threat detection from cyber activities\",\n        \"Theory of positive linear dependence\",\n        \"Text classification and co-training from positive and unlabeled examples\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"A comparison of term weighting schemes for text classification and sentiment analysis with a supervised variant of tf. idf.\",\n        \"Bns feature scaling: an improved representation over tf-idf for svm text classification\",\n        \"An extensive empirical study of feature selection metrics for text classification\",\n        \"Computational complexity of neural networks\",\n        \"Bridging the gap: A pragmatic approach to generating insider threat data\",\n        \"One class splitting criteria for random forests\",\n        \"Google colaboratory\",\n        \"Automated document classification for news article in bahasa indonesia based on term frequency inverse document frequency (tf-idf) approach\",\n        \"One-class classification by combining density and class probability estimation\",\n        \"One-class text classification with multi-modal deep support vector data description\",\n        \"Expert guided natural language processing using one-class classification\",\n        \"A statistical interpretation of term specificity and its application in retrieval\",\n        \"Multi-co-training for document classification using various document representations: Tfâ€“idf, lda, and doc2vec\",\n        \"Fraud detection for job placement using hierarchical clusters-based deep neural networks\",\n        \"Research paper classification systems based on tf-idf and lda schemes\",\n        \"Local interpretable model-agnostic explanations for long short-term memory network used for classification of amazon customer reviews\",\n        \"Benchmarking evolutionary computation approaches to insider threat detection\",\n        \"Machine learning based insider threat modelling and detection\",\n        \"Machine learning based on natural language processing to detect cardiac failure in clinical narratives\",\n        \"Twitter trending topic classification\",\n        \"Sentiment analysis of e-commerce customer reviews based on natural language processing\",\n        \"Research of text classification based on improved tf-idf algorithm\",\n        \"Isolation forest\",\n        \"Using contextual features for online recruitment fraud detection\",\n        \"One-class svms for document classification\",\n        \"Delta tfidf: An improved feature space for sentiment analysis\",\n        \"Deep learning based attribute classification insider threat detection for data security\",\n        \"Towards objectively evaluating the quality of generated medical summaries\",\n        \"Collection of transcribed medical transcription sample reports and examples\",\n        \"The oec: Facts about the language\",\n        \"Scikit-learn: Machine learning in Python\",\n        \"Glove: Global vectors for word representation\",\n        \"Us jobs kaggle dataset\",\n        \"Computational analysis and understanding of natural languages: Principles, methods and applications\",\n        \"Analysis of e-recruitment systems and detecting e-recruitment fraud\",\n        \"Self-attentive, multi-context one-class classification for unsupervised anomaly detection on text\",\n        \"Image-based feature representation for insider threat classification\",\n        \"An application of one-class support vector machines in content-based image retrieval\",\n        \"A comparison of semantic similarity methods for maximum human interpretability\",\n        \"Motion and manipulation lecture series\",\n        \"Sentiment analysis of commodity reviews based on multilayer lstm network\",\n        \"1313\\\\frac{1}{3} million most frequent english words on the web\",\n        \"Knn with tf-idf based framework for text categorization\",\n        \"Deep learning for unsupervised insider threat detection in structured cybersecurity data streams\",\n        \"Automatic detection of online recruitment frauds: Characteristics, methods, and a public dataset\",\n        \"Baselines and bigrams: Simple, good sentiment and topic classification\",\n        \"Insider threat prediction based on unsupervised anomaly detection scheme for proactive forensic investigation\",\n        \"Prediction of user consumption behavior data based on the combined model of TF-IDF and logistic regression\",\n        \"A comparative study of tf* idf, lsi and multi-words for text classification\",\n        \"Parameter estimation of one-class svm on imbalance text classification\",\n        \"De-identification of health records using anonym: Effectiveness and robustness across datasets\"\n    ],\n    \"reasoning\": \"Selected these 64 references because they represent foundational work and recent advances in Conical Classification For Computationally Efficient One-Class Topic Determination, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}