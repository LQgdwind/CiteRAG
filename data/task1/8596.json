{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 47 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain\n\nPaper Abstract: Abstract We propose a novel approach to learn domain-specific plausible materials for components in the vehicle repair domain by probing Pretrained Language Models (PLMs) in a cloze task style setting to overcome the lack of annotated datasets. We devise a new method to aggregate salient predictions from a set of cloze query templates and show that domain-adaptation using either a small, high-quality or a customized Wikipedia corpus boosts performance. When exploring resource-lean alternatives, we find a distilled PLM clearly outperforming a classic pattern-based algorithm. Further, given that 98% of our domain-specific components are multiword expressions, we successfully exploit the compositionality assumption as a way to address data sparsity.\n\n{retrieved_text}\n\nGenerate exactly 47 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 47\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A cross-linguistic perspective on the Right-Hand Head Rule: The rule and the exceptions\",\n        \"ALL dolphins are intelligent and SOME are friendly: Probing BERT for nouns’ semantic properties and their prototypicality\",\n        \"Better Statistical Machine Translation through Linguistic Treatment of Phrasal Verbs\",\n        \"Splitting of compound terms in non-prototypical compounding languages\",\n        \"Unsupervised Compositionality Prediction of Nominal Compounds\",\n        \"Commonsense Knowledge Mining from Pretrained Models\",\n        \"Measuring and Improving Consistency in Pretrained Language Models\",\n        \"ADEPT: An Adjective-Dependent Plausibility Task\",\n        \"A Flexible, Corpus-Driven Model of Regular and Inverse Selectional Preferences\",\n        \"What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models\",\n        \"WordNet – An Electronic Lexical Database\",\n        \"The SOFC-Exp Corpus and Neural Approaches to Information Extraction in the Materials Science Domain\",\n        \"Assessing BERT’s Syntactic Abilities\",\n        \"MatSciBERT: A Materials Domain Language Model for Text Mining and Information Extraction\",\n        \"Compound or Term Features? Analyzing Salience in Predicting the Difficulty of German Noun Compounds across Domains\",\n        \"Predicting Degrees of Technicality in Automatic Terminology Extraction\",\n        \"spaCy: Industrial-strength Natural Language Processing in Python\",\n        \"How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering\",\n        \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\",\n        \"Exploring BERT’s Sensitivity to Lexical Cues using Tests from Semantic Priming\",\n        \"The Materials Science Procedural Text Corpus: Annotating Materials Synthesis Procedures with Shallow Semantic Structures\",\n        \"Automatically Extracting Action Graphs from Materials Science Synthesis Procedures\",\n        \"Wiki to automotive: Understanding the distribution shift and its impact on named entity recognition\",\n        \"MS-Mentions: Consistently Annotating Entity Mentions in Materials Science Procedural Text\",\n        \"Data-driven materials research enabled by natural language processing and information extraction\",\n        \"Sorting through the noise: Testing robustness of information processing in pre-trained language models\",\n        \"Language Models as Knowledge Bases?\",\n        \"Can a Gorilla Ride a Camel? Learning Semantic Plausibility from Text\",\n        \"Modeling Event Plausibility with Consistent Conceptual Abstraction\",\n        \"Topic modeling and its applications in materials science and engineering\",\n        \"On the Systematicity of Probing Contextualized Word Representations: The Case of Hypernymy in BERT\",\n        \"An Empirical Study on Compositionality in Compound Nouns\",\n        \"A Primer in BERTology: What We Know About How BERT Works\",\n        \"Multiword Expressions: A Pain in the Neck for NLP\",\n        \"Using Distributional Similarity of Multi-way Translations to Predict Multiword Expression Compositionality\",\n        \"DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter\",\n        \"Processing and querying large web corpora with the COW14 architecture\",\n        \"Rare Words: A Major Problem for Contextualized Embeddings and How to Fix it by Attentive Mimicking\",\n        \"The Role of Modifier and Head Properties in Predicting the Compositionality of English and German Noun-Noun Compounds: A Vector-Space Perspective\",\n        \"The Role of Constituents in Multi-Word Expressions: An Interdisciplinary, Cross-Lingual Perspective\",\n        \"AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts\",\n        \"Cloze Procedure: A New Tool for Measuring Readability\",\n        \"A Bootstrapping Method for Learning Semantic Lexicons using Extraction Pattern Contexts\",\n        \"Looking through glass: Knowledge discovery from materials science literature using natural language processing\",\n        \"Modeling Semantic Plausibility by Injecting World Knowledge\",\n        \"Distinguishing Degrees of Compositionality in Compound Splitting for Statistical Machine Translation\",\n        \"Transformers: State-of-the-Art Natural Language Processing\"\n    ],\n    \"reasoning\": \"Selected these 47 references because they represent foundational work and recent advances in Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}