{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 52 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Stacked LSTM Based Deep Recurrent Neural Network with Kalman Smoothing for Blood Glucose Prediction\n\nPaper Abstract: Abstract Blood glucose (BG) management is crucial for type-1 diabetes patients resulting in the necessity of reliable artificial pancreas or insulin infusion systems. In recent years, deep learning techniques have been utilized for a more accurate BG level prediction system. However, continuous glucose monitoring (CGM) readings are susceptible to sensor errors. As a result, inaccurate CGM readings would affect BG prediction and make it unreliable, even if the most optimal machine learning model is used. In this work, we propose a novel approach to predicting blood glucose level with a stacked Long short-term memory (LSTM) based deep recurrent neural network (RNN) model considering sensor fault. We use the Kalman smoothing technique for the correction of the inaccurate CGM readings due to sensor error. For the OhioT1DM dataset, containing eight weeksâ€™ data from six different patients, we achieve an average RMSE of 6.45 and 17.24 mg/dl for 30 minutes and 60 minutes of prediction horizon (PH), respectively. To the best of our knowledge, this is the leading average prediction accuracy for the ohioT1DM dataset. Different physiological information, e.g., Kalman smoothed CGM data, carbohydrates from the meal, bolus insulin, and cumulative step counts in a fixed time interval, are crafted to represent meaningful features used as input to the model. The goal of our approach is to lower the difference between the predicted CGM values and the fingerstick blood glucose readings - the ground truth. Our results indicate that the proposed approach is feasible for more reliable BG forecasting that might improve the performance of the artificial pancreas and insulin infusion system for T1D diabetes management.\n\n{retrieved_text}\n\nGenerate exactly 52 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 52\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"A recurrent neural network approach for predicting glucose concentration in type-1 diabetic patients\",\n        \"Diagnosis and classification of diabetes mellitus\",\n        \"2. classification and diagnosis of diabetes\",\n        \"Hypoglycemia early alarm systems based on recursive autoregressive partial least squares models\",\n        \"Learning long-term dependencies with gradient descent is difficult\",\n        \"Effectiveness of sensor-augmented insulin-pump therapy in type 1 diabetes\",\n        \"Prediction of blood glucose levels and nocturnal hypoglycemia using physiological models and artificial neural networks.\",\n        \"Blood glucose level prediction using physiological models and support vector regression\",\n        \"Statistical hypoglycemia prediction\",\n        \"Dilated recurrent neural network for short-time prediction of glucose concentration.\",\n        \"Artificial pancreas: past, present, future\",\n        \"Hypoglycemia in diabetes\",\n        \"An early warning system for hypoglycemic/hyperglycemic events based on fusion of adaptive prediction models\",\n        \"Why Sensor Glucose does not equal Blood Glucose\",\n        \"Predicting hypoglycemia in diabetic patients using time-sensitive artificial neural networks\",\n        \"Modeling transient disconnections and compression artifacts of continuous glucose sensors\",\n        \"An online failure detection method of the glucose sensor-insulin pump system: improved overnight safety of type-1 diabetic subjects\",\n        \"Deep multi-output forecasting: Learning to accurately predict blood glucose trajectories\",\n        \"Multivariate prediction of subcutaneous glucose concentration in type 1 diabetes patients based on support vector regression\",\n        \"Glucose prediction in type 1 and type 2 diabetic patients using data driven techniques\",\n        \"Understanding the difficulty of training deep feedforward neural networks\",\n        \"Speech recognition with deep recurrent neural networks\",\n        \"Classification and diagnosis of diabetes mellitus and other categories of glucose intolerance\",\n        \"Training and analysing deep recurrent neural networks\",\n        \"The vanishing gradient problem during learning recurrent neural nets and problem solutions\",\n        \"Long short-term memory\",\n        \"Cascading k-means clustering and k-nearest neighbor classifier for categorization of diabetic patients\",\n        \"Perioperative hyperglycemia and risk of adverse events among patients with and without diabetes\",\n        \"Timing of insulin delivery with meals\",\n        \"Physiological differences between interstitial glucose and blood glucose measured in human subjects\",\n        \"Convolutional recurrent neural networks for glucose prediction\",\n        \"Accuracy and reliability of continuous glucose monitoring systems: a head-to-head comparison\",\n        \"Application of the continuous-discrete extended kalman filter for fault detection in continuous glucose monitors for type 1 diabetes\",\n        \"The ohiot1dm dataset for blood glucose level prediction.\",\n        \"Automatic blood glucose prediction with confidence using recurrent neural networks\",\n        \"Neural network approach for non-invasive detection of hyperglycemia using electrocardiographic signals\",\n        \"Neural network-based real-time prediction of glucose in patients with insulin-dependent diabetes\",\n        \"How to construct deep recurrent neural networks\",\n        \"Artificial neural network algorithm for online glucose prediction from continuous glucose monitoring\",\n        \"Maximum likelihood estimates of linear dynamic systems\",\n        \"Deep learning in neural networks: An overview\",\n        \"Dropout: a simple way to prevent neural networks from overfitting\",\n        \"Kalman smoothing for objective and automatic preprocessing of glucose data\",\n        \"Predicting blood glucose with an lstm and bi-lstm based deep neural network\",\n        \"Neural-network models for the blood glucose metabolism of a diabetic\",\n        \"Hypoglycemia early alarm systems based on multivariable models\",\n        \"Type-1 diabetes patient decision simulator for in silico testing safety and effectiveness of insulin treatments\",\n        \"Insulin kinetics in type-1 diabetes: continuous and bolus delivery of rapid acting insulin\",\n        \"An arima model with adaptive orders for predicting blood glucose concentrations and hypoglycemia\",\n        \"In silicoclosed-loop control validation studies for optimal insulin delivery in type 1 diabetes\",\n        \"Neural network incorporating meal information improves accuracy of short-time prediction of glucose concentration\",\n        \"A deep learning algorithm for personalized blood glucose prediction.\"\n    ],\n    \"reasoning\": \"Selected these 52 references because they represent foundational work and recent advances in Stacked LSTM Based Deep Recurrent Neural Network with Kalman Smoothing for Blood Glucose Prediction, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}