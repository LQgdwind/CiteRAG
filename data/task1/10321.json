{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 46 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Adaptive Fusion of Multi-view Remote Sensing data for Optimal Sub-field Crop Yield Prediction\n\nPaper Abstract: Abstract Accurate crop yield prediction is of utmost importance for informed decision-making in agriculture, aiding farmers, industry stakeholders, and policymakers in optimizing agricultural practices. However, this task is complex and depends on multiple factors, such as environmental conditions, soil properties, and management practices. Leveraging Remote Sensing (RS) technologies, multi-view data from diverse global data sources can be collected to enhance predictive model accuracy. However, combining heterogeneous RS views poses a fusion challenge, like identifying the specific contribution of each view in the predictive task. In this paper, we present a novel multi-view learning approach to predict crop yield for different crops (soybean, wheat, rapeseed) and regions (Argentina, Uruguay, and Germany). Our multi-view input data includes multi-spectral optical images from Sentinel-2 satellites and weather data as dynamic features during the crop growing season, complemented by static features like soil properties and topographic information. To effectively fuse the multi-view data, we introduce a Multi-view Gated Fusion (MVGF) model, comprising dedicated view-encoders and a Gated Unit (GU) module. The view-encoders handle the heterogeneity of data sources with varying temporal resolutions by learning a view-specific representation. These representations are adaptively fused via a weighted sum. The fusion weights are computed for each sample by the GU using a concatenation of all the view-representations. The MVGF model is trained at sub-field level with 10 m resolution pixels. Our evaluations show that the MVGF outperforms conventional models on the same task, achieving the best results by incorporating all the data sources, unlike the usual fusion results in the literature. For Argentina, the MVGF model achieves an R2superscriptùëÖ2R^{2} value of 0.68 at sub-field yield prediction, while at the field level evaluation (comparing field averages), it reaches around 0.80 across different countries. The GU module learned different weights based on the country and crop-type, aligning with the variable significance of each data source to the prediction task. This novel method has proven its effectiveness in enhancing the accuracy of the challenging sub-field crop yield prediction. Our investigation indicates that the gated fusion approach promises a significant advancement in the field of agriculture and precision farming.\n\n{retrieved_text}\n\nGenerate exactly 46 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 46\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Gated multimodal networks\",\n        \"Beyond rgb: Very high resolution urban remote sensing with multimodal deep networks\",\n        \"M3fusion: A deep learning architecture for multiscale multimodal multitemporal satellite data fusion\",\n        \"The effect of tuning, feature engineering, and feature selection in data mining applied to rainfed sugarcane yield modelling\",\n        \"Integrating satellite and climate data to predict wheat yield in australia using machine learning approaches\",\n        \"Deep learning for the Earth Sciences: A comprehensive approach to remote sensing, climate science and geosciences\",\n        \"Integrating multi-source data for rice yield prediction across china using machine learning and deep learning approaches\",\n        \"Deep fusion of remote sensing data for accurate classification\",\n        \"An end-to-end model for rice yield prediction using deep learning fusion\",\n        \"An image is worth 16x16 words: Transformers for image recognition at scale\",\n        \"Shuttle radar topography mission produces a wealth of data\",\n        \"Fusing sentinel-1 and sentinel-2 images for deforestation detection in the brazilian amazon under diverse cloud conditions\",\n        \"Lightweight temporal self-attention for classifying satellite images time series\",\n        \"Deepyield: A combined convolutional neural network with long short-term memory for crop yield forecasting\",\n        \"Crop yield prediction: An operational approach to crop yield modeling on field and subfield level with machine learning models\",\n        \"The ERA5 global reanalysis\",\n        \"Cmgfnet: A deep cross-modal gated fusion network for building extraction from very high-resolution remote sensing images\",\n        \"Adaptive mixtures of local experts\",\n        \"Attention is not Explanation\",\n        \"Comparative assessment of environmental variables and machine learning algorithms for maize yield prediction in the us midwest\",\n        \"Adam: A method for stochastic optimization\",\n        \"Deepcropnet: a deep spatial-temporal learning framework for county-level corn yield estimation\",\n        \"Soybean yield prediction from uav using multimodal data fusion and deep learning\",\n        \"Explaining a deep spatiotemporal land cover classifier with attention and redescription mining\",\n        \"Common practices and taxonomy in deep multi-view fusion for remote sensing applications\",\n        \"A comparative assessment of multi-view fusion learning for crop classification\",\n        \"Exploring self-attention for crop-type classification explainability\",\n        \"Crop type mapping from optical and radar time series using attention-based deep learning\",\n        \"Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and Subfield Level\",\n        \"SoilGrids 2.0: producing soil information for the globe with quantified spatial uncertainty\",\n        \"On a theoretical property of the bhattacharyya coefficient as a feature evaluation criterion\",\n        \"Self-attention for raw optical satellite time series classification\",\n        \"Corn yield prediction with ensemble cnn-dnn\",\n        \"Missing information reconstruction of remote sensing data: A technical review\",\n        \"Winter wheat yield prediction using convolutional neural networks from environmental and phenological data\",\n        \"Attention is all you need\",\n        \"Multi-attentive hierarchical dense fusion net for fusion classification of hyperspectral and lidar data\",\n        \"Winter wheat yield prediction at county level and uncertainty analysis in main wheat-producing regions of china with deep learning approaches\",\n        \"Attention is not not explanation\",\n        \"Convolutional neural networks for multimodal remote sensing data classification\",\n        \"Deep multi-view learning methods: A review\",\n        \"Deep convolutional neural networks for rice grain yield estimation at the ripening stage using uav-based remotely sensed images\",\n        \"Information fusion for classification of hyperspectral and lidar data using ip-cnn\",\n        \"A hybrid attention-aware fusion network (hafnet) for building extraction from high-resolution imagery and lidar data\",\n        \"Cnn, rnn, or vit? an evaluation of different deep learning architectures for spatio-temporal representation of sentinel time series\",\n        \"A gather-to-guide network for remote sensing semantic segmentation of rgb and auxiliary image\"\n    ],\n    \"reasoning\": \"Selected these 46 references because they represent foundational work and recent advances in Adaptive Fusion of Multi-view Remote Sensing data for Optimal Sub-field Crop Yield Prediction, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}