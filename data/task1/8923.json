{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 50 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues\n\nPaper Abstract: Abstract User Satisfaction Modeling (USM) is one of the popular choices for task-oriented dialogue systems evaluation, where user satisfaction typically depends on whether the user’s task goals were fulfilled by the system. Task-oriented dialogue systems use task schema, which is a set of task attributes, to encode the user’s task goals. Existing studies on USM neglect explicitly modeling the user’s task goals fulfillment using the task schema. In this paper, we propose SG-USM, a novel schema-guided user satisfaction modeling framework. It explicitly models the degree to which the user’s preferences regarding the task attributes are fulfilled by the system for predicting the user’s satisfaction level. SG-USM employs a pre-trained language model for encoding dialogue context and task attributes. Further, it employs a fulfillment representation layer for learning how many task attributes have been fulfilled in the dialogue, an importance predictor component for calculating the importance of task attributes. Finally, it predicts the user satisfaction based on task attribute fulfillment and task attribute importance. Experimental results on benchmark datasets (i.e. MWOZ, SGD, ReDial, and JDDC) show that SG-USM consistently outperforms competitive existing methods. Our extensive analysis demonstrates that SG-USM can improve the interpretability of user satisfaction modeling, has good scalability as it can effectively deal with unseen tasks and can also effectively work in low-resource settings by leveraging unlabeled data.111Code is available at https://github.com/amzn/user-satisfaction-modeling.\n\n{retrieved_text}\n\nGenerate exactly 50 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 50\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Joint turn and dialogue level user satisfaction estimation on multi-domain conversations\",\n        \"Predicting user intents and satisfaction with dialogue-based conversational recommendations\",\n        \"The use of mmr, diversity-based reranking for reordering documents and producing summaries\",\n        \"Schema-guided multi-domain dialogue state tracking with graph attention neural networks\",\n        \"The jddc corpus: A large-scale multi-turn chinese dialogue dataset for e-commerce customer service\",\n        \"Offline and online satisfaction prediction in open-domain conversational systems\",\n        \"User satisfaction estimation with sequential dialogue act modeling in goal-oriented conversational systems\",\n        \"Survey on evaluation methods for dialogue systems\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Gate-variants of gated recurrent unit (gru) neural networks\",\n        \"Modeling user satisfaction with hidden markov models\",\n        \"Multiwoz 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines\",\n        \"Topic-aware response generation in task-oriented dialogue with unstructured knowledge access\",\n        \"Dynamic schema graph fusion network for multi-domain dialogue state tracking\",\n        \"A sequence-to-sequence approach to dialogue state tracking\",\n        \"Slot-gated modeling for joint slot filling and intent prediction\",\n        \"A deep prediction network for understanding advertiser intent and satisfaction\",\n        \"Measuring user satisfaction on smart speaker intelligent assistants using intent sensitive query embeddings\",\n        \"The elements of statistical learning: data mining, inference, and prediction, volume 2\",\n        \"Trippy: A triple copy strategy for value independent neural dialog state tracking\",\n        \"A simple language model for task-oriented dialogue\",\n        \"Higru: Hierarchical gated recurrent units for utterance-level emotion recognition\",\n        \"Self-supervised contrastive learning for efficient user satisfaction prediction in conversational agents\",\n        \"A multi-task based neural model to simulate users in goal-oriented dialogue systems\",\n        \"Adam: A method for stochastic optimization\",\n        \"Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures\",\n        \"Towards deep conversational recommendations\",\n        \"Rouge: A package for automatic evaluation of summaries\",\n        \"Attention-based recurrent neural network models for joint intent detection and slot filling\",\n        \"How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation\",\n        \"Mem2seq: Effectively incorporating knowledge bases into end-to-end task-oriented dialog systems\",\n        \"Jointly leveraging intent and interaction signals to predict user satisfaction with slate recommendations\",\n        \"User interaction sequences for search satisfaction prediction\",\n        \"Neural belief tracker: Data-driven dialogue state tracking\",\n        \"Bleu: a method for automatic evaluation of machine translation\",\n        \"Dynamic fusion network for multi-domain end-to-end task-oriented dialog\",\n        \"Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset\",\n        \"Automatic user experience evaluation of goal-oriented dialogs using pre-trained language models\",\n        \"Using customer service dialogues for satisfaction analysis with context-assisted multiple instance learning\",\n        \"User intent, behaviour, and perceived satisfaction in product search\",\n        \"Multi-task pre-training for plug-and-play task-oriented dialogue system\",\n        \"Simulating user satisfaction for the evaluation of task-oriented dialogue systems\",\n        \"Attention is all you need\",\n        \"Transferable multi-domain state generator for task-oriented dialogue systems\",\n        \"The influence of image search intents on user behavior and satisfaction\",\n        \"Graphdialog: Integrating graph knowledge into end-to-end task-oriented dialogue systems\",\n        \"Hierarchical attention networks for document classification\",\n        \"Recurrent conditional random field for language understanding\",\n        \"Assist: Towards label noise-robust dialogue state tracking\",\n        \"Overview of the ntcir-15 dialogue evaluation (dialeval-1) task\"\n    ],\n    \"reasoning\": \"Selected these 50 references because they represent foundational work and recent advances in Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}