{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 50 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Updatable Siamese Tracker with Two-stage One-shot Learning\n\nPaper Abstract: Abstract Offline Siamese networks have achieved very promising tracking performance, especially in accuracy and efficiency. However, they often fail to track an object in complex scenes due to the incapacity in online update. Traditional updaters are difficult to process the irregular variations and sampling noises of objects, so it is quite risky to adopt them to update Siamese networks. In this paper, we first present a two-stage one-shot learner, which can predict the local parameters of primary classifier with object samples from diverse stages. Then, an updatable Siamese network is proposed based on the learner (SiamTOL), which is able to complement online update by itself. Concretely, we introduce an extra inputting branch to sequentially capture the latest object features, and design a residual module to update the initial exemplar using these features. Besides, an effective multi-aspect training loss is designed for our network to avoid overfit. Extensive experimental results on several popular benchmarks including OTB100, VOT2018, VOT2019, LaSOT, UAV123 and GOT10k manifest that the proposed tracker achieves the leading performance and outperforms other state-of-the-art methods.\n\n{retrieved_text}\n\nGenerate exactly 50 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 50\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Learning feed-forward one-shot learners\",\n        \"Fully convolutional siamese networks for object tracking\",\n        \"Learning discriminative model prediction for tracking\",\n        \"Siamese box adaptive network for visual tracking\",\n        \"High-performance long-term tracking with meta-updater\",\n        \"Clnet: A compact latent network for fast adjusting siamese trackers\",\n        \"Hyperparameter optimization for tracking with continuous deep q-learning\",\n        \"Correlation-guided attention for corner detection based visual tracking\",\n        \"Lasot: A high-quality benchmark for large-scale single object tracking\",\n        \"Siamese cascaded region proposal networks for real-time visual tracking\",\n        \"Model agnostic meta-learning for fast adaptation of deep networks\",\n        \"Deep relative tracking\",\n        \"Supervised sequence labelling with recurrent neural networks\",\n        \"Learning dynamic siamese network for visual object tracking\",\n        \"A novel vision-based tracking algorithm for a human-following mobile robot\",\n        \"Deep residual learning for image recognition\",\n        \"Got-10k: A large high-diversity benchmark for generic object tracking in the wild\",\n        \"Real-time object tracking via meta-learning: Efficient model adaptation and one-shot channel pruning\",\n        \"The seventh visual object tracking vot2019 challenge results\",\n        \"Siamrpn++: Evolution of siamese visual tracking with very deep networks\",\n        \"High performance visual tracking with siamese region proposal network\",\n        \"Gradnet: Gradient-guided network for visual object tracking\",\n        \"Hand posture recognition using finger geometric feature\",\n        \"The sixth visual object tracking vot2018 challenge results\",\n        \"A benchmark and simulator for uav tracking\",\n        \"Meta networks\",\n        \"Learning multi-domain convolutional neural networks for visual tracking\",\n        \"Meta-tracker: Fast and robust online adaptation for visual object trackers\",\n        \"Optimization as a model for few-shot learning\",\n        \"Youtube-boundingboxes: A large high-precision human-annotated data set for object detection in video\",\n        \"Faster r-cnn: towards real-time object detection with region proposal networks\",\n        \"Imagenet large scale visual recognition challenge\",\n        \"One-shot learning with memory-augmented neural networks\",\n        \"Prototypical networks for few-shot learning\",\n        \"Vital: Visual tracking via adversarial learning\",\n        \"Learning to compare: Relation network for few-shot learning\",\n        \"Siamese instance search for tracking\",\n        \"Microsoft coco: Common objects in context\",\n        \"End-to-end representation learning for correlation filter based tracking\",\n        \"Spm-tracker: Series-parallel matching for real-time visual object tracking\",\n        \"Visual tracking with fully convolutional networks\",\n        \"Fast online object tracking and segmentation: A unifying approach\",\n        \"Sint++: Robust visual tracking via adversarial positive instance generation\",\n        \"Object tracking benchmark\",\n        \"Multiple human tracking based on multi-view upper-body detection and discriminative learning\",\n        \"Good features to track for visual slam\",\n        \"Learning the model update for siamese trackers\",\n        \"Deeper and wider siamese networks for real-time visual tracking\",\n        \"Ocean: Object-aware anchor-free tracking\",\n        \"Distractor-aware siamese networks for visual object tracking\"\n    ],\n    \"reasoning\": \"Selected these 50 references because they represent foundational work and recent advances in Updatable Siamese Tracker with Two-stage One-shot Learning, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}