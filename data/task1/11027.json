{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 51 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: From Canteen Food to Daily Meals: Generalizing Food Recognition to More Practical Scenarios\n\nPaper Abstract: Abstract The precise recognition of food categories plays a pivotal role for intelligent health management, attracting significant research attention in recent years. Prominent benchmarks, such as Food-101 and VIREO Food-172, provide abundant food image resources that catalyze the prosperity of research in this field. Nevertheless, these datasets are well-curated from canteen scenarios and thus deviate from food appearances in daily life. This discrepancy poses great challenges in effectively transferring classifiers trained on these canteen datasets to broader daily-life scenarios encountered by humans. Toward this end, we present two new benchmarks, namely DailyFood-172 and DailyFood-16, specifically designed to curate food images from everyday meals. These two datasets are used to evaluate the transferability of approaches from the well-curated food image domain to the everyday-life food image domain. In addition, we also propose a simple yet effective baseline method named Multi-Cluster Reference Learning (MCRL) to tackle the aforementioned domain gap. MCRL is motivated by the observation that food images in daily-life scenarios exhibit greater intra-class appearance variance compared with those in well-curated benchmarks. Notably, MCRL can be seamlessly coupled with existing approaches, yielding non-trivial performance enhancements. We hope our new benchmarks can inspire the community to explore the transferability of food recognition models trained on well-curated datasets toward practical real-life applications.\n\n{retrieved_text}\n\nGenerate exactly 51 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 51\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Large scale visual food recognition\",\n        \"Nutrition5k: Towards automatic nutritional understanding of generic food\",\n        \"Image segmentation and recognition for multi-class chinese food\",\n        \"Deep-based ingredient recognition for cooking recipe retrieval\",\n        \"Food-101â€“mining discriminative components with random forests\",\n        \"A study of multi-task and region-wise deep learning for food ingredient recognition\",\n        \"Deep domain confusion: Maximizing for domain invariance\",\n        \"Learning transferable features with deep adaptation networks\",\n        \"Deep coral: Correlation alignment for deep domain adaptation\",\n        \"Domain separation networks\",\n        \"Similarity-based domain adaptation network\",\n        \"Category contrast for unsupervised domain adaptation in visual tasks\",\n        \"Deep subdomain adaptation network for image classification\",\n        \"Transfer learning with dynamic adversarial adaptation network\",\n        \"Contrastive adaptation network for unsupervised domain adaptation\",\n        \"Improving pseudo labels with intra-class similarity for unsupervised domain adaptation\",\n        \"Dual adversarial domain adaptation\",\n        \"Visual domain adaptation with manifold embedded distribution alignment\",\n        \"Transfer feature learning with joint distribution adaptation\",\n        \"Foodx-251: a dataset for fine-grained food classification\",\n        \"Learning cross-modal embeddings for cooking recipes and food images\",\n        \"Automatic chinese food identification and quantity estimation\",\n        \"Recognition and volume estimation of food intake using a mobile device\",\n        \"Multiple-food recognition considering co-occurrence employing manifold ranking\",\n        \"Food image classification with deep features\",\n        \"Fine-grained food classification methods on the uec food-100 database\",\n        \"Cross-domain cross-modal food transfer\",\n        \"Domain-adversarial training of neural networks\",\n        \"Return of frustratingly easy domain adaptation\",\n        \"Domain adaptive neural networks for object recognition\",\n        \"Deep transfer learning with joint adaptation networks\",\n        \"Generative adversarial networks\",\n        \"Unsupervised domain adaptation by backpropagation\",\n        \"Dlow: Domain flow for adaptation and generalization\",\n        \"Cycada: Cycle-consistent adversarial domain adaptation\",\n        \"Deep transfer network: Unsupervised domain adaptation\",\n        \"Multi-adversarial domain adaptation\",\n        \"Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks\",\n        \"Spherical space domain adaptation with robust pseudo-label loss\",\n        \"Fisher deep domain adaptation\",\n        \"Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation\",\n        \"A kernel two-sample test\",\n        \"Rethinking softmax with cross-entropy: Neural network classifier as mutual information estimator\",\n        \"Deep hashing network for unsupervised domain adaptation\",\n        \"Visda: The visual domain adaptation challenge\",\n        \"Contrastive vicinal space for unsupervised domain adaptation\",\n        \"Cdtrans: Cross-domain transformer for unsupervised domain adaptation\",\n        \"Imagenet large scale visual recognition challenge\",\n        \"Adam: A method for stochastic optimization\",\n        \"An image is worth 16x16 words: Transformers for image recognition at scale\",\n        \"Training data-efficient image transformers & distillation through attention\"\n    ],\n    \"reasoning\": \"Selected these 51 references because they represent foundational work and recent advances in From Canteen Food to Daily Meals: Generalizing Food Recognition to More Practical Scenarios, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}