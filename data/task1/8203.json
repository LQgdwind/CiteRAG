{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 51 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Practical Statistical Considerations for the Clinical Validation of AI/ML-enabled Medical Diagnostic Devices\n\nPaper Abstract: Abstract Artificial Intelligence (AI) and Machine-Learning (ML) models have been increasingly used in medical products, such as medical device software. General considerations on the statistical aspects for the evaluation of AI/ML-enabled medical diagnostic devices are discussed in this paper. We also provide relevant academic references and note good practices in addressing various statistical challenges in the clinical validation of AI/ML-enabled medical devices in the context of their intended use.\n\n{retrieved_text}\n\nGenerate exactly 51 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 51\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"What do we mean by validating a prognostic model\",\n        \"Prognosis and prognostic research: validating a prognostic model\",\n        \"Using relative utility curves to evaluate risk prediction\",\n        \"Measuring agreement in method comparison studies\",\n        \"Calibration of prognostic risk scores\",\n        \"Statistical Guidance on Reporting Results from Studies Evaluating Diagnostic Tests\",\n        \"Design Considerations for Pivotal Clinical Investigations for Medical Devices\",\n        \"Software as a Medical Device (SAMD): Clinical Evaluation\",\n        \"Calibration of medical diagnostic classifier scores to the probability of disease\",\n        \"Harmonized Terminology Database\",\n        \"Stard 2015 guidelines for reporting diagnostic accuracy studies: explanation and elaboration\",\n        \"Two further applications of a model for binary regression\",\n        \"Evaluation of heart failure biomarker tests: a survey of statistical considerations\",\n        \"Statistical Adjustment of Data\",\n        \"The reusable holdout: Preserving validity in adaptive data analysis\",\n        \"Improvements on cross-validation: the 632+ bootstrap method\",\n        \"Good Machine Learning Practice for Medical Device Development:Guiding Principles\",\n        \"Adversarial attacks on medical machine learning\",\n        \"Decision curve analysis\",\n        \"Is there a role for statistics in artificial intelligence?\",\n        \"Test data reuse for the evaluation of continuously evolving classification algorithms using the area under the receiver operating characteristic curve\",\n        \"This is how ai bias really happens–and why it’s so hard to fix\",\n        \"Statistically Efficient Ways to Quantify Added Predictive Value of New Measurements\",\n        \"Regression modelling strategies for improved prognostic prediction\",\n        \"Multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors\",\n        \"The elements of statistical learning\",\n        \"Prevalence scaling: Applications to an intelligent workstation for the diagnosis of breast cancer\",\n        \"A parametric roc model-based approach for evaluating the predictiveness of continuous markers in case–control studies\",\n        \"Evaluating the predictiveness of a continuous marker\",\n        \"An introduction to statistical learning\",\n        \"Assessing the generalizability of prognostic information\",\n        \"Clinical applications of continual learning machine learning\",\n        \"Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the consort-ai extension\",\n        \"Statistical inference for net benefit measures in biomarker validation studies\",\n        \"Validation of probabilistic predictions\",\n        \"Transparent reporting of a multivariable prediction model for individual prognosis or diagnosis (tripod): Explanation and elaboration\",\n        \"Interpretation and application of the likelihood ratio to clinical practice in thoracic oncology\",\n        \"Integrating the predictiveness of a marker with its performance as a classifier\",\n        \"Pivotal evaluation of the accuracy of a biomarker used for classification or prediction: standards for study design\",\n        \"Early-phase studies of biomarkers: what target sensitivity and specificity values might confer clinical utility?\",\n        \"Guidelines for clinical trial protocols for interventions involving artificial intelligence: the spirit-ai extension\",\n        \"Exploratory subgroup analyses in clinical research\",\n        \"External validation of a cox prognostic model: principles and methods\",\n        \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead\",\n        \"Pitfalls in the use of dna microarray data for diagnostic and prognostic classification\",\n        \"Medical Decision Making\",\n        \"Towards better clinical prediction models: seven steps for development and an abcd for validation\",\n        \"A calibration hierarchy for risk models was defined: from utopia to empirical data\",\n        \"Decision curve analysis: a novel method for evaluating prediction models\",\n        \"A simple, step-by-step guide to interpreting decision curve analysis\",\n        \"Understanding deep learning (still) requires rethinking generalization\"\n    ],\n    \"reasoning\": \"Selected these 51 references because they represent foundational work and recent advances in Practical Statistical Considerations for the Clinical Validation of AI/ML-enabled Medical Diagnostic Devices, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}