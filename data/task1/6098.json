{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 56 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Justifying Social-Choice Mechanism Outcome for Improving Participant Satisfaction\n\nPaper Abstract: Abstract In many social-choice mechanisms the resulting choice is not the most preferred one for some of the participants, thus the need for methods to justify the choice made in a way that improves the acceptance and satisfaction of said participants. One natural method for providing such explanations is to ask people to provide them, e.g., through crowdsourcing, and choosing the most convincing arguments among those received. In this paper we propose the use of an alternative approach, one that automatically generates explanations based on desirable mechanism features found in theoretical mechanism design literature. We test the effectiveness of both of the methods through a series of extensive experiments conducted with over 600 participants in ranked voting, a classic social choice mechanism. The analysis of the results reveals that explanations indeed affect both average satisfaction from and acceptance of the outcome in such settings. In particular, explanations are shown to have a positive effect on satisfaction and acceptance when the outcome (the winning candidate in our case) is the least desirable choice for the participant. A comparative analysis reveals that the automatically generated explanations result in similar levels of satisfaction from and acceptance of an outcome as with the more costly alternative of crowdsourced explanations, hence eliminating the need to keep humans in the loop. Furthermore, the automatically generated explanations significantly reduce participants’ belief that a different winner should have been elected compared to crowdsourced explanations.\n\n{retrieved_text}\n\nGenerate exactly 56 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 56\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Driving into the ocean and 8 other spectacular fails as gps turns 25\",\n        \"Why didn’t you allocate this task to them?’negotiation-aware task allocation and contrastive explanation generation\",\n        \"The devil is in the tails: actuarial mathematics and the subprime mortgage crisis\",\n        \"Why does my model fail? contrastive local explanations for retail forecasting\",\n        \"Can you explain that? lucid explanations help human-ai collaborative image retrieval\",\n        \"Providing explanations for recommendations in reciprocal environments\",\n        \"Personalized explanations for hybrid recommender systems\",\n        \"Ai for explaining decisions in multi-agent environments\",\n        \"Principles of explanatory debugging to personalize interactive machine learning\",\n        \"No explainability without accountability: An empirical study of explanations and feedback in interactive ml\",\n        \"Explaining ridesharing: selection of explanations for increasing user satisfaction\",\n        \"Social choice and individual values\",\n        \"On maxsum fair cake divisions\",\n        \"Cake cutting mechanisms\",\n        \"Fair rent division on a budget\",\n        \"Budget balance, fairness, and minimal manipulability\",\n        \"Axioms should explain solutions\",\n        \"On the evaluation of election outcomes under uncertainty\",\n        \"The original borda count and partial voting\",\n        \"Condorcet’s theory of voting\",\n        \"“how can we compare different voting methods?” a voting theory project\",\n        \"Voting procedures designed to elect a single candidate\",\n        \"Clustering and psychological barriers: The importance of numbers\",\n        \"Fairness and retaliation: The economics of reciprocity\",\n        \"Trust-inspiring explanation interfaces for recommender systems\",\n        \"The Aligned Rank Transform for Nonparametric Factorial Analyses Using Only Anova Procedures\",\n        \"Voting systems and strategic manipulation: An experimental study\",\n        \"An experimental study of voting rules and polls in three-candidate elections\",\n        \"A study of human behavior in online voting\",\n        \"European union regulations on algorithmic decision-making and a “right to explanation”\",\n        \"“meaningful information” and the right to explanation\",\n        \"The Black Box Society: The Secret Algorithms That Control Money and Information\",\n        \"Accountability of ai under the law: The role of explanation\",\n        \"Explainability in human–agent systems\",\n        \"Explainability fact sheets: a framework for systematic assessment of explainable approaches\",\n        \"A systematic method to understand requirements for explainable ai (xai) systems\",\n        \"A two-dimensional explanation framework to classify ai as incomprehensible, interpretable, or understandable\",\n        \"Best practices for transparency in machine generated personalization\",\n        \"Explanation in artificial intelligence: Insights from the social sciences\",\n        \"Agent-based explanations in ai: Towards an abstract framework\",\n        \"Using arguments for making and explaining decisions\",\n        \"Preferred explanations: theory and generation via planning\",\n        \"Explainable and ethical ai: A perspective on argumentation and logic programming\",\n        \"Arguing about voting rules\",\n        \"Automated justification of collective decisions via constraint solving\",\n        \"Accountable approval sorting\",\n        \"On the complexity of finding justifications for collective decisions\",\n        \"Explainable voting\",\n        \"Which is the fairest (rent division) of them all?\",\n        \"Explaining machine learning classifiers through diverse counterfactual explanations\",\n        \"Explanation through argumentation\",\n        \"“ why should i trust you?” explaining the predictions of any classifier\",\n        \"A unified approach to interpreting model predictions\",\n        \"On human predictions with explanations and predictions of machine learning models: A case study on deception detection\",\n        \"Ranked choice voting and attitudes toward democracy in the united states: Results from a survey experiment\",\n        \"Self-reported understanding of ranked-choice voting\"\n    ],\n    \"reasoning\": \"Selected these 56 references because they represent foundational work and recent advances in Justifying Social-Choice Mechanism Outcome for Improving Participant Satisfaction, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}