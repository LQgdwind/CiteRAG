{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 58 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: What’s the Problem, Linda? The Conjunction Fallacy as a Fairness Problem\n\nPaper Abstract: Abstract. Artificial Intelligence (AI) researchers increasingly focus on creating automated decision-making (ADM) systems that operate close to human-like intelligence. Such efforts have pushed AI researchers into cognitive fields like psychology. As a result, the works of Daniel Kahneman and the late Amos Tversky on biased human decision-making, including the study of the conjunction fallacy, have experienced a second revival. Under the conjunction fallacy a human decision-maker goes against basic probability laws and ranks as more likely a conjunction over one of its parts. It has been proven overtime through a set of experiments with the Linda Problem being the most famous one. Although this interdisciplinary effort is welcomed, we fear that AI researchers ignore the driving force behind the conjunction fallacy as captured by the Linda Problem: the fact that Linda must be stereotypically described as a woman. In this paper, we revisit the Linda Problem and formulate it as a fairness problem. We introduce perception as a parameter of interest through the structural causal perception framework. Using an illustrative decision-making example, we showcase the proposed conceptual framework and its potential impact for developing fair ADM systems.\n\n{retrieved_text}\n\nGenerate exactly 58 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 58\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Counterfactual Situation Testing: Uncovering Discrimination under Fairness given the Difference\",\n        \"Machine Bias\",\n        \"The Economists’ Hour: False Prophets, Free Markets, and the Fracture of Society\",\n        \"NeurIPS 2019 Posner Lecture: From System 1 Deep Learning to System 2 Deep Learning\",\n        \"Arguments Using Ontological and Causal Knowledge\",\n        \"How stereotypes are shared through language: A review and introduction of the Social Categories and Stereotypes Communication (SCSC) Framework\",\n        \"Causal Discovery for Fairness\",\n        \"Thinking Fast and Slow in AI\",\n        \"Sorting Things Out: Classification and Its Consequences\",\n        \"The ’23 ways to nudge’ framework: designing technologies that influence behavior subtly\",\n        \"How probability theory explains the conjunction fallacy\",\n        \"The atlas of AI: Power, politics, and the planetary costs of artificial intelligence\",\n        \"Confirmation Theory\",\n        \"On Bayesian Measures of Evidential Support: Theoretical and Empirical Issues*\",\n        \"Amazon scraps secret AI recruiting tool that showed bias against women\",\n        \"Data Feminism\",\n        \"The dependence of the conjunction fallacy on subtle linguistic factors\",\n        \"The Plurality of Bayesian Measures of Confirmation and the Problem of Measure Sensitivity\",\n        \"La superioridad de los economistas\",\n        \"On Narrow Norms and Vague Heuristics: A Reply to Kahneman and Tversky (1996)\",\n        \"Toward principles for the design of ontologies used for knowledge sharing?\",\n        \"Citations in economics: Measurement, uses, and impacts\",\n        \"Towards a critical race methodology in algorithmic fairness\",\n        \"Dutch scandal serves as a warning for Europe over risks of using algorithms\",\n        \"The conjunction fallacy and the many meanings of and\",\n        \"Knowledge Graphs\",\n        \"What’s sex got to do with machine learning?\",\n        \"The structure of bias\",\n        \"Thinking, Fast and Slow\",\n        \"NeurIPS 2021: A Conversation on Human and Machine Intelligence\",\n        \"Noise: How to Overcome the High, Hidden Cost of Inconsistent Decision Making\",\n        \"Noise: A Flaw in Human Judgment\",\n        \"The Use and Misuse of Counterfactuals in Ethical Machine Learning\",\n        \"Discrimination in the Age of Algorithms\",\n        \"Why Does Racial Inequality Persist? Culture, Causation, and Responsibility\",\n        \"Subverting machines, fluctuating identities: Re-learning human categorization\",\n        \"Survey on Causal-based Machine Learning Fairness Notions\",\n        \"A field guide to social construction\",\n        \"Want Less-Biased Decisions? Use Algorithms\",\n        \"Invited Talk: Fairness and Privacy\",\n        \"Physics envy: Get over it\",\n        \"Causality: Models, Reasoning, and Inference (2nd ed.)\",\n        \"The Book of Why: The New Science of Cause and Effect\",\n        \"Elements of Causal Inference: Foundations and Learning Algorithms\",\n        \"Who talks to whom? Intra-and interdisciplinary communication of economics journals\",\n        \"Can We Trust Fair-AI?\",\n        \"Causal Relational Learning\",\n        \"Causality for Machine Learning\",\n        \"Towards Causal Representation Learning\",\n        \"Ethics and Economics: How and How NOT to Do Economics with Robert Skidelsky\",\n        \"Too much Maths, too little History: The problem of Economics\",\n        \"Signaling Games\",\n        \"What Can the Conjunction Fallacy Tell Us about Human Reasoning?\",\n        \"Nudge: Improving Decisions about Health, Wealth, and Happiness\",\n        \"Judgment Under Uncertainty: Heuristics and Biases\",\n        \"Judgments of and by Representativeness\",\n        \"Extensional versus intuitive reasoning: The conjunction fallacy in probability judgment\",\n        \"The Inner Loop of Collective Human–Machine Intelligence\"\n    ],\n    \"reasoning\": \"Selected these 58 references because they represent foundational work and recent advances in What’s the Problem, Linda? The Conjunction Fallacy as a Fairness Problem, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}