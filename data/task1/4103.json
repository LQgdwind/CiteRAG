{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 65 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Thirty years of Epistemic Specifications\n\nPaper Abstract: Abstract The language of epistemic specifications and epistemic logic programs extends disjunctive logic programs under the stable model semantics with modal constructs called subjective literals. Using subjective literals, it is possible to check whether a regular literal is true in every or some stable models of the program, those models, in this context also called belief sets, being collected in a set called world view. This allows for representing, within the language, whether some proposition should be understood accordingly to the open or the closed world assumption. Several attempts for capturing the intuitions underlying the language by means of a formal semantics were given, resulting in a multitude of proposals that makes it difficult to understand the current state of the art. In this paper, we provide an overview of the inception of the field and the knowledge representation and reasoning tasks it is suitable for. We also provide a detailed analysis of properties of proposed semantics, and an outlook of challenges to be tackled by future research in the area.\n\n{retrieved_text}\n\nGenerate exactly 65 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 65\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Revisiting explicit negation in answer set programming\",\n        \"Time-efficient and cost-effective network hardening using attack graphs\",\n        \"Epistemic logic programs with sorts\",\n        \"selp: A single-shot epistemic logic program solver\",\n        \"On an intuitionistic modal logic\",\n        \"Founded world views with autoepistemic equilibrium logic\",\n        \"Splitting epistemic logic programs\",\n        \"Autoepistemic answer set programming\",\n        \"eclingo: A solver for epistemic logic programs\",\n        \"On the computational cost of disjunctive logic programming: Propositional case\",\n        \"On uniform equivalence of epistemic logic programs\",\n        \"Strong equivalence for epistemic logic programs made easy\",\n        \"Founded (auto)epistemic equilibrium logic satisfies epistemic splitting\",\n        \"Epistemic equilibrium logic\",\n        \"Some results in intuitionistic modal logic\",\n        \"On modal logic with an intuitionistic base\",\n        \"First-order modal logic. Vol. 277\",\n        \"Strong introspection\",\n        \"Logic programming and reasoning with incomplete information\",\n        \"New semantics for epistemic specifications\",\n        \"The stable model semantics for logic programming\",\n        \"Classical negation in logic programs and disjunctive databases\",\n        \"Reasoning on open domains\",\n        \"Nonmonotonic logic and temporal projection\",\n        \"Structural decompositions of epistemic logic programs\",\n        \"Autoepistemic equilibrium logic and epistemic specifications\",\n        \"A parallel memory-efficient epistemic logic program solver: Harder, better, faster\",\n        \"The language of epistemic specifications (refined) including a prototype solver\",\n        \"Wviews\",\n        \"On the relation between default and autoepistemic logic\",\n        \"EP-ASP\",\n        \"Elpsolve (version 1.0)\",\n        \"Epistemic logic programs with world view constraints\",\n        \"A survey of advances in epistemic logic program solvers\",\n        \"Disjunctive stable models: Unfounded sets, fixpoint semantics, and computation\",\n        \"Answer set programming and plan generation\",\n        \"Splitting a logic program\",\n        \"Relating autoepistemic and default logics\",\n        \"Nonmonotonic logic: context-dependent reasoning\",\n        \"Stable models and an alternative logic programming paradigm\",\n        \"Nonmonotonic logic - context-dependent reasoning\",\n        \"Semantical considerations on nonmonotonic logic\",\n        \"Constructible falsity\",\n        \"Constructive tightly grounded autoepistemic reasoning\",\n        \"Logic programs with stable model semantics as a constraint programming paradigm\",\n        \"Quantified equilibrium logic and the first order logic of here-and-there\",\n        \"On closed world data bases\",\n        \"What should a database know?\",\n        \"Attack trees\",\n        \"Autoepistemic logic of knowledge\",\n        \"Minimal model semantics for nonmonotonic modal logics\",\n        \"Evaluating epistemic negation in answer set programming\",\n        \"Evaluating epistemic negation in answer set programming (extended abstract)\",\n        \"The proof theory and semantics of intuitionistic modal logic\",\n        \"Conformant Graphplan\",\n        \"On computing world views of epistemic logic programs\",\n        \"EHEX\",\n        \"Revisiting epistemic specifications\",\n        \"On the complexity of derivation in the propositional calculus\",\n        \"Polynomial-length planning spans the polynomial hierarchy\",\n        \"Notes on N-lattices and constructive logic with strong negation\",\n        \"A splitting set theorem for epistemic specifications\",\n        \"GISolver\",\n        \"PelpSolver\",\n        \"ESmodels: An epistemic specification solver\"\n    ],\n    \"reasoning\": \"Selected these 65 references because they represent foundational work and recent advances in Thirty years of Epistemic Specifications, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}