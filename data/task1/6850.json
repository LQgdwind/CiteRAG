{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 50 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: \\tool: Exploring and Curating Sparse Decision Trees with Interactive Visualization\n\nPaper Abstract: Abstract Given thousands of equally accurate machine learning (ML) models, how can users choose among them? A recent ML technique enables domain experts and data scientists to generate a complete Rashomon set for sparse decision trees—a huge set of almost-optimal interpretable ML models. To help ML practitioners identify models with desirable properties from this Rashomon set, we develop \\tool, the first interactive visualization system that summarizes thousands of sparse decision trees at scale. Two usage scenarios highlight how \\tool can empower users to easily explore, compare, and curate models that align with their domain knowledge and values. Our open-source tool runs directly in users’ computational notebooks and web browsers, lowering the barrier to creating more responsible ML models. \\tool is available at the following public demo link: \\linkhttps://poloclub.github.io/timbertrek.\n\n{retrieved_text}\n\nGenerate exactly 50 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 50\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Software Engineering for Machine Learning: A Case Study\",\n        \"Power to the People: The Role of Humans in Interactive Machine Learning\",\n        \"Guidelines for Human-AI Interaction\",\n        \"Knowledge Acquisition and Explanation for Multi-Attribute Decision Making\",\n        \"D3 Data-Driven Documents\",\n        \"Multi-Model Semantic Interaction for Text Analytics\",\n        \"Random forests\",\n        \"Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)\",\n        \"Classification and Regression Trees\",\n        \"Readings in Information Visualization: Using Vision to Think\",\n        \"Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission\",\n        \"Ablate, Variate, and Contemplate: Visual Analytics for Discovering Neural Architectures\",\n        \"How Interpretable and Trustworthy are GAMs?\",\n        \"The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations\",\n        \"VisRuler: Visual Analytics for Extracting Decision Rules from Bagged and Boosted Decision Trees\",\n        \"StackGenVis: Alignment of Data, Algorithms, and Models for Stacking Ensemble Learning Using Performance Metrics\",\n        \"Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments\",\n        \"Characterizing Fairness Over the Set of Good Models Under Selective Labels\",\n        \"BEAMES: Interactive Multimodel Steering, Selection, and Inspection for Regression Tasks\",\n        \"Exploring the Cloud of Variable Importance for the Set of All Good Models\",\n        \"All models are wrong, but many are useful: Learning a variable’s importance by studying an entire class of prediction models simultaneously\",\n        \"Greedy Function Approximation: A Gradient Boosting Machine\",\n        \"Robustness in Machine Learning Explanations: Does It Matter?\",\n        \"Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models\",\n        \"Optimal Sparse Decision Trees\",\n        \"Forward Stability and Model Path Selection\",\n        \"Jupyter Notebooks - a Publishing Format for Reproducible Computational Workflows\",\n        \"How We Analyzed the COMPAS Recidivism Algorithm\",\n        \"A Visual Analytics System for Multi-Model Comparison on Clinical Data Predictions\",\n        \"Generalized and Scalable Optimal Sparse Decision Trees\",\n        \"Fifty Years of Classification and Regression Trees: Fifty Years of Classification and Regression Trees\",\n        \"Problems in the Analysis of Survey Data, and a Proposal\",\n        \"TreePOD: Sensitivity-Aware Selection of Pareto-Optimal Decision Trees\",\n        \"Explainable Matrix - Visualization for Global and Local Interpretability of Random Forest Classification Ensembles\",\n        \"A Visualization Tool for Interactive Learning of Large Decision Trees\",\n        \"Accuracy, interpretability, and differential privacy via explainable boosting\",\n        \"Interactive Exploration of Parameter Space in Data Mining: Comprehending the Predictive Quality of Large Decision Tree Collections\",\n        \"Reactive, Reproducible, Collaborative: Computational Notebooks Evolve\",\n        \"Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead\",\n        \"Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges\",\n        \"Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations\",\n        \"Task-Based Visual Interactive Modeling: Decision Trees and Rule-Based Classifiers\",\n        \"Learning Optimized Risk Scores\",\n        \"In Pursuit of Interpretable, Fair and Accurate Machine Learning for Criminal Recidivism Prediction\",\n        \"StickyLand: Breaking the Linear Presentation of Computational Notebooks\",\n        \"Interpretability, Then What? Editing Machine Learning Models to Reflect Human Knowledge and Values\",\n        \"Exploring the Whole Rashomon Set of Sparse Decision Trees\",\n        \"Visual Exploration of Machine Learning Model Behavior with Hierarchical Surrogate Rule Sets\",\n        \"Escaping RGBland: Selecting colors for statistical graphics\",\n        \"iForest: Interpreting Random Forests via Visual Analytics\"\n    ],\n    \"reasoning\": \"Selected these 50 references because they represent foundational work and recent advances in \\\\tool: Exploring and Curating Sparse Decision Trees with Interactive Visualization, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}