{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 266 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: From Text to Life: On the Reciprocal Relationship between Artificial Life and Large Language Models\n\nPaper Abstract: Abstract Large Language Models (LLMs) have taken the field of AI by storm, but their adoption in the field of Artificial Life (ALife) has been, so far, relatively reserved. In this work we investigate the potential synergies between LLMs and ALife, drawing on a large body of research in the two fields. We explore the potential of LLMs as tools for ALife research, for example, as operators for evolutionary computation or the generation of open-ended environments. Reciprocally, principles of ALife, such as self-organization, collective intelligence and evolvability can provide an opportunity for shaping the development and functionalities of LLMs, leading to more adaptive and responsive models. By investigating this dynamic interplay, the paper aims to inspire innovative crossover approaches for both ALife and LLM research. Along the way, we examine the extent to which LLMs appear to increasingly exhibit properties such as emergence or collective intelligence, expanding beyond their original goal of generating text, and potentially redefining our perception of lifelike intelligence in artificial systems.\n\n{retrieved_text}\n\nGenerate exactly 266 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 266\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Can AI Solve Science?—Stephen Wolfram Writings\",\n        \"Large language models show human-like content biases in transmission chain experiments\",\n        \"Scaling laws for generative mixed-modal language models\",\n        \"The Past, Present, and Future of Artificial Life\",\n        \"Quantifying affordances through information theory\",\n        \"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances\",\n        \"Evolutionary Optimization of Model Merging Recipes\",\n        \"Rest meets react: Self-improvement for multi-step reasoning llm agent\",\n        \"Anthropic’s responsible scaling policy\",\n        \"Constitutional ai: Harmlessness from ai feedback\",\n        \"Self-organized criticality in the’game of life\",\n        \"Emergent tool use from multi-agent interaction\",\n        \"Emergent complexity via multi-agent competition\",\n        \"Defining and simulating open-ended novelty: requirements, guidelines, and challenges\",\n        \"Grounding cognition: heterarchical control mechanisms in biology\",\n        \"Open problems in artificial life\",\n        \"A classification of long-term evolutionary dynamics\",\n        \"Computational and dymamical languages for autonomous agents\",\n        \"What is cybernetics?\",\n        \"Artificial life: A constructive lower bound for artificial intelligence\",\n        \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? xn–st9h.\",\n        \"A neural probabilistic language model\",\n        \"A cellular platform for the development of synthetic living machines\",\n        \"Autonomy: What is it?\",\n        \"Intrinsic brain activity in altered states of consciousness: how conscious is the default mode of brain function?\",\n        \"Quality-Diversity through AI Feedback\",\n        \"The unconventionality of nature: biology, from noise to functional randomness\",\n        \"Machine culture\",\n        \"Rt-2: Vision-language-action models transfer web knowledge to robotic control\",\n        \"Language models are few-shot learners\",\n        \"Genie: Generative Interactive Environments\",\n        \"Sparks of artificial general intelligence: Early experiments with gpt-4\",\n        \"Codeit: Self-improving language models with prioritized hindsight replay\",\n        \"Rhythms of the Brain\",\n        \"Large language models as tool makers\",\n        \"Exploring the carbon footprint of hugging face’s ml models: A repository mining study\",\n        \"Robots: The century past and the century ahead, an introduction to the 2021 alife conference\",\n        \"Lenia-biology of artificial life\",\n        \"Lenia and expanded universe\",\n        \"Chateval: Towards better llm-based evaluators through multi-agent debate\",\n        \"Amorphous fortress: Observing emergent behavior in multi-agent fsms\",\n        \"EvoPrompting: Language Models for Code-Level Neural Architecture Search\",\n        \"Extending context window of large language models via positional interpolation\",\n        \"Teaching large language models to self-debug\",\n        \"Variational empowerment as representation learning for goal-based reinforcement learning\",\n        \"Emergence of self-replicating structures in a cellular automata space\",\n        \"Deep reinforcement learning from human preferences\",\n        \"Being there: Putting brain, body, and world together again\",\n        \"AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence\",\n        \"Autotelic agents with intrinsically motivated goal-conditioned reinforcement learning: a short survey\",\n        \"Augmenting autotelic agents with large language models\",\n        \"How intrinsic motivation can speed up language emergence\",\n        \"Excavating ai: The politics of images in machine learning training sets\",\n        \"From egocentric systems to systems allowing for theory of mind and mutualism\",\n        \"The wetware route to explore embodied cognition: A proposal\",\n        \"The Playful Machine, volume 15 of Cognitive Systems Monographs\",\n        \"Hybrid llm: Cost-efficient and quality-aware query routing\",\n        \"Exploring context window of large language models via decomposed positional vectors\",\n        \"Evolving self-organizing behaviors for a swarm-bot\",\n        \"What is artificial life today, and where should it go?\",\n        \"Improving factuality and reasoning in language models through multiagent debate\",\n        \"Guiding Pretraining in Reinforcement Learning with Large Language Models\",\n        \"Quality diversity in the amorphous fortress (qd-af): Evolving for complexity in 0-player games\",\n        \"Manipulating artificial ecosystems\",\n        \"AI-driven Automated Discovery Tools Reveal Diverse Behavioral Competencies of Biological Networks\",\n        \"Human-level play in the game of diplomacy by combining language models with strategic reasoning\",\n        \"Llmcarbon: Modeling the end-to-end carbon footprint of large language models\",\n        \"Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution\",\n        \"“The arrival of the fittest”: Toward a theory of biological organization\",\n        \"Intrinsically motivated goal exploration processes with automatic curriculum learning\",\n        \"Autonomy: a review and a reappraisal\",\n        \"Retrieval-augmented generation for large language models: A survey\",\n        \"Evoked brain responses are generated by feedback loops\",\n        \"Self-organization and artificial life: a review\",\n        \"Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data\",\n        \"Looped Transformers as Programmable Computers\",\n        \"The life of behavior\",\n        \"Critic: Large language models can self-correct with tool-interactive critiquing\",\n        \"Evocraft: A new challenge for open-endedness\",\n        \"Reinforced self-training (rest) for language modeling\",\n        \"Gmat: Global memory augmentation for transformers\",\n        \"A real-world webagent with planning, long context understanding, and program synthesis\",\n        \"Evolution of collective behaviors by minimizing surprise\",\n        \"Swarm robotics: A formal approach, volume 221\",\n        \"Discovering Sensorimotor Agency in Cellular Automata using Diversity Search\",\n        \"Inductive reasoning in humans and large language models\",\n        \"The CMA Evolution Strategy: A Tutorial\",\n        \"Environmental bias forces parasitism in tierra\",\n        \"Long short-term memory\",\n        \"Training compute-optimal large language models\",\n        \"Large Language Models for Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering\",\n        \"Hybrids and the Boundaries of Moral Considerability or Revisiting the Idea of Non-Instrumental Value\",\n        \"Metagpt: Meta programming for multi-agent collaborative framework\",\n        \"Neural networks and physical systems with emergent collective computational abilities\",\n        \"A history of autocatalytic sets: A tribute to stuart kauffman\",\n        \"Large language models can self-improve\",\n        \"Inner monologue: Embodied reasoning through planning with language models\",\n        \"Self-organized agents: A llm multi-agent framework toward ultra large-scale code generation and optimization\",\n        \"Co-writing with opinionated language models affects users’ views\",\n        \"Social influence as intrinsic motivation for multi-agent deep reinforcement learning\",\n        \"Perplexity—a measure of the difficulty of speech recognition tasks\",\n        \"AI Alignment: A Comprehensive Survey\",\n        \"Self-[in] correct: Llms struggle with refining self-generated responses\",\n        \"Llm maybe longlm: Self-extend llm context window without tuning\",\n        \"From Artificial Evolution to Artificial Life\",\n        \"Challenges and applications of large language models\",\n        \"Engineered self-organization for resilient robot self-assembly with minimal surprise\",\n        \"Scaling laws for neural language models\",\n        \"A comprehensive overview of the applications of artificial life\",\n        \"Nobel Turing Challenge: creating the engine for scientific discovery\",\n        \"Genetic programming as a means for programming computers by natural selection\",\n        \"SCENECRAFT: automating interactive narrative scene generation in digital games with large language models\",\n        \"PaperQA: Retrieval-Augmented Generative Agent for Scientific Research\",\n        \"Large Language Models As Evolution Strategies\",\n        \"Artificial Life: Proceedings Of An Interdisciplinary Workshop On The Synthesis And Simulation Of Living Systems\",\n        \"Self-reproduction in cellular automata\",\n        \"Artificial life: the proceedings of an interdisciplinary workshop on the synthesis and simulation of living systems, held september, 1987\",\n        \"Reassembling the social: An introduction to actor-network-theory\",\n        \"Machine love\",\n        \"The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities\",\n        \"Evolution through Large Models\",\n        \"Evolving a diversity of virtual creatures through novelty search and local competition\",\n        \"Beyond open-endedness: Quantifying impressiveness\",\n        \"Exploiting open-endedness to solve problems through the search for novelty\",\n        \"Mart: Memory-augmented recurrent transformer for coherent video paragraph captioning\",\n        \"Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models\",\n        \"Camel: Communicative agents for” mind” exploration of large language model society\",\n        \"Transformers as algorithms: generalization and stability in in-context learning\",\n        \"Encouraging divergent thinking in large language models through multi-agent debate\",\n        \"Learning to Model the World with Language\",\n        \"Ring attention with blockwise transformers for near-infinite context\",\n        \"ChatGPT-powered Conversational Drug Editing Using Retrieval and Domain Feedback\",\n        \"The data provenance initiative: A large scale audit of dataset licensing & attribution in ai\",\n        \"On the mechanisms of the feedback control of human brain wave activity\",\n        \"Self-refine: Iterative refinement with self-feedback\",\n        \"Artificial ecosystems for creative discovery\",\n        \"Is chatgpt really disembodied?\",\n        \"Artificial intelligence and illusions of understanding in scientific research\",\n        \"Language Model Crossover: Variation through Few-Shot Prompting\",\n        \"Natural behavior is the language of the brain\",\n        \"Large language models: A survey\",\n        \"The debate over understanding in AI’s large language models\",\n        \"Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks\",\n        \"Evaluating Cognitive Maps and Planning in Large Language Models with CogEval\",\n        \"Growing neural cellular automata\",\n        \"Generative representational instruction tuning\",\n        \"Programmable self-assembly using biologically-inspired multiagent control\",\n        \"Dera: enhancing large language model completions with dialog-enabled resolving agents\",\n        \"Towards self-assembling artificial neural networks through neural developmental programs\",\n        \"LLMatic: Neural Architecture Search via Large Language Models and Quality Diversity Optimization\",\n        \"The Oxford handbook of 4E cognition\",\n        \"Ca-neat: evolved compositional pattern producing networks for cellular automata morphogenesis and replication\",\n        \"Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making using Language Guided World Modelling\",\n        \"Avida: a software platform for research in computational evolutionary biology\",\n        \"Our responsible approach to meta ai and meta llama 3\",\n        \"What is intrinsic motivation? A typology of computational approaches\",\n        \"Training language models to follow instructions with human feedback\",\n        \"An overview of open-ended evolution: Editorial introduction to the open-ended evolution ii special issue\",\n        \"Lattice models for solidification and aggregation\",\n        \"Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies\",\n        \"Cooperative multi-agent learning: The state of the art\",\n        \"Interesting object, curious agent: Learning task-agnostic exploration\",\n        \"Generative agents: Interactive simulacra of human behavior\",\n        \"Learning to control self-assembling morphologies: a study of generalization via modularity\",\n        \"Simulations, Realizations, and Theories of Life\",\n        \"Rwkv: Reinventing rnns for the transformer era\",\n        \"Yarn: Efficient context window extension of large language models\",\n        \"Random feature attention\",\n        \"Self-reproducing machines\",\n        \"Unsupervised learning of goal spaces for intrinsically motivated goal exploration\",\n        \"Cultural evolution in populations of Large Language Models\",\n        \"Language Models as Knowledge Bases?\",\n        \"Ethical challenges in the development of virtual assistants powered by large language models\",\n        \"Information and self-organization of behavior\",\n        \"Aces: generating diverse programming puzzles with autotelic language models and semantic descriptors\",\n        \"Guided self-organization: Inception, volume 9\",\n        \"Tool learning with foundation models\",\n        \"A language-based recommendation system for material discovery\",\n        \"Learning transferable visual models from natural language supervision\",\n        \"Zero: Memory optimizations toward training trillion parameter models\",\n        \"Zero-shot text-to-image generation\",\n        \"An Approach to the Synthesis of Life\",\n        \"Evolution, ecology and optimization of digital organisms\",\n        \"Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems\",\n        \"Flocks, herds and schools: A distributed behavioral model\",\n        \"A sustainable ecosystem through emergent cooperation in multi-agent reinforcement learning\",\n        \"High-resolution image synthesis with latent diffusion models\",\n        \"Programmable self-assembly in a thousand-robot swarm\",\n        \"Basic autonomy as a fundamental step in the synthesis of life\",\n        \"Explorations of self-repair in language models\",\n        \"Swarm-bot: Pattern formation in a swarm of self-assembling mobile robots\",\n        \"Rainbow teaming: Open-ended generation of diverse adversarial prompts\",\n        \"Active role of self-sustained neural activity on sensory input processing: A minimal theoretical model\",\n        \"Are emergent abilities of large language models a mirage?\",\n        \"Toolformer: Language models can teach themselves to use tools\",\n        \"Memory Augmented Large Language Models are Computationally Universal\",\n        \"Picbreeder: A case study in collaborative evolutionary exploration of design space\",\n        \"Procedural Content Generation in Games\",\n        \"Probing the psychology of AI models\",\n        \"Human Learning from Artificial Intelligence: Evidence from Human Go Players’ Decisions after AlphaGo\",\n        \"On the mode of existence of technical objects\",\n        \"Evolving 3d morphology and behavior by competition\",\n        \"Fifty years of research on self-replication: An overview\",\n        \"The Problems of Biology\",\n        \"The major transitions in evolution\",\n        \"Necessary Conditions for Open-Ended Evolution\",\n        \"Identifying necessary conditions for open-ended evolution through the artificial life world of chromaria\",\n        \"Accelerating science with human-aware artificial intelligence\",\n        \"Body size, energy metabolism and lifespan\",\n        \"Art in the sciences of the artificial\",\n        \"Why open-endedness matters\",\n        \"MarioGPT: Open-Ended Text2Level Generation through Large Language Models\",\n        \"Reinforcement learning agents acquire flocking and symbiotic behaviour in simulated ecosystems\",\n        \"Efficient transformers: A survey\",\n        \"Rise of the self-replicators\",\n        \"Open-ended learning leads to generally capable agents\",\n        \"Level Generation Through Large Language Models\",\n        \"Many hands make light work: Group evolution and the emergent division of labour\",\n        \"Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\",\n        \"Autopoiesis: The organization of living systems, its characterization and a model\",\n        \"Principles of Biological Autonomy\",\n        \"Attention Is All You Need\",\n        \"From visual awareness to consciousness without sensory input: The role of spontaneous brain activity\",\n        \"Humans inherit artificial intelligence biases\",\n        \"Signal propagation and logic gating in networks of integrate-and-fire neurons\",\n        \"Theory of Self-Reproducing Automata\",\n        \"Symbiosis in digital evolution: A review and future directions\",\n        \"Neural machine translation with byte-level subwords\",\n        \"A survey on effective invocation methods of massive llm services\",\n        \"Voyager: An open-ended embodied agent with large language models\",\n        \"A survey on large language model based autonomous agents\",\n        \"POET: open-ended coevolution of environments and their optimized solutions\",\n        \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\",\n        \"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents\",\n        \"Jarvis-1: Open-world multi-task agents with memory-augmented multimodal language models\",\n        \"Emergent abilities of large language models\",\n        \"Chain-of-thought prompting elicits reasoning in large language models\",\n        \"Relationships between body size and abundance in ecology\",\n        \"Recommender systems and the amplification of extremist content\",\n        \"Homeostatic adaptive networks\",\n        \"Ethics of Artificial Life: The Moral Status of Life as It Could Be\",\n        \"Statistical mechanics of cellular automata\",\n        \"From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought\",\n        \"Body size in ecological networks\",\n        \"Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time\",\n        \"Next-gpt: Any-to-any multimodal llm\",\n        \"Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap\",\n        \"Parameter-efficient fine-tuning methods for pretrained language models: A critical review and assessment\",\n        \"Retrieval meets long context large language models\",\n        \"Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions\",\n        \"Tree of thoughts: Deliberate problem solving with large language models\",\n        \"Phylolm : Inferring the phylogeny of large language models and predicting their performances in benchmarks\",\n        \"From Text to Motion: Grounding GPT-4 in a Humanoid Robot ”Alter3”\",\n        \"Self-rewarding language models\",\n        \"Large language model cascades with mixture of thoughts representations for cost-efficient reasoning\",\n        \"Neural control of brain state\",\n        \"Big bird: Transformers for longer sequences\",\n        \"EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents\",\n        \"Star: Bootstrapping reasoning with reasoning\",\n        \"Socratic models: Composing zero-shot multimodal reasoning with language\",\n        \"Controlling large language model-based agents for large-scale decision-making: An actor-critic approach\",\n        \"Omni: Open-endedness via models of human notions of interestingness\",\n        \"A survey of large language models\",\n        \"Mindstorms in natural language-based societies of mind\",\n        \"Language agents as optimizable graphs\",\n        \"Can Large Language Models Transform Computational Social Science?\"\n    ],\n    \"reasoning\": \"Selected these 266 references because they represent foundational work and recent advances in From Text to Life: On the Reciprocal Relationship between Artificial Life and Large Language Models, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}