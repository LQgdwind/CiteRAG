{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 49 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Potential Impacts of Smart Homes on Human Behavior: A Reinforcement Learning Approach\n\nPaper Abstract: Abstract Smart homes are becoming increasingly popular as a result of advances in machine learning and cloud computing. Devices such as smart thermostats and speakers are now capable of learning from user feedback and adaptively adjust their settings to human preferences. Nonetheless, these devices might in turn impact human behaviour. To investigate the potential impacts of smart homes on human behavior we simulate a series of Hierarchical-Reinforcement Learning-based human models capable of performing various activities namely setting temperature and humidity for thermal comfort inside a Q-Learning-based smart home model. We then investigate the possibility of the human models’ behaviors being altered as a result of the smart home and the human model adapting to one another. For our human model, the activities are based on Hierarchical-Reinforcement Learning. This allows the human to learn how long it must continue a given activity and decide when to leave to pursue a different one. We then integrate our human model in the environment along with the smart home model and perform rigorous experiments considering various scenarios involving a single human model and two human models with the smart home. Our experiments show that with the smart home, the human model can exhibit unexpected behaviors like frequent changing of activities and an increase in the time required to modify the thermal preferences. With two human models, we interestingly observe that certain combinations of models result in normal behaviours, while other combinations exhibit the same unexpected behaviours as those observed from the single human experiment.\n\n{retrieved_text}\n\nGenerate exactly 49 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 49\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"State abstraction for programmable reinforcement learning agents\",\n        \"Standard 55-2010, thermal environmental conditions for human occupancy\",\n        \"A personalised thermal comfort model using a bayesian network\",\n        \"User comfort and energy efficiency in hvac systems by q-learning\",\n        \"Emergent tool use from multi-agent autocurricula\",\n        \"Model-based hierarchical reinforcement learning and human action control\",\n        \"Hierarchical reinforcement learning and decision making\",\n        \"Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective\",\n        \"Dopamine in motivational control: rewarding, aversive, and alerting\",\n        \"Back to basics: Benchmarking canonical evolution strategies for playing atari\",\n        \"Different levels of work-related stress and the effects on sleep, fatigue and cortisol\",\n        \"Effects of intrinsic motivation on feedback processing during learning\",\n        \"Hierarchical reinforcement learning with the maxq value function decomposition\",\n        \"Divide and conquer: hierarchical reinforcement learning and task decomposition in humans\",\n        \"Computational evidence for hierarchically structured reinforcement learning in humans\",\n        \"Energy-efficient thermal comfort control in smart buildings via deep reinforcement learning\",\n        \"Hierarchical reinforcement learning as a model of human task interleaving\",\n        \"Understanding dopamine and reinforcement learning: the dopamine reward prediction error hypothesis\",\n        \"A deep reinforcement learning-based autonomous ventilation control system for smart indoor air quality management in a subway station\",\n        \"The effects of intrinsic motivation on mental fatigue\",\n        \"Airscope: Mobile robots-assisted cooperative indoor air quality sensing by distributed deep reinforcement learning\",\n        \"Unity: A general platform for intelligent agents\",\n        \"The effects of level of automation and adaptive automation on human performance, situation awareness and workload in a dynamic control task\",\n        \"Dopamine prediction errors in reward learning and addiction: From theory to neural circuitry\",\n        \"Autonomous learning of user’s preference of music and light services in smart home applications\",\n        \"Effects of thermal discomfort in an office on perceived air quality, sbs symptoms, physiological responses, and human performance\",\n        \"The relationship between relative humidity and the dewpoint temperature in moist air: A simple conversion and applications\",\n        \"Dialogue learning with human-in-the-loop\",\n        \"An unsupervised user behavior prediction algorithm based on machine learning and neural network for smart home\",\n        \"Computational roles for dopamine in behavioural control\",\n        \"Happiness and productivity\",\n        \"The structure of reinforcement-learning mechanisms in the human brain\",\n        \"Newton’s law of cooling—a critical assessment\",\n        \"Lightlearn: An adaptive and occupant centered controller for lighting based on reinforcement learning\",\n        \"Trial without error: Towards safe reinforcement learning via human intervention\",\n        \"Hierarchical control of cognitive processes: switching tasks in sequences\",\n        \"A neural substrate of prediction and reward\",\n        \"Bored by interest: How intrinsic motivation in one task can reduce performance on other tasks\",\n        \"Introduction to reinforcement learning, volume 135\",\n        \"Cbe thermal comfort tool: Online tool for thermal comfort calculations and visualizations\",\n        \"Yerkes-dodson: A law for all seasons\",\n        \"Energy optimization associated with thermal comfort and indoor air control via a deep reinforcement learning algorithm\",\n        \"Human-like decision making: Document-level aspect sentiment classification via hierarchical reinforcement learning\",\n        \"Q-learning\",\n        \"Executive control: Attention switching, interruptions, and task management\",\n        \"Discrete task switching in overload: A meta-analyses and a model\",\n        \"Applied attention theory\",\n        \"Large-scale home energy management using entropy-based collective multiagent deep reinforcement learning framework\",\n        \"Leveraging human guidance for deep reinforcement learning tasks\"\n    ],\n    \"reasoning\": \"Selected these 49 references because they represent foundational work and recent advances in Potential Impacts of Smart Homes on Human Behavior: A Reinforcement Learning Approach, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}