{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 63 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Prediction-Powered Inference\n\nPaper Abstract: Abstract Prediction-powered inference is a framework for performing valid statistical inference when an experimental dataset is supplemented with predictions from a machine-learning system. The framework yields simple algorithms for computing provably valid confidence intervals for quantities such as means, quantiles, and linear and logistic regression coefficients, without making any assumptions on the machine-learning algorithm that supplies the predictions. Furthermore, more accurate predictions translate to smaller confidence intervals. Prediction-powered inference could enable researchers to draw valid and more data-efficient conclusions using machine learning. The benefits of prediction-powered inference are demonstrated with datasets from proteomics, astronomy, genomics, remote sensing, census analysis, and ecology.\n\n{retrieved_text}\n\nGenerate exactly 63 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 63\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Highly accurate protein structure prediction with AlphaFold\",\n        \"Highly accurate protein structure prediction for the human proteome\",\n        \"The structural context of posttranslational modifications at a proteome-wide scale\",\n        \"Clustering predicted structures at the scale of the known protein universe\",\n        \"Model Assisted Survey Sampling\",\n        \"Some results on generalized difference estimation and generalized regression estimation for finite populations\",\n        \"A Model-Calibration Approach to Using Complete Auxiliary Information From Survey Data\",\n        \"Model-assisted survey estimation with modern prediction techniques\",\n        \"Statistical Analysis with Missing Data\",\n        \"Estimation of regression coefficients when some regressors are not always observed\",\n        \"Semiparametric efficiency in multivariate regression models with missing data\",\n        \"Semiparametric efficient estimation for the auxiliary outcome problem with the conditional mean model\",\n        \"A revisit of semiparametric regression models with missing data\",\n        \"Measurement Error in Nonlinear Models: A Modern Perspective\",\n        \"Measurement error models with auxiliary data\",\n        \"Inference using surrogate outcome data and a validation sample\",\n        \"Information recovery in a study with surrogate endpoints\",\n        \"Statistical Analysis of Semi-Supervised Regression\",\n        \"Semi-supervised inference: General theory and estimation of means\",\n        \"Semi-Supervised Linear Regression\",\n        \"A General M-estimation Theory in Semi-Supervised Framework\",\n        \"Efficient and adaptive linear regression in semi-supervised settings\",\n        \"Semi-Supervised Quantile Estimation: Robust and Efficient Inference in High Dimensional Settings\",\n        \"A general framework for treatment effect estimation in semi-supervised and high dimensional settings\",\n        \"High-dimensional semi-supervised learning: in search of optimal inference of the mean\",\n        \"Optimal and Safe Estimation for High-Dimensional Semi-Supervised Learning\",\n        \"Surrogate assisted semi-supervised inference for high dimensional risk prediction\",\n        \"Semi-supervised learning literature survey\",\n        \"Introduction to semi-supervised learning\",\n        \"Predicting with proxies: Transfer learning in high dimension\",\n        \"Learning across bandits in high dimension via robust statistics\",\n        \"Transfer learning under high-dimensional generalized linear models\",\n        \"On transfer learning in functional linear regression\",\n        \"On the role of surrogates in the efficient estimation of treatment effects with limited outcome data\",\n        \"Methods for correcting inference based on outcomes predicted by machine learning\",\n        \"Regression quantiles\",\n        \"Exponential Families in Theory and Practice\",\n        \"ppi-py: A Python package for scientific discovery using machine learning\",\n        \"The importance of intrinsic disorder for protein phosphorylation\",\n        \"UniProt: a hub for protein information\",\n        \"Galaxy Zoo 2: detailed morphological classifications for 304 122 galaxies from the Sloan Digital Sky Survey\",\n        \"The sloan digital sky survey: Technical summary\",\n        \"The evolution, evolvability and engineering of gene regulatory DNA\",\n        \"Satellite-based estimates reveal widespread forest degradation in the Amazon\",\n        \"Global, 30-m resolution continuous fields of tree cover: Landsat-based rescaling of MODIS vegetation continuous fields with lidar-based estimates of error\",\n        \"Retiring adult: New datasets for fair machine learning\",\n        \"Xgboost: A scalable tree boosting system\",\n        \"An automated submersible flow cytometer for analyzing pico-and nanophytoplankton: FlowCytobot\",\n        \"WHOI-Plankton-a large scale fine grained visual recognition benchmark dataset for plankton classification\",\n        \"Detecting and correcting for label shift with black box predictors\",\n        \"Estimating means of bounded random variables by betting\",\n        \"Models as approximations I: Consequences illustrated with linear regression\",\n        \"Using least squares to approximate unknown regression functions\",\n        \"A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity\",\n        \"Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator\",\n        \"The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality\",\n        \"A short note on learning discrete distributions\",\n        \"On the central limit theorem for samples from a finite population\",\n        \"Sampling from a finite population. A remainder term estimate\",\n        \"PDB file parser and structure class implemented in Python\",\n        \"Deep residual learning for image recognition\",\n        \"Adam: A method for stochastic optimization\",\n        \"Decoupled weight decay regularization\"\n    ],\n    \"reasoning\": \"Selected these 63 references because they represent foundational work and recent advances in Prediction-Powered Inference, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}