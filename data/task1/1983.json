{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 52 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: A Gap-ETH-Tight Approximation Scheme for Euclidean TSP\n\nPaper Abstract: We revisit the classic task of finding the shortest tour of n𝑛n points in d𝑑d-dimensional Euclidean space, for any fixed constant d⩾2𝑑2d\\geqslant 2. We determine the optimal dependence on ε𝜀\\varepsilon in the running time of an algorithm that computes a (1+ε)1𝜀(1+\\varepsilon)-approximate tour, under a plausible assumption. Specifically, we give an algorithm that runs in 2𝒪​(1/εd−1)​n​log⁡nsuperscript2𝒪1superscript𝜀𝑑1𝑛𝑛2^{\\mathcal{O}(1/\\varepsilon^{d-1})}n\\log n time. This improves the previously smallest dependence on ε𝜀\\varepsilon in the running time (1/ε)𝒪​(1/εd−1)​n​log⁡nsuperscript1𝜀𝒪1superscript𝜀𝑑1𝑛𝑛(1/\\varepsilon)^{\\mathcal{O}(1/\\varepsilon^{d-1})}n\\log n of the algorithm by Rao and Smith (STOC 1998). We also show that a 2o​(1/εd−1)​poly​(n)superscript2𝑜1superscript𝜀𝑑1poly𝑛2^{o(1/\\varepsilon^{d-1})}\\mathrm{poly}(n) algorithm would violate the Gap-Exponential Time Hypothesis (Gap-ETH). Our new algorithm builds upon the celebrated quadtree-based methods initially proposed by Arora (J. ACM 1998), but it adds a new idea that we call sparsity-sensitive patching. On a high level this lets the granularity with which we simplify the tour depend on how sparse it is locally. We demonstrate that our technique extends to other problems, by showing that for Steiner Tree and Rectilinear Steiner Tree it yields the same running time. We complement our results with a matching Gap-ETH lower bound for Rectilinear Steiner Tree.\n\n{retrieved_text}\n\nGenerate exactly 52 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 52\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Polynomial Time Approximation Schemes for Euclidean Traveling Salesman and other Geometric Problems\",\n        \"Approximation schemes for NP-hard geometric optimization problems: a survey\",\n        \"A polynomial-time approximation scheme for weighted planar graph TSP\",\n        \"Approximation Schemes for Euclidean k-Medians and Related Problems\",\n        \"Approximation Algorithms for NP-Complete Problems on Planar Graphs\",\n        \"A Linear Time Approximation Scheme for Euclidean TSP\",\n        \"The Traveling Salesman Problem: Low-Dimensionality Implies a Polynomial Time Approximation Scheme\",\n        \"Light Euclidean Steiner Spanners in the Plane\",\n        \"Deterministic single exponential time algorithms for connectivity problems parameterized by treewidth\",\n        \"A Polynomial-Time Approximation Scheme for Euclidean Steiner Forest\",\n        \"Minor-free graphs have light spanners\",\n        \"Reducing curse of dimensionality: Improved PTAS for TSP (with neighborhoods) in doubling metrics\",\n        \"On the optimality of exact and approximation algorithms for scheduling problems\",\n        \"Fast Hamiltonicity Checking Via Bases of Perfect Matchings\",\n        \"A Polynomial Time Approximation Scheme for Euclidean Minimum Cost k-Connectivity\",\n        \"Polynomial-Time Approximation Schemes for the Euclidean Survivable Network Design Problem\",\n        \"On the Complexity of Approximating Euclidean Traveling Salesman Tours and Minimum Spanning Trees\",\n        \"An ETH-tight exact algorithm for Euclidean TSP\",\n        \"A Framework for Exponential-Time-Hypothesis-Tight Algorithms and Lower Bounds in Geometric Intersection Graphs\",\n        \"Contraction Decomposition in H-Minor-Free Graphs and Algorithmic Applications\",\n        \"Mildly exponential reduction from gap 3SAT to polynomial-gap label-cover\",\n        \"The Steiner problem in graphs\",\n        \"A survey on approximation in parameterized complexity: Hardness and algorithms\",\n        \"The greedy spanner is existentially optimal\",\n        \"The rectilinear steiner tree problem is NP-complete\",\n        \"Near-linear time approximation schemes for Steiner tree and forest in low-dimensional spaces\",\n        \"An approximation scheme for planar graph TSP\",\n        \"Fast greedy algorithms for constructing sparse geometric spanners\",\n        \"On Steiner’s problem with rectilinear distance\",\n        \"Geometric Approximation Algorithms\",\n        \"Hamilton Paths in Grid Graphs\",\n        \"ETH-Tight Algorithms for Geometric Network Problems\",\n        \"A Subset Spanner for Planar Graphs, with Application to Subset TSP\",\n        \"A linear-time approximation scheme for TSP in undirected planar graphs with edge-weights\",\n        \"A Nearly Linear-Time Approximation Scheme for the Euclidean k-Median Problem\",\n        \"Combinatorial Optimization: Theory and Algorithms\",\n        \"Algorithms on negatively curved spaces\",\n        \"A PTAS for subset TSP in minor-free graphs\",\n        \"Truly optimal euclidean spanners\",\n        \"Light Euclidean Spanners with Steiner Points\",\n        \"Planar formulae and their uses\",\n        \"A Birthday Repetition Theorem and Complexity of Approximating Dense CSPs\",\n        \"On the optimality of planar and geometric approximation schemes\",\n        \"Guillotine subdivisions approximate polygonal subdivisions: A simple polynomial-time approximation scheme for geometric TSP, k-MST, and related problems\",\n        \"Geometric Spanner Networks\",\n        \"Computational Complexity\",\n        \"The NP-Completeness of the Hamiltonian Cycle Problem in Planar Diagraphs with Degree Bound Two\",\n        \"Approximating Geometrical Graphs via Spanners and Banyans\",\n        \"On the Exact Location of Steiner Points in General Dimension\",\n        \"When Hamming Meets Euclid: The Approximability of Geometric TSP and Steiner Tree\",\n        \"Approximation Algorithms\",\n        \"The Design of Approximation Algorithms\"\n    ],\n    \"reasoning\": \"Selected these 52 references because they represent foundational work and recent advances in A Gap-ETH-Tight Approximation Scheme for Euclidean TSP, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}