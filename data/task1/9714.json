{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 339 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Large Language Models for Software Engineering: A Systematic Literature Review\n\nPaper Abstract: Abstract. Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We collect and analyze 229 research papers from 2017 to 2023 to answer four key research questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, preprocessing, and application highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and flagging promising areas for future study.\n\n{retrieved_text}\n\nGenerate exactly 339 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 339\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Software documentation: the practitioners’ perspective\",\n        \"Fixing Hardware Security Bugs with Large Language Models\",\n        \"Unified pre-training for program understanding and generation\",\n        \"Improving Few-Shot Prompts with Relevant Static Analysis Products\",\n        \"Compilers: principles, techniques, and tools. Vol. 2\",\n        \"Extending Source Code Pre-Trained Language Models to Summarise Decompiled Binarie\",\n        \"Evaluation of Context-Aware Language Models and Experts for Effort Estimation of Software Maintenance Issues\",\n        \"Control flow analysis\",\n        \"Stanford Alpaca: An Instruction-following LLaMA Model\",\n        \"Low level source code vulnerability detection using advanced bert language model\",\n        \"Syntax-guided synthesis\",\n        \"A study of visual studio usage in practice\",\n        \"Amazon CodeWhisperer\",\n        \"National vulnerability database\",\n        \"Exploring Distributional Shifts in Large Language Models for Code Analysis\",\n        \"ChatGPT is a Remarkable Tool–For Experts\",\n        \"Code generation tools (almost) for free? a study of few-shot, pre-trained language models on code\",\n        \"Case tool support for variability management in software product lines\",\n        \"Marcelo Sant’Anna\",\n        \"The Technology Behind BLOOM Training\",\n        \"Mehmet Efruz Karabulut\",\n        \"Gpt-neox-20b: An open-source autoregressive language model\",\n        \"GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow\",\n        \"Language models are few-shot learners\",\n        \"Sparks of artificial general intelligence: Early experiments with gpt-4\",\n        \"CodeTF: One-stop Transformer Library for State-of-the-art Code LLM\",\n        \"A study on prompt design, advantages and limitations of chatgpt for deep learning program repair\",\n        \"MultiPL-E: a scalable and polyglot approach to benchmarking neural code generation\",\n        \"Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning?\",\n        \"A survey on evaluation of large language models\",\n        \"A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification\",\n        \"Improving code generation by training with natural language feedback\",\n        \"Evaluating large language models trained on code\",\n        \"Teaching large language models to self-debug\",\n        \"Towards synthesizing complex programs from input-output examples\",\n        \"Latent execution for neural program synthesis beyond domain-specific languages\",\n        \"DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection\",\n        \"Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality\",\n        \"Agnieszka Ciborowska and Kostadin Damevski\",\n        \"Too Few Bug Reports? Exploring Data Augmentation for Improved Changeset-based Bug Localization\",\n        \"An empirical study on the usage of transformer models for code completion\",\n        \"PyMT5: multi-mode translation of natural language and Python code with transformers\",\n        \"Jailbreaker: Automated Jailbreak Across Multiple Large Language Model Chatbots\",\n        \"PentestGPT: An LLM-empowered Automatic Penetration Testing Tool\",\n        \"Chunqiu Steven Xia\",\n        \"Large language models are edge-case fuzzers: Testing deep learning libraries via fuzzgpt\",\n        \"Bert: Pre-training of deep bidirectional transformers for language understanding\",\n        \"Development of recommendation systems for software engineering: the CROSSMINER experience\",\n        \"Aligning Offline Metrics and Human Judgments of Value of AI-Pair Programmers\",\n        \"A static evaluation of code completion by large language models\",\n        \"Benjamin CM Fung\",\n        \"Large Language Models of Code Fail at Completing Code with Potential Bugs\",\n        \"Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?\",\n        \"Self-collaboration Code Generation via ChatGPT\",\n        \"Towards Understanding the Capability of Large Language Models on Code Clone Detection: A Survey\",\n        \"ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation\",\n        \"Marco Castelluccio\",\n        \"On the Impossible Safety of Large AI Models\",\n        \"LangKit: Making Large Language Models Safe and Responsible\",\n        \"Sallam Abualhaija\",\n        \"Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions\",\n        \"A bibliometric review of large language models research from 2017 to 2023\",\n        \"Recommender systems in the era of large language models (llms)\",\n        \"Abhik Roychoudhury\",\n        \"Automated Repair of Programs from Large Language Models\",\n        \"Flakify: A black-box, language model-based predictor for flaky tests\",\n        \"Prompting Is All Your Need: Automated Android Bug Replay with Large Language Models\",\n        \"Codebert: A pre-trained model for programming and natural languages\",\n        \"SecureFalcon: The Next Cyber Reasoning System for Cyber Security\",\n        \"Does automated unit test generation really help software testers? a controlled empirical study\",\n        \"Incoder: A generative model for code infilling and synthesis\",\n        \"GPT2SP: A transformer-based agile story point estimation approach\",\n        \"Natural Language Commanding via Program Synthesis\",\n        \"The pile: An 800gb dataset of diverse text for language modeling\",\n        \"Constructing Effective In-Context Demonstration for Code Intelligence Tasks: An Empirical Study\",\n        \"Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning\",\n        \"Denys Poshyvanyk\",\n        \"Augmenting commit classification by using fine-grained source code changes and a pre-trained deep neural language model\",\n        \"Semantic Compression With Large Language Models\",\n        \"Github copilot\",\n        \"BERT-and TF-IDF-based feature extraction for long-lived bug prediction in FLOSS: a comparative study\",\n        \"What is the intended usage context of this model? An exploratory study of pre-trained models on various model repositories\",\n        \"Ppt: Pre-trained prompt tuning for few-shot learning\",\n        \"Graphcodebert: Pre-training code representations with data flow\",\n        \"GrACE: Generation using Associated Code Edits\",\n        \"Ptr: Prompt tuning with rules for text classification\",\n        \"Getting pwn’d by AI: Penetration Testing with Large Language Models\",\n        \"Kieker: A monitoring framework for software engineering research\",\n        \"Representation Learning for Stack Overflow Posts: How Far are We?\",\n        \"Few-shot learning for sentence pair classification and its applications in software engineering\",\n        \"Karl Trygve Kalleberg\",\n        \"Measuring coding challenge competence with apps\",\n        \"Leopoldo Teixeira\",\n        \"LLaMA Efficient Tuning\",\n        \"Training compute-optimal large language models\",\n        \"Augmenting Greybox Fuzzing with Generative AI\",\n        \"ANPL: Compiling Natural Programs with Interactive Decomposition\",\n        \"API Entity and Relation Joint Extraction from Text via Dynamic Prompt-tuned Language Model\",\n        \"A Chain of AI-based Solutions for Resolving FQNs and Fixing Syntax Errors in Partial Code\",\n        \"AI Chain on Large Language Model for Unsupervised Control Flow Graph Generation for Statically-Typed Partial Code\",\n        \"Codesearchnet challenge: Evaluating the state of semantic code search\",\n        \"Dilara Tekinoglu\",\n        \"Md Rakibul Islam and Minhaz F Zibran\",\n        \"Hironori Washizaki\",\n        \"Roberta Gismondi\",\n        \"Skanda Vaidyanath\",\n        \"Attention, Compilation, and Solver-based Symbolic Analysis are All You Need\",\n        \"Learning to predict user-defined types\",\n        \"SelfEvolve: A Code Evolution Framework via Large Language Models\",\n        \"Self-planning code generation with large language model\",\n        \"Automated expansion of abbreviations based on semantic relation and transfer expansion\",\n        \"Inferfix: End-to-end program repair with llms\",\n        \"Capturing failures of large language models via human cognitive biases\",\n        \"The future of software development powered by AI\",\n        \"Gogul Balakrishnan\",\n        \"Explainable Automated Debugging via Large Language Model-driven Scientific Debugging\",\n        \"Large language models are few-shot testers: Exploring llm-based general bug reproduction\",\n        \"Scelmo: Source code embeddings from language models\",\n        \"Discriminating Human-authored from ChatGPT-Generated Code Via Discernable Feature Analysis\",\n        \"PAC Prediction Sets for Large Language Models of Code\",\n        \"Md Tawkat Islam Khondaker\",\n        \"Junaed Younus Khan and Gias Uddin\",\n        \"xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval\",\n        \"Efficient Mutation Testing via Pre-Trained Language Models\",\n        \"Guidelines for performing systematic literature reviews in software engineering\",\n        \"SEGRESS: Software engineering guidelines for reporting secondary studies\",\n        \"An exploratory study of how developers seek, relate, and collect relevant information during software maintenance tasks\",\n        \"Detecting Phishing Sites Using ChatGPT\",\n        \"Large language models are zero-shot reasoners\",\n        \"Data-driven prototyping via natural-language-based GUI retrieval\",\n        \"Automated Summarization of Stack Overflow Posts\",\n        \"Is Model Attention Aligned with Human Attention? An Empirical Study on Large Language Models for Code Generation\",\n        \"GitHub Copilot AI Is Leaking Functional API Keys\",\n        \"Less is more: Summary of long instructions is better for program synthesis\",\n        \"Interactive code generation via test-driven user-intent formalization\",\n        \"Luke Zettlemoyer\",\n        \"Albert: A lite bert for self-supervised learning of language representations\",\n        \"A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets\",\n        \"Truong Giang Nguyen\",\n        \"Invalidator: Automated patch correctness assessment via semantic and syntactic reasoning\",\n        \"The power of scale for parameter-efficient prompt tuning\",\n        \"Generation-Augmented Query Expansion For Code Retrieval\",\n        \"Jennifer Horkoff\",\n        \"Enabling Programming Thinking in Large Language Models Toward Code Generation\",\n        \"Poison Attack and Defense on Deep Source Code Processing Models\",\n        \"Static analysis of android apps: A systematic literature review\",\n        \"CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors\",\n        \"Finding Failure-Inducing Test Cases with ChatGPT\",\n        \"Prefix-tuning: Optimizing continuous prompts for generation\",\n        \"Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation\",\n        \"Competition-level code generation with alphacode\",\n        \"Exploring the Effectiveness of LLMs in Automated Logging Generation: An Empirical Study\",\n        \"Do Pre-trained Language Models Indeed Understand Software Engineering Tasks?\",\n        \"CCTEST: Testing and Repairing Code Completion Systems\",\n        \"Yuding Liang and Kenny Zhu\",\n        \"Improving ChatGPT Prompt for Code Generation\",\n        \"Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation\",\n        \"Recurrent neural network for text classification with multi-task learning\",\n        \"Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing\",\n        \"RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems\",\n        \"Prompt Injection attack against LLM-integrated Applications\",\n        \"Refining ChatGPT-Generated Code: Characterizing and Mitigating Code Quality Issues\",\n        \"Roberta: A robustly optimized bert pretraining approach\",\n        \"Deep learning for android malware defenses: a systematic literature review\",\n        \"Codexglue: A machine learning benchmark dataset for code understanding and generation\",\n        \"ChatGPT, an artificial intelligence chatbot, is impacting medical literature\",\n        \"Improving Requirements Completeness: Automated Assistance through Large Language Models\",\n        \"WizardCoder: Empowering Code Large Language Models with Evol-Instruct\",\n        \"The Scope of ChatGPT in Software Engineering: A Thorough Investigation\",\n        \"Are Code Pre-trained Models Powerful to Learn Code Syntax and Semantics?\",\n        \"Learning performance-improving code edits\",\n        \"Language models of code are few-shot commonsense learners\",\n        \"Large Language Models Based Automatic Synthesis of Software Specifications\",\n        \"The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation\",\n        \"A deductive approach to program synthesis\",\n        \"Mariano Graziano\",\n        \"Using transfer learning for code-related tasks\",\n        \"Simone Scalabrino\",\n        \"Code Llama: Open Foundation Models for Code\",\n        \"Bing Chat\",\n        \"Understanding the role of training regimes in continual learning\",\n        \"Ambarish Moharil and Arpit Sharma\",\n        \"TABASCO: A Transformer Based Contextualization Toolkit\",\n        \"Robert C Moore and William Lewis\",\n        \"Google Brain unveils trillion-parameter AI language model, the largest yet\",\n        \"Stack Over-Flowing with Results: The Case for Domain-Specific Pre-Training Over One-Size-Fits-All Models\",\n        \"CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code Authoring\",\n        \"GoldMax, GoldFinder, and Sibot: Analyzing NOBELIUM’s layered persistence\",\n        \"Anh Nguyen-Tuong\",\n        \"Comparing Software Developers with ChatGPT: An Empirical Investigation\",\n        \"LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization\",\n        \"Anh Tuan Nguyen and Tien N Nguyen\",\n        \"Is this Snippet Written by ChatGPT? An Empirical Study with a CodeBERT-Based Classifier\",\n        \"Query expansion based on crowd knowledge for code search\",\n        \"Codegen2: Lessons for training llms on programming and natural languages\",\n        \"Codegen: An open large language model for code with multi-turn program synthesis\",\n        \"A conversational paradigm for program synthesis\",\n        \"Krishna Narasimhan\",\n        \"Demystifying GPT Self-Repair for Code Generation\",\n        \"Free and open source software license compliance: tools for software composition analysis\",\n        \"Chatgpt: Optimizing language models for dialogue\",\n        \"Code Interpreter\",\n        \"GPT-4 Technical Report\",\n        \"Training language models to follow instructions with human feedback\",\n        \"LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation\",\n        \"Stack Overflow\",\n        \"Understanding the Effectiveness of Large Language Models in Code Translation\",\n        \"Unifying Large Language Models and Knowledge Graphs: A Roadmap\",\n        \"Neuro-symbolic program synthesis\",\n        \"Gorilla: Large language model connected with massive apis\",\n        \"Automated Program Repair Based on Code Review: How do Pre-trained Transformer Models Perform?\",\n        \"Enhancing Automated Program Repair through Fine-tuning and Prompt Engineering\",\n        \"Examining zero-shot vulnerability repair with large language models\",\n        \"QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models\",\n        \"Trex: Learning execution semantics from micro-traces for binary similarity\",\n        \"Cotext: Multi-task learning with code-text transformer\",\n        \"Local type inference\",\n        \"Making the most of small Software Engineering datasets with modern machine learning\",\n        \"From Copilot to Pilot: Towards AI Supported Software Development\",\n        \"Communicative Agents for Software Development\",\n        \"Improving language understanding by generative pre-training\",\n        \"Language models are unsupervised multitask learners\",\n        \"Exploring the limits of transfer learning with a unified text-to-text transformer\",\n        \"Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study\",\n        \"A systematic review of interaction in search-based software engineering\",\n        \"Preventing Abuse of LLMs’ Alignment Deficit by Injection Neutralization (PALADIN)\",\n        \"Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks\",\n        \"AI for Low-Code for AI\",\n        \"Developing safety-critical software: a practical guide for aviation software and DO-178C compliance\",\n        \"Risks and benefits of large language models for the environment\",\n        \"What makes APIs hard to learn? Answers from developers\",\n        \"A field study of API learning obstacles\",\n        \"Dobf: A deobfuscation pre-training objective for programming languages\",\n        \"Multilingual Adapter-based Knowledge Aggregation on Code Summarization for Low-Resource Languages\",\n        \"Utilization of Pre-trained Language Model for Adapter-based Knowledge Transfer in Software Engineering\",\n        \"Analysis of ChatGPT on Source Code\",\n        \"On Contrastive Learning of Semantic Similarity forCode to Code Search\",\n        \"Extending the Frontier of ChatGPT: Code Generation and Debugging\",\n        \"On the effectiveness of transfer learning for code search\",\n        \"Bloom: A 176b-parameter open-access multilingual language model\",\n        \"Adaptive test generation using a large language model\",\n        \"Large Language Model Programs\",\n        \"Oussama Ben Sghaier and Houari Sahraoui\",\n        \"Talking about large language models\",\n        \"Benchmarking Language Models for Code Syntax Understanding\",\n        \"Exploring the Robustness of Large Language Models for Solving Programming Problems\",\n        \"A Lightweight Framework for High-Quality Code Generation\",\n        \"Exploring the Effectiveness of Large Language Models in Generating Unit Tests\",\n        \"Evaluating ChatGPT and GPT-4 for Visual Programming\",\n        \"An analysis of the automatic bug fixing performance of chatgpt\",\n        \"ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks\",\n        \"When GPT Meets Program Analysis: Towards Intelligent Detection of Smart Contract Logic Vulnerabilities in GPTScan\",\n        \"Code and named entity recognition in stackoverflow\",\n        \"Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based Large Language Models\",\n        \"CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection\",\n        \"ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation\",\n        \"The potential of LLMs for coding with low-resource and domain-specific programming languages\",\n        \"Galactica: A large language model for science\",\n        \"VeriGen: A Large Language Model for Verilog Code Generation\",\n        \"Muhammad Ejaz Ahmed\",\n        \"Abdoul Kader Kaboré\",\n        \"The Best of Both Worlds: Combining Learned Embeddings with Engineered Features for Accurate Prediction of Correct Patches\",\n        \"Is ChatGPT the Ultimate Programming Assistant–How far is it?\",\n        \"The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification\",\n        \"Llama: Open and efficient foundation language models\",\n        \"Llama 2: Open foundation and fine-tuned chat models\",\n        \"Multimodal few-shot learning with frozen language models\",\n        \"LLM4CBI: Taming LLMs to Generate Effective Test Programs for Compiler Bug Isolation\",\n        \"Predicting Code Coverage without Execution\",\n        \"Antonio Mastropaolo\",\n        \"Attention is all you need\",\n        \"Can Large Language Models Write Good Property-Based Tests?\",\n        \"On the validity of pre-trained transformers for natural language processing in the software engineering domain\",\n        \"GPT-J-6B: A 6 billion parameter autoregressive language model\",\n        \"Software Testing with Large Language Model: Survey, Landscape, and Vision\",\n        \"Evaluating AIGC Detectors on Code Content\",\n        \"Machine/deep learning for software engineering: A systematic literature review\",\n        \"Measuring and Mitigating Constraint Violations of In-Context Learning for Utterance-to-API Semantic Parsing\",\n        \"ReCode: Robustness Evaluation of Code Generation Models\",\n        \"Modular tree network for source code representation learning\",\n        \"LeTI: Learning to Generate from Textual Interactions\",\n        \"Syncobert: Syntax-guided multi-modal contrastive pre-training for code representation\",\n        \"Codet5+: Open code large language models for code understanding and generation\",\n        \"Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation\",\n        \"Chain-of-thought prompting elicits reasoning in large language models\",\n        \"Nima Shiri Harzevili\",\n        \"On the Usage of Continual Learning for Out-of-Distribution Generalization in Pre-trained Language Models of Code\",\n        \"A prompt pattern catalog to enhance prompt engineering with chatgpt\",\n        \"Chatgpt prompt patterns for improving code quality, refactoring, requirements elicitation, and software design\",\n        \"Addressing Compiler Errors: Stack Overflow or Large Language Models?\",\n        \"Natural Language Generation and Understanding of Big Code for AI-Assisted Programming: A Review\",\n        \"Defending ChatGPT against Jailbreak Attack via Self-Reminder\",\n        \"Kenneth Koedinger\",\n        \"How Effective Are Neural Networks for Fixing Security Vulnerabilities\",\n        \"Practical program repair in the era of large pre-trained language models\",\n        \"Conversational automated program repair\",\n        \"Chunqiu Steven Xia and Lingming Zhang\",\n        \"ChatUniTest: a ChatGPT-based automated unit test generation tool\",\n        \"and Vincent Josua Hellendoorn\",\n        \"LmPa: Improving Decompilation by Synergy of Large Language Model and Program Analysis\",\n        \"Junaed Younus Khan\",\n        \"and Cristina Videira Lopes\",\n        \"A Syntax-Guided Multi-Task Learning Approach for Turducken-Style Code Generation\",\n        \"Harnessing the power of llms in practice: A survey on chatgpt and beyond\",\n        \"Quality assessment in systematic literature reviews: A software engineering perspective\",\n        \"A survey on deep learning for software engineering\",\n        \"Stealthy Backdoor Attack for Code Models\",\n        \"Generating Data for Symbolic Language with Large Language Models\",\n        \"Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT\",\n        \"A syntactic neural model for general-purpose code generation\",\n        \"Chinese LLaMA & Alpaca Large Language Models\",\n        \"CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models\",\n        \"Nguyen Quoc Viet Hung\",\n        \"Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation\",\n        \"No More Manual Tests? Evaluating and Improving ChatGPT for Unit Test Generation\",\n        \"Private-library-oriented code generation with large language models\",\n        \"When language model meets private library\",\n        \"CERT: Continual Pre-training on Sketches for Library-oriented Code Generation\",\n        \"Identifying relevant studies in software engineering\",\n        \"BEQAIN: An Effective and Efficient Identifier Normalization Approach With BERT and the Question Answering System\",\n        \"Multilingual Code Co-Evolution Using Large Language Models\",\n        \"Sheena Panthaplackel\",\n        \"ToolCoder: Teach Code Generation Models to use APIs with search tools\",\n        \"Self-Edit: Fault-Aware Code Editor for Code Generation\",\n        \"ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers\",\n        \"Boosting Automated Patch Correctness Prediction via Pre-trained Language Model\",\n        \"Duplicate bug report detection: How far are we?\",\n        \"Stefanus Agus Haryono\",\n        \"Neural Program Repair with Program Dependence Analysis and Effective Filter Mechanism\",\n        \"Understanding Programs by Exploiting (Fuzzing) Test Cases\",\n        \"A survey of large language models\",\n        \"Automatic Model Selection with Large Language Models for Reasoning\",\n        \"On the impact of sample duplication in machine-learning-based android malware detection\",\n        \"Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x\",\n        \"Outline, then details: Syntactically guided coarse-to-fine code generation\",\n        \"UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition\",\n        \"Large Language Models Are Human-Level Prompt Engineers\",\n        \"Automating Method Naming with Context-Aware Prompt-Tuning\",\n        \"Root causing, detecting, and fixing flaky tests: State of the art and future roadmap\"\n    ],\n    \"reasoning\": \"Selected these 339 references because they represent foundational work and recent advances in Large Language Models for Software Engineering: A Systematic Literature Review, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}