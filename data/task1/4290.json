{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 46 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Spline-PINN: Approaching PDEs without Data using Fast, Physics-Informed Hermite-Spline CNNs\n\nPaper Abstract: Abstract Partial Differential Equations (PDEs) are notoriously difficult to solve. In general, closed-form solutions are not available and numerical approximation schemes are computationally expensive. In this paper, we propose to approach the solution of PDEs based on a novel technique that combines the advantages of two recently emerging machine learning based approaches. First, physics-informed neural networks (PINNs) learn continuous solutions of PDEs and can be trained with little to no ground truth data. However, PINNs do not generalize well to unseen domains. Second, convolutional neural networks provide fast inference and generalize but either require large amounts of training data or a physics-constrained loss based on finite differences that can lead to inaccuracies and discretization artifacts. We leverage the advantages of both of these approaches by using Hermite spline kernels in order to continuously interpolate a grid-based state representation that can be handled by a CNN. This allows for training without any precomputed training data using a physics-informed loss function only and provides fast, continuous solutions that generalize to unseen domains. We demonstrate the potential of our method at the examples of the incompressible Navier-Stokes equation and the damped wave equation. Our models are able to learn several intriguing phenomena such as Karman vortex streets, the Magnus effect, Doppler effect, interference patterns and wave reflections. Our quantitative assessment and an interactive real-time demo show that we are narrowing the gap in accuracy of unsupervised ML based methods to industrial solvers for computational fluid dynamics (CFD) while being orders of magnitude faster.\n\n{retrieved_text}\n\nGenerate exactly 46 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 46\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Deep unsupervised learning of turbulence for inflow generation at various reynolds numbers\",\n        \"Embedding hard physical constraints in neural network coarse-graining of 3d turbulence\",\n        \"Deep learning methods for reynolds-averaged navier–stokes simulations of airfoil flows\",\n        \"Solver-in-the-loop: Learning from differentiable physics to interact with iterative pde-solvers\",\n        \"Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations\",\n        \"Learning mesh-based simulation with graph networks\",\n        \"Deep fluids: A generative network for parameterized fluid simulations\",\n        \"Data-driven fluid simulations using regression forests\",\n        \"Accelerating eulerian fluid simulation with convolutional networks\",\n        \"Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data\",\n        \"Learning incompressible fluid dynamics from scratch - towards fast, differentiable fluid models that generalize\",\n        \"Teaching the incompressible navier-stokes equations to fast neural surrogate models in 3d\",\n        \"Nsfnets (navier-stokes flow nets): Physics-informed neural networks for the incompressible navier-stokes equations\",\n        \"Hidden fluid mechanics: A navier-stokes informed deep learning framework for assimilating flow visualization data\",\n        \"The cfd benchmarking project\",\n        \"Smoothed particle hydrodynamics: theory and application to non-spherical stars\",\n        \"Flexible neural representation for physics prediction\",\n        \"Learning particle dynamics for manipulating rigid bodies, deformable objects, and fluids\",\n        \"Lagrangian fluid simulation with continuous convolutions\",\n        \"Spnets: Differentiable fluid dynamics for deep neural networks\",\n        \"Realistic animation of liquids\",\n        \"Dgm: A deep learning algorithm for solving partial differential equations\",\n        \"A proof that artificial neural networks overcome the curse of dimensionality in the numerical approximation of black-scholes partial differential equations\",\n        \"Solving for high-dimensional committor functions using artificial neural networks\",\n        \"Deepxde: A deep learning library for solving differential equations\",\n        \"Bayesian deep convolutional encoder–decoder networks for surrogate modeling and uncertainty quantification\",\n        \"Deep uq: Learning deep neural network surrogate models for high dimensional uncertainty quantification\",\n        \"Data-driven projection method in fluid simulation\",\n        \"Quantifying model form uncertainty in reynolds-averaged turbulence models with bayesian deep neural networks\",\n        \"Reynolds averaged turbulence modelling using deep neural networks with embedded invariance\",\n        \"Physics-informed neural networks (pinns) for wave propagation and full waveform inversions\",\n        \"Implicit neural representations with periodic activation functions\",\n        \"Predictive collective variable discovery with deep bayesian models\",\n        \"Train once and use forever: Solving boundary value problems in unseen domains with pre-trained deep learning models\",\n        \"Lattice boltzmann method for fluid flows\",\n        \"Well-balanced lattice boltzmann model for two-phase systems\",\n        \"Numerical calculation of time-dependent viscous incompressible flow of fluid with free surface\",\n        \"Stable fluids\",\n        \"Modeling the dynamics of pde systems with physics-constrained deep auto-regressive networks\",\n        \"Direct prediction of steady-state flow fields in meshed domain with graph networks\",\n        \"Learning to simulate complex physics with graph networks\",\n        \"Physics-informed graph neural galerkin networks: A unified framework for solving pde-governed forward and inverse problems\",\n        \"Galerkin neural networks: A framework for approximating variational equations with error control\",\n        \"Splinecnn: Fast geometric deep learning with continuous b-spline kernels\",\n        \"U-net: Convolutional networks for biomedical image segmentation\",\n        \"Understanding and mitigating gradient pathologies in physics-informed neural networks\"\n    ],\n    \"reasoning\": \"Selected these 46 references because they represent foundational work and recent advances in Spline-PINN: Approaching PDEs without Data using Fast, Physics-Informed Hermite-Spline CNNs, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}