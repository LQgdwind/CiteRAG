{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 43 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: EA4RCA: Efficient AIE accelerator design framework for Regular Communication-Avoiding Algorithm\n\nPaper Abstract: Abstract. With the introduction of the Adaptive Intelligence Engine (AIE), the Versal Adaptive Compute Acceleration Platform (Versal ACAP) has garnered great attention. However, the current focus of Vitis Libraries and limited research has mainly been on how to invoke AIE modules, without delving into a thorough discussion on effectively utilizing AIE in its typical use cases. As a result, the widespread adoption of Versal ACAP has been restricted. The Communication Avoidance (CA) algorithm is considered a typical application within the AIE architecture. Nevertheless, the effective utilization of AIE in CA applications remains an area that requires further exploration. We propose a top-down customized design framework, EA4RCA(Efficient AIE accelerator design framework for regular Communication-Avoiding Algorithm), specifically tailored for CA algorithms with regular communication patterns, and equipped with AIE Graph Code Generator software to accelerate the AIE design process. The primary objective of this framework is to maximize the performance of AIE while incorporating high-speed data streaming services. Experiments show that for the RCA algorithm Filter2D and Matrix Multiple (MM) with lower communication requirements and the RCA algorithm FFT with higher communication requirements, the accelerators implemented by the RA4RCA framework achieve the highest throughput improvements of 22.19x, 1.05x and 3.88x compared with the current highest performance acceleration scheme (SOTA), and the highest energy efficiency improvements of 6.11x, 1.30x and 7.00x.\n\n{retrieved_text}\n\nGenerate exactly 43 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 43\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Vitis Accelerated Libraries\",\n        \"Xilinx First 7nm Device: Versal AI Core (VC1902)\",\n        \"Customized Computing Challenge 2023\",\n        \"Performance Analysis of Parallel FFT on Large Multi-GPU Systems\",\n        \"Exploring the Versal AI Engines for Accelerating Stencil-based Atmospheric Advection Simulation\",\n        \"A decoupled access-execute architecture for reconfigurable accelerators\",\n        \"DGNN-Booster: A Generic FPGA Accelerator Framework For Dynamic Graph Neural Network Inference\",\n        \"Flexible Communication Avoiding Matrix Multiplication on FPGA with High-Level Synthesis\",\n        \"Communication avoiding algorithms\",\n        \"Communication-Avoiding Optimizations for Large-Scale Unstructured-Mesh Applications with OP2\",\n        \"Xilinx Adaptive Compute Acceleration Platform: VersalTM Architecture\",\n        \"Challenging the limits of FFT performance on FPGAs (Invited paper)\",\n        \"Efficient Implementation of a Genetic Algorithm for the Capacitated Vehicle Routing Problem on a High-Performance FPGA\",\n        \"Communication-Avoiding and Memory-Constrained Sparse Matrix-Matrix Multiplication at Extreme Scale\",\n        \"XVDPU: A High Performance CNN Accelerator on the Versal Platform Powered by the AI Engine\",\n        \"Accelerating 128-bit Floating-Point Matrix Multiplication on FPGAs\",\n        \"Design of High-Throughput Mixed-Precision CNN Accelerators on FPGA\",\n        \"Toward Matrix Multiplication for Deep Learning Inference on the Xilinx Versal\",\n        \"GEMM-Like Convolution for Deep Learning Inference on the Xilinx Versal\",\n        \"gPPM: A Generalized Matrix Operation and Parallel Algorithm to Accelerate the Encoding/Decoding Process of Erasure Codes\",\n        \"Building a Performance Model for Deep Learning Recommendation Model Training on GPUs\",\n        \"Nonuniform Fast Fourier Transform on Tpus\",\n        \"Plasticine: A Reconfigurable Accelerator for Parallel Patterns\",\n        \"SPARTA: Spatial Acceleration for Efficient and Scalable Horizontal Diffusion Weather Stencil Computation\",\n        \"Decoupled Access/Execute Computer Architectures\",\n        \"A fast fourier transform subroutine for ILLIAC IV\",\n        \"BAX: A Bundle Adjustment Accelerator With Decoupled Access/Execute Architecture for Visual Odometry\",\n        \"Network-on-Chip Programmable Platform in VersalTM ACAP Architecture\",\n        \"Versal Network-on-Chip (NoC)\",\n        \"An algorithm for the machine calculation of complex Fourier series\",\n        \"Versal: The Xilinx Adaptive Compute Acceleration Platform (ACAP)\",\n        \"A New Input Grouping and Sharing Method to Design Low Complexity FFT Implementation\",\n        \"QUANTIZATION EFFECTS IN DIGITAL FILTERS\",\n        \"A High-Performance CNN Processor Based on FPGA for MobileNets\",\n        \"AIM: Accelerating Arbitrary-Precision Integer Multiplication on Heterogeneous Reconfigurable Computing Platform Versal ACAP\",\n        \"EAIS: Energy-aware adaptive scheduling for CNN inference on high-performance GPUs\",\n        \"Communication-avoiding kernel ridge regression on parallel and distributed systems\",\n        \"H-GCN: A Graph Convolutional Network Accelerator on Versal ACAP Architecture\",\n        \"A-U3D: A Unified 2D/3D CNN Accelerator on the Versal Platform for Disparity Estimation\",\n        \"A New Multichannel Parallel Real-time FFT Algorithm for a Solar Radio Observation System Based on FPGA\",\n        \"MFFT: A GPU Accelerated Highly Efficient Mixed-Precision Large-Scale FFT Framework\",\n        \"Communication Avoiding All-Pairs Shortest Paths Algorithm for Sparse Graphs\",\n        \"CHARM: Composing Heterogeneous AcceleRators for Matrix Multiply on Versal ACAP Architecture\"\n    ],\n    \"reasoning\": \"Selected these 43 references because they represent foundational work and recent advances in EA4RCA: Efficient AIE accelerator design framework for Regular Communication-Avoiding Algorithm, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}