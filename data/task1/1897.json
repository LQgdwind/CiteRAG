{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 65 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: On the Robustness of Noise-Blind Low-Rank Recovery from Rank-One Measurements\n\nPaper Abstract: Abstract We prove new results about the robustness of well-known convex noise-blind optimization formulations for the reconstruction of low-rank matrices from underdetermined linear measurements. Our results are applicable for symmetric rank-one measurements as used in a formulation of the phase retrieval problem. We obtain these results by establishing that with high probability rank-one measurement operators defined by i.i.d. Gaussian vectors exhibit the so-called Schatten-111 quotient property, which corresponds to a lower bound for the inradius of their image of the nuclear norm (Schatten-111) unit ball. We complement our analysis by numerical experiments comparing the solutions of noise-blind and noise-aware formulations. These experiments confirm that noise-blind optimization methods exhibit comparable robustness to noise-aware formulations. Keywords: low-rank matrix recovery, phase retrieval, quotient property, noise-blind, robustness, nuclear norm minimization\n\n{retrieved_text}\n\nGenerate exactly 65 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 65\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Breaking the coherence barrier: A new theory for compressed sensing\",\n        \"Blind deconvolution using convex programming\",\n        \"Compressive wideband power spectrum estimation\",\n        \"Square-root lasso: pivotal recovery of sparse signals via conic programming\",\n        \"Matrix Analysis, volume 169 of Graduate Texts in Mathematics\",\n        \"Robustness to unknown error in sparse regularization\",\n        \"The restricted isometry property and its implications for compressed sensing\",\n        \"Phase Retrieval via Matrix Completion\",\n        \"Solving quadratic equations via phaselift when there are about as many equations as unknowns\",\n        \"Phase retrieval from coded diffraction patterns\",\n        \"Matrix completion with noise\",\n        \"Tight oracle inequalities for low-rank matrix recovery from a minimal number of noisy random measurements\",\n        \"Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information\",\n        \"Stable signal recovery from incomplete and inaccurate measurements\",\n        \"Phaselift: Exact and stable signal recovery from magnitude measurements via convex programming\",\n        \"Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?\",\n        \"The power of convex relaxation: Near-optimal matrix completion\",\n        \"Exact and stable covariance estimation from quadratic sampling via convex programming\",\n        \"The distribution of quadratic forms in a normal system, with applications to the analysis of covariance\",\n        \"Compressed sensing and best k-term approximation\",\n        \"Asymptotic shape of a random polytope in a convex body\",\n        \"Iteratively reweighted least squares minimization for sparse recovery\",\n        \"Stable optimizationless recovery from phaseless linear measurements\",\n        \"Instance-optimality in probability with an ‚Ñì1subscript‚Ñì1\\\\ell_{1}-minimization decoder\",\n        \"Compressed sensing\",\n        \"Optimally sparse representation in general (nonorthogonal) dictionaries via l1 minimization\",\n        \"Matrix Rank Minimization with Applications\",\n        \"Quantum tomography via compressed sensing: error bounds, sample complexity and efficient estimators\",\n        \"Low-rank matrix recovery via iteratively reweighted least squares minimization\",\n        \"Stability and robustness of ‚Ñì1subscript‚Ñì1\\\\ell_{1}-minimizations with weibull matrices and redundant dictionaries\",\n        \"A mathematical introduction to compressive sensing\",\n        \"High dimensional matrix estimation with unknown variance of the noise\",\n        \"Extremal Properties of Orthogonal Parallelepipeds and Their Applications to the Geometry of Banach Spaces\",\n        \"CVX: Matlab Software for Disciplined Convex Programming, Version 2.2\",\n        \"Quantum state tomography via compressed sensing\",\n        \"On the geometry of polytopes generated by heavy-tailed random vectors\",\n        \"Toeplitz compressed sensing matrices with applications to sparse channel estimation\",\n        \"Blind demixing and deconvolution at near-optimal rate\",\n        \"Stable low-rank matrix recovery via null space properties\",\n        \"Matrix Factorization Techniques for Recommender Systems\",\n        \"Suprema of chaos processes and the restricted isometry property\",\n        \"On the convex geometry of blind deconvolution and matrix completion\",\n        \"Stable and robust sampling strategies for compressive imaging\",\n        \"Low rank matrix recovery from rank one measurements\",\n        \"Harmonic Mean Iteratively Reweighted Least Squares for Low-Rank Matrix Recovery\",\n        \"Improved iteratively reweighted least squares for unconstrained smoothed ‚Ñìqsubscript‚Ñìùëû\\\\ell_{q} minimization\",\n        \"Recovering second-order statistics from compressive measurements\",\n        \"Smallest singular value of random matrices and geometry of random polytopes\",\n        \"Universal low-rank matrix recovery from Pauli measurements\",\n        \"Compressed sensing mri\",\n        \"Sparse recovery under weak moment assumptions\",\n        \"Sparse approximate solutions to linear systems\",\n        \"CoSaMP: Iterative signal recovery from incomplete and inaccurate samples\",\n        \"Robust instance-optimal recovery of sparse signals at unknown noise levels\",\n        \"Compressive sensing and structured random matrices\",\n        \"Restricted isometries for partial random circulant matrices\",\n        \"Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization\",\n        \"On sparse reconstruction from Fourier and Gaussian measurements\",\n        \"Regularization-free estimation in trace regression with symmetric positive semidefinite matrices\",\n        \"Multiplexed coded illumination for fourier ptychography with an led array microscope\",\n        \"Regression shrinkage and selection via the lasso\",\n        \"Signal recovery from random measurements via orthogonal matching pursuit\",\n        \"Solving semidefinite-quadratic-linear programs using sdpt3\",\n        \"High-Dimensional Probability\",\n        \"Stability and instance optimality for Gaussian measurements in compressed sensing\"\n    ],\n    \"reasoning\": \"Selected these 65 references because they represent foundational work and recent advances in On the Robustness of Noise-Blind Low-Rank Recovery from Rank-One Measurements, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}