{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional academic reference prediction expert. Your task is to predict the most likely references for a given academic paper based on its title, abstract, and retrieved relevant papers.\n\nRETRIEVER INTERFACE:\n- Input: paper title + abstract\n- Output: {top_r} retrieved papers with title and abstract\n- Format: List of dictionaries with 'title' and 'abstract' fields\n\nREQUIREMENTS:\n1. Analyze the paper's title and abstract to understand its research area and focus\n2. Consider the retrieved papers as potential references (when available)\n3. Generate a list of predicted reference titles that would be most relevant and likely to be cited\n4. Provide reasoning for each prediction to prevent hallucination\n5. Output format: JSON object with \"titles\" array and \"reasoning\" string\n6. Generate exactly 52 most relevant reference titles (this should be at least 40 to cover all evaluation metrics)\n7. Ensure titles are realistic and appropriate for the research area\n8. Consider citation patterns in the field\n9. CRITICAL: Each title must be unique - never repeat the same title multiple times\n\nEXAMPLE:\nInput:\nTitle: \"Question Type Classification Methods Comparison\"\nAbstract: \"The paper presents a comparative study of state-of-the-art approaches for question classification task: Logistic Regression, Convolutional Neural Networks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent Neural Networks (QRNN). All models use pre-trained GLoVe word embeddings and trained on human-labeled data. The best accuracy is achieved using CNN model with five convolutional layers and various kernel sizes stacked in parallel, followed by one fully connected layer. The model reached 90.7% accuracy on TREC 10 test set.\"\n\nRetrieved papers ({top_r}):\n1. Title: Convolutional Neural Networks for Sentence Classification\n   Abstract: We report on a series of experiments with convolutional neural networks trained on top of pre-trained word vectors for sentence-level classification tasks.\n\n2. Title: Glove: Global vectors for word representation\n   Abstract: We present a new global log-bilinear regression model that combines the advantages of the two major model families in the literature.\n\nOutput:\n{\n  \"titles\": [\n    \"Convolutional Neural Networks for Sentence Classification\",\n    \"Glove: Global vectors for word representation\",\n    \"Quasi-Recurrent Neural Networks\",\n    \"A Comparative Study of Neural Network Models for Sentence Classification\",\n    \"Deep lstm based feature mapping for query classification\"\n  ],\n  \"reasoning\": \"Based on the paper's focus on question classification using neural networks, I predict these references because: 1) CNN paper is directly relevant to the convolutional approach used; 2) GloVe embeddings are mentioned as pre-trained features; 3) QRNN is one of the compared methods; 4) Comparative study papers are common in this field; 5) LSTM-based query classification is closely related to question classification. Additional references cover related neural network architectures, NLP applications, deep learning methodologies, optimization techniques, and advanced neural network methods that would be relevant for this research area.\"\n}\n\nReturn JSON object only."
    },
    {
      "role": "user",
      "content": "Paper Title: Parallel-friendly Spatio-Temporal Graph Learning for Photovoltaic Degradation Analysis at Scale\n\nPaper Abstract: Abstract. We propose a novel Spatio-Temporal Graph Neural Network empowered trend analysis approach (ST-GTrend) to perform fleet-level performance degradation analysis for Photovoltaic (PV) power networks. PV power stations have become an integral component to the global sustainable energy production landscape. Accurately estimating the performance of PV systems is critical to their feasibility as a power generation technology and as a financial asset. One of the most challenging problems in assessing the Levelized Cost of Energy (LCOE) of a PV system is to understand and estimate the long-term Performance Loss Rate (PLR) for large fleets of PV inverters. ST-GTrend integrates spatio-temporal coherence and graph attention to separate PLR as a long-term “aging” trend from multiple fluctuation terms in the PV input data. To cope with diverse degradation patterns in timeseries, ST-GTrend adopts a paralleled graph autoencoder array to extract aging and fluctuation terms simultaneously. ST-GTrend imposes flatness and smoothness regularization to ensure the disentanglement between aging and fluctuation. To scale the analysis to large PV systems, we also introduce Para-GTrend, a parallel algorithm to accelerate the training and inference of ST-GTrend. We have evaluated ST-GTrend on three large-scale PV datasets, spanning a time period of 10 years. Our results show that ST-GTrend reduces Mean Absolute Percent Error (MAPE) and Euclidean Distances by 34.74% and 33.66% compared to the SOTA methods. Our results demonstrate that Para-GTrend can speed up ST-GTrend by up to 7.92 times. We further verify the generality and effectiveness of ST-GTrend for trend analysis using financial and economic datasets. Our source code, datasets, and a full version of the paper are made available. 111https://github.com/Yangxin666/ST-GTrend\n\n{retrieved_text}\n\nGenerate exactly 52 most likely reference titles for this paper. Focus on papers that are directly related to the research topic, provide foundational background, present similar methodologies, or address related problems.\n\nCRITICAL: Each title must appear exactly once. Do not repeat any title.\n\nIMPORTANT: You must respond with ONLY valid JSON in this exact format:\n{\n    \"titles\": [\n        \"Reference Title 1\",\n        \"Reference Title 2\",\n        \"Reference Title 3\",\n        \"Reference Title 4\",\n        \"Reference Title 52\"\n    ],\n    \"reasoning\": \"Explain why you chose these specific references based on the paper's title, abstract, and retrieved papers. This helps prevent hallucination and ensures relevance.\"\n}\n\nDo not include any text before or after the JSON. Do not include authors, venues, or years - only the paper titles. The reasoning field is required to explain your prediction logic."
    },
    {
      "role": "assistant",
      "content": "{\n    \"titles\": [\n        \"Artificial intelligence modelling integrated with Singular Spectral analysis and Seasonal-Trend decomposition using Loess approaches for streamflow predictions\",\n        \"Adaptive graph convolutional recurrent network for traffic forecasting\",\n        \"Demystifying parallel and distributed deep learning: An in-depth concurrency analysis\",\n        \"Parallel and distributed graph neural networks: An in-depth concurrency analysis\",\n        \"Determining the power rate of change of 353 plant inverters time-series data across multiple climate zones, using a month-by-month data science analysis\",\n        \"Forecasting stock market returns by combining sum-of-the-parts and ensemble empirical mode decomposition\",\n        \"Assumptions and the levelized cost of energy for photovoltaics\",\n        \"Reducing Uncertainty of Fielded Photovoltaic Performance (Final Technical Report)\",\n        \"Multi-step-ahead stock price index forecasting using long short-term memory model with multivariate empirical mode decomposition\",\n        \"CVXPY: A Python-embedded modeling language for convex optimization\",\n        \"Distributed graph simulation: Impossibility and possibility\",\n        \"Spatio-Temporal Denoising Graph Autoencoders with Data Augmentation for Photovoltaic Data Imputation\",\n        \"PVplr-stGNN\",\n        \"Context-aware spatial-temporal neural network for citywide crowd flow prediction via modeling long-range spatial dependency\",\n        \"Fast Graph Representation Learning with PyTorch Geometric\",\n        \"Assessment of performance loss rate of PV power systems\",\n        \"Efficient Graph Neural Network Inference at Large Scale\",\n        \"A path to reduce variability of the environmental footprint results of photovoltaic systems\",\n        \"A review on degradation models in reliability analysis\",\n        \"Analysis of stress-induced degradation in CdS/CdTe solar cells\",\n        \"The empirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis\",\n        \"A power-rating model for crystalline silicon PV modules\",\n        \"Comparison of statistical and deterministic smoothing methods to reduce the uncertainty of performance loss rate estimates\",\n        \"Robust PV degradation methodology and application\",\n        \"PV Degradation Curves: Non-Linearities and Failure Modes\",\n        \"Photovoltaic lifetime forecast model based on degradation patterns\",\n        \"Spatiotemporal Graph Neural Network for Performance Prediction of Photovoltaic Power Systems\",\n        \"Field experience with a new performance characterization procedure for photovoltaic arrays\",\n        \"Semi-Supervised Classification with Graph Convolutional Networks\",\n        \"Analysis of scalability of parallel algorithms and architectures: A survey\",\n        \"Review of statistical and analytical degradation models for photovoltaic modules and systems as well as related improvements\",\n        \"Best practices for photovoltaic performance loss rate calculations\",\n        \"Performance loss rate of twelve photovoltaic technologies under field conditions using statistical techniques\",\n        \"Analysis of economic growth fluctuations based on EEMD and causal decomposition\",\n        \"Estimation of Soiling Losses in Unlabeled PV Data\",\n        \"PipeDream: Generalized pipeline parallelism for DNN training\",\n        \"Toward findable, accessible, interoperable and reusable (fair) photovoltaic system time series data\",\n        \"Design of experiments and focused grid search for neural network parameter optimization\",\n        \"PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models\",\n        \"Multiscaled neural autoregressive distributed lag: A new empirical mode decomposition model for nonlinear time series forecasting\",\n        \"Structured sequence modeling with graph convolutional recurrent networks\",\n        \"A review on degradation modelling and its engineering applications\",\n        \"Masked label prediction: Unified message passing model for semi-supervised classification\",\n        \"Spatio-temporal graph neural networks for multi-site PV power forecasting\",\n        \"Multiple seasonal STL decomposition with discrete-interval moving seasonalities\",\n        \"Efficient long-term degradation profiling in time series for complex physical systems\",\n        \"Graph attention networks\",\n        \"CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting\",\n        \"A comprehensive survey on graph neural networks\",\n        \"Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting\",\n        \"Gman: A graph multi-attention network for traffic prediction\",\n        \"Distdgl: distributed graph neural network training for billion-scale graphs\"\n    ],\n    \"reasoning\": \"Selected these 52 references because they represent foundational work and recent advances in Parallel-friendly Spatio-Temporal Graph Learning for Photovoltaic Degradation Analysis at Scale, providing essential background knowledge and methodological foundations relevant to this research.\"\n}"
    }
  ],
  "format": "chatml"
}